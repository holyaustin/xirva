[{"id": "2002.00011", "submitter": "Chi Nok Enoch Kan", "authors": "Chi Nok Enoch Kan, Najibakram Maheenaboobacker, Dong Hye Ye", "title": "Age-Conditioned Synthesis of Pediatric Computed Tomography with\n  Auxiliary Classifier Generative Adversarial Networks", "comments": "Accepted for publication at IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2020", "journal-ref": "2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI\n  2020)", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a popular and powerful tool in computed tomography (CT)\nimage processing such as organ segmentation, but its requirement of large\ntraining datasets remains a challenge. Even though there is a large anatomical\nvariability for children during their growth, the training datasets for\npediatric CT scans are especially hard to obtain due to risks of radiation to\nchildren. In this paper, we propose a method to conditionally synthesize\nrealistic pediatric CT images using a new auxiliary classifier generative\nadversarial network (ACGAN) architecture by taking age information into\naccount. The proposed network generated age-conditioned high-resolution CT\nimages to enrich pediatric training datasets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:52:10 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Kan", "Chi Nok Enoch", ""], ["Maheenaboobacker", "Najibakram", ""], ["Ye", "Dong Hye", ""]]}, {"id": "2002.00022", "submitter": "Jun-Jie Huang", "authors": "Jun-Jie Huang and Pier Luigi Dragotti", "title": "Learning Deep Analysis Dictionaries -- Part II: Convolutional\n  Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a Deep Convolutional Analysis Dictionary Model\n(DeepCAM) by learning convolutional dictionaries instead of unstructured\ndictionaries as in the case of deep analysis dictionary model introduced in the\ncompanion paper. Convolutional dictionaries are more suitable for processing\nhigh-dimensional signals like for example images and have only a small number\nof free parameters. By exploiting the properties of a convolutional dictionary,\nwe present an efficient convolutional analysis dictionary learning approach. A\nL-layer DeepCAM consists of L layers of convolutional analysis dictionary and\nelement-wise soft-thresholding pairs and a single layer of convolutional\nsynthesis dictionary. Similar to DeepAM, each convolutional analysis dictionary\nis composed of a convolutional Information Preserving Analysis Dictionary\n(IPAD) and a convolutional Clustering Analysis Dictionary (CAD). The IPAD and\nthe CAD are learned using variations of the proposed learning algorithm. We\ndemonstrate that DeepCAM is an effective multilayer convolutional model and, on\nsingle image super-resolution, achieves performance comparable with other\nmethods while also showing good generalization capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:02:10 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Huang", "Jun-Jie", ""], ["Dragotti", "Pier Luigi", ""]]}, {"id": "2002.00025", "submitter": "Tankut Can", "authors": "Tankut Can, Kamesh Krishnamurthy, David J. Schwab", "title": "Gating creates slow modes and controls phase-space complexity in GRUs\n  and LSTMs", "comments": "18+18 pages, 4 figures, to appear in Proceedings of Machine Learning\n  Research Vol. 107, 2020, 1st Annual Conference on Mathematical and Scientific\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful dynamical models for data with\ncomplex temporal structure. However, training RNNs has traditionally proved\nchallenging due to exploding or vanishing of gradients. RNN models such as\nLSTMs and GRUs (and their variants) significantly mitigate these issues\nassociated with training by introducing various types of gating units into the\narchitecture. While these gates empirically improve performance, how the\naddition of gates influences the dynamics and trainability of GRUs and LSTMs is\nnot well understood. Here, we take the perspective of studying randomly\ninitialized LSTMs and GRUs as dynamical systems, and ask how the salient\ndynamical properties are shaped by the gates. We leverage tools from random\nmatrix theory and mean-field theory to study the state-to-state Jacobians of\nGRUs and LSTMs. We show that the update gate in the GRU and the forget gate in\nthe LSTM can lead to an accumulation of slow modes in the dynamics. Moreover,\nthe GRU update gate can poise the system at a marginally stable point. The\nreset gate in the GRU and the output and input gates in the LSTM control the\nspectral radius of the Jacobian, and the GRU reset gate also modulates the\ncomplexity of the landscape of fixed-points. Furthermore, for the GRU we obtain\na phase diagram describing the statistical properties of fixed-points. We also\nprovide a preliminary comparison of training performance to the various\ndynamical regimes realized by varying hyperparameters. Looking to the future,\nwe have introduced a powerful set of techniques which can be adapted to a broad\nclass of RNNs, to study the influence of various architectural choices on\ndynamics, and potentially motivate the principled discovery of novel\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:09:37 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 23:14:05 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Can", "Tankut", ""], ["Krishnamurthy", "Kamesh", ""], ["Schwab", "David J.", ""]]}, {"id": "2002.00027", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle and Rodolfo Anibal Lobo", "title": "Hypercomplex-Valued Recurrent Correlation Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.12.034", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent correlation neural networks (RCNNs), introduced by Chiueh and\nGoodman as an improved version of the bipolar correlation-based Hopfield neural\nnetwork, can be used to implement high-capacity associative memories. In this\npaper, we extend the bipolar RCNNs for processing hypercomplex-valued data.\nPrecisely, we present the mathematical background for a broad class of\nhypercomplex-valued RCNNs. Then, we provide the necessary conditions which\nensure that a hypercomplex-valued RCNN always settles at an equilibrium using\neither synchronous or asynchronous update modes. Examples with bipolar,\ncomplex, hyperbolic, quaternion, and octonion-valued RCNNs are given to\nillustrate the theoretical results. Finally, computational experiments confirm\nthe potential application of hypercomplex-valued RCNNs as associative memories\ndesigned for the storage and recall of gray-scale images.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:14:19 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Valle", "Marcos Eduardo", ""], ["Lobo", "Rodolfo Anibal", ""]]}, {"id": "2002.00041", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Ben Poole", "title": "On Implicit Regularization in $\\beta$-VAEs", "comments": "ICML 2020; Final version, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the impact of variational inference (VI) on posterior inference in a\nfixed generative model is well-characterized, its role in regularizing a\nlearned generative model when used in variational autoencoders (VAEs) is poorly\nunderstood. We study the regularizing effects of variational distributions on\nlearning in generative models from two perspectives. First, we analyze the role\nthat the choice of variational family plays in imparting uniqueness to the\nlearned model by restricting the set of optimal generative models. Second, we\nstudy the regularization effect of the variational family on the local geometry\nof the decoding model. This analysis uncovers the regularizer implicit in the\n$\\beta$-VAE objective, and leads to an approximation consisting of a\ndeterministic autoencoding objective plus analytic regularizers that depend on\nthe Hessian or Jacobian of the decoding model, unifying VAEs with recent\nheuristics proposed for training regularized autoencoders. We empirically\nverify these findings, observing that the proposed deterministic objective\nexhibits similar behavior to the $\\beta$-VAE in terms of objective value and\nsample quality.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:57:52 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 16:24:19 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 05:30:42 GMT"}, {"version": "v4", "created": "Mon, 28 Dec 2020 22:36:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kumar", "Abhishek", ""], ["Poole", "Ben", ""]]}, {"id": "2002.00053", "submitter": "Jo\\~ao E. Batista", "authors": "Jo\\~ao E. Batista, Sara Silva", "title": "Improving the Detection of Burnt Areas in Remote Sensing using\n  Hyper-features Evolved by M3GP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One problem found when working with satellite images is the radiometric\nvariations across the image and different images. Intending to improve remote\nsensing models for the classification of burnt areas, we set two objectives.\nThe first is to understand the relationship between feature spaces and the\npredictive ability of the models, allowing us to explain the differences\nbetween learning and generalization when training and testing in different\ndatasets. We find that training on datasets built from more than one image\nprovides models that generalize better. These results are explained by\nvisualizing the dispersion of values on the feature space. The second objective\nis to evolve hyper-features that improve the performance of different\nclassifiers on a variety of test sets. We find the hyper-features to be\nbeneficial, and obtain the best models with XGBoost, even if the hyper-features\nare optimized for a different method.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 20:42:15 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Batista", "Jo\u00e3o E.", ""], ["Silva", "Sara", ""]]}, {"id": "2002.00057", "submitter": "Noah Golowich", "authors": "Noah Golowich, Sarath Pattathil, Constantinos Daskalakis, Asuman\n  Ozdaglar", "title": "Last Iterate is Slower than Averaged Iterate in Smooth Convex-Concave\n  Saddle Point Problems", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the smooth convex-concave saddle point problem.\nSpecifically, we analyze the last iterate convergence properties of the\nExtragradient (EG) algorithm. It is well known that the ergodic (averaged)\niterates of EG converge at a rate of $O(1/T)$ (Nemirovski, 2004). In this\npaper, we show that the last iterate of EG converges at a rate of\n$O(1/\\sqrt{T})$. To the best of our knowledge, this is the first paper to\nprovide a convergence rate guarantee for the last iterate of EG for the smooth\nconvex-concave saddle point problem. Moreover, we show that this rate is tight\nby proving a lower bound of $\\Omega(1/\\sqrt{T})$ for the last iterate. This\nlower bound therefore shows a quadratic separation of the convergence rates of\nergodic and last iterates in smooth convex-concave saddle point problems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:05:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 03:20:34 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Golowich", "Noah", ""], ["Pattathil", "Sarath", ""], ["Daskalakis", "Constantinos", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.00059", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Risto Miikkulainen", "title": "Optimizing Loss Functions Through Multivariate Taylor Polynomial\n  Parameterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metalearning of deep neural network (DNN) architectures and hyperparameters\nhas become an increasingly important area of research. Loss functions are a\ntype of metaknowledge that is crucial to effective training of DNNs, however,\ntheir potential role in metalearning has not yet been fully explored. Whereas\nearly work focused on genetic programming (GP) on tree representations, this\npaper proposes continuous CMA-ES optimization of multivariate Taylor polynomial\nparameterizations. This approach, TaylorGLO, makes it possible to represent and\nsearch useful loss functions more effectively. In MNIST, CIFAR-10, and SVHN\nbenchmark tasks, TaylorGLO finds new loss functions that outperform functions\npreviously discovered through GP, as well as the standard cross-entropy loss,\nin fewer generations. These functions serve to regularize the learning task by\ndiscouraging overfitting to the labels, which is particularly useful in tasks\nwhere limited training data is available. The results thus demonstrate that\nloss function optimization is a productive new avenue for metalearning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:25:37 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 17:28:04 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 05:44:27 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 05:29:18 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.00066", "submitter": "Ville Rimpil\\\"ainen", "authors": "Alexandra Koulouri and Ville Rimpilainen", "title": "Simultaneous Skull Conductivity and Focal Source Imaging from EEG\n  Recordings with the help of Bayesian Uncertainty Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electroencephalography (EEG) source imaging problem is very sensitive to\nthe electrical modelling of the skull of the patient under examination.\nUnfortunately, the currently available EEG devices and their embedded software\ndo not take this into account; instead, it is common to use a literature-based\nskull conductivity parameter. In this paper, we propose a statistical method\nbased on the Bayesian approximation error approach to compensate for source\nimaging errors due to the unknown skull conductivity and, simultaneously, to\ncompute a low-order estimate for the actual skull conductivity value. By using\nsimulated EEG data that corresponds to focal source activity, we demonstrate\nthe potential of the method to reconstruct the underlying focal sources and\nlow-order errors induced by the unknown skull conductivity. Subsequently, the\nestimated errors are used to approximate the skull conductivity. The results\nindicate clear improvements in the source localization accuracy and feasible\nskull conductivity estimates.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 21:33:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Koulouri", "Alexandra", ""], ["Rimpilainen", "Ville", ""]]}, {"id": "2002.00072", "submitter": "Alessandro Lameiras Koerich", "authors": "Steve Tsham Mpinda Ataky and Jonathan de Matos and Alceu de S. Britto\n  Jr. and Luiz E. S. Oliveira and Alessandro L. Koerich", "title": "Data Augmentation for Histopathological Images Based on\n  Gaussian-Laplacian Pyramid Blending", "comments": "8 pages", "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN\n  2020), Glasgow, UK", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance is a major problem that affects several machine learning (ML)\nalgorithms. Such a problem is troublesome because most of the ML algorithms\nattempt to optimize a loss function that does not take into account the data\nimbalance. Accordingly, the ML algorithm simply generates a trivial model that\nis biased toward predicting the most frequent class in the training data. In\nthe case of histopathologic images (HIs), both low-level and high-level data\naugmentation (DA) techniques still present performance issues when applied in\nthe presence of inter-patient variability; whence the model tends to learn\ncolor representations, which is related to the staining process. In this paper,\nwe propose a novel approach capable of not only augmenting HI dataset but also\ndistributing the inter-patient variability by means of image blending using the\nGaussian-Laplacian pyramid. The proposed approach consists of finding the\nGaussian pyramids of two images of different patients and finding the Laplacian\npyramids thereof. Afterwards, the left-half side and the right-half side of\ndifferent HIs are joined in each level of the Laplacian pyramid, and from the\njoint pyramids, the original image is reconstructed. This composition combines\nthe stain variation of two patients, avoiding that color differences mislead\nthe learning process. Experimental results on the BreakHis dataset have shown\npromising gains vis-a-vis the majority of DA techniques presented in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:02:57 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 16:25:22 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ataky", "Steve Tsham Mpinda", ""], ["de Matos", "Jonathan", ""], ["Britto", "Alceu de S.", "Jr."], ["Oliveira", "Luiz E. S.", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "2002.00073", "submitter": "Sami Khairy", "authors": "Sami Khairy, Prasanna Balaprakash, Lin X. Cai, Yu Cheng", "title": "Constrained Deep Reinforcement Learning for Energy Sustainable Multi-UAV\n  based Random Access IoT Networks with NOMA", "comments": "Submitted to IEEE JSAC Special Issue on Massive Access for 5G and\n  Beyond", "journal-ref": null, "doi": "10.1109/JSAC.2020.3018804", "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply the Non-Orthogonal Multiple Access (NOMA) technique\nto improve the massive channel access of a wireless IoT network where\nsolar-powered Unmanned Aerial Vehicles (UAVs) relay data from IoT devices to\nremote servers. Specifically, IoT devices contend for accessing the shared\nwireless channel using an adaptive $p$-persistent slotted Aloha protocol; and\nthe solar-powered UAVs adopt Successive Interference Cancellation (SIC) to\ndecode multiple received data from IoT devices to improve access efficiency. To\nenable an energy-sustainable capacity-optimal network, we study the joint\nproblem of dynamic multi-UAV altitude control and multi-cell wireless channel\naccess management of IoT devices as a stochastic control problem with multiple\nenergy constraints. To learn an optimal control policy, we first formulate this\nproblem as a Constrained Markov Decision Process (CMDP), and propose an online\nmodel-free Constrained Deep Reinforcement Learning (CDRL) algorithm based on\nLagrangian primal-dual policy optimization to solve the CMDP. Extensive\nsimulations demonstrate that our proposed algorithm learns a cooperative policy\namong UAVs in which the altitude of UAVs and channel access probability of IoT\ndevices are dynamically and jointly controlled to attain the maximal long-term\nnetwork capacity while maintaining energy sustainability of UAVs. The proposed\nalgorithm outperforms Deep RL based solutions with reward shaping to account\nfor energy costs, and achieves a temporal average system capacity which is\n$82.4\\%$ higher than that of a feasible DRL based solution, and only $6.47\\%$\nlower compared to that of the energy-constraint-free system.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:05:30 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 02:03:28 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Khairy", "Sami", ""], ["Balaprakash", "Prasanna", ""], ["Cai", "Lin X.", ""], ["Cheng", "Yu", ""]]}, {"id": "2002.00079", "submitter": "Duzhe Wang", "authors": "Duzhe Wang, Haoda Fu, Po-Ling Loh", "title": "Boosting Algorithms for Estimating Optimal Individualized Treatment\n  Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present nonparametric algorithms for estimating optimal individualized\ntreatment rules. The proposed algorithms are based on the XGBoost algorithm,\nwhich is known as one of the most powerful algorithms in the machine learning\nliterature. Our main idea is to model the conditional mean of clinical outcome\nor the decision rule via additive regression trees, and use the boosting\ntechnique to estimate each single tree iteratively. Our approaches overcome the\nchallenge of correct model specification, which is required in current\nparametric methods. The major contribution of our proposed algorithms is\nproviding efficient and accurate estimation of the highly nonlinear and complex\noptimal individualized treatment rules that often arise in practice. Finally,\nwe illustrate the superior performance of our algorithms by extensive\nsimulation studies and conclude with an application to the real data from a\ndiabetes Phase III trial.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:26:38 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Duzhe", ""], ["Fu", "Haoda", ""], ["Loh", "Po-Ling", ""]]}, {"id": "2002.00082", "submitter": "Sahin Lale", "authors": "Sahin Lale, Kamyar Azizzadenesheli, Babak Hassibi, Anima Anandkumar", "title": "Regret Minimization in Partially Observable Linear Quadratic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of regret minimization in partially observable linear\nquadratic control systems when the model dynamics are unknown a priori. We\npropose ExpCommit, an explore-then-commit algorithm that learns the model\nMarkov parameters and then follows the principle of optimism in the face of\nuncertainty to design a controller. We propose a novel way to decompose the\nregret and provide an end-to-end sublinear regret upper bound for partially\nobservable linear quadratic control. Finally, we provide stability guarantees\nand establish a regret upper bound of $\\tilde{\\mathcal{O}}(T^{2/3})$ for\nExpCommit, where $T$ is the time horizon of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 22:35:08 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 02:35:18 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Lale", "Sahin", ""], ["Azizzadenesheli", "Kamyar", ""], ["Hassibi", "Babak", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2002.00097", "submitter": "Xinyue Hu", "authors": "Xinyue Hu, Haoji Hu, Saurabh Verma, Zhi-Li Zhang", "title": "Physics-Guided Deep Neural Networks for Power Flow Analysis", "comments": "9 pages", "journal-ref": null, "doi": "10.1109/TPWRS.2020.3029557", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving power flow (PF) equations is the basis of power flow analysis, which\nis important in determining the best operation of existing systems, performing\nsecurity analysis, etc. However, PF equations can be out-of-date or even\nunavailable due to system dynamics and uncertainties, making traditional\nnumerical approaches infeasible. To address these concerns, researchers have\nproposed data-driven approaches to solve the PF problem by learning the mapping\nrules from historical system operation data. Nevertheless, prior data-driven\napproaches suffer from poor performance and generalizability, due to overly\nsimplified assumptions of the PF problem or ignorance of physical laws\ngoverning power systems. In this paper, we propose a physics-guided neural\nnetwork to solve the PF problem, with an auxiliary task to rebuild the PF\nmodel. By encoding different granularity of Kirchhoff's laws and system\ntopology into the rebuilt PF model, our neural-network based PF solver is\nregularized by the auxiliary task and constrained by the physical laws. The\nsimulation results show that our physics-guided neural network methods achieve\nbetter performance and generalizability compared to existing unconstrained\ndata-driven approaches. Furthermore, we demonstrate that the weight matrices of\nour physics-guided neural networks embody power system physics by showing their\nsimilarities with the bus admittance matrices.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:24:30 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:06:44 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Hu", "Xinyue", ""], ["Hu", "Haoji", ""], ["Verma", "Saurabh", ""], ["Zhang", "Zhi-Li", ""]]}, {"id": "2002.00099", "submitter": "Antoine Lesage-Landry", "authors": "Antoine Lesage-Landry and Duncan S. Callaway", "title": "Dynamic and Distributed Online Convex Optimization for Demand Response\n  of Commercial Buildings", "comments": null, "journal-ref": "IEEE Control Systems Letters, 4 (3): 632-637. July 2020", "doi": "10.1109/LCSYS.2020.2989110", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the regret analysis of the online distributed weighted dual\naveraging (DWDA) algorithm [1] to the dynamic setting and provide the tightest\ndynamic regret bound known to date with respect to the time horizon for a\ndistributed online convex optimization (OCO) algorithm. Our bound is linear in\nthe cumulative difference between consecutive optima and does not depend\nexplicitly on the time horizon. We use dynamic-online DWDA (D-ODWDA) and\nformulate a performance-guaranteed distributed online demand response approach\nfor heating, ventilation, and air-conditioning (HVAC) systems of commercial\nbuildings. We show the performance of our approach for fast timescale demand\nresponse in numerical simulations and obtain demand response decisions that\nclosely reproduce the centralized optimal ones.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:34:53 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 20:46:30 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 20:35:34 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Lesage-Landry", "Antoine", ""], ["Callaway", "Duncan S.", ""]]}, {"id": "2002.00100", "submitter": "Dean Eckles", "authors": "Madhav Kumar, Dean Eckles, Sinan Aral", "title": "Scalable bundling via dense product embeddings", "comments": "47 pages, 14 figures, 22 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bundling, the practice of jointly selling two or more products at a discount,\nis a widely used strategy in industry and a well examined concept in academia.\nHistorically, the focus has been on theoretical studies in the context of\nmonopolistic firms and assumed product relationships, e.g., complementarity in\nusage. We develop a new machine-learning-driven methodology for designing\nbundles in a large-scale, cross-category retail setting. We leverage historical\npurchases and consideration sets created from clickstream data to generate\ndense continuous representations of products called embeddings. We then put\nminimal structure on these embeddings and develop heuristics for\ncomplementarity and substitutability among products. Subsequently, we use the\nheuristics to create multiple bundles for each product and test their\nperformance using a field experiment with a large retailer. We combine the\nresults from the experiment with product embeddings using a hierarchical model\nthat maps bundle features to their purchase likelihood, as measured by the\nadd-to-cart rate. We find that our embeddings-based heuristics are strong\npredictors of bundle success, robust across product categories, and generalize\nwell to the retailer's entire assortment.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:34:56 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kumar", "Madhav", ""], ["Eckles", "Dean", ""], ["Aral", "Sinan", ""]]}, {"id": "2002.00102", "submitter": "Marco Podda", "authors": "Davide Bacciu, Alessio Micheli, Marco Podda", "title": "Edge-based sequential graph generation with recurrent neural networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.112", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation with Machine Learning is an open problem with applications\nin various research fields. In this work, we propose to cast the generative\nprocess of a graph into a sequential one, relying on a node ordering procedure.\nWe use this sequential process to design a novel generative model composed of\ntwo recurrent neural networks that learn to predict the edges of graphs: the\nfirst network generates one endpoint of each edge, while the second network\ngenerates the other endpoint conditioned on the state of the first. We test our\napproach extensively on five different datasets, comparing with two well-known\nbaselines coming from graph literature, and two recurrent approaches, one of\nwhich holds state of the art performances. Evaluation is conducted considering\nquantitative and qualitative characteristics of the generated samples. Results\nshow that our approach is able to yield novel, and unique graphs originating\nfrom very different distributions, while retaining structural properties very\nsimilar to those in the training sample. Under the proposed evaluation\nframework, our approach is able to reach performances comparable to the current\nstate of the art on the graph generation task.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:44:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""], ["Podda", "Marco", ""]]}, {"id": "2002.00104", "submitter": "Jun Fang", "authors": "Jun Fang, Ali Shafiee, Hamzah Abdel-Aziz, David Thorsley, Georgios\n  Georgiadis, Joseph Hassoun", "title": "Post-Training Piecewise Linear Quantization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization plays an important role in the energy-efficient deployment of\ndeep neural networks on resource-limited devices. Post-training quantization is\nhighly desirable since it does not require retraining or access to the full\ntraining dataset. The well-established uniform scheme for post-training\nquantization achieves satisfactory results by converting neural networks from\nfull-precision to 8-bit fixed-point integers. However, it suffers from\nsignificant performance degradation when quantizing to lower bit-widths. In\nthis paper, we propose a piecewise linear quantization (PWLQ) scheme to enable\naccurate approximation for tensor values that have bell-shaped distributions\nwith long tails. Our approach breaks the entire quantization range into\nnon-overlapping regions for each tensor, with each region being assigned an\nequal number of quantization levels. Optimal breakpoints that divide the entire\nrange are found by minimizing the quantization error. Compared to\nstate-of-the-art post-training quantization methods, experimental results show\nthat our proposed method achieves superior performance on image classification,\nsemantic segmentation, and object detection with minor overhead.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:47:00 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 18:49:40 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Fang", "Jun", ""], ["Shafiee", "Ali", ""], ["Abdel-Aziz", "Hamzah", ""], ["Thorsley", "David", ""], ["Georgiadis", "Georgios", ""], ["Hassoun", "Joseph", ""]]}, {"id": "2002.00107", "submitter": "Adam B. Block", "authors": "Adam Block, Youssef Mroueh, and Alexander Rakhlin", "title": "Generative Modeling with Denoising Auto-Encoders and Langevin Sampling", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study convergence of a generative modeling method that first estimates the\nscore function of the distribution using Denoising Auto-Encoders (DAE) or\nDenoising Score Matching (DSM) and then employs Langevin diffusion for\nsampling. We show that both DAE and DSM provide estimates of the score of the\nGaussian smoothed population density, allowing us to apply the machinery of\nEmpirical Processes.\n  We overcome the challenge of relying only on $L^2$ bounds on the score\nestimation error and provide finite-sample bounds in the Wasserstein distance\nbetween the law of the population distribution and the law of this sampling\nscheme. We then apply our results to the homotopy method of arXiv:1907.05600\nand provide theoretical justification for its empirical success.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 23:50:03 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 01:11:46 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:49:19 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Block", "Adam", ""], ["Mroueh", "Youssef", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2002.00119", "submitter": "Wei Zhang", "authors": "Qianming Xue, Wei Zhang, Hongyuan Zha", "title": "Improving Domain-Adapted Sentiment Classification by Deep Adversarial\n  Mutual Learning", "comments": "Accepted to appear in AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain-adapted sentiment classification refers to training on a labeled\nsource domain to well infer document-level sentiment on an unlabeled target\ndomain. Most existing relevant models involve a feature extractor and a\nsentiment classifier, where the feature extractor works towards learning\ndomain-invariant features from both domains, and the sentiment classifier is\ntrained only on the source domain to guide the feature extractor. As such, they\nlack a mechanism to use sentiment polarity lying in the target domain. To\nimprove domain-adapted sentiment classification by learning sentiment from the\ntarget domain as well, we devise a novel deep adversarial mutual learning\napproach involving two groups of feature extractors, domain discriminators,\nsentiment classifiers, and label probers. The domain discriminators enable the\nfeature extractors to obtain domain-invariant features. Meanwhile, the label\nprober in each group explores document sentiment polarity of the target domain\nthrough the sentiment prediction generated by the classifier in the peer group,\nand guides the learning of the feature extractor in its own group. The proposed\napproach achieves the mutual learning of the two groups in an end-to-end\nmanner. Experiments on multiple public datasets indicate our method obtains the\nstate-of-the-art performance, validating the effectiveness of mutual learning\nthrough label probers.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:22:44 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Xue", "Qianming", ""], ["Zhang", "Wei", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.00120", "submitter": "Lori Dalton", "authors": "Ali Foroughi pour and Lori A. Dalton", "title": "On the Consistency of Optimal Bayesian Feature Selection in the Presence\n  of Correlations", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal Bayesian feature selection (OBFS) is a multivariate supervised\nscreening method designed from the ground up for biomarker discovery. In this\nwork, we prove that Gaussian OBFS is strongly consistent under mild conditions,\nand provide rates of convergence for key posteriors in the framework. These\nresults are of enormous importance, since they identify precisely what features\nare selected by OBFS asymptotically, characterize the relative rates of\nconvergence for posteriors on different types of features, provide conditions\nthat guarantee convergence, justify the use of OBFS when its internal\nassumptions are invalid, and set the stage for understanding the asymptotic\nbehavior of other algorithms based on the OBFS framework.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:41:08 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["pour", "Ali Foroughi", ""], ["Dalton", "Lori A.", ""]]}, {"id": "2002.00123", "submitter": "Naoto Yanai", "authors": "Tatsuya Takemura and Naoto Yanai and Toru Fujiwara", "title": "Model Extraction Attacks against Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model extraction attacks are a kind of attacks in which an adversary obtains\na new model, whose performance is equivalent to that of a target model, via\nquery access to the target model efficiently, i.e., fewer datasets and\ncomputational resources than those of the target model. Existing works have\ndealt with only simple deep neural networks (DNNs), e.g., only three layers, as\ntargets of model extraction attacks, and hence are not aware of the\neffectiveness of recurrent neural networks (RNNs) in dealing with time-series\ndata. In this work, we shed light on the threats of model extraction attacks\nagainst RNNs. We discuss whether a model with a higher accuracy can be\nextracted with a simple RNN from a long short-term memory (LSTM), which is a\nmore complicated and powerful RNN. Specifically, we tackle the following\nproblems. First, in a case of a classification problem, such as image\nrecognition, extraction of an RNN model without final outputs from an LSTM\nmodel is presented by utilizing outputs halfway through the sequence. Next, in\na case of a regression problem. such as in weather forecasting, a new attack by\nnewly configuring a loss function is presented. We conduct experiments on our\nmodel extraction attacks against an RNN and an LSTM trained with publicly\navailable academic datasets. We then show that a model with a higher accuracy\ncan be extracted efficiently, especially through configuring a loss function\nand a more complex architecture different from the target model.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:47:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Takemura", "Tatsuya", ""], ["Yanai", "Naoto", ""], ["Fujiwara", "Toru", ""]]}, {"id": "2002.00125", "submitter": "Aparna Khare", "authors": "Sanna Wager, Aparna Khare, Minhua Wu, Kenichi Kumatani, Shiva Sundaram", "title": "Fully Learnable Front-End for Multi-Channel Acoustic Modeling using\n  Semi-Supervised Learning", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053367", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigated the teacher-student training paradigm to train\na fully learnable multi-channel acoustic model for far-field automatic speech\nrecognition (ASR). Using a large offline teacher model trained on beamformed\naudio, we trained a simpler multi-channel student acoustic model used in the\nspeech recognition system. For the student, both multi-channel feature\nextraction layers and the higher classification layers were jointly trained\nusing the logits from the teacher model. In our experiments, compared to a\nbaseline model trained on about 600 hours of transcribed data, a relative\nword-error rate (WER) reduction of about 27.3% was achieved when using an\nadditional 1800 hours of untranscribed data. We also investigated the benefit\nof pre-training the multi-channel front end to output the beamformed log-mel\nfilter bank energies (LFBE) using L2 loss. We find that pre-training improves\nthe word error rate by 10.7% when compared to a multi-channel model directly\ninitialized with a beamformer and mel-filter bank coefficients for the front\nend. Finally, combining pre-training and teacher-student training produces a\nWER reduction of 31% compared to our baseline.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 02:06:05 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wager", "Sanna", ""], ["Khare", "Aparna", ""], ["Wu", "Minhua", ""], ["Kumatani", "Kenichi", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2002.00149", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Prabhat Nagarajan, Guilherme Maeda", "title": "Periodic Intra-Ensemble Knowledge Distillation for Reinforcement\n  Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy ensemble reinforcement learning (RL) methods have demonstrated\nimpressive results across a range of RL benchmark tasks. Recent works suggest\nthat directly imitating experts' policies in a supervised manner before or\nduring the course of training enables faster policy improvement for an RL\nagent. Motivated by these recent insights, we propose Periodic Intra-Ensemble\nKnowledge Distillation (PIEKD). PIEKD is a learning framework that uses an\nensemble of policies to act in the environment while periodically sharing\nknowledge amongst policies in the ensemble through knowledge distillation. Our\nexperiments demonstrate that PIEKD improves upon a state-of-the-art RL method\nin sample efficiency on several challenging MuJoCo benchmark tasks.\nAdditionally, we perform ablation studies to better understand PIEKD.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 06:00:12 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Nagarajan", "Prabhat", ""], ["Maeda", "Guilherme", ""]]}, {"id": "2002.00155", "submitter": "Daniel Obmann", "authors": "Daniel Obmann, Johannes Schwab and Markus Haltmeier", "title": "Deep synthesis regularization of inverse problems", "comments": "Submitted to IEEE Trans. Image Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a large number of efficient deep learning methods for solving\ninverse problems have been developed and show outstanding numerical\nperformance. For these deep learning methods, however, a solid theoretical\nfoundation in the form of reconstruction guarantees is missing. In contrast,\nfor classical reconstruction methods, such as convex variational and\nframe-based regularization, theoretical convergence and convergence rate\nresults are well established. In this paper, we introduce deep synthesis\nregularization (DESYRE) using neural networks as nonlinear synthesis operator\nbridging the gap between these two worlds. The proposed method allows to\nexploit the deep learning benefits of being well adjustable to available\ntraining data and on the other hand comes with a solid mathematical foundation.\nWe present a complete convergence analysis with convergence rates for the\nproposed deep synthesis regularization. We present a strategy for constructing\na synthesis network as part of an analysis-synthesis sequence together with an\nappropriate training strategy. Numerical results show the plausibility of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 06:50:42 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Obmann", "Daniel", ""], ["Schwab", "Johannes", ""], ["Haltmeier", "Markus", ""]]}, {"id": "2002.00169", "submitter": "Biao Gong", "authors": "Chenggang Yan, Biao Gong, Yuxuan Wei, Yue Gao", "title": "Deep Multi-View Enhancement Hashing for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing is an efficient method for nearest neighbor search in large-scale\ndata space by embedding high-dimensional feature descriptors into a similarity\npreserving Hamming space with a low dimension. However, large-scale high-speed\nretrieval through binary code has a certain degree of reduction in retrieval\naccuracy compared to traditional retrieval methods. We have noticed that\nmulti-view methods can well preserve the diverse characteristics of data.\nTherefore, we try to introduce the multi-view deep neural network into the hash\nlearning field, and design an efficient and innovative retrieval model, which\nhas achieved a significant improvement in retrieval performance. In this paper,\nwe propose a supervised multi-view hash model which can enhance the multi-view\ninformation through neural networks. This is a completely new hash learning\nmethod that combines multi-view and deep learning methods. The proposed method\nutilizes an effective view stability evaluation method to actively explore the\nrelationship among views, which will affect the optimization direction of the\nentire network. We have also designed a variety of multi-data fusion methods in\nthe Hamming space to preserve the advantages of both convolution and\nmulti-view. In order to avoid excessive computing resources on the enhancement\nprocedure during retrieval, we set up a separate structure called memory\nnetwork which participates in training together. The proposed method is\nsystematically evaluated on the CIFAR-10, NUS-WIDE and MS-COCO datasets, and\nthe results show that our method significantly outperforms the state-of-the-art\nsingle-view and multi-view hashing methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 08:32:27 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:41:20 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yan", "Chenggang", ""], ["Gong", "Biao", ""], ["Wei", "Yuxuan", ""], ["Gao", "Yue", ""]]}, {"id": "2002.00178", "submitter": "Pierre Wolinski", "authors": "Pierre Wolinski, Guillaume Charpiat, Yann Ollivier", "title": "An Equivalence between Bayesian Priors and Penalties in Variational\n  Inference", "comments": "17 pages, 2 columns, including 2 pages of references and 7 pages of\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, it is common to optimize the parameters of a\nprobabilistic model, modulated by an ad hoc regularization term that penalizes\nsome values of the parameters. Regularization terms appear naturally in\nVariational Inference (VI), a tractable way to approximate Bayesian posteriors:\nthe loss to optimize contains a Kullback--Leibler divergence term between the\napproximate posterior and a Bayesian prior. We fully characterize which\nregularizers can arise this way, and provide a systematic way to compute the\ncorresponding prior. This viewpoint also provides a prediction for useful\nvalues of the regularization factor in neural networks. We apply this framework\nto regularizers such as L2, L1 or group-Lasso.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:48:51 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 10:11:57 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Wolinski", "Pierre", ""], ["Charpiat", "Guillaume", ""], ["Ollivier", "Yann", ""]]}, {"id": "2002.00189", "submitter": "Tomas Vaskevicius", "authors": "Tomas Va\\v{s}kevi\\v{c}ius, Varun Kanade, Patrick Rebeschini", "title": "The Statistical Complexity of Early-Stopped Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a surge of interest in understanding implicit\nregularization properties of iterative gradient-based optimization algorithms.\nIn this paper, we study the statistical guarantees on the excess risk achieved\nby early-stopped unconstrained mirror descent algorithms applied to the\nunregularized empirical risk with the squared loss for linear models and kernel\nmethods. By completing an inequality that characterizes convexity for the\nsquared loss, we identify an intrinsic link between offset Rademacher\ncomplexities and potential-based convergence analysis of mirror descent\nmethods. Our observation immediately yields excess risk guarantees for the path\ntraced by the iterates of mirror descent in terms of offset complexities of\ncertain function classes depending only on the choice of the mirror map,\ninitialization point, step-size, and the number of iterations. We apply our\ntheory to recover, in a clean and elegant manner via rather short proofs, some\nof the recent results in the implicit regularization literature, while also\nshowing how to improve upon them in some settings.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 11:05:08 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 15:45:06 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Va\u0161kevi\u010dius", "Tomas", ""], ["Kanade", "Varun", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "2002.00208", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Elena Zheleva, and Tanya Berger-Wolf", "title": "Variable-lag Granger Causality and Transfer Entropy for Time Series\n  Analysis", "comments": "This preprint is the extension of the work [arXiv:1912.10829]\n  entitled \"Variable-lag Granger Causality for Time Series Analysis\" by the\n  same authors. The revision was made based on reviewers' suggestions. The R\n  package is available at https://github.com/DarkEyes/VLTimeSeriesCausality", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 15(4),\n  67 (2021)", "doi": "10.1145/3441452", "report-no": null, "categories": "cs.LG econ.EM physics.data-an stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality is a fundamental technique for causal inference in time\nseries data, commonly used in the social and biological sciences. Typical\noperationalizations of Granger causality make a strong assumption that every\ntime point of the effect time series is influenced by a combination of other\ntime series with a fixed time delay. The assumption of fixed time delay also\nexists in Transfer Entropy, which is considered to be a non-linear version of\nGranger causality. However, the assumption of the fixed time delay does not\nhold in many applications, such as collective behavior, financial markets, and\nmany natural phenomena. To address this issue, we develop Variable-lag Granger\ncausality and Variable-lag Transfer Entropy, generalizations of both Granger\ncausality and Transfer Entropy that relax the assumption of the fixed time\ndelay and allow causes to influence effects with arbitrary time delays. In\naddition, we propose methods for inferring both variable-lag Granger causality\nand Transfer Entropy relations. In our approaches, we utilize an optimal\nwarping path of Dynamic Time Warping (DTW) to infer variable-lag causal\nrelations. We demonstrate our approaches on an application for studying\ncoordinated collective behavior and other real-world casual-inference datasets\nand show that our proposed approaches perform better than several existing\nmethods in both simulated and real-world datasets. Our approaches can be\napplied in any domain of time series analysis. The software of this work is\navailable in the R-CRAN package: VLTimeCausality.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:03:01 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 03:26:47 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 09:24:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Zheleva", "Elena", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "2002.00210", "submitter": "Byeong-Hoo Lee", "authors": "Byeong-Hoo Lee, Ji-Hoon Jeong, Kyung-Hwan Shim, Seong-Whan Lee", "title": "Classification of High-Dimensional Motor Imagery Tasks based on An\n  End-to-end role assigned convolutional neural network", "comments": "Pre-review version, accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brain-computer interface (BCI) provides a direct communication pathway\nbetween user and external devices. Electroencephalogram (EEG) motor imagery\n(MI) paradigm is widely used in non-invasive BCI to obtain encoded signals\ncontained user intention of movement execution. However, EEG has intricate and\nnon-stationary properties resulting in insufficient decoding performance. By\nimagining numerous movements of a single-arm, decoding performance can be\nimproved without artificial command matching. In this study, we collected\nintuitive EEG data contained the nine different types of movements of a\nsingle-arm from 9 subjects. We propose an end-to-end role assigned\nconvolutional neural network (ERA-CNN) which considers discriminative features\nof each upper limb region by adopting the principle of a hierarchical CNN\narchitecture. The proposed model outperforms previous methods on 3-class,\n5-class and two different types of 7-class classification tasks. Hence, we\ndemonstrate the possibility of decoding user intention by using only EEG\nsignals with robust performance using an ERA-CNN.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:06:16 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 04:48:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lee", "Byeong-Hoo", ""], ["Jeong", "Ji-Hoon", ""], ["Shim", "Kyung-Hwan", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2002.00211", "submitter": "Suyi Li", "authors": "Suyi Li, Yong Cheng, Wei Wang, Yang Liu, Tianjian Chen", "title": "Learning to Detect Malicious Clients for Robust Federated Learning", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning systems are vulnerable to attacks from malicious clients.\nAs the central server in the system cannot govern the behaviors of the clients,\na rogue client may initiate an attack by sending malicious model updates to the\nserver, so as to degrade the learning performance or enforce targeted model\npoisoning attacks (a.k.a. backdoor attacks). Therefore, timely detecting these\nmalicious model updates and the underlying attackers becomes critically\nimportant. In this work, we propose a new framework for robust federated\nlearning where the central server learns to detect and remove the malicious\nmodel updates using a powerful detection model, leading to targeted defense. We\nevaluate our solution in both image classification and sentiment analysis tasks\nwith a variety of machine learning models. Experimental results show that our\nsolution ensures robust federated learning that is resilient to both the\nByzantine attacks and the targeted model poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:09:48 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Suyi", ""], ["Cheng", "Yong", ""], ["Wang", "Wei", ""], ["Liu", "Yang", ""], ["Chen", "Tianjian", ""]]}, {"id": "2002.00228", "submitter": "Thanuja Ambegoda", "authors": "Thanuja D. Ambegoda, Julien N. P. Martel, Jozef Adamcik, Matthew Cook,\n  Richard H. R. Hahnloser", "title": "Estimation of Z-Thickness and XY-Anisotropy of Electron Microscopy\n  Images using Gaussian Processes", "comments": null, "journal-ref": "Journal of Neuroinformatics and Neuroimaging. 2018;2(2):15-22", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serial section electron microscopy (ssEM) is a widely used technique for\nobtaining volumetric information of biological tissues at nanometer scale.\nHowever, accurate 3D reconstructions of identified cellular structures and\nvolumetric quantifications require precise estimates of section thickness and\nanisotropy (or stretching) along the XY imaging plane. In fact, many image\nprocessing algorithms simply assume isotropy within the imaging plane. To\nameliorate this problem, we present a method for estimating thickness and\nstretching of electron microscopy sections using non-parametric Bayesian\nregression of image statistics. We verify our thickness and stretching\nestimates using direct measurements obtained by atomic force microscopy (AFM)\nand show that our method has a lower estimation error compared to a recent\nindirect thickness estimation method as well as a relative Z coordinate\nestimation method. Furthermore, we have made the first dataset of ssSEM images\nwith directly measured section thickness values publicly available for the\nevaluation of indirect thickness estimation methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 15:18:55 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 21:32:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Ambegoda", "Thanuja D.", ""], ["Martel", "Julien N. P.", ""], ["Adamcik", "Jozef", ""], ["Cook", "Matthew", ""], ["Hahnloser", "Richard H. R.", ""]]}, {"id": "2002.00232", "submitter": "Qiuyu Zhu", "authors": "Qiuyu Zhu and Vincent Y. F. Tan", "title": "Thompson Sampling Algorithms for Mean-Variance Bandits", "comments": "26 pages, 10 figures, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit (MAB) problem is a classical learning task that\nexemplifies the exploration-exploitation tradeoff. However, standard\nformulations do not take into account {\\em risk}. In online decision making\nsystems, risk is a primary concern. In this regard, the mean-variance risk\nmeasure is one of the most common objective functions. Existing algorithms for\nmean-variance optimization in the context of MAB problems have unrealistic\nassumptions on the reward distributions. We develop Thompson Sampling-style\nalgorithms for mean-variance MAB and provide comprehensive regret analyses for\nGaussian and Bernoulli bandits with fewer assumptions. Our algorithms achieve\nthe best known regret bounds for mean-variance MABs and also attain the\ninformation-theoretic bounds in some parameter regimes. Empirical simulations\nshow that our algorithms significantly outperform existing LCB-based algorithms\nfor all risk tolerances.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 15:33:50 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 14:07:38 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 13:34:15 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhu", "Qiuyu", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2002.00240", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Lior Wolf", "title": "Molecule Property Prediction and Classification with Graph Hypernetworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph neural networks are currently leading the performance charts in\nlearning-based molecule property prediction and classification. Computational\nchemistry has, therefore, become the a prominent testbed for generic graph\nneural networks, as well as for specialized message passing methods. In this\nwork, we demonstrate that the replacement of the underlying networks with\nhypernetworks leads to a boost in performance, obtaining state of the art\nresults in various benchmarks. A major difficulty in the application of\nhypernetworks is their lack of stability. We tackle this by combining the\ncurrent message and the first message. A recent work has tackled the training\ninstability of hypernetworks in the context of error correcting codes, by\nreplacing the activation function of the message passing network with a\nlow-order Taylor approximation of it. We demonstrate that our generic solution\ncan replace this domain-specific solution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 16:44:34 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Nachmani", "Eliya", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.00253", "submitter": "Karthik Abinav Sankararaman", "authors": "Karthik Abinav Sankararaman and Aleksandrs Slivkins", "title": "Bandits with Knapsacks beyond the Worst-Case", "comments": "The initial version, titled \"Advances in Bandits with Knapsacks\", was\n  published on arxiv.org in Jan'20. The present version improves both upper and\n  lower bounds, deriving Theorem 3.2(ii) and Theorem 4.2. Moreover, it\n  simplifies the algorithm and analysis in the main result, and fixes several\n  issues in the lower bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandits with Knapsacks (BwK) is a general model for multi-armed bandits under\nsupply/budget constraints. While worst-case regret bounds for BwK are\nwell-understood, we present three results that go beyond the worst-case\nperspective. First, we provide upper and lower bounds which amount to a full\ncharacterization for logarithmic, instance-dependent regret rates. Second, we\nconsider \"simple regret\" in BwK, which tracks algorithm's performance in a\ngiven round, and prove that it is small in all but a few rounds. Third, we\nprovide a general \"reduction\" from BwK to bandits which takes advantage of some\nknown helpful structure, and apply this reduction to combinatorial\nsemi-bandits, linear contextual bandits, and multinomial-logit bandits. Our\nresults build on the BwK algorithm from \\citet{AgrawalDevanur-ec14}, providing\nnew analyses thereof.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 18:50:44 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 22:45:16 GMT"}, {"version": "v3", "created": "Mon, 3 May 2021 06:05:07 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 16:29:16 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 17:18:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sankararaman", "Karthik Abinav", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "2002.00254", "submitter": "Nikolai Zolotykh", "authors": "V. V. Kuznetsov and V. A. Moskalenko and N. Yu. Zolotykh", "title": "Electrocardiogram Generation and Feature Extraction Using a Variational\n  Autoencoder", "comments": "6 pages, 6 figures Submitted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for generating an electrocardiogram (ECG) signal for one\ncardiac cycle using a variational autoencoder. Using this method we extracted a\nvector of new 25 features, which in many cases can be interpreted. The\ngenerated ECG has quite natural appearance. The low value of the Maximum Mean\nDiscrepancy metric, 0.00383, indicates good quality of ECG generation too. The\nextracted new features will help to improve the quality of automatic\ndiagnostics of cardiovascular diseases. Also, generating new synthetic ECGs\nwill allow us to solve the issue of the lack of labeled ECG for use them in\nsupervised learning.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 19:01:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kuznetsov", "V. V.", ""], ["Moskalenko", "V. A.", ""], ["Zolotykh", "N. Yu.", ""]]}, {"id": "2002.00260", "submitter": "Guannan Qu", "authors": "Guannan Qu, Adam Wierman", "title": "Finite-Time Analysis of Asynchronous Stochastic Approximation and\n  $Q$-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general asynchronous Stochastic Approximation (SA) scheme\nfeaturing a weighted infinity-norm contractive operator, and prove a bound on\nits finite-time convergence rate on a single trajectory. Additionally, we\nspecialize the result to asynchronous $Q$-learning. The resulting bound matches\nthe sharpest available bound for synchronous $Q$-learning, and improves over\nprevious known bounds for asynchronous $Q$-learning.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 19:20:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Qu", "Guannan", ""], ["Wierman", "Adam", ""]]}, {"id": "2002.00269", "submitter": "David Heckerman", "authors": "David Heckerman", "title": "A Tutorial on Learning With Bayesian Networks", "comments": "Previous arXiv submission hid all references--now fixed", "journal-ref": "Original version published in Learning in Graphical Models, M.\n  Jordan, ed., MIT Press, Cambridge, MA, 1999", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian network is a graphical model that encodes probabilistic\nrelationships among variables of interest. When used in conjunction with\nstatistical techniques, the graphical model has several advantages for data\nanalysis. One, because the model encodes dependencies among all variables, it\nreadily handles situations where some data entries are missing. Two, a Bayesian\nnetwork can be used to learn causal relationships, and hence can be used to\ngain understanding about a problem domain and to predict the consequences of\nintervention. Three, because the model has both a causal and probabilistic\nsemantics, it is an ideal representation for combining prior knowledge (which\noften comes in causal form) and data. Four, Bayesian statistical methods in\nconjunction with Bayesian networks offer an efficient and principled approach\nfor avoiding the overfitting of data. In this paper, we discuss methods for\nconstructing Bayesian networks from prior knowledge and summarize Bayesian\nstatistical methods for using data to improve these models. With regard to the\nlatter task, we describe methods for learning both the parameters and structure\nof a Bayesian network, including techniques for learning with incomplete data.\nIn addition, we relate Bayesian-network methods for learning to techniques for\nsupervised and unsupervised learning. We illustrate the graphical-modeling\napproach using a real-world case study.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:03:21 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 22:18:01 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Heckerman", "David", ""]]}, {"id": "2002.00274", "submitter": "Dheeraj Nagaraj", "authors": "Guy Bresler and Dheeraj Nagaraj", "title": "A Corrective View of Neural Networks: Representation, Memorization and\n  Learning", "comments": "Contains 2 figures (you heard that right!), V2 removes dimension\n  dependence in memorization bounds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a corrective mechanism for neural network approximation: the total\navailable non-linear units are divided into multiple groups and the first group\napproximates the function under consideration, the second group approximates\nthe error in approximation produced by the first group and corrects it, the\nthird group approximates the error produced by the first and second groups\ntogether and so on. This technique yields several new representation and\nlearning results for neural networks. First, we show that two-layer neural\nnetworks in the random features regime (RF) can memorize arbitrary labels for\narbitrary points under under Euclidean distance separation condition using\n$\\tilde{O}(n)$ ReLUs which is optimal in $n$ up to logarithmic factors. Next,\nwe give a powerful representation result for two-layer neural networks with\nReLUs and smoothed ReLUs which can achieve a squared error of at most\n$\\epsilon$ with $O(C(a,d)\\epsilon^{-1/(a+1)})$ for $a \\in \\mathbb{N}\\cup\\{0\\}$\nwhen the function is smooth enough (roughly when it has $\\Theta(ad)$ bounded\nderivatives). In certain cases $d$ can be replaced with effective dimension $q\n\\ll d$. Previous results of this type implement Taylor series approximation\nusing deep architectures. We also consider three-layer neural networks and show\nthat the corrective mechanism yields faster representation rates for smooth\nradial functions. Lastly, we obtain the first $O(\\mathrm{subpoly}(1/\\epsilon))$\nupper bound on the number of neurons required for a two layer network to learn\nlow degree polynomials up to squared error $\\epsilon$ via gradient descent.\nEven though deep networks can express these polynomials with\n$O(\\mathrm{polylog}(1/\\epsilon))$ neurons, the best learning bounds on this\nproblem require $\\mathrm{poly}(1/\\epsilon)$ neurons.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:51:09 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 02:37:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bresler", "Guy", ""], ["Nagaraj", "Dheeraj", ""]]}, {"id": "2002.00276", "submitter": "Mike Wu", "authors": "Mike Wu, Richard L. Davis, Benjamin W. Domingue, Chris Piech, Noah\n  Goodman", "title": "Variational Item Response Theory: Fast, Accurate, and Expressive", "comments": "10 pages of content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item Response Theory (IRT) is a ubiquitous model for understanding humans\nbased on their responses to questions, used in fields as diverse as education,\nmedicine and psychology. Large modern datasets offer opportunities to capture\nmore nuances in human behavior, potentially improving test scoring and better\ninforming public policy. Yet larger datasets pose a difficult speed / accuracy\nchallenge to contemporary algorithms for fitting IRT models. We introduce a\nvariational Bayesian inference algorithm for IRT, and show that it is fast and\nscaleable without sacrificing accuracy. Using this inference approach we then\nextend classic IRT with expressive Bayesian models of responses. Applying this\nmethod to five large-scale item response datasets from cognitive science and\neducation yields higher log likelihoods and improvements in imputing missing\ndata. The algorithm implementation is open-source, and easily usable.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:54:02 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 17:19:23 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Mike", ""], ["Davis", "Richard L.", ""], ["Domingue", "Benjamin W.", ""], ["Piech", "Chris", ""], ["Goodman", "Noah", ""]]}, {"id": "2002.00287", "submitter": "Julia Olkhovskaya", "authors": "Gergely Neu, Julia Olkhovskaya", "title": "Efficient and Robust Algorithms for Adversarial Linear Contextual\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an adversarial variant of the classic $K$-armed linear contextual\nbandit problem where the sequence of loss functions associated with each arm\nare allowed to change without restriction over time. Under the assumption that\nthe $d$-dimensional contexts are generated i.i.d.~at random from a known\ndistributions, we develop computationally efficient algorithms based on the\nclassic Exp3 algorithm. Our first algorithm, RealLinExp3, is shown to achieve a\nregret guarantee of $\\widetilde{O}(\\sqrt{KdT})$ over $T$ rounds, which matches\nthe best available bound for this problem. Our second algorithm, RobustLinExp3,\nis shown to be robust to misspecification, in that it achieves a regret bound\nof $\\widetilde{O}((Kd)^{1/3}T^{2/3}) + \\varepsilon \\sqrt{d} T$ if the true\nreward function is linear up to an additive nonlinear error uniformly bounded\nin absolute value by $\\varepsilon$. To our knowledge, our performance\nguarantees constitute the very first results on this problem setting.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 22:49:46 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 20:00:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Neu", "Gergely", ""], ["Olkhovskaya", "Julia", ""]]}, {"id": "2002.00288", "submitter": "Yu Wang", "authors": "Yu Wang, Byoungwook Jang, Alfred Hero", "title": "The Sylvester Graphical Lasso (SyGlasso)", "comments": "Accepted in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces the Sylvester graphical lasso (SyGlasso) that captures\nmultiway dependencies present in tensor-valued data. The model is based on the\nSylvester equation that defines a generative model. The proposed model\ncomplements the tensor graphical lasso (Greenewald et al., 2019) that imposes a\nKronecker sum model for the inverse covariance matrix by providing an\nalternative Kronecker sum model that is generative and interpretable. A\nnodewise regression approach is adopted for estimating the conditional\nindependence relationships among variables. The statistical convergence of the\nmethod is established, and empirical studies are provided to demonstrate the\nrecovery of meaningful conditional dependency graphs. We apply the SyGlasso to\nan electroencephalography (EEG) study to compare the brain connectivity of\nalcoholic and nonalcoholic subjects. We demonstrate that our model can\nsimultaneously estimate both the brain connectivity and its temporal\ndependencies.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 22:57:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Yu", ""], ["Jang", "Byoungwook", ""], ["Hero", "Alfred", ""]]}, {"id": "2002.00291", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Peter L. Bartlett, Philip M. Long", "title": "Oracle Lower Bounds for Stochastic Gradient Sampling Algorithms", "comments": "21 pages; accepted for publication at Bernoulli", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling from a strongly log-concave density in\n$\\mathbb{R}^d$, and prove an information theoretic lower bound on the number of\nstochastic gradient queries of the log density needed. Several popular sampling\nalgorithms (including many Markov chain Monte Carlo methods) operate by using\nstochastic gradients of the log density to generate a sample; our results\nestablish an information theoretic limit for all these algorithms.\n  We show that for every algorithm, there exists a well-conditioned strongly\nlog-concave target density for which the distribution of points generated by\nthe algorithm would be at least $\\varepsilon$ away from the target in total\nvariation distance if the number of gradient queries is less than\n$\\Omega(\\sigma^2 d/\\varepsilon^2)$, where $\\sigma^2 d$ is the variance of the\nstochastic gradient. Our lower bound follows by combining the ideas of Le Cam\ndeficiency routinely used in the comparison of statistical experiments along\nwith standard information theoretic tools used in lower bounding Bayes risk\nfunctions. To the best of our knowledge our results provide the first\nnontrivial dimension-dependent lower bound for this problem.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 23:46:35 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 20:35:47 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 04:12:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Bartlett", "Peter L.", ""], ["Long", "Philip M.", ""]]}, {"id": "2002.00306", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi and Walid Saad", "title": "Brainstorming Generative Adversarial Networks (BGANs): Towards\n  Multi-Agent Generative Models with Distributed Private Datasets", "comments": "13 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve a high learning accuracy, generative adversarial networks (GANs)\nmust be fed by large datasets that adequately represent the data space.\nHowever, in many scenarios, the available datasets may be limited and\ndistributed across multiple agents, each of which is seeking to learn the\ndistribution of the data on its own. In such scenarios, the local datasets are\ninherently private and agents often do not wish to share them. In this paper,\nto address this multi-agent GAN problem, a novel brainstorming GAN (BGAN)\narchitecture is proposed using which multiple agents can generate real-like\ndata samples while operating in a fully distributed manner and preserving their\ndata privacy. BGAN allows the agents to gain information from other agents\nwithout sharing their real datasets but by \"brainstorming\" via the sharing of\ntheir generated data samples. In contrast to existing distributed GAN\nsolutions, the proposed BGAN architecture is designed to be fully distributed,\nand it does not need any centralized controller. Moreover, BGANs are shown to\nbe scalable and not dependent on the hyperparameters of the agents' deep neural\nnetworks (DNNs) thus enabling the agents to have different DNN architectures.\nTheoretically, the interactions between BGAN agents are analyzed as a game\nwhose unique Nash equilibrium is derived. Experimental results show that BGAN\ncan generate real-like data samples with higher quality and lower\nJensen-Shannon divergence (JSD) and Fr\\'echet Inception distance (FID) compared\nto other distributed GAN architectures.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 02:58:32 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 02:49:06 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Saad", "Walid", ""]]}, {"id": "2002.00315", "submitter": "Mengxiao Zhang", "authors": "Chung-Wei Lee, Haipeng Luo, Mengxiao Zhang", "title": "A Closer Look at Small-loss Bounds for Bandits with Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study small-loss bounds for adversarial multi-armed bandits with graph\nfeedback, that is, adaptive regret bounds that depend on the loss of the best\narm or related quantities, instead of the total number of rounds. We derive the\nfirst small-loss bound for general strongly observable graphs, resolving an\nopen problem of Lykouris et al. (2018). Specifically, we develop an algorithm\nwith regret $\\mathcal{\\tilde{O}}(\\sqrt{\\kappa L_*})$ where $\\kappa$ is the\nclique partition number and $L_*$ is the loss of the best arm, and for the\nspecial case of self-aware graphs where every arm has a self-loop, we improve\nthe regret to $\\mathcal{\\tilde{O}}(\\min\\{\\sqrt{\\alpha T}, \\sqrt{\\kappa L_*}\\})$\nwhere $\\alpha \\leq \\kappa$ is the independence number. Our results\nsignificantly improve and extend those by Lykouris et al. (2018) who only\nconsider self-aware undirected graphs.\n  Furthermore, we also take the first attempt at deriving small-loss bounds for\nweakly observable graphs. We first prove that no typical small-loss bounds are\nachievable in this case, and then propose algorithms with alternative\nsmall-loss bounds in terms of the loss of some specific subset of arms. A\nsurprising side result is that $\\mathcal{\\tilde{O}}(\\sqrt{T})$ regret is\nachievable even for weakly observable graphs as long as the best arm has a\nself-loop.\n  Our algorithms are based on the Online Mirror Descent framework but require a\nsuite of novel techniques that might be of independent interest. Moreover, all\nour algorithms can be made parameter-free without the knowledge of the\nenvironment.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 03:48:01 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 02:06:49 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lee", "Chung-Wei", ""], ["Luo", "Haipeng", ""], ["Zhang", "Mengxiao", ""]]}, {"id": "2002.00319", "submitter": "Jingdong Li", "authors": "Jingdong Li, Hui Zhang, Xueliang Zhang, and Changliang Li", "title": "Single Channel Speech Enhancement Using Temporal Convolutional Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent decades, neural network based methods have significantly improved\nthe performace of speech enhancement. Most of them estimate time-frequency\n(T-F) representation of target speech directly or indirectly, then resynthesize\nwaveform using the estimated T-F representation. In this work, we proposed the\ntemporal convolutional recurrent network (TCRN), an end-to-end model that\ndirectly map noisy waveform to clean waveform. The TCRN, which is combined\nconvolution and recurrent neural network, is able to efficiently and\neffectively leverage short-term ang long-term information. Futuremore, we\npresent the architecture that repeatedly downsample and upsample speech during\nforward propagation. We show that our model is able to improve the performance\nof model, compared with existing convolutional recurrent networks. Futuremore,\nWe present several key techniques to stabilize the training process. The\nexperimental results show that our model consistently outperforms existing\nspeech enhancement approaches, in terms of speech intelligibility and quality.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 04:26:50 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Li", "Jingdong", ""], ["Zhang", "Hui", ""], ["Zhang", "Xueliang", ""], ["Li", "Changliang", ""]]}, {"id": "2002.00329", "submitter": "Jeongyeol Kwon", "authors": "Jeongyeol Kwon, Constantine Caramanis", "title": "The EM Algorithm gives Sample-Optimality for Learning Mixtures of\n  Well-Separated Gaussians", "comments": "Accepted to COLT 2020; Title changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of spherical Gaussian Mixture models with $k \\geq 3$\ncomponents when the components are well separated. A fundamental previous\nresult established that separation of $\\Omega(\\sqrt{\\log k})$ is necessary and\nsufficient for identifiability of the parameters with polynomial sample\ncomplexity (Regev and Vijayaraghavan, 2017). In the same context, we show that\n$\\tilde{O} (kd/\\epsilon^2)$ samples suffice for any $\\epsilon \\lesssim 1/k$,\nclosing the gap from polynomial to linear, and thus giving the first optimal\nsample upper bound for the parameter estimation of well-separated Gaussian\nmixtures. We accomplish this by proving a new result for the\nExpectation-Maximization (EM) algorithm: we show that EM converges locally,\nunder separation $\\Omega(\\sqrt{\\log k})$. The previous best-known guarantee\nrequired $\\Omega(\\sqrt{k})$ separation (Yan, et al., 2017). Unlike prior work,\nour results do not assume or use prior knowledge of the (potentially different)\nmixing weights or variances of the Gaussian components. Furthermore, our\nresults show that the finite-sample error of EM does not depend on\nnon-universal quantities such as pairwise distances between means of Gaussian\ncomponents.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:09:26 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:36:40 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kwon", "Jeongyeol", ""], ["Caramanis", "Constantine", ""]]}, {"id": "2002.00336", "submitter": "Arun CS Kumar", "authors": "Arun CS Kumar, Disha Ahuja, Ashwath Aithal", "title": "3D Object Detection on Point Clouds using Local Ground-aware and\n  Adaptive Representation of scenes' surface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A novel, adaptive ground-aware, and cost-effective 3D Object Detection\npipeline is proposed. The ground surface representation introduced in this\npaper, in comparison to its uni-planar counterparts (methods that model the\nsurface of a whole 3D scene using single plane), is far more accurate while\nbeing ~10x faster. The novelty of the ground representation lies both in the\nway in which the ground surface of the scene is represented in Lidar perception\nproblems, as well as in the (cost-efficient) way in which it is computed.\nFurthermore, the proposed object detection pipeline builds on the traditional\ntwo-stage object detection models by incorporating the ability to dynamically\nreason the surface of the scene, ultimately achieving a new state-of-the-art 3D\nobject detection performance among the two-stage Lidar Object Detection\npipelines.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 05:42:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 22:13:24 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kumar", "Arun CS", ""], ["Ahuja", "Disha", ""], ["Aithal", "Ashwath", ""]]}, {"id": "2002.00343", "submitter": "Sungho Shin", "authors": "Sungho Shin, Yoonho Boo, Wonyong Sung", "title": "SQWA: Stochastic Quantized Weight Averaging for Improving the\n  Generalization Capability of Low-Precision Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a deep neural network (DNN) with good generalization capability is\na complex process especially when the weights are severely quantized. Model\naveraging is a promising approach for achieving the good generalization\ncapability of DNNs, especially when the loss surface for training contains many\nsharp minima. We present a new quantized neural network optimization approach,\nstochastic quantized weight averaging (SQWA), to design low-precision DNNs with\ngood generalization capability using model averaging. The proposed approach\nincludes (1) floating-point model training, (2) direct quantization of weights,\n(3) capturing multiple low-precision models during retraining with cyclical\nlearning rates, (4) averaging the captured models, and (5) re-quantizing the\naveraged model and fine-tuning it with low-learning rates. Additionally, we\npresent a loss-visualization technique on the quantized weight domain to\nclearly elucidate the behavior of the proposed method. Visualization results\nindicate that a quantized DNN (QDNN) optimized with the proposed approach is\nlocated near the center of the flat minimum in the loss surface. With SQWA\ntraining, we achieved state-of-the-art results for 2-bit QDNNs on CIFAR-100 and\nImageNet datasets. Although we only employed a uniform quantization scheme for\nthe sake of implementation in VLSI or low-precision neural processing units,\nthe performance achieved exceeded those of previous studies employing\nnon-uniform quantization.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 07:02:51 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shin", "Sungho", ""], ["Boo", "Yoonho", ""], ["Sung", "Wonyong", ""]]}, {"id": "2002.00372", "submitter": "C Anantaram", "authors": "Rupam Patir, Shubham Singhal, C. Anantaram, Vikram Goyal", "title": "Interpretability of Blackbox Machine Learning Models through Dataview\n  Extraction and Shadow Model creation", "comments": "13 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models trained using massive amounts of data tend to capture\none view of the data and its associated mapping. Different deep learning models\nbuilt on the same training data may capture different views of the data based\non the underlying techniques used. For explaining the decisions arrived by\nblackbox deep learning models, we argue that it is essential to reproduce that\nmodel's view of the training data faithfully. This faithful reproduction can\nthen be used for explanation generation. We investigate two methods for data\nview extraction: hill-climbing approach and a GAN-driven approach. We then use\nthis synthesized data for creating shadow models for explanation generation:\nDecision-Tree model and Formal Concept Analysis based model. We evaluate these\napproaches on a Blackbox model trained on public datasets and show its\nusefulness in explanation generation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 11:47:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Patir", "Rupam", ""], ["Singhal", "Shubham", ""], ["Anantaram", "C.", ""], ["Goyal", "Vikram", ""]]}, {"id": "2002.00401", "submitter": "Liang-Chi Huang Mr.", "authors": "Jwo-Yuh Wu, Wen-Hsuan Li, Liang-Chi Huang, Yen-Ping Lin, Chun-Hung Liu\n  and Rung-Hung Gau", "title": "Provable Noisy Sparse Subspace Clustering using Greedy Neighbor\n  Selection: A Coherence-Based Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse subspace clustering (SSC) using greedy-based neighbor selection, such\nas matching pursuit (MP) and orthogonal matching pursuit (OMP), has been known\nas a popular computationally-efficient alternative to the conventional\nL1-minimization based methods. Under deterministic bounded noise corruption, in\nthis paper we derive coherence-based sufficient conditions guaranteeing correct\nneighbor identification using MP/OMP. Our analyses exploit the maximum/minimum\ninner product between two noisy data points subject to a known upper bound on\nthe noise level. The obtained sufficient condition clearly reveals the impact\nof noise on greedy-based neighbor recovery. Specifically, it asserts that, as\nlong as noise is sufficiently small so that the resultant perturbed residual\nvectors stay close to the desired subspace, both MP and OMP succeed in\nreturning a correct neighbor subset. A striking finding is that, when the\nground truth subspaces are well-separated from each other and noise is not\nlarge, MP-based iterations, while enjoying lower algorithmic complexity, yield\nsmaller perturbation of residuals, thereby better able to identify correct\nneighbors and, in turn, achieving higher global data clustering accuracy.\nExtensive numerical experiments are used to corroborate our theoretical study.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:28:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wu", "Jwo-Yuh", ""], ["Li", "Wen-Hsuan", ""], ["Huang", "Liang-Chi", ""], ["Lin", "Yen-Ping", ""], ["Liu", "Chun-Hung", ""], ["Gau", "Rung-Hung", ""]]}, {"id": "2002.00412", "submitter": "Konrad Zolna", "authors": "Konrad Zolna, Chitwan Saharia, Leonard Boussioux, David Yu-Tung Hui,\n  Maxime Chevalier-Boisvert, Dzmitry Bahdanau and Yoshua Bengio", "title": "Combating False Negatives in Adversarial Imitation Learning", "comments": "This is an extended version of the student abstract published at 34th\n  AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial imitation learning, a discriminator is trained to\ndifferentiate agent episodes from expert demonstrations representing the\ndesired behavior. However, as the trained policy learns to be more successful,\nthe negative examples (the ones produced by the agent) become increasingly\nsimilar to expert ones. Despite the fact that the task is successfully\naccomplished in some of the agent's trajectories, the discriminator is trained\nto output low values for them. We hypothesize that this inconsistent training\nsignal for the discriminator can impede its learning, and consequently leads to\nworse overall performance of the agent. We show experimental evidence for this\nhypothesis and that the 'False Negatives' (i.e. successful agent episodes)\nsignificantly hinder adversarial imitation learning, which is the first\ncontribution of this paper. Then, we propose a method to alleviate the impact\nof false negatives and test it on the BabyAI environment. This method\nconsistently improves sample efficiency over the baselines by at least an order\nof magnitude.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:56:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zolna", "Konrad", ""], ["Saharia", "Chitwan", ""], ["Boussioux", "Leonard", ""], ["Hui", "David Yu-Tung", ""], ["Chevalier-Boisvert", "Maxime", ""], ["Bahdanau", "Dzmitry", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.00413", "submitter": "Yiyan Qi", "authors": "Yiyan Qi, Pinghui Wang, Yuanming Zhang, Junzhou Zhao, Guangjian Tian,\n  and Xiaohong Guan", "title": "Fast Generating A Large Number of Gumbel-Max Variables", "comments": "Accepted by WebConf2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Gumbel-Max Trick for sampling elements from a categorical\ndistribution (or more generally a nonnegative vector) and its variants have\nbeen widely used in areas such as machine learning and information retrieval.\nTo sample a random element $i$ (or a Gumbel-Max variable $i$) in proportion to\nits positive weight $v_i$, the Gumbel-Max Trick first computes a Gumbel random\nvariable $g_i$ for each positive weight element $i$, and then samples the\nelement $i$ with the largest value of $g_i+\\ln v_i$. Recently, applications\nincluding similarity estimation and graph embedding require to generate $k$\nindependent Gumbel-Max variables from high dimensional vectors. However, it is\ncomputationally expensive for a large $k$ (e.g., hundreds or even thousands)\nwhen using the traditional Gumbel-Max Trick. To solve this problem, we propose\na novel algorithm, \\emph{FastGM}, that reduces the time complexity from\n$O(kn^+)$ to $O(k \\ln k + n^+)$, where $n^+$ is the number of positive elements\nin the vector of interest. Instead of computing $k$ independent Gumbel random\nvariables directly, we find that there exists a technique to generate these\nvariables in descending order. Using this technique, our method FastGM computes\nvariables $g_i+\\ln v_i$ for all positive elements $i$ in descending order. As a\nresult, FastGM significantly reduces the computation time because we can stop\nthe procedure of Gumbel random variables computing for many elements especially\nfor those with small weights. Experiments on a variety of real-world datasets\nshow that FastGM is orders of magnitude faster than state-of-the-art methods\nwithout sacrificing accuracy and incurring additional expenses.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:15:44 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Qi", "Yiyan", ""], ["Wang", "Pinghui", ""], ["Zhang", "Yuanming", ""], ["Zhao", "Junzhou", ""], ["Tian", "Guangjian", ""], ["Guan", "Xiaohong", ""]]}, {"id": "2002.00421", "submitter": "Kiran Tomlinson", "authors": "Kiran Tomlinson and Austin R. Benson", "title": "Choice Set Optimization Under Discrete Choice Models of Group Decisions", "comments": "19 pages, 7 figures. ICML 2020. This is an updated version after\n  reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The way that people make choices or exhibit preferences can be strongly\naffected by the set of available alternatives, often called the choice set.\nFurthermore, there are usually heterogeneous preferences, either at an\nindividual level within small groups or within sub-populations of large groups.\nGiven the availability of choice data, there are now many models that capture\nthis behavior in order to make effective predictions--however, there is little\nwork in understanding how directly changing the choice set can be used to\ninfluence the preferences of a collection of decision-makers. Here, we use\ndiscrete choice modeling to develop an optimization framework of such\ninterventions for several problems of group influence, namely maximizing\nagreement or disagreement and promoting a particular choice. We show that these\nproblems are NP-hard in general, but imposing restrictions reveals a\nfundamental boundary: promoting a choice can be easier than encouraging\nconsensus or sowing discord. We design approximation algorithms for the hard\nproblems and show that they work well on real-world choice data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 15:59:58 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 00:54:26 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tomlinson", "Kiran", ""], ["Benson", "Austin R.", ""]]}, {"id": "2002.00423", "submitter": "Ibrahim Abdelaziz", "authors": "Ibrahim Abdelaziz, Veronika Thost, Maxwell Crouse, Achille Fokoue", "title": "An Experimental Study of Formula Embeddings for Automated Theorem\n  Proving in First-Order Logic", "comments": "7 pages, preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated theorem proving in first-order logic is an active research area\nwhich is successfully supported by machine learning. While there have been\nvarious proposals for encoding logical formulas into numerical vectors -- from\nsimple strings to more involved graph-based embeddings -- little is known about\nhow these different encodings compare. In this paper, we study and\nexperimentally compare pattern-based embeddings that are applied in current\nsystems with popular graph-based encodings, most of which have not been\nconsidered in the theorem proving context before. Our experiments show that the\nadvantages of simpler encoding schemes in terms of runtime are outdone by more\ncomplex graph-based embeddings, which yield more efficient search strategies\nand simpler proofs. To support this, we present a detailed analysis across\nseveral dimensions of theorem prover performance beyond just proof completion\nrate, thus providing empirical evidence to help guide future research on\nneural-guided theorem proving towards the most promising directions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 16:07:15 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 16:41:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Abdelaziz", "Ibrahim", ""], ["Thost", "Veronika", ""], ["Crouse", "Maxwell", ""], ["Fokoue", "Achille", ""]]}, {"id": "2002.00444", "submitter": "Senthil Yogamani", "authors": "B Ravi Kiran, Ibrahim Sobh, Victor Talpaert, Patrick Mannion, Ahmad A.\n  Al Sallab, Senthil Yogamani, Patrick P\\'erez", "title": "Deep Reinforcement Learning for Autonomous Driving: A Survey", "comments": "Accepted for publication at IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep representation learning, the domain of\nreinforcement learning (RL) has become a powerful learning framework now\ncapable of learning complex policies in high dimensional environments. This\nreview summarises deep reinforcement learning (DRL) algorithms and provides a\ntaxonomy of automated driving tasks where (D)RL methods have been employed,\nwhile addressing key computational challenges in real world deployment of\nautonomous driving agents. It also delineates adjacent domains such as behavior\ncloning, imitation learning, inverse reinforcement learning that are related\nbut are not classical RL algorithms. The role of simulators in training agents,\nmethods to validate, test and robustify existing solutions in RL are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:21:22 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 17:02:01 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Kiran", "B Ravi", ""], ["Sobh", "Ibrahim", ""], ["Talpaert", "Victor", ""], ["Mannion", "Patrick", ""], ["Sallab", "Ahmad A. Al", ""], ["Yogamani", "Senthil", ""], ["P\u00e9rez", "Patrick", ""]]}, {"id": "2002.00453", "submitter": "Chau Luu", "authors": "Chau Luu, Peter Bell, Steve Renals", "title": "DropClass and DropAdapt: Dropping classes for deep speaker\n  representation learning", "comments": "Submitted to Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent works on deep speaker embeddings train their feature extraction\nnetworks on large classification tasks, distinguishing between all speakers in\na training set. Empirically, this has been shown to produce\nspeaker-discriminative embeddings, even for unseen speakers. However, it is not\nclear that this is the optimal means of training embeddings that generalize\nwell. This work proposes two approaches to learning embeddings, based on the\nnotion of dropping classes during training. We demonstrate that both approaches\ncan yield performance gains in speaker verification tasks. The first proposed\nmethod, DropClass, works via periodically dropping a random subset of classes\nfrom the training data and the output layer throughout training, resulting in a\nfeature extractor trained on many different classification tasks. Combined with\nan additive angular margin loss, this method can yield a 7.9% relative\nimprovement in equal error rate (EER) over a strong baseline on VoxCeleb. The\nsecond proposed method, DropAdapt, is a means of adapting a trained model to a\nset of enrolment speakers in an unsupervised manner. This is performed by\nfine-tuning a model on only those classes which produce high probability\npredictions when the enrolment speakers are used as input, again also dropping\nthe relevant rows from the output layer. This method yields a large 13.2%\nrelative improvement in EER on VoxCeleb. The code for this paper has been made\npublicly available.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 18:43:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Luu", "Chau", ""], ["Bell", "Peter", ""], ["Renals", "Steve", ""]]}, {"id": "2002.00467", "submitter": "Rolf Jagerman", "authors": "Rolf Jagerman and Ilya Markov and Maarten de Rijke", "title": "Safe Exploration for Optimizing Contextual Bandits", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit problems are a natural fit for many information retrieval\ntasks, such as learning to rank, text classification, recommendation, etc.\nHowever, existing learning methods for contextual bandit problems have one of\ntwo drawbacks: they either do not explore the space of all possible document\nrankings (i.e., actions) and, thus, may miss the optimal ranking, or they\npresent suboptimal rankings to a user and, thus, may harm the user experience.\nWe introduce a new learning method for contextual bandit problems, Safe\nExploration Algorithm (SEA), which overcomes the above drawbacks. SEA starts by\nusing a baseline (or production) ranking system (i.e., policy), which does not\nharm the user experience and, thus, is safe to execute, but has suboptimal\nperformance and, thus, needs to be improved. Then SEA uses counterfactual\nlearning to learn a new policy based on the behavior of the baseline policy.\nSEA also uses high-confidence off-policy evaluation to estimate the performance\nof the newly learned policy. Once the performance of the newly learned policy\nis at least as good as the performance of the baseline policy, SEA starts using\nthe new policy to execute new actions, allowing it to actively explore\nfavorable regions of the action space. This way, SEA never performs worse than\nthe baseline policy and, thus, does not harm the user experience, while still\nexploring the action space and, thus, being able to find an optimal policy. Our\nexperiments using text classification and document retrieval confirm the above\nby comparing SEA (and a boundless variant called BSEA) to online and offline\nlearning methods for contextual bandit problems.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 19:18:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Jagerman", "Rolf", ""], ["Markov", "Ilya", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2002.00476", "submitter": "Konstantinos Drossos", "authors": "Konstantinos Drossos and Stylianos I. Mimilakis and Shayan Gharib and\n  Yanxiong Li and Tuomas Virtanen", "title": "Sound Event Detection with Depthwise Separable and Dilated Convolutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art sound event detection (SED) methods usually employ a series\nof convolutional neural networks (CNNs) to extract useful features from the\ninput audio signal, and then recurrent neural networks (RNNs) to model longer\ntemporal context in the extracted features. The number of the channels of the\nCNNs and size of the weight matrices of the RNNs have a direct effect on the\ntotal amount of parameters of the SED method, which is to a couple of millions.\nAdditionally, the usually long sequences that are used as an input to an SED\nmethod along with the employment of an RNN, introduce implications like\nincreased training time, difficulty at gradient flow, and impeding the\nparallelization of the SED method. To tackle all these problems, we propose the\nreplacement of the CNNs with depthwise separable convolutions and the\nreplacement of the RNNs with dilated convolutions. We compare the proposed\nmethod to a baseline convolutional neural network on a SED task, and achieve a\nreduction of the amount of parameters by 85% and average training time per\nepoch by 78%, and an increase the average frame-wise F1 score and reduction of\nthe average error rate by 4.6% and 3.8%, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 19:50:51 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Drossos", "Konstantinos", ""], ["Mimilakis", "Stylianos I.", ""], ["Gharib", "Shayan", ""], ["Li", "Yanxiong", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "2002.00492", "submitter": "Peizhong Ju", "authors": "Peizhong Ju, Xiaojun Lin, Jia Liu", "title": "Overfitting Can Be Harmless for Basis Pursuit, But Only to a Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been significant interests in studying the so-called\n\"double-descent\" of the generalization error of linear regression models under\nthe overparameterized and overfitting regime, with the hope that such analysis\nmay provide the first step towards understanding why overparameterized deep\nneural networks (DNN) still generalize well. However, to date most of these\nstudies focused on the min $\\ell_2$-norm solution that overfits the data. In\ncontrast, in this paper we study the overfitting solution that minimizes the\n$\\ell_1$-norm, which is known as Basis Pursuit (BP) in the compressed sensing\nliterature. Under a sparse true linear regression model with $p$ i.i.d.\nGaussian features, we show that for a large range of $p$ up to a limit that\ngrows exponentially with the number of samples $n$, with high probability the\nmodel error of BP is upper bounded by a value that decreases with $p$. To the\nbest of our knowledge, this is the first analytical result in the literature\nestablishing the double-descent of overfitting BP for finite $n$ and $p$.\nFurther, our results reveal significant differences between the double-descent\nof BP and min $\\ell_2$-norm solutions. Specifically, the double-descent\nupper-bound of BP is independent of the signal strength, and for high SNR and\nsparse models the descent-floor of BP can be much lower and wider than that of\nmin $\\ell_2$-norm solutions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 20:48:39 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 23:29:36 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ju", "Peizhong", ""], ["Lin", "Xiaojun", ""], ["Liu", "Jia", ""]]}, {"id": "2002.00495", "submitter": "Andrew Wagenmaker", "authors": "Andrew Wagenmaker and Kevin Jamieson", "title": "Active Learning for Identification of Linear Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm to actively estimate the parameters of a linear\ndynamical system. Given complete control over the system's input, our algorithm\nadaptively chooses the inputs to accelerate estimation. We show a finite time\nbound quantifying the estimation rate our algorithm attains and prove matching\nupper and lower bounds which guarantee its asymptotic optimality, up to\nconstants. In addition, we show that this optimal rate is unattainable when\nusing Gaussian noise to excite the system, even with optimally tuned\ncovariance, and analyze several examples where our algorithm provably improves\nover rates obtained by playing noise. Our analysis critically relies on a novel\nresult quantifying the error in estimating the parameters of a dynamical system\nwhen arbitrary periodic inputs are being played. We conclude with numerical\nexamples that illustrate the effectiveness of our algorithm in practice.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:30:38 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 15:57:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Wagenmaker", "Andrew", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2002.00497", "submitter": "Karl Kurzer", "authors": "Karl Kurzer, Marcus Fechner and J. Marius Z\\\"ollner", "title": "Accelerating Cooperative Planning for Automated Vehicles with Learned\n  Heuristics and Monte Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient driving in urban traffic scenarios requires foresight. The\nobservation of other traffic participants and the inference of their possible\nnext actions depending on the own action is considered cooperative prediction\nand planning. Humans are well equipped with the capability to predict the\nactions of multiple interacting traffic participants and plan accordingly,\nwithout the need to directly communicate with others. Prior work has shown that\nit is possible to achieve effective cooperative planning without the need for\nexplicit communication. However, the search space for cooperative plans is so\nlarge that most of the computational budget is spent on exploring the search\nspace in unpromising regions that are far away from the solution. To accelerate\nthe planning process, we combined learned heuristics with a cooperative\nplanning method to guide the search towards regions with promising actions,\nyielding better solutions at lower computational costs.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:41:35 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 14:46:05 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kurzer", "Karl", ""], ["Fechner", "Marcus", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2002.00498", "submitter": "Nisara Sriwattanaworachai", "authors": "Roxana Pamfil, Nisara Sriwattanaworachai, Shaan Desai, Philip\n  Pilgerstorfer, Paul Beaumont, Konstantinos Georgatzis, Bryon Aragam", "title": "DYNOTEARS: Structure Learning from Time-Series Data", "comments": "23 pages, 13 figures, accepted to AISTATS 2020, corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the structure learning problem for dynamic Bayesian networks and\npropose a method that simultaneously estimates contemporaneous (intra-slice)\nand time-lagged (inter-slice) relationships between variables in a time-series.\nOur approach is score-based, and revolves around minimizing a penalized loss\nsubject to an acyclicity constraint. To solve this problem, we leverage a\nrecent algebraic result characterizing the acyclicity constraint as a smooth\nequality constraint. The resulting algorithm, which we call DYNOTEARS,\noutperforms other methods on simulated data, especially in high-dimensions as\nthe number of variables increases. We also apply this algorithm on real\ndatasets from two different domains, finance and molecular biology, and analyze\nthe resulting output. Compared to state-of-the-art methods for learning dynamic\nBayesian networks, our method is both scalable and accurate on real data. The\nsimple formulation and competitive performance of our method make it suitable\nfor a variety of problems where one seeks to learn connections between\nvariables across time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:47:48 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 18:06:04 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Pamfil", "Roxana", ""], ["Sriwattanaworachai", "Nisara", ""], ["Desai", "Shaan", ""], ["Pilgerstorfer", "Philip", ""], ["Beaumont", "Paul", ""], ["Georgatzis", "Konstantinos", ""], ["Aragam", "Bryon", ""]]}, {"id": "2002.00514", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li and Joao Saude", "title": "Explain Graph Neural Networks to Understand Weighted Graph Features in\n  Node Classification", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real data collected from different applications that have additional\ntopological structures and connection information are amenable to be\nrepresented as a weighted graph. Considering the node labeling problem, Graph\nNeural Networks (GNNs) is a powerful tool, which can mimic experts' decision on\nnode labeling. GNNs combine node features, connection patterns, and graph\nstructure by using a neural network to embed node information and pass it\nthrough edges in the graph. We want to identify the patterns in the input data\nused by the GNN model to make a decision and examine if the model works as we\ndesire. However, due to the complex data representation and non-linear\ntransformations, explaining decisions made by GNNs is challenging. In this\nwork, we propose new graph features' explanation methods to identify the\ninformative components and important node features. Besides, we propose a\npipeline to identify the key factors used for node classification. We use four\ndatasets (two synthetic and two real) to validate our methods. Our results\ndemonstrate that our explanation approach can mimic data patterns used for node\nclassification by human interpretation and disentangle different features in\nthe graphs. Furthermore, our explanation methods can be used for understanding\ndata, debugging GNN models, and examine model decisions.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 23:53:21 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Saude", "Joao", ""]]}, {"id": "2002.00522", "submitter": "Chengwei Chen", "authors": "Chengwei Chen and Wang Yuan and Yuan Xie and Yanyun Qu and Yiqing Tao\n  and Haichuan Song and Lizhuang Ma", "title": "Novelty Detection via Non-Adversarial Generative Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class novelty detection is the process of determining if a query example\ndiffers from the training examples (the target class). Most of previous\nstrategies attempt to learn the real characteristics of target sample by using\ngenerative adversarial networks (GANs) methods. However, the training process\nof GANs remains challenging, suffering from instability issues such as mode\ncollapse and vanishing gradients. In this paper, by adopting non-adversarial\ngenerative networks, a novel decoder-encoder framework is proposed for novelty\ndetection task, insteading of classical encoder-decoder style. Under the\nnon-adversarial framework, both latent space and image reconstruction space are\njointly optimized, leading to a more stable training process with super fast\nconvergence and lower training losses. During inference, inspired by cycleGAN,\nwe design a new testing scheme to conduct image reconstruction, which is the\nreverse way of training sequence. Experiments show that our model has the clear\nsuperiority over cutting-edge novelty detectors and achieves the\nstate-of-the-art results on the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 01:05:59 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Chen", "Chengwei", ""], ["Yuan", "Wang", ""], ["Xie", "Yuan", ""], ["Qu", "Yanyun", ""], ["Tao", "Yiqing", ""], ["Song", "Haichuan", ""], ["Ma", "Lizhuang", ""]]}, {"id": "2002.00526", "submitter": "Wenbo Guo", "authors": "Yang Lu, Wenbo Guo, Xinyu Xing, William Stafford Noble", "title": "DANCE: Enhancing saliency maps using decoys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saliency methods can make deep neural network predictions more interpretable\nby identifying a set of critical features in an input sample, such as pixels\nthat contribute most strongly to a prediction made by an image classifier.\nUnfortunately, recent evidence suggests that many saliency methods poorly\nperform, especially in situations where gradients are saturated, inputs contain\nadversarial perturbations, or predictions rely upon inter-feature dependence.\nTo address these issues, we propose a framework that improves the robustness of\nsaliency methods by following a two-step procedure. First, we introduce a\nperturbation mechanism that subtly varies the input sample without changing its\nintermediate representations. Using this approach, we can gather a corpus of\nperturbed data samples while ensuring that the perturbed and original input\nsamples follow the same distribution. Second, we compute saliency maps for the\nperturbed samples and propose a new method to aggregate saliency maps. With\nthis design, we offset the gradient saturation influence upon interpretation.\nFrom a theoretical perspective, we show the aggregated saliency map could not\nonly capture inter-feature dependence but, more importantly, robustify\ninterpretation against previously described adversarial perturbation methods.\nFollowing our theoretical analysis, we present experimental results suggesting\nthat, both qualitatively and quantitatively, our saliency method outperforms\nexisting methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 01:21:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 21:26:14 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 15:31:30 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lu", "Yang", ""], ["Guo", "Wenbo", ""], ["Xing", "Xinyu", ""], ["Noble", "William Stafford", ""]]}, {"id": "2002.00533", "submitter": "Jianyuan Yu", "authors": "Jianyuan Yu, Mohammad Alhassoun and R. Michael Buehrer", "title": "Interference Classification Using Deep Neural Networks", "comments": "paper get rejected, need more editing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success in implementing supervised learning to classify modulation\ntypes suggests that other problems akin to modulation classification would\neventually benefit from that implementation. One of these problems is\nclassifying the interference type added to a signal-of-interest, also known as\ninterference classification. In this paper, we propose an interference\nclassification method using a deep neural network. We generate five distinct\ntypes of interfering signals then use both the power-spectral density (PSD) and\nthe cyclic spectrum of the received signal as input features to the network.\nThe computer experiments reveal that using the received signal PSD outperforms\nusing its cyclic spectrum in terms of accuracy. In addition, the same\nexperiments show that the feed-forward networks yield better accuracy than\nclassic methods. The proposed classifier aids the subsequent stage in the\nreceiver chain with choosing the appropriate mitigation algorithm and also can\ncoexist with modulation-classification methods to further improve the\nclassifier accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:12:39 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 02:32:36 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Yu", "Jianyuan", ""], ["Alhassoun", "Mohammad", ""], ["Buehrer", "R. Michael", ""]]}, {"id": "2002.00537", "submitter": "Jing Zhang", "authors": "Jing Zhang and Zhe Chen and Dacheng Tao", "title": "Towards High Performance Human Keypoint Detection", "comments": "Accepted by IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human keypoint detection from a single image is very challenging due to\nocclusion, blur, illumination and scale variance. In this paper, we address\nthis problem from three aspects by devising an efficient network structure,\nproposing three effective training strategies, and exploiting four useful\npostprocessing techniques. First, we find that context information plays an\nimportant role in reasoning human body configuration and invisible keypoints.\nInspired by this, we propose a cascaded context mixer (CCM), which efficiently\nintegrates spatial and channel context information and progressively refines\nthem. Then, to maximize CCM's representation capability, we develop a\nhard-negative person detection mining strategy and a joint-training strategy by\nexploiting abundant unlabeled data. It enables CCM to learn discriminative\nfeatures from massive diverse poses. Third, we present several sub-pixel\nrefinement techniques for postprocessing keypoint predictions to improve\ndetection accuracy. Extensive experiments on the MS COCO keypoint detection\nbenchmark demonstrate the superiority of the proposed method over\nrepresentative state-of-the-art (SOTA) methods. Our single model achieves\ncomparable performance with the winner of the 2018 COCO Keypoint Detection\nChallenge. The final ensemble model sets a new SOTA on this benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:24:51 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 02:23:25 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhang", "Jing", ""], ["Chen", "Zhe", ""], ["Tao", "Dacheng", ""]]}, {"id": "2002.00539", "submitter": "C.-H. Huck Yang", "authors": "Haoling Zhang, Chao-Han Huck Yang, Hector Zenil, Narsis A. Kiani, Yue\n  Shen, Jesper N. Tegner", "title": "Evolving Neural Networks through a Reverse Encoding Tree", "comments": "Accepted to IEEE Congress on Evolutionary Computation (IEEE CEC)\n  2020. Lecture Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SY eess.SY q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NeuroEvolution is one of the most competitive evolutionary learning\nframeworks for designing novel neural networks for use in specific tasks, such\nas logic circuit design and digital gaming. However, the application of\nbenchmark methods such as the NeuroEvolution of Augmenting Topologies (NEAT)\nremains a challenge, in terms of their computational cost and search time\ninefficiency. This paper advances a method which incorporates a type of\ntopological edge coding, named Reverse Encoding Tree (RET), for evolving\nscalable neural networks efficiently. Using RET, two types of approaches --\nNEAT with Binary search encoding (Bi-NEAT) and NEAT with Golden-Section search\nencoding (GS-NEAT) -- have been designed to solve problems in benchmark\ncontinuous learning environments such as logic gates, Cartpole, and Lunar\nLander, and tested against classical NEAT and FS-NEAT as baselines.\nAdditionally, we conduct a robustness test to evaluate the resilience of the\nproposed NEAT algorithms. The results show that the two proposed strategies\ndeliver improved performance, characterized by (1) a higher accumulated reward\nwithin a finite number of time steps; (2) using fewer episodes to solve\nproblems in targeted environments, and (3) maintaining adaptive robustness\nunder noisy perturbations, which outperform the baselines in all tested cases.\nOur analysis also demonstrates that RET expends potential future research\ndirections in dynamic environments. Code is available from\nhttps://github.com/HaolingZHANG/ReverseEncodingTree.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:29:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 21:00:11 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhang", "Haoling", ""], ["Yang", "Chao-Han Huck", ""], ["Zenil", "Hector", ""], ["Kiani", "Narsis A.", ""], ["Shen", "Yue", ""], ["Tegner", "Jesper N.", ""]]}, {"id": "2002.00541", "submitter": "Jianyuan Yu", "authors": "Jianyuan Yu", "title": "Multiple Angles of Arrival Estimation using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MUltiple SIgnal Classification (MUSIC) and Estimation of signal parameters\nvia rotational via rotational invariance (ESPRIT) has been widely used in super\nresolution direction of arrival estimation (DoA) in both Uniform Linear Arrays\n(ULA) or Uniform Circular Arrays (UCA). However, problems become challenging\nwhen the number of source signal increase, MUSIC suffer from computation\ncomplexity when finding the peaks, while ESPRIT may not robust to array\ngeometry offset. Therefore, Neural Network become a potential solution. In this\npaper, we propose a neural network to estimate the azimuth and elevation\nangles, based on the correlated matrix extracted from received data. Also, a\nserial scheme is listed to estimate multiple signals cases. The result shows\nthe neural network can achieve an accurate estimation under low SNR and deal\nwith multiple signals.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:37:43 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yu", "Jianyuan", ""]]}, {"id": "2002.00544", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Hu Hu, Yannan Wang, Chao-Han Huck Yang, Sabato Marco\n  Siniscalchi, Chin-Hui Lee", "title": "Tensor-to-Vector Regression for Multi-channel Speech Enhancement based\n  on Tensor-Train Network", "comments": "Accepted to ICASSP 2020. Update reproducible code", "journal-ref": "IEEE ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a tensor-to-vector regression approach to multi-channel speech\nenhancement in order to address the issue of input size explosion and\nhidden-layer size expansion. The key idea is to cast the conventional deep\nneural network (DNN) based vector-to-vector regression formulation under a\ntensor-train network (TTN) framework. TTN is a recently emerged solution for\ncompact representation of deep models with fully connected hidden layers. Thus\nTTN maintains DNN's expressive power yet involves a much smaller amount of\ntrainable parameters. Furthermore, TTN can handle a multi-dimensional tensor\ninput by design, which exactly matches the desired setting in multi-channel\nspeech enhancement. We first provide a theoretical extension from DNN to TTN\nbased regression. Next, we show that TTN can attain speech enhancement quality\ncomparable with that for DNN but with much fewer parameters, e.g., a reduction\nfrom 27 million to only 5 million parameters is observed in a single-channel\nscenario. TTN also improves PESQ over DNN from 2.86 to 2.96 by slightly\nincreasing the number of trainable parameters. Finally, in 8-channel\nconditions, a PESQ of 3.12 is achieved using 20 million parameters for TTN,\nwhereas a DNN with 68 million parameters can only attain a PESQ of 3.06. Our\nimplementation is available online\nhttps://github.com/uwjunqi/Tensor-Train-Neural-Network.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 02:58:00 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Qi", "Jun", ""], ["Hu", "Hu", ""], ["Wang", "Yannan", ""], ["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2002.00552", "submitter": "Di Huang", "authors": "Di Huang, Xishan Zhang, Rui Zhang, Tian Zhi, Deyuan He, Jiaming Guo,\n  Chang Liu, Qi Guo, Zidong Du, Shaoli Liu, Tianshi Chen, Yunji Chen", "title": "DWM: A Decomposable Winograd Method for Convolution Acceleration", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Winograd's minimal filtering algorithm has been widely used in Convolutional\nNeural Networks (CNNs) to reduce the number of multiplications for faster\nprocessing. However, it is only effective on convolutions with kernel size as\n3x3 and stride as 1, because it suffers from significantly increased FLOPs and\nnumerical accuracy problem for kernel size larger than 3x3 and fails on\nconvolution with stride larger than 1. In this paper, we propose a novel\nDecomposable Winograd Method (DWM), which breaks through the limitation of\noriginal Winograd's minimal filtering algorithm to a wide and general\nconvolutions. DWM decomposes kernels with large size or large stride to several\nsmall kernels with stride as 1 for further applying Winograd method, so that\nDWM can reduce the number of multiplications while keeping the numerical\naccuracy. It enables the fast exploring of larger kernel size and larger stride\nvalue in CNNs for high performance and accuracy and even the potential for new\nCNNs. Comparing against the original Winograd, the proposed DWM is able to\nsupport all kinds of convolutions with a speedup of ~2, without affecting the\nnumerical accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 03:42:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Huang", "Di", ""], ["Zhang", "Xishan", ""], ["Zhang", "Rui", ""], ["Zhi", "Tian", ""], ["He", "Deyuan", ""], ["Guo", "Jiaming", ""], ["Liu", "Chang", ""], ["Guo", "Qi", ""], ["Du", "Zidong", ""], ["Liu", "Shaoli", ""], ["Chen", "Tianshi", ""], ["Chen", "Yunji", ""]]}, {"id": "2002.00557", "submitter": "Amol Kelkar", "authors": "Amol Kelkar, Rohan Relan, Vaishali Bhardwaj, Saurabh Vaichal, Chandra\n  Khatri, Peter Relan", "title": "Bertrand-DR: Improving Text-to-SQL using a Discriminative Re-ranker", "comments": "Accepted at WeCNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To access data stored in relational databases, users need to understand the\ndatabase schema and write a query using a query language such as SQL. To\nsimplify this task, text-to-SQL models attempt to translate a user's natural\nlanguage question to corresponding SQL query. Recently, several generative\ntext-to-SQL models have been developed. We propose a novel discriminative\nre-ranker to improve the performance of generative text-to-SQL models by\nextracting the best SQL query from the beam output predicted by the text-to-SQL\ngenerator, resulting in improved performance in the cases where the best query\nwas in the candidate list, but not at the top of the list. We build the\nre-ranker as a schema agnostic BERT fine-tuned classifier. We analyze relative\nstrengths of the text-to-SQL and re-ranker models across different query\nhardness levels, and suggest how to combine the two models for optimal\nperformance. We demonstrate the effectiveness of the re-ranker by applying it\nto two state-of-the-art text-to-SQL models, and achieve top 4 score on the\nSpider leaderboard at the time of writing this article.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 04:52:47 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 22:22:57 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Kelkar", "Amol", ""], ["Relan", "Rohan", ""], ["Bhardwaj", "Vaishali", ""], ["Vaichal", "Saurabh", ""], ["Khatri", "Chandra", ""], ["Relan", "Peter", ""]]}, {"id": "2002.00558", "submitter": "Mark Sellke", "authors": "Mark Sellke, Aleksandrs Slivkins", "title": "The Price of Incentivizing Exploration: A Characterization via Thompson\n  Sampling and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider incentivized exploration: a version of multi-armed bandits where\nthe choice of arms is controlled by self-interested agents, and the algorithm\ncan only issue recommendations. The algorithm controls the flow of information,\nand the information asymmetry can incentivize the agents to explore. Prior work\nachieves optimal regret rates up to multiplicative factors that become\narbitrarily large depending on the Bayesian priors, and scale exponentially in\nthe number of arms. A more basic problem of sampling each arm once runs into\nsimilar factors.\n  We focus on the price of incentives: the loss in performance, broadly\nconstrued, incurred for the sake of incentive-compatibility. We prove that\nThompson Sampling, a standard bandit algorithm, is incentive-compatible if\ninitialized with sufficiently many data points. The performance loss due to\nincentives is therefore limited to the initial rounds when these data points\nare collected. The problem is largely reduced to that of sample complexity: how\nmany rounds are needed? We address this question, providing matching upper and\nlower bounds and instantiating them in various corollaries. Typically, the\noptimal sample complexity is polynomial in the number of arms and exponential\nin the \"strength of beliefs\".\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 04:58:51 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 02:59:53 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 19:43:52 GMT"}, {"version": "v4", "created": "Sat, 5 Jun 2021 04:13:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Sellke", "Mark", ""], ["Slivkins", "Aleksandrs", ""]]}, {"id": "2002.00573", "submitter": "Wei-Lun Chao", "authors": "Wei-Lun Chao, Han-Jia Ye, De-Chuan Zhan, Mark Campbell, Kilian Q.\n  Weinberger", "title": "Revisiting Meta-Learning as Supervised Learning", "comments": "An extended version of the paper titled \"A Meta Understanding of\n  Meta-Learning\" presented in ICML 2019 Workshop on Adaptive and Multitask\n  Learning: Algorithms & Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed an abundance of new publications and approaches\non meta-learning. This community-wide enthusiasm has sparked great insights but\nhas also created a plethora of seemingly different frameworks, which can be\nhard to compare and evaluate. In this paper, we aim to provide a principled,\nunifying framework by revisiting and strengthening the connection between\nmeta-learning and traditional supervised learning. By treating pairs of\ntask-specific data sets and target models as (feature, label) samples, we can\nreduce many meta-learning algorithms to instances of supervised learning. This\nview not only unifies meta-learning into an intuitive and practical framework\nbut also allows us to transfer insights from supervised learning directly to\nimprove meta-learning. For example, we obtain a better understanding of\ngeneralization properties, and we can readily transfer well-understood\ntechniques, such as model ensemble, pre-training, joint training, data\naugmentation, and even nearest neighbor based methods. We provide an intuitive\nanalogy of these methods in the context of meta-learning and show that they\ngive rise to significant improvements in model performance on few-shot\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 06:13:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Chao", "Wei-Lun", ""], ["Ye", "Han-Jia", ""], ["Zhan", "De-Chuan", ""], ["Campbell", "Mark", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.00577", "submitter": "Kangying Lin", "authors": "Huawei Huang, Kangying Lin, Song Guo, Pan Zhou, Zibin Zheng", "title": "Prophet: Proactive Candidate-Selection for Federated Learning by\n  Predicting the Qualities of Training and Reporting Phases", "comments": "We found significant technique errors in our previous version. The\n  proposed DRL-based algorithm cannot solve the large-scale scheduling for\n  federated learning. For the health of relevant research communities, we\n  decide to withdraw our submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the challenge of the device connection is much relieved in 5G\nnetworks, the training latency is still an obstacle preventing Federated\nLearning (FL) from being largely adopted. One of the most fundamental problems\nthat lead to large latency is the bad candidate-selection for FL. In the\ndynamic environment, the mobile devices selected by the existing reactive\ncandidate-selection algorithms very possibly fail to complete the training and\nreporting phases of FL, because the FL parameter server only knows the\ncurrently-observed resources of all candidates. To this end, we study the\nproactive candidate-selection for FL in this paper. We first let each candidate\ndevice predict the qualities of both its training and reporting phases locally\nusing LSTM. Then, the proposed candidateselection algorithm is implemented by\nthe Deep Reinforcement Learning (DRL) framework. Finally, the real-world\ntrace-driven experiments prove that the proposed approach outperforms the\nexisting reactive algorithms\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 06:40:04 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:55:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Huang", "Huawei", ""], ["Lin", "Kangying", ""], ["Guo", "Song", ""], ["Zhou", "Pan", ""], ["Zheng", "Zibin", ""]]}, {"id": "2002.00582", "submitter": "Kelin Xia", "authors": "Zhenyu Meng, Kelin Xia", "title": "Persistent spectral based machine learning (PerSpect ML) for drug design", "comments": "17 pages; 8 Figures; 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose persistent spectral based machine learning\n(PerSpect ML) models for drug design. Persistent spectral models, including\npersistent spectral graph, persistent spectral simplicial complex and\npersistent spectral hypergraph, are proposed based on spectral graph theory,\nspectral simplicial complex theory and spectral hypergraph theory,\nrespectively. Different from all previous spectral models, a filtration\nprocess, as proposed in persistent homology, is introduced to generate\nmultiscale spectral models. More specifically, from the filtration process, a\nseries of nested topological representations, i,e., graphs, simplicial\ncomplexes, and hypergraphs, can be systematically generated and their spectral\ninformation can be obtained. Persistent spectral variables are defined as the\nfunction of spectral variables over the filtration value. Mathematically,\npersistent multiplicity (of zero eigenvalues) is exactly the persistent Betti\nnumber (or Betti curve). We consider 11 persistent spectral variables and use\nthem as the feature for machine learning models in protein-ligand binding\naffinity prediction. We systematically test our models on three most\ncommonly-used databases, including PDBbind-2007, PDBbind-2013 and PDBbind-2016.\nOur results, for all these databases, are better than all existing models, as\nfar as we know. This demonstrates the great power of our PerSpect ML in\nmolecular data analysis and drug design.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 07:14:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Meng", "Zhenyu", ""], ["Xia", "Kelin", ""]]}, {"id": "2002.00583", "submitter": "Fei Huang", "authors": "Fei Huang, Dazhen Wan, Zhihong Shao, Pei Ke, Jian Guan, Yilin Niu,\n  Xiaoyan Zhu, Minlie Huang", "title": "CoTK: An Open-Source Toolkit for Fast Development and Fair Evaluation of\n  Text Generation", "comments": "Submitting to ACL2020 demo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text generation evaluation, many practical issues, such as inconsistent\nexperimental settings and metric implementations, are often ignored but lead to\nunfair evaluation and untenable conclusions. We present CoTK, an open-source\ntoolkit aiming to support fast development and fair evaluation of text\ngeneration. In model development, CoTK helps handle the cumbersome issues, such\nas data processing, metric implementation, and reproduction. It standardizes\nthe development steps and reduces human errors which may lead to inconsistent\nexperimental settings. In model evaluation, CoTK provides implementation for\nmany commonly used metrics and benchmark models across different experimental\nsettings. As a unique feature, CoTK can signify when and which metric cannot be\nfairly compared. We demonstrate that it is convenient to use CoTK for model\ndevelopment and evaluation, particularly across different experimental\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 07:15:29 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Huang", "Fei", ""], ["Wan", "Dazhen", ""], ["Shao", "Zhihong", ""], ["Ke", "Pei", ""], ["Guan", "Jian", ""], ["Niu", "Yilin", ""], ["Zhu", "Xiaoyan", ""], ["Huang", "Minlie", ""]]}, {"id": "2002.00585", "submitter": "Eran Malach", "authors": "Eran Malach, Gilad Yehudai, Shai Shalev-Shwartz, Ohad Shamir", "title": "Proving the Lottery Ticket Hypothesis: Pruning is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis (Frankle and Carbin, 2018), states that a\nrandomly-initialized network contains a small subnetwork such that, when\ntrained in isolation, can compete with the performance of the original network.\nWe prove an even stronger hypothesis (as was also conjectured in Ramanujan et\nal., 2019), showing that for every bounded distribution and every target\nnetwork with bounded weights, a sufficiently over-parameterized neural network\nwith random weights contains a subnetwork with roughly the same accuracy as the\ntarget network, without any further training.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 07:23:11 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Malach", "Eran", ""], ["Yehudai", "Gilad", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "2002.00606", "submitter": "Jingwei Zhang", "authors": "Zihang Zhang, Jianping Gu", "title": "Facial Affect Recognition in the Wild Using Multi-Task Learning\n  Convolutional Network", "comments": "submitted to ABAW challenge in FG2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a neural network based method Multi-Task Affect\nNet(MTANet) submitted to the Affective Behavior Analysis in-the-Wild Challenge\nin FG2020. This method is a multi-task network and based on SE-ResNet modules.\nBy utilizing multi-task learning, this network can estimate and recognize three\nquantified affective models: valence and arousal, action units, and seven basic\nemotions simultaneously. MTANet achieve Concordance Correlation\nCoefficient(CCC) rates of 0.28 and 0.34 for valence and arousal, F1-score of\n0.427 and 0.32 for AUs detection and categorical emotion classification.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:02:26 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Zihang", ""], ["Gu", "Jianping", ""]]}, {"id": "2002.00614", "submitter": "B.S. Vivek", "authors": "B.S. Vivek, R. Venkatesh Babu", "title": "Regularizers for Single-step Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The progress in the last decade has enabled machine learning models to\nachieve impressive performance across a wide range of tasks in Computer Vision.\nHowever, a plethora of works have demonstrated the susceptibility of these\nmodels to adversarial samples. Adversarial training procedure has been proposed\nto defend against such adversarial attacks. Adversarial training methods\naugment mini-batches with adversarial samples, and typically single-step\n(non-iterative) methods are used for generating these adversarial samples.\nHowever, models trained using single-step adversarial training converge to\ndegenerative minima where the model merely appears to be robust. The pseudo\nrobustness of these models is due to the gradient masking effect. Although\nmulti-step adversarial training helps to learn robust models, they are hard to\nscale due to the use of iterative methods for generating adversarial samples.\nTo address these issues, we propose three different types of regularizers that\nhelp to learn robust models using single-step adversarial training methods. The\nproposed regularizers mitigate the effect of gradient masking by harnessing on\nproperties that differentiate a robust model from that of a pseudo robust\nmodel. Performance of models trained using the proposed regularizers is on par\nwith models trained using computationally expensive multi-step adversarial\ntraining methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:21:04 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Vivek", "B. S.", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2002.00625", "submitter": "Ahmed Rasheed", "authors": "Ahmed Rasheed, Muhammad Shahzad Younis, Muhammad Bilal, and Maha\n  Rasheed", "title": "Classification of Chest Diseases using Wavelet Transforms and Transfer\n  Learning", "comments": "8 pages, 4 figures, Presented in International Conference On Medical\n  Imaging And Computer-Aided Diagnosis (MICAD 2020), proceeding will be\n  published with Springer in their \"Lecture Notes in Electrical Engineering\n  (LNEE)\" (ISSN: 1876-1100)", "journal-ref": null, "doi": "10.1007/978-981-15-5199-4_16", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest X-ray scan is a most often used modality by radiologists to diagnose\nmany chest related diseases in their initial stages. The proposed system aids\nthe radiologists in making decision about the diseases found in the scans more\nefficiently. Our system combines the techniques of image processing for feature\nenhancement and deep learning for classification among diseases. We have used\nthe ChestX-ray14 database in order to train our deep learning model on the 14\ndifferent labeled diseases found in it. The proposed research shows the\nsignificant improvement in the results by using wavelet transforms as\npre-processing technique.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:44:23 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Rasheed", "Ahmed", ""], ["Younis", "Muhammad Shahzad", ""], ["Bilal", "Muhammad", ""], ["Rasheed", "Maha", ""]]}, {"id": "2002.00632", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder and Aldo Pacchiano and Krzysztof Choromanski and\n  Stephen Roberts", "title": "Effective Diversity in Population Based Reinforcement Learning", "comments": "Camera-ready version, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a key problem in reinforcement learning, since agents can only\nlearn from data they acquire in the environment. With that in mind, maintaining\na population of agents is an attractive method, as it allows data be collected\nwith a diverse set of behaviors. This behavioral diversity is often boosted via\nmulti-objective loss functions. However, those approaches typically leverage\nmean field updates based on pairwise distances, which makes them susceptible to\ncycling behaviors and increased redundancy. In addition, explicitly boosting\ndiversity often has a detrimental impact on optimizing already fruitful\nbehaviors for rewards. As such, the reward-diversity trade off typically relies\non heuristics. Finally, such methods require behavioral representations, often\nhandcrafted and domain specific. In this paper, we introduce an approach to\noptimize all members of a population simultaneously. Rather than using pairwise\ndistance, we measure the volume of the entire population in a behavioral\nmanifold, defined by task-agnostic behavioral embeddings. In addition, our\nalgorithm Diversity via Determinants (DvD), adapts the degree of diversity\nduring training using online learning techniques. We introduce both\nevolutionary and gradient-based instantiations of DvD and show they effectively\nimprove exploration without reducing performance when better exploration is not\nrequired.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 10:09:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 05:49:56 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 16:03:39 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Pacchiano", "Aldo", ""], ["Choromanski", "Krzysztof", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.00643", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Kate Lin, Emily Fertig, Sharad Vikram, Max Hinne,\n  Dave Moore, Marcel van Gerven", "title": "Automatic structured variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference offers an attractive option as a default\nmethod for differentiable probabilistic programming. However, the performance\nof the variational approach depends on the choice of an appropriate variational\nfamily. Here, we introduce automatic structured variational inference (ASVI), a\nfully automated method for constructing structured variational families,\ninspired by the closed-form update in conjugate Bayesian models. These\nconvex-update families incorporate the forward pass of the input probabilistic\nprogram and can therefore capture complex statistical dependencies.\nConvex-update families have the same space and time complexity as the input\nprobabilistic program and are therefore tractable for a very large family of\nmodels including both continuous and discrete variables. We validate our\nautomatic variational method on a wide range of low- and high-dimensional\ninference problems. We find that ASVI provides a clear improvement in\nperformance when compared with other popular approaches such as the mean-field\napproach and inverse autoregressive flows. We provide an open source\nimplementation of ASVI in TensorFlow Probability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 10:52:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 11:44:50 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 18:52:08 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Ambrogioni", "Luca", ""], ["Lin", "Kate", ""], ["Fertig", "Emily", ""], ["Vikram", "Sharad", ""], ["Hinne", "Max", ""], ["Moore", "Dave", ""], ["van Gerven", "Marcel", ""]]}, {"id": "2002.00655", "submitter": "Alexander Renz-Wieland", "authors": "Alexander Renz-Wieland, Rainer Gemulla, Steffen Zeuch, Volker Markl", "title": "Dynamic Parameter Allocation in Parameter Servers", "comments": null, "journal-ref": "PVLDB, 13(11): 1877-1890, 2020", "doi": "10.14778/3407790.3407796", "report-no": null, "categories": "cs.LG cs.DB cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To keep up with increasing dataset sizes and model complexity, distributed\ntraining has become a necessity for large machine learning tasks. Parameter\nservers ease the implementation of distributed parameter management---a key\nconcern in distributed training---, but can induce severe communication\noverhead. To reduce communication overhead, distributed machine learning\nalgorithms use techniques to increase parameter access locality (PAL),\nachieving up to linear speed-ups. We found that existing parameter servers\nprovide only limited support for PAL techniques, however, and therefore prevent\nefficient training. In this paper, we explore whether and to what extent PAL\ntechniques can be supported, and whether such support is beneficial. We propose\nto integrate dynamic parameter allocation into parameter servers, describe an\nefficient implementation of such a parameter server called Lapse, and\nexperimentally compare its performance to existing parameter servers across a\nnumber of machine learning tasks. We found that Lapse provides near-linear\nscaling and can be orders of magnitude faster than existing parameter servers.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:37:54 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 14:05:58 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 12:52:13 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Renz-Wieland", "Alexander", ""], ["Gemulla", "Rainer", ""], ["Zeuch", "Steffen", ""], ["Markl", "Volker", ""]]}, {"id": "2002.00658", "submitter": "Marine Le Morvan", "authors": "Marine Le Morvan (PARIETAL, IJCLab), Nicolas Prost (CMAP, XPOP), Julie\n  Josse (CMAP, XPOP), Erwan Scornet (CMAP), Ga\\\"el Varoquaux (PARIETAL, MILA)", "title": "Linear predictor on linearly-generated data with missing values: non\n  consistency and solutions", "comments": null, "journal-ref": "Proceedings of Machine Learning Research, PMLR, In press", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider building predictors when the data have missing values. We study\nthe seemingly-simple case where the target to predict is a linear function of\nthe fully-observed data and we show that, in the presence of missing values,\nthe optimal predictor may not be linear. In the particular Gaussian case, it\ncan be written as a linear function of multiway interactions between the\nobserved data and the various missing-value indicators. Due to its intrinsic\ncomplexity, we study a simple approximation and prove generalization bounds\nwith finite samples, highlighting regimes for which each method performs best.\nWe then show that multilayer perceptrons with ReLU activation functions can be\nconsistent, and can explore good trade-offs between the true model and\napproximations. Our study highlights the interesting family of models that are\nbeneficial to fit with missing values depending on the amount of data\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 11:49:35 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:48:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Morvan", "Marine Le", "", "PARIETAL, IJCLab"], ["Prost", "Nicolas", "", "CMAP, XPOP"], ["Josse", "Julie", "", "CMAP, XPOP"], ["Scornet", "Erwan", "", "CMAP"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, MILA"]]}, {"id": "2002.00695", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Besnik Fetahu, Eirini Ntoutsi", "title": "FAE: A Fairness-Aware Ensemble Framework", "comments": "6 pages", "journal-ref": "IEEE International Conference on Big Data, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated decision making based on big data and machine learning (ML)\nalgorithms can result in discriminatory decisions against certain protected\ngroups defined upon personal data like gender, race, sexual orientation etc.\nSuch algorithms designed to discover patterns in big data might not only pick\nup any encoded societal biases in the training data, but even worse, they might\nreinforce such biases resulting in more severe discrimination. The majority of\nthus far proposed fairness-aware machine learning approaches focus solely on\nthe pre-, in- or post-processing steps of the machine learning process, that\nis, input data, learning algorithms or derived models, respectively. However,\nthe fairness problem cannot be isolated to a single step of the ML process.\nRather, discrimination is often a result of complex interactions between big\ndata and algorithms, and therefore, a more holistic approach is required. The\nproposed FAE (Fairness-Aware Ensemble) framework combines fairness-related\ninterventions at both pre- and postprocessing steps of the data analysis\nprocess. In the preprocessing step, we tackle the problems of\nunder-representation of the protected group (group imbalance) and of\nclass-imbalance by generating balanced training samples. In the post-processing\nstep, we tackle the problem of class overlapping by shifting the decision\nboundary in the direction of fairness.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:05:18 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Fetahu", "Besnik", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "2002.00717", "submitter": "Xinze Zhang", "authors": "Xinze Zhang, Kun He, Yukun Bao", "title": "Error-feedback Stochastic Configuration Strategy on Convolutional Neural\n  Networks for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the superiority of convolutional neural networks demonstrated in time\nseries modeling and forecasting, it has not been fully explored on the design\nof the neural network architecture as well as the tuning of the\nhyper-parameters. Inspired by the iterative construction strategy for building\na random multilayer perceptron, we propose a novel Error-feedback Stochastic\nConfiguration (ESC) strategy to construct a random Convolutional Neural Network\n(ESC-CNN) for time series forecasting task, which builds the network\narchitecture adaptively. The ESC strategy suggests that random filters and\nneurons of the error-feedback fully connected layer are incrementally added in\na manner that they can steadily compensate the prediction error during the\nconstruction process, and a filter selection strategy is introduced to secure\nthat ESC-CNN holds the universal approximation property, providing helpful\ninformation at each iterative process for the prediction. The performance of\nESC-CNN is justified on its prediction accuracy for one-step-ahead and\nmulti-step-ahead forecasting tasks. Comprehensive experiments on a synthetic\ndataset and two real-world datasets show that the proposed ESC-CNN not only\noutperforms the state-of-art random neural networks, but also exhibits strong\npredictive power in comparison to trained Convolution Neural Networks and Long\nShort-Term Memory models, demonstrating the effectiveness of ESC-CNN in time\nseries forecasting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:30:29 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhang", "Xinze", ""], ["He", "Kun", ""], ["Bao", "Yukun", ""]]}, {"id": "2002.00721", "submitter": "Nikolai Zolotykh", "authors": "Evgeny Dolotov and Nikolai Zolotykh", "title": "Evolutionary algorithms for constructing an ensemble of decision trees", "comments": "7 pages, 2 tables AIST 2019, accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most decision tree induction algorithms are based on a greedy top-down\nrecursive partitioning strategy for tree growth. In this paper, we propose\nseveral methods for induction of decision trees and their ensembles based on\nevolutionary algorithms. The main difference of our approach is using\nreal-valued vector representation of decision tree that allows to use a large\nnumber of different optimization algorithms, as well as optimize the whole tree\nor ensemble for avoiding local optima. Differential evolution and evolution\nstrategies were chosen as optimization algorithms, as they have good results in\nreinforcement learning problems. We test the predictive performance of this\nmethods using several public UCI data sets, and the proposed methods show\nbetter quality than classical methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:38:50 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Dolotov", "Evgeny", ""], ["Zolotykh", "Nikolai", ""]]}, {"id": "2002.00727", "submitter": "Tomoki Yoshida", "authors": "Tomoki Yoshida, Ichiro Takeuchi, Masayuki Karasuyama", "title": "Distance Metric Learning for Graph Structured Data", "comments": "38 pages, 11 figures. This is a pre-print of an article published in\n  Machine Learning Journal. The final authenticated version is available online\n  at: https://doi.org/10.1007/s10994-021-06009-3", "journal-ref": null, "doi": "10.1007/s10994-021-06009-3", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are versatile tools for representing structured data. As a result, a\nvariety of machine learning methods have been studied for graph data analysis.\nAlthough many such learning methods depend on the measurement of differences\nbetween input graphs, defining an appropriate distance metric for graphs\nremains a controversial issue. Hence, we propose a supervised distance metric\nlearning method for the graph classification problem. Our method, named\ninterpretable graph metric learning (IGML), learns discriminative metrics in a\nsubgraph-based feature space, which has a strong graph representation\ncapability. By introducing a sparsity-inducing penalty on the weight of each\nsubgraph, IGML can identify a small number of important subgraphs that can\nprovide insight into the given classification task. Because our formulation has\na large number of optimization variables, an efficient algorithm that uses\npruning techniques based on safe screening and working set selection methods is\nalso proposed. An important property of IGML is that solution optimality is\nguaranteed because the problem is formulated as a convex problem and our\npruning strategies only discard unnecessary subgraphs. Furthermore, we show\nthat IGML is also applicable to other structured data such as itemset and\nsequence data, and that it can incorporate vertex-label similarity by using a\ntransportation-based subgraph feature. We empirically evaluate the\ncomputational efficiency and classification performance of IGML on several\nbenchmark datasets and provide some illustrative examples of how IGML\nidentifies important subgraphs from a given graph dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:42:43 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 06:22:00 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Yoshida", "Tomoki", ""], ["Takeuchi", "Ichiro", ""], ["Karasuyama", "Masayuki", ""]]}, {"id": "2002.00733", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi, George Han, Celine Liang", "title": "Generation-Distillation for Efficient Natural Language Understanding in\n  Low-Data Settings", "comments": "EMNLP 2019 Workshop on Deep Learning for Low-resource NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past year, the emergence of transfer learning with large-scale\nlanguage models (LM) has led to dramatic performance improvements across a\nbroad range of natural language understanding tasks. However, the size and\nmemory footprint of these large LMs makes them difficult to deploy in many\nscenarios (e.g. on mobile phones). Recent research points to knowledge\ndistillation as a potential solution, showing that when training data for a\ngiven task is abundant, it is possible to distill a large (teacher) LM into a\nsmall task-specific (student) network with minimal loss of performance.\nHowever, when such data is scarce, there remains a significant performance gap\nbetween large pretrained LMs and smaller task-specific models, even when\ntraining via distillation. In this paper, we bridge this gap with a novel\ntraining approach, called generation-distillation, that leverages large\nfinetuned LMs in two ways: (1) to generate new (unlabeled) training examples,\nand (2) to distill their knowledge into a small network using these examples.\nAcross three low-resource text classification datsets, we achieve comparable\nperformance to BERT while using 300x fewer parameters, and we outperform prior\napproaches to distillation for text classification while using 3x fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 08:20:46 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Han", "George", ""], ["Liang", "Celine", ""]]}, {"id": "2002.00737", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Jihun Choi, Daniel Edmiston, and Sang-goo Lee", "title": "Are Pre-trained Language Models Aware of Phrases? Simple but Strong\n  Baselines for Grammar Induction", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success and popularity of pre-trained language models (LMs)\nin natural language processing, there has been a rise in efforts to understand\ntheir inner workings. In line with such interest, we propose a novel method\nthat assists us in investigating the extent to which pre-trained LMs capture\nthe syntactic notion of constituency. Our method provides an effective way of\nextracting constituency trees from the pre-trained LMs without training. In\naddition, we report intriguing findings in the induced trees, including the\nfact that pre-trained LMs outperform other approaches in correctly demarcating\nadverb phrases in sentences.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:06:49 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kim", "Taeuk", ""], ["Choi", "Jihun", ""], ["Edmiston", "Daniel", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2002.00741", "submitter": "Jibang Wu", "authors": "Jibang Wu, Renqin Cai, Hongning Wang", "title": "D\\'ej\\`a vu: A Contextualized Temporal Attention Mechanism for\n  Sequential Recommendation", "comments": "Key Words: Sequential Recommendation, Self-attention mechanism,\n  Temporal Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting users' preferences based on their sequential behaviors in history\nis challenging and crucial for modern recommender systems. Most existing\nsequential recommendation algorithms focus on transitional structure among the\nsequential actions, but largely ignore the temporal and context information,\nwhen modeling the influence of a historical event to current prediction.\n  In this paper, we argue that the influence from the past events on a user's\ncurrent action should vary over the course of time and under different context.\nThus, we propose a Contextualized Temporal Attention Mechanism that learns to\nweigh historical actions' influence on not only what action it is, but also\nwhen and how the action took place. More specifically, to dynamically calibrate\nthe relative input dependence from the self-attention mechanism, we deploy\nmultiple parameterized kernel functions to learn various temporal dynamics, and\nthen use the context information to determine which of these reweighing kernels\nto follow for each input. In empirical evaluations on two large public\nrecommendation datasets, our model consistently outperformed an extensive set\nof state-of-the-art sequential recommendation methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:27:42 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wu", "Jibang", ""], ["Cai", "Renqin", ""], ["Wang", "Hongning", ""]]}, {"id": "2002.00743", "submitter": "Kshitij Jain", "authors": "Xin Lian, Kshitij Jain, Jakub Truszkowski, Pascal Poupart, and\n  Yaoliang Yu", "title": "Unsupervised Multilingual Alignment using Wasserstein Barycenter", "comments": "Code is available at https://github.com/alixxxin/multi-lang", "journal-ref": "Proceedings of International Joint Conference on Artificial\n  Intelligence (IJCAI), 2020", "doi": "10.24963/ijcai.2020/512", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study unsupervised multilingual alignment, the problem of finding\nword-to-word translations between multiple languages without using any parallel\ndata. One popular strategy is to reduce multilingual alignment to the much\nsimplified bilingual setting, by picking one of the input languages as the\npivot language that we transit through. However, it is well-known that\ntransiting through a poorly chosen pivot language (such as English) may\nseverely degrade the translation quality, since the assumed transitive\nrelations among all pairs of languages may not be enforced in the training\nprocess. Instead of going through a rather arbitrarily chosen pivot language,\nwe propose to use the Wasserstein barycenter as a more informative \"mean\"\nlanguage: it encapsulates information from all languages and minimizes all\npairwise transportation costs. We evaluate our method on standard benchmarks\nand demonstrate state-of-the-art performances.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 23:42:33 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Lian", "Xin", ""], ["Jain", "Kshitij", ""], ["Truszkowski", "Jakub", ""], ["Poupart", "Pascal", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2002.00744", "submitter": "Shoubin Li", "authors": "Shoubin Li, Wenzao Cui, Yujiang Liu, Xuran Ming, Jun Hu, YuanzheHu,\n  Qing Wang", "title": "PEL-BERT: A Joint Model for Protocol Entity Linking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained models such as BERT are widely used in NLP tasks and are\nfine-tuned to improve the performance of various NLP tasks consistently.\nNevertheless, the fine-tuned BERT model trained on our protocol corpus still\nhas a weak performance on the Entity Linking (EL) task. In this paper, we\npropose a model that joints a fine-tuned language model with an RFC Domain\nModel. Firstly, we design a Protocol Knowledge Base as the guideline for\nprotocol EL. Secondly, we propose a novel model, PEL-BERT, to link named\nentities in protocols to categories in Protocol Knowledge Base. Finally, we\nconduct a comprehensive study on the performance of pre-trained language models\non descriptive texts and abstract concepts. Experimental results demonstrate\nthat our model achieves state-of-the-art performance in EL on our annotated\ndataset, outperforming all the baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:42:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Li", "Shoubin", ""], ["Cui", "Wenzao", ""], ["Liu", "Yujiang", ""], ["Ming", "Xuran", ""], ["Hu", "Jun", ""], ["YuanzheHu", "", ""], ["Wang", "Qing", ""]]}, {"id": "2002.00745", "submitter": "Zihao Wang", "authors": "Zihao Wang, Yong Zhang, Hao Wu", "title": "Structural-Aware Sentence Similarity with Recursive Optimal Transport", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Measuring sentence similarity is a classic topic in natural language\nprocessing. Light-weighted similarities are still of particular practical\nsignificance even when deep learning models have succeeded in many other tasks.\nSome light-weighted similarities with more theoretical insights have been\ndemonstrated to be even stronger than supervised deep learning approaches.\nHowever, the successful light-weighted models such as Word Mover's Distance\n[Kusner et al., 2015] or Smooth Inverse Frequency [Arora et al., 2017] failed\nto detect the difference from the structure of sentences, i.e. order of words.\nTo address this issue, we present Recursive Optimal Transport (ROT) framework\nto incorporate the structural information with the classic OT. Moreover, we\nfurther develop Recursive Optimal Similarity (ROTS) for sentences with the\nvaluable semantic insights from the connections between cosine similarity of\nweighted average of word vectors and optimal transport. ROTS is\nstructural-aware and with low time complexity compared to optimal transport.\nOur experiments over 20 sentence textural similarity (STS) datasets show the\nclear advantage of ROTS over all weakly supervised approaches. Detailed\nablation study demonstrate the effectiveness of ROT and the semantic insights.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 09:07:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wang", "Zihao", ""], ["Zhang", "Yong", ""], ["Wu", "Hao", ""]]}, {"id": "2002.00748", "submitter": "Bang Liu", "authors": "Bang Liu, Haojie Wei, Di Niu, Haolan Chen, Yancheng He", "title": "Asking Questions the Human Way: Scalable Question-Answer Generation from\n  Text Corpus", "comments": "Accepted by The Web Conference 2020 (WWW 2020) as full paper (oral\n  presentation)", "journal-ref": null, "doi": "10.1145/3366423.3380270", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to ask questions is important in both human and machine\nintelligence. Learning to ask questions helps knowledge acquisition, improves\nquestion-answering and machine reading comprehension tasks, and helps a chatbot\nto keep the conversation flowing with a human. Existing question generation\nmodels are ineffective at generating a large amount of high-quality\nquestion-answer pairs from unstructured text, since given an answer and an\ninput passage, question generation is inherently a one-to-many mapping. In this\npaper, we propose Answer-Clue-Style-aware Question Generation (ACS-QG), which\naims at automatically generating high-quality and diverse question-answer pairs\nfrom unlabeled text corpus at scale by imitating the way a human asks\nquestions. Our system consists of: i) an information extractor, which samples\nfrom the text multiple types of assistive information to guide question\ngeneration; ii) neural question generators, which generate diverse and\ncontrollable questions, leveraging the extracted assistive information; and\niii) a neural quality controller, which removes low-quality generated data\nbased on text entailment. We compare our question generation models with\nexisting approaches and resort to voluntary human evaluation to assess the\nquality of the generated question-answer pairs. The evaluation results suggest\nthat our system dramatically outperforms state-of-the-art neural question\ngeneration models in terms of the generation quality, while being scalable in\nthe meantime. With models trained on a relatively smaller amount of data, we\ncan generate 2.8 million quality-assured question-answer pairs from a million\nsentences found in Wikipedia.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 05:27:09 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 01:06:21 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Liu", "Bang", ""], ["Wei", "Haojie", ""], ["Niu", "Di", ""], ["Chen", "Haolan", ""], ["He", "Yancheng", ""]]}, {"id": "2002.00750", "submitter": "Chandra Khatri", "authors": "Yue Weng, Sai Sumanth Miryala, Chandra Khatri, Runze Wang, Huaixiu\n  Zheng, Piero Molino, Mahdi Namazifar, Alexandros Papangelis, Hugh Williams,\n  Franziska Bell, Gokhan Tur", "title": "Joint Contextual Modeling for ASR Correction and Language Understanding", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of automatic speech recognition (ASR) is critical to Dialogue\nSystems as ASR errors propagate to and directly impact downstream tasks such as\nlanguage understanding (LU). In this paper, we propose multi-task neural\napproaches to perform contextual language correction on ASR outputs jointly\nwith LU to improve the performance of both tasks simultaneously. To measure the\neffectiveness of this approach we used a public benchmark, the 2nd Dialogue\nState Tracking (DSTC2) corpus. As a baseline approach, we trained task-specific\nStatistical Language Models (SLM) and fine-tuned state-of-the-art Generalized\nPre-training (GPT) Language Model to re-rank the n-best ASR hypotheses,\nfollowed by a model to identify the dialog act and slots. i) We further trained\nranker models using GPT and Hierarchical CNN-RNN models with discriminatory\nlosses to detect the best output given n-best hypotheses. We extended these\nranker models to first select the best ASR output and then identify the\ndialogue act and slots in an end to end fashion. ii) We also proposed a novel\njoint ASR error correction and LU model, a word confusion pointer network\n(WCN-Ptr) with multi-head self-attention on top, which consumes the word\nconfusions populated from the n-best. We show that the error rates of off the\nshelf ASR and following LU systems can be reduced significantly by 14% relative\nwith joint models trained using small amounts of in-domain data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:09:25 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Weng", "Yue", ""], ["Miryala", "Sai Sumanth", ""], ["Khatri", "Chandra", ""], ["Wang", "Runze", ""], ["Zheng", "Huaixiu", ""], ["Molino", "Piero", ""], ["Namazifar", "Mahdi", ""], ["Papangelis", "Alexandros", ""], ["Williams", "Hugh", ""], ["Bell", "Franziska", ""], ["Tur", "Gokhan", ""]]}, {"id": "2002.00751", "submitter": "Johannes Hofmanninger", "authors": "Johannes Hofmanninger, Sebastian Roehrich, Helmut Prosch and Georg\n  Langs", "title": "Separation of target anatomical structure and occlusions in chest\n  radiographs", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiographs are commonly performed low-cost exams for screening and\ndiagnosis. However, radiographs are 2D representations of 3D structures causing\nconsiderable clutter impeding visual inspection and automated image analysis.\nHere, we propose a Fully Convolutional Network to suppress, for a specific\ntask, undesired visual structure from radiographs while retaining the relevant\nimage information such as lung-parenchyma. The proposed algorithm creates\nreconstructed radiographs and ground-truth data from high resolution CT-scans.\nResults show that removing visual variation that is irrelevant for a\nclassification task improves the performance of a classifier when only limited\ntraining data are available. This is particularly relevant because a low number\nof ground-truth cases is common in medical imaging.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:01:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hofmanninger", "Johannes", ""], ["Roehrich", "Sebastian", ""], ["Prosch", "Helmut", ""], ["Langs", "Georg", ""]]}, {"id": "2002.00758", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Nariman Farsad, Yonina C. Eldar, and Andrea J.\n  Goldsmith", "title": "Data-Driven Factor Graphs for Deep Symbol Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important schemes in signal processing and communications, ranging from\nthe BCJR algorithm to the Kalman filter, are instances of factor graph methods.\nThis family of algorithms is based on recursive message passing-based\ncomputations carried out over graphical models, representing a factorization of\nthe underlying statistics. Consequently, in order to implement these\nalgorithms, one must have accurate knowledge of the statistical model of the\nconsidered signals. In this work we propose to implement factor graph methods\nin a data-driven manner. In particular, we propose to use machine learning (ML)\ntools to learn the factor graph, instead of the overall system task, which in\nturn is used for inference by message passing over the learned graph. We apply\nthe proposed approach to learn the factor graph representing a finite-memory\nchannel, demonstrating the resulting ability to implement BCJR detection in a\ndata-driven fashion. We demonstrate that the proposed system, referred to as\nBCJRNet, learns to implement the BCJR algorithm from a small training set, and\nthat the resulting receiver exhibits improved robustness to inaccurate training\ncompared to the conventional channel-model-based receiver operating under the\nsame level of uncertainty. Our results indicate that by utilizing ML tools to\nlearn factor graphs from labeled data, one can implement a broad range of\nmodel-based algorithms, which traditionally require full knowledge of the\nunderlying statistics, in a data-driven fashion.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:23:52 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Shlezinger", "Nir", ""], ["Farsad", "Nariman", ""], ["Eldar", "Yonina C.", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "2002.00761", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Francisco Guzm\\'an", "title": "Massively Multilingual Document Alignment with Cross-lingual\n  Sentence-Mover's Distance", "comments": "In Proceedings of AACL-IJCNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document alignment aims to identify pairs of documents in two distinct\nlanguages that are of comparable content or translations of each other. Such\naligned data can be used for a variety of NLP tasks from training cross-lingual\nrepresentations to mining parallel data for machine translation. In this paper\nwe develop an unsupervised scoring function that leverages cross-lingual\nsentence embeddings to compute the semantic distance between documents in\ndifferent languages. These semantic distances are then used to guide a document\nalignment algorithm to properly pair cross-lingual web documents across a\nvariety of low, mid, and high-resource language pairs. Recognizing that our\nproposed scoring function and other state of the art methods are\ncomputationally intractable for long web documents, we utilize a more tractable\ngreedy algorithm that performs comparably. We experimentally demonstrate that\nour distance metric performs better alignment than current baselines\noutperforming them by 7% on high-resource language pairs, 15% on mid-resource\nlanguage pairs, and 22% on low-resource language pairs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:14:16 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 05:26:32 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Guzm\u00e1n", "Francisco", ""]]}, {"id": "2002.00763", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Uboho Victor, and Lijun Qian", "title": "Two-path Deep Semi-supervised Learning for Timely Fake News Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 02:28:35 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Dong", "Xishuang", ""], ["Victor", "Uboho", ""], ["Qian", "Lijun", ""]]}, {"id": "2002.00768", "submitter": "Vaishali Pal", "authors": "Vaishali Pal, Fabien Guillot, Manish Shrivastava, Jean-Michel Renders,\n  Laurent Besacier", "title": "Modeling ASR Ambiguity for Dialogue State Tracking Using Word Confusion\n  Networks", "comments": "Accepted at Interspeech-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Spoken dialogue systems typically use a list of top-N ASR hypotheses for\ninferring the semantic meaning and tracking the state of the dialogue. However\nASR graphs, such as confusion networks (confnets), provide a compact\nrepresentation of a richer hypothesis space than a top-N ASR list. In this\npaper, we study the benefits of using confusion networks with a\nstate-of-the-art neural dialogue state tracker (DST). We encode the\n2-dimensional confnet into a 1-dimensional sequence of embeddings using an\nattentional confusion network encoder which can be used with any DST system.\nOur confnet encoder is plugged into the state-of-the-art 'Global-locally\nSelf-Attentive Dialogue State Tacker' (GLAD) model for DST and obtains\nsignificant improvements in both accuracy and inference time compared to using\ntop-N ASR hypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:11:48 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 18:40:00 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Pal", "Vaishali", ""], ["Guillot", "Fabien", ""], ["Shrivastava", "Manish", ""], ["Renders", "Jean-Michel", ""], ["Besacier", "Laurent", ""]]}, {"id": "2002.00779", "submitter": "Erixhen Sula", "authors": "Michael Gastpar and Erixhen Sula", "title": "Common Information Components Analysis", "comments": "5 pages, 1 figure. Presented at the 2020 Information Theory and\n  Applications (ITA) Workshop, San Diego, CA, USA, February 2-7, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an information-theoretic interpretation of Canonical Correlation\nAnalysis (CCA) via (relaxed) Wyner's common information. CCA permits to extract\nfrom two high-dimensional data sets low-dimensional descriptions (features)\nthat capture the commonalities between the data sets, using a framework of\ncorrelations and linear transforms. Our interpretation first extracts the\ncommon information up to a pre-selected resolution level, and then projects\nthis back onto each of the data sets. In the case of Gaussian statistics, this\nprocedure precisely reduces to CCA, where the resolution level specifies the\nnumber of CCA components that are extracted. This also suggests a novel\nalgorithm, Common Information Components Analysis (CICA), with several\ndesirable features, including a natural extension to beyond just two data sets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:31:27 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 10:17:24 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 10:35:53 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Gastpar", "Michael", ""], ["Sula", "Erixhen", ""]]}, {"id": "2002.00784", "submitter": "Craig Innes", "authors": "Craig Innes, Subramanian Ramamoorthy", "title": "Elaborating on Learned Demonstrations with Temporal Logic Specifications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current methods for learning from demonstrations assume that those\ndemonstrations alone are sufficient to learn the underlying task. This is often\nuntrue, especially if extra safety specifications exist which were not present\nin the original demonstrations. In this paper, we allow an expert to elaborate\non their original demonstration with additional specification information using\nlinear temporal logic (LTL). Our system converts LTL specifications into a\ndifferentiable loss. This loss is then used to learn a dynamic movement\nprimitive that satisfies the underlying specification, while remaining close to\nthe original demonstration. Further, by leveraging adversarial training, our\nsystem learns to robustly satisfy the given LTL specification on unseen inputs,\nnot just those seen in training. We show that our method is expressive enough\nto work across a variety of common movement specification patterns such as\nobstacle avoidance, patrolling, keeping steady, and speed limitation. In\naddition, we show that our system can modify a base demonstration with complex\nspecifications by incrementally composing multiple simpler specifications. We\nalso implement our system on a PR-2 robot to show how a demonstrator can start\nwith an initial (sub-optimal) demonstration, then interactively improve task\nsuccess by including additional specifications enforced with our differentiable\nLTL loss.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:33:38 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 19:53:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Innes", "Craig", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2002.00790", "submitter": "Joseph Bakarji", "authors": "Joseph Bakarji, Daniel M. Tartakovsky", "title": "Data-Driven Discovery of Coarse-Grained Equations", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2021.110219", "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical (machine learning) tools for equation discovery require large\namounts of data that are typically computer generated rather than\nexperimentally observed. Multiscale modeling and stochastic simulations are two\nareas where learning on simulated data can lead to such discovery. In both, the\ndata are generated with a reliable but impractical model, e.g., molecular\ndynamics simulations, while a model on the scale of interest is uncertain,\nrequiring phenomenological constitutive relations and ad-hoc approximations. We\nreplace the human discovery of such models, which typically involves\nspatial/stochastic averaging or coarse-graining, with a machine-learning\nstrategy based on sparse regression that can be executed in two modes. The\nfirst, direct equation-learning, discovers a differential operator from the\nwhole dictionary. The second, constrained equation-learning, discovers only\nthose terms in the differential operator that need to be discovered, i.e.,\nlearns closure approximations. We illustrate our approach by learning a\ndeterministic equation that governs the spatiotemporal evolution of the\nprobability density function of a system state whose dynamics are described by\na nonlinear partial differential equation with random inputs. A series of\nexamples demonstrates the accuracy, robustness, and limitations of our approach\nto equation discovery.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 23:41:37 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 22:31:41 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 20:40:05 GMT"}, {"version": "v4", "created": "Sat, 23 May 2020 00:32:44 GMT"}, {"version": "v5", "created": "Mon, 27 Jul 2020 16:57:59 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Bakarji", "Joseph", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2002.00792", "submitter": "Siddhartha Srivastava", "authors": "Siddhartha Srivastava, Veera Sundararaghavan", "title": "Machine learning in quantum computers via general Boltzmann Machines:\n  Generative and Discriminative training through annealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Hybrid-Quantum-classical method for learning Boltzmann machines\n(BM) for generative and discriminative tasks. Boltzmann machines are undirected\ngraphs that form the building block of many learning architectures such as\nRestricted Boltzmann machines (RBM's) and Deep Boltzmann machines (DBM's). They\nhave a network of visible and hidden nodes where the former are used as the\nreading sites while the latter are used to manipulate the probability of the\nvisible states. BM's are versatile machines that can be used for both learning\ndistributions as a generative task as well as for performing classification or\nfunction approximation as a discriminative task. We show that minimizing\nKL-divergence works best for training BM for applications of function\napproximation. In our approach, we use Quantum annealers for sampling Boltzmann\nstates. These states are used to approximate gradients in a stochastic gradient\ndescent scheme. The approach is used to demonstrate logic circuits in the\ndiscriminative sense and a specialized two-phase distribution using generative\nBM.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:41:52 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 22:48:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Srivastava", "Siddhartha", ""], ["Sundararaghavan", "Veera", ""]]}, {"id": "2002.00793", "submitter": "Junning Deng", "authors": "Junning Deng, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "Explainable Subgraphs with Surprising Densities: A Subgroup Discovery\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectivity structure of graphs is typically related to the attributes\nof the nodes. In social networks for example, the probability of a friendship\nbetween two people depends on their attributes, such as their age, address, and\nhobbies. The connectivity of a graph can thus possibly be understood in terms\nof patterns of the form 'the subgroup of individuals with properties X are\noften (or rarely) friends with individuals in another subgroup with properties\nY'. Such rules present potentially actionable and generalizable insights into\nthe graph. We present a method that finds pairs of node subgroups between which\nthe edge density is interestingly high or low, using an information-theoretic\ndefinition of interestingness. This interestingness is quantified subjectively,\nto contrast with prior information an analyst may have about the graph. This\nview immediately enables iterative mining of such patterns. Our work\ngeneralizes prior work on dense subgraph mining (i.e. subgraphs induced by a\nsingle subgroup). Moreover, not only is the proposed method more general, we\nalso demonstrate considerable practical advantages for the single subgroup\nspecial case.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 14:25:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Deng", "Junning", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.00797", "submitter": "Eliza O'Reilly", "authors": "Eliza O'Reilly and Ngoc Tran", "title": "Stochastic geometry to generalize the Mondrian Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mondrian process is a stochastic process that produces a recursive\npartition of space with random axis-aligned cuts. Random forests and Laplace\nkernel approximations built from the Mondrian process have led to efficient\nonline learning methods and Bayesian optimization. By viewing the Mondrian\nprocess as a special case of the stable under iterated tessellation (STIT)\nprocess, we utilize tools from stochastic geometry to resolve some fundamental\nquestions concerning the Mondrian process in machine learning. First, we show\nthat the Mondrian process with general cut directions can be efficiently\nsimulated by lifting to a higher dimensional axis-aligned Mondrian process.\nSecond, we characterize all possible kernels that generalizations of the\nMondrian process can approximate with fixed parameters as well as additional\nkernels obtained from mixtures of STIT processes. This includes, for instance,\nvarious forms of the weighted Laplace kernel and the exponential kernel.\nLastly, we give an explicit formula for the density estimator arising from a\nMondrian forest. This allows for precise comparisons between the Mondrian\nforest, the Mondrian kernel and the Laplace kernel in density estimation. Our\npaper calls for further developments at the novel intersection of stochastic\ngeometry and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:47:26 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:47:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["O'Reilly", "Eliza", ""], ["Tran", "Ngoc", ""]]}, {"id": "2002.00815", "submitter": "Sebastian Mathias Keller", "authors": "Sebastian Mathias Keller, Maxim Samarin, Fabricio Arend Torres, Mario\n  Wieser, Volker Roth", "title": "Learning Extremal Representations with Deep Archetypal Analysis", "comments": "Under review for publication at the International Journal of Computer\n  Vision (IJCV). Extended version of our GCPR2019 paper \"Deep Archetypal\n  Analysis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Archetypes are typical population representatives in an extremal sense, where\ntypicality is understood as the most extreme manifestation of a trait or\nfeature. In linear feature space, archetypes approximate the data convex hull\nallowing all data points to be expressed as convex mixtures of archetypes.\nHowever, it might not always be possible to identify meaningful archetypes in a\ngiven feature space. Learning an appropriate feature space and identifying\nsuitable archetypes simultaneously addresses this problem. This paper\nintroduces a generative formulation of the linear archetype model,\nparameterized by neural networks. By introducing the distance-dependent\narchetype loss, the linear archetype model can be integrated into the latent\nspace of a variational autoencoder, and an optimal representation with respect\nto the unknown archetypes can be learned end-to-end. The reformulation of\nlinear Archetypal Analysis as deep variational information bottleneck, allows\nthe incorporation of arbitrarily complex side information during training.\nFurthermore, an alternative prior, based on a modified Dirichlet distribution,\nis proposed. The real-world applicability of the proposed method is\ndemonstrated by exploring archetypes of female facial expressions while using\nmulti-rater based emotion scores of these expressions as side information. A\nsecond application illustrates the exploration of the chemical space of small\norganic molecules. In this experiment, it is demonstrated that exchanging the\nside information but keeping the same set of molecules, e. g. using as side\ninformation the heat capacity of each molecule instead of the band gap energy,\nwill result in the identification of different archetypes. As an application,\nthese learned representations of chemical space might reveal distinct starting\npoints for de novo molecular design.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:13:49 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Keller", "Sebastian Mathias", ""], ["Samarin", "Maxim", ""], ["Torres", "Fabricio Arend", ""], ["Wieser", "Mario", ""], ["Roth", "Volker", ""]]}, {"id": "2002.00818", "submitter": "Markus Lange-Hegermann", "authors": "Markus Lange-Hegermann", "title": "Linearly Constrained Gaussian Processes with Boundary Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SC math.AC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One goal in Bayesian machine learning is to encode prior knowledge into prior\ndistributions, to model data efficiently. We consider prior knowledge from\nsystems of linear partial differential equations together with their boundary\nconditions. We construct multi-output Gaussian process priors with realizations\nin the solution set of such systems, in particular only such solutions can be\nrepresented by Gaussian process regression. The construction is fully\nalgorithmic via Gr\\\"obner bases and it does not employ any approximation. It\nbuilds these priors combining two parametrizations via a pullback: the first\nparametrizes the solutions for the system of differential equations and the\nsecond parametrizes all functions adhering to the boundary conditions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:19:03 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 14:24:03 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 11:34:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Lange-Hegermann", "Markus", ""]]}, {"id": "2002.00819", "submitter": "Donatella Firmani", "authors": "Andrea Rossi, Donatella Firmani, Antonio Matinata, Paolo Merialdo,\n  Denilson Barbosa", "title": "Knowledge Graph Embedding for Link Prediction: A Comparative Analysis", "comments": "Andrea Rossi, Donatella Firmani, Antonio Matinata, Paolo Merialdo,\n  Denilson Barbosa. 2020. Knowledge Graph Embedding for Link Prediction: A\n  Comparative Analysis. In ACM Transactions on Knowledge Discovery from Data.\n  January 2021. (TKDD 2021). ACM, New York, NY, USA", "journal-ref": null, "doi": "10.1145/3424672", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Graphs (KGs) have found many applications in industry and academic\nsettings, which in turn, have motivated considerable research efforts towards\nlarge-scale information extraction from a variety of sources. Despite such\nefforts, it is well known that even state-of-the-art KGs suffer from\nincompleteness. Link Prediction (LP), the task of predicting missing facts\namong entities already a KG, is a promising and widely studied task aimed at\naddressing KG incompleteness. Among the recent LP techniques, those based on KG\nembeddings have achieved very promising performances in some benchmarks.\nDespite the fast growing literature in the subject, insufficient attention has\nbeen paid to the effect of the various design choices in those methods.\nMoreover, the standard practice in this area is to report accuracy by\naggregating over a large number of test facts in which some entities are\nover-represented; this allows LP methods to exhibit good performance by just\nattending to structural properties that include such entities, while ignoring\nthe remaining majority of the KG. This analysis provides a comprehensive\ncomparison of embedding-based LP methods, extending the dimensions of analysis\nbeyond what is commonly available in the literature. We experimentally compare\neffectiveness and efficiency of 16 state-of-the-art methods, consider a\nrule-based baseline, and report detailed analysis over the most popular\nbenchmarks in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:21:25 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 09:32:38 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 22:13:48 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 21:15:36 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Rossi", "Andrea", ""], ["Firmani", "Donatella", ""], ["Matinata", "Antonio", ""], ["Merialdo", "Paolo", ""], ["Barbosa", "Denilson", ""]]}, {"id": "2002.00833", "submitter": "Steven Thompson Mr", "authors": "Steven Thompson, Paul Fergus, Carl Chalmers, and Denis Reilly", "title": "Detection of Obstructive Sleep Apnoea Using Features Extracted from\n  Segmented Time-Series ECG Signals Using a One Dimensional Convolutional\n  Neural Network", "comments": "8 pages, 6 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study in this paper presents a one-dimensional convolutional neural\nnetwork (1DCNN) model, designed for the automated detection of obstructive\nSleep Apnoea (OSA) captured from single-channel electrocardiogram (ECG)\nsignals. The system provides mechanisms in clinical practice that help diagnose\npatients suffering with OSA. Using the state-of-the-art in 1DCNNs, a model is\nconstructed using convolutional, max pooling layers and a fully connected\nMultilayer Perceptron (MLP) consisting of a hidden layer and SoftMax output for\nclassification. The 1DCNN extracts prominent features, which are used to train\nan MLP. The model is trained using segmented ECG signals grouped into 5 unique\ndatasets of set window sizes. 35 ECG signal recordings were selected from an\nannotated database containing 70 night-time ECG recordings. (Group A = a01 to\na20 (Apnoea breathing), Group B = b01 to b05 (moderate), and Group C = c01 to\nc10 (normal). A total of 6514 minutes of Apnoea was recorded. Evaluation of the\nmodel is performed using a set of standard metrics which show the proposed\nmodel achieves high classification results in both training and validation\nusing our windowing strategy, particularly W=500 (Sensitivity 0.9705,\nSpecificity 0.9725, F1 Score 0.9717, Kappa Score 0.9430, Log Loss 0.0836,\nROCAUC 0.9945). This demonstrates the model can identify the presence of Apnoea\nwith a high degree of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:47:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Thompson", "Steven", ""], ["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Reilly", "Denis", ""]]}, {"id": "2002.00837", "submitter": "Enyan Dai", "authors": "Enyan Dai, Yiwei Sun, Suhang Wang", "title": "Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:27:58 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 06:08:08 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Dai", "Enyan", ""], ["Sun", "Yiwei", ""], ["Wang", "Suhang", ""]]}, {"id": "2002.00838", "submitter": "Bo Ni", "authors": "Bo Ni, Zhichun Guo, Jianing Li, Meng Jiang", "title": "Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 00:44:59 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Ni", "Bo", ""], ["Guo", "Zhichun", ""], ["Li", "Jianing", ""], ["Jiang", "Meng", ""]]}, {"id": "2002.00839", "submitter": "Xiao Guo", "authors": "Hai Zhang and Xiao Guo and Xiangyu Chang", "title": "Randomized Spectral Clustering in Large-Scale Stochastic Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering has been one of the widely used methods for community\ndetection in networks. However, large-scale networks bring computational\nchallenge to it. In this paper, we study spectral clustering using randomized\nsketching algorithms from a statistical perspective, where we typically assume\nthe network data are generated from a stochastic block model. To do this, we\nfirst use the recent developed sketching algorithms to derive two randomized\nspectral clustering algorithms, namely, the random projection-based and the\nrandom sampling-based spectral clustering. Then we study the theoretical bounds\nof the resulting algorithms in terms of the approximation error for the\npopulation adjacency matrix, the misclustering error, and the estimation error\nfor the link probability matrix. It turns out that, under mild conditions, the\nrandomized spectral clustering algorithms perform similarly to the original\none. We also conduct numerical experiments to support the theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:15:25 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:59:32 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Hai", ""], ["Guo", "Xiao", ""], ["Chang", "Xiangyu", ""]]}, {"id": "2002.00841", "submitter": "Carl Yang", "authors": "Carl Yang, Mengxiong Liu, Frank He, Jian Peng, Jiawei Han", "title": "cube2net: Efficient Query-Specific Network Construction with Data Cube\n  Organization", "comments": "Full paper of the extended abstract published in ICDMW 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are widely used to model objects with interactions and have enabled\nvarious downstream applications. However, in the real world, network mining is\noften done on particular query sets of objects, which does not require the\nconstruction and computation of networks including all objects in the datasets.\nIn this work, for the first time, we propose to address the problem of\nquery-specific network construction, to break the efficiency bottlenecks of\nexisting network mining algorithms and facilitate various downstream tasks. To\ndeal with real-world massive networks with complex attributes, we propose to\nleverage the well-developed data cube technology to organize network objects\nw.r.t. their essential attributes. An efficient reinforcement learning\nalgorithm is then developed to automatically explore the data cube structures\nand construct the optimal query-specific networks. With extensive experiments\nof two classic network mining tasks on different real-world large datasets, we\nshow that our proposed cube2net pipeline is general, and much more effective\nand efficient in query-specific network construction, compared with other\nmethods without the leverage of data cube or reinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:53:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yang", "Carl", ""], ["Liu", "Mengxiong", ""], ["He", "Frank", ""], ["Peng", "Jian", ""], ["Han", "Jiawei", ""]]}, {"id": "2002.00843", "submitter": "Fran\\c{c}ois Th\\'eberge", "authors": "Bogumi{\\l} Kami\\'nski and Pawe{\\l} Pra{\\l}at and Fran\\c{c}ois\n  Th\\'eberge", "title": "Artificial Benchmark for Community Detection (ABCD): Fast Random Graph\n  Model with Community Structure", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": "10.1017/nws.2020.45", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the current complex networks that are of interest to practitioners\npossess a certain community structure that plays an important role in\nunderstanding the properties of these networks. Moreover, many machine learning\nalgorithms and tools that are developed for complex networks try to take\nadvantage of the existence of communities to improve their performance or\nspeed. As a result, there are many competing algorithms for detecting\ncommunities in large networks. Unfortunately, these algorithms are often quite\nsensitive and so they cannot be fine-tuned for a given, but a constantly\nchanging, real-world network at hand. It is therefore important to test these\nalgorithms for various scenarios that can only be done using synthetic graphs\nthat have built-in community structure, power-law degree distribution, and\nother typical properties observed in complex networks. The standard and\nextensively used method for generating artificial networks is the LFR graph\ngenerator. Unfortunately, this model has some scalability limitations and it is\nchallenging to analyze it theoretically. Finally, the mixing parameter $\\mu$,\nthe main parameter of the model guiding the strength of the communities, has a\nnon-obvious interpretation and so can lead to unnaturally-defined networks. In\nthis paper, we provide an alternative random graph model with community\nstructure and power-law distribution for both degrees and community sizes, the\nArtificial Benchmark for Community Detection (ABCD). We show that the new model\nsolves the three issues identified above and more. The conclusion is that these\nmodels produce comparable graphs but ABCD is fast, simple, and can be easily\ntuned to allow the user to make a smooth transition between the two extremes:\npure (independent) communities and random graph with no community structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:20:27 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kami\u0144ski", "Bogumi\u0142", ""], ["Pra\u0142at", "Pawe\u0142", ""], ["Th\u00e9berge", "Fran\u00e7ois", ""]]}, {"id": "2002.00844", "submitter": "Peijie Sun", "authors": "Le Wu, Junwei Li, Peijie Sun, Richang Hong, Yong Ge, Meng Wang", "title": "DiffNet++: A Neural Influence and Interest Diffusion Network for Social\n  Recommendation", "comments": "This paper has been accepted by IEEE TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social recommendation has emerged to leverage social connections among users\nfor predicting users' unknown preferences, which could alleviate the data\nsparsity issue in collaborative filtering based recommendation. Early\napproaches relied on utilizing each user's first-order social neighbors'\ninterests for better user modeling and failed to model the social influence\ndiffusion process from the global social network structure. Recently, we\npropose a preliminary work of a neural influence diffusion network (i.e.,\nDiffNet) for social recommendation (Diffnet), which models the recursive social\ndiffusion process to capture the higher-order relationships for each user.\nHowever, we argue that, as users play a central role in both user-user social\nnetwork and user-item interest network, only modeling the influence diffusion\nprocess in the social network would neglect the users' latent collaborative\ninterests in the user-item interest network. In this paper, we propose\nDiffNet++, an improved algorithm of DiffNet that models the neural influence\ndiffusion and interest diffusion in a unified framework. By reformulating the\nsocial recommendation as a heterogeneous graph with social network and interest\nnetwork as input, DiffNet++ advances DiffNet by injecting these two network\ninformation for user embedding learning at the same time. This is achieved by\niteratively aggregating each user's embedding from three aspects: the user's\nprevious embedding, the influence aggregation of social neighbors from the\nsocial network, and the interest aggregation of item neighbors from the\nuser-item interest network. Furthermore, we design a multi-level attention\nnetwork that learns how to attentively aggregate user embeddings from these\nthree aspects. Finally, extensive experimental results on two real-world\ndatasets clearly show the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 08:45:34 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 22:55:40 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 22:20:14 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 09:34:56 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wu", "Le", ""], ["Li", "Junwei", ""], ["Sun", "Peijie", ""], ["Hong", "Richang", ""], ["Ge", "Yong", ""], ["Wang", "Meng", ""]]}, {"id": "2002.00848", "submitter": "Xudong Wang", "authors": "Liang Zhang, Xudong Wang, Hongsheng Li, Guangming Zhu, Peiyi Shen,\n  Ping Li, Xiaoyuan Lu, Syed Afaq Ali Shah, Mohammed Bennamoun", "title": "Structure-Feature based Graph Self-adaptive Pooling", "comments": "7 pages, 4 figures, The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380083", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods to deal with graph data have been proposed in recent years.\nHowever, most of these methods focus on graph feature aggregation rather than\ngraph pooling. Besides, the existing top-k selection graph pooling methods have\na few problems. First, to construct the pooled graph topology, current top-k\nselection methods evaluate the importance of the node from a single perspective\nonly, which is simplistic and unobjective. Second, the feature information of\nunselected nodes is directly lost during the pooling process, which inevitably\nleads to a massive loss of graph feature information. To solve these problems\nmentioned above, we propose a novel graph self-adaptive pooling method with the\nfollowing objectives: (1) to construct a reasonable pooled graph topology,\nstructure and feature information of the graph are considered simultaneously,\nwhich provide additional veracity and objectivity in node selection; and (2) to\nmake the pooled nodes contain sufficiently effective graph information, node\nfeature information is aggregated before discarding the unimportant nodes;\nthus, the selected nodes contain information from neighbor nodes, which can\nenhance the use of features of the unselected nodes. Experimental results on\nfour different datasets demonstrate that our method is effective in graph\nclassification and outperforms state-of-the-art graph pooling methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:58:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Liang", ""], ["Wang", "Xudong", ""], ["Li", "Hongsheng", ""], ["Zhu", "Guangming", ""], ["Shen", "Peiyi", ""], ["Li", "Ping", ""], ["Lu", "Xiaoyuan", ""], ["Shah", "Syed Afaq Ali", ""], ["Bennamoun", "Mohammed", ""]]}, {"id": "2002.00850", "submitter": "Aron Szanto", "authors": "Nir Rosenfeld, Aron Szanto, David C. Parkes", "title": "A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone", "comments": "Published at The Web Conference (WWW) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380180", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n\"sanitized\" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 19:56:03 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:30:49 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Rosenfeld", "Nir", ""], ["Szanto", "Aron", ""], ["Parkes", "David C.", ""]]}, {"id": "2002.00852", "submitter": "Quentin Paris", "authors": "Quentin Paris", "title": "The exponentially weighted average forecaster in geodesic spaces of\n  non-positive curvature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.GT cs.LG math.MG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of prediction with expert advice for\noutcomes in a geodesic space with non-positive curvature in the sense of\nAlexandrov. Via geometric considerations, and in particular the notion of\nbarycenters, we extend to this setting the definition and analysis of the\nclassical exponentially weighted average forecaster. We also adapt the\nprinciple of online to batch conversion to this setting. We shortly discuss the\napplication of these results in the context of aggregation and for the problem\nof barycenter estimation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 15:59:42 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Paris", "Quentin", ""]]}, {"id": "2002.00863", "submitter": "Fabrizio Pastore", "authors": "Hazem Fahmy, Fabrizio Pastore, Mojtaba Bagherzadeh, Lionel Briand", "title": "Supporting DNN Safety Analysis and Retraining through Heatmap-based\n  Unsupervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are increasingly important in safety-critical\nsystems, for example in their perception layer to analyze images.\nUnfortunately, there is a lack of methods to ensure the functional safety of\nDNN-based components. We observe three major challenges with existing practices\nregarding DNNs in safety-critical systems: (1) scenarios that are\nunderrepresented in the test set may lead to serious safety violation risks,\nbut may, however, remain unnoticed; (2) characterizing such high-risk scenarios\nis critical for safety analysis; (3) retraining DNNs to address these risks is\npoorly supported when causes of violations are difficult to determine. To\naddress these problems in the context of DNNs analyzing images, we propose\nHUDD, an approach that automatically supports the identification of root causes\nfor DNN errors. HUDD identifies root causes by applying a clustering algorithm\nto heatmaps capturing the relevance of every DNN neuron on the DNN outcome.\nAlso, HUDD retrains DNNs with images that are automatically selected based on\ntheir relatedness to the identified image clusters. We evaluated HUDD with DNNs\nfrom the automotive domain. HUDD was able to identify all the distinct root\ncauses of DNN errors, thus supporting safety analysis. Also, our retraining\napproach has shown to be more effective at improving DNN accuracy than existing\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:16:05 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 17:29:55 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 09:09:58 GMT"}, {"version": "v4", "created": "Thu, 22 Apr 2021 12:10:27 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Fahmy", "Hazem", ""], ["Pastore", "Fabrizio", ""], ["Bagherzadeh", "Mojtaba", ""], ["Briand", "Lionel", ""]]}, {"id": "2002.00864", "submitter": "Jonathan Lacotte", "authors": "Jonathan Lacotte, Sifan Liu, Edgar Dobriban and Mert Pilanci", "title": "Optimal Iterative Sketching with the Subsampled Randomized Hadamard\n  Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random projections or sketching are widely used in many algorithmic and\nlearning contexts. Here we study the performance of iterative Hessian sketch\nfor least-squares problems. By leveraging and extending recent results from\nrandom matrix theory on the limiting spectrum of matrices randomly projected\nwith the subsampled randomized Hadamard transform, and truncated Haar matrices,\nwe can study and compare the resulting algorithms to a level of precision that\nhas not been possible before. Our technical contributions include a novel\nformula for the second moment of the inverse of projected matrices. We also\nfind simple closed-form expressions for asymptotically optimal step-sizes and\nconvergence rates. These show that the convergence rate for Haar and randomized\nHadamard matrices are identical, and asymptotically improve upon Gaussian\nrandom projections. These techniques may be applied to other algorithms that\nemploy randomized dimension reduction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:17:50 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:46:35 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 08:02:42 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 07:58:40 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 12:35:02 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Lacotte", "Jonathan", ""], ["Liu", "Sifan", ""], ["Dobriban", "Edgar", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.00865", "submitter": "Kalliopi Basioti", "authors": "Kalliopi Basioti and George V. Moustakides", "title": "Designing GANs: A Likelihood Ratio Approach", "comments": "Accepted to \"The Joint International Conference on Neural Networks\n  (IJCNN 2021)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the design of generative networks. The training of these\nmathematical structures is mostly performed with the help of adversarial\n(min-max) optimization problems. We propose a simple methodology for\nconstructing such problems assuring, at the same time, consistency of the\ncorresponding solution. We give characteristic examples developed by our\nmethod, some of which can be recognized from other applications, and some are\nintroduced here for the first time. We present a new metric, the likelihood\nratio, that can be employed online to examine the convergence and stability\nduring the training of different Generative Adversarial Networks (GANs).\nFinally, we compare various possibilities by applying them to well-known\ndatasets using neural networks of different configurations and sizes.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:19:08 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 02:06:22 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:50:33 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Basioti", "Kalliopi", ""], ["Moustakides", "George V.", ""]]}, {"id": "2002.00872", "submitter": "Amaury Depierre", "authors": "Amaury Depierre (imagine), Emmanuel Dellandr\\'ea (imagine), Liming\n  Chen (imagine)", "title": "Scoring Graspability based on Grasp Regression for Better Grasp\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping objects is one of the most important abilities that a robot needs to\nmaster in order to interact with its environment. Current state-of-the-art\nmethods rely on deep neural networks trained to jointly predict a graspability\nscore together with a regression of an offset with respect to grasp reference\nparameters. However, these two predictions are performed independently, which\ncan lead to a decrease in the actual graspability score when applying the\npredicted offset. Therefore, in this paper, we extend a state-of-the-art neural\nnetwork with a scorer that evaluates the graspability of a given position, and\nintroduce a novel loss function which correlates regression of grasp parameters\nwith graspability score. We show that this novel architecture improves\nperformance from 82.13% for a state-of-the-art grasp detection network to\n85.74% on Jacquard dataset. When the learned model is transferred onto a real\nrobot, the proposed method correlating graspability and grasp regression\nachieves a 92.4% rate compared to 88.1% for the baseline trained without the\ncorrelation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:40:16 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 13:19:44 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 08:09:26 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Depierre", "Amaury", "", "imagine"], ["Dellandr\u00e9a", "Emmanuel", "", "imagine"], ["Chen", "Liming", "", "imagine"]]}, {"id": "2002.00874", "submitter": "Zaiwei Chen", "authors": "Zaiwei Chen, Siva Theja Maguluri, Sanjay Shakkottai, and Karthikeyan\n  Shanmugam", "title": "Finite-Sample Analysis of Stochastic Approximation Using Smooth Convex\n  Envelopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic Approximation (SA) is a popular approach for solving fixed-point\nequations where the information is corrupted by noise. In this paper, we\nconsider an SA involving a contraction mapping with respect to an arbitrary\nnorm, and show its finite-sample error bounds while using different stepsizes.\nThe idea is to construct a smooth Lyapunov function using the generalized\nMoreau envelope, and show that the iterates of SA have negative drift with\nrespect to that Lyapunov function. Our result is applicable in Reinforcement\nLearning (RL). In particular, we use it to establish the first-known\nconvergence rate of the V-trace algorithm for off-policy TD-learning. Moreover,\nwe also use it to study TD-learning in the on-policy setting, and recover the\nexisting state-of-the-art results for $Q$-learning. Importantly, our\nconstruction results in only a logarithmic dependence of the convergence bound\non the size of the state-space.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:42:01 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 14:31:15 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 02:01:51 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 20:35:15 GMT"}, {"version": "v5", "created": "Wed, 16 Jun 2021 20:14:34 GMT"}, {"version": "v6", "created": "Wed, 30 Jun 2021 13:09:14 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Chen", "Zaiwei", ""], ["Maguluri", "Siva Theja", ""], ["Shakkottai", "Sanjay", ""], ["Shanmugam", "Karthikeyan", ""]]}, {"id": "2002.00883", "submitter": "Decky Aspandi", "authors": "Decky Aspandi, Adria Mallol-Ragolta, Bj\\\"orn Schuller, Xavier Binefa", "title": "Adversarial-based neural networks for affect estimations in the wild", "comments": "Paper for FG 2020 Affect Challenge\n  https://ibug.doc.ic.ac.uk/resources/fg-2020-competition-affective-behavior-analysis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in affective computing research nowadays given\nits crucial role in bridging humans with computers. This progress has been\nrecently accelerated due to the emergence of bigger data. One recent advance in\nthis field is the use of adversarial learning to improve model learning through\naugmented samples. However, the use of latent features, which is feasible\nthrough adversarial learning, is not largely explored, yet. This technique may\nalso improve the performance of affective models, as analogously demonstrated\nin related fields, such as computer vision. To expand this analysis, in this\nwork, we explore the use of latent features through our proposed\nadversarial-based networks for valence and arousal recognition in the wild.\nSpecifically, our models operate by aggregating several modalities to our\ndiscriminator, which is further conditioned to the extracted latent features by\nthe generator. Our experiments on the recently released SEWA dataset suggest\nthe progressive improvements of our results. Finally, we show our competitive\nresults on the Affective Behavior Analysis in-the-Wild (ABAW) challenge dataset\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:52:49 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 15:31:49 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 23:00:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Aspandi", "Decky", ""], ["Mallol-Ragolta", "Adria", ""], ["Schuller", "Bj\u00f6rn", ""], ["Binefa", "Xavier", ""]]}, {"id": "2002.00897", "submitter": "Hossein Pourmeidani", "authors": "Paul Wood, Hossein Pourmeidani, and Ronald F. DeMara", "title": "Modular Simulation Framework for Process Variation Analysis of\n  MRAM-based Deep Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic Random-Access Memory (MRAM) based p-bit neuromorphic computing\ndevices are garnering increasing interest as a means to compactly and\nefficiently realize machine learning operations in Restricted Boltzmann\nMachines (RBMs). When embedded within an RBM resistive crossbar array, the\np-bit based neuron realizes a tunable sigmoidal activation function. Since the\nstochasticity of activation is dependent on the energy barrier of the MRAM\ndevice, it is essential to assess the impact of process variation on the\nvoltage-dependent behavior of the sigmoid function. Other influential\nperformance factors arise from varying energy barriers on power consumption\nrequiring a simulation environment to facilitate the multi-objective\noptimization of device and network parameters. Herein, transportable Python\nscripts are developed to analyze the output variation under changes in device\ndimensions on the accuracy of machine learning applications. Evaluation with\nRBM circuits using the MNIST dataset reveal impacts and limits for processing\nvariation of device fabrication in terms of the resulting energy vs. accuracy\ntradeoffs, and the resulting simulation framework is available via a Creative\nCommons license.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:20:21 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Wood", "Paul", ""], ["Pourmeidani", "Hossein", ""], ["DeMara", "Ronald F.", ""]]}, {"id": "2002.00901", "submitter": "Zheng Yu", "authors": "Zheng Yu, Xuhui Fan, Marcin Pietrasik, Marek Reformat", "title": "Fragmentation Coagulation Based Mixed Membership Stochastic Blockmodel", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mixed-Membership Stochastic Blockmodel~(MMSB) is proposed as one of the\nstate-of-the-art Bayesian relational methods suitable for learning the complex\nhidden structure underlying the network data. However, the current formulation\nof MMSB suffers from the following two issues: (1), the prior information~(e.g.\nentities' community structural information) can not be well embedded in the\nmodelling; (2), community evolution can not be well described in the\nliterature. Therefore, we propose a non-parametric fragmentation coagulation\nbased Mixed Membership Stochastic Blockmodel (fcMMSB). Our model performs\nentity-based clustering to capture the community information for entities and\nlinkage-based clustering to derive the group information for links\nsimultaneously. Besides, the proposed model infers the network structure and\nmodels community evolution, manifested by appearances and disappearances of\ncommunities, using the discrete fragmentation coagulation process (DFCP). By\nintegrating the community structure with the group compatibility matrix we\nderive a generalized version of MMSB. An efficient Gibbs sampling scheme with\nPolya Gamma (PG) approach is implemented for posterior inference. We validate\nour model on synthetic and real world data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:02:23 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Yu", "Zheng", ""], ["Fan", "Xuhui", ""], ["Pietrasik", "Marcin", ""], ["Reformat", "Marek", ""]]}, {"id": "2002.00904", "submitter": "Soroosh Shahtalebi", "authors": "Soroosh Shahtalebi, Amir Asif, Arash Mohammadi", "title": "Siamese Neural Networks for EEG-based Brain-computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the inconceivable capability of the human brain in\nsimultaneously processing multi-modal signals and its real-time feedback to the\nouter world events, there has been a surge of interest in establishing a\ncommunication bridge between the human brain and a computer, which are referred\nto as Brain-computer Interfaces (BCI). To this aim, monitoring the electrical\nactivity of brain through Electroencephalogram (EEG) has emerged as the prime\nchoice for BCI systems. To discover the underlying and specific features of\nbrain signals for different mental tasks, a considerable number of research\nworks are developed based on statistical and data-driven techniques. However, a\nmajor bottleneck in the development of practical and commercial BCI systems is\ntheir limited performance when the number of mental tasks for classification is\nincreased. In this work, we propose a new EEG processing and feature extraction\nparadigm based on Siamese neural networks, which can be conveniently merged and\nscaled up for multi-class problems. The idea of Siamese networks is to train a\ndouble-input neural network based on a contrastive loss-function, which\nprovides the capability of verifying if two input EEG trials are from the same\nclass or not. In this work, a Siamese architecture, which is developed based on\nConvolutional Neural Networks (CNN) and provides a binary output on the\nsimilarity of two inputs, is combined with OVR and OVO techniques to scale up\nfor multi-class problems. The efficacy of this architecture is evaluated on a\n4-class Motor Imagery (MI) dataset from BCI Competition IV-2a and the results\nsuggest a promising performance compared to its counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:31:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shahtalebi", "Soroosh", ""], ["Asif", "Amir", ""], ["Mohammadi", "Arash", ""]]}, {"id": "2002.00909", "submitter": "Mikail Yayla", "authors": "Sebastian Buschj\\\"ager, Jian-Jia Chen, Kuan-Hsun Chen, Mario G\\\"unzel,\n  Christian Hakert, Katharina Morik, Rodion Novkin, Lukas Pfahler, Mikail Yayla", "title": "Towards Explainable Bit Error Tolerance of Resistive RAM-Based Binarized\n  Neural Networks", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-volatile memory, such as resistive RAM (RRAM), is an emerging\nenergy-efficient storage, especially for low-power machine learning models on\nthe edge. It is reported, however, that the bit error rate of RRAMs can be up\nto 3.3% in the ultra low-power setting, which might be crucial for many use\ncases. Binary neural networks (BNNs), a resource efficient variant of neural\nnetworks (NNs), can tolerate a certain percentage of errors without a loss in\naccuracy and demand lower resources in computation and storage. The bit error\ntolerance (BET) in BNNs can be achieved by flipping the weight signs during\ntraining, as proposed by Hirtzlin et al., but their method has a significant\ndrawback, especially for fully connected neural networks (FCNN): The FCNNs\noverfit to the error rate used in training, which leads to low accuracy under\nlower error rates. In addition, the underlying principles of BET are not\ninvestigated. In this work, we improve the training for BET of BNNs and aim to\nexplain this property. We propose straight-through gradient approximation to\nimprove the weight-sign-flip training, by which BNNs adapt less to the bit\nerror rates. To explain the achieved robustness, we define a metric that aims\nto measure BET without fault injection. We evaluate the metric and find that it\ncorrelates with accuracy over error rate for all FCNNs tested. Finally, we\nexplore the influence of a novel regularizer that optimizes with respect to\nthis metric, with the aim of providing a configurable trade-off in accuracy and\nBET.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:38:45 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Chen", "Jian-Jia", ""], ["Chen", "Kuan-Hsun", ""], ["G\u00fcnzel", "Mario", ""], ["Hakert", "Christian", ""], ["Morik", "Katharina", ""], ["Novkin", "Rodion", ""], ["Pfahler", "Lukas", ""], ["Yayla", "Mikail", ""]]}, {"id": "2002.00922", "submitter": "Yafei Han Ms", "authors": "Yafei Han, Christopher Zegras, Francisco Camara Pereira, Moshe\n  Ben-Akiva", "title": "A Neural-embedded Choice Model: TasteNet-MNL Modeling Taste\n  Heterogeneity with Flexibility and Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete choice models (DCMs) and neural networks (NNs) can complement each\nother. We propose a neural network embedded choice model - TasteNet-MNL, to\nimprove the flexibility in modeling taste heterogeneity while keeping model\ninterpretability. The hybrid model consists of a TasteNet module: a\nfeed-forward neural network that learns taste parameters as flexible functions\nof individual characteristics; and a choice module: a multinomial logit model\n(MNL) with manually specified utility. TasteNet and MNL are fully integrated\nand jointly estimated. By embedding a neural network into a DCM, we exploit a\nneural network's function approximation capacity to reduce specification bias.\nThrough special structure and parameter constraints, we incorporate expert\nknowledge to regularize the neural network and maintain interpretability. On\nsynthetic data, we show that TasteNet-MNL can recover the underlying non-linear\nutility function, and provide predictions and interpretations as accurate as\nthe true model; while examples of logit or random coefficient logit models with\nmisspecified utility functions result in large parameter bias and low\npredictability. In the case study of Swissmetro mode choice, TasteNet-MNL\noutperforms benchmarking MNLs' predictability; and discovers a wider spectrum\nof taste variations within the population, and higher values of time on\naverage. This study takes an initial step towards developing a framework to\ncombine theory-based and data-driven approaches for discrete choice modeling.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:03:54 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Han", "Yafei", ""], ["Zegras", "Christopher", ""], ["Pereira", "Francisco Camara", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2002.00937", "submitter": "Alexandre Sablayrolles", "authors": "Alexandre Sablayrolles, Matthijs Douze, Cordelia Schmid, Herv\\'e\n  J\\'egou", "title": "Radioactive data: tracing through training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We want to detect whether a particular image dataset has been used to train a\nmodel. We propose a new technique, \\emph{radioactive data}, that makes\nimperceptible changes to this dataset such that any model trained on it will\nbear an identifiable mark. The mark is robust to strong variations such as\ndifferent architectures or optimization methods. Given a trained model, our\ntechnique detects the use of radioactive data and provides a level of\nconfidence (p-value). Our experiments on large-scale benchmarks (Imagenet),\nusing standard architectures (Resnet-18, VGG-16, Densenet-121) and training\nprocedures, show that we can detect usage of radioactive data with high\nconfidence (p<10^-4) even when only 1% of the data used to trained our model is\nradioactive. Our method is robust to data augmentation and the stochasticity of\ndeep network optimization. As a result, it offers a much higher signal-to-noise\nratio than data poisoning and backdoor methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:41:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sablayrolles", "Alexandre", ""], ["Douze", "Matthijs", ""], ["Schmid", "Cordelia", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "2002.00941", "submitter": "Andreea Bobu", "authors": "Andreea Bobu, Andrea Bajcsy, Jaime F. Fisac, Sampada Deglurkar, Anca\n  D. Dragan", "title": "Quantifying Hypothesis Space Misspecification in Learning from\n  Human-Robot Demonstrations and Physical Corrections", "comments": "20 pages. 12 figures, 1 table. IEEE Transactions on Robotics, 2020", "journal-ref": null, "doi": "10.1109/TRO.2020.2971415", "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human input has enabled autonomous systems to improve their capabilities and\nachieve complex behaviors that are otherwise challenging to generate\nautomatically. Recent work focuses on how robots can use such input - like\ndemonstrations or corrections - to learn intended objectives. These techniques\nassume that the human's desired objective already exists within the robot's\nhypothesis space. In reality, this assumption is often inaccurate: there will\nalways be situations where the person might care about aspects of the task that\nthe robot does not know about. Without this knowledge, the robot cannot infer\nthe correct objective. Hence, when the robot's hypothesis space is\nmisspecified, even methods that keep track of uncertainty over the objective\nfail because they reason about which hypothesis might be correct, and not\nwhether any of the hypotheses are correct. In this paper, we posit that the\nrobot should reason explicitly about how well it can explain human inputs given\nits hypothesis space and use that situational confidence to inform how it\nshould incorporate human input. We demonstrate our method on a 7\ndegree-of-freedom robot manipulator in learning from two important types of\nhuman input: demonstrations of manipulation tasks, and physical corrections\nduring the robot's task execution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:59:23 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 23:59:41 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Bobu", "Andreea", ""], ["Bajcsy", "Andrea", ""], ["Fisac", "Jaime F.", ""], ["Deglurkar", "Sampada", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2002.00949", "submitter": "Bart Baesens", "authors": "Tine Van Calster, Filip Van den Bossche, Bart Baesens, Wilfried\n  Lemahieu", "title": "Profit-oriented sales forecasting: a comparison of forecasting\n  techniques from a business perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the technique that is the best at forecasting your data, is a\nproblem that arises in any forecasting application. Decades of research have\nresulted into an enormous amount of forecasting methods that stem from\nstatistics, econometrics and machine learning (ML), which leads to a very\ndifficult and elaborate choice to make in any forecasting exercise. This paper\naims to facilitate this process for high-level tactical sales forecasts by\ncomparing a large array of techniques for 35 times series that consist of both\nindustry data from the Coca-Cola Company and publicly available datasets.\nHowever, instead of solely focusing on the accuracy of the resulting forecasts,\nthis paper introduces a novel and completely automated profit-driven approach\nthat takes into account the expected profit that a technique can create during\nboth the model building and evaluation process. The expected profit function\nthat is used for this purpose, is easy to understand and adaptable to any\nsituation by combining forecasting accuracy with business expertise.\nFurthermore, we examine the added value of ML techniques, the inclusion of\nexternal factors and the use of seasonal models in order to ascertain which\ntype of model works best in tactical sales forecasting. Our findings show that\nsimple seasonal time series models consistently outperform other methodologies\nand that the profit-driven approach can lead to selecting a different\nforecasting model.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 14:50:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Van Calster", "Tine", ""], ["Bossche", "Filip Van den", ""], ["Baesens", "Bart", ""], ["Lemahieu", "Wilfried", ""]]}, {"id": "2002.00952", "submitter": "Maria Ines Meyer", "authors": "Mattias Billast, Maria Ines Meyer, Diana M. Sima and David Robben", "title": "Improved inter-scanner MS lesion segmentation by adversarial training on\n  longitudinal data", "comments": "Added link to final authenticated publication\n  (https://doi.org/10.1007/978-3-030-46640-4_10)", "journal-ref": "Crimi A., Bakas S. (eds) Brainlesion: Glioma, Multiple Sclerosis,\n  Stroke and Traumatic Brain Injuries. BrainLes 2019. Lecture Notes in Computer\n  Science, vol 11992. Springer, Cham", "doi": "10.1007/978-3-030-46640-4_10", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of white matter lesion progression is an important biomarker\nin the follow-up of MS patients and plays a crucial role when deciding the\ncourse of treatment. Current automated lesion segmentation algorithms are\nsusceptible to variability in image characteristics related to MRI scanner or\nprotocol differences. We propose a model that improves the consistency of MS\nlesion segmentations in inter-scanner studies. First, we train a CNN base model\nto approximate the performance of icobrain, an FDA-approved clinically\navailable lesion segmentation software. A discriminator model is then trained\nto predict if two lesion segmentations are based on scans acquired using the\nsame scanner type or not, achieving a 78% accuracy in this task. Finally, the\nbase model and the discriminator are trained adversarially on multi-scanner\nlongitudinal data to improve the inter-scanner consistency of the base model.\nThe performance of the models is evaluated on an unseen dataset containing\nmanual delineations. The inter-scanner variability is evaluated on test-retest\ndata, where the adversarial network produces improved results over the base\nmodel and the FDA-approved solution.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:56:05 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 11:11:26 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Billast", "Mattias", ""], ["Meyer", "Maria Ines", ""], ["Sima", "Diana M.", ""], ["Robben", "David", ""]]}, {"id": "2002.00994", "submitter": "Ignacio Becker", "authors": "Ignacio Becker, Karim Pichara, M\\'arcio Catelan, Pavlos Protopapas,\n  Carlos Aguirre, Fatemeh Nikzat", "title": "Scalable End-to-end Recurrent Neural Network for Variable star\n  classification", "comments": "15 pages, 17 figures. To be published in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/staa350", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, considerable effort has been made to perform\nautomatic classification of variable stars using machine learning techniques.\nTraditionally, light curves are represented as a vector of descriptors or\nfeatures used as input for many algorithms. Some features are computationally\nexpensive, cannot be updated quickly and hence for large datasets such as the\nLSST cannot be applied. Previous work has been done to develop alternative\nunsupervised feature extraction algorithms for light curves, but the cost of\ndoing so still remains high. In this work, we propose an end-to-end algorithm\nthat automatically learns the representation of light curves that allows an\naccurate automatic classification. We study a series of deep learning\narchitectures based on Recurrent Neural Networks and test them in automated\nclassification scenarios. Our method uses minimal data preprocessing, can be\nupdated with a low computational cost for new observations and light curves,\nand can scale up to massive datasets. We transform each light curve into an\ninput matrix representation whose elements are the differences in time and\nmagnitude, and the outputs are classification probabilities. We test our method\nin three surveys: OGLE-III, Gaia and WISE. We obtain accuracies of about $95\\%$\nin the main classes and $75\\%$ in the majority of subclasses. We compare our\nresults with the Random Forest classifier and obtain competitive accuracies\nwhile being faster and scalable. The analysis shows that the computational\ncomplexity of our approach grows up linearly with the light curve size, while\nthe traditional approach cost grows as $N\\log{(N)}$.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:56:42 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Becker", "Ignacio", ""], ["Pichara", "Karim", ""], ["Catelan", "M\u00e1rcio", ""], ["Protopapas", "Pavlos", ""], ["Aguirre", "Carlos", ""], ["Nikzat", "Fatemeh", ""]]}, {"id": "2002.00995", "submitter": "Soham Dan", "authors": "Soham Dan, Han Bao, Masashi Sugiyama", "title": "Learning from Noisy Similar and Dissimilar Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread use of machine learning for classification, it becomes\nincreasingly important to be able to use weaker kinds of supervision for tasks\nin which it is hard to obtain standard labeled data. One such kind of\nsupervision is provided pairwise---in the form of Similar (S) pairs (if two\nexamples belong to the same class) and Dissimilar (D) pairs (if two examples\nbelong to different classes). This kind of supervision is realistic in\nprivacy-sensitive domains. Although this problem has been looked at recently,\nit is unclear how to learn from such supervision under label noise, which is\nvery common when the supervision is crowd-sourced. In this paper, we close this\ngap and demonstrate how to learn a classifier from noisy S and D labeled data.\nWe perform a detailed investigation of this problem under two realistic noise\nmodels and propose two algorithms to learn from noisy S-D data. We also show\nimportant connections between learning from such pairwise supervision data and\nlearning from ordinary class-labeled data. Finally, we perform experiments on\nsynthetic and real world datasets and show our noise-informed algorithms\noutperform noise-blind baselines in learning from noisy pairwise data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:59:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dan", "Soham", ""], ["Bao", "Han", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.01020", "submitter": "Haotian Wang", "authors": "Haotian Wang, Min Xian, Aleksandar Vakanski", "title": "Bending Loss Regularized Network for Nuclei Segmentation in\n  Histopathology Images", "comments": "4 pages, 5 figures, 2020 IEEE 17th International Symposium on\n  Biomedical Imaging (ISBI), accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating overlapped nuclei is a major challenge in histopathology image\nanalysis. Recently published approaches have achieved promising overall\nperformance on public datasets; however, their performance in segmenting\noverlapped nuclei are limited. To address the issue, we propose the bending\nloss regularized network for nuclei segmentation. The proposed bending loss\ndefines high penalties to contour points with large curvatures, and applies\nsmall penalties to contour points with small curvature. Minimizing the bending\nloss can avoid generating contours that encompass multiple nuclei. The proposed\napproach is validated on the MoNuSeg dataset using five quantitative metrics.\nIt outperforms six state-of-the-art approaches on the following metrics:\nAggregate Jaccard Index, Dice, Recognition Quality, and Pan-optic Quality.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 21:20:50 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wang", "Haotian", ""], ["Xian", "Min", ""], ["Vakanski", "Aleksandar", ""]]}, {"id": "2002.01029", "submitter": "Olivier Pannekoucke", "authors": "Olivier Pannekoucke and Ronan Fablet", "title": "PDE-NetGen 1.0: from symbolic PDE representations of physical processes\n  to trainable neural network representations", "comments": null, "journal-ref": null, "doi": "10.5194/gmd-13-3373-2020", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridging physics and deep learning is a topical challenge. While deep\nlearning frameworks open avenues in physical science, the design of\nphysically-consistent deep neural network architectures is an open issue. In\nthe spirit of physics-informed NNs, PDE-NetGen package provides new means to\nautomatically translate physical equations, given as PDEs, into neural network\narchitectures. PDE-NetGen combines symbolic calculus and a neural network\ngenerator. The later exploits NN-based implementations of PDE solvers using\nKeras. With some knowledge of a problem, PDE-NetGen is a plug-and-play tool to\ngenerate physics-informed NN architectures. They provide\ncomputationally-efficient yet compact representations to address a variety of\nissues, including among others adjoint derivation, model calibration,\nforecasting, data assimilation as well as uncertainty quantification. As an\nillustration, the workflow is first presented for the 2D diffusion equation,\nthen applied to the data-driven and physics-informed identification of\nuncertainty dynamics for the Burgers equation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:11:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Pannekoucke", "Olivier", ""], ["Fablet", "Ronan", ""]]}, {"id": "2002.01031", "submitter": "Hongyu Li", "authors": "Hongyu Li, Zifei Liang, Chaoyi Zhang, Ruiying Liu, Jing Li, Weihong\n  Zhang, Dong Liang, Bowen Shen, Xiaoliang Zhang, Yulin Ge, Jiangyang Zhang and\n  Leslie Ying", "title": "SuperDTI: Ultrafast diffusion tensor imaging and fiber tractography with\n  deep learning", "comments": "27 pages, 7 figures, 3 tables, 3 supporting figures", "journal-ref": null, "doi": "10.1002/mrm.28937", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To propose a deep learning-based reconstruction framework for\nultrafast and robust diffusion tensor imaging and fiber tractography. Methods:\nWe propose SuperDTI to learn the nonlinear relationship between\ndiffusion-weighted images (DWIs) and the corresponding tensor-derived\nquantitative maps as well as the fiber tractography. Super DTI bypasses the\ntensor fitting procedure, which is well known to be highly susceptible to noise\nand motion in DWIs. The network is trained and tested using datasets from Human\nConnectome Project and patients with ischemic stroke. SuperDTI is compared\nagainst the state-of-the-art methods for diffusion map reconstruction and fiber\ntracking. Results: Using training and testing data both from the same protocol\nand scanner, SuperDTI is shown to generate fractional anisotropy and mean\ndiffusivity maps, as well as fiber tractography, from as few as six raw DWIs.\nThe method achieves a quantification error of less than 5% in all regions of\ninterest in white matter and gray matter structures. We also demonstrate that\nthe trained neural network is robust to noise and motion in the testing data,\nand the network trained using healthy volunteer data can be directly applied to\nstroke patient data without compromising the lesion detectability. Conclusion:\nThis paper demonstrates the feasibility of superfast diffusion tensor imaging\nand fiber tractography using deep learning with as few as six DWIs directly,\nbypassing tensor fitting. Such a significant reduction in scan time may allow\nthe inclusion of DTI into the clinical routine for many potential applications.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:15:27 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 22:10:31 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 14:37:10 GMT"}, {"version": "v4", "created": "Wed, 24 Mar 2021 15:23:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Li", "Hongyu", ""], ["Liang", "Zifei", ""], ["Zhang", "Chaoyi", ""], ["Liu", "Ruiying", ""], ["Li", "Jing", ""], ["Zhang", "Weihong", ""], ["Liang", "Dong", ""], ["Shen", "Bowen", ""], ["Zhang", "Xiaoliang", ""], ["Ge", "Yulin", ""], ["Zhang", "Jiangyang", ""], ["Ying", "Leslie", ""]]}, {"id": "2002.01034", "submitter": "Bryar Shareef", "authors": "Bryar Shareef, Min Xian, Aleksandar Vakanski", "title": "Stan: Small tumor-aware network for breast ultrasound image segmentation", "comments": "5 pages, 3 figures, Accepted to 2020 ISBI conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast tumor segmentation provides accurate tumor boundary, and serves as a\nkey step toward further cancer quantification. Although deep learning-based\napproaches have been proposed and achieved promising results, existing\napproaches have difficulty in detecting small breast tumors. The capacity to\ndetecting small tumors is particularly important in finding early stage cancers\nusing computer-aided diagnosis (CAD) systems. In this paper, we propose a novel\ndeep learning architecture called Small Tumor-Aware Network (STAN), to improve\nthe performance of segmenting tumors with different size. The new architecture\nintegrates both rich context information and high-resolution image features. We\nvalidate the proposed approach using seven quantitative metrics on two public\nbreast ultrasound datasets. The proposed approach outperformed the\nstate-of-the-art approaches in segmenting small breast tumors. Index\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:25:01 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Shareef", "Bryar", ""], ["Xian", "Min", ""], ["Vakanski", "Aleksandar", ""]]}, {"id": "2002.01038", "submitter": "Luana Ruiz", "authors": "Luana Ruiz, Fernando Gama, Alejandro Ribeiro", "title": "Gated Graph Recurrent Neural Networks", "comments": "Under review at IEEE TSP", "journal-ref": null, "doi": "10.1109/TSP.2020.3033962", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph processes exhibit a temporal structure determined by the sequence index\nand and a spatial structure determined by the graph support. To learn from\ngraph processes, an information processing architecture must then be able to\nexploit both underlying structures. We introduce Graph Recurrent Neural\nNetworks (GRNNs) as a general learning framework that achieves this goal by\nleveraging the notion of a recurrent hidden state together with graph signal\nprocessing (GSP). In the GRNN, the number of learnable parameters is\nindependent of the length of the sequence and of the size of the graph,\nguaranteeing scalability. We prove that GRNNs are permutation equivariant and\nthat they are stable to perturbations of the underlying graph support. To\naddress the problem of vanishing gradients, we also put forward gated GRNNs\nwith three different gating mechanisms: time, node and edge gates. In numerical\nexperiments involving both synthetic and real datasets, time-gated GRNNs are\nshown to improve upon GRNNs in problems with long term dependencies, while node\nand edge gates help encode long range dependencies present in the graph. The\nnumerical results also show that GRNNs outperform GNNs and RNNs, highlighting\nthe importance of taking both the temporal and graph structures of a graph\nprocess into account.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:35:14 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 18:48:30 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ruiz", "Luana", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2002.01043", "submitter": "Zhigang Lu", "authors": "Zhigang Lu, Hong Shen", "title": "Differentially Private k-Means Clustering with Guaranteed Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative clustering algorithms help us to learn the insights behind the\ndata. Unfortunately, this may allow adversaries to infer the privacy of\nindividuals with some background knowledge. In the worst case, the adversaries\nknow the centroids of an arbitrary iteration and the information of n-1 out of\nn items. To protect individual privacy against such an inference attack,\npreserving differential privacy (DP) for the iterative clustering algorithms\nhas been extensively studied in the interactive settings. However, existing\ninteractive differentially private clustering algorithms suffer from a\nnon-convergence problem, i.e., these algorithms may not terminate without a\npredefined number of iterations. This problem severely impacts the clustering\nquality and the efficiency of a differentially private algorithm. To resolve\nthis problem, in this paper, we propose a novel differentially private\nclustering framework in the interactive settings which controls the orientation\nof the movement of the centroids over the iterations to ensure the convergence\nby injecting DP noise in a selected area. We prove that, in the expected case,\nalgorithm under our framework converges in at most twice the iterations of\nLloyd's algorithm. We perform experimental evaluations on real-world datasets\nto show that our algorithm outperforms the state-of-the-art of the interactive\ndifferentially private clustering algorithms with guaranteed convergence and\nbetter clustering quality to meet the same DP requirement.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:53:47 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lu", "Zhigang", ""], ["Shen", "Hong", ""]]}, {"id": "2002.01044", "submitter": "Ardhendu Shekhar Tripathy", "authors": "Matthew L. Malloy, Ardhendu Tripathy, Robert D. Nowak", "title": "Optimal Confidence Regions for the Multinomial Parameter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Construction of tight confidence regions and intervals is central to\nstatistical inference and decision making. This paper develops new theory\nshowing minimum average volume confidence regions for categorical data. More\nprecisely, consider an empirical distribution $\\widehat{\\boldsymbol{p}}$\ngenerated from $n$ iid realizations of a random variable that takes one of $k$\npossible values according to an unknown distribution $\\boldsymbol{p}$. This is\nanalogous to a single draw from a multinomial distribution. A confidence region\nis a subset of the probability simplex that depends on\n$\\widehat{\\boldsymbol{p}}$ and contains the unknown $\\boldsymbol{p}$ with a\nspecified confidence. This paper shows how one can construct minimum average\nvolume confidence regions, answering a long standing question. We also show the\noptimality of the regions directly translates to optimal confidence intervals\nof linear functionals such as the mean, implying sample complexity and regret\nimprovements for adaptive machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:00:16 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 18:58:14 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Malloy", "Matthew L.", ""], ["Tripathy", "Ardhendu", ""], ["Nowak", "Robert D.", ""]]}, {"id": "2002.01048", "submitter": "Hao Tang", "authors": "Hao Tang, Dan Xu, Yan Yan, Jason J. Corso, Philip H.S. Torr, Nicu Sebe", "title": "Multi-Channel Attention Selection GANs for Guided Image-to-Image\n  Translation", "comments": "An extended version of a paper published in CVPR2019. arXiv admin\n  note: substantial text overlap with arXiv:1904.06807", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel model named Multi-Channel Attention Selection Generative\nAdversarial Network (SelectionGAN) for guided image-to-image translation, where\nwe translate an input image into another while respecting an external semantic\nguidance. The proposed SelectionGAN explicitly utilizes the semantic guidance\ninformation and consists of two stages. In the first stage, the input image and\nthe conditional semantic guidance are fed into a cycled semantic-guided\ngeneration network to produce initial coarse results. In the second stage, we\nrefine the initial results by using the proposed multi-scale spatial pooling \\&\nchannel selection module and the multi-channel attention selection module.\nMoreover, uncertainty maps automatically learned from attention maps are used\nto guide the pixel loss for better network optimization. Exhaustive experiments\non four challenging guided image-to-image translation tasks (face, hand, body\nand street view) demonstrate that our SelectionGAN is able to generate\nsignificantly better results than the state-of-the-art methods. Meanwhile, the\nproposed framework and modules are unified solutions and can be applied to\nsolve other generation tasks, such as semantic image synthesis. The code is\navailable at https://github.com/Ha0Tang/SelectionGAN.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:17:10 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Tang", "Hao", ""], ["Xu", "Dan", ""], ["Yan", "Yan", ""], ["Corso", "Jason J.", ""], ["Torr", "Philip H. S.", ""], ["Sebe", "Nicu", ""]]}, {"id": "2002.01053", "submitter": "Chirag Agarwal", "authors": "Chirag Agarwal, Shahin Khobahi, Arindam Bose, Mojtaba Soltanalian, Dan\n  Schonfeld", "title": "Deep-URL: A Model-Aware Approach To Blind Deconvolution Based On Deep\n  Unfolded Richardson-Lucy Network", "comments": "Accepted. 27th IEEE International Conference on Image Processing\n  (ICIP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability in current deep learning models causes serious\nconcerns as they are extensively used for various life-critical applications.\nHence, it is of paramount importance to develop interpretable deep learning\nmodels. In this paper, we consider the problem of blind deconvolution and\npropose a novel model-aware deep architecture that allows for the recovery of\nboth the blur kernel and the sharp image from the blurred image. In particular,\nwe propose the Deep Unfolded Richardson-Lucy (Deep-URL) framework -- an\ninterpretable deep-learning architecture that can be seen as an amalgamation of\nclassical estimation technique and deep neural network, and consequently leads\nto improved performance. Our numerical investigations demonstrate significant\nimprovement compared to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:43:08 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 18:53:45 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 21:19:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agarwal", "Chirag", ""], ["Khobahi", "Shahin", ""], ["Bose", "Arindam", ""], ["Soltanalian", "Mojtaba", ""], ["Schonfeld", "Dan", ""]]}, {"id": "2002.01059", "submitter": "Albert Zhan", "authors": "Albert Zhan, Stas Tiomkin, Pieter Abbeel", "title": "Preventing Imitation Learning with Adversarial Policy Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning can reproduce policies by observing experts, which poses a\nproblem regarding policy privacy. Policies, such as human, or policies on\ndeployed robots, can all be cloned without consent from the owners. How can we\nprotect against external observers cloning our proprietary policies? To answer\nthis question we introduce a new reinforcement learning framework, where we\ntrain an ensemble of near-optimal policies, whose demonstrations are guaranteed\nto be useless for an external observer. We formulate this idea by a constrained\noptimization problem, where the objective is to improve proprietary policies,\nand at the same time deteriorate the virtual policy of an eventual external\nobserver. We design a tractable algorithm to solve this new optimization\nproblem by modifying the standard policy gradient algorithm. Our formulation\ncan be interpreted in lenses of confidentiality and adversarial behaviour,\nwhich enables a broader perspective of this work. We demonstrate the existence\nof \"non-clonable\" ensembles, providing a solution to the above optimization\nproblem, which is calculated by our modified policy gradient algorithm. To our\nknowledge, this is the first work regarding the protection of policies in\nReinforcement Learning.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 01:57:16 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 23:15:58 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Zhan", "Albert", ""], ["Tiomkin", "Stas", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.01060", "submitter": "Chase Dowling", "authors": "Chase P. Dowling and Baosen Zhang", "title": "Transfer Learning for HVAC System Fault Detection", "comments": "7 pages, 4 figures, accepted to American Control Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faults in HVAC systems degrade thermal comfort and energy efficiency in\nbuildings and have received significant attention from the research community,\nwith data driven methods gaining in popularity. Yet the lack of labeled data,\nsuch as normal versus faulty operational status, has slowed the application of\nmachine learning to HVAC systems. In addition, for any particular building,\nthere may be an insufficient number of observed faults over a reasonable amount\nof time for training. To overcome these challenges, we present a transfer\nmethodology for a novel Bayesian classifier designed to distinguish between\nnormal operations and faulty operations. The key is to train this classifier on\na building with a large amount of sensor and fault data (for example, via\nsimulation or standard test data) then transfer the classifier to a new\nbuilding using a small amount of normal operations data from the new building.\nWe demonstrate a proof-of-concept for transferring a classifier between\narchitecturally similar buildings in different climates and show few samples\nare required to maintain classification precision and recall.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:06:48 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dowling", "Chase P.", ""], ["Zhang", "Baosen", ""]]}, {"id": "2002.01066", "submitter": "Parth Kashyap Thaker", "authors": "Parth Thaker, Gautam Dasarathy, and Angelia Nedi\\'c", "title": "On the Sample Complexity and Optimization Landscape for Quadratic\n  Feasibility Problems", "comments": "21 pages", "journal-ref": null, "doi": "10.1109/ISIT44484.2020.9174368", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of recovering a complex vector $\\mathbf{x}\\in\n\\mathbb{C}^n$ from $m$ quadratic measurements $\\{\\langle A_i\\mathbf{x},\n\\mathbf{x}\\rangle\\}_{i=1}^m$. This problem, known as quadratic feasibility,\nencompasses the well known phase retrieval problem and has applications in a\nwide range of important areas including power system state estimation and x-ray\ncrystallography. In general, not only is the the quadratic feasibility problem\nNP-hard to solve, but it may in fact be unidentifiable. In this paper, we\nestablish conditions under which this problem becomes {identifiable}, and\nfurther prove isometry properties in the case when the matrices\n$\\{A_i\\}_{i=1}^m$ are Hermitian matrices sampled from a complex Gaussian\ndistribution. Moreover, we explore a nonconvex {optimization} formulation of\nthis problem, and establish salient features of the associated optimization\nlandscape that enables gradient algorithms with an arbitrary initialization to\nconverge to a \\emph{globally optimal} point with a high probability. Our\nresults also reveal sample complexity requirements for successfully identifying\na feasible solution in these contexts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:35:09 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 19:10:15 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Thaker", "Parth", ""], ["Dasarathy", "Gautam", ""], ["Nedi\u0107", "Angelia", ""]]}, {"id": "2002.01068", "submitter": "Jiahao Yao", "authors": "Jiahao Yao, Marin Bukov, Lin Lin", "title": "Policy Gradient based Quantum Approximate Optimization Algorithm", "comments": "Mathematical and Scientific Machine Learning Conference (MSML) 2020", "journal-ref": "Proceedings of Machine Learning Research vol 107, 2020", "doi": null, "report-no": null, "categories": "quant-ph cond-mat.other cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum approximate optimization algorithm (QAOA), as a hybrid\nquantum/classical algorithm, has received much interest recently. QAOA can also\nbe viewed as a variational ansatz for quantum control. However, its direct\napplication to emergent quantum technology encounters additional physical\nconstraints: (i) the states of the quantum system are not observable; (ii)\nobtaining the derivatives of the objective function can be computationally\nexpensive or even inaccessible in experiments, and (iii) the values of the\nobjective function may be sensitive to various sources of uncertainty, as is\nthe case for noisy intermediate-scale quantum (NISQ) devices. Taking such\nconstraints into account, we show that policy-gradient-based reinforcement\nlearning (RL) algorithms are well suited for optimizing the variational\nparameters of QAOA in a noise-robust fashion, opening up the way for developing\nRL techniques for continuous quantum control. This is advantageous to help\nmitigate and monitor the potentially unknown sources of errors in modern\nquantum simulators. We analyze the performance of the algorithm for quantum\nstate transfer problems in single- and multi-qubit systems, subject to various\nsources of noise such as error terms in the Hamiltonian, or quantum uncertainty\nin the measurement process. We show that, in noisy setups, it is capable of\noutperforming state-of-the-art existing optimization algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:46:51 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 19:36:43 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yao", "Jiahao", ""], ["Bukov", "Marin", ""], ["Lin", "Lin", ""]]}, {"id": "2002.01071", "submitter": "Karam Abdulahhad", "authors": "Karam Abdulahhad", "title": "Concept Embedding for Information Retrieval", "comments": "6 pages", "journal-ref": null, "doi": "10.1007/978-3-319-76941-7_45", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts are used to solve the term-mismatch problem. However, we need an\neffective similarity measure between concepts. Word embedding presents a\npromising solution. We present in this study three approaches to build concepts\nvectors based on words vectors. We use a vector-based measure to estimate\ninter-concepts similarity. Our experiments show promising results. Furthermore,\nwords and concepts become comparable. This could be used to improve conceptual\nindexing process.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 09:18:56 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abdulahhad", "Karam", ""]]}, {"id": "2002.01089", "submitter": "Mahabubul Alam", "authors": "Mahabubul Alam, Abdullah Ash-Saki, Swaroop Ghosh", "title": "Accelerating Quantum Approximate Optimization Algorithm using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine learning based approach to accelerate quantum\napproximate optimization algorithm (QAOA) implementation which is a promising\nquantum-classical hybrid algorithm to prove the so-called quantum supremacy. In\nQAOA, a parametric quantum circuit and a classical optimizer iterates in a\nclosed loop to solve hard combinatorial optimization problems. The performance\nof QAOA improves with increasing number of stages (depth) in the quantum\ncircuit. However, two new parameters are introduced with each added stage for\nthe classical optimizer increasing the number of optimization loop iterations.\nWe note a correlation among parameters of the lower-depth and the higher-depth\nQAOA implementations and, exploit it by developing a machine learning model to\npredict the gate parameters close to the optimal values. As a result, the\noptimization loop converges in a fewer number of iterations. We choose graph\nMaxCut problem as a prototype to solve using QAOA. We perform a feature\nextraction routine using 100 different QAOA instances and develop a training\ndata-set with 13,860 optimal parameters. We present our analysis for 4 flavors\nof regression models and 4 flavors of classical optimizers. Finally, we show\nthat the proposed approach can curtail the number of optimization iterations by\non average 44.9% (up to 65.7%) from an analysis performed with 264 flavors of\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:21:00 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:50:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Alam", "Mahabubul", ""], ["Ash-Saki", "Abdullah", ""], ["Ghosh", "Swaroop", ""]]}, {"id": "2002.01093", "submitter": "Abhinav Gupta", "authors": "Ryan Lowe, Abhinav Gupta, Jakob Foerster, Douwe Kiela, Joelle Pineau", "title": "On the interaction between supervision and self-play in emergent\n  communication", "comments": "The first two authors contributed equally. Accepted at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A promising approach for teaching artificial agents to use natural language\ninvolves using human-in-the-loop training. However, recent work suggests that\ncurrent machine learning methods are too data inefficient to be trained in this\nway from scratch. In this paper, we investigate the relationship between two\ncategories of learning signals with the ultimate goal of improving sample\nefficiency: imitating human language data via supervised learning, and\nmaximizing reward in a simulated multi-agent environment via self-play (as done\nin emergent communication), and introduce the term supervised self-play (S2P)\nfor algorithms using both of these signals. We find that first training agents\nvia supervised learning on human data followed by self-play outperforms the\nconverse, suggesting that it is not beneficial to emerge languages from\nscratch. We then empirically investigate various S2P schedules that begin with\nsupervised learning in two environments: a Lewis signaling game with symbolic\ninputs, and an image-based referential game with natural language descriptions.\nLastly, we introduce population based approaches to S2P, which further improves\nthe performance over single-agent methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:35:19 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:48:08 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lowe", "Ryan", ""], ["Gupta", "Abhinav", ""], ["Foerster", "Jakob", ""], ["Kiela", "Douwe", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.01100", "submitter": "Marco Carmosino", "authors": "Mark Bun, Marco Leandro Carmosino, Jessica Sorrell", "title": "Efficient, Noise-Tolerant, and Private Learning via Boosting", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple framework for designing private boosting algorithms. We\ngive natural conditions under which these algorithms are differentially\nprivate, efficient, and noise-tolerant PAC learners. To demonstrate our\nframework, we use it to construct noise-tolerant and private PAC learners for\nlarge-margin halfspaces whose sample complexity does not depend on the\ndimension.\n  We give two sample complexity bounds for our large-margin halfspace learner.\nOne bound is based only on differential privacy, and uses this guarantee as an\nasset for ensuring generalization. This first bound illustrates a general\nmethodology for obtaining PAC learners from privacy, which may be of\nindependent interest. The second bound uses standard techniques from the theory\nof large-margin classification (the fat-shattering dimension) to match the best\nknown sample complexity for differentially private learning of large-margin\nhalfspaces, while additionally tolerating random label noise.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:16:37 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Bun", "Mark", ""], ["Carmosino", "Marco Leandro", ""], ["Sorrell", "Jessica", ""]]}, {"id": "2002.01107", "submitter": "Chengwei Chen", "authors": "Chengwei Chen and Pan Chen and Lingyu Yang and Jinyuan Mo and Haichuan\n  Song and Yuan Xie and Lizhuang Ma", "title": "Acoustic anomaly detection via latent regularized gaussian mixture\n  generative adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic anomaly detection aims at distinguishing abnormal acoustic signals\nfrom the normal ones. It suffers from the class imbalance issue and the lacking\nin the abnormal instances. In addition, collecting all kinds of abnormal or\nunknown samples for training purpose is impractical and timeconsuming. In this\npaper, a novel Gaussian Mixture Generative Adversarial Network (GMGAN) is\nproposed under semi-supervised learning framework, in which the underlying\nstructure of training data is not only captured in spectrogram reconstruction\nspace, but also can be further restricted in the space of latent representation\nin a discriminant manner. Experiments show that our model has clear superiority\nover previous methods, and achieves the state-of-the-art results on DCASE\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:39:50 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 02:27:12 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Chen", "Chengwei", ""], ["Chen", "Pan", ""], ["Yang", "Lingyu", ""], ["Mo", "Jinyuan", ""], ["Song", "Haichuan", ""], ["Xie", "Yuan", ""], ["Ma", "Lizhuang", ""]]}, {"id": "2002.01110", "submitter": "Abdollah Shafieezadeh", "authors": "Zeyu Wang and Abdollah Shafieezadeh", "title": "REAK: Reliability analysis through Error rate-based Adaptive Kriging", "comments": null, "journal-ref": null, "doi": "10.1016/j.ress.2018.10.004", "report-no": null, "categories": "stat.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As models in various fields are becoming more complex, associated\ncomputational demands have been increasing significantly. Reliability analysis\nfor these systems when failure probabilities are small is significantly\nchallenging, requiring a large number of costly simulations. To address this\nchallenge, this paper introduces Reliability analysis through Error rate-based\nAdaptive Kriging (REAK). An extension of the Central Limit Theorem based on\nLindeberg condition is adopted here to derive the distribution of the number of\ndesign samples with wrong sign estimate and subsequently determine the maximum\nerror rate for failure probability estimates. This error rate enables optimal\nestablishment of effective sampling regions at each stage of an adaptive scheme\nfor strategic generation of design samples. Moreover, it facilitates setting a\ntarget accuracy for failure probability estimation, which is used as stopping\ncriterion for reliability analysis. These capabilities together can\nsignificantly reduce the number of calls to sophisticated, computationally\ndemanding models. The application of REAK for four examples with varying extent\nof nonlinearity and dimension is presented. Results indicate that REAK is able\nto reduce the computational demand by as high as 50% compared to\nstate-of-the-art methods of Adaptive Kriging with Monte Carlo Simulation\n(AK-MCS) and Improved Sequential Kriging Reliability Analysis (ISKRA).\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 03:47:20 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wang", "Zeyu", ""], ["Shafieezadeh", "Abdollah", ""]]}, {"id": "2002.01113", "submitter": "Jun Li", "authors": "Jun Li, Li Fuxin, Sinisa Todorovic", "title": "Efficient Riemannian Optimization on the Stiefel Manifold via the Cayley\n  Transform", "comments": "ICLR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Strictly enforcing orthonormality constraints on parameter matrices has been\nshown advantageous in deep learning. This amounts to Riemannian optimization on\nthe Stiefel manifold, which, however, is computationally expensive. To address\nthis challenge, we present two main contributions: (1) A new efficient\nretraction map based on an iterative Cayley transform for optimization updates,\nand (2) An implicit vector transport mechanism based on the combination of a\nprojection of the momentum and the Cayley transform on the Stiefel manifold. We\nspecify two new optimization algorithms: Cayley SGD with momentum, and Cayley\nADAM on the Stiefel manifold. Convergence of Cayley SGD is theoretically\nanalyzed. Our experiments for CNN training demonstrate that both algorithms:\n(a) Use less running time per iteration relative to existing approaches that\nenforce orthonormality of CNN parameters; and (b) Achieve faster convergence\nrates than the baseline SGD and ADAM algorithms without compromising the\nperformance of the CNN. Cayley SGD and Cayley ADAM are also shown to reduce the\ntraining time for optimizing the unitary transition matrices in RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:01:51 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Li", "Jun", ""], ["Fuxin", "Li", ""], ["Todorovic", "Sinisa", ""]]}, {"id": "2002.01119", "submitter": "Wei Zhang", "authors": "Wei Zhang, Xiaodong Cui, Abdullah Kayi, Mingrui Liu, Ulrich Finkler,\n  Brian Kingsbury, George Saon, Youssef Mroueh, Alper Buyuktosunoglu, Payel\n  Das, David Kung, Michael Picheny", "title": "Improving Efficiency in Large-Scale Decentralized Distributed Training", "comments": null, "journal-ref": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP'2020) Oral", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized Parallel SGD (D-PSGD) and its asynchronous variant Asynchronous\nParallel SGD (AD-PSGD) is a family of distributed learning algorithms that have\nbeen demonstrated to perform well for large-scale deep learning tasks. One\ndrawback of (A)D-PSGD is that the spectral gap of the mixing matrix decreases\nwhen the number of learners in the system increases, which hampers convergence.\nIn this paper, we investigate techniques to accelerate (A)D-PSGD based training\nby improving the spectral gap while minimizing the communication cost. We\ndemonstrate the effectiveness of our proposed techniques by running experiments\non the 2000-hour Switchboard speech recognition task and the ImageNet computer\nvision task. On an IBM P9 supercomputer, our system is able to train an LSTM\nacoustic model in 2.28 hours with 7.5% WER on the Hub5-2000 Switchboard (SWB)\ntest set and 13.3% WER on the CallHome (CH) test set using 64 V100 GPUs and in\n1.98 hours with 7.7% WER on SWB and 13.3% WER on CH using 128 V100 GPUs, the\nfastest training time reported to date.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:29:09 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Kayi", "Abdullah", ""], ["Liu", "Mingrui", ""], ["Finkler", "Ulrich", ""], ["Kingsbury", "Brian", ""], ["Saon", "George", ""], ["Mroueh", "Youssef", ""], ["Buyuktosunoglu", "Alper", ""], ["Das", "Payel", ""], ["Kung", "David", ""], ["Picheny", "Michael", ""]]}, {"id": "2002.01122", "submitter": "Byeong-Hoo Lee", "authors": "Byeong-Hoo Lee, Ji-Hoon Jeong, Kyung-Hwan Shim, Dong-Joo Kim", "title": "Motor Imagery Classification of Single-Arm Tasks Using Convolutional\n  Neural Network based on Feature Refining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) decodes brain signals to understand user\nintention and status. Because of its simple and safe data acquisition process,\nelectroencephalogram (EEG) is commonly used in non-invasive BCI. One of EEG\nparadigms, motor imagery (MI) is commonly used for recovery or rehabilitation\nof motor functions due to its signal origin. However, the EEG signals are an\noscillatory and non-stationary signal that makes it difficult to collect and\nclassify MI accurately. In this study, we proposed a band-power feature\nrefining convolutional neural network (BFR-CNN) which is composed of two\nconvolution blocks to achieve high classification accuracy. We collected EEG\nsignals to create MI dataset contained the movement imagination of a\nsingle-arm. The proposed model outperforms conventional approaches in 4-class\nMI tasks classification. Hence, we demonstrate that the decoding of user\nintention is possible by using only EEG signals with robust performance using\nBFR-CNN.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 04:36:09 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lee", "Byeong-Hoo", ""], ["Jeong", "Ji-Hoon", ""], ["Shim", "Kyung-Hwan", ""], ["Kim", "Dong-Joo", ""]]}, {"id": "2002.01129", "submitter": "Sareh Nabi", "authors": "Sareh Nabi, Houssam Nassif, Joseph Hong, Hamed Mamani, Guido Imbens", "title": "Bayesian Meta-Prior Learning Using Empirical Bayes", "comments": "Expanded discussions on applications and extended literature review\n  section. Forthcoming in the Management Science Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding domain knowledge to a learning system is known to improve results. In\nmulti-parameter Bayesian frameworks, such knowledge is incorporated as a prior.\nOn the other hand, various model parameters can have different learning rates\nin real-world problems, especially with skewed data. Two often-faced challenges\nin Operation Management and Management Science applications are the absence of\ninformative priors, and the inability to control parameter learning rates. In\nthis study, we propose a hierarchical Empirical Bayes approach that addresses\nboth challenges, and that can generalize to any Bayesian framework. Our method\nlearns empirical meta-priors from the data itself and uses them to decouple the\nlearning rates of first-order and second-order features (or any other given\nfeature grouping) in a Generalized Linear Model. As the first-order features\nare likely to have a more pronounced effect on the outcome, focusing on\nlearning first-order weights first is likely to improve performance and\nconvergence time. Our Empirical Bayes method clamps features in each group\ntogether and uses the deployed model's observed data to empirically compute a\nhierarchical prior in hindsight. We report theoretical results for the\nunbiasedness, strong consistency, and optimal frequentist cumulative regret\nproperties of our meta-prior variance estimator. We apply our method to a\nstandard supervised learning optimization problem, as well as an online\ncombinatorial optimization problem in a contextual bandit setting implemented\nin an Amazon production system. Both during simulations and live experiments,\nour method shows marked improvements, especially in cases of small traffic. Our\nfindings are promising, as optimizing over sparse data is often a challenge.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 05:08:17 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 23:00:22 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 21:18:32 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Nabi", "Sareh", ""], ["Nassif", "Houssam", ""], ["Hong", "Joseph", ""], ["Mamani", "Hamed", ""], ["Imbens", "Guido", ""]]}, {"id": "2002.01132", "submitter": "Shikha Dubey", "authors": "Shikha Dubey, Abhijeet Boragule, Moongu Jeon", "title": "3D ResNet with Ranking Loss Function for Abnormal Activity Detection in\n  Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abnormal activity detection is one of the most challenging tasks in the field\nof computer vision. This study is motivated by the recent state-of-art work of\nabnormal activity detection, which utilizes both abnormal and normal videos in\nlearning abnormalities with the help of multiple instance learning by providing\nthe data with video-level information. In the absence of temporal-annotations,\nsuch a model is prone to give a false alarm while detecting the abnormalities.\nFor this reason, in this paper, we focus on the task of minimizing the false\nalarm rate while performing an abnormal activity detection task. The mitigation\nof these false alarms and recent advancement of 3D deep neural network in video\naction recognition task collectively give us motivation to exploit the 3D\nResNet in our proposed method, which helps to extract spatial-temporal features\nfrom the videos. Afterwards, using these features and deep multiple instance\nlearning along with the proposed ranking loss, our model learns to predict the\nabnormality score at the video segment level. Therefore, our proposed method 3D\ndeep Multiple Instance Learning with ResNet (MILR) along with the new proposed\nranking loss function achieves the best performance on the UCF-Crime benchmark\ndataset, as compared to other state-of-art methods. The effectiveness of our\nproposed method is demonstrated on the UCF-Crime dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 05:32:21 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dubey", "Shikha", ""], ["Boragule", "Abhijeet", ""], ["Jeon", "Moongu", ""]]}, {"id": "2002.01136", "submitter": "Tianyu Guo", "authors": "Tianyu Guo, Chang Xu, Jiajun Huang, Yunhe Wang, Boxin Shi, Chao Xu,\n  Dacheng Tao", "title": "On Positive-Unlabeled Classification in GAN", "comments": null, "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a positive and unlabeled classification problem for\nstandard GANs, which then leads to a novel technique to stabilize the training\nof the discriminator in GANs. Traditionally, real data are taken as positive\nwhile generated data are negative. This positive-negative classification\ncriterion was kept fixed all through the learning process of the discriminator\nwithout considering the gradually improved quality of generated data, even if\nthey could be more realistic than real data at times. In contrast, it is more\nreasonable to treat the generated data as unlabeled, which could be positive or\nnegative according to their quality. The discriminator is thus a classifier for\nthis positive and unlabeled classification problem, and we derive a new\nPositive-Unlabeled GAN (PUGAN). We theoretically discuss the global optimality\nthe proposed model will achieve and the equivalent optimization goal.\nEmpirically, we find that PUGAN can achieve comparable or even better\nperformance than those sophisticated discriminator stabilization methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 05:59:37 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guo", "Tianyu", ""], ["Xu", "Chang", ""], ["Huang", "Jiajun", ""], ["Wang", "Yunhe", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Tao", "Dacheng", ""]]}, {"id": "2002.01169", "submitter": "Zhen Peng", "authors": "Zhen Peng, Wenbing Huang, Minnan Luo, Qinghua Zheng, Yu Rong, Tingyang\n  Xu, Junzhou Huang", "title": "Graph Representation Learning via Graphical Mutual Information\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The richness in the content of various information networks such as social\nnetworks and communication networks provides the unprecedented potential for\nlearning high-quality expressive representations without external supervision.\nThis paper investigates how to preserve and extract the abundant information\nfrom graph-structured data into embedding space in an unsupervised manner. To\nthis end, we propose a novel concept, Graphical Mutual Information (GMI), to\nmeasure the correlation between input graphs and high-level hidden\nrepresentations. GMI generalizes the idea of conventional mutual information\ncomputations from vector space to the graph domain where measuring mutual\ninformation from two aspects of node features and topological structure is\nindispensable. GMI exhibits several benefits: First, it is invariant to the\nisomorphic transformation of input graphs---an inevitable constraint in many\nexisting graph representation learning algorithms; Besides, it can be\nefficiently estimated and maximized by current mutual information estimation\nmethods such as MINE; Finally, our theoretical analysis confirms its\ncorrectness and rationality. With the aid of GMI, we develop an unsupervised\nlearning model trained by maximizing GMI between the input and output of a\ngraph neural encoder. Considerable experiments on transductive as well as\ninductive node classification and link prediction demonstrate that our method\noutperforms state-of-the-art unsupervised counterparts, and even sometimes\nexceeds the performance of supervised ones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:33:49 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Peng", "Zhen", ""], ["Huang", "Wenbing", ""], ["Luo", "Minnan", ""], ["Zheng", "Qinghua", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "2002.01171", "submitter": "Aung Aung Phyo Wai", "authors": "Aung Aung Phyo Wai, Yangsong Zhang, Heng Guo, Ying Chi, Lei Zhang,\n  Xian-Sheng Hua, Seong Whan Lee and Cuntai Guan", "title": "Towards a Fast Steady-State Visual Evoked Potentials (SSVEP)\n  Brain-Computer Interface (BCI)", "comments": "Further improvements or modifications required to algorithm design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady-state visual evoked potentials (SSVEP) brain-computer interface (BCI)\nprovides reliable responses leading to high accuracy and information\nthroughput. But achieving high accuracy typically requires a relatively long\ntime window of one second or more. Various methods were proposed to improve\nsub-second response accuracy through subject-specific training and calibration.\nSubstantial performance improvements were achieved with tedious calibration and\nsubject-specific training; resulting in the user's discomfort. So, we propose a\ntraining-free method by combining spatial-filtering and temporal alignment\n(CSTA) to recognize SSVEP responses in sub-second response time. CSTA exploits\nlinear correlation and non-linear similarity between steady-state responses and\nstimulus templates with complementary fusion to achieve desirable performance\nimprovements. We evaluated the performance of CSTA in terms of accuracy and\nInformation Transfer Rate (ITR) in comparison with both training-based and\ntraining-free methods using two SSVEP data-sets. We observed that CSTA achieves\nthe maximum mean accuracy of 97.43$\\pm$2.26 % and 85.71$\\pm$13.41 % with\nfour-class and forty-class SSVEP data-sets respectively in sub-second response\ntime in offline analysis. CSTA yields significantly higher mean performance\n(p<0.001) than the training-free method on both data-sets. Compared with\ntraining-based methods, CSTA shows 29.33$\\pm$19.65 % higher mean accuracy with\nstatistically significant differences in time window less than 0.5 s. In longer\ntime windows, CSTA exhibits either better or comparable performance though not\nstatistically significantly better than training-based methods. We show that\nthe proposed method brings advantages of subject-independent SSVEP\nclassification without requiring training while enabling high target\nrecognition performance in sub-second response time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:48:36 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 05:40:04 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Wai", "Aung Aung Phyo", ""], ["Zhang", "Yangsong", ""], ["Guo", "Heng", ""], ["Chi", "Ying", ""], ["Zhang", "Lei", ""], ["Hua", "Xian-Sheng", ""], ["Lee", "Seong Whan", ""], ["Guan", "Cuntai", ""]]}, {"id": "2002.01180", "submitter": "Arun Pandey", "authors": "Arun Pandey, Joachim Schreurs, Johan A. K. Suykens", "title": "Robust Generative Restricted Kernel Machines using Weighted Conjugate\n  Feature Duality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in generative models has grown tremendously in the past decade.\nHowever, their training performance can be adversely affected by contamination,\nwhere outliers are encoded in the representation of the model. This results in\nthe generation of noisy data. In this paper, we introduce weighted conjugate\nfeature duality in the framework of Restricted Kernel Machines (RKMs). The RKM\nformulation allows for an easy integration of methods from classical robust\nstatistics. This formulation is used to fine-tune the latent space of\ngenerative RKMs using a weighting function based on the Minimum Covariance\nDeterminant, which is a highly robust estimator of multivariate location and\nscatter. Experiments show that the weighted RKM is capable of generating clean\nimages when contamination is present in the training data. We further show that\nthe robust method also preserves uncorrelated feature learning through\nqualitative and quantitative experiments on standard datasets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:23:25 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:53:39 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 14:35:30 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pandey", "Arun", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.01182", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "Learning bounded subsets of $L_p$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning problems in which the underlying class is a bounded subset\nof $L_p$ and the target $Y$ belongs to $L_p$. Previously, minimax sample\ncomplexity estimates were known under such boundedness assumptions only when\n$p=\\infty$. We present a sharp sample complexity estimate that holds for any $p\n> 4$. It is based on a learning procedure that is suited for heavy-tailed\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:25:34 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "2002.01197", "submitter": "Etienne Boursier", "authors": "Etienne Boursier and Vianney Perchet", "title": "Selfish Robustness and Equilibria in Multi-Player Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by cognitive radios, stochastic multi-player multi-armed bandits\ngained a lot of interest recently. In this class of problems, several players\nsimultaneously pull arms and encounter a collision - with 0 reward - if some of\nthem pull the same arm at the same time. While the cooperative case where\nplayers maximize the collective reward (obediently following some fixed\nprotocol) has been mostly considered, robustness to malicious players is a\ncrucial and challenging concern. Existing approaches consider only the case of\nadversarial jammers whose objective is to blindly minimize the collective\nreward. We shall consider instead the more natural class of selfish players\nwhose incentives are to maximize their individual rewards, potentially at the\nexpense of the social welfare. We provide the first algorithm robust to selfish\nplayers (a.k.a. Nash equilibrium) with a logarithmic regret, when the arm\nperformance is observed. When collisions are also observed, Grim Trigger type\nof strategies enable some implicit communication-based algorithms and we\nconstruct robust algorithms in two different settings: the homogeneous (with a\nregret comparable to the centralized optimal one) and heterogeneous cases (for\nan adapted and relevant notion of regret). We also provide impossibility\nresults when only the reward is observed or when arm means vary arbitrarily\namong players.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 09:50:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 08:02:43 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Boursier", "Etienne", ""], ["Perchet", "Vianney", ""]]}, {"id": "2002.01207", "submitter": "Kareem Darwish", "authors": "Kareem Darwish, Ahmed Abdelali, Hamdy Mubarak, Mohamed Eldesouki", "title": "Arabic Diacritic Recovery Using a Feature-Rich biLSTM Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diacritics (short vowels) are typically omitted when writing Arabic text, and\nreaders have to reintroduce them to correctly pronounce words. There are two\ntypes of Arabic diacritics: the first are core-word diacritics (CW), which\nspecify the lexical selection, and the second are case endings (CE), which\ntypically appear at the end of the word stem and generally specify their\nsyntactic roles. Recovering CEs is relatively harder than recovering core-word\ndiacritics due to inter-word dependencies, which are often distant. In this\npaper, we use a feature-rich recurrent neural network model that uses a variety\nof linguistic and surface-level features to recover both core word diacritics\nand case endings. Our model surpasses all previous state-of-the-art systems\nwith a CW error rate (CWER) of 2.86\\% and a CE error rate (CEER) of 3.7% for\nModern Standard Arabic (MSA) and CWER of 2.2% and CEER of 2.5% for Classical\nArabic (CA). When combining diacritized word cores with case endings, the\nresultant word error rate is 6.0% and 4.3% for MSA and CA respectively. This\nhighlights the effectiveness of feature engineering for such deep neural\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 10:09:42 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Darwish", "Kareem", ""], ["Abdelali", "Ahmed", ""], ["Mubarak", "Hamdy", ""], ["Eldesouki", "Mohamed", ""]]}, {"id": "2002.01222", "submitter": "Ricardo Vinuesa", "authors": "Luca Guastoni, Prem A. Srinivasan, Hossein Azizpour, Philipp Schlatter\n  and Ricardo Vinuesa", "title": "On the use of recurrent neural networks for predictions of turbulent\n  flows", "comments": "Conference paper presented at 11th International Symposium on\n  Turbulence and Shear Flow Phenomena (TSFP11) at Southampton, UK, July 30 to\n  August 2, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the prediction capabilities of recurrent neural networks are\nassessed in the low-order model of near-wall turbulence by Moehlis {\\it et al.}\n(New J. Phys. {\\bf 6}, 56, 2004). Our results show that it is possible to\nobtain excellent predictions of the turbulence statistics and the dynamic\nbehavior of the flow with properly trained long short-term memory (LSTM)\nnetworks, leading to relative errors in the mean and the fluctuations below\n$1\\%$. We also observe that using a loss function based only on the\ninstantaneous predictions of the flow may not lead to the best predictions in\nterms of turbulence statistics, and it is necessary to define a stopping\ncriterion based on the computed statistics. Furthermore, more sophisticated\nloss functions, including not only the instantaneous predictions but also the\naveraged behavior of the flow, may lead to much faster neural network training.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:01:43 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Guastoni", "Luca", ""], ["Srinivasan", "Prem A.", ""], ["Azizpour", "Hossein", ""], ["Schlatter", "Philipp", ""], ["Vinuesa", "Ricardo", ""]]}, {"id": "2002.01227", "submitter": "Xi Chen", "authors": "Xi Chen, Bo Kang, Jefrey Lijffijt and Tijl De Bie", "title": "ALPINE: Active Link Prediction using Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems can be formalized as predicting links in a partially\nobserved network. Examples include Facebook friendship suggestions,\nconsumer-product recommendations, and the identification of hidden interactions\nbetween actors in a crime network. Several link prediction algorithms, notably\nthose recently introduced using network embedding, are capable of doing this by\njust relying on the observed part of the network. Often, the link status of a\nnode pair can be queried, which can be used as additional information by the\nlink prediction algorithm. Unfortunately, such queries can be expensive or\ntime-consuming, mandating the careful consideration of which node pairs to\nquery. In this paper we estimate the improvement in link prediction accuracy\nafter querying any particular node pair, to use in an active learning setup.\nSpecifically, we propose ALPINE (Active Link Prediction usIng Network\nEmbedding), the first method to achieve this for link prediction based on\nnetwork embedding. To this end, we generalized the notion of V-optimality from\nexperimental design to this setting, as well as more basic active learning\nheuristics originally developed in standard classification settings. Empirical\nresults on real data show that ALPINE is scalable, and boosts link prediction\naccuracy with far fewer queries.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:09:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Chen", "Xi", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.01238", "submitter": "Arunima Banerjee Dr.", "authors": "Prem Prakash, Arunima Banerjee, Pavan Kumar Perepu", "title": "Determination of the relative inclination and the viewing angle of an\n  interacting pair of galaxies using convolutional neural networks", "comments": "13 pages, 11 Figures, 15 tables (Accepted for publication in the\n  MNRAS)", "journal-ref": null, "doi": "10.1093/mnras/staa2109", "report-no": null, "categories": "astro-ph.GA cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing dynamical models for interacting pair of galaxies as constrained\nby their observed structure and kinematics crucially depends on the correct\nchoice of the values of the relative inclination ($i$) between their galactic\nplanes as well as the viewing angle ($\\theta$), the angle between the line of\nsight and the normal to the plane of their orbital motion. We construct Deep\nConvolutional Neural Network (DCNN) models to determine the relative\ninclination ($i$) and the viewing angle ($\\theta$) of interacting galaxy pairs,\nusing N-body $+$ Smoothed Particle Hydrodynamics (SPH) simulation data from the\nGALMER database for training the same. In order to classify galaxy pairs based\non their $i$ values only, we first construct DCNN models for a (a) 2-class (\n$i$ = 0 $^{\\circ}$, 45$^{\\circ}$ ) and (b) 3-class ($i = 0^{\\circ}, 45^{\\circ}\n\\text{ and } 90^{\\circ}$) classification, obtaining $F_1$ scores of 99% and 98%\nrespectively. Further, for a classification based on both $i$ and $\\theta$\nvalues, we develop a DCNN model for a 9-class classification ($(i,\\theta) \\sim\n(0^{\\circ},15^{\\circ}) ,(0^{\\circ},45^{\\circ}), (0^{\\circ},90^{\\circ}),\n(45^{\\circ},15^{\\circ}), (45^{\\circ}, 45^{\\circ}), (45^{\\circ}, 90^{\\circ}),\n(90^{\\circ}, 15^{\\circ}), (90^{\\circ}, 45^{\\circ}), (90^{\\circ},90^{\\circ})$),\nand the $F_1$ score was 97$\\%$. Finally, we tested our 2-class model on real\ndata of interacting galaxy pairs from the Sloan Digital Sky Survey (SDSS) DR15,\nand achieve an $F_1$ score of 78%. Our DCNN models could be further extended to\ndetermine additional parameters needed to model dynamics of interacting galaxy\npairs, which is currently accomplished by trial and error method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:54:07 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 06:42:42 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Prakash", "Prem", ""], ["Banerjee", "Arunima", ""], ["Perepu", "Pavan Kumar", ""]]}, {"id": "2002.01240", "submitter": "Michael Burke Dr", "authors": "Michael Burke, Katie Lu, Daniel Angelov, Art\\=uras Strai\\v{z}ys, Craig\n  Innes, Kartic Subr, Subramanian Ramamoorthy", "title": "Learning rewards for robotic ultrasound scanning using probabilistic\n  temporal ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a common class of problems where a robot learns to\nperform a discovery task based on example solutions, or \\emph{human\ndemonstrations}. As an example, this work considers the problem of ultrasound\nscanning, where a demonstration involves an expert adaptively searching for a\nsatisfactory view of internal organs, vessels or tissue and potential anomalies\nwhile maintaining optimal contact between the probe and surface tissue. Such\nproblems are often solved by inferring notional \\emph{rewards} that, when\noptimised for, result in a plan that mimics demonstrations. A pivotal\nassumption, that plans with higher reward should be exponentially more likely,\nleads to the de facto approach for reward inference in robotics. While this\napproach of maximum entropy inverse reinforcement learning leads to a general\nand elegant formulation, it struggles to cope with frequently encountered\nsub-optimal demonstrations. In this paper, we propose an alternative approach\nto cope with the class of problems where sub-optimal demonstrations occur\nfrequently. We hypothesise that, in tasks which require discovery, successive\nstates of any demonstration are progressively more likely to be associated with\na higher reward. We formalise this \\emph{temporal ranking} approach and show\nthat it improves upon maximum-entropy approaches to perform reward inference\nfor autonomous ultrasound scanning, a novel application of learning from\ndemonstration in medical imaging.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 11:58:38 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 13:31:45 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Burke", "Michael", ""], ["Lu", "Katie", ""], ["Angelov", "Daniel", ""], ["Strai\u017eys", "Art\u016bras", ""], ["Innes", "Craig", ""], ["Subr", "Kartic", ""], ["Ramamoorthy", "Subramanian", ""]]}, {"id": "2002.01244", "submitter": "Othniel Konan", "authors": "Othniel J.E.Y. Konan, Amit Kumar Mishra, Stefan Lotz", "title": "Machine Learning Techniques to Detect and Characterise Whistler Radio\n  Waves", "comments": "20 pages, 13 tables, 26 figures, Preliminary work presented at the\n  Machine Learning in Heliophysics hosted in September 2019 in Amsterdam\n  (https://ml-helio.github.io/). Code can be found at\n  (https://github.com/Kojey/MSc-whistler-waves-detector)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Lightning strokes create powerful electromagnetic pulses that routinely cause\nvery low frequency (VLF) waves to propagate across hemispheres along\ngeomagnetic field lines. VLF antenna receivers can be used to detect these\nwhistler waves generated by these lightning strokes. The particular\ntime/frequency dependence of the received whistler wave enables the estimation\nof electron density in the plasmasphere region of the magnetosphere. Therefore\nthe identification and characterisation of whistlers are important tasks to\nmonitor the plasmasphere in real-time and to build large databases of events to\nbe used for statistical studies. The current state of the art in detecting\nwhistler is the Automatic Whistler Detection (AWD) method developed by\nLichtenberger (2009). This method is based on image correlation in 2 dimensions\nand requires significant computing hardware situated at the VLF receiver\nantennas (e.g. in Antarctica). The aim of this work is to develop a machine\nlearning-based model capable of automatically detecting whistlers in the data\nprovided by the VLF receivers. The approach is to use a combination of image\nclassification and localisation on the spectrogram data generated by the VLF\nreceivers to identify and localise each whistler. The data at hand has around\n2300 events identified by AWD at SANAE and Marion and will be used as training,\nvalidation, and testing data. Three detector designs have been proposed. The\nfirst one using a similar method to AWD, the second using image classification\non regions of interest extracted from a spectrogram, and the last one using\nYOLO, the current state of the art in object detection. It has been shown that\nthese detectors can achieve a misdetection and false alarm of less than 15% on\nMarion's dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:05:44 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Konan", "Othniel J. E. Y.", ""], ["Mishra", "Amit Kumar", ""], ["Lotz", "Stefan", ""]]}, {"id": "2002.01245", "submitter": "Kuruge Darshana Abeyrathna", "authors": "K. Darshana Abeyrathna, Ole-Christoffer Granmo, Morten Goodwin", "title": "A Regression Tsetlin Machine with Integer Weighted Clauses for Compact\n  Pattern Representation", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Regression Tsetlin Machine (RTM) addresses the lack of interpretability\nimpeding state-of-the-art nonlinear regression models. It does this by using\nconjunctive clauses in propositional logic to capture the underlying non-linear\nfrequent patterns in the data. These, in turn, are combined into a continuous\noutput through summation, akin to a linear regression function, however, with\nnon-linear components and unity weights. Although the RTM has solved non-linear\nregression problems with competitive accuracy, the resolution of the output is\nproportional to the number of clauses employed. This means that computation\ncost increases with resolution. To reduce this problem, we here introduce\ninteger weighted RTM clauses. Our integer weighted clause is a compact\nrepresentation of multiple clauses that capture the same sub-pattern-N\nrepeating clauses are turned into one, with an integer weight N. This reduces\ncomputation cost N times, and increases interpretability through a sparser\nrepresentation. We further introduce a novel learning scheme that allows us to\nsimultaneously learn both the clauses and their weights, taking advantage of\nso-called stochastic searching on the line. We evaluate the potential of the\ninteger weighted RTM empirically using six artificial datasets. The results\nshow that the integer weighted RTM is able to acquire on par or better accuracy\nusing significantly less computational resources compared to regular RTMs. We\nfurther show that integer weights yield improved accuracy over real-valued\nones.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:06:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Abeyrathna", "K. Darshana", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "2002.01256", "submitter": "Blerta Lindqvist", "authors": "Blerta Lindqvist, Rauf Izmailov", "title": "Minimax Defense against Gradient-based Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art adversarial attacks are aimed at neural network classifiers.\nBy default, neural networks use gradient descent to minimize their loss\nfunction. The gradient of a classifier's loss function is used by\ngradient-based adversarial attacks to generate adversarially perturbed images.\nWe pose the question whether another type of optimization could give neural\nnetwork classifiers an edge. Here, we introduce a novel approach that uses\nminimax optimization to foil gradient-based adversarial attacks. Our minimax\nclassifier is the discriminator of a generative adversarial network (GAN) that\nplays a minimax game with the GAN generator. In addition, our GAN generator\nprojects all points onto a manifold that is different from the original\nmanifold since the original manifold might be the cause of adversarial attacks.\nTo measure the performance of our minimax defense, we use adversarial attacks -\nCarlini Wagner (CW), DeepFool, Fast Gradient Sign Method (FGSM) - on three\ndatasets: MNIST, CIFAR-10 and German Traffic Sign (TRAFFIC). Against CW\nattacks, our minimax defense achieves 98.07% (MNIST-default 98.93%), 73.90%\n(CIFAR-10-default 83.14%) and 94.54% (TRAFFIC-default 96.97%). Against DeepFool\nattacks, our minimax defense achieves 98.87% (MNIST), 76.61% (CIFAR-10) and\n94.57% (TRAFFIC). Against FGSM attacks, we achieve 97.01% (MNIST), 76.79%\n(CIFAR-10) and 81.41% (TRAFFIC). Our Minimax adversarial approach presents a\nsignificant shift in defense strategy for neural network classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 12:33:13 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lindqvist", "Blerta", ""], ["Izmailov", "Rauf", ""]]}, {"id": "2002.01268", "submitter": "Alexey Naumov", "authors": "Maxim Kaledin, Eric Moulines, Alexey Naumov, Vladislav Tadic, Hoi-To\n  Wai", "title": "Finite Time Analysis of Linear Two-timescale Stochastic Approximation\n  with Markovian Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear two-timescale stochastic approximation (SA) scheme is an important\nclass of algorithms which has become popular in reinforcement learning (RL),\nparticularly for the policy evaluation problem. Recently, a number of works\nhave been devoted to establishing the finite time analysis of the scheme,\nespecially under the Markovian (non-i.i.d.) noise settings that are ubiquitous\nin practice. In this paper, we provide a finite-time analysis for linear two\ntimescale SA. Our bounds show that there is no discrepancy in the convergence\nrate between Markovian and martingale noise, only the constants are affected by\nthe mixing time of the Markov chain. With an appropriate step size schedule,\nthe transient term in the expected error bound is $o(1/k^c)$ and the\nsteady-state term is ${\\cal O}(1/k)$, where $c>1$ and $k$ is the iteration\nnumber. Furthermore, we present an asymptotic expansion of the expected error\nwith a matching lower bound of $\\Omega(1/k)$. A simple numerical experiment is\npresented to support our theory.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 13:03:17 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kaledin", "Maxim", ""], ["Moulines", "Eric", ""], ["Naumov", "Alexey", ""], ["Tadic", "Vladislav", ""], ["Wai", "Hoi-To", ""]]}, {"id": "2002.01276", "submitter": "Wenyang Hu", "authors": "Wenyang Hu, Xiaocong Cai, Jun Hou, Shuai Yi, Zhiping Lin", "title": "GTC: Guided Training of CTC Towards Efficient and Accurate Scene Text\n  Recognition", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist Temporal Classification (CTC) and attention mechanism are two\nmain approaches used in recent scene text recognition works. Compared with\nattention-based methods, CTC decoder has a much shorter inference time, yet a\nlower accuracy. To design an efficient and effective model, we propose the\nguided training of CTC (GTC), where CTC model learns a better alignment and\nfeature representations from a more powerful attentional guidance. With the\nbenefit of guided training, CTC model achieves robust and accurate prediction\nfor both regular and irregular scene text while maintaining a fast inference\nspeed. Moreover, to further leverage the potential of CTC decoder, a graph\nconvolutional network (GCN) is proposed to learn the local correlations of\nextracted features. Extensive experiments on standard benchmarks demonstrate\nthat our end-to-end model achieves a new state-of-the-art for regular and\nirregular scene text recognition and needs 6 times shorter inference time than\nattentionbased methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 13:26:14 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Hu", "Wenyang", ""], ["Cai", "Xiaocong", ""], ["Hou", "Jun", ""], ["Yi", "Shuai", ""], ["Lin", "Zhiping", ""]]}, {"id": "2002.01281", "submitter": "Cyprien Ruffino", "authors": "Cyprien Ruffino and Romain H\\'erault and Eric Laloy and Gilles Gasso", "title": "Pixel-wise Conditioned Generative Adversarial Networks for Image\n  Synthesis and Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have proven successful for\nunsupervised image generation. Several works have extended GANs to image\ninpainting by conditioning the generation with parts of the image to be\nreconstructed. Despite their success, these methods have limitations in\nsettings where only a small subset of the image pixels is known beforehand. In\nthis paper we investigate the effectiveness of conditioning GANs when very few\npixel values are provided. We propose a modelling framework which results in\nadding an explicit cost term to the GAN objective function to enforce\npixel-wise conditioning. We investigate the influence of this regularization\nterm on the quality of the generated images and the fulfillment of the given\npixel constraints. Using the recent PacGAN technique, we ensure that we keep\ndiversity in the generated samples. Conducted experiments on FashionMNIST show\nthat the regularization term effectively controls the trade-off between quality\nof the generated images and the conditioning. Experimental evaluation on the\nCIFAR-10 and CelebA datasets evidences that our method achieves accurate\nresults both visually and quantitatively in term of Fr\\'echet Inception\nDistance, while still enforcing the pixel conditioning. We also evaluate our\nmethod on a texture image generation task using fully-convolutional networks.\nAs a final contribution, we apply the method to a classical geological\nsimulation application.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 13:49:15 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ruffino", "Cyprien", ""], ["H\u00e9rault", "Romain", ""], ["Laloy", "Eric", ""], ["Gasso", "Gilles", ""]]}, {"id": "2002.01306", "submitter": "Nikolai Zolotykh", "authors": "Sergey Sidorov and Nikolai Zolotykh", "title": "Linear and Fisher Separability of Random Points in the d-dimensional\n  Spherical Layer", "comments": "6 pages, 3 figures IJCNN 2020 Accepted", "journal-ref": null, "doi": "10.3390/e22111281", "report-no": null, "categories": "math.PR cs.LG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic separation theorems play important role in high-dimensional data\nanalysis and machine learning. It turns out that in high dimension any point of\na random set of points can be separated from other points by a hyperplane with\nhigh probability even if the number of points is exponential in terms of\ndimension. This and similar facts can be used for constructing correctors for\nartificial intelligent systems, for determining an intrinsic dimension of data\nand for explaining various natural intelligence phenomena. In this paper, we\nrefine the estimations for the number of points and for the probability in\nstochastic separation theorems, thereby strengthening some results obtained\nearlier. We propose the boundaries for linear and Fisher separability, when the\npoints are drawn randomly, independently and uniformly from a $d$-dimensional\nspherical layer. These results allow us to better outline the applicability\nlimits of the stochastic separation theorems in applications.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 18:24:06 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 10:25:03 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sidorov", "Sergey", ""], ["Zolotykh", "Nikolai", ""]]}, {"id": "2002.01322", "submitter": "Kevin Kilgour", "authors": "James Lin, Kevin Kilgour, Dominik Roblek, Matthew Sharifi", "title": "Training Keyword Spotters with Limited and Synthesized Speech Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of low power speech-enabled devices, there is a growing demand\nto quickly produce models for recognizing arbitrary sets of keywords. As with\nmany machine learning tasks, one of the most challenging parts in the model\ncreation process is obtaining a sufficient amount of training data. In this\npaper, we explore the effectiveness of synthesized speech data in training\nsmall, spoken term detection models of around 400k parameters. Instead of\ntraining such models directly on the audio or low level features such as MFCCs,\nwe use a pre-trained speech embedding model trained to extract useful features\nfor keyword spotting models. Using this speech embedding, we show that a model\nwhich detects 10 keywords when trained on only synthetic speech is equivalent\nto a model trained on over 500 real examples. We also show that a model without\nour speech embeddings would need to be trained on over 4000 real examples to\nreach the same accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:50:42 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Lin", "James", ""], ["Kilgour", "Kevin", ""], ["Roblek", "Dominik", ""], ["Sharifi", "Matthew", ""]]}, {"id": "2002.01323", "submitter": "Vikramjit Mitra", "authors": "Vasudha Kowtha, Vikramjit Mitra, Chris Bartels, Erik Marchi, Sue\n  Booker, William Caruso, Sachin Kajarekar, Devang Naik", "title": "Detecting Emotion Primitives from Speech and their use in discerning\n  Categorical Emotions", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion plays an essential role in human-to-human communication, enabling us\nto convey feelings such as happiness, frustration, and sincerity. While modern\nspeech technologies rely heavily on speech recognition and natural language\nunderstanding for speech content understanding, the investigation of vocal\nexpression is increasingly gaining attention. Key considerations for building\nrobust emotion models include characterizing and improving the extent to which\na model, given its training data distribution, is able to generalize to unseen\ndata conditions. This work investigated a long-shot-term memory (LSTM) network\nand a time convolution - LSTM (TC-LSTM) to detect primitive emotion attributes\nsuch as valence, arousal, and dominance, from speech. It was observed that\ntraining with multiple datasets and using robust features improved the\nconcordance correlation coefficient (CCC) for valence, by 30\\% with respect to\nthe baseline system. Additionally, this work investigated how emotion\nprimitives can be used to detect categorical emotions such as happiness,\ndisgust, contempt, anger, and surprise from neutral speech, and results\nindicated that arousal, followed by dominance was a better detector of such\nemotions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 03:11:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Kowtha", "Vasudha", ""], ["Mitra", "Vikramjit", ""], ["Bartels", "Chris", ""], ["Marchi", "Erik", ""], ["Booker", "Sue", ""], ["Caruso", "William", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""]]}, {"id": "2002.01325", "submitter": "Jae-Hyun Park", "authors": "Jae-Hyun Park, Woo-Jeoung Nam, Seong-Whan Lee", "title": "A Two-Stream Symmetric Network with Bidirectional Ensemble for Aerial\n  Image Matching", "comments": "20pages", "journal-ref": "Remote Sens. 12(3) (2020) 465-484", "doi": "10.3390/rs12030465", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel method to precisely match two aerial images\nthat were obtained in different environments via a two-stream deep network. By\ninternally augmenting the target image, the network considers the two-stream\nwith the three input images and reflects the additional augmented pair in the\ntraining. As a result, the training process of the deep network is regularized\nand the network becomes robust for the variance of aerial images. Furthermore,\nwe introduce an ensemble method that is based on the bidirectional network,\nwhich is motivated by the isomorphic nature of the geometric transformation. We\nobtain two global transformation parameters without any additional network or\nparameters, which alleviate asymmetric matching results and enable significant\nimprovement in performance by fusing two outcomes. For the experiment, we adopt\naerial images from Google Earth and the International Society for\nPhotogrammetry and Remote Sensing (ISPRS). To quantitatively assess our result,\nwe apply the probability of correct keypoints (PCK) metric, which measures the\ndegree of matching. The qualitative and quantitative results show the sizable\ngap of performance compared to the conventional methods for matching the aerial\nimages. All code and our trained model, as well as the dataset are available\nonline.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:38:18 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Park", "Jae-Hyun", ""], ["Nam", "Woo-Jeoung", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2002.01335", "submitter": "Abhinav Gupta", "authors": "Agnieszka S{\\l}owik, Abhinav Gupta, William L. Hamilton, Mateja\n  Jamnik, Sean B. Holden, Christopher Pal", "title": "Structural Inductive Biases in Emergent Communication", "comments": "The first two authors contributed equally. Poster presented at CogSci\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to communicate, humans flatten a complex representation of ideas and\ntheir attributes into a single word or a sentence. We investigate the impact of\nrepresentation learning in artificial agents by developing graph referential\ngames. We empirically show that agents parametrized by graph neural networks\ndevelop a more compositional language compared to bag-of-words and sequence\nmodels, which allows them to systematically generalize to new combinations of\nfamiliar features.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 14:59:08 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 18:57:45 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 22:05:34 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 04:13:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["S\u0142owik", "Agnieszka", ""], ["Gupta", "Abhinav", ""], ["Hamilton", "William L.", ""], ["Jamnik", "Mateja", ""], ["Holden", "Sean B.", ""], ["Pal", "Christopher", ""]]}, {"id": "2002.01336", "submitter": "Feng Wei", "authors": "Feng Wei and Uyen Trang Nguyen", "title": "Twitter Bot Detection Using Bidirectional Long Short-term Memory Neural\n  Networks and Word Embeddings", "comments": "IEEE TPS 2019. arXiv admin note: text overlap with arXiv:1703.04482\n  by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a web application playing dual roles of online social networking\nand micro-blogging. The popularity and open structure of Twitter have attracted\na large number of automated programs, known as bots. Legitimate bots generate a\nlarge amount of benign contextual content, i.e., tweets delivering news and\nupdating feeds, while malicious bots spread spam or malicious contents. To\nassist human users in identifying who they are interacting with, this paper\nfocuses on the classification of human and spambot accounts on Twitter, by\nemploying recurrent neural networks, specifically bidirectional Long Short-term\nMemory (BiLSTM), to efficiently capture features across tweets. To the best of\nour knowledge, our work is the first that develops a recurrent neural model\nwith word embeddings to distinguish Twitter bots from human accounts, that\nrequires no prior knowledge or assumption about users' profiles, friendship\nnetworks, or historical behavior on the target account. Moreover, our model\ndoes not require any handcrafted features. The preliminary simulation results\nare very encouraging. Experiments on the cresci-2017 dataset show that our\napproach can achieve competitive performance compared with existing\nstate-of-the-art bot detection systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:07:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Wei", "Feng", ""], ["Nguyen", "Uyen Trang", ""]]}, {"id": "2002.01365", "submitter": "Shangmin Guo", "authors": "Yi Ren, Shangmin Guo, Matthieu Labeau, Shay B. Cohen, Simon Kirby", "title": "Compositional Languages Emerge in a Neural Iterated Learning Model", "comments": "accepted by ICLR-2020", "journal-ref": "ICLR-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of compositionality, which enables natural language to\nrepresent complex concepts via a structured combination of simpler ones, allows\nus to convey an open-ended set of messages using a limited vocabulary. If\ncompositionality is indeed a natural property of language, we may expect it to\nappear in communication protocols that are created by neural agents in language\ngames. In this paper, we propose an effective neural iterated learning (NIL)\nalgorithm that, when applied to interacting neural agents, facilitates the\nemergence of a more structured type of language. Indeed, these languages\nprovide learning speed advantages to neural agents during training, which can\nbe incrementally amplified via NIL. We provide a probabilistic model of NIL and\nan explanation of why the advantage of compositional language exist. Our\nexperiments confirm our analysis, and also demonstrate that the emerged\nlanguages largely improve the generalizing power of the neural agent\ncommunication.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:19:09 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:22:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ren", "Yi", ""], ["Guo", "Shangmin", ""], ["Labeau", "Matthieu", ""], ["Cohen", "Shay B.", ""], ["Kirby", "Simon", ""]]}, {"id": "2002.01368", "submitter": "Emile Engelbrecht Mr.", "authors": "Emile R. Engelbrecht, Johan A. du Preez", "title": "Semi-supervised learning with an open augmenting unknown class for\n  cost-effective training and reliable classifications", "comments": "9 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to (a) train off partially labelled datasets and (b) ensure\nresulting networks separate data outside the domain of interest hugely expands\nthe practical and cost-effective applicability of neural network classifiers.\nWe design a classifier based off generative adversarial networks (GANs) that\ntrains off a practical and cost-saving semi-supervised criteria which,\nspecifically, allows novel classes within the unlabelled training set.\nFurthermore, we ensure the resulting classifier is capable of absolute novel\nclass detection, be these from the semi-supervised unlabelled training set or a\nso-called open set. Results are both state-of-the-art and a first of its kind.\nWe argue this technique greatly decreases training cost in respect to labelling\nwhile greatly improving the reliability of classifications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:32:23 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 11:39:19 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 09:31:35 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Engelbrecht", "Emile R.", ""], ["Preez", "Johan A. du", ""]]}, {"id": "2002.01370", "submitter": "Wenzel Pilar Von Pilchau", "authors": "Wenzel Baron Pilar von Pilchau and Anthony Stein and J\\\"org H\\\"ahner", "title": "Bootstrapping a DQN Replay Memory with Synthetic Experiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important component of many Deep Reinforcement Learning algorithms is the\nExperience Replay which serves as a storage mechanism or memory of made\nexperiences. These experiences are used for training and help the agent to\nstably find the perfect trajectory through the problem space. The classic\nExperience Replay however makes only use of the experiences it actually made,\nbut the stored samples bear great potential in form of knowledge about the\nproblem that can be extracted. We present an algorithm that creates synthetic\nexperiences in a nondeterministic discrete environment to assist the learner.\nThe Interpolated Experience Replay is evaluated on the FrozenLake environment\nand we show that it can support the agent to learn faster and even better than\nthe classic version.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 15:36:36 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["von Pilchau", "Wenzel Baron Pilar", ""], ["Stein", "Anthony", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.01406", "submitter": "Mihaela Dimovska", "authors": "Mihaela Dimovska, Travis Johnston, Catherine D. Schuman, J. Parker\n  Mitchell, Thomas E. Potok", "title": "Multi-Objective Optimization for Size and Resilience of Spiking Neural\n  Networks", "comments": "Will appear in proceedings of 2019 IEEE 10th Annual Ubiquitous\n  Computing, Electronics & Mobile Communication Conference (UEMCON). IEEE\n  Catalog Number: CFP19G31-USB ISBN: 978-1-7281-3884-8 pg. 431-438", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the connectivity mechanisms in the brain, neuromorphic computing\narchitectures model Spiking Neural Networks (SNNs) in silicon. As such,\nneuromorphic architectures are designed and developed with the goal of having\nsmall, low power chips that can perform control and machine learning tasks.\nHowever, the power consumption of the developed hardware can greatly depend on\nthe size of the network that is being evaluated on the chip. Furthermore, the\naccuracy of a trained SNN that is evaluated on chip can change due to voltage\nand current variations in the hardware that perturb the learned weights of the\nnetwork. While efforts are made on the hardware side to minimize those\nperturbations, a software based strategy to make the deployed networks more\nresilient can help further alleviate that issue. In this work, we study Spiking\nNeural Networks in two neuromorphic architecture implementations with the goal\nof decreasing their size, while at the same time increasing their resiliency to\nhardware faults. We leverage an evolutionary algorithm to train the SNNs and\npropose a multiobjective fitness function to optimize the size and resiliency\nof the SNN. We demonstrate that this strategy leads to well-performing,\nsmall-sized networks that are more resilient to hardware faults.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 16:58:25 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Dimovska", "Mihaela", ""], ["Johnston", "Travis", ""], ["Schuman", "Catherine D.", ""], ["Mitchell", "J. Parker", ""], ["Potok", "Thomas E.", ""]]}, {"id": "2002.01408", "submitter": "Eran Kaufman Dr.", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich", "title": "Apportioned Margin Approach for Cost Sensitive Large Margin Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of cost sensitive multiclass classification, where we\nwould like to increase the sensitivity of an important class at the expense of\na less important one. We adopt an {\\em apportioned margin} framework to address\nthis problem, which enables an efficient margin shift between classes that\nshare the same boundary. The decision boundary between all pairs of classes\ndivides the margin between them in accordance to a given prioritization vector,\nwhich yields a tighter error bound for the important classes while also\nreducing the overall out-of-sample error. In addition to demonstrating an\nefficient implementation of our framework, we derive generalization bounds,\ndemonstrate Fisher consistency, adapt the framework to Mercer's kernel and to\nneural networks, and report promising empirical results on all accounts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:00:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""]]}, {"id": "2002.01411", "submitter": "Jianyuan Yu", "authors": "Jianyuan Yu, R. Michael Buehrer", "title": "Centimeter-Level Indoor Localization using Channel State Information\n  with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern techniques in the Internet of Things or autonomous driving require\nmore accuracy positioning ever. Classic location techniques mainly adapt to\noutdoor scenarios, while they do not meet the requirement of indoor cases with\nmultiple paths. Meanwhile as a feature robust to noise and time variations,\nChannel State Information (CSI) has shown its advantages over Received Signal\nStrength Indicator (RSSI) at more accurate positioning. To this end, this paper\nproposes the neural network method to estimate the centimeter-level indoor\npositioning with real CSI data collected from linear antennas. It utilizes an\namplitude of channel response or a correlation matrix as the input, which can\nhighly reduce the data size and suppress the noise. Also, it makes use of the\nconsistency in the user motion trajectory via Recurrent Neural Network (RNN)\nand signal-noise ratio (SNR) information, which can further improve the\nestimation accuracy, especially in small datasize learning. These contributions\nall benefit the efficiency of the neural network, based on the results with\nother classic supervised learning methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:10:18 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Yu", "Jianyuan", ""], ["Buehrer", "R. Michael", ""]]}, {"id": "2002.01412", "submitter": "Neil Mallinar", "authors": "Neil Mallinar, Abhishek Shah, Tin Kam Ho, Rajendra Ugrani, Ayush Gupta", "title": "Iterative Data Programming for Expanding Text Classification Corpora", "comments": "6 pages, 2 figures, In Proceedings of the AAAI Conference on\n  Artificial Intelligence 2020 (IAAI Technical Track: Emerging Papers)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world text classification tasks often require many labeled training\nexamples that are expensive to obtain. Recent advancements in machine teaching,\nspecifically the data programming paradigm, facilitate the creation of training\ndata sets quickly via a general framework for building weak models, also known\nas labeling functions, and denoising them through ensemble learning techniques.\nWe present a fast, simple data programming method for augmenting text data sets\nby generating neighborhood-based weak models with minimal supervision.\nFurthermore, our method employs an iterative procedure to identify sparsely\ndistributed examples from large volumes of unlabeled data. The iterative data\nprogramming techniques improve newer weak models as more labeled data is\nconfirmed with human-in-loop. We show empirical results on sentence\nclassification tasks, including those from a task of improving intent\nrecognition in conversational agents.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:12:43 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mallinar", "Neil", ""], ["Shah", "Abhishek", ""], ["Ho", "Tin Kam", ""], ["Ugrani", "Rajendra", ""], ["Gupta", "Ayush", ""]]}, {"id": "2002.01427", "submitter": "Giles Strong", "authors": "Giles Chatham Strong", "title": "On the impact of selected modern deep-learning techniques to the\n  performance and celerity of classification models in an experimental\n  high-energy physics use case", "comments": "Preprint V4: Fixing typographical error and correcting two plots.\n  Mach. Learn.: Sci. Technol (2020)", "journal-ref": null, "doi": "10.1088/2632-2153/ab983a", "report-no": null, "categories": "physics.data-an cs.LG hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beginning from a basic neural-network architecture, we test the potential\nbenefits offered by a range of advanced techniques for machine learning, in\nparticular deep learning, in the context of a typical classification problem\nencountered in the domain of high-energy physics, using a well-studied dataset:\nthe 2014 Higgs ML Kaggle dataset. The advantages are evaluated in terms of both\nperformance metrics and the time required to train and apply the resulting\nmodels. Techniques examined include domain-specific data-augmentation, learning\nrate and momentum scheduling, (advanced) ensembling in both model-space and\nweight-space, and alternative architectures and connection methods. Following\nthe investigation, we arrive at a model which achieves equal performance to the\nwinning solution of the original Kaggle challenge, whilst being significantly\nquicker to train and apply, and being suitable for use with both GPU and CPU\nhardware setups. These reductions in timing and hardware requirements\npotentially allow the use of more powerful algorithms in HEP analyses, where\nmodels must be retrained frequently, sometimes at short notice, by small groups\nof researchers with limited hardware resources. Additionally, a new wrapper\nlibrary for PyTorch called LUMIN is presented, which incorporates all of the\ntechniques studied.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:29:59 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 16:20:14 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 14:54:56 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 10:29:13 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Strong", "Giles Chatham", ""]]}, {"id": "2002.01428", "submitter": "Vincent Pacelli", "authors": "Vincent Pacelli and Anirudha Majumdar", "title": "Learning Task-Driven Control Policies via Information Bottlenecks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a reinforcement learning approach to synthesizing\ntask-driven control policies for robotic systems equipped with rich sensory\nmodalities (e.g., vision or depth). Standard reinforcement learning algorithms\ntypically produce policies that tightly couple control actions to the entirety\nof the system's state and rich sensor observations. As a consequence, the\nresulting policies can often be sensitive to changes in task-irrelevant\nportions of the state or observations (e.g., changing background colors). In\ncontrast, the approach we present here learns to create a task-driven\nrepresentation that is used to compute control actions. Formally, this is\nachieved by deriving a policy gradient-style algorithm that creates an\ninformation bottleneck between the states and the task-driven representation;\nthis constrains actions to only depend on task-relevant information. We\ndemonstrate our approach in a thorough set of simulation results on multiple\nexamples including a grasping task that utilizes depth images and a\nball-catching task that utilizes RGB images. Comparisons with a standard policy\ngradient approach demonstrate that the task-driven policies produced by our\nalgorithm are often significantly more robust to sensor noise and\ntask-irrelevant changes in the environment.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:50:06 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Pacelli", "Vincent", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2002.01441", "submitter": "Alireza Rezazadeh", "authors": "Alireza Rezazadeh", "title": "A Generalized Flow for B2B Sales Predictive Modeling: An Azure Machine\n  Learning Approach", "comments": null, "journal-ref": null, "doi": "10.3390/forecast2030015", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the outcome of sales opportunities is a core part of successful\nbusiness management. Conventionally, making this prediction has relied mostly\non subjective human evaluations in the process of sales decision making. In\nthis paper, we addressed the problem of forecasting the outcome of business to\nbusiness (B2B) sales by proposing a thorough data-driven Machine Learning (ML)\nworkflow on a cloud-based computing platform: Microsoft Azure Machine Learning\nService (Azure ML). This workflow consists of two pipelines: (1) An ML pipeline\nto train probabilistic predictive models on the historical sales opportunities\ndata. In this pipeline, data is enriched with an extensive feature enhancement\nstep and then used to train an ensemble of ML classification models in\nparallel. (2) A prediction pipeline to utilize the trained ML model and infer\nthe likelihood of winning new sales opportunities along with calculating\noptimal decision boundaries. The effectiveness of the proposed workflow was\nevaluated on a real sales dataset of a major global B2B consulting firm. Our\nresults implied that decision-making based on the ML predictions is more\naccurate and brings a higher monetary value.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:01:24 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 01:00:22 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Rezazadeh", "Alireza", ""]]}, {"id": "2002.01444", "submitter": "Jakub Marecek", "authors": "Quan Zhou and Jakub Marecek", "title": "Proper Learning of Linear Dynamical Systems as a Non-Commutative\n  Polynomial Optimisation Problem", "comments": "27 pages, 6 figures, with additional experiments exploiting sparsity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been much recent progress in forecasting the next observation of a\nlinear dynamical system (LDS), which is known as the improper learning, as well\nas in the estimation of its system matrices, which is known as the proper\nlearning of LDS. We present an approach to proper learning of LDS, which in\nspite of the non-convexity of the problem, guarantees global convergence of\nnumerical solutions to a least-squares estimator. We present promising\ncomputational results.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:08:49 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 21:07:10 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 14:16:42 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Zhou", "Quan", ""], ["Marecek", "Jakub", ""]]}, {"id": "2002.01464", "submitter": "Jiayuan Mao", "authors": "Chi Han, Jiayuan Mao, Chuang Gan, Joshua B. Tenenbaum, Jiajun Wu", "title": "Visual Concept-Metaconcept Learning", "comments": "NeurIPS 2019. First two authors contributed equally. Project page:\n  http://vcml.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans reason with concepts and metaconcepts: we recognize red and green from\nvisual input; we also understand that they describe the same property of\nobjects (i.e., the color). In this paper, we propose the visual\nconcept-metaconcept learner (VCML) for joint learning of concepts and\nmetaconcepts from images and associated question-answer pairs. The key is to\nexploit the bidirectional connection between visual concepts and metaconcepts.\nVisual representations provide grounding cues for predicting relations between\nunseen pairs of concepts. Knowing that red and green describe the same property\nof objects, we generalize to the fact that cube and sphere also describe the\nsame property of objects, since they both categorize the shape of objects.\nMeanwhile, knowledge about metaconcepts empowers visual concept learning from\nlimited, noisy, and even biased data. From just a few examples of purple cubes\nwe can understand a new color purple, which resembles the hue of the cubes\ninstead of the shape of them. Evaluation on both synthetic and real-world\ndatasets validates our claims.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:42:30 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Han", "Chi", ""], ["Mao", "Jiayuan", ""], ["Gan", "Chuang", ""], ["Tenenbaum", "Joshua B.", ""], ["Wu", "Jiajun", ""]]}, {"id": "2002.01490", "submitter": "Matthias C. Caro", "authors": "Matthias C. Caro and Ishaun Datta", "title": "Pseudo-dimension of quantum circuits", "comments": "22 pages, 1 figure; corrected Lemma 3.8, this does not change our\n  results", "journal-ref": "Quantum Mach. Intell. 2, 14 (2020)", "doi": "10.1007/s42484-020-00027-5", "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the expressive power of quantum circuits with the\npseudo-dimension, a measure of complexity for probabilistic concept classes. We\nprove pseudo-dimension bounds on the output probability distributions of\nquantum circuits; the upper bounds are polynomial in circuit depth and number\nof gates. Using these bounds, we exhibit a class of circuit output states out\nof which at least one has exponential state complexity, and moreover\ndemonstrate that quantum circuits of known polynomial size and depth are\nPAC-learnable.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 19:00:13 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 15:03:54 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 08:10:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Caro", "Matthias C.", ""], ["Datta", "Ishaun", ""]]}, {"id": "2002.01523", "submitter": "Satyen Kale", "authors": "Naman Agarwal and Pranjal Awasthi and Satyen Kale", "title": "A Deep Conditioning Treatment of Neural Networks", "comments": "In proceedings of ALT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of depth in training randomly initialized overparameterized\nneural networks. We give a general result showing that depth improves\ntrainability of neural networks by improving the conditioning of certain kernel\nmatrices of the input data. This result holds for arbitrary non-linear\nactivation functions under a certain normalization. We provide versions of the\nresult that hold for training just the top layer of the neural network, as well\nas for training all layers, via the neural tangent kernel. As applications of\nthese general results, we provide a generalization of the results of Das et al.\n(2019) showing that learnability of deep random neural networks with a large\nclass of non-linear activations degrades exponentially with depth. We also show\nhow benign overfitting can occur in deep neural networks via the results of\nBartlett et al. (2019b). We also give experimental evidence that normalized\nversions of ReLU are a viable alternative to more complex operations like Batch\nNormalization in training deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 20:21:36 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 18:44:14 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 14:06:52 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Agarwal", "Naman", ""], ["Awasthi", "Pranjal", ""], ["Kale", "Satyen", ""]]}, {"id": "2002.01535", "submitter": "Shrey Desai", "authors": "Shrey Desai, Geoffrey Goh, Arun Babu, Ahmed Aly", "title": "Lightweight Convolutional Representations for On-Device Natural Language\n  Processing", "comments": "Accepted to MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing computational and memory complexities of deep neural networks\nhave made it difficult to deploy them on low-resource electronic devices (e.g.,\nmobile phones, tablets, wearables). Practitioners have developed numerous model\ncompression methods to address these concerns, but few have condensed input\nrepresentations themselves. In this work, we propose a fast, accurate, and\nlightweight convolutional representation that can be swapped into any neural\nmodel and compressed significantly (up to 32x) with a negligible reduction in\nperformance. In addition, we show gains over recurrent representations when\nconsidering resource-centric metrics (e.g., model file size, latency, memory\nusage) on a Samsung Galaxy S9.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:02:11 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Desai", "Shrey", ""], ["Goh", "Geoffrey", ""], ["Babu", "Arun", ""], ["Aly", "Ahmed", ""]]}, {"id": "2002.01547", "submitter": "Gustavo Malkomes", "authors": "Trevor J. Larsen, Gustavo Malkomes, Dennis L. Barbour", "title": "Accelerating Psychometric Screening Tests With Bayesian Active\n  Differential Selection", "comments": "Extended Abstract accepted to ML4H: Machine Learning for Health\n  Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical methods for psychometric function estimation either require\nexcessive measurements or produce only a low-resolution approximation of the\ntarget psychometric function. In this paper, we propose a novel solution for\nrapid screening for a change in the psychometric function estimation of a given\npatient. We use Bayesian active model selection to perform an automated\npure-tone audiogram test with the goal of quickly finding if the current\naudiogram will be different from a previous audiogram. We validate our approach\nusing audiometric data from the National Institute for Occupational Safety and\nHealth NIOSH. Initial results show that with a few tones we can detect if the\npatient's audiometric function has changed between the two test sessions with\nhigh confidence.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:35:03 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Larsen", "Trevor J.", ""], ["Malkomes", "Gustavo", ""], ["Barbour", "Dennis L.", ""]]}, {"id": "2002.01552", "submitter": "Ren\\'e S{\\o}rensen", "authors": "Ren\\'e Brandborg S{\\o}rensen, Jimmy Jessen Nielsen, Petar Popovski", "title": "Machine Learning Methods for Monitoring of Quasi-Periodic Traffic in\n  Massive IoT Networks", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.2983217", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central problems in massive Internet of Things (IoT) deployments\nis the monitoring of the status of a massive number of links. The problem is\naggravated by the irregularity of the traffic transmitted over the link, as the\ntraffic intermittency can be disguised as a link failure and vice versa. In\nthis work we present a traffic model for IoT devices running quasi-periodic\napplications and we present both supervised and unsupervised machine learning\nmethods for monitoring the network performance of IoT deployments with\nquasi-periodic reporting, such as smart-metering, environmental monitoring and\nagricultural monitoring. The unsupervised methods are based on the Lomb-Scargle\nperiodogram, an approach developed by astronomers for estimating the spectral\ndensity of unevenly sampled time series.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 21:42:56 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 15:25:07 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["S\u00f8rensen", "Ren\u00e9 Brandborg", ""], ["Nielsen", "Jimmy Jessen", ""], ["Popovski", "Petar", ""]]}, {"id": "2002.01563", "submitter": "Kirill Shmilovich", "authors": "Kirill Shmilovich, Rachael A. Mansbach, Hythem Sidky, Olivia E. Dunne,\n  Sayak Subhra Panda, John D. Tovar, Andrew L. Ferguson", "title": "Discovery of Self-Assembling $\\pi$-Conjugated Peptides by Active\n  Learning-Directed Coarse-Grained Molecular Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cond-mat.soft cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronically-active organic molecules have demonstrated great promise as\nnovel soft materials for energy harvesting and transport. Self-assembled\nnanoaggregates formed from $\\pi$-conjugated oligopeptides composed of an\naromatic core flanked by oligopeptide wings offer emergent optoelectronic\nproperties within a water soluble and biocompatible substrate. Nanoaggregate\nproperties can be controlled by tuning core chemistry and peptide composition,\nbut the sequence-structure-function relations remain poorly characterized. In\nthis work, we employ coarse-grained molecular dynamics simulations within an\nactive learning protocol employing deep representational learning and Bayesian\noptimization to efficiently identify molecules capable of assembling pseudo-1D\nnanoaggregates with good stacking of the electronically-active $\\pi$-cores. We\nconsider the DXXX-OPV3-XXXD oligopeptide family, where D is an Asp residue and\nOPV3 is an oligophenylene vinylene oligomer (1,4-distyrylbenzene), to identify\nthe top performing XXX tripeptides within all 20$^3$ = 8,000 possible\nsequences. By direct simulation of only 2.3% of this space, we identify\nmolecules predicted to exhibit superior assembly relative to those reported in\nprior work. Spectral clustering of the top candidates reveals new design rules\ngoverning assembly. This work establishes new understanding of DXXX-OPV3-XXXD\nassembly, identifies promising new candidates for experimental testing, and\npresents a computational design platform that can be generically extended to\nother peptide-based and peptide-like systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 00:01:21 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Shmilovich", "Kirill", ""], ["Mansbach", "Rachael A.", ""], ["Sidky", "Hythem", ""], ["Dunne", "Olivia E.", ""], ["Panda", "Sayak Subhra", ""], ["Tovar", "John D.", ""], ["Ferguson", "Andrew L.", ""]]}, {"id": "2002.01568", "submitter": "Leila Saadatifard", "authors": "Leila Saadatifard, Aryan Mobiny, Pavel Govyadinov, Hien Nguyen, David\n  Mayerich", "title": "DVNet: A Memory-Efficient Three-Dimensional CNN for Large-Scale\n  Neurovascular Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maps of brain microarchitecture are important for understanding neurological\nfunction and behavior, including alterations caused by chronic conditions such\nas neurodegenerative disease. Techniques such as knife-edge scanning microscopy\n(KESM) provide the potential for whole organ imaging at sub-cellular\nresolution. However, multi-terabyte data sizes make manual annotation\nimpractical and automatic segmentation challenging. Densely packed cells\ncombined with interconnected microvascular networks are a challenge for current\nsegmentation algorithms. The massive size of high-throughput microscopy data\nnecessitates fast and largely unsupervised algorithms. In this paper, we\ninvestigate a fully-convolutional, deep, and densely-connected encoder-decoder\nfor pixel-wise semantic segmentation. The excessive memory complexity often\nencountered with deep and dense networks is mitigated using skip connections,\nresulting in fewer parameters and enabling a significant performance increase\nover prior architectures. The proposed network provides superior performance\nfor semantic segmentation problems applied to open-source benchmarks. We\nfinally demonstrate our network for cellular and microvascular segmentation,\nenabling quantitative metrics for organ-scale neurovascular analysis.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:39:58 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Saadatifard", "Leila", ""], ["Mobiny", "Aryan", ""], ["Govyadinov", "Pavel", ""], ["Nguyen", "Hien", ""], ["Mayerich", "David", ""]]}, {"id": "2002.01571", "submitter": "Hyobin Kim", "authors": "Hyobin Kim, Stalin Mu\\~noz, Pamela Osuna, and Carlos Gershenson", "title": "Antifragility Predicts the Robustness and Evolvability of Biological\n  Networks through Multi-class Classification with a Convolutional Neural\n  Network", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG nlin.CG q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness and evolvability are essential properties to the evolution of\nbiological networks. To determine if a biological network is robust and/or\nevolvable, it is required to compare its functions before and after mutations.\nHowever, this sometimes takes a high computational cost as the network size\ngrows. Here we develop a predictive method to estimate the robustness and\nevolvability of biological networks without an explicit comparison of\nfunctions. We measure antifragility in Boolean network models of biological\nsystems and use this as the predictor. Antifragility occurs when a system\nbenefits from external perturbations. By means of the differences of\nantifragility between the original and mutated biological networks, we train a\nconvolutional neural network (CNN) and test it to classify the properties of\nrobustness and evolvability. We found that our CNN model successfully\nclassified the properties. Thus, we conclude that our antifragility measure can\nbe used as a predictor of the robustness and evolvability of biological\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:52:28 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 10:33:00 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Kim", "Hyobin", ""], ["Mu\u00f1oz", "Stalin", ""], ["Osuna", "Pamela", ""], ["Gershenson", "Carlos", ""]]}, {"id": "2002.01576", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Heng Huang", "title": "Large Batch Training Does Not Need Warmup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks using a large batch size has shown promising\nresults and benefits many real-world applications. However, the optimizer\nconverges slowly at early epochs and there is a gap between large-batch deep\nlearning optimization heuristics and theoretical underpinnings. In this paper,\nwe propose a novel Complete Layer-wise Adaptive Rate Scaling (CLARS) algorithm\nfor large-batch training. We also analyze the convergence rate of the proposed\nmethod by introducing a new fine-grained analysis of gradient-based methods.\nBased on our analysis, we bridge the gap and illustrate the theoretical\ninsights for three popular large-batch training techniques, including linear\nlearning rate scaling, gradual warmup, and layer-wise adaptive rate scaling.\nExtensive experiments demonstrate that the proposed algorithm outperforms\ngradual warmup technique by a large margin and defeats the convergence of the\nstate-of-the-art large-batch optimizer in training advanced deep neural\nnetworks (ResNet, DenseNet, MobileNet) on ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 23:03:12 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Huang", "Heng", ""]]}, {"id": "2002.01584", "submitter": "Matthew McDermott", "authors": "Matthew B.A. McDermott (1), Emily Alsentzer (1 and 2), Sam Finlayson\n  (1 and 2), Michael Oberst (1), Fabian Falck (3), Tristan Naumann (4), Brett\n  K. Beaulieu-Jones (2), Adrian V. Dalca (2 and 1) ((1) Massachusetts Institute\n  of Technology, (2) Harvard Medical School, (3) Carnegie Mellon University,\n  (4) Microsoft Research)", "title": "ML4H Abstract Track 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collection of the accepted abstracts for the Machine Learning for Health\n(ML4H) workshop at NeurIPS 2019. This index is not complete, as some accepted\nabstracts chose to opt-out of inclusion.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:18:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["McDermott", "Matthew B. A.", "", "1 and 2"], ["Alsentzer", "Emily", "", "1 and 2"], ["Finlayson", "Sam", "", "1 and 2"], ["Oberst", "Michael", "", "2 and 1"], ["Falck", "Fabian", "", "2 and 1"], ["Naumann", "Tristan", "", "2 and 1"], ["Beaulieu-Jones", "Brett K.", "", "2 and 1"], ["Dalca", "Adrian V.", "", "2 and 1"]]}, {"id": "2002.01586", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang and Pragya Sur", "title": "A Precise High-Dimensional Asymptotic Theory for Boosting and\n  Minimum-$\\ell_1$-Norm Interpolated Classifiers", "comments": "68 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a precise high-dimensional asymptotic theory for\nboosting on separable data, taking statistical and computational perspectives.\nWe consider a high-dimensional setting where the number of features (weak\nlearners) $p$ scales with the sample size $n$, in an overparametrized regime.\nUnder a class of statistical models, we provide an exact analysis of the\ngeneralization error of boosting when the algorithm interpolates the training\ndata and maximizes the empirical $\\ell_1$-margin. Further, we explicitly pin\ndown the relation between the boosting test error and the optimal Bayes error,\nas well as the proportion of active features at interpolation (with zero\ninitialization). In turn, these precise characterizations answer certain\nquestions raised in \\cite{breiman1999prediction, schapire1998boosting}\nsurrounding boosting, under assumed data generating processes. At the heart of\nour theory lies an in-depth study of the maximum-$\\ell_1$-margin, which can be\naccurately described by a new system of non-linear equations; to analyze this\nmargin, we rely on Gaussian comparison techniques and develop a novel uniform\ndeviation argument. Our statistical and computational arguments can handle (1)\nany finite-rank spiked covariance model for the feature distribution and (2)\nvariants of boosting corresponding to general $\\ell_q$-geometry, $q \\in [1,\n2]$. As a final component, via the Lindeberg principle, we establish a\nuniversality result showcasing that the scaled $\\ell_1$-margin (asymptotically)\nremains the same, whether the covariates used for boosting arise from a\nnon-linear random feature model or an appropriately linearized model with\nmatching moments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:24:53 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 20:49:20 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 20:55:22 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Liang", "Tengyuan", ""], ["Sur", "Pragya", ""]]}, {"id": "2002.01587", "submitter": "David D. Fan", "authors": "David D. Fan, Ali-akbar Agha-mohammadi and Evangelos A. Theodorou", "title": "Deep Learning Tubes for Tube MPC", "comments": "RSS 2020 Camera Ready Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based control aims to construct models of a system to use for\nplanning or trajectory optimization, e.g. in model-based reinforcement\nlearning. In order to obtain guarantees of safety in this context, uncertainty\nmust be accurately quantified. This uncertainty may come from errors in\nlearning (due to a lack of data, for example), or may be inherent to the\nsystem. Propagating uncertainty forward in learned dynamics models is a\ndifficult problem. In this work we use deep learning to obtain expressive and\nflexible models of how distributions of trajectories behave, which we then use\nfor nonlinear Model Predictive Control (MPC). We introduce a deep quantile\nregression framework for control that enforces probabilistic quantile bounds\nand quantifies epistemic uncertainty. Using our method we explore three\ndifferent approaches for learning tubes that contain the possible trajectories\nof the system, and demonstrate how to use each of them in a Tube MPC scheme. We\nprove these schemes are recursively feasible and satisfy constraints with a\ndesired margin of probability. We present experiments in simulation on a\nnonlinear quadrotor system, demonstrating the practical efficacy of these\nideas.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 00:32:18 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 20:12:35 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Fan", "David D.", ""], ["Agha-mohammadi", "Ali-akbar", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2002.01598", "submitter": "Byungsoo Jeon", "authors": "Byungsoo Jeon, Namyong Park, Seojin Bang", "title": "Dropout Prediction over Weeks in MOOCs via Interpretable Multi-Layer\n  Representation Learning", "comments": "Accepted at AAAI 2020 AI4Edu Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Courses (MOOCs) have become popular platforms for online\nlearning. While MOOCs enable students to study at their own pace, this\nflexibility makes it easy for students to drop out of class. In this paper, our\ngoal is to predict if a learner is going to drop out within the next week,\ngiven clickstream data for the current week. To this end, we present a\nmulti-layer representation learning solution based on branch and bound (BB)\nalgorithm, which learns from low-level clickstreams in an unsupervised manner,\nproduces interpretable results, and avoids manual feature engineering. In\nexperiments on Coursera data, we show that our model learns a representation\nthat allows a simple model to perform similarly well to more complex,\ntask-specific models, and how the BB algorithm enables interpretable results.\nIn our analysis of the observed limitations, we discuss promising future\ndirections.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:15:34 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Jeon", "Byungsoo", ""], ["Park", "Namyong", ""], ["Bang", "Seojin", ""]]}, {"id": "2002.01600", "submitter": "Johannes Hendriks", "authors": "Johannes Hendriks, Carl Jidling, Adrian Wills and Thomas Sch\\\"on", "title": "Linearly Constrained Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to modelling and learning vector fields from\nphysical systems using neural networks that explicitly satisfy known linear\noperator constraints. To achieve this, the target function is modelled as a\nlinear transformation of an underlying potential field, which is in turn\nmodelled by a neural network. This transformation is chosen such that any\nprediction of the target function is guaranteed to satisfy the constraints. The\napproach is demonstrated on both simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:27:29 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 23:38:01 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 01:24:06 GMT"}, {"version": "v4", "created": "Wed, 28 Apr 2021 01:43:49 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Hendriks", "Johannes", ""], ["Jidling", "Carl", ""], ["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas", ""]]}, {"id": "2002.01605", "submitter": "Zhi-Hua Zhou", "authors": "Yu-Jie Zhang and Peng Zhao and Zhi-Hua Zhou", "title": "Exploratory Machine Learning with Unknown Unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In conventional supervised learning, a training dataset is given with\nground-truth labels from a known label set, and the learned model will classify\nunseen instances to the known labels. In this paper, we study a new problem\nsetting in which there are unknown classes in the training dataset misperceived\nas other labels, and thus their existence appears unknown from the given\nsupervision. We attribute the unknown unknowns to the fact that the training\ndataset is badly advised by the incompletely perceived label space due to the\ninsufficient feature information. To this end, we propose the exploratory\nmachine learning, which examines and investigates the training dataset by\nactively augmenting the feature space to discover potentially unknown labels.\nOur approach consists of three ingredients including rejection model, feature\nacquisition, and model cascade. The effectiveness is validated on both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 02:06:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Yu-Jie", ""], ["Zhao", "Peng", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2002.01615", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Marco Cuturi, Makoto Yamada, Hisashi Kashima", "title": "Fast and Robust Comparison of Probability Measures in Heterogeneous\n  Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing two probability measures supported on heterogeneous spaces is an\nincreasingly important problem in machine learning. Such problems arise when\ncomparing for instance two populations of biological cells, each described with\nits own set of features, or when looking at families of word embeddings trained\nacross different corpora/languages. For such settings, the Gromov Wasserstein\n(GW) distance is often presented as the gold standard. GW is intuitive, as it\nquantifies whether one measure can be isomorphically mapped to the other.\nHowever, its exact computation is intractable, and most algorithms that claim\nto approximate it remain expensive. Building on \\cite{memoli-2011}, who\nproposed to represent each point in each distribution as the 1D distribution of\nits distances to all other points, we introduce in this paper the Anchor Energy\n(AE) and Anchor Wasserstein (AW) distances, which are respectively the energy\nand Wasserstein distances instantiated on such representations. Our main\ncontribution is to propose a sweep line algorithm to compute AE \\emph{exactly}\nin log-quadratic time, where a naive implementation would be cubic. This is\nquasi-linear w.r.t. the description of the problem itself. Our second\ncontribution is the proposal of robust variants of AE and AW that uses rank\nstatistics rather than the original distances. We show that AE and AW perform\nwell in various experimental settings at a fraction of the computational cost\nof popular GW approximations. Code is available at\n\\url{https://github.com/joisino/anchor-energy}.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:09:23 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 12:35:24 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 09:47:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Sato", "Ryoma", ""], ["Cuturi", "Marco", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.01618", "submitter": "Jonggi Hong", "authors": "Jonggi Hong, Kyungjun Lee, June Xu, Hernisa Kacorri", "title": "Crowdsourcing the Perception of Machine Teaching", "comments": "10 pages, 8 figures, 5 tables, CHI2020 conference", "journal-ref": "Proceedings of the 2020 CHI Conference on Human Factors in\n  Computing Systems", "doi": "10.1145/3313831.3376428", "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teachable interfaces can empower end-users to attune machine learning systems\nto their idiosyncratic characteristics and environment by explicitly providing\npertinent training examples. While facilitating control, their effectiveness\ncan be hindered by the lack of expertise or misconceptions. We investigate how\nusers may conceptualize, experience, and reflect on their engagement in machine\nteaching by deploying a mobile teachable testbed in Amazon Mechanical Turk.\nUsing a performance-based payment scheme, Mechanical Turkers (N = 100) are\ncalled to train, test, and re-train a robust recognition model in real-time\nwith a few snapshots taken in their environment. We find that participants\nincorporate diversity in their examples drawing from parallels to how humans\nrecognize objects independent of size, viewpoint, location, and illumination.\nMany of their misconceptions relate to consistency and model capabilities for\nreasoning. With limited variation and edge cases in testing, the majority of\nthem do not change strategies on a second training attempt.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:20:25 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hong", "Jonggi", ""], ["Lee", "Kyungjun", ""], ["Xu", "June", ""], ["Kacorri", "Hernisa", ""]]}, {"id": "2002.01622", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Revisit to the Inverse Exponential Radon Transform", "comments": "This review was first written in 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.IT cs.LG cs.NA math.IT math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This revisit gives a survey on the analytical methods for the inverse\nexponential Radon transform which has been investigated in the past three\ndecades from both mathematical interests and medical applications such as\nnuclear medicine emission imaging. The derivation of the classical inversion\nformula is through the recent argument developed for the inverse attenuated\nRadon transform. That derivation allows the exponential parameter to be a\ncomplex constant, which is useful to other applications such as magnetic\nresonance imaging and tensor field imaging. The survey also includes the new\ntechnique of using the finite Hilbert transform to handle the exact\nreconstruction from 180 degree data. Special treatment has been paid on two\npractically important subjects. One is the exact reconstruction from partial\nmeasurements such as half-scan and truncated-scan data, and the other is the\nreconstruction from diverging-beam data. The noise propagation in the\nreconstruction is touched upon with more heuristic discussions than\nmathematical inference. The numerical realizations of several classical\nreconstruction algorithms are included. In the conclusion, several topics are\ndiscussed for more investigations in the future.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:32:00 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.01626", "submitter": "Cunhang Fan", "authors": "Cunhang Fan, Bin Liu, Jianhua Tao, Jiangyan Yi, and Zhengqi Wen", "title": "Spatial and spectral deep attention fusion for multi-channel speech\n  separation using deep embedding features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-channel deep clustering (MDC) has acquired a good performance for\nspeech separation. However, MDC only applies the spatial features as the\nadditional information. So it is difficult to learn mutual relationship between\nspatial and spectral features. Besides, the training objective of MDC is\ndefined at embedding vectors, rather than real separated sources, which may\ndamage the separation performance. In this work, we propose a deep attention\nfusion method to dynamically control the weights of the spectral and spatial\nfeatures and combine them deeply. In addition, to solve the training objective\nproblem of MDC, the real separated sources are used as the training objectives.\nSpecifically, we apply the deep clustering network to extract deep embedding\nfeatures. Instead of using the unsupervised K-means clustering to estimate\nbinary masks, another supervised network is utilized to learn soft masks from\nthese deep embedding features. Our experiments are conducted on a spatialized\nreverberant version of WSJ0-2mix dataset. Experimental results show that the\nproposed method outperforms MDC baseline and even better than the oracle ideal\nbinary mask (IBM).\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:49:39 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Fan", "Cunhang", ""], ["Liu", "Bin", ""], ["Tao", "Jianhua", ""], ["Yi", "Jiangyan", ""], ["Wen", "Zhengqi", ""]]}, {"id": "2002.01628", "submitter": "Zijian Lei", "authors": "Zijian Lei and Liang Lan", "title": "Improved Subsampled Randomized Hadamard Transform for Linear SVM", "comments": "AAAI-20", "journal-ref": null, "doi": "10.1609/aaai.v34i04.5880", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsampled Randomized Hadamard Transform (SRHT), a popular random projection\nmethod that can efficiently project a $d$-dimensional data into $r$-dimensional\nspace ($r \\ll d$) in $O(dlog(d))$ time, has been widely used to address the\nchallenge of high-dimensionality in machine learning. SRHT works by rotating\nthe input data matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ by Randomized\nWalsh-Hadamard Transform followed with a subsequent uniform column sampling on\nthe rotated matrix. Despite the advantages of SRHT, one limitation of SRHT is\nthat it generates the new low-dimensional embedding without considering any\nspecific properties of a given dataset. Therefore, this data-independent random\nprojection method may result in inferior and unstable performance when used for\na particular machine learning task, e.g., classification. To overcome this\nlimitation, we analyze the effect of using SRHT for random projection in the\ncontext of linear SVM classification. Based on our analysis, we propose\nimportance sampling and deterministic top-$r$ sampling to produce effective\nlow-dimensional embedding instead of uniform sampling SRHT. In addition, we\nalso proposed a new supervised non-uniform sampling method. Our experimental\nresults have demonstrated that our proposed methods can achieve higher\nclassification accuracies than SRHT and other random projection methods on six\nreal-life datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 04:09:23 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lei", "Zijian", ""], ["Lan", "Liang", ""]]}, {"id": "2002.01633", "submitter": "Deyu Bo", "authors": "Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu and Peng Cui", "title": "Structural Deep Clustering Network", "comments": "Published at The Web Conference (WWW) 2020, full paper", "journal-ref": null, "doi": "10.1145/3366423.3380214", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental task in data analysis. Recently, deep clustering,\nwhich derives inspiration primarily from deep learning approaches, achieves\nstate-of-the-art performance and has attracted considerable attention. Current\ndeep clustering methods usually boost the clustering results by means of the\npowerful representation ability of deep learning, e.g., autoencoder, suggesting\nthat learning an effective representation for clustering is a crucial\nrequirement. The strength of deep clustering methods is to extract the useful\nrepresentations from the data itself, rather than the structure of data, which\nreceives scarce attention in representation learning. Motivated by the great\nsuccess of Graph Convolutional Network (GCN) in encoding the graph structure,\nwe propose a Structural Deep Clustering Network (SDCN) to integrate the\nstructural information into deep clustering. Specifically, we design a delivery\noperator to transfer the representations learned by autoencoder to the\ncorresponding GCN layer, and a dual self-supervised mechanism to unify these\ntwo different deep neural architectures and guide the update of the whole\nmodel. In this way, the multiple structures of data, from low-order to\nhigh-order, are naturally combined with the multiple representations learned by\nautoencoder. Furthermore, we theoretically analyze the delivery operator, i.e.,\nwith the delivery operator, GCN improves the autoencoder-specific\nrepresentation as a high-order graph regularization constraint and autoencoder\nhelps alleviate the over-smoothing problem in GCN. Through comprehensive\nexperiments, we demonstrate that our propose model can consistently perform\nbetter over the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 04:33:40 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 01:38:08 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 13:27:06 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bo", "Deyu", ""], ["Wang", "Xiao", ""], ["Shi", "Chuan", ""], ["Zhu", "Meiqi", ""], ["Lu", "Emiao", ""], ["Cui", "Peng", ""]]}, {"id": "2002.01647", "submitter": "Hongyu Li", "authors": "Hongyu Li, Dan Meng, Hong Wang and Xiaolin Li", "title": "Knowledge Federation: A Unified and Hierarchical Privacy-Preserving AI\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With strict protections and regulations of data privacy and security,\nconventional machine learning based on centralized datasets is confronted with\nsignificant challenges, making artificial intelligence (AI) impractical in many\nmission-critical and data-sensitive scenarios, such as finance, government, and\nhealth. In the meantime, tremendous datasets are scattered in isolated silos in\nvarious industries, organizations, different units of an organization, or\ndifferent branches of an international organization. These valuable data\nresources are well underused. To advance AI theories and applications, we\npropose a comprehensive framework (called Knowledge Federation - KF) to address\nthese challenges by enabling AI while preserving data privacy and ownership.\nBeyond the concepts of federated learning and secure multi-party computation,\nKF consists of four levels of federation: (1) information level, low-level\nstatistics and computation of data, meeting the requirements of simple queries,\nsearching and simplistic operators; (2) model level, supporting training,\nlearning, and inference; (3) cognition level, enabling abstract feature\nrepresentation at various levels of abstractions and contexts; (4) knowledge\nlevel, fusing knowledge discovery, representation, and reasoning. We further\nclarify the relationship and differentiation between knowledge federation and\nother related research areas. We have developed a reference implementation of\nKF, called iBond Platform, to offer a production-quality KF platform to enable\nindustrial applications in finance, insurance et al. The iBond platform will\nalso help establish the KF community and a comprehensive ecosystem and usher in\na novel paradigm shift towards secure, privacy-preserving and responsible AI.\nAs far as we know, knowledge federation is the first hierarchical and unified\nframework for secure multi-party computing and learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:23:35 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 01:54:28 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 07:34:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Li", "Hongyu", ""], ["Meng", "Dan", ""], ["Wang", "Hong", ""], ["Li", "Xiaolin", ""]]}, {"id": "2002.01648", "submitter": "Jes\\'us Daniel Arroyo Reli\\'on", "authors": "Jes\\'us Arroyo, Carey E. Priebe, Vince Lyzinski", "title": "Graph matching between bipartite and unipartite networks: to collapse,\n  or not to collapse, that is the question", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching consists of aligning the vertices of two unlabeled graphs in\norder to maximize the shared structure across networks; when the graphs are\nunipartite, this is commonly formulated as minimizing their edge disagreements.\nIn this paper, we address the common setting in which one of the graphs to\nmatch is a bipartite network and one is unipartite. Commonly, the bipartite\nnetworks are collapsed or projected into a unipartite graph, and graph matching\nproceeds as in the classical setting. This potentially leads to noisy edge\nestimates and loss of information. We formulate the graph matching problem\nbetween a bipartite and a unipartite graph using an undirected graphical model,\nand introduce methods to find the alignment with this model without collapsing.\nWe theoretically demonstrate that our methodology is consistent, and provide\nnon-asymptotic conditions that ensure exact recovery of the matching solution.\nIn simulations and real data examples, we show how our methods can result in a\nmore accurate matching than the naive approach of transforming the bipartite\nnetworks into unipartite, and we demonstrate the performance gains achieved by\nour method in simulated and real data networks, including a\nco-authorship-citation network pair, and brain structural and functional data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:24:54 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 21:30:45 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 17:35:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Arroyo", "Jes\u00fas", ""], ["Priebe", "Carey E.", ""], ["Lyzinski", "Vince", ""]]}, {"id": "2002.01650", "submitter": "Zhi Chen", "authors": "Zhi Chen, Yijie Bei and Cynthia Rudin", "title": "Concept Whitening for Interpretable Image Recognition", "comments": "Authors' pre-publication version of a 2020 Nature Machine\n  Intelligence article", "journal-ref": "Nature Machine Intelligence, Vol 2, Dec 2020, 772-782", "doi": "10.1038/s42256-020-00265-z", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does a neural network encode about a concept as we traverse through the\nlayers? Interpretability in machine learning is undoubtedly important, but the\ncalculations of neural networks are very challenging to understand. Attempts to\nsee inside their hidden layers can either be misleading, unusable, or rely on\nthe latent space to possess properties that it may not have. In this work,\nrather than attempting to analyze a neural network posthoc, we introduce a\nmechanism, called concept whitening (CW), to alter a given layer of the network\nto allow us to better understand the computation leading up to that layer. When\na concept whitening module is added to a CNN, the axes of the latent space are\naligned with known concepts of interest. By experiment, we show that CW can\nprovide us a much clearer understanding for how the network gradually learns\nconcepts over layers. CW is an alternative to a batch normalization layer in\nthat it normalizes, and also decorrelates (whitens) the latent space. CW can be\nused in any layer of the network without hurting predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 05:28:09 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 16:55:49 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 05:06:19 GMT"}, {"version": "v4", "created": "Mon, 19 Oct 2020 14:13:19 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 19:09:35 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Chen", "Zhi", ""], ["Bei", "Yijie", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2002.01664", "submitter": "Krishna D N", "authors": "Krishna D N, Ankita Patil, M.S.P Raj, Sai Prasad H S, Prabhu Aashish\n  Garapati", "title": "Identification of Indian Languages using Ghost-VLAD pooling", "comments": null, "journal-ref": "REJECTED ICASSP 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a new pooling strategy for language identification\nby considering Indian languages. The idea is to obtain utterance level features\nfor any variable length audio for robust language recognition. We use the\nGhostVLAD approach to generate an utterance level feature vector for any\nvariable length input audio by aggregating the local frame level features\nacross time. The generated feature vector is shown to have very good language\ndiscriminative features and helps in getting state of the art results for\nlanguage identification task. We conduct our experiments on 635Hrs of audio\ndata for 7 Indian languages. Our method outperforms the previous state of the\nart x-vector [11] method by an absolute improvement of 1.88% in F1-score and\nachieves 98.43% F1-score on the held-out test data. We compare our system with\nvarious pooling approaches and show that GhostVLAD is the best pooling approach\nfor this task. We also provide visualization of the utterance level embeddings\ngenerated using Ghost-VLAD pooling and show that this method creates embeddings\nwhich has very good language discriminative features.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 07:07:15 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["N", "Krishna D", ""], ["Patil", "Ankita", ""], ["Raj", "M. S. P", ""], ["S", "Sai Prasad H", ""], ["Garapati", "Prabhu Aashish", ""]]}, {"id": "2002.01680", "submitter": "Xinyu Fu", "authors": "Xinyu Fu, Jiani Zhang, Ziqiao Meng, Irwin King", "title": "MAGNN: Metapath Aggregated Graph Neural Network for Heterogeneous Graph\n  Embedding", "comments": "To appear at WWW 2020; 11 pages, 4 figures; typos of model name\n  corrected", "journal-ref": null, "doi": "10.1145/3366423.3380297", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of real-world graphs or networks are inherently heterogeneous,\ninvolving a diversity of node types and relation types. Heterogeneous graph\nembedding is to embed rich structural and semantic information of a\nheterogeneous graph into low-dimensional node representations. Existing models\nusually define multiple metapaths in a heterogeneous graph to capture the\ncomposite relations and guide neighbor selection. However, these models either\nomit node content features, discard intermediate nodes along the metapath, or\nonly consider one metapath. To address these three limitations, we propose a\nnew model named Metapath Aggregated Graph Neural Network (MAGNN) to boost the\nfinal performance. Specifically, MAGNN employs three major components, i.e.,\nthe node content transformation to encapsulate input node attributes, the\nintra-metapath aggregation to incorporate intermediate semantic nodes, and the\ninter-metapath aggregation to combine messages from multiple metapaths.\nExtensive experiments on three real-world heterogeneous graph datasets for node\nclassification, node clustering, and link prediction show that MAGNN achieves\nmore accurate prediction results than state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 08:21:00 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 03:51:52 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Fu", "Xinyu", ""], ["Zhang", "Jiani", ""], ["Meng", "Ziqiao", ""], ["King", "Irwin", ""]]}, {"id": "2002.01685", "submitter": "David Vilares", "authors": "David Vilares and Michalina Strzyz and Anders S{\\o}gaard and Carlos\n  G\\'omez-Rodr\\'iguez", "title": "Parsing as Pretraining", "comments": "AAAI 2020 - The Thirty-Fourth AAAI Conference on Artificial\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent analyses suggest that encoders pretrained for language modeling\ncapture certain morpho-syntactic structure. However, probing frameworks for\nword vectors still do not report results on standard setups such as constituent\nand dependency parsing. This paper addresses this problem and does full parsing\n(on English) relying only on pretraining architectures -- and no decoding. We\nfirst cast constituent and dependency parsing as sequence tagging. We then use\na single feed-forward layer to directly map word vectors to labels that encode\na linearized tree. This is used to: (i) see how far we can reach on syntax\nmodelling with just pretrained encoders, and (ii) shed some light about the\nsyntax-sensitivity of different word vectors (by freezing the weights of the\npretraining network during training). For evaluation, we use bracketing\nF1-score and LAS, and analyze in-depth differences across representations for\nspan lengths and dependency displacements. The overall results surpass existing\nsequence tagging parsers on the PTB (93.5%) and end-to-end EN-EWT UD (78.8%).\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 08:43:02 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Vilares", "David", ""], ["Strzyz", "Michalina", ""], ["S\u00f8gaard", "Anders", ""], ["G\u00f3mez-Rodr\u00edguez", "Carlos", ""]]}, {"id": "2002.01687", "submitter": "Nicolas Turpault", "authors": "Nicolas Turpault (MULTISPEECH), Romain Serizel (MULTISPEECH), Emmanuel\n  Vincent (MULTISPEECH)", "title": "Limitations of weak labels for embedding and tagging", "comments": null, "journal-ref": "ICASSP 2020 - 45th International Conference on Acoustics, Speech,\n  and Signal Processing, May 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many datasets and approaches in ambient sound analysis use weakly labeled\ndata.Weak labels are employed because annotating every data sample with a\nstrong label is too expensive.Yet, their impact on the performance in\ncomparison to strong labels remains unclear.Indeed, weak labels must often be\ndealt with at the same time as other challenges, namely multiple labels per\nsample, unbalanced classes and/or overlapping events.In this paper, we\nformulate a supervised learning problem which involves weak labels.We create a\ndataset that focuses on the difference between strong and weak labels as\nopposed to other challenges. We investigate the impact of weak labels when\ntraining an embedding or an end-to-end classifier.Different experimental\nscenarios are discussed to provide insights into which applications are most\nsensitive to weakly labeled data.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 08:54:08 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 09:27:00 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:14:56 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 13:13:51 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Turpault", "Nicolas", "", "MULTISPEECH"], ["Serizel", "Romain", "", "MULTISPEECH"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "2002.01690", "submitter": "Xiaofu Wu Dr", "authors": "Xiaofu Wu, Suofei hang, Quan Zhou, Zhen Yang, Chunming Zhao, Longin\n  Jan Latecki", "title": "Entropy Minimization vs. Diversity Maximization for Domain Adaptation", "comments": "submitted to IEEE T-IP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy minimization has been widely used in unsupervised domain adaptation\n(UDA). However, existing works reveal that entropy minimization only may result\ninto collapsed trivial solutions. In this paper, we propose to avoid trivial\nsolutions by further introducing diversity maximization. In order to achieve\nthe possible minimum target risk for UDA, we show that diversity maximization\nshould be elaborately balanced with entropy minimization, the degree of which\ncan be finely controlled with the use of deep embedded validation in an\nunsupervised manner. The proposed minimal-entropy diversity maximization (MEDM)\ncan be directly implemented by stochastic gradient descent without use of\nadversarial learning. Empirical evidence demonstrates that MEDM outperforms the\nstate-of-the-art methods on four popular domain adaptation datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:13:19 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wu", "Xiaofu", ""], ["hang", "Suofei", ""], ["Zhou", "Quan", ""], ["Yang", "Zhen", ""], ["Zhao", "Chunming", ""], ["Latecki", "Longin Jan", ""]]}, {"id": "2002.01697", "submitter": "Zhaoqiang Liu", "authors": "Zhaoqiang Liu, Selwyn Gomes, Avtansh Tiwari, Jonathan Scarlett", "title": "Sample Complexity Bounds for 1-bit Compressive Sensing and Binary Stable\n  Embeddings with Generative Priors", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of standard 1-bit compressive sensing is to accurately recover an\nunknown sparse vector from binary-valued measurements, each indicating the sign\nof a linear function of the vector. Motivated by recent advances in compressive\nsensing with generative models, where a generative modeling assumption replaces\nthe usual sparsity assumption, we study the problem of 1-bit compressive\nsensing with generative models. We first consider noiseless 1-bit measurements,\nand provide sample complexity bounds for approximate recovery under\ni.i.d.~Gaussian measurements and a Lipschitz continuous generative prior, as\nwell as a near-matching algorithm-independent lower bound. Moreover, we\ndemonstrate that the Binary $\\epsilon$-Stable Embedding property, which\ncharacterizes the robustness of the reconstruction to measurement errors and\nnoise, also holds for 1-bit compressive sensing with Lipschitz continuous\ngenerative models with sufficiently many Gaussian measurements. In addition, we\napply our results to neural network generative models, and provide a\nproof-of-concept numerical experiment demonstrating significant improvements\nover sparsity-based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:44:10 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:47:05 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 04:57:09 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Gomes", "Selwyn", ""], ["Tiwari", "Avtansh", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2002.01711", "submitter": "Chengchun Shi", "authors": "Chengchun Shi, Xiaoyu Wang, Shikai Luo, Rui Song, Hongtu Zhu, Jieping\n  Ye", "title": "A Reinforcement Learning Framework for Time-Dependent Causal Effects\n  Evaluation in A/B Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A/B testing, or online experiment is a standard business strategy to compare\na new product with an old one in pharmaceutical, technological, and traditional\nindustries. Major challenges arise in online experiments where there is only\none unit that receives a sequence of treatments over time. In those\nexperiments, the treatment at a given time impacts current outcome as well as\nfuture outcomes. The aim of this paper is to introduce a reinforcement learning\nframework for carrying A/B testing, while characterizing the long-term\ntreatment effects. Our proposed testing procedure allows for sequential\nmonitoring and online updating, so it is generally applicable to a variety of\ntreatment designs in different industries. In addition, we systematically\ninvestigate the theoretical properties (e.g., asymptotic distribution and\npower) of our testing procedure. Finally, we apply our framework to both\nsynthetic datasets and a real-world data example obtained from a ride-sharing\ncompany to illustrate its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 10:25:02 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 15:57:41 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2020 15:57:52 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2020 08:49:39 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shi", "Chengchun", ""], ["Wang", "Xiaoyu", ""], ["Luo", "Shikai", ""], ["Song", "Rui", ""], ["Zhu", "Hongtu", ""], ["Ye", "Jieping", ""]]}, {"id": "2002.01726", "submitter": "Qi Yang", "authors": "Qi Yang, Aleksandr Farseev, Andrey Filchenkov", "title": "I Know Where You Are Coming From: On the Impact of Social Media Sources\n  on AI Model Performance", "comments": "AAAI-20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, social networks play a crucial role in human everyday life and no\nlonger purely associated with spare time spending. In fact, instant\ncommunication with friends and colleagues has become an essential component of\nour daily interaction giving a raise of multiple new social network types\nemergence. By participating in such networks, individuals generate a multitude\nof data points that describe their activities from different perspectives and,\nfor example, can be further used for applications such as personalized\nrecommendation or user profiling. However, the impact of the different social\nmedia networks on machine learning model performance has not been studied\ncomprehensively yet. Particularly, the literature on modeling multi-modal data\nfrom multiple social networks is relatively sparse, which had inspired us to\ntake a deeper dive into the topic in this preliminary study. Specifically, in\nthis work, we will study the performance of different machine learning models\nwhen being learned on multi-modal data from different social networks. Our\ninitial experimental results reveal that social network choice impacts the\nperformance and the proper selection of data source is crucial.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 11:10:44 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Yang", "Qi", ""], ["Farseev", "Aleksandr", ""], ["Filchenkov", "Andrey", ""]]}, {"id": "2002.01751", "submitter": "Chengchun Shi", "authors": "Chengchun Shi, Runzhe Wan, Rui Song, Wenbin Lu, Ling Leng", "title": "Does the Markov Decision Process Fit the Data: Testing for the Markov\n  Property in Sequential Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov assumption (MA) is fundamental to the empirical validity of\nreinforcement learning. In this paper, we propose a novel Forward-Backward\nLearning procedure to test MA in sequential decision making. The proposed test\ndoes not assume any parametric form on the joint distribution of the observed\ndata and plays an important role for identifying the optimal policy in\nhigh-order Markov decision processes and partially observable MDPs. We apply\nour test to both synthetic datasets and a real data example from mobile health\nstudies to illustrate its usefulness.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:29:10 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Shi", "Chengchun", ""], ["Wan", "Runzhe", ""], ["Song", "Rui", ""], ["Lu", "Wenbin", ""], ["Leng", "Ling", ""]]}, {"id": "2002.01768", "submitter": "Mihail Bogojeski", "authors": "Mihail Bogojeski, Simeon Sauer, Franziska Horn, Klaus-Robert M\\\"uller", "title": "Forecasting Industrial Aging Processes with Machine Learning Methods", "comments": "30 pages (41 including appendix), 13 figures, accepted in Computers\n  and Chemical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting industrial aging processes makes it possible to\nschedule maintenance events further in advance, ensuring a cost-efficient and\nreliable operation of the plant. So far, these degradation processes were\nusually described by mechanistic or simple empirical prediction models. In this\npaper, we evaluate a wider range of data-driven models, comparing some\ntraditional stateless models (linear and kernel ridge regression, feed-forward\nneural networks) to more complex recurrent neural networks (echo state networks\nand LSTMs). We first examine how much historical data is needed to train each\nof the models on a synthetic dataset with known dynamics. Next, the models are\ntested on real-world data from a large scale chemical plant. Our results show\nthat recurrent models produce near perfect predictions when trained on larger\ndatasets, and maintain a good performance even when trained on smaller datasets\nwith domain shifts, while the simpler models only performed comparably on the\nsmaller datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:06:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:00:44 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Bogojeski", "Mihail", ""], ["Sauer", "Simeon", ""], ["Horn", "Franziska", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2002.01771", "submitter": "Se-In Jang", "authors": "Se-In Jang", "title": "Online Passive-Aggressive Total-Error-Rate Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a new online learning algorithm which utilizes online\npassive-aggressive learning (PA) and total-error-rate minimization (TER) for\nbinary classification. The PA learning establishes not only large margin\ntraining but also the capacity to handle non-separable data. The TER learning\non the other hand minimizes an approximated classification error based\nobjective function. We propose an online PATER algorithm which combines those\nuseful properties. In addition, we also present a weighted PATER algorithm to\nimprove the ability to cope with data imbalance problems. Experimental results\ndemonstrate that the proposed PATER algorithms achieves better performances in\nterms of efficiency and effectiveness than the existing state-of-the-art online\nlearning algorithms in real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:10:01 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Jang", "Se-In", ""]]}, {"id": "2002.01775", "submitter": "Inseop Chung", "authors": "Inseop Chung, SeongUk Park, Jangho Kim, Nojun Kwak", "title": "Feature-map-level Online Adversarial Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature maps contain rich information about image intensity and spatial\ncorrelation. However, previous online knowledge distillation methods only\nutilize the class probabilities. Thus in this paper, we propose an online\nknowledge distillation method that transfers not only the knowledge of the\nclass probabilities but also that of the feature map using the adversarial\ntraining framework. We train multiple networks simultaneously by employing\ndiscriminators to distinguish the feature map distributions of different\nnetworks. Each network has its corresponding discriminator which discriminates\nthe feature map from its own as fake while classifying that of the other\nnetwork as real. By training a network to fool the corresponding discriminator,\nit can learn the other network's feature map distribution. We show that our\nmethod performs better than the conventional direct alignment method such as L1\nand is more suitable for online distillation. Also, we propose a novel cyclic\nlearning scheme for training more than two networks together. We have applied\nour method to various network architectures on the classification task and\ndiscovered a significant improvement of performance especially in the case of\ntraining a pair of a small network and a large one.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:16:37 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 17:58:38 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 18:15:40 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chung", "Inseop", ""], ["Park", "SeongUk", ""], ["Kim", "Jangho", ""], ["Kwak", "Nojun", ""]]}, {"id": "2002.01793", "submitter": "Yacov Hel-Or", "authors": "Inbal Lav, Shai Avidan, Yoram Singer, Yacov Hel-Or", "title": "Proximity Preserving Binary Code using Signed Graph-Cut", "comments": null, "journal-ref": "AAAI Conference on Artificial Intelligence , Feb. 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a binary embedding framework, called Proximity Preserving Code\n(PPC), which learns similarity and dissimilarity between data points to create\na compact and affinity-preserving binary code. This code can be used to apply\nfast and memory-efficient approximation to nearest-neighbor searches. Our\nframework is flexible, enabling different proximity definitions between data\npoints. In contrast to previous methods that extract binary codes based on\nunsigned graph partitioning, our system models the attractive and repulsive\nforces in the data by incorporating positive and negative graph weights. The\nproposed framework is shown to boil down to finding the minimal cut of a signed\ngraph, a problem known to be NP-hard. We offer an efficient approximation and\nachieve superior results by constructing the code bit after bit. We show that\nthe proposed approximation is superior to the commonly used spectral methods\nwith respect to both accuracy and complexity. Thus, it is useful for many other\nproblems that can be translated into signed graph cut.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 13:58:41 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Lav", "Inbal", ""], ["Avidan", "Shai", ""], ["Singer", "Yoram", ""], ["Hel-Or", "Yacov", ""]]}, {"id": "2002.01808", "submitter": "Ruize Wang", "authors": "Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Jianshu\n  ji, Guihong Cao, Daxin Jiang, Ming Zhou", "title": "K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of injecting knowledge into large pre-trained models\nlike BERT and RoBERTa. Existing methods typically update the original\nparameters of pre-trained models when injecting knowledge. However, when\nmultiple kinds of knowledge are injected, the historically injected knowledge\nwould be flushed away. To address this, we propose K-Adapter, a framework that\nretains the original parameters of the pre-trained model fixed and supports the\ndevelopment of versatile knowledge-infused model. Taking RoBERTa as the\nbackbone model, K-Adapter has a neural adapter for each kind of infused\nknowledge, like a plug-in connected to RoBERTa. There is no information flow\nbetween different adapters, thus multiple adapters can be efficiently trained\nin a distributed way. As a case study, we inject two kinds of knowledge in this\nwork, including (1) factual knowledge obtained from automatically aligned\ntext-triplets on Wikipedia and Wikidata and (2) linguistic knowledge obtained\nvia dependency parsing. Results on three knowledge-driven tasks, including\nrelation classification, entity typing, and question answering, demonstrate\nthat each adapter improves the performance and the combination of both adapters\nbrings further improvements. Further analysis indicates that K-Adapter captures\nversatile knowledge than RoBERTa.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:30:49 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 03:30:44 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 06:29:54 GMT"}, {"version": "v4", "created": "Sun, 4 Oct 2020 16:11:45 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 06:07:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Wang", "Ruize", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Wei", "Zhongyu", ""], ["Huang", "Xuanjing", ""], ["ji", "Jianshu", ""], ["Cao", "Guihong", ""], ["Jiang", "Daxin", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.01810", "submitter": "Felix Assion", "authors": "David Mickisch, Felix Assion, Florens Gre{\\ss}ner, Wiebke G\\\"unther,\n  Mariele Motta", "title": "Understanding the Decision Boundary of Deep Neural Networks: An\n  Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving remarkable performance on many image classification tasks,\nstate-of-the-art machine learning (ML) classifiers remain vulnerable to small\ninput perturbations. Especially, the existence of adversarial examples raises\nconcerns about the deployment of ML models in safety- and security-critical\nenvironments, like autonomous driving and disease detection. Over the last few\nyears, numerous defense methods have been published with the goal of improving\nadversarial as well as corruption robustness. However, the proposed measures\nsucceeded only to a very limited extent. This limited progress is partly due to\nthe lack of understanding of the decision boundary and decision regions of deep\nneural networks. Therefore, we study the minimum distance of data points to the\ndecision boundary and how this margin evolves over the training of a deep\nneural network. By conducting experiments on MNIST, FASHION-MNIST, and\nCIFAR-10, we observe that the decision boundary moves closer to natural images\nover training. This phenomenon even remains intact in the late epochs of\ntraining, where the classifier already obtains low training and test error\nrates. On the other hand, adversarial training appears to have the potential to\nprevent this undesired convergence of the decision boundary.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:34:22 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Mickisch", "David", ""], ["Assion", "Felix", ""], ["Gre\u00dfner", "Florens", ""], ["G\u00fcnther", "Wiebke", ""], ["Motta", "Mariele", ""]]}, {"id": "2002.01849", "submitter": "Pini Zilber", "authors": "Jonathan Bauch, Boaz Nadler and Pini Zilber", "title": "Rank $2r$ iterative least squares: efficient recovery of ill-conditioned\n  low rank matrices from few entries", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science, 3(1), 439-465 (2021)", "doi": "10.1137/20M1315294", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, simple and computationally efficient iterative method for\nlow rank matrix completion. Our method is inspired by the class of\nfactorization-type iterative algorithms, but substantially differs from them in\nthe way the problem is cast. Precisely, given a target rank $r$, instead of\noptimizing on the manifold of rank $r$ matrices, we allow our interim estimated\nmatrix to have a specific over-parametrized rank $2r$ structure. Our algorithm,\ndenoted R2RILS for rank $2r$ iterative least squares, has low memory\nrequirements, and at each iteration it solves a computationally cheap sparse\nleast-squares problem. We motivate our algorithm by its theoretical analysis\nfor the simplified case of a rank-1 matrix. Empirically, R2RILS is able to\nrecover ill conditioned low rank matrices from very few observations -- near\nthe information limit, and it is stable to additive noise.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:20:58 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 17:10:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bauch", "Jonathan", ""], ["Nadler", "Boaz", ""], ["Zilber", "Pini", ""]]}, {"id": "2002.01861", "submitter": "Jimmy Lin", "authors": "Ruixue Zhang, Wei Yang, Luyun Lin, Zhengkai Tu, Yuqing Xie, Zihang Fu,\n  Yuhao Xie, Luchen Tan, Kun Xiong, Jimmy Lin", "title": "Rapid Adaptation of BERT for Information Extraction on Domain-Specific\n  Business Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for automatically extracting important content elements from\nbusiness documents such as contracts, statements, and filings have the\npotential to make business operations more efficient. This problem can be\nformulated as a sequence labeling task, and we demonstrate the adaption of BERT\nto two types of business documents: regulatory filings and property lease\nagreements. There are aspects of this problem that make it easier than\n\"standard\" information extraction tasks and other aspects that make it more\ndifficult, but on balance we find that modest amounts of annotated data (less\nthan 100 documents) are sufficient to achieve reasonable accuracy. We integrate\nour models into an end-to-end cloud platform that provides both an easy-to-use\nannotation interface as well as an inference interface that allows users to\nupload documents and inspect model outputs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:45:44 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Zhang", "Ruixue", ""], ["Yang", "Wei", ""], ["Lin", "Luyun", ""], ["Tu", "Zhengkai", ""], ["Xie", "Yuqing", ""], ["Fu", "Zihang", ""], ["Xie", "Yuhao", ""], ["Tan", "Luchen", ""], ["Xiong", "Kun", ""], ["Lin", "Jimmy", ""]]}, {"id": "2002.01873", "submitter": "George De Ath", "authors": "George De Ath, Richard M. Everson, Jonathan E. Fieldsend, Alma A. M.\n  Rahat", "title": "$\\epsilon$-shotgun: $\\epsilon$-greedy Batch Bayesian Optimisation", "comments": "Genetic and Evolutionary Computation Conference 2020 (GECCO '20). 9\n  pages (main paper) + 11 pages (supplementary material). Code avaliable at\n  https://github.com/georgedeath/eshotgun", "journal-ref": null, "doi": "10.1145/3377930.3390154", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular, surrogate model-based approach for\noptimising expensive black-box functions. Given a surrogate model, the next\nlocation to expensively evaluate is chosen via maximisation of a cheap-to-query\nacquisition function. We present an $\\epsilon$-greedy procedure for Bayesian\noptimisation in batch settings in which the black-box function can be evaluated\nmultiple times in parallel. Our $\\epsilon$-shotgun algorithm leverages the\nmodel's prediction, uncertainty, and the approximated rate of change of the\nlandscape to determine the spread of batch solutions to be distributed around a\nputative location. The initial target location is selected either in an\nexploitative fashion on the mean prediction, or -- with probability $\\epsilon$\n-- from elsewhere in the design space. This results in locations that are more\ndensely sampled in regions where the function is changing rapidly and in\nlocations predicted to be good (i.e close to predicted optima), with more\nscattered samples in regions where the function is flatter and/or of poorer\nquality. We empirically evaluate the $\\epsilon$-shotgun methods on a range of\nsynthetic functions and two real-world problems, finding that they perform at\nleast as well as state-of-the-art batch methods and in many cases exceed their\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:24:39 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 15:25:31 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard M.", ""], ["Fieldsend", "Jonathan E.", ""], ["Rahat", "Alma A. M.", ""]]}, {"id": "2002.01878", "submitter": "Henri De Plaen", "authors": "Henri De Plaen, Micha\\\"el Fanuel and Johan A. K. Suykens", "title": "Wasserstein Exponential Kernels", "comments": "9 pages, 3 figures and 1 table", "journal-ref": null, "doi": null, "report-no": "Internal Report 20-12, ESAT-STADIUS, KU Leuven (Leuven, Belgium)", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of kernel methods, the similarity between data points is\nencoded by the kernel function which is often defined thanks to the Euclidean\ndistance, a common example being the squared exponential kernel. Recently,\nother distances relying on optimal transport theory - such as the Wasserstein\ndistance between probability distributions - have shown their practical\nrelevance for different machine learning techniques. In this paper, we study\nthe use of exponential kernels defined thanks to the regularized Wasserstein\ndistance and discuss their positive definiteness. More specifically, we define\nWasserstein feature maps and illustrate their interest for supervised learning\nproblems involving shapes and images. Empirically, Wasserstein squared\nexponential kernels are shown to yield smaller classification errors on small\ntraining sets of shapes, compared to analogous classifiers using Euclidean\ndistances.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:31:56 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["De Plaen", "Henri", ""], ["Fanuel", "Micha\u00ebl", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.01882", "submitter": "Ilja Kuzborskij", "authors": "Ilja Kuzborskij, Nicol\\`o Cesa-Bianchi", "title": "Locally-Adaptive Nonparametric Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main strengths of online algorithms is their ability to adapt to\narbitrary data sequences. This is especially important in nonparametric\nsettings, where performance is measured against rich classes of comparator\nfunctions that are able to fit complex environments. Although such hard\ncomparators and complex environments may exhibit local regularities, efficient\nalgorithms, which can provably take advantage of these local patterns, are\nhardly known. We fill this gap by introducing efficient online algorithms\n(based on a single versatile master algorithm) each adapting to one of the\nfollowing regularities: (i) local Lipschitzness of the competitor function,\n(ii) local metric dimension of the instance sequence, (iii) local performance\nof the predictor across different regions of the instance space. Extending\nprevious approaches, we design algorithms that dynamically grow hierarchical\n$\\epsilon$-nets on the instance space whose prunings correspond to different\n\"locality profiles\" for the problem at hand. Using a technique based on tree\nexperts, we simultaneously and efficiently compete against all such prunings,\nand prove regret bounds each scaling with a quantity associated with a\ndifferent type of local regularity. When competing against \"simple\" locality\nprofiles, our technique delivers regret bounds that are significantly better\nthan those proven using the previous approach. On the other hand, the time\ndependence of our bounds is not worse than that obtained by ignoring any local\nregularities.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:42:04 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 14:37:18 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kuzborskij", "Ilja", ""], ["Cesa-Bianchi", "Nicol\u00f2", ""]]}, {"id": "2002.01883", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Neev Parikh, Ronald E. Parr, George D. Konidaris,\n  Michael L. Littman", "title": "Deep Radial-Basis Value Functions for Continuous Control", "comments": "In Proceedings of the 35th AAAI Conference on Artificial Intelligence\n  (AAAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core operation in reinforcement learning (RL) is finding an action that is\noptimal with respect to a learned value function. This operation is often\nchallenging when the learned value function takes continuous actions as input.\nWe introduce deep radial-basis value functions (RBVFs): value functions learned\nusing a deep network with a radial-basis function (RBF) output layer. We show\nthat the maximum action-value with respect to a deep RBVF can be approximated\neasily and accurately. Moreover, deep RBVFs can represent any true value\nfunction owing to their support for universal function approximation. We extend\nthe standard DQN algorithm to continuous control by endowing the agent with a\ndeep RBVF. We show that the resultant agent, called RBF-DQN, significantly\noutperforms value-function-only baselines, and is competitive with\nstate-of-the-art actor-critic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:44:16 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 01:29:44 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Asadi", "Kavosh", ""], ["Parikh", "Neev", ""], ["Parr", "Ronald E.", ""], ["Konidaris", "George D.", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.01889", "submitter": "Tatjana Petrov", "authors": "Tatjana Petrov and Denis Repin", "title": "Automated Deep Abstractions for Stochastic Chemical Reaction Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting stochastic cellular dynamics as emerging from the mechanistic\nmodels of molecular interactions is a long-standing challenge in systems\nbiology: low-level chemical reaction network (CRN) models give raise to a\nhighly-dimensional continuous-time Markov chain (CTMC) which is computationally\ndemanding and often prohibitive to analyse in practice. A recently proposed\nabstraction method uses deep learning to replace this CTMC with a discrete-time\ncontinuous-space process, by training a mixture density deep neural network\nwith traces sampled at regular time intervals (which can obtained either by\nsimulating a given CRN or as time-series data from experiment). The major\nadvantage of such abstraction is that it produces a computational model that is\ndramatically cheaper to execute, while preserving the statistical features of\nthe training data. In general, the abstraction accuracy improves with the\namount of training data. However, depending on a CRN, the overall quality of\nthe method -- the efficiency gain and abstraction accuracy -- will also depend\non the choice of neural network architecture given by hyper-parameters such as\nthe layer types and connections between them. As a consequence, in practice,\nthe modeller would have to take care of finding the suitable architecture\nmanually, for each given CRN, through a tedious and time-consuming\ntrial-and-error cycle. In this paper, we propose to further automatise deep\nabstractions for stochastic CRNs, through learning the optimal neural network\narchitecture along with learning the transition kernel of the abstract process.\nAutomated search of the architecture makes the method applicable directly to\nany given CRN, which is time-saving for deep learning experts and crucial for\nnon-specialists. We implement the method and demonstrate its performance on a\nnumber of representative CRNs with multi-modal emergent phenotypes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:49:58 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Petrov", "Tatjana", ""], ["Repin", "Denis", ""]]}, {"id": "2002.01890", "submitter": "Thais Fonseca Dr", "authors": "Victhor S. Sart\\'orio and Tha\\'is C. O. Fonseca", "title": "Dynamic clustering of time series data", "comments": "27 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for clustering multivariate time-series data based on\nDynamic Linear Models. Whereas usual time-series clustering methods obtain\nstatic membership parameters, our proposal allows each time-series to\ndynamically change their cluster memberships over time. In this context, a\nmixture model is assumed for the time series and a flexible Dirichlet evolution\nfor mixture weights allows for smooth membership changes over time. Posterior\nestimates and predictions can be obtained through Gibbs sampling, but a more\nefficient method for obtaining point estimates is presented, based on\nStochastic Expectation-Maximization and Gradient Descent. Finally, two\napplications illustrate the usefulness of our proposed model to model both\nunivariate and multivariate time-series: World Bank indicators for the\nrenewable energy consumption of EU nations and the famous Gapminder dataset\ncontaining life-expectancy and GDP per capita for various countries.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:01:28 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Sart\u00f3rio", "Victhor S.", ""], ["Fonseca", "Tha\u00eds C. O.", ""]]}, {"id": "2002.01891", "submitter": "Yasuhiko Tachibana", "authors": "Yasuhiko Tachibana, Masataka Nishimori, Naoyuki Kitamura, Kensuke\n  Umehara, Junko Ota, Takayuki Obata, and Tatsuya Higashi", "title": "A neural network model that learns differences in diagnosis strategies\n  among radiologists has an improved area under the curve for aneurysm status\n  classification in magnetic resonance angiography image series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To construct a neural network model that can learn the different\ndiagnosing strategies of radiologists to better classify aneurysm status in\nmagnetic resonance angiography images. Materials and methods: This\nretrospective study included 3423 time-of-flight brain magnetic resonance\nangiography image series (subjects: male 1843 [mean age, 50.2 +/- 11.7 years],\nfemale 1580 [50.8 +/- 11.3 years]) recorded from November 2017 through January\n2019. The image series were read independently for aneurysm status by one of\nfour board-certified radiologists, who were assisted by an established deep\nlearning-based computer-assisted diagnosis (CAD) system. The constructed neural\nnetworks were trained to classify the aneurysm status of zero to five\naneurysm-suspicious areas suggested by the CAD system for each image series,\nand any additional aneurysm areas added by the radiologists, and this\nclassification was compared with the judgment of the annotating radiologist.\nImage series were randomly allocated to training and testing data in an 8:2\nratio. The accuracy of the classification was compared by receiver operating\ncharacteristic analysis between the control model that accepted only image data\nas input and the proposed model that additionally accepted the information of\nwho the annotating radiologist was. The DeLong test was used to compare areas\nunder the curves (P < 0.05 was considered significant). Results: The area under\nthe curve was larger in the proposed model (0.845) than in the control model\n(0.793), and the difference was significant (P < 0.0001). Conclusion: The\nproposed model improved classification accuracy by learning the diagnosis\nstrategies of individual annotating radiologists.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:19:57 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Tachibana", "Yasuhiko", ""], ["Nishimori", "Masataka", ""], ["Kitamura", "Naoyuki", ""], ["Umehara", "Kensuke", ""], ["Ota", "Junko", ""], ["Obata", "Takayuki", ""], ["Higashi", "Tatsuya", ""]]}, {"id": "2002.01893", "submitter": "Houpu Yao", "authors": "Houpu Yao, Yi Gao, Yongming Liu", "title": "FEA-Net: A Physics-guided Data-driven Model for Efficient Mechanical\n  Response Prediction", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.112892", "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovative physics-guided learning algorithm for predicting the mechanical\nresponse of materials and structures is proposed in this paper. The key concept\nof the proposed study is based on the fact that physics models are governed by\nPartial Differential Equation (PDE), and its loading/ response mapping can be\nsolved using Finite Element Analysis (FEA). Based on this, a special type of\ndeep convolutional neural network (DCNN) is proposed that takes advantage of\nour prior knowledge in physics to build data-driven models whose architectures\nare of physics meaning. This type of network is named as FEA-Net and is used to\nsolve the mechanical response under external loading. Thus, the identification\nof a mechanical system parameters and the computation of its responses are\ntreated as the learning and inference of FEA-Net, respectively. Case studies on\nmulti-physics (e.g., coupled mechanical-thermal analysis) and multi-phase\nproblems (e.g., composite materials with random micro-structures) are used to\ndemonstrate and verify the theoretical and computational advantages of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 09:37:44 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yao", "Houpu", ""], ["Gao", "Yi", ""], ["Liu", "Yongming", ""]]}, {"id": "2002.01896", "submitter": "Diab Abueidda", "authors": "Diab W. Abueidda, Seid Koric, Nahil A. Sobh", "title": "Topology optimization of 2D structures with nonlinearities using deep\n  learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.compstruc.2020.106283", "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of optimal design of linear elastic structures has seen many\nexciting successes that resulted in new architected materials and structural\ndesigns. With the availability of cloud computing, including high-performance\ncomputing, machine learning, and simulation, searching for optimal nonlinear\nstructures is now within reach. In this study, we develop convolutional neural\nnetwork models to predict optimized designs for a given set of boundary\nconditions, loads, and optimization constraints. We have considered the case of\nmaterials with a linear elastic response with and without stress constraint.\nAlso, we have considered the case of materials with a hyperelastic response,\nwhere material and geometric nonlinearities are involved. For the nonlinear\nelastic case, the neo-Hookean model is utilized. For this purpose, we generate\ndatasets composed of the optimized designs paired with the corresponding\nboundary conditions, loads, and constraints, using a topology optimization\nframework to train and validate the neural network models. The developed models\nare capable of accurately predicting the optimized designs without requiring an\niterative scheme and with negligible inference computational time. The\nsuggested pipeline can be generalized to other nonlinear mechanics scenarios\nand design domains.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:36:17 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 12:10:23 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 23:19:51 GMT"}, {"version": "v4", "created": "Mon, 13 Apr 2020 18:51:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Abueidda", "Diab W.", ""], ["Koric", "Seid", ""], ["Sobh", "Nahil A.", ""]]}, {"id": "2002.01910", "submitter": "Guillaume Salha-Galvan", "authors": "Guillaume Salha and Romain Hennequin and Jean-Baptiste Remy and Manuel\n  Moussallam and Michalis Vazirgiannis", "title": "FastGAE: Scalable Graph Autoencoders with Stochastic Subgraph Decoding", "comments": "Accepted for publication in Elsevier's Neural Networks journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph autoencoders (AE) and variational autoencoders (VAE) are powerful node\nembedding methods, but suffer from scalability issues. In this paper, we\nintroduce FastGAE, a general framework to scale graph AE and VAE to large\ngraphs with millions of nodes and edges. Our strategy, based on an effective\nstochastic subgraph decoding scheme, significantly speeds up the training of\ngraph AE and VAE while preserving or even improving performances. We\ndemonstrate the effectiveness of FastGAE on various real-world graphs,\noutperforming the few existing approaches to scale graph AE and VAE by a wide\nmargin.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:27:39 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 16:54:02 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 14:05:07 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 12:42:24 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 15:37:01 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Salha", "Guillaume", ""], ["Hennequin", "Romain", ""], ["Remy", "Jean-Baptiste", ""], ["Moussallam", "Manuel", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2002.01913", "submitter": "Augusto Luis Ballardini PhD", "authors": "Augusto Luis Ballardini, Daniele Cattaneo, Rub\\'en Izquierdo, Ignacio\n  Parra Alonso, Andrea Piazzoni, Miguel \\'Angel Sotelo, Domenico Giorgio\n  Sorrenti", "title": "Vehicle Ego-Lane Estimation with Sensor Failure Modeling", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a probabilistic ego-lane estimation algorithm for highway-like\nscenarios that is designed to increase the accuracy of the ego-lane estimate,\nwhich can be obtained relying only on a noisy line detector and tracker. The\ncontribution relies on a Hidden Markov Model (HMM) with a transient failure\nmodel. The proposed algorithm exploits the OpenStreetMap (or other cartographic\nservices) road property lane number as the expected number of lanes and\nleverages consecutive, possibly incomplete, observations. The algorithm\neffectiveness is proven by employing different line detectors and showing we\ncould achieve much more usable, i.e. stable and reliable, ego-lane estimates\nover more than 100 Km of highway scenarios, recorded both in Italy and Spain.\nMoreover, as we could not find a suitable dataset for a quantitative comparison\nwith other approaches, we collected datasets and manually annotated the Ground\nTruth about the vehicle ego-lane. Such datasets are made publicly available for\nusage from the scientific community.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:32:00 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 15:06:49 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ballardini", "Augusto Luis", ""], ["Cattaneo", "Daniele", ""], ["Izquierdo", "Rub\u00e9n", ""], ["Alonso", "Ignacio Parra", ""], ["Piazzoni", "Andrea", ""], ["Sotelo", "Miguel \u00c1ngel", ""], ["Sorrenti", "Domenico Giorgio", ""]]}, {"id": "2002.01921", "submitter": "Thai Duong", "authors": "Thai Duong, Nikhil Das, Michael Yip, Nikolay Atanasov", "title": "Autonomous Navigation in Unknown Environments using Sparse Kernel-based\n  Occupancy Mapping", "comments": "Accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on real-time occupancy mapping and collision checking\nonboard an autonomous robot navigating in an unknown environment. We propose a\nnew map representation, in which occupied and free space are separated by the\ndecision boundary of a kernel perceptron classifier. We develop an online\ntraining algorithm that maintains a very sparse set of support vectors to\nrepresent obstacle boundaries in configuration space. We also derive conditions\nthat allow complete (without sampling) collision-checking for piecewise-linear\nand piecewise-polynomial robot trajectories. We demonstrate the effectiveness\nof our mapping and collision checking algorithms for autonomous navigation of\nan Ackermann-drive robot in unknown environments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:54:07 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Duong", "Thai", ""], ["Das", "Nikhil", ""], ["Yip", "Michael", ""], ["Atanasov", "Nikolay", ""]]}, {"id": "2002.01925", "submitter": "Khansa Rasheed", "authors": "Khansa Rasheed, Adnan Qayyum, Junaid Qadir, Shobi Sivathamboo, Patrick\n  Kwan, Levin Kuhlmann, Terence O'Brien, and Adeel Razi", "title": "Machine Learning for Predicting Epileptic Seizures Using EEG Signals: A\n  Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in artificial intelligence (AI) and machine learning\n(ML) techniques, researchers are striving towards employing these techniques\nfor advancing clinical practice. One of the key objectives in healthcare is the\nearly detection and prediction of disease to timely provide preventive\ninterventions. This is especially the case for epilepsy, which is characterized\nby recurrent and unpredictable seizures. Patients can be relieved from the\nadverse consequences of epileptic seizures if it could somehow be predicted in\nadvance. Despite decades of research, seizure prediction remains an unsolved\nproblem. This is likely to remain at least partly because of the inadequate\namount of data to resolve the problem. There have been exciting new\ndevelopments in ML-based algorithms that have the potential to deliver a\nparadigm shift in the early and accurate prediction of epileptic seizures. Here\nwe provide a comprehensive review of state-of-the-art ML techniques in early\nprediction of seizures using EEG signals. We will identify the gaps,\nchallenges, and pitfalls in the current research and recommend future\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 06:22:24 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Rasheed", "Khansa", ""], ["Qayyum", "Adnan", ""], ["Qadir", "Junaid", ""], ["Sivathamboo", "Shobi", ""], ["Kwan", "Patrick", ""], ["Kuhlmann", "Levin", ""], ["O'Brien", "Terence", ""], ["Razi", "Adeel", ""]]}, {"id": "2002.01927", "submitter": "Changyu Deng", "authors": "Changyu Deng, Yizhou Wang, Can Qin, Wei Lu", "title": "Self-Directed Online Machine Learning for Topology Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topology optimization by optimally distributing materials in a given domain\nrequires gradient-free optimizers to solve highly complicated problems.\nHowever, with hundreds of design variables or more involved, solving such\nproblems would require millions of Finite Element Method (FEM) calculations\nwhose computational cost is huge and impractical. Here we report a\nSelf-directed Online Learning Optimization (SOLO) which integrates Deep Neural\nNetwork (DNN) with FEM calculations. A DNN learns and substitutes the objective\nas a function of design variables. A small amount of training data is generated\ndynamically based on the DNN's prediction of the global optimum. The DNN adapts\nto the new training data and gives better prediction in the region of interest\nuntil convergence. Our algorithm was tested by compliance minimization problems\nand fluid-structure optimization problems. It reduced the computational time by\n2~5 orders of magnitude compared with directly using heuristic methods, and\noutperformed all state-of-the-art algorithms tested in our experiments. This\napproach enables solving large multi-dimensional optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 20:00:28 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 21:25:57 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 14:40:54 GMT"}, {"version": "v4", "created": "Sat, 12 Sep 2020 18:58:11 GMT"}, {"version": "v5", "created": "Tue, 15 Sep 2020 00:53:37 GMT"}, {"version": "v6", "created": "Mon, 4 Jan 2021 16:12:25 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Deng", "Changyu", ""], ["Wang", "Yizhou", ""], ["Qin", "Can", ""], ["Lu", "Wei", ""]]}, {"id": "2002.01953", "submitter": "Henry Moss", "authors": "Henry B.Moss, Vatsal Aggarwal, Nishant Prateek, Javier Gonz\\'alez,\n  Roberto Barra-Chicote", "title": "BOFFIN TTS: Few-Shot Speaker Adaptation by Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BOFFIN TTS (Bayesian Optimization For FIne-tuning Neural Text To\nSpeech), a novel approach for few-shot speaker adaptation. Here, the task is to\nfine-tune a pre-trained TTS model to mimic a new speaker using a small corpus\nof target utterances. We demonstrate that there does not exist a\none-size-fits-all adaptation strategy, with convincing synthesis requiring a\ncorpus-specific configuration of the hyper-parameters that control fine-tuning.\nBy using Bayesian optimization to efficiently optimize these hyper-parameter\nvalues for a target speaker, we are able to perform adaptation with an average\n30% improvement in speaker similarity over standard techniques. Results\nindicate, across multiple corpora, that BOFFIN TTS can learn to synthesize new\nspeakers using less than ten minutes of audio, achieving the same naturalness\nas produced for the speakers used to train the base model.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 16:37:52 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Moss", "Henry B.", ""], ["Aggarwal", "Vatsal", ""], ["Prateek", "Nishant", ""], ["Gonz\u00e1lez", "Javier", ""], ["Barra-Chicote", "Roberto", ""]]}, {"id": "2002.01955", "submitter": "Byungsoo Jeon", "authors": "Byungsoo Jeon, Namyong Park", "title": "Dropout Prediction over Weeks in MOOCs by Learning Representations of\n  Clicks and Videos", "comments": "Accepted at AAAI 2020 AI4Edu Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a key challenge in MOOC dropout prediction, namely to\nbuild meaningful representations from clickstream data. While a variety of\nfeature extraction techniques have been explored extensively for such purposes,\nto our knowledge, no prior works have explored modeling of educational content\n(e.g. video) and their correlation with the learner's behavior (e.g.\nclickstream) in this context. We bridge this gap by devising a method to learn\nrepresentation for videos and the correlation between videos and clicks. The\nresults indicate that modeling videos and their correlation with clicks bring\nstatistically significant improvements in predicting dropout.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:10:01 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Jeon", "Byungsoo", ""], ["Park", "Namyong", ""]]}, {"id": "2002.01963", "submitter": "Rui Zhao", "authors": "Rui Zhao, Yang Gao, Pieter Abbeel, Volker Tresp, Wei Xu", "title": "Mutual Information-based State-Control for Intrinsically Motivated\n  Reinforcement Learning", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, an agent learns to reach a set of goals by means\nof an external reward signal. In the natural world, intelligent organisms learn\nfrom internal drives, bypassing the need for external signals, which is\nbeneficial for a wide range of tasks. Motivated by this observation, we propose\nto formulate an intrinsic objective as the mutual information between the goal\nstates and the controllable states. This objective encourages the agent to take\ncontrol of its environment. Subsequently, we derive a surrogate objective of\nthe proposed reward function, which can be optimized efficiently. Lastly, we\nevaluate the developed framework in different robotic manipulation and\nnavigation tasks and demonstrate the efficacy of our approach. A video showing\nexperimental results is available at https://youtu.be/CT4CKMWBYz0\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:21:20 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 19:07:38 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Zhao", "Rui", ""], ["Gao", "Yang", ""], ["Abbeel", "Pieter", ""], ["Tresp", "Volker", ""], ["Xu", "Wei", ""]]}, {"id": "2002.01965", "submitter": "Andrew Patterson", "authors": "Andrew Patterson, Aditya Gahlawat, Naira Hovakimyan", "title": "Learning Probabilistic Intersection Traffic Models for Trajectory\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous agents must be able to safely interact with other vehicles to\nintegrate into urban environments. The safety of these agents is dependent on\ntheir ability to predict collisions with other vehicles' future trajectories\nfor replanning and collision avoidance. The information needed to predict\ncollisions can be learned from previously observed vehicle trajectories in a\nspecific environment, generating a traffic model. The learned traffic model can\nthen be incorporated as prior knowledge into any trajectory estimation method\nbeing used in this environment. This work presents a Gaussian process based\nprobabilistic traffic model that is used to quantify vehicle behaviors in an\nintersection. The Gaussian process model provides estimates for the average\nvehicle trajectory, while also capturing the variance between the different\npaths a vehicle may take in the intersection. The method is demonstrated on a\nset of time-series position trajectories. These trajectories are reconstructed\nby removing object recognition errors and missed frames that may occur due to\ndata source processing. To create the intersection traffic model, the\nreconstructed trajectories are clustered based on their source and destination\nlanes. For each cluster, a Gaussian process model is created to capture the\naverage behavior and the variance of the cluster. To show the applicability of\nthe Gaussian model, the test trajectories are classified with only partial\nobservations. Performance is quantified by the number of observations required\nto correctly classify the vehicle trajectory. Both the intersection traffic\nmodeling computations and the classification procedure are timed. These times\nare presented as results and demonstrate that the model can be constructed in a\nreasonable amount of time and the classification procedure can be used for\nonline applications.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:22:26 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Patterson", "Andrew", ""], ["Gahlawat", "Aditya", ""], ["Hovakimyan", "Naira", ""]]}, {"id": "2002.01973", "submitter": "Raul Rojas Prof.", "authors": "Raul Rojas", "title": "Exploring Maximum Entropy Distributions with Evolutionary Algorithms", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IT cs.LG cs.NE math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to evolve numerically the maximum entropy probability\ndistributions for a given set of constraints, which is a variational calculus\nproblem. An evolutionary algorithm can obtain approximations to some well-known\nanalytical results, but is even more flexible and can find distributions for\nwhich a closed formula cannot be readily stated. The numerical approach handles\ndistributions over finite intervals. We show that there are two ways of\nconducting the procedure: by direct optimization of the Lagrangian of the\nconstrained problem, or by optimizing the entropy among the subset of\ndistributions which fulfill the constraints. An incremental evolutionary\nstrategy easily obtains the uniform, the exponential, the Gaussian, the\nlog-normal, the Laplace, among other distributions, once the constrained\nproblem is solved with any of the two methods. Solutions for mixed (\"chimera\")\ndistributions can be also found. We explain why many of the distributions are\nsymmetrical and continuous, but some are not.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:52:05 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Rojas", "Raul", ""]]}, {"id": "2002.01982", "submitter": "Vaishnavi Subramanian", "authors": "Vaishnavi Subramanian, Minh N. Do, Tanveer Syeda-Mahmood", "title": "Multimodal fusion of imaging and genomics for lung cancer recurrence\n  prediction", "comments": "Accepted for presentation at International Symposium on Biomedical\n  Imaging (ISBI) 2020 (Iowa City). 5 pages, last page references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer has a high rate of recurrence in early-stage patients. Predicting\nthe post-surgical recurrence in lung cancer patients has traditionally been\napproached using single modality information of genomics or radiology images.\nWe investigate the potential of multimodal fusion for this task. By combining\ncomputed tomography (CT) images and genomics, we demonstrate improved\nprediction of recurrence using linear Cox proportional hazards models with\nelastic net regularization. We work on a recent non-small cell lung cancer\n(NSCLC) radiogenomics dataset of 130 patients and observe an increase in\nconcordance-index values of up to 10%. Employing non-linear methods from the\nneural network literature, such as multi-layer perceptrons and visual-question\nanswering fusion modules, did not improve performance consistently. This\nindicates the need for larger multimodal datasets and fusion techniques better\nadapted to this biological setting.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 20:32:36 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Subramanian", "Vaishnavi", ""], ["Do", "Minh N.", ""], ["Syeda-Mahmood", "Tanveer", ""]]}, {"id": "2002.01987", "submitter": "Maxim Raginsky", "authors": "Belinda Tzen and Maxim Raginsky", "title": "A mean-field theory of lazy training in two-layer neural nets: entropic\n  regularization and controlled McKean-Vlasov dynamics", "comments": "fixed a few typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of universal approximation of functions by two-layer\nneural nets with random weights that are \"nearly Gaussian\" in the sense of\nKullback-Leibler divergence. This problem is motivated by recent works on lazy\ntraining, where the weight updates generated by stochastic gradient descent do\nnot move appreciably from the i.i.d. Gaussian initialization. We first consider\nthe mean-field limit, where the finite population of neurons in the hidden\nlayer is replaced by a continual ensemble, and show that our problem can be\nphrased as global minimization of a free-energy functional on the space of\nprobability measures over the weights. This functional trades off the $L^2$\napproximation risk against the KL divergence with respect to a centered\nGaussian prior. We characterize the unique global minimizer and then construct\na controlled nonlinear dynamics in the space of probability measures over\nweights that solves a McKean--Vlasov optimal control problem. This control\nproblem is closely related to the Schr\\\"odinger bridge (or entropic optimal\ntransport) problem, and its value is proportional to the minimum of the free\nenergy. Finally, we show that SGD in the lazy training regime (which can be\nensured by jointly tuning the variance of the Gaussian prior and the entropic\nregularization parameter) serves as a greedy approximation to the optimal\nMcKean--Vlasov distributional dynamics and provide quantitative guarantees on\nthe $L^2$ approximation error.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 20:50:33 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:11:07 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 21:47:47 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Tzen", "Belinda", ""], ["Raginsky", "Maxim", ""]]}, {"id": "2002.01999", "submitter": "Eran Kaufman Dr.", "authors": "Lee-Ad Gottlieb, Eran Kaufman, Aryeh Kontorovich, Gabriel Nivasch, and\n  Ofir Pele", "title": "Nested Barycentric Coordinate System as an Explicit Feature Map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new embedding method which is particularly well-suited for\nsettings where the sample size greatly exceeds the ambient dimension. Our\ntechnique consists of partitioning the space into simplices and then embedding\nthe data points into features corresponding to the simplices' barycentric\ncoordinates. We then train a linear classifier in the rich feature space\nobtained from the simplices. The decision boundary may be highly non-linear,\nthough it is linear within each simplex (and hence piecewise-linear overall).\nFurther, our method can approximate any convex body. We give generalization\nbounds based on empirical margin and a novel hybrid sample compression\ntechnique. An extensive empirical evaluation shows that our method consistently\noutperforms a range of popular kernel embedding methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:27:06 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Gottlieb", "Lee-Ad", ""], ["Kaufman", "Eran", ""], ["Kontorovich", "Aryeh", ""], ["Nivasch", "Gabriel", ""], ["Pele", "Ofir", ""]]}, {"id": "2002.02000", "submitter": "Nuo Wang Pierse", "authors": "Nuo Wang Pierse, Jingwen Lu", "title": "Aligning the Pretraining and Finetuning Objectives of Language Models", "comments": "8 pages, 2 figures and 6 tables. Submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that explicitly aligning the pretraining objectives to the\nfinetuning objectives in language model training significantly improves the\nfinetuning task performance and reduces the minimum amount of finetuning\nexamples required. The performance margin gained from objective alignment\nallows us to build language models with smaller sizes for tasks with less\navailable training data. We provide empirical evidence of these claims by\napplying objective alignment to concept-of-interest tagging and acronym\ndetection tasks. We found that, with objective alignment, our 768 by 3 and 512\nby 3 transformer language models can reach accuracy of 83.9%/82.5% for\nconcept-of-interest tagging and 73.8%/70.2% for acronym detection using only\n200 finetuning examples per task, outperforming the 768 by 3 model pretrained\nwithout objective alignment by +4.8%/+3.4% and +9.9%/+6.3%. We name finetuning\nsmall language models in the presence of hundreds of training examples or less\n\"Few Example learning\". In practice, Few Example Learning enabled by objective\nalignment not only saves human labeling costs, but also makes it possible to\nleverage language models in more real-time applications.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:40:50 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Pierse", "Nuo Wang", ""], ["Lu", "Jingwen", ""]]}, {"id": "2002.02007", "submitter": "Shuo Wang", "authors": "Shuo Wang, Tianle Chen, Surya Nepal, Carsten Rudolph, Marthie Grobler,\n  Shangyu Chen", "title": "Defending Adversarial Attacks via Semantic Feature Manipulation", "comments": "arXiv admin note: text overlap with arXiv:2001.06640 and text overlap\n  with arXiv:1705.09064 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have demonstrated vulnerability to adversarial\nattacks, more specifically misclassification of adversarial examples. In this\npaper, we propose a one-off and attack-agnostic Feature Manipulation\n(FM)-Defense to detect and purify adversarial examples in an interpretable and\nefficient manner. The intuition is that the classification result of a normal\nimage is generally resistant to non-significant intrinsic feature changes,\ne.g., varying thickness of handwritten digits. In contrast, adversarial\nexamples are sensitive to such changes since the perturbation lacks\ntransferability. To enable manipulation of features, a combo-variational\nautoencoder is applied to learn disentangled latent codes that reveal semantic\nfeatures. The resistance to classification change over the morphs, derived by\nvarying and reconstructing latent codes, is used to detect suspicious inputs.\nFurther, combo-VAE is enhanced to purify the adversarial examples with good\nquality by considering both class-shared and class-unique features. We\nempirically demonstrate the effectiveness of detection and the quality of\npurified instance. Our experiments on three datasets show that FM-Defense can\ndetect nearly $100\\%$ of adversarial examples produced by different\nstate-of-the-art adversarial attacks. It achieves more than $99\\%$ overall\npurification accuracy on the suspicious instances that close the manifold of\nnormal examples.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 23:24:32 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 13:14:48 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Shuo", ""], ["Chen", "Tianle", ""], ["Nepal", "Surya", ""], ["Rudolph", "Carsten", ""], ["Grobler", "Marthie", ""], ["Chen", "Shangyu", ""]]}, {"id": "2002.02008", "submitter": "Bryan Lim", "authors": "Bryan Lim, Stefan Zohren, Stephen Roberts", "title": "Detecting Changes in Asset Co-Movement Using the Autoencoder\n  Reconstruction Ratio", "comments": null, "journal-ref": "Risk 2020", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting changes in asset co-movements is of much importance to financial\npractitioners, with numerous risk management benefits arising from the timely\ndetection of breakdowns in historical correlations. In this article, we propose\na real-time indicator to detect temporary increases in asset co-movements, the\nAutoencoder Reconstruction Ratio, which measures how well a basket of asset\nreturns can be modelled using a lower-dimensional set of latent variables. The\nARR uses a deep sparse denoising autoencoder to perform the dimensionality\nreduction on the returns vector, which replaces the PCA approach of the\nstandard Absorption Ratio, and provides a better model for non-Gaussian\nreturns. Through a systemic risk application on forecasting on the CRSP US\nTotal Market Index, we show that lower ARR values coincide with higher\nvolatility and larger drawdowns, indicating that increased asset co-movement\ndoes correspond with periods of market weakness. We also demonstrate that\nshort-term (i.e. 5-min and 1-hour) predictors for realised volatility and\nmarket crashes can be improved by including additional ARR inputs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:33:54 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:14:44 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02011", "submitter": "Rising Odegua", "authors": "Rising Odegua", "title": "Predicting Bank Loan Default with Extreme Gradient Boosting", "comments": "5 pages, 3 Figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loan default prediction is one of the most important and critical problems\nfaced by banks and other financial institutions as it has a huge effect on\nprofit. Although many traditional methods exist for mining information about a\nloan application, most of these methods seem to be under-performing as there\nhave been reported increases in the number of bad loans. In this paper, we use\nan Extreme Gradient Boosting algorithm called XGBoost for loan default\nprediction. The prediction is based on a loan data from a leading bank taking\ninto consideration data sets from both the loan application and the demographic\nof the applicant. We also present important evaluation metrics such as\nAccuracy, Recall, precision, F1-Score and ROC area of the analysis. This paper\nprovides an effective basis for loan credit approval in order to identify risky\ncustomers from a large number of loan applications using predictive modeling.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 18:52:10 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Odegua", "Rising", ""]]}, {"id": "2002.02012", "submitter": "Christopher Cervantes", "authors": "Christopher M Cervantes", "title": "From Route Instructions to Landmark Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Landmarks are central to how people navigate, but most navigation\ntechnologies do not incorporate them into their representations. We propose the\nlandmark graph generation task (creating landmark-based spatial representations\nfrom natural language) and introduce a fully end-to-end neural approach to\ngenerate these graphs. We evaluate our models on the SAIL route instruction\ndataset, as well as on a small set of real-world delivery instructions that we\ncollected, and we show that our approach yields high quality results on both\nour task and the related robotic navigation task.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:05:11 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cervantes", "Christopher M", ""]]}, {"id": "2002.02013", "submitter": "Benwei Shi", "authors": "Benwei Shi and Jeff M. Phillips", "title": "A Deterministic Streaming Sketch for Ridge Regression", "comments": "Fix a few typos. To be published in AISTATS 2021", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:586-594, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a deterministic space-efficient algorithm for estimating ridge\nregression. For $n$ data points with $d$ features and a large enough\nregularization parameter, we provide a solution within $\\varepsilon$ L$_2$\nerror using only $O(d/\\varepsilon)$ space. This is the first $o(d^2)$ space\ndeterministic streaming algorithm with guaranteed solution error and risk bound\nfor this classic problem. The algorithm sketches the covariance matrix by\nvariants of Frequent Directions, which implies it can operate in insertion-only\nstreams and a variety of distributed data settings. In comparisons to\nrandomized sketching algorithms on synthetic and real-world datasets, our\nalgorithm has less empirical error using less space and similar time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:08:29 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 01:54:24 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 00:12:56 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 07:47:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Shi", "Benwei", ""], ["Phillips", "Jeff M.", ""]]}, {"id": "2002.02025", "submitter": "Vahid Jamali", "authors": "Vahid Jamali, Antonia Tulino, Jaime Llorca, and Elza Erkip", "title": "R\\'{e}nyi Entropy Bounds on the Active Learning Cost-Performance\n  Tradeoff", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised classification, one of the most prominent fields in machine\nlearning, studies how to combine the statistical knowledge of the often\nabundant unlabeled data with the often limited labeled data in order to\nmaximize overall classification accuracy. In this context, the process of\nactively choosing the data to be labeled is referred to as active learning. In\nthis paper, we initiate the non-asymptotic analysis of the optimal policy for\nsemi-supervised classification with actively obtained labeled data. Considering\na general Bayesian classification model, we provide the first characterization\nof the jointly optimal active learning and semi-supervised classification\npolicy, in terms of the cost-performance tradeoff driven by the label query\nbudget (number of data items to be labeled) and overall classification\naccuracy. Leveraging recent results on the R\\'enyi Entropy, we derive tight\ninformation-theoretic bounds on such active learning cost-performance tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:38:35 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Jamali", "Vahid", ""], ["Tulino", "Antonia", ""], ["Llorca", "Jaime", ""], ["Erkip", "Elza", ""]]}, {"id": "2002.02040", "submitter": "Zachary Ross", "authors": "Xiaotian Zhang, Zhe Jia, Zachary E. Ross, and Robert W. Clayton", "title": "Extracting dispersion curves from ambient noise correlations using deep\n  learning", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2020.2992043", "report-no": null, "categories": "cs.LG eess.IV physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a machine-learning approach to classifying the phases of surface\nwave dispersion curves. Standard FTAN analysis of surfaces observed on an array\nof receivers is converted to an image, of which, each pixel is classified as\nfundamental mode, first overtone, or noise. We use a convolutional neural\nnetwork (U-net) architecture with a supervised learning objective and\nincorporate transfer learning. The training is initially performed with\nsynthetic data to learn coarse structure, followed by fine-tuning of the\nnetwork using approximately 10% of the real data based on human classification.\nThe results show that the machine classification is nearly identical to the\nhuman picked phases. Expanding the method to process multiple images at once\ndid not improve the performance. The developed technique will faciliate\nautomated processing of large dispersion curve datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 23:41:12 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Zhang", "Xiaotian", ""], ["Jia", "Zhe", ""], ["Ross", "Zachary E.", ""], ["Clayton", "Robert W.", ""]]}, {"id": "2002.02046", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Supervised Learning on Relational Databases with Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of data scientists and machine learning practitioners use\nrelational data in their work [State of ML and Data Science 2017, Kaggle,\nInc.]. But training machine learning models on data stored in relational\ndatabases requires significant data extraction and feature engineering efforts.\nThese efforts are not only costly, but they also destroy potentially important\nrelational structure in the data. We introduce a method that uses Graph Neural\nNetworks to overcome these challenges. Our proposed method outperforms\nstate-of-the-art automatic feature engineering methods on two out of three\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 00:57:39 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "2002.02050", "submitter": "Jiechao Guan", "authors": "Jiechao Guan, Zhiwu Lu, Tao Xiang, Ji-Rong Wen", "title": "Few-Shot Learning as Domain Adaptation: Algorithm and Analysis", "comments": "There exist some mistakes in the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To recognize the unseen classes with only few samples, few-shot learning\n(FSL) uses prior knowledge learned from the seen classes. A major challenge for\nFSL is that the distribution of the unseen classes is different from that of\nthose seen, resulting in poor generalization even when a model is meta-trained\non the seen classes. This class-difference-caused distribution shift can be\nconsidered as a special case of domain shift. In this paper, for the first\ntime, we propose a domain adaptation prototypical network with attention\n(DAPNA) to explicitly tackle such a domain shift problem in a meta-learning\nframework. Specifically, armed with a set transformer based attention module,\nwe construct each episode with two sub-episodes without class overlap on the\nseen classes to simulate the domain shift between the seen and unseen classes.\nTo align the feature distributions of the two sub-episodes with limited\ntraining samples, a feature transfer network is employed together with a margin\ndisparity discrepancy (MDD) loss. Importantly, theoretical analysis is provided\nto give the learning bound of our DAPNA. Extensive experiments show that our\nDAPNA outperforms the state-of-the-art FSL alternatives, often by significant\nmargins.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:04:53 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 09:17:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 06:26:34 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Guan", "Jiechao", ""], ["Lu", "Zhiwu", ""], ["Xiang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2002.02058", "submitter": "Takahiro Yabe", "authors": "Toru Shimizu, Takahiro Yabe, Kota Tsubouchi", "title": "Learning Fine Grained Place Embeddings with Spatial Hierarchy from Human\n  Mobility Trajectories", "comments": "submitted to IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place embeddings generated from human mobility trajectories have become a\npopular method to understand the functionality of places. Place embeddings with\nhigh spatial resolution are desirable for many applications, however,\ndownscaling the spatial resolution deteriorates the quality of embeddings due\nto data sparsity, especially in less populated areas. We address this issue by\nproposing a method that generates fine grained place embeddings, which\nleverages spatial hierarchical information according to the local density of\nobserved data points. The effectiveness of our fine grained place embeddings\nare compared to baseline methods via next place prediction tasks using real\nworld trajectory data from 3 cities in Japan. In addition, we demonstrate the\nvalue of our fine grained place embeddings for land use classification\napplications. We believe that our technique of incorporating spatial\nhierarchical information can complement and reinforce various place embedding\ngenerating methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:37:40 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Shimizu", "Toru", ""], ["Yabe", "Takahiro", ""], ["Tsubouchi", "Kota", ""]]}, {"id": "2002.02061", "submitter": "Xiaoguang Li", "authors": "Xiaoguang Li, Hui Li, Haonan Yan, Zelei Cheng, Wenhai Sun, Hui Zhu", "title": "Mitigating Query-Flooding Parameter Duplication Attack on Regression\n  Models with High-Dimensional Gaussian Mechanism", "comments": "it has some mistakes. Since I submitted the paper for the first time,\n  there were many mistakes in the paper. At the same time, I found a serious\n  mistake in the content of the paper, so I thought it was inappropriate to\n  publish it now after careful consideration.", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public intelligent services enabled by machine learning algorithms are\nvulnerable to model extraction attacks that can steal confidential information\nof the learning models through public queries. Differential privacy (DP) has\nbeen considered a promising technique to mitigate this attack. However, we find\nthat the vulnerability persists when regression models are being protected by\ncurrent DP solutions. We show that the adversary can launch a query-flooding\nparameter duplication (QPD) attack to infer the model information by repeated\nqueries.\n  To defend against the QPD attack on logistic and linear regression models, we\npropose a novel High-Dimensional Gaussian (HDG) mechanism to prevent\nunauthorized information disclosure without interrupting the intended services.\nIn contrast to prior work, the proposed HDG mechanism will dynamically generate\nthe privacy budget and random noise for different queries and their results to\nenhance the obfuscation. Besides, for the first time, HDG enables an optimal\nprivacy budget allocation that automatically determines the minimum amount of\nnoise to be added per user-desired privacy level on each dimension. We\ncomprehensively evaluate the performance of HDG using real-world datasets and\nshows that HDG effectively mitigates the QPD attack while satisfying the\nprivacy requirements. We also prepare to open-source the relevant codes to the\ncommunity for further research.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:47:08 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 14:20:42 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 01:40:09 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Li", "Xiaoguang", ""], ["Li", "Hui", ""], ["Yan", "Haonan", ""], ["Cheng", "Zelei", ""], ["Sun", "Wenhai", ""], ["Zhu", "Hui", ""]]}, {"id": "2002.02064", "submitter": "Holden Lee", "authors": "Udaya Ghai, Holden Lee, Karan Singh, Cyril Zhang, Yi Zhang", "title": "No-Regret Prediction in Marginally Stable Systems", "comments": "43 pages. Appears in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of online prediction in a marginally stable linear\ndynamical system subject to bounded adversarial or (non-isotropic) stochastic\nperturbations. This poses two challenges. Firstly, the system is in general\nunidentifiable, so recent and classical results on parameter recovery do not\napply. Secondly, because we allow the system to be marginally stable, the state\ncan grow polynomially with time; this causes standard regret bounds in online\nconvex optimization to be vacuous. In spite of these challenges, we show that\nthe online least-squares algorithm achieves sublinear regret (improvable to\npolylogarithmic in the stochastic setting), with polynomial dependence on the\nsystem's parameters. This requires a refined regret analysis, including a\nstructural lemma showing the current state of the system to be a small linear\ncombination of past states, even if the state grows polynomially. By applying\nour techniques to learning an autoregressive filter, we also achieve\nlogarithmic regret in the partially observed setting under Gaussian noise, with\npolynomial dependence on the memory of the associated Kalman filter.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 01:53:34 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 19:48:51 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 19:08:58 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Ghai", "Udaya", ""], ["Lee", "Holden", ""], ["Singh", "Karan", ""], ["Zhang", "Cyril", ""], ["Zhang", "Yi", ""]]}, {"id": "2002.02068", "submitter": "Shota Yasui", "authors": "Shota Yasui, Gota Morishita, Komei Fujita, Masashi Shibata", "title": "A Feedback Shift Correction in Predicting Conversion Rates under Delayed\n  Feedback", "comments": "The Web Conference 2020 (WWW '20)", "journal-ref": null, "doi": "10.1145/3366423.3380032", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In display advertising, predicting the conversion rate, that is, the\nprobability that a user takes a predefined action on an advertiser's website,\nsuch as purchasing goods is fundamental in estimating the value of displaying\nthe advertisement. However, there is a relatively long time delay between a\nclick and its resultant conversion. Because of the delayed feedback, some\npositive instances at the training period are labeled as negative because some\nconversions have not yet occurred when training data are gathered. As a result,\nthe conditional label distributions differ between the training data and the\nproduction environment. This situation is referred to as a feedback shift. We\naddress this problem by using an importance weight approach typically used for\ncovariate shift correction. We prove its consistency for the feedback shift.\nResults in both offline and online experiments show that our proposed method\noutperforms the existing method.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:05:07 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yasui", "Shota", ""], ["Morishita", "Gota", ""], ["Fujita", "Komei", ""], ["Shibata", "Masashi", ""]]}, {"id": "2002.02071", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Finite Hilbert Transform in Weighted L2 Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several new properties of weighted Hilbert transform are obtained. If mu is\nzero, two Plancherel-like equations and the isotropic properties are derived.\nFor mu is real number, a coerciveness is derived and two iterative sequences\nare constructed to find the inversion. The proposed iterative sequences are\napplicable to the case of pure imaginary constant mu=i*eta with |eta|<pi/4 .\nFor mu=0.0 and 3.0 , we present the computer simulation results by using the\nChebyshev series representation of finite Hilbert transform. The results in\nthis paper are useful to the half scan in several imaging applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:13:18 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:47:58 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.02073", "submitter": "Jiangsheng You Dr.", "authors": "Jason You", "title": "Truncated Hilbert Transform: Uniqueness and a Chebyshev series Expansion\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.FA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a stronger uniqueness result if a function with compact support and\nits truncated Hilbert transform are known on the same interval by using the\nSokhotski-Plemelj formulas. To find a function from its truncated Hilbert\ntransform, we express them in the Chebyshev polynomial series and then suggest\ntwo methods to numerically estimate the coefficients. We present computer\nsimulation results to show that the extrapolative procedure numerically works\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:26:19 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 04:01:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["You", "Jason", ""]]}, {"id": "2002.02075", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "MAC Protocol Design Optimization Using Deep Learning", "comments": "7 pages, 4 figures, 2020 International Conference on Artificial\n  Intelligence in Information and Communication (ICAIIC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL)-based solutions have recently been developed for\ncommunication protocol design. Such learning-based solutions can avoid manual\nefforts to tune individual protocol parameters. While these solutions look\npromising, they are hard to interpret due to the black-box nature of the ML\ntechniques. To this end, we propose a novel DRL-based framework to\nsystematically design and evaluate networking protocols. While other proposed\nML-based methods mainly focus on tuning individual protocol parameters (e.g.,\nadjusting contention window), our main contribution is to decouple a protocol\ninto a set of parametric modules, each representing a main protocol\nfunctionality and is used as DRL input to better understand the generated\nprotocols design optimization and analyze them in a systematic fashion. As a\ncase study, we introduce and evaluate DeepMAC a framework in which a MAC\nprotocol is decoupled into a set of blocks across popular flavors of 802.11\nWLANs (e.g., 802.11a/b/g/n/ac). We are interested to see what blocks are\nselected by DeepMAC across different networking scenarios and whether DeepMAC\nis able to adapt to network dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:36:52 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2002.02077", "submitter": "Akshay Rangesh", "authors": "Akshay Rangesh, Bowen Zhang and Mohan M. Trivedi", "title": "Gaze Preserving CycleGANs for Eyeglass Removal & Persistent Gaze\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A driver's gaze is critical for determining their attention, state,\nsituational awareness, and readiness to take over control from partially\nautomated vehicles. Estimating the gaze direction is the most obvious way to\ngauge a driver's state under ideal conditions when limited to using\nnon-intrusive imaging sensors. Unfortunately, the vehicular environment\nintroduces a variety of challenges that are usually unaccounted for - harsh\nillumination, nighttime conditions, and reflective eyeglasses. Relying on head\npose alone under such conditions can prove to be unreliable and erroneous. In\nthis study, we offer solutions to address these problems encountered in the\nreal world. To solve issues with lighting, we demonstrate that using an\ninfrared camera with suitable equalization and normalization suffices. To\nhandle eyeglasses and their corresponding artifacts, we adopt image-to-image\ntranslation using generative adversarial networks to pre-process images prior\nto gaze estimation. Our proposed Gaze Preserving CycleGAN (GPCycleGAN) is\ntrained to preserve the driver's gaze while removing potential eyeglasses from\nface images. GPCycleGAN is based on the well-known CycleGAN approach - with the\naddition of a gaze classifier and a gaze consistency loss for additional\nsupervision. Our approach exhibits improved performance, interpretability,\nrobustness and superior qualitative results on challenging real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:45:25 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 21:20:47 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 19:24:00 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 00:36:01 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 19:34:41 GMT"}, {"version": "v6", "created": "Tue, 15 Jun 2021 21:41:54 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Rangesh", "Akshay", ""], ["Zhang", "Bowen", ""], ["Trivedi", "Mohan M.", ""]]}, {"id": "2002.02081", "submitter": "Nan Jiang", "authors": "Nan Jiang, Jiawei Huang", "title": "Minimax Value Interval for Off-Policy Evaluation and Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax methods for off-policy evaluation (OPE) using value\nfunctions and marginalized importance weights. Despite that they hold promises\nof overcoming the exponential variance in traditional importance sampling,\nseveral key problems remain:\n  (1) They require function approximation and are generally biased. For the\nsake of trustworthy OPE, is there anyway to quantify the biases?\n  (2) They are split into two styles (\"weight-learning\" vs \"value-learning\").\nCan we unify them?\n  In this paper we answer both questions positively. By slightly altering the\nderivation of previous methods (one from each style; Uehara et al., 2020), we\nunify them into a single value interval that comes with a special type of\ndouble robustness: when either the value-function or the importance-weight\nclass is well specified, the interval is valid and its length quantifies the\nmisspecification of the other class. Our interval also provides a unified view\nof and new insights to some recent methods, and we further explore the\nimplications of our results on exploration and exploitation in off-policy\npolicy optimization with insufficient data coverage.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:54:11 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:56:55 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 13:55:25 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 00:41:22 GMT"}, {"version": "v5", "created": "Mon, 26 Oct 2020 05:12:58 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 23:43:32 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Jiang", "Nan", ""], ["Huang", "Jiawei", ""]]}, {"id": "2002.02085", "submitter": "Lijun Zhang", "authors": "Lijun Zhang, Shiyin Lu, Tianbao Yang", "title": "Minimizing Dynamic Regret and Adaptive Regret Simultaneously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regret minimization is treated as the golden rule in the traditional study of\nonline learning. However, regret minimization algorithms tend to converge to\nthe static optimum, thus being suboptimal for changing environments. To address\nthis limitation, new performance measures, including dynamic regret and\nadaptive regret have been proposed to guide the design of online algorithms.\nThe former one aims to minimize the global regret with respect to a sequence of\nchanging comparators, and the latter one attempts to minimize every local\nregret with respect to a fixed comparator. Existing algorithms for dynamic\nregret and adaptive regret are developed independently, and only target one\nperformance measure. In this paper, we bridge this gap by proposing novel\nonline algorithms that are able to minimize the dynamic regret and adaptive\nregret simultaneously. In fact, our theoretical guarantee is even stronger in\nthe sense that one algorithm is able to minimize the dynamic regret over any\ninterval.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:32:37 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Zhang", "Lijun", ""], ["Lu", "Shiyin", ""], ["Yang", "Tianbao", ""]]}, {"id": "2002.02086", "submitter": "Siping Liu", "authors": "Di Wu and Huayan Wan and Siping Liu and Weiren Yu and Zhanpeng Jin and\n  Dakuo Wang", "title": "DeepBrain: Towards Personalized EEG Interaction through Attentional and\n  Embedded LSTM Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"mind-controlling\" capability has always been in mankind's fantasy. With\nthe recent advancements of electroencephalograph (EEG) techniques,\nbrain-computer interface (BCI) researchers have explored various solutions to\nallow individuals to perform various tasks using their minds. However, the\ncommercial off-the-shelf devices to run accurate EGG signal collection are\nusually expensive and the comparably cheaper devices can only present coarse\nresults, which prevents the practical application of these devices in domestic\nservices. To tackle this challenge, we propose and develop an end-to-end\nsolution that enables fine brain-robot interaction (BRI) through embedded\nlearning of coarse EEG signals from the low-cost devices, namely DeepBrain, so\nthat people having difficulty to move, such as the elderly, can mildly command\nand control a robot to perform some basic household tasks. Our contributions\nare two folds: 1) We present a stacked long short term memory (Stacked LSTM)\nstructure with specific pre-processing techniques to handle the time-dependency\nof EEG signals and their classification. 2) We propose personalized design to\ncapture multiple features and achieve accurate recognition of individual EEG\nsignals by enhancing the signal interpretation of Stacked LSTM with attention\nmechanism. Our real-world experiments demonstrate that the proposed end-to-end\nsolution with low cost can achieve satisfactory run-time speed, accuracy and\nenergy-efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:34:08 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 04:37:12 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Wu", "Di", ""], ["Wan", "Huayan", ""], ["Liu", "Siping", ""], ["Yu", "Weiren", ""], ["Jin", "Zhanpeng", ""], ["Wang", "Dakuo", ""]]}, {"id": "2002.02087", "submitter": "Atreyee Kundu", "authors": "Atreyee Kundu", "title": "Data-based computation of stabilizing minimum dwell times for\n  discrete-time switched linear systems", "comments": "7 pages, 1 figure, submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to compute stabilizing minimum dwell times for\ndiscrete-time switched linear systems without the explicit knowledge of\nstate-space models of their subsystems. Given a set of finite traces of state\ntrajectories of the subsystems that satisfies certain properties, our algorithm\ninvolves the following tasks: first, multiple Lyapunov functions are designed\nfrom the given data; second, a set of relevant scalars is computed from these\nfunctions; and third, a stabilizing minimum dwell time is determined as a\nfunction of these scalars. A numerical example is presented to demonstrate the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:40:20 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 10:58:06 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Kundu", "Atreyee", ""]]}, {"id": "2002.02088", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Liang Li, Bingzhe Wu, Cheng Hong, Li Wang, Jun Zhou", "title": "Secure Social Recommendation based on Secret Sharing", "comments": "Accepted by ECAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, privacy preserving machine learning has been drawing much attention\nin both industry and academy. Meanwhile, recommender systems have been\nextensively adopted by many commercial platforms (e.g. Amazon) and they are\nmainly built based on user-item interactions. Besides, social platforms (e.g.\nFacebook) have rich resources of user social information. It is well known that\nsocial information, which is rich on social platforms such as Facebook, are\nuseful to recommender systems. It is anticipated to combine the social\ninformation with the user-item ratings to improve the overall recommendation\nperformance. Most existing recommendation models are built based on the\nassumptions that the social information are available. However, different\nplatforms are usually reluctant to (or cannot) share their data due to certain\nconcerns. In this paper, we first propose a SEcure SOcial RECommendation\n(SeSoRec) framework which can (1) collaboratively mine knowledge from social\nplatform to improve the recommendation performance of the rating platform, and\n(2) securely keep the raw data of both platforms. We then propose a Secret\nSharing based Matrix Multiplication (SSMM) protocol to optimize SeSoRec and\nprove its correctness and security theoretically. By applying minibatch\ngradient descent, SeSoRec has linear time complexities in terms of both\ncomputation and communication. The comprehensive experimental results on three\nreal-world datasets demonstrate the effectiveness of our proposed SeSoRec and\nSSMM.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:49:51 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 06:43:35 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Chen", "Chaochao", ""], ["Li", "Liang", ""], ["Wu", "Bingzhe", ""], ["Hong", "Cheng", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""]]}, {"id": "2002.02090", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Qian Yang, Bin Gu, Lawrence Carin. Heng Huang", "title": "Faster On-Device Training Using New Federated Momentum Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile crowdsensing has gained significant attention in recent years and has\nbecome a critical paradigm for emerging Internet of Things applications. The\nsensing devices continuously generate a significant quantity of data, which\nprovide tremendous opportunities to develop innovative intelligent\napplications. To utilize these data to train machine learning models while not\ncompromising user privacy, federated learning has become a promising solution.\nHowever, there is little understanding of whether federated learning algorithms\nare guaranteed to converge. We reconsider model averaging in federated learning\nand formulate it as a gradient-based method with biased gradients. This novel\nperspective assists analysis of its convergence rate and provides a new\ndirection for more acceleration. We prove for the first time that the federated\naveraging algorithm is guaranteed to converge for non-convex problems, without\nimposing additional assumptions. We further propose a novel accelerated\nfederated learning algorithm and provide a convergence guarantee. Simulated\nfederated learning experiments are conducted to train deep neural networks on\nbenchmark datasets, and experimental results show that our proposed method\nconverges faster than previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:12:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Yang", "Qian", ""], ["Gu", "Bin", ""], ["Huang", "Lawrence Carin. Heng", ""]]}, {"id": "2002.02091", "submitter": "Yingting Liu", "authors": "Yingting Liu, Chaochao Chen, Longfei Zheng, Li Wang, Jun Zhou, Guiquan\n  Liu, Shuang Yang", "title": "Privacy Preserving PCA for Multiparty Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a general multiparty modeling paradigm with Privacy\nPreserving Principal Component Analysis (PPPCA) for horizontally partitioned\ndata. PPPCA can accomplish multiparty cooperative execution of PCA under the\npremise of keeping plaintext data locally. We also propose implementations\nusing two techniques, i.e., homomorphic encryption and secret sharing. The\noutput of PPPCA can be sent directly to data consumer to build any machine\nlearning models. We conduct experiments on three UCI benchmark datasets and a\nreal-world fraud detection dataset. Results show that the accuracy of the model\nbuilt upon PPPCA is the same as the model with PCA that is built based on\ncentralized plaintext data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:16:59 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 13:29:21 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 12:38:39 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Liu", "Yingting", ""], ["Chen", "Chaochao", ""], ["Zheng", "Longfei", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""], ["Liu", "Guiquan", ""], ["Yang", "Shuang", ""]]}, {"id": "2002.02095", "submitter": "Yun-Zhu Song", "authors": "Yun-Zhu Song (1), Hong-Han Shuai (1), Sung-Lin Yeh (2), Yi-Lun Wu (1),\n  Lun-Wei Ku (3), Wen-Chih Peng (1) ((1) National Chiao Tung University,\n  Taiwan, (2) National Tsing Hua University, Taiwan, (3) Academia Sinica,\n  Taiwan)", "title": "Attractive or Faithful? Popularity-Reinforced Learning for Inspired\n  Headline Generation", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid proliferation of online media sources and published news,\nheadlines have become increasingly important for attracting readers to news\narticles, since users may be overwhelmed with the massive information. In this\npaper, we generate inspired headlines that preserve the nature of news articles\nand catch the eye of the reader simultaneously. The task of inspired headline\ngeneration can be viewed as a specific form of Headline Generation (HG) task,\nwith the emphasis on creating an attractive headline from a given news article.\nTo generate inspired headlines, we propose a novel framework called\nPOpularity-Reinforced Learning for inspired Headline Generation (PORL-HG).\nPORL-HG exploits the extractive-abstractive architecture with 1) Popular Topic\nAttention (PTA) for guiding the extractor to select the attractive sentence\nfrom the article and 2) a popularity predictor for guiding the abstractor to\nrewrite the attractive sentence. Moreover, since the sentence selection of the\nextractor is not differentiable, techniques of reinforcement learning (RL) are\nutilized to bridge the gap with rewards obtained from a popularity score\npredictor. Through quantitative and qualitative experiments, we show that the\nproposed PORL-HG significantly outperforms the state-of-the-art headline\ngeneration models in terms of attractiveness evaluated by both human (71.03%)\nand the predictor (at least 27.60%), while the faithfulness of PORL-HG is also\ncomparable to the state-of-the-art generation model.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:37:44 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Song", "Yun-Zhu", ""], ["Shuai", "Hong-Han", ""], ["Yeh", "Sung-Lin", ""], ["Wu", "Yi-Lun", ""], ["Ku", "Lun-Wei", ""], ["Peng", "Wen-Chih", ""]]}, {"id": "2002.02096", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Boosting in the Local Setting", "comments": "12 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, boosting is one of the most popular methods that\ndesigned to combine multiple base learners to a superior one. The well-known\nBoosted Decision Tree classifier, has been widely adopted in many areas. In the\nbig data era, the data held by individual and entities, like personal images,\nbrowsing history and census information, are more likely to contain sensitive\ninformation. The privacy concern raises when such data leaves the hand of the\nowners and be further explored or mined. Such privacy issue demands that the\nmachine learning algorithm should be privacy aware. Recently, Local\nDifferential Privacy is proposed as an effective privacy protection approach,\nwhich offers a strong guarantee to the data owners, as the data is perturbed\nbefore any further usage, and the true values never leave the hands of the\nowners. Thus the machine learning algorithm with the private data instances is\nof great value and importance. In this paper, we are interested in developing\nthe privacy-preserving boosting algorithm that a data user is allowed to build\na classifier without knowing or deriving the exact value of each data samples.\nOur experiments demonstrate the effectiveness of the proposed boosting\nalgorithm and the high utility of the learned classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 04:48:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.02100", "submitter": "S.H. Shabbeer Basha", "authors": "S.H. Shabbeer Basha, Viswanath Pulabaigari, Snehasis Mukherjee", "title": "An Information-rich Sampling Technique over Spatio-Temporal CNN for\n  Classification of Human Actions in Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel scheme for human action recognition in videos, using a\n3-dimensional Convolutional Neural Network (3D CNN) based classifier.\nTraditionally in deep learning based human activity recognition approaches,\neither a few random frames or every $k^{th}$ frame of the video is considered\nfor training the 3D CNN, where $k$ is a small positive integer, like 4, 5, or\n6. This kind of sampling reduces the volume of the input data, which speeds-up\ntraining of the network and also avoids over-fitting to some extent, thus\nenhancing the performance of the 3D CNN model. In the proposed video sampling\ntechnique, consecutive $k$ frames of a video are aggregated into a single frame\nby computing a Gaussian-weighted summation of the $k$ frames. The resulting\nframe (aggregated frame) preserves the information in a better way than the\nconventional approaches and experimentally shown to perform better. In this\npaper, a 3D CNN architecture is proposed to extract the spatio-temporal\nfeatures and follows Long Short-Term Memory (LSTM) to recognize human actions.\nThe proposed 3D CNN architecture is capable of handling the videos where the\ncamera is placed at a distance from the performer. Experiments are performed\nwith KTH and WEIZMANN human actions datasets, whereby it is shown to produce\ncomparable results with the state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 05:07:41 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 06:42:20 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Basha", "S. H. Shabbeer", ""], ["Pulabaigari", "Viswanath", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "2002.02105", "submitter": "Jingxiao Liu", "authors": "Jingxiao Liu, Bingqing Chen, Siheng Chen, Mario Berges, Jacobo Bielak,\n  HaeYoung Noh", "title": "Damage-sensitive and domain-invariant feature extraction for\n  vehicle-vibration-based bridge health monitoring", "comments": "To appear in Proc. ICASSP2020, May 04-08, 2020, Barcelona, Spain.\n  IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a physics-guided signal processing approach to extract a\ndamage-sensitive and domain-invariant (DS & DI) feature from acceleration\nresponse data of a vehicle traveling over a bridge to assess bridge health.\nMotivated by indirect sensing methods' benefits, such as low-cost and\nlow-maintenance, vehicle-vibration-based bridge health monitoring has been\nstudied to efficiently monitor bridges in real-time. Yet applying this approach\nis challenging because 1) physics-based features extracted manually are\ngenerally not damage-sensitive, and 2) features from machine learning\ntechniques are often not applicable to different bridges. Thus, we formulate a\nvehicle bridge interaction system model and find a physics-guided DS & DI\nfeature, which can be extracted using the synchrosqueezed wavelet transform\nrepresenting non-stationary signals as intrinsic-mode-type components. We\nvalidate the effectiveness of the proposed feature with simulated experiments.\nCompared to conventional time- and frequency-domain features, our feature\nprovides the best damage quantification and localization results across\ndifferent bridges in five of six experiments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 05:45:39 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Liu", "Jingxiao", ""], ["Chen", "Bingqing", ""], ["Chen", "Siheng", ""], ["Berges", "Mario", ""], ["Bielak", "Jacobo", ""], ["Noh", "HaeYoung", ""]]}, {"id": "2002.02112", "submitter": "Hyungrok Ham", "authors": "Hyungrok Ham, Tae Joon Jun, Daeyoung Kim", "title": "Unbalanced GANs: Pre-training the Generator of Generative Adversarial\n  Network using Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Unbalanced GANs, which pre-trains the generator of the generative\nadversarial network (GAN) using variational autoencoder (VAE). We guarantee the\nstable training of the generator by preventing the faster convergence of the\ndiscriminator at early epochs. Furthermore, we balance between the generator\nand the discriminator at early epochs and thus maintain the stabilized training\nof GANs. We apply Unbalanced GANs to well known public datasets and find that\nUnbalanced GANs reduce mode collapses. We also show that Unbalanced GANs\noutperform ordinary GANs in terms of stabilized learning, faster convergence\nand better image quality at early epochs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 06:03:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ham", "Hyungrok", ""], ["Jun", "Tae Joon", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2002.02117", "submitter": "Yuma Kinoshita", "authors": "Yuma Kinoshita and Hitoshi Kiya", "title": "Fixed smooth convolutional layer for avoiding checkerboard artifacts in\n  CNNs", "comments": "5 pages, to appear in IEEE International Conference on Acoustics,\n  Speech, and Signal Processing 2020 (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fixed convolutional layer with an order of\nsmoothness not only for avoiding checkerboard artifacts in convolutional neural\nnetworks (CNNs) but also for enhancing the performance of CNNs, where the\nsmoothness of its filter kernel can be controlled by a parameter. It is\nwell-known that a number of CNNs generate checkerboard artifacts in both of two\nprocess: forward-propagation of upsampling layers and backward-propagation of\nstrided convolutional layers. The proposed layer can perfectly prevent\ncheckerboard artifacts caused by strided convolutional layers or upsampling\nlayers including transposed convolutional layers. In an image-classification\nexperiment with four CNNs: a simple CNN, VGG8, ResNet-18, and ResNet-101,\napplying the fixed layers to these CNNs is shown to improve the classification\nperformance of all CNNs. In addition, the fixed layer are applied to generative\nadversarial networks (GANs), for the first time. From image-generation results,\na smoother fixed convolutional layer is demonstrated to enable us to improve\nthe quality of images generated with GANs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 06:36:45 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Kinoshita", "Yuma", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "2002.02126", "submitter": "Kuan Deng", "authors": "Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang and Meng\n  Wang", "title": "LightGCN: Simplifying and Powering Graph Convolution Network for\n  Recommendation", "comments": "Accepted by SIGIR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Network (GCN) has become new state-of-the-art for\ncollaborative filtering. Nevertheless, the reasons of its effectiveness for\nrecommendation are not well understood. Existing work that adapts GCN to\nrecommendation lacks thorough ablation analyses on GCN, which is originally\ndesigned for graph classification tasks and equipped with many neural network\noperations. However, we empirically find that the two most common designs in\nGCNs -- feature transformation and nonlinear activation -- contribute little to\nthe performance of collaborative filtering. Even worse, including them adds to\nthe difficulty of training and degrades recommendation performance.\n  In this work, we aim to simplify the design of GCN to make it more concise\nand appropriate for recommendation. We propose a new model named LightGCN,\nincluding only the most essential component in GCN -- neighborhood aggregation\n-- for collaborative filtering. Specifically, LightGCN learns user and item\nembeddings by linearly propagating them on the user-item interaction graph, and\nuses the weighted sum of the embeddings learned at all layers as the final\nembedding. Such simple, linear, and neat model is much easier to implement and\ntrain, exhibiting substantial improvements (about 16.0\\% relative improvement\non average) over Neural Graph Collaborative Filtering (NGCF) -- a\nstate-of-the-art GCN-based recommender model -- under exactly the same\nexperimental setting. Further analyses are provided towards the rationality of\nthe simple LightGCN from both analytical and empirical perspectives.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 06:53:42 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 05:42:54 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 11:07:46 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 04:20:53 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["He", "Xiangnan", ""], ["Deng", "Kuan", ""], ["Wang", "Xiang", ""], ["Li", "Yan", ""], ["Zhang", "Yongdong", ""], ["Wang", "Meng", ""]]}, {"id": "2002.02145", "submitter": "Sanket Tavarageri", "authors": "Sanket Tavarageri, Alexander Heinecke, Sasikanth Avancha, Gagandeep\n  Goyal, Ramakrishna Upadrasta, Bharat Kaul", "title": "PolyScientist: Automatic Loop Transformations Combined with Microkernels\n  for Optimization of Deep Learning Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of deep learning training and inferencing are computationally\nintensive primitives such as convolutions which form the building blocks of\ndeep neural networks. Researchers have taken two distinct approaches to\ncreating high performance implementations of deep learning kernels, namely, 1)\nlibrary development exemplified by Intel MKL-DNN for CPUs, 2) automatic\ncompilation represented by the TensorFlow XLA compiler. The two approaches have\ntheir drawbacks: even though a custom built library can deliver very good\nperformance, the cost and time of development of the library can be high.\nAutomatic compilation of kernels is attractive but in practice, till date,\nautomatically generated implementations lag expert coded kernels in performance\nby orders of magnitude.\n  In this paper, we develop a hybrid solution to the development of deep\nlearning kernels that achieves the best of both worlds: the expert coded\nmicrokernels are utilized for the innermost loops of kernels and we use the\nadvanced polyhedral technology to automatically tune the outer loops for\nperformance. We design a novel polyhedral model based data reuse algorithm to\noptimize the outer loops of the kernel. Through experimental evaluation on an\nimportant class of deep learning primitives namely convolutions, we demonstrate\nthat the approach we develop attains the same levels of performance as Intel\nMKL-DNN, a hand coded deep learning library.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:02:34 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Tavarageri", "Sanket", ""], ["Heinecke", "Alexander", ""], ["Avancha", "Sasikanth", ""], ["Goyal", "Gagandeep", ""], ["Upadrasta", "Ramakrishna", ""], ["Kaul", "Bharat", ""]]}, {"id": "2002.02153", "submitter": "Minghong Xu", "authors": "Minghong Xu, Piji Li, Haoran Yang, Pengjie Ren, Zhaochun Ren, Zhumin\n  Chen, Jun Ma", "title": "A Neural Topical Expansion Framework for Unstructured Persona-oriented\n  Dialogue Generation", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured Persona-oriented Dialogue Systems (UPDS) has been demonstrated\neffective in generating persona consistent responses by utilizing predefined\nnatural language user persona descriptions (e.g., \"I am a vegan\"). However, the\npredefined user persona descriptions are usually short and limited to only a\nfew descriptive words, which makes it hard to correlate them with the\ndialogues. As a result, existing methods either fail to use the persona\ndescription or use them improperly when generating persona consistent\nresponses. To address this, we propose a neural topical expansion framework,\nnamely Persona Exploration and Exploitation (PEE), which is able to extend the\npredefined user persona description with semantically correlated content before\nutilizing them to generate dialogue responses. PEE consists of two main\nmodules: persona exploration and persona exploitation. The former learns to\nextend the predefined user persona description by mining and correlating with\nexisting dialogue corpus using a variational auto-encoder (VAE) based topic\nmodel. The latter learns to generate persona consistent responses by utilizing\nthe predefined and extended user persona description. In order to make persona\nexploitation learn to utilize user persona description more properly, we also\nintroduce two persona-oriented loss functions: Persona-oriented Matching\n(P-Match) loss and Persona-oriented Bag-of-Words (P-BoWs) loss which\nrespectively supervise persona selection in encoder and decoder. Experimental\nresults show that our approach outperforms state-of-the-art baselines, in terms\nof both automatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:24:33 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Xu", "Minghong", ""], ["Li", "Piji", ""], ["Yang", "Haoran", ""], ["Ren", "Pengjie", ""], ["Ren", "Zhaochun", ""], ["Chen", "Zhumin", ""], ["Ma", "Jun", ""]]}, {"id": "2002.02158", "submitter": "Yasuhiro Katsura", "authors": "Yasuhiro Katsura, Masato Uchida", "title": "Bridging Ordinary-Label Learning and Complementary-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A supervised learning framework has been proposed for the situation where\neach training data is provided with a complementary label that represents a\nclass to which the pattern does not belong. In the existing literature,\ncomplementary-label learning has been studied independently from ordinary-label\nlearning, which assumes that each training data is provided with a label\nrepresenting the class to which the pattern belongs. However, providing a\ncomplementary label should be treated as equivalent to providing the rest of\nall the labels as the candidates of the one true class. In this paper, we focus\non the fact that the loss functions for one-versus-all and pairwise\nclassification corresponding to ordinary-label learning and complementary-label\nlearning satisfy certain additivity and duality, and provide a framework which\ndirectly bridge those existing supervised learning frameworks. Further, we\nderive classification risk and error bound for any loss functions which satisfy\nadditivity and duality.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 08:54:19 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 11:48:24 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 09:11:41 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 14:06:03 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 07:56:56 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Katsura", "Yasuhiro", ""], ["Uchida", "Masato", ""]]}, {"id": "2002.02164", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Francisco Herrera", "title": "LUNAR: Cellular Automata for Drifting Data Streams", "comments": "36 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of huges volumes of data produced in the form of fast\nstreams, real-time machine learning has become a challenge of relevance\nemerging in a plethora of real-world applications. Processing such fast streams\noften demands high memory and processing resources. In addition, they can be\naffected by non-stationary phenomena (concept drift), by which learning methods\nhave to detect changes in the distribution of streaming data, and adapt to\nthese evolving conditions. A lack of efficient and scalable solutions is\nparticularly noted in real-time scenarios where computing resources are\nseverely constrained, as it occurs in networks of small, numerous,\ninterconnected processing units (such as the so-called Smart Dust, Utility Fog,\nor Swarm Robotics paradigms). In this work we propose LUNAR, a streamified\nversion of cellular automata devised to successfully meet the aforementioned\nrequirements. It is able to act as a real incremental learner while adapting to\ndrifting conditions. Extensive simulations with synthetic and real data will\nprovide evidence of its competitive behavior in terms of classification\nperformance when compared to long-established and successful online learning\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:10:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.02175", "submitter": "Guannan Lou", "authors": "Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, Miryung Kim", "title": "An Analysis of Adversarial Attacks and Defenses on Autonomous Driving\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, autonomous driving has attracted much attention from both industry\nand academia. Convolutional neural network (CNN) is a key component in\nautonomous driving, which is also increasingly adopted in pervasive computing\nsuch as smartphones, wearable devices, and IoT networks. Prior work shows\nCNN-based classification models are vulnerable to adversarial attacks. However,\nit is uncertain to what extent regression models such as driving models are\nvulnerable to adversarial attacks, the effectiveness of existing defense\ntechniques, and the defense implications for system and middleware builders.\nThis paper presents an in-depth analysis of five adversarial attacks and four\ndefense methods on three driving models. Experiments show that, similar to\nclassification models, these models are still highly vulnerable to adversarial\nattacks. This poses a big security threat to autonomous driving and thus should\nbe taken into account in practice. While these defense methods can effectively\ndefend against different attacks, none of them are able to provide adequate\nprotection against all five attacks. We derive several implications for system\nand middleware builders: (1) when adding a defense component against\nadversarial attacks, it is important to deploy multiple defense methods in\ntandem to achieve a good coverage of various attacks, (2) a blackbox attack is\nmuch less effective compared with a white-box attack, implying that it is\nimportant to keep model details (e.g., model architecture, hyperparameters)\nconfidential via model obfuscation, and (3) driving models with a complex\narchitecture are preferred if computing resources permit as they are more\nresilient to adversarial attacks than simple models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:49:16 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Deng", "Yao", ""], ["Zheng", "Xi", ""], ["Zhang", "Tianyi", ""], ["Chen", "Chen", ""], ["Lou", "Guannan", ""], ["Kim", "Miryung", ""]]}, {"id": "2002.02176", "submitter": "Guy Amit", "authors": "Guy Amit, Ishai Rosenberg, Moshe Levy, Ron Bitton, Asaf Shabtai, and\n  Yuval Elovici", "title": "GIM: Gaussian Isolation Machines", "comments": "Submitted to IJCNN2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, neural network classifiers are likely to be exposed to input\ndata that is outside of their training distribution data. Samples from outside\nthe distribution may be classified as an existing class with high probability\nby softmax-based classifiers; such incorrect classifications affect the\nperformance of the classifiers and the applications/systems that depend on\nthem. Previous research aimed at distinguishing training distribution data from\nout-of-distribution data (OOD) has proposed detectors that are external to the\nclassification method. We present Gaussian isolation machine (GIM), a novel\nhybrid (generative-discriminative) classifier aimed at solving the problem\narising when OOD data is encountered. The GIM is based on a neural network and\nutilizes a new loss function that imposes a distribution on each of the trained\nclasses in the neural network's output space, which can be approximated by a\nGaussian. The proposed GIM's novelty lies in its discriminative performance and\ngenerative capabilities, a combination of characteristics not usually seen in a\nsingle classifier. The GIM achieves state-of-the-art classification results on\nimage recognition and sentiment analysis benchmarking datasets and can also\ndeal with OOD inputs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:51:47 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:39:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Amit", "Guy", ""], ["Rosenberg", "Ishai", ""], ["Levy", "Moshe", ""], ["Bitton", "Ron", ""], ["Shabtai", "Asaf", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.02184", "submitter": "Francisco Jesus Martinez-Murcia", "authors": "F.J. Martinez-Murcia, A. Ortiz, Marco A. Formoso, M. Lopez-Zamora,\n  J.L. Luque, A. Gim\\'enez", "title": "A Neural Approach to Ordinal Regression for the Preventive Assessment of\n  Developmental Dyslexia", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": "10.1007/978-3-030-61705-9_51", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Developmental Dyslexia (DD) is a learning disability related to the\nacquisition of reading skills that affects about 5% of the population. DD can\nhave an enormous impact on the intellectual and personal development of\naffected children, so early detection is key to implementing preventive\nstrategies for teaching language. Research has shown that there may be\nbiological underpinnings to DD that affect phoneme processing, and hence these\nsymptoms may be identifiable before reading ability is acquired, allowing for\nearly intervention. In this paper we propose a new methodology to assess the\nrisk of DD before students learn to read. For this purpose, we propose a mixed\nneural model that calculates risk levels of dyslexia from tests that can be\ncompleted at the age of 5 years. Our method first trains an auto-encoder, and\nthen combines the trained encoder with an optimized ordinal regression neural\nnetwork devised to ensure consistency of predictions. Our experiments show that\nthe system is able to detect unaffected subjects two years before it can assess\nthe risk of DD based mainly on phonological processing, giving a specificity of\n0.969 and a correct rate of more than 0.92. In addition, the trained encoder\ncan be used to transform test results into an interpretable subject spatial\ndistribution that facilitates risk assessment and validates methodology.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:08:41 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 10:49:21 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Martinez-Murcia", "F. J.", ""], ["Ortiz", "A.", ""], ["Formoso", "Marco A.", ""], ["Lopez-Zamora", "M.", ""], ["Luque", "J. L.", ""], ["Gim\u00e9nez", "A.", ""]]}, {"id": "2002.02193", "submitter": "Francesco Giannini", "authors": "Giuseppe Marra, Michelangelo Diligenti, Francesco Giannini, Marco Gori\n  and Marco Maggini", "title": "Relational Neural Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to achieve impressive results in several tasks\nwhere a large amount of training data is available. However, deep learning\nsolely focuses on the accuracy of the predictions, neglecting the reasoning\nprocess leading to a decision, which is a major issue in life-critical\napplications. Probabilistic logic reasoning allows to exploit both statistical\nregularities and specific domain expertise to perform reasoning under\nuncertainty, but its scalability and brittle integration with the layers\nprocessing the sensory data have greatly limited its applications. For these\nreasons, combining deep architectures and probabilistic logic reasoning is a\nfundamental goal towards the development of intelligent agents operating in\ncomplex environments. This paper presents Relational Neural Machines, a novel\nframework allowing to jointly train the parameters of the learners and of a\nFirst--Order Logic based reasoner. A Relational Neural Machine is able to\nrecover both classical learning from supervised data in case of pure\nsub-symbolic learning, and Markov Logic Networks in case of pure symbolic\nreasoning, while allowing to jointly train and perform inference in hybrid\nlearning tasks. Proper algorithmic solutions are devised to make learning and\ninference tractable in large-scale problems. The experiments show promising\nresults in different relational tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:53:57 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Marra", "Giuseppe", ""], ["Diligenti", "Michelangelo", ""], ["Giannini", "Francesco", ""], ["Gori", "Marco", ""], ["Maggini", "Marco", ""]]}, {"id": "2002.02196", "submitter": "Tao Bai", "authors": "Tao Bai, Jun Zhao, Jinlin Zhu, Shoudong Han, Jiefeng Chen, Bo Li, Alex\n  Kot", "title": "AI-GAN: Attack-Inspired Generation of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples, which are\ncrafted by adding imperceptible perturbations to inputs. Recently different\nattacks and strategies have been proposed, but how to generate adversarial\nexamples perceptually realistic and more efficiently remains unsolved. This\npaper proposes a novel framework called Attack-Inspired GAN (AI-GAN), where a\ngenerator, a discriminator, and an attacker are trained jointly. Once trained,\nit can generate adversarial perturbations efficiently given input images and\ntarget classes. Through extensive experiments on several popular datasets \\eg\nMNIST and CIFAR-10, AI-GAN achieves high attack success rates and reduces\ngeneration time significantly in various settings. Moreover, for the first\ntime, AI-GAN successfully scales to complicated datasets \\eg CIFAR-100 with\naround $90\\%$ success rates among all classes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 10:57:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 06:22:17 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Bai", "Tao", ""], ["Zhao", "Jun", ""], ["Zhu", "Jinlin", ""], ["Han", "Shoudong", ""], ["Chen", "Jiefeng", ""], ["Li", "Bo", ""], ["Kot", "Alex", ""]]}, {"id": "2002.02202", "submitter": "Zeyue Xue", "authors": "Zeyue Xue, Shuang Luo, Chao Wu, Pan Zhou, Kaigui Bian and Wei Du", "title": "Transfer Heterogeneous Knowledge Among Peer-to-Peer Teammates: A Model\n  Distillation Approach", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer-to-peer knowledge transfer in distributed environments has emerged as a\npromising method since it could accelerate learning and improve team-wide\nperformance without relying on pre-trained teachers in deep reinforcement\nlearning. However, for traditional peer-to-peer methods such as action\nadvising, they have encountered difficulties in how to efficiently expressed\nknowledge and advice. As a result, we propose a brand new solution to reuse\nexperiences and transfer value functions among multiple students via model\ndistillation. But it is still challenging to transfer Q-function directly since\nit is unstable and not bounded. To address this issue confronted with existing\nworks, we adopt Categorical Deep Q-Network. We also describe how to design an\nefficient communication protocol to exploit heterogeneous knowledge among\nmultiple distributed agents. Our proposed framework, namely Learning and\nTeaching Categorical Reinforcement (LTCR), shows promising performance on\nstabilizing and accelerating learning progress with improved team-wide reward\nin four typical experimental environments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 11:31:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Xue", "Zeyue", ""], ["Luo", "Shuang", ""], ["Wu", "Chao", ""], ["Zhou", "Pan", ""], ["Bian", "Kaigui", ""], ["Du", "Wei", ""]]}, {"id": "2002.02208", "submitter": "Alexandre d'Aspremont", "authors": "Alexandre d'Aspremont, Mert Pilanci", "title": "Global Convergence of Frank Wolfe on One Hidden Layer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive global convergence bounds for the Frank Wolfe algorithm when\ntraining one hidden layer neural networks. When using the ReLU activation\nfunction, and under tractable preconditioning assumptions on the sample data\nset, the linear minimization oracle used to incrementally form the solution can\nbe solved explicitly as a second order cone program. The classical Frank Wolfe\nalgorithm then converges with rate $O(1/T)$ where $T$ is both the number of\nneurons and the number of calls to the oracle.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 11:58:43 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["d'Aspremont", "Alexandre", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.02210", "submitter": "Javier Del Ser Dr.", "authors": "Ibai Lana, Javier J. Sanchez-Medina, Eleni I. Vlahogianni, Javier Del\n  Ser", "title": "From Data to Actions in Intelligent Transportation Systems: a\n  Prescription of Functional Requirements for Model Actionability", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Data Science permeate every field of Transportation Science and\nEngineering, resulting in developments in the transportation sector that {are}\ndata-driven. Nowadays, Intelligent Transportation Systems (ITS) could be\narguably approached as a ``story'' intensively producing and consuming large\namounts of data. A~diversity of sensing devices densely spread over the\ninfrastructure, vehicles or the travelers' personal devices act as sources of\ndata flows that are eventually fed {into} software running on automatic\ndevices, actuators or control systems producing, in~turn, complex information\nflows {among} users, traffic managers, data analysts, traffic modeling\nscientists, etc. These~information flows provide enormous opportunities to\nimprove model development and decision-making. This work aims to describe how\ndata, coming from diverse ITS sources, can be used to learn and adapt\ndata-driven models for efficiently operating ITS assets, systems and processes;\nin~other words, for data-based models to fully become \\emph{actionable}.\nGrounded in this described data modeling pipeline for ITS, we~define the\ncharacteristics, engineering requisites and challenges intrinsic to its three\ncompounding stages, namely, data fusion, adaptive learning and model\nevaluation. We~deliberately generalize model learning to be adaptive, since,\nin~the core of our paper is the firm conviction that most learners will have to\nadapt to the ever-changing phenomenon scenario underlying the majority of ITS\napplications. Finally, we~provide a prospect of current research lines within\nData Science that can bring notable advances to data-based ITS modeling, which\nwill eventually bridge the gap towards the practicality and actionability of\nsuch models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:02:30 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 14:33:07 GMT"}, {"version": "v3", "created": "Mon, 8 Feb 2021 15:17:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lana", "Ibai", ""], ["Sanchez-Medina", "Javier J.", ""], ["Vlahogianni", "Eleni I.", ""], ["Del Ser", "Javier", ""]]}, {"id": "2002.02247", "submitter": "Jaron Sanders", "authors": "Albert Senen-Cerda, Jaron Sanders", "title": "Almost Sure Convergence of Dropout Algorithms for Neural Networks", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the convergence and convergence rate of stochastic training\nalgorithms for Neural Networks (NNs) that, over the years, have spawned from\nDropout (Hinton et al., 2012). Modeling that neurons in the brain may not fire,\ndropout algorithms consist in practice of multiplying the weight matrices of a\nNN component-wise by independently drawn random matrices with $\\{0,1\\}$-valued\nentries during each iteration of the Feedforward-Backpropagation algorithm.\nThis paper presents a probability theoretical proof that for any NN topology\nand differentiable polynomially bounded activation functions, if we project the\nNN's weights into a compact set and use a dropout algorithm, then the weights\nconverge to a unique stationary set of a projected system of Ordinary\nDifferential Equations (ODEs). We also establish an upper bound on the rate of\nconvergence of Gradient Descent (GD) on the limiting ODEs of dropout algorithms\nfor arborescences (a class of trees) of arbitrary depth and with linear\nactivation functions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:25:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Senen-Cerda", "Albert", ""], ["Sanders", "Jaron", ""]]}, {"id": "2002.02250", "submitter": "Agust\\'in Somacal", "authors": "Agust\\'in Somacal, Yamila Barrera, Leonardo Boechi, Matthieu\n  Jonckheere, Vincent Lefieux, Dominique Picard and Ezequiel Smucler", "title": "Uncovering differential equations from data with hidden variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG nlin.CD physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SINDy is a method for learning system of differential equations from data by\nsolving a sparse linear regression optimization problem [Brunton et al., 2016].\nIn this article, we propose an extension of the SINDy method that learns\nsystems of differential equations in cases where some of the variables are not\nobserved. Our extension is based on regressing a higher order time derivative\nof a target variable onto a dictionary of functions that includes lower order\ntime derivatives of the target variable. We evaluate our method by measuring\nthe prediction accuracy of the learned dynamical systems on synthetic data and\non a real data-set of temperature time series provided by the R\\'eseau de\nTransport d'\\'Electricit\\'e (RTE). Our method provides high quality short-term\nforecasts and it is orders of magnitude faster than competing methods for\nlearning differential equations with latent variables.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:33:18 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:43:26 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Somacal", "Agust\u00edn", ""], ["Barrera", "Yamila", ""], ["Boechi", "Leonardo", ""], ["Jonckheere", "Matthieu", ""], ["Lefieux", "Vincent", ""], ["Picard", "Dominique", ""], ["Smucler", "Ezequiel", ""]]}, {"id": "2002.02265", "submitter": "Evin Pinar Ornek", "authors": "Evin Pinar Ornek", "title": "Zero-Shot Activity Recognition with Videos", "comments": "This is a research report done during master's studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examined the zero-shot activity recognition task with the\nusage of videos. We introduce an auto-encoder based model to construct a\nmultimodal joint embedding space between the visual and textual manifolds. On\nthe visual side, we used activity videos and a state-of-the-art 3D\nconvolutional action recognition network to extract the features. On the\ntextual side, we worked with GloVe word embeddings. The zero-shot recognition\nresults are evaluated by top-n accuracy. Then, the manifold learning ability is\nmeasured by mean Nearest Neighbor Overlap. In the end, we provide an extensive\ndiscussion over the results and the future directions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:33:10 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ornek", "Evin Pinar", ""]]}, {"id": "2002.02271", "submitter": "Dmitry Efimov", "authors": "Dmitry Efimov, Di Xu, Luyang Kong, Alexey Nefedov and Archana\n  Anandakrishnan", "title": "Using generative adversarial networks to synthesize artificial financial\n  datasets", "comments": null, "journal-ref": "Robust AI in FS 2019 : NeurIPS 2019 Workshop on Robust AI in\n  Financial Services: Data, Fairness, Explainability, Trustworthiness, and\n  Privacy, December 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) became very popular for generation of\nrealistically looking images. In this paper, we propose to use GANs to\nsynthesize artificial financial data for research and benchmarking purposes. We\ntest this approach on three American Express datasets, and show that properly\ntrained GANs can replicate these datasets with high fidelity. For our\nexperiments, we define a novel type of GAN, and suggest methods for data\npreprocessing that allow good training and testing performance of GANs. We also\ndiscuss methods for evaluating the quality of generated data, and their\ncomparison with the original real data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:25:08 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Efimov", "Dmitry", ""], ["Xu", "Di", ""], ["Kong", "Luyang", ""], ["Nefedov", "Alexey", ""], ["Anandakrishnan", "Archana", ""]]}, {"id": "2002.02274", "submitter": "Sara Ahmadian", "authors": "Sara Ahmadian, Alessandro Epasto, Ravi Kumar, Mohammad Mahdian", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study correlation clustering under fairness constraints.\nFair variants of $k$-median and $k$-center clustering have been studied\nrecently, and approximation algorithms using a notion called fairlet\ndecomposition have been proposed. We obtain approximation algorithms for fair\ncorrelation clustering under several important types of fairness constraints.\n  Our results hinge on obtaining a fairlet decomposition for correlation\nclustering by introducing a novel combinatorial optimization problem. We define\na fairlet decomposition with cost similar to the $k$-median cost and this\nallows us to obtain approximation algorithms for a wide range of fairness\nconstraints.\n  We complement our theoretical results with an in-depth analysis of our\nalgorithms on real graphs where we show that fair solutions to correlation\nclustering can be obtained with limited increase in cost compared to the\nstate-of-the-art (unfair) algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 14:28:21 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 22:27:51 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Ahmadian", "Sara", ""], ["Epasto", "Alessandro", ""], ["Kumar", "Ravi", ""], ["Mahdian", "Mohammad", ""]]}, {"id": "2002.02286", "submitter": "Edward Beeching", "authors": "Edward Beeching, Christian Wolf, Jilles Dibangoye, Olivier Simonin", "title": "EgoMap: Projective mapping and structured egocentric memory for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tasks involving localization, memorization and planning in partially\nobservable 3D environments are an ongoing challenge in Deep Reinforcement\nLearning. We present EgoMap, a spatially structured neural memory architecture.\nEgoMap augments a deep reinforcement learning agent's performance in 3D\nenvironments on challenging tasks with multi-step objectives. The EgoMap\narchitecture incorporates several inductive biases including a differentiable\ninverse projection of CNN feature vectors onto a top-down spatially structured\nmap. The map is updated with ego-motion measurements through a differentiable\naffine transform. We show this architecture outperforms both standard recurrent\nagents and state of the art agents with structured memory. We demonstrate that\nincorporating these inductive biases into an agent's architecture allows for\nstable training with reward alone, circumventing the expense of acquiring and\nlabelling expert trajectories. A detailed ablation study demonstrates the\nimpact of key aspects of the architecture and through extensive qualitative\nanalysis, we show how the agent exploits its structured internal memory to\nachieve higher performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:59:59 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 14:00:39 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Beeching", "Edward", ""], ["Wolf", "Christian", ""], ["Dibangoye", "Jilles", ""], ["Simonin", "Olivier", ""]]}, {"id": "2002.02302", "submitter": "Ziping Xu", "authors": "Ziping Xu and Ambuj Tewari", "title": "Reinforcement Learning in Factored MDPs: Oracle-Efficient Algorithms and\n  Tighter Regret Bounds for the Non-Episodic Setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study reinforcement learning in non-episodic factored Markov decision\nprocesses (FMDPs). We propose two near-optimal and oracle-efficient algorithms\nfor FMDPs. Assuming oracle access to an FMDP planner, they enjoy a Bayesian and\na frequentist regret bound respectively, both of which reduce to the\nnear-optimal bound $\\widetilde{O}(DS\\sqrt{AT})$ for standard non-factored MDPs.\nWe propose a tighter connectivity measure, factored span, for FMDPs and prove a\nlower bound that depends on the factored span rather than the diameter $D$. In\norder to decrease the gap between lower and upper bounds, we propose an\nadaptation of the REGAL.C algorithm whose regret bound depends on the factored\nspan. Our oracle-efficient algorithms outperform previously proposed\nnear-optimal algorithms on computer network administration simulations.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:19:53 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 03:30:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Xu", "Ziping", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2002.02305", "submitter": "Gregory Teichert", "authors": "Gregory Teichert, Anirudh Natarajan, Anton Van der Ven, Krishna\n  Garikipati", "title": "Scale bridging materials physics: Active learning workflows and\n  integrable deep neural networks for free energy function representations in\n  alloys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The free energy plays a fundamental role in descriptions of many systems in\ncontinuum physics. Notably, in multiphysics applications, it encodes\nthermodynamic coupling between different fields. It thereby gives rise to\ndriving forces on the dynamics of interaction between the constituent\nphenomena. In mechano-chemically interacting materials systems, even\nconsideration of only compositions, order parameters and strains can render the\nfree energy to be reasonably high-dimensional. In proposing the free energy as\na paradigm for scale bridging, we have previously exploited neural networks for\ntheir representation of such high-dimensional functions. Specifically, we have\ndeveloped an integrable deep neural network (IDNN) that can be trained to free\nenergy derivative data obtained from atomic scale models and statistical\nmechanics, then analytically integrated to recover a free energy density\nfunction. The motivation comes from the statistical mechanics formalism, in\nwhich certain free energy derivatives are accessible for control of the system,\nrather than the free energy itself. Our current work combines the IDNN with an\nactive learning workflow to improve sampling of the free energy derivative data\nin a high-dimensional input space. Treated as input-output maps, machine\nlearning accommodates role reversals between independent and dependent\nquantities as the mathematical descriptions change with scale bridging. As a\nprototypical system we focus on Ni-Al. Phase field simulations using the\nresulting IDNN representation for the free energy density of Ni-Al demonstrate\nthat the appropriate physics of the material have been learned. To the best of\nour knowledge, this represents the most complete treatment of scale bridging,\nusing the free energy for a practical materials system, that starts with\nelectronic structure calculations and proceeds through statistical mechanics to\ncontinuum physics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 03:59:24 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 20:03:17 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 14:12:08 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 23:43:21 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 20:31:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Teichert", "Gregory", ""], ["Natarajan", "Anirudh", ""], ["Van der Ven", "Anton", ""], ["Garikipati", "Krishna", ""]]}, {"id": "2002.02315", "submitter": "Nir Raviv", "authors": "Nir Raviv, Avi Caciularu, Tomer Raviv, Jacob Goldberger and Yair\n  Be'ery", "title": "perm2vec: Graph Permutation Selection for Decoding of Error Correction\n  Codes using Self-Attention", "comments": null, "journal-ref": "IEEE Journal on Selected Areas in Communications, vol. 39, no. 1,\n  pp. 79-88, Jan. 2021", "doi": "10.1109/JSAC.2020.3036951", "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error correction codes are an integral part of communication applications,\nboosting the reliability of transmission. The optimal decoding of transmitted\ncodewords is the maximum likelihood rule, which is NP-hard due to the curse of\ndimensionality. For practical realizations, sub-optimal decoding algorithms are\nemployed; yet limited theoretical insights prevent one from exploiting the full\npotential of these algorithms. One such insight is the choice of permutation in\npermutation decoding. We present a data-driven framework for permutation\nselection, combining domain knowledge with machine learning concepts such as\nnode embedding and self-attention. Significant and consistent improvements in\nthe bit error rate are introduced for all simulated codes, over the baseline\ndecoders. To the best of the authors' knowledge, this work is the first to\nleverage the benefits of the neural Transformer networks in physical layer\ncommunication systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:42:08 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 08:27:51 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Raviv", "Nir", ""], ["Caciularu", "Avi", ""], ["Raviv", "Tomer", ""], ["Goldberger", "Jacob", ""], ["Be'ery", "Yair", ""]]}, {"id": "2002.02318", "submitter": "Kun Ouyang", "authors": "Kun Ouyang, Yuxuan Liang, Ye Liu, Zekun Tong, Sijie Ruan, Yu Zheng,\n  and David S. Rosenblum", "title": "Fine-Grained Urban Flow Inference", "comments": "16 pages. arXiv admin note: substantial text overlap with\n  arXiv:1902.05377", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ubiquitous deployment of monitoring devices in urban flow monitoring\nsystems induces a significant cost for maintenance and operation. A technique\nis required to reduce the number of deployed devices, while preventing the\ndegeneration of data accuracy and granularity. In this paper, we present an\napproach for inferring the real-time and fine-grained crowd flows throughout a\ncity based on coarse-grained observations. This task exhibits two challenges:\nthe spatial correlations between coarse- and fine-grained urban flows, and the\ncomplexities of external impacts. To tackle these issues, we develop a model\nentitled UrbanFM which consists of two major parts: 1) an inference network to\ngenerate fine-grained flow distributions from coarse-grained inputs that uses a\nfeature extraction module and a novel distributional upsampling module; 2) a\ngeneral fusion subnet to further boost the performance by considering the\ninfluence of different external factors. This structure provides outstanding\neffectiveness and efficiency for small scale upsampling. However, the\nsingle-pass upsampling used by UrbanFM is insufficient at higher upscaling\nrates. Therefore, we further present UrbanPy, a cascading model for progressive\ninference of fine-grained urban flows by decomposing the original tasks into\nmultiple subtasks. Compared to UrbanFM, such an enhanced structure demonstrates\nfavorable performance for larger-scale inference tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 01:11:24 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Ouyang", "Kun", ""], ["Liang", "Yuxuan", ""], ["Liu", "Ye", ""], ["Tong", "Zekun", ""], ["Ruan", "Sijie", ""], ["Zheng", "Yu", ""], ["Rosenblum", "David S.", ""]]}, {"id": "2002.02339", "submitter": "Nikita Zhivotovskiy", "authors": "Yegor Klochkov, Alexey Kroshnin, and Nikita Zhivotovskiy", "title": "Robust $k$-means Clustering for Distributions with Two Moments", "comments": "28 pages, to appear in Ann. of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the robust algorithms for the $k$-means clustering problem where\na quantizer is constructed based on $N$ independent observations. Our main\nresults are median of means based non-asymptotic excess distortion bounds that\nhold under the two bounded moments assumption in a general separable Hilbert\nspace. In particular, our results extend the renowned asymptotic result of\nPollard, 1981 who showed that the existence of two moments is sufficient for\nstrong consistency of an empirically optimal quantizer in $\\mathbb{R}^d$. In a\nspecial case of clustering in $\\mathbb{R}^d$, under two bounded moments, we\nprove matching (up to constant factors) non-asymptotic upper and lower bounds\non the excess distortion, which depend on the probability mass of the lightest\ncluster of an optimal quantizer. Our bounds have the sub-Gaussian form, and the\nproofs are based on the versions of uniform bounds for robust mean estimators.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:36:53 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:59:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Klochkov", "Yegor", ""], ["Kroshnin", "Alexey", ""], ["Zhivotovskiy", "Nikita", ""]]}, {"id": "2002.02342", "submitter": "Xiaoliang Luo", "authors": "Xiaoliang Luo, Brett D. Roads, Bradley C. Love", "title": "The Costs and Benefits of Goal-Directed Attention in Deep Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People deploy top-down, goal-directed attention to accomplish tasks, such as\nfinding lost keys. By tuning the visual system to relevant information sources,\nobject recognition can become more efficient (a benefit) and more biased toward\nthe target (a potential cost). Motivated by selective attention in\ncategorisation models, we developed a goal-directed attention mechanism that\ncan process naturalistic (photographic) stimuli. Our attention mechanism can be\nincorporated into any existing deep convolutional neural network (DCNNs). The\nprocessing stages in DCNNs have been related to ventral visual stream. In that\nlight, our attentional mechanism incorporates top-down influences from\nprefrontal cortex (PFC) to support goal-directed behaviour. Akin to how\nattention weights in categorisation models warp representational spaces, we\nintroduce a layer of attention weights to the mid-level of a DCNN that amplify\nor attenuate activity to further a goal. We evaluated the attentional mechanism\nusing photographic stimuli, varying the attentional target. We found that\nincreasing goal-directed attention has benefits (increasing hit rates) and\ncosts (increasing false alarm rates). At a moderate level, attention improves\nsensitivity (i.e., increases $d^\\prime$) at only a moderate increase in bias\nfor tasks involving standard images, blended images, and natural adversarial\nimages chosen to fool DCNNs. These results suggest that goal-directed attention\ncan reconfigure general-purpose DCNNs to better suit the current task goal,\nmuch like PFC modulates activity along the ventral stream. In addition to being\nmore parsimonious and brain consistent, the mid-level attention approach\nperformed better than a standard machine learning approach for transfer\nlearning, namely retraining the final network layer to accommodate the new\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:42:00 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 20:21:42 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 11:25:26 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Luo", "Xiaoliang", ""], ["Roads", "Brett D.", ""], ["Love", "Bradley C.", ""]]}, {"id": "2002.02368", "submitter": "Abdalrahman Hwoij Mr", "authors": "Abdalrahman Hwoij, Mouhammd Al-kasassbeh, Mustafa Al-Fayoumi", "title": "Detecting Network Anomalies using Rule-based machine learning within\n  SNMP-MIB dataset", "comments": "17 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most effective threats that targeting cybercriminals to limit\nnetwork performance is Denial of Service (DOS) attack. Thus, data security,\ncompleteness and efficiency could be greatly damaged by this type of attacks.\nThis paper developed a network traffic system that relies on adopted dataset to\ndifferentiate the DOS attacks from normal traffic. The detection model is built\nwith five Rule-based machine learning classifiers (DecisionTable, JRip, OneR,\nPART and ZeroR). The findings have shown that the ICMP variables are\nimplemented in the identification of ICMP attack, HTTP flood attack, and\nSlowloris at a high accuracy of approximately 99.7% using PART classifier. In\naddition, PART classifier has succeeded in classifying normal traffic from\ndifferent DOS attacks at 100%.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 13:05:41 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Hwoij", "Abdalrahman", ""], ["Al-kasassbeh", "Mouhammd", ""], ["Al-Fayoumi", "Mustafa", ""]]}, {"id": "2002.02372", "submitter": "Zhuanghua Liu", "authors": "Zhuanghua Liu and Ivor W. Tsang", "title": "Towards Sharper First-Order Adversary with Quantized Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite the huge success of Deep Neural Networks (DNNs) in a wide spectrum of\nmachine learning and data mining tasks, recent research shows that this\npowerful tool is susceptible to maliciously crafted adversarial examples. Up\nuntil now, adversarial training has been the most successful defense against\nadversarial attacks. To increase adversarial robustness, a DNN can be trained\nwith a combination of benign and adversarial examples generated by first-order\nmethods. However, in state-of-the-art first-order attacks, adversarial examples\nwith sign gradients retain the sign information of each gradient component but\ndiscard the relative magnitude between components. In this work, we replace\nsign gradients with quantized gradients. Gradient quantization not only\npreserves the sign information, but also keeps the relative magnitude between\ncomponents. Experiments show white-box first-order attacks with quantized\ngradients outperform their variants with sign gradients on multiple datasets.\nNotably, our BLOB\\_QG attack achieves an accuracy of $88.32\\%$ on the secret\nMNIST model from the MNIST Challenge and it outperforms all other methods on\nthe leaderboard of white-box attacks.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:33:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Liu", "Zhuanghua", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "2002.02374", "submitter": "Yun Yuan", "authors": "Yun Yuan, Xianfeng Terry Yang, Zhao Zhang, Shandian Zhe", "title": "Macroscopic Traffic Flow Modeling with Physics Regularized Gaussian\n  Process: A New Insight into Machine Learning Applications", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide implementation of machine learning (ML) techniques in\ntraffic flow modeling recently, those data-driven approaches often fall short\nof accuracy in the cases with a small or noisy dataset. To address this issue,\nthis study presents a new modeling framework, named physics regularized machine\nlearning (PRML), to encode classical traffic flow models (referred as physical\nmodels) into the ML architecture and to regularize the ML training process.\nMore specifically, a stochastic physics regularized Gaussian process (PRGP)\nmodel is developed and a Bayesian inference algorithm is used to estimate the\nmean and kernel of the PRGP. A physical regularizer based on macroscopic\ntraffic flow models is also developed to augment the estimation via a shadow GP\nand an enhanced latent force model is used to encode physical knowledge into\nstochastic processes. Based on the posterior regularization inference\nframework, an efficient stochastic optimization algorithm is also developed to\nmaximize the evidence lowerbound of the system likelihood. To prove the\neffectiveness of the proposed model, this paper conducts empirical studies on a\nreal-world dataset which is collected from a stretch of I-15 freeway, Utah.\nResults show the new PRGP model can outperform the previous compatible methods,\nsuch as calibrated pure physical models and pure machine learning methods, in\nestimation precision and input robustness.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:22:20 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Yuan", "Yun", ""], ["Yang", "Xianfeng Terry", ""], ["Zhang", "Zhao", ""], ["Zhe", "Shandian", ""]]}, {"id": "2002.02383", "submitter": "Dario Zanca", "authors": "Dario Zanca, Alessandra Rufa", "title": "1-D Convlutional Neural Networks for the Analysis of Pupil Size\n  Variations in Scotopic Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that a systematic analysis of the pupil size variations,\nrecorded by means of an eye-tracker, is a rich source of information about a\nsubject's arousal and cognitive state. Current methods for pupil analysis are\nlimited to descriptive statistics, struggle in handling the wide inter-subjects\nvariability and must be coupled with a long series of pre-processing signal\noperations. In this we present a data-driven approach in which 1-D\nConvolutional Neural Networks are applied directly to the raw pupil size data.\nTo test its effectiveness, we apply our method in a binary classification task\nwith two different groups of subjects: a group of elderly patients with\nParkinson disease (PDs), a condition in which pupil abnormalities have been\nextensively reported, and a group of healthy adults subjects (HCs). Long-range\nregistration (10 minutes) of the pupil size were collected in scotopic\nconditions (complete darkness, 0 lux). 1-D convolutional neural network models\nare trained for classification of short-range sequences (10 to 60 seconds of\nregistration). The model provides prediction with high average accuracy on a\nhold out test set. Dataset and codes are released for reproducibility and\nbenchmarking purposes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:25:37 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:49:51 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Zanca", "Dario", ""], ["Rufa", "Alessandra", ""]]}, {"id": "2002.02385", "submitter": "Adam Marblestone", "authors": "Adam Marblestone, Yan Wu, Greg Wayne", "title": "Product Kanerva Machines: Factorized Bayesian Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ideal cognitively-inspired memory system would compress and organize\nincoming items. The Kanerva Machine (Wu et al, 2018) is a Bayesian model that\nnaturally implements online memory compression. However, the organization of\nthe Kanerva Machine is limited by its use of a single Gaussian random matrix\nfor storage. Here we introduce the Product Kanerva Machine, which dynamically\ncombines many smaller Kanerva Machines. Its hierarchical structure provides a\nprincipled way to abstract invariant features and gives scaling and capacity\nadvantages over single Kanerva Machines. We show that it can exhibit\nunsupervised clustering, find sparse and combinatorial allocation patterns, and\ndiscover spatial tunings that approximately factorize simple images by object.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:29:04 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Marblestone", "Adam", ""], ["Wu", "Yan", ""], ["Wayne", "Greg", ""]]}, {"id": "2002.02390", "submitter": "Sebastien Gerchinovitz", "authors": "Cl\\'ement Bouttier, Tommaso Cesari (ANITI, TSE, UNIMI), S\\'ebastien\n  Gerchinovitz (IMT)", "title": "Regret analysis of the Piyavskii-Shubert algorithm for global Lipschitz\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of maximizing a non-concave Lipschitz multivariate\nfunction f over a compact domain. We provide regret guarantees (i.e.,\noptimization error bounds) for a very natural algorithm originally designed by\nPiyavskii and Shubert in 1972. Our results hold in a general setting in which\nvalues of f can only be accessed approximately. In particular, they yield\nstate-of-the-art regret bounds both when f is observed exactly and when\nevaluations are perturbed by an independent subgaussian noise.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:31:27 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Bouttier", "Cl\u00e9ment", "", "ANITI, TSE, UNIMI"], ["Cesari", "Tommaso", "", "ANITI, TSE, UNIMI"], ["Gerchinovitz", "S\u00e9bastien", "", "IMT"]]}, {"id": "2002.02393", "submitter": "Ke Chen", "authors": "Ke Chen, Gus Xia, Shlomo Dubnov", "title": "Continuous Melody Generation via Disentangled Short-Term Representations\n  and Structural Conditions", "comments": "9 pages, 12 figures, 4 tables. in 14th international conference on\n  semantic computing, ICSC 2020", "journal-ref": "2020 IEEE 14th International Conference on Semantic Computing", "doi": "10.1109/ICSC.2020.00025", "report-no": null, "categories": "cs.SD cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic music generation is an interdisciplinary research topic that\ncombines computational creativity and semantic analysis of music to create\nautomatic machine improvisations. An important property of such a system is\nallowing the user to specify conditions and desired properties of the generated\nmusic. In this paper we designed a model for composing melodies given a user\nspecified symbolic scenario combined with a previous music context. We add\nmanual labeled vectors denoting external music quality in terms of chord\nfunction that provides a low dimensional representation of the harmonic tension\nand resolution. Our model is capable of generating long melodies by regarding\n8-beat note sequences as basic units, and shares consistent rhythm pattern\nstructure with another specific song. The model contains two stages and\nrequires separate training where the first stage adopts a Conditional\nVariational Autoencoder (C-VAE) to build a bijection between note sequences and\ntheir latent representations, and the second stage adopts long short-term\nmemory networks (LSTM) with structural conditions to continue writing future\nmelodies. We further exploit the disentanglement technique via C-VAE to allow\nmelody generation based on pitch contour information separately from\nconditioning on rhythm patterns. Finally, we evaluate the proposed model using\nquantitative analysis of rhythm and the subjective listening study. Results\nshow that the music generated by our model tends to have salient repetition\nstructures, rich motives, and stable rhythm patterns. The ability to generate\nlonger and more structural phrases from disentangled representations combined\nwith semantic scenario specification conditions shows a broad application of\nour model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:23:44 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Ke", ""], ["Xia", "Gus", ""], ["Dubnov", "Shlomo", ""]]}, {"id": "2002.02400", "submitter": "Brian Kim", "authors": "Brian Kim and Yalin E. Sagduyu and Kemal Davaslioglu and Tugba Erpek\n  and Sennur Ulukus", "title": "Over-the-Air Adversarial Attacks on Deep Learning Based Modulation\n  Classifier over Wireless Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless communication system that consists of a transmitter, a\nreceiver, and an adversary. The transmitter transmits signals with different\nmodulation types, while the receiver classifies its received signals to\nmodulation types using a deep learning-based classifier. In the meantime, the\nadversary makes over-the-air transmissions that are received as superimposed\nwith the transmitter's signals to fool the classifier at the receiver into\nmaking errors. While this evasion attack has received growing interest\nrecently, the channel effects from the adversary to the receiver have been\nignored so far such that the previous attack mechanisms cannot be applied under\nrealistic channel effects. In this paper, we present how to launch a realistic\nevasion attack by considering channels from the adversary to the receiver. Our\nresults show that modulation classification is vulnerable to an adversarial\nattack over a wireless channel that is modeled as Rayleigh fading with path\nloss and shadowing. We present various adversarial attacks with respect to\navailability of information about channel, transmitter input, and classifier\narchitecture. First, we present two types of adversarial attacks, namely a\ntargeted attack (with minimum power) and non-targeted attack that aims to\nchange the classification to a target label or to any other label other than\nthe true label, respectively. Both are white-box attacks that are transmitter\ninput-specific and use channel information. Then we introduce an algorithm to\ngenerate adversarial attacks using limited channel information where the\nadversary only knows the channel distribution. Finally, we present a black-box\nuniversal adversarial perturbation (UAP) attack where the adversary has limited\nknowledge about both channel and transmitter input.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 18:45:43 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 17:35:34 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kim", "Brian", ""], ["Sagduyu", "Yalin E.", ""], ["Davaslioglu", "Kemal", ""], ["Erpek", "Tugba", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2002.02405", "submitter": "Sebastian Nowozin", "authors": "Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub\n  \\'Swi\\k{a}tkowski, Linh Tran, Stephan Mandt, Jasper Snoek, Tim Salimans,\n  Rodolphe Jenatton, Sebastian Nowozin", "title": "How Good is the Bayes Posterior in Deep Neural Networks Really?", "comments": "Full version (main paper and appendix) of the ICML 2020 publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past five years the Bayesian deep learning community has developed\nincreasingly accurate and efficient approximate inference procedures that allow\nfor Bayesian inference in deep neural networks. However, despite this\nalgorithmic progress and the promise of improved uncertainty quantification and\nsample efficiency there are---as of early 2020---no publicized deployments of\nBayesian neural networks in industrial practice. In this work we cast doubt on\nthe current understanding of Bayes posteriors in popular deep neural networks:\nwe demonstrate through careful MCMC sampling that the posterior predictive\ninduced by the Bayes posterior yields systematically worse predictions compared\nto simpler methods including point estimates obtained from SGD. Furthermore, we\ndemonstrate that predictive performance is improved significantly through the\nuse of a \"cold posterior\" that overcounts evidence. Such cold posteriors\nsharply deviate from the Bayesian paradigm but are commonly used as heuristic\nin Bayesian deep learning papers. We put forward several hypotheses that could\nexplain cold posteriors and evaluate the hypotheses through experiments. Our\nwork questions the goal of accurate posterior approximations in Bayesian deep\nlearning: If the true Bayes posterior is poor, what is the use of more accurate\napproximations? Instead, we argue that it is timely to focus on understanding\nthe origin of the improved performance of cold posteriors.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:38:48 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 22:18:12 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wenzel", "Florian", ""], ["Roth", "Kevin", ""], ["Veeling", "Bastiaan S.", ""], ["\u015awi\u0105tkowski", "Jakub", ""], ["Tran", "Linh", ""], ["Mandt", "Stephan", ""], ["Snoek", "Jasper", ""], ["Salimans", "Tim", ""], ["Jenatton", "Rodolphe", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "2002.02406", "submitter": "Daniel Daza", "authors": "Daniel Daza and Michael Cochez", "title": "Message Passing Query Embedding", "comments": "Presented at ICML 2020 - GRL+ Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works on representation learning for Knowledge Graphs have moved\nbeyond the problem of link prediction, to answering queries of an arbitrary\nstructure. Existing methods are based on ad-hoc mechanisms that require\ntraining with a diverse set of query structures. We propose a more general\narchitecture that employs a graph neural network to encode a graph\nrepresentation of the query, where nodes correspond to entities and variables.\nThe generality of our method allows it to encode a more diverse set of query\ntypes in comparison to previous work. Our method shows competitive performance\nagainst previous models for complex queries, and in contrast with these models,\nit can answer complex queries when trained for link prediction only. We show\nthat the model learns entity embeddings that capture the notion of entity type\nwithout explicit supervision.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 17:40:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 11:35:19 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Daza", "Daniel", ""], ["Cochez", "Michael", ""]]}, {"id": "2002.02417", "submitter": "Tianyi Lin", "authors": "Tianyi Lin, Chi Jin and Michael. I. Jordan", "title": "Near-Optimal Algorithms for Minimax Optimization", "comments": "Accepted by COLT 2020; Improve the writing and fix some confusing\n  parts in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper resolves a longstanding open question pertaining to the design of\nnear-optimal first-order algorithms for smooth and\nstrongly-convex-strongly-concave minimax problems. Current state-of-the-art\nfirst-order algorithms find an approximate Nash equilibrium using\n$\\tilde{O}(\\kappa_{\\mathbf x}+\\kappa_{\\mathbf y})$ or\n$\\tilde{O}(\\min\\{\\kappa_{\\mathbf x}\\sqrt{\\kappa_{\\mathbf y}},\n\\sqrt{\\kappa_{\\mathbf x}}\\kappa_{\\mathbf y}\\})$ gradient evaluations, where\n$\\kappa_{\\mathbf x}$ and $\\kappa_{\\mathbf y}$ are the condition numbers for the\nstrong-convexity and strong-concavity assumptions. A gap still remains between\nthese results and the best existing lower bound\n$\\tilde{\\Omega}(\\sqrt{\\kappa_{\\mathbf x}\\kappa_{\\mathbf y}})$. This paper\npresents the first algorithm with $\\tilde{O}(\\sqrt{\\kappa_{\\mathbf\nx}\\kappa_{\\mathbf y}})$ gradient complexity, matching the lower bound up to\nlogarithmic factors. Our algorithm is designed based on an accelerated proximal\npoint method and an accelerated solver for minimax proximal steps. It can be\neasily extended to the settings of strongly-convex-concave, convex-concave,\nnonconvex-strongly-concave, and nonconvex-concave functions. This paper also\npresents algorithms that match or outperform all existing methods in these\nsettings in terms of gradient complexity, up to logarithmic factors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:49:09 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:00:36 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:15:15 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 01:40:41 GMT"}, {"version": "v5", "created": "Sun, 14 Jun 2020 20:00:53 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 17:48:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Lin", "Tianyi", ""], ["Jin", "Chi", ""], ["Jordan", "Michael. I.", ""]]}, {"id": "2002.02418", "submitter": "Ali Marjaninejad", "authors": "Romina Mir, Ali Marjaninejad, Francisco J. Valero-Cuevas", "title": "The utility of tactile force to autonomous learning of in-hand\n  manipulation is task-dependent", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile sensors provide information that can be used to learn and execute\nmanipulation tasks. Different tasks, however, might require different levels of\nsensory information; which in turn likely affect learning rates and\nperformance. This paper evaluates the role of tactile information on autonomous\nlearning of manipulation with a simulated 3-finger tendon-driven hand. We\ncompare the ability of the same learning algorithm (Proximal Policy\nOptimization, PPO) to learn two manipulation tasks (rolling a ball about the\nhorizontal axis with and without rotational stiffness) with three levels of\ntactile sensing: no sensing, 1D normal force, and 3D force vector.\nSurprisingly, and contrary to recent work on manipulation, adding 1D\nforce-sensing did not always improve learning rates compared to no\nsensing---likely due to whether or not normal force is relevant to the task.\nNonetheless, even though 3D force-sensing increases the dimensionality of the\nsensory input---which would in general hamper algorithm convergence---it\nresulted in faster learning rates and better performance. We conclude that, in\ngeneral, sensory input is useful to learning only when it is relevant to the\ntask---as is the case of 3D force-sensing for in-hand manipulation against\ngravity. Moreover, the utility of 3D force-sensing can even offset the added\ncomputational cost of learning with higher-dimensional sensory input.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:24:40 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mir", "Romina", ""], ["Marjaninejad", "Ali", ""], ["Valero-Cuevas", "Francisco J.", ""]]}, {"id": "2002.02423", "submitter": "Ali Kheradmand", "authors": "Ali Kheradmand", "title": "Automatic Inference of High-Level Network Intents by Mining Forwarding\n  Patterns", "comments": "SOSR 2020", "journal-ref": null, "doi": "10.1145/3373360.3380831", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a semantic gap between the high-level intents of network operators\nand the low-level configurations that achieve the intents. Previous works tried\nto bridge the gap using verification or synthesis techniques, both requiring\nformal specifications of the intended behavior which are rarely available or\neven known in the real world. This paper discusses an alternative approach for\nbridging the gap, namely to infer the high-level intents from the low-level\nnetwork behavior. Specifically, we provide Anime, a framework and a tool that\ngiven a set of observed forwarding behavior, automatically infers a set of\npossible intents that best describe all observations. Our results show that\nAnime can infer high-quality intents from the low-level forwarding behavior\nwith acceptable performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:06:42 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 19:05:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kheradmand", "Ali", ""]]}, {"id": "2002.02428", "submitter": "George Papamakarios", "authors": "Danilo Jimenez Rezende, George Papamakarios, S\\'ebastien Racani\\`ere,\n  Michael S. Albergo, Gurtej Kanwar, Phiala E. Shanahan, Kyle Cranmer", "title": "Normalizing Flows on Tori and Spheres", "comments": "Accepted to the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows are a powerful tool for building expressive distributions\nin high dimensions. So far, most of the literature has concentrated on learning\nflows on Euclidean spaces. Some problems however, such as those involving\nangles, are defined on spaces with more complex geometries, such as tori or\nspheres. In this paper, we propose and compare expressive and numerically\nstable flows on such spaces. Our flows are built recursively on the dimension\nof the space, starting from flows on circles, closed intervals or spheres.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:24:06 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 16:48:12 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Papamakarios", "George", ""], ["Racani\u00e8re", "S\u00e9bastien", ""], ["Albergo", "Michael S.", ""], ["Kanwar", "Gurtej", ""], ["Shanahan", "Phiala E.", ""], ["Cranmer", "Kyle", ""]]}, {"id": "2002.02431", "submitter": "Ilqar Ramazanli", "authors": "Ilqar ramazanli, Barnabas Poczos", "title": "Optimal Adaptive Matrix Completion", "comments": "-", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of exact completion for $m \\times n$ sized matrix of\nrank r with the adaptive sampling method. We introduce a relation of the exact\ncompletion problem with the sparsest vector of column and row spaces (which we\ncall sparsity-number here). Using this relation, we propose matrix completion\nalgorithms that exactly recovers the target matrix. These algorithms are\nsuperior to previous works in two important ways. First, our algorithms exactly\nrecover $\\mu_0$-coherent column space matrices by probability at least\n$1-\\epsilon$ using much smaller observations complexity than -\n$\\mathcal{O}(\\mu_0 rn \\mathrm{log}\\frac{r}{\\epsilon})$ - the state of art.\nSpecifically, many of the previous adaptive sampling methods require to observe\nthe entire matrix when the column space is highly coherent. However, we show\nthat our method is still able to recover this type of matrices by observing a\nsmall fraction of entries under many scenarios. Second, we propose an exact\ncompletion algorithm, which requires minimal pre-information as either row or\ncolumn space is not being highly coherent. We provide an extension of these\nalgorithms that is robust to sparse random noise. Besides, we propose an\nadditional low-rank estimation algorithm that is robust to any small noise by\nadaptively studying the shape of column space. At the end of the paper, we\nprovide experimental results that illustrate the strength of the algorithms\nproposed here.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:31:47 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["ramazanli", "Ilqar", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2002.02450", "submitter": "Pavel Gulyaev", "authors": "Pavel Gulyaev, Eugenia Elistratova, Vasily Konovalov, Yuri Kuratov,\n  Leonid Pugachev, Mikhail Burtsev", "title": "Goal-Oriented Multi-Task BERT-Based Dialogue State Tracker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue State Tracking (DST) is a core component of virtual assistants such\nas Alexa or Siri. To accomplish various tasks, these assistants need to support\nan increasing number of services and APIs. The Schema-Guided State Tracking\ntrack of the 8th Dialogue System Technology Challenge highlighted the DST\nproblem for unseen services. The organizers introduced the Schema-Guided\nDialogue (SGD) dataset with multi-domain conversations and released a zero-shot\ndialogue state tracking model. In this work, we propose a GOaL-Oriented\nMulti-task BERT-based dialogue state tracker (GOLOMB) inspired by architectures\nfor reading comprehension question answering systems. The model \"queries\"\ndialogue history with descriptions of slots and services as well as possible\nvalues of slots. This allows to transfer slot values in multi-domain dialogues\nand have a capability to scale to unseen slot types. Our model achieves a joint\ngoal accuracy of 53.97% on the SGD dataset, outperforming the baseline model.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 22:56:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Gulyaev", "Pavel", ""], ["Elistratova", "Eugenia", ""], ["Konovalov", "Vasily", ""], ["Kuratov", "Yuri", ""], ["Pugachev", "Leonid", ""], ["Burtsev", "Mikhail", ""]]}, {"id": "2002.02453", "submitter": "Shomik Jain", "authors": "Shomik Jain, Balasubramanian Thiagarajan, Zhonghao Shi, Caitlyn\n  Clabaugh, Maja J. Matari\\'c", "title": "Modeling Engagement in Long-Term, In-Home Socially Assistive Robot\n  Interventions for Children with Autism Spectrum Disorders", "comments": "This manuscript was published in Science Robotics on February 26,\n  2020", "journal-ref": "Sci. Robot. 5, eaaz3791 (2020)", "doi": "10.1126/scirobotics.aaz3791", "report-no": null, "categories": "cs.HC cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socially assistive robotics (SAR) has great potential to provide accessible,\naffordable, and personalized therapeutic interventions for children with autism\nspectrum disorders (ASD). However, human-robot interaction (HRI) methods are\nstill limited in their ability to autonomously recognize and respond to\nbehavioral cues, especially in atypical users and everyday settings. This work\napplies supervised machine learning algorithms to model user engagement in the\ncontext of long-term, in-home SAR interventions for children with ASD.\nSpecifically, we present two types of engagement models for each user: (i)\ngeneralized models trained on data from different users; and (ii)\nindividualized models trained on an early subset of the user's data. The models\nachieved approximately 90% accuracy (AUROC) for post hoc binary classification\nof engagement, despite the high variance in data observed across users,\nsessions, and engagement states. Moreover, temporal patterns in model\npredictions could be used to reliably initiate re-engagement actions at\nappropriate times. These results validate the feasibility and challenges of\nrecognition and response to user disengagement in long-term, real-world HRI\nsettings. The contributions of this work also inform the design of engaging and\npersonalized HRI, especially for the ASD community.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:26:11 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 03:26:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Jain", "Shomik", ""], ["Thiagarajan", "Balasubramanian", ""], ["Shi", "Zhonghao", ""], ["Clabaugh", "Caitlyn", ""], ["Matari\u0107", "Maja J.", ""]]}, {"id": "2002.02460", "submitter": "Ezequiel Alvarez", "authors": "Ezequiel Alvarez (ICAS), Federico Lamagna (CAB), Cesar Miquel\n  (Easytech) and Manuel Szewc (ICAS)", "title": "Intelligent Arxiv: Sort daily papers by learning users topics preference", "comments": "We are open to new ideas and to scientists and institutions wishing\n  to collaborate and/or partner in further improvements for this service. With\n  this tool the time a paper is sent is irrelevant for its order of appearance", "journal-ref": null, "doi": null, "report-no": "ICAS 047/20", "categories": "cs.LG astro-ph.HE gr-qc hep-ph hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current daily paper releases are becoming increasingly large and areas of\nresearch are growing in diversity. This makes it harder for scientists to keep\nup to date with current state of the art and identify relevant work within\ntheir lines of interest. The goal of this article is to address this problem\nusing Machine Learning techniques. We model a scientific paper to be built as a\ncombination of different scientific knowledge from diverse topics into a new\nproblem. In light of this, we implement the unsupervised Machine Learning\ntechnique of Latent Dirichlet Allocation (LDA) on the corpus of papers in a\ngiven field to: i) define and extract underlying topics in the corpus; ii) get\nthe topics weight vector for each paper in the corpus; and iii) get the topics\nweight vector for new papers. By registering papers preferred by a user, we\nbuild a user vector of weights using the information of the vectors of the\nselected papers. Hence, by performing an inner product between the user vector\nand each paper in the daily Arxiv release, we can sort the papers according to\nthe user preference on the underlying topics.\n  We have created the website IArxiv.org where users can read sorted daily\nArxiv releases (and more) while the algorithm learns each users preference,\nyielding a more accurate sorting every day. Current IArxiv.org version runs on\nArxiv categories astro-ph, gr-qc, hep-ph and hep-th and we plan to extend to\nothers. We propose several new useful and relevant implementations to be\nadditionally developed as well as new Machine Learning techniques beyond LDA to\nfurther improve the accuracy of this new tool.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:00:02 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Alvarez", "Ezequiel", "", "ICAS"], ["Lamagna", "Federico", "", "CAB"], ["Miquel", "Cesar", "", "Easytech"], ["Szewc", "Manuel", "", "ICAS"]]}, {"id": "2002.02492", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Jaedeok Kim, Richard Yuanzhe Pang,\n  Kyunghyun Cho", "title": "Consistency of a Recurrent Language Model With Respect to Incomplete\n  Decoding", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite strong performance on a variety of tasks, neural sequence models\ntrained with maximum likelihood have been shown to exhibit issues such as\nlength bias and degenerate repetition. We study the related issue of receiving\ninfinite-length sequences from a recurrent language model when using common\ndecoding algorithms. To analyze this issue, we first define inconsistency of a\ndecoding algorithm, meaning that the algorithm can yield an infinite-length\nsequence that has zero probability under the model. We prove that commonly used\nincomplete decoding algorithms - greedy search, beam search, top-k sampling,\nand nucleus sampling - are inconsistent, despite the fact that recurrent\nlanguage models are trained to produce sequences of finite length. Based on\nthese insights, we propose two remedies which address inconsistency: consistent\nvariants of top-k and nucleus sampling, and a self-terminating recurrent\nlanguage model. Empirical results show that inconsistency occurs in practice,\nand that the proposed methods prevent inconsistency.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 19:56:15 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 22:36:49 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Kim", "Jaedeok", ""], ["Pang", "Richard Yuanzhe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2002.02497", "submitter": "Joseph Paul Cohen", "authors": "Joseph Paul Cohen and Mohammad Hashir and Rupert Brooks and Hadrien\n  Bertrand", "title": "On the limits of cross-domain generalization in automated X-ray\n  prediction", "comments": "Full paper at MIDL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This large scale study focuses on quantifying what X-rays diagnostic\nprediction tasks generalize well across multiple different datasets. We present\nevidence that the issue of generalization is not due to a shift in the images\nbut instead a shift in the labels. We study the cross-domain performance,\nagreement between models, and model representations. We find interesting\ndiscrepancies between performance and agreement where models which both achieve\ngood performance disagree in their predictions as well as models which agree\nyet achieve poor performance. We also test for concept similarity by\nregularizing a network to group tasks across multiple datasets together and\nobserve variation across the tasks. All code is made available online and data\nis publicly available: https://github.com/mlmed/torchxrayvision\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:07:54 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 21:40:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Cohen", "Joseph Paul", ""], ["Hashir", "Mohammad", ""], ["Brooks", "Rupert", ""], ["Bertrand", "Hadrien", ""]]}, {"id": "2002.02508", "submitter": "Victoria Kostina", "authors": "Chung-Yi Lin, Victoria Kostina, and Babak Hassibi", "title": "Differentially Quantized Gradient Methods", "comments": "Extended version of the paper accepted to ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers quantized distributed optimization algorithms in the\nparameter server framework of distributed training. We introduce the principle\nwe call Differential Quantization (DQ) that prescribes that the past\nquantization errors should be compensated in such a way as to direct the\ndescent trajectory of a quantized algorithm towards that of its unquantized\ncounterpart. Assuming that the objective function is smooth and strongly\nconvex, we prove that in the limit of large problem dimension, Differentially\nQuantized Gradient Descent (DQ-GD) attains a linear contraction factor of\n$\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$, where $\\sigma_{\\mathrm{GD}}$ is the\ncontraction factor of unquantized gradient descent (GD). Thus at any\n$R\\geq\\log_2 1 /\\sigma_{\\mathrm{GD}}$ bits, the contraction factor of DQ-GD is\nthe same as that of unquantized GD, i.e., there is no loss due to quantization.\nWe show a converse demonstrating that no quantized gradient descent algorithm\ncan converge faster than $\\max\\{\\sigma_{\\mathrm{GD}}, 2^{-R}\\}$. In contrast,\nnaively quantized GD where the worker directly quantizes the gradient barely\nattains $\\sigma_{\\mathrm{GD}} + 2^{-R}$. The principle of differential\nquantization continues to apply to gradient methods with momentum such as\nNesterov's accelerated gradient descent, and Polyak's heavy ball method. For\nthese algorithms as well, if the rate is above a certain threshold, there is no\nloss in contraction factor obtained by the differentially quantized algorithm\ncompared to its unquantized counterpart, and furthermore, the differentially\nquantized heavy ball method attains the optimal contraction achievable among\nall (even unquantized) gradient methods. Experimental results on both simulated\nand real-world least-squares problems validate our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:40:53 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 21:03:45 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 21:00:33 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lin", "Chung-Yi", ""], ["Kostina", "Victoria", ""], ["Hassibi", "Babak", ""]]}, {"id": "2002.02511", "submitter": "Brendan Bena", "authors": "Brendan Bena and Jugal Kalita", "title": "Introducing Aspects of Creativity in Automatic Poetry Generation", "comments": "10 pages, 10 figures, 4 tables, ICON-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poetry Generation involves teaching systems to automatically generate text\nthat resembles poetic work. A deep learning system can learn to generate poetry\non its own by training on a corpus of poems and modeling the particular style\nof language. In this paper, we propose taking an approach that fine-tunes\nGPT-2, a pre-trained language model, to our downstream task of poetry\ngeneration. We extend prior work on poetry generation by introducing creative\nelements. Specifically, we generate poems that express emotion and elicit the\nsame in readers, and poems that use the language of dreams---called dream\npoetry. We are able to produce poems that correctly elicit the emotions of\nsadness and joy 87.5 and 85 percent, respectively, of the time. We produce\ndreamlike poetry by training on a corpus of texts that describe dreams. Poems\nfrom this model are shown to capture elements of dream poetry with scores of no\nless than 3.2 on the Likert scale. We perform crowdsourced human-evaluation for\nall our poems. We also make use of the Coh-Metrix tool, outlining metrics we\nuse to gauge the quality of text generated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:44:12 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bena", "Brendan", ""], ["Kalita", "Jugal", ""]]}, {"id": "2002.02513", "submitter": "Sriram Ganapathi Subramanian", "authors": "Sriram Ganapathi Subramanian and Pascal Poupart and Matthew E. Taylor\n  and Nidhi Hegde", "title": "Multi Type Mean Field Reinforcement Learning", "comments": "Paper to appear in the Proceedings of International Conference on\n  Autonomous Agents and Multi-Agent Systems (AAMAS) 2020. Revised version has\n  some typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field theory provides an effective way of scaling multiagent\nreinforcement learning algorithms to environments with many agents that can be\nabstracted by a virtual mean agent. In this paper, we extend mean field\nmultiagent algorithms to multiple types. The types enable the relaxation of a\ncore assumption in mean field games, which is that all agents in the\nenvironment are playing almost similar strategies and have the same goal. We\nconduct experiments on three different testbeds for the field of many agent\nreinforcement learning, based on the standard MAgents framework. We consider\ntwo different kinds of mean field games: a) Games where agents belong to\npredefined types that are known a priori and b) Games where the type of each\nagent is unknown and therefore must be learned based on observations. We\nintroduce new algorithms for each type of game and demonstrate their superior\nperformance over state of the art algorithms that assume that all agents belong\nto the same type and other baseline algorithms in the MAgent framework.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:58:58 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 13:22:40 GMT"}, {"version": "v3", "created": "Mon, 9 Mar 2020 14:38:52 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 14:02:16 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Subramanian", "Sriram Ganapathi", ""], ["Poupart", "Pascal", ""], ["Taylor", "Matthew E.", ""], ["Hegde", "Nidhi", ""]]}, {"id": "2002.02515", "submitter": "Fenglei Fan", "authors": "Feng-Lei Fan, Rongjie Lai, Ge Wang", "title": "Quasi-Equivalence of Width and Depth of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classic studies proved that wide networks allow universal\napproximation, recent research and successes of deep learning demonstrate the\npower of the network depth. Based on a symmetric consideration, we investigate\nif the design of artificial neural networks should have a directional\npreference, and what the mechanism of interaction is between the width and\ndepth of a network. We address this fundamental question by establishing a\nquasi-equivalence between the width and depth of ReLU networks. Specifically,\nwe formulate a transformation from an arbitrary ReLU network to a wide network\nand a deep network for either regression or classification so that an\nessentially same capability of the original network can be implemented. That\nis, a deep regression/classification ReLU network has a wide equivalent, and\nvice versa, subject to an arbitrarily small error. Interestingly, the\nquasi-equivalence between wide and deep classification ReLU networks is a\ndata-driven version of the De Morgan law.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:17:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 21:40:03 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 13:08:47 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 01:50:47 GMT"}, {"version": "v5", "created": "Sun, 4 Oct 2020 21:16:03 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Fan", "Feng-Lei", ""], ["Lai", "Rongjie", ""], ["Wang", "Ge", ""]]}, {"id": "2002.02518", "submitter": "Jack Parker-Holder", "authors": "Jack Parker-Holder and Vu Nguyen and Stephen Roberts", "title": "Provably Efficient Online Hyperparameter Optimization with\n  Population-Based Bandits", "comments": "Camera-ready version, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the recent triumphs in machine learning are dependent on well-tuned\nhyperparameters. This is particularly prominent in reinforcement learning (RL)\nwhere a small change in the configuration can lead to failure. Despite the\nimportance of tuning hyperparameters, it remains expensive and is often done in\na naive and laborious way. A recent solution to this problem is Population\nBased Training (PBT) which updates both weights and hyperparameters in a single\ntraining run of a population of agents. PBT has been shown to be particularly\neffective in RL, leading to widespread use in the field. However, PBT lacks\ntheoretical guarantees since it relies on random heuristics to explore the\nhyperparameter space. This inefficiency means it typically requires vast\ncomputational resources, which is prohibitive for many small and medium sized\nlabs. In this work, we introduce the first provably efficient PBT-style\nalgorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to\nguide the search in an efficient way, making it possible to discover high\nperforming hyperparameter configurations with far fewer agents than typically\nrequired by PBT. We show in a series of RL experiments that PB2 is able to\nachieve high performance with a modest computational budget.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:27:04 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:34:18 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 09:18:31 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 17:12:31 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Parker-Holder", "Jack", ""], ["Nguyen", "Vu", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02521", "submitter": "Benjamin Stevens", "authors": "Ben Stevens, Tim Colonius", "title": "Enhancement of shock-capturing methods via machine learning", "comments": "10 pages, 11 figures. Under review for TCFD", "journal-ref": null, "doi": "10.1007/s00162-020-00531-1", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NA cs.NE math.NA physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has been used to create data-driven\nsolutions to problems for which an algorithmic solution is intractable, as well\nas fine-tuning existing algorithms. This research applies machine learning to\nthe development of an improved finite-volume method for simulating PDEs with\ndiscontinuous solutions. Shock capturing methods make use of nonlinear\nswitching functions that are not guaranteed to be optimal. Because data can be\nused to learn nonlinear relationships, we train a neural network to improve the\nresults of a fifth-order WENO method. We post-process the outputs of the neural\nnetwork to guarantee that the method is consistent. The training data consists\nof the exact mapping between cell averages and interpolated values for a set of\nintegrable functions that represent waveforms we would expect to see while\nsimulating a PDE. We demonstrate our method on linear advection of a\ndiscontinuous function, the inviscid Burgers' equation, and the 1-D Euler\nequations. For the latter, we examine the Shu-Osher model problem for\nturbulence-shockwave interactions. We find that our method outperforms WENO in\nsimulations where the numerical solution becomes overly diffused due to\nnumerical viscosity.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 21:51:39 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Stevens", "Ben", ""], ["Colonius", "Tim", ""]]}, {"id": "2002.02525", "submitter": "Seth Strimas-Mackey", "authors": "Florentina Bunea, Seth Strimas-Mackey, Marten Wegkamp", "title": "Interpolating Predictors in High-Dimensional Factor Regression", "comments": "47 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies finite-sample properties of the risk of the minimum-norm\ninterpolating predictor in high-dimensional regression models. If the effective\nrank of the covariance matrix $\\Sigma$ of the $p$ regression features is much\nlarger than the sample size $n$, we show that the min-norm interpolating\npredictor is not desirable, as its risk approaches the risk of trivially\npredicting the response by 0. However, our detailed finite-sample analysis\nreveals, surprisingly, that this behavior is not present when the regression\nresponse and the features are {\\it jointly} low-dimensional, following a widely\nused factor regression model. Within this popular model class, and when the\neffective rank of $\\Sigma$ is smaller than $n$, while still allowing for $p \\gg\nn$, both the bias and the variance terms of the excess risk can be controlled,\nand the risk of the minimum-norm interpolating predictor approaches optimal\nbenchmarks. Moreover, through a detailed analysis of the bias term, we exhibit\nmodel classes under which our upper bound on the excess risk approaches zero,\nwhile the corresponding upper bound in the recent work arXiv:1906.11300\ndiverges. Furthermore, we show that the minimum-norm interpolating predictor\nanalyzed under the factor regression model, despite being model-agnostic and\ndevoid of tuning parameters, can have similar risk to predictors based on\nprincipal components regression and ridge regression, and can improve over\nLASSO based predictors, in the high-dimensional regime.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:08:36 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 16:52:54 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 22:48:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Bunea", "Florentina", ""], ["Strimas-Mackey", "Seth", ""], ["Wegkamp", "Marten", ""]]}, {"id": "2002.02527", "submitter": "Antoine Delplace", "authors": "Antoine Delplace", "title": "Synthetic Magnetic Resonance Images with Generative Adversarial Networks", "comments": "4 pages, 1 figure, UQ Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is essential for medical research to increase the size of\ntraining datasets and achieve better results. In this work, we experiment three\nGAN architectures with different loss functions to generate new brain MRIs. The\nresults show the importance of hyperparameter tuning and the use of mini-batch\nsimilarity layer in the Discriminator and gradient penalty in the loss function\nto achieve convergence with high quality and realism. Moreover, huge\ncomputation time is needed to generate indistinguishable images from the\noriginal dataset.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 11:00:32 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Delplace", "Antoine", ""]]}, {"id": "2002.02528", "submitter": "Zhen Chen", "authors": "Zhen Chen and Dongbin Xiu", "title": "On generalized residue network for deep learning of unknown dynamical\n  systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2021.110362", "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general numerical approach for learning unknown dynamical\nsystems using deep neural networks (DNNs). Our method is built upon recent\nstudies that identified the residue network (ResNet) as an effective neural\nnetwork structure. In this paper, we present a generalized ResNet framework and\nbroadly define residue as the discrepancy between observation data and\nprediction made by another model, which can be an existing coarse model or\nreduced-order model. In this case, the generalized ResNet serves as a model\ncorrection to the existing model and recovers the unresolved dynamics. When an\nexisting coarse model is not available, we present numerical strategies for\nfast creation of coarse models, to be used in conjunction with the generalized\nResNet. These coarse models are constructed using the same data set and thus do\nnot require additional resources. The generalized ResNet is capable of learning\nthe underlying unknown equations and producing predictions with accuracy higher\nthan the standard ResNet structure. This is demonstrated via several numerical\nexamples, including long-term prediction of a chaotic system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:50:22 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chen", "Zhen", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2002.02530", "submitter": "Kevin McCloskey", "authors": "Kevin McCloskey, Eric A. Sigel, Steven Kearnes, Ling Xue, Xia Tian,\n  Dennis Moccia, Diana Gikunju, Sana Bazzaz, Betty Chan, Matthew A. Clark, John\n  W. Cuozzo, Marie-Aude Gui\\'e, John P. Guilinger, Christelle Huguet,\n  Christopher D. Hupp, Anthony D. Keefe, Christopher J. Mulhern, Ying Zhang,\n  and Patrick Riley", "title": "Machine learning on DNA-encoded libraries: A new paradigm for\n  hit-finding", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jmedchem.0c00452", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNA-encoded small molecule libraries (DELs) have enabled discovery of novel\ninhibitors for many distinct protein targets of therapeutic value through\nscreening of libraries with up to billions of unique small molecules. We\ndemonstrate a new approach applying machine learning to DEL selection data by\nidentifying active molecules from a large commercial collection and a virtual\nlibrary of easily synthesizable compounds. We train models using only DEL\nselection data and apply automated or automatable filters with chemist review\nrestricted to the removal of molecules with potential for instability or\nreactivity. We validate this approach with a large prospective study (nearly\n2000 compounds tested) across three diverse protein targets: sEH (a hydrolase),\nER{\\alpha} (a nuclear receptor), and c-KIT (a kinase). The approach is\neffective, with an overall hit rate of {\\sim}30% at 30 {\\textmu}M and discovery\nof potent compounds (IC50 <10 nM) for every target. The model makes useful\npredictions even for molecules dissimilar to the original DEL and the compounds\nidentified are diverse, predominantly drug-like, and different from known\nligands. Collectively, the quality and quantity of DEL selection data; the\npower of modern machine learning methods; and access to large, inexpensive,\ncommercially-available libraries creates a powerful new approach for hit\nfinding.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 19:31:23 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["McCloskey", "Kevin", ""], ["Sigel", "Eric A.", ""], ["Kearnes", "Steven", ""], ["Xue", "Ling", ""], ["Tian", "Xia", ""], ["Moccia", "Dennis", ""], ["Gikunju", "Diana", ""], ["Bazzaz", "Sana", ""], ["Chan", "Betty", ""], ["Clark", "Matthew A.", ""], ["Cuozzo", "John W.", ""], ["Gui\u00e9", "Marie-Aude", ""], ["Guilinger", "John P.", ""], ["Huguet", "Christelle", ""], ["Hupp", "Christopher D.", ""], ["Keefe", "Anthony D.", ""], ["Mulhern", "Christopher J.", ""], ["Zhang", "Ying", ""], ["Riley", "Patrick", ""]]}, {"id": "2002.02533", "submitter": "Burak \\c{C}akmak", "authors": "Manfred Opper and Burak \\c{C}akmak", "title": "Understanding the dynamics of message passing algorithms: a free\n  probability heuristics", "comments": "11 pages, 2 figures. Presented at the conference \"Random Matrix\n  Theory: Applications in the Information Era'' 2019 Krak\\'{o}w", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use freeness assumptions of random matrix theory to analyze the dynamical\nbehavior of inference algorithms for probabilistic models with dense coupling\nmatrices in the limit of large systems. For a toy Ising model, we are able to\nrecover previous results such as the property of vanishing effective memories\nand the analytical convergence rate of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 19:50:31 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Opper", "Manfred", ""], ["\u00c7akmak", "Burak", ""]]}, {"id": "2002.02534", "submitter": "Sioni Summers", "authors": "Sioni Summers, Giuseppe Di Guglielmo, Javier Duarte, Philip Harris,\n  Duc Hoang, Sergo Jindariani, Edward Kreinar, Vladimir Loncar, Jennifer\n  Ngadiuba, Maurizio Pierini, Dylan Rankin, Nhan Tran, Zhenbin Wu", "title": "Fast inference of Boosted Decision Trees in FPGAs for particle physics", "comments": null, "journal-ref": "JINST 15 P05026 (2020)", "doi": "10.1088/1748-0221/15/05/p05026", "report-no": null, "categories": "physics.comp-ph astro-ph.IM cs.LG hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the implementation of Boosted Decision Trees in the hls4ml\nlibrary, which allows the translation of a trained model into FPGA firmware\nthrough an automated conversion process. Thanks to its fully on-chip\nimplementation, hls4ml performs inference of Boosted Decision Tree models with\nextremely low latency. With a typical latency less than 100 ns, this solution\nis suitable for FPGA-based real-time processing, such as in the Level-1 Trigger\nsystem of a collider experiment. These developments open up prospects for\nphysicists to deploy BDTs in FPGAs for identifying the origin of jets, better\nreconstructing the energies of muons, and enabling better selection of rare\nsignal processes.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 12:55:28 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:47:20 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Summers", "Sioni", ""], ["Di Guglielmo", "Giuseppe", ""], ["Duarte", "Javier", ""], ["Harris", "Philip", ""], ["Hoang", "Duc", ""], ["Jindariani", "Sergo", ""], ["Kreinar", "Edward", ""], ["Loncar", "Vladimir", ""], ["Ngadiuba", "Jennifer", ""], ["Pierini", "Maurizio", ""], ["Rankin", "Dylan", ""], ["Tran", "Nhan", ""], ["Wu", "Zhenbin", ""]]}, {"id": "2002.02547", "submitter": "Didrik Nielsen", "authors": "Didrik Nielsen, Ole Winther", "title": "Closing the Dequantization Gap: PixelCNN as a Single-Layer Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow models have recently made great progress at modeling ordinal discrete\ndata such as images and audio. Due to the continuous nature of flow models,\ndequantization is typically applied when using them for such discrete data,\nresulting in lower bound estimates of the likelihood. In this paper, we\nintroduce subset flows, a class of flows that can tractably transform finite\nvolumes and thus allow exact computation of likelihoods for discrete data.\nBased on subset flows, we identify ordinal discrete autoregressive models,\nincluding WaveNets, PixelCNNs and Transformers, as single-layer flows. We use\nthe flow formulation to compare models trained and evaluated with either the\nexact likelihood or its dequantization lower bound. Finally, we study\nmultilayer flows composed of PixelCNNs and non-autoregressive coupling layers\nand demonstrate state-of-the-art results on CIFAR-10 for flow models trained\nwith dequantization.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 22:58:51 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:04:08 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 17:05:37 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Nielsen", "Didrik", ""], ["Winther", "Ole", ""]]}, {"id": "2002.02557", "submitter": "Amila Silva", "authors": "Amila Silva and Pei-Chi Lo and Ee-Peng Lim", "title": "JPLink: On Linking Jobs to Vocational Interest Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linking job seekers with relevant jobs requires matching based on not only\nskills, but also personality types. Although the Holland Code also known as\nRIASEC has frequently been used to group people by their suitability for six\ndifferent categories of occupations, the RIASEC category labels of individual\njobs are often not found in job posts. This is attributed to significant manual\nefforts required for assigning job posts with RIASEC labels. To cope with\nassigning massive number of jobs with RIASEC labels, we propose JPLink, a\nmachine learning approach using the text content in job titles and job\ndescriptions. JPLink exploits domain knowledge available in an\noccupation-specific knowledge base known as O*NET to improve feature\nrepresentation of job posts. To incorporate relative ranking of RIASEC labels\nof each job, JPLink proposes a listwise loss function inspired by learning to\nrank. Both our quantitative and qualitative evaluations show that JPLink\noutperforms conventional baselines. We conduct an error analysis on JPLink's\npredictions to show that it can uncover label errors in existing job posts.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 23:56:46 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Silva", "Amila", ""], ["Lo", "Pei-Chi", ""], ["Lim", "Ee-Peng", ""]]}, {"id": "2002.02561", "submitter": "Blake Bordelon", "authors": "Blake Bordelon, Abdulkadir Canatar, Cengiz Pehlevan", "title": "Spectrum Dependent Learning Curves in Kernel Regression and Wide Neural\n  Networks", "comments": "ICML 2020 Update: Updated section on asymptotics generalization error\n  for power law spectra, finding agreement with Spigler, Geiger, Wyart 2019\n  arXiv:1905.10843. Added a section on Discrete measures and an MNIST\n  Experiment. Eigenvalue problem can be approximated by Kernel PCA. Typo fixed\n  on 2/25/2021", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:1024-1034, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive analytical expressions for the generalization performance of kernel\nregression as a function of the number of training samples using theoretical\nmethods from Gaussian processes and statistical physics. Our expressions apply\nto wide neural networks due to an equivalence between training them and kernel\nregression with the Neural Tangent Kernel (NTK). By computing the decomposition\nof the total generalization error due to different spectral components of the\nkernel, we identify a new spectral principle: as the size of the training set\ngrows, kernel machines and neural networks fit successively higher spectral\nmodes of the target function. When data are sampled from a uniform distribution\non a high-dimensional hypersphere, dot product kernels, including NTK, exhibit\nlearning stages where different frequency modes of the target function are\nlearned. We verify our theory with simulations on synthetic data and MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:03:40 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 02:38:09 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 21:32:34 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 00:06:11 GMT"}, {"version": "v5", "created": "Thu, 13 Aug 2020 21:05:27 GMT"}, {"version": "v6", "created": "Thu, 27 Aug 2020 17:13:23 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 18:40:10 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Bordelon", "Blake", ""], ["Canatar", "Abdulkadir", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2002.02568", "submitter": "Wei Li", "authors": "Wei Li (1), Amin Kiaghadi (1), Clint N. Dawson (1) ((1) Oden Institute\n  for Computational Engineering and Sciences, The University of Texas at\n  Austin, Austin, TX)", "title": "High Temporal Resolution Rainfall Runoff Modelling Using\n  Long-Short-Term-Memory (LSTM) Networks", "comments": null, "journal-ref": null, "doi": "10.1007/s00521-020-05010-6", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient models for rainfall runoff (RR) simulations are\ncrucial for flood risk management. Most rainfall models in use today are\nprocess-driven; i.e. they solve either simplified empirical formulas or some\nvariation of the St. Venant (shallow water) equations. With the development of\nmachine-learning techniques, we may now be able to emulate rainfall models\nusing, for example, neural networks. In this study, a data-driven RR model\nusing a sequence-to-sequence Long-short-Term-Memory (LSTM) network was\nconstructed. The model was tested for a watershed in Houston, TX, known for\nsevere flood events. The LSTM network's capability in learning long-term\ndependencies between the input and output of the network allowed modeling RR\nwith high resolution in time (15 minutes). Using 10-years precipitation from\n153 rainfall gages and river channel discharge data (more than 5.3 million data\npoints), and by designing several numerical tests the developed model\nperformance in predicting river discharge was tested. The model results were\nalso compared with the output of a process-driven model Gridded Surface\nSubsurface Hydrologic Analysis (GSSHA). Moreover, physical consistency of the\nLSTM model was explored. The model results showed that the LSTM model was able\nto efficiently predict discharge and achieve good model performance. When\ncompared to GSSHA, the data-driven model was more efficient and robust in terms\nof prediction and calibration. Interestingly, the performance of the LSTM model\nimproved (test Nash-Sutcliffe model efficiency from 0.666 to 0.942) when a\nselected subset of rainfall gages based on the model performance, were used as\ninput instead of all rainfall gages.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:38:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 01:21:07 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Li", "Wei", ""], ["Kiaghadi", "Amin", ""], ["Dawson", "Clint N.", ""]]}, {"id": "2002.02572", "submitter": "Enmao Diao", "authors": "Enmao Diao, Jie Ding, Vahid Tarokh", "title": "Multimodal Controller for Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-conditional generative models are crucial tools for data generation\nfrom user-specified class labels. Existing approaches for class-conditional\ngenerative models require nontrivial modifications of backbone generative\narchitectures to model conditional information fed into the model. This paper\nintroduces a plug-and-play module named `multimodal controller' to generate\nmultimodal data without introducing additional learning parameters. In the\nabsence of the controllers, our model reduces to non-conditional generative\nmodels. We test the efficacy of multimodal controllers on CIFAR10, COIL100, and\nOmniglot benchmark datasets. We demonstrate that multimodal controlled\ngenerative models (including VAE, PixelCNN, Glow, and GAN) can generate\nclass-conditional images of significantly better quality when compared with the\nstate-of-the-art conditional generative models. Moreover, we show that\nmultimodal controlled models can also create novel modalities of images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:55:10 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 17:24:54 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 15:04:30 GMT"}, {"version": "v4", "created": "Fri, 11 Sep 2020 22:44:57 GMT"}, {"version": "v5", "created": "Fri, 16 Oct 2020 14:43:11 GMT"}, {"version": "v6", "created": "Mon, 29 Mar 2021 00:08:28 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Diao", "Enmao", ""], ["Ding", "Jie", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2002.02574", "submitter": "Gautam Goel", "authors": "Gautam Goel, Babak Hassibi", "title": "The Power of Linear Controllers in LQR Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Linear Quadratic Regulator (LQR) framework considers the problem of\nregulating a linear dynamical system perturbed by environmental noise. We\ncompute the policy regret between three distinct control policies: i) the\noptimal online policy, whose linear structure is given by the Ricatti\nequations; ii) the optimal offline linear policy, which is the best linear\nstate feedback policy given the noise sequence; and iii) the optimal offline\npolicy, which selects the globally optimal control actions given the noise\nsequence. We fully characterize the optimal offline policy and show that it has\na recursive form in terms of the optimal online policy and future disturbances.\nWe also show that cost of the optimal offline linear policy converges to the\ncost of the optimal online policy as the time horizon grows large, and\nconsequently the optimal offline linear policy incurs linear regret relative to\nthe optimal offline policy, even in the optimistic setting where the noise is\ndrawn i.i.d from a known distribution. Although we focus on the setting where\nthe noise is stochastic, our results also imply new lower bounds on the policy\nregret achievable when the noise is chosen by an adaptive adversary.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 00:58:49 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Goel", "Gautam", ""], ["Hassibi", "Babak", ""]]}, {"id": "2002.02581", "submitter": "Lei Lei", "authors": "Lei Lei, Yue Tan, Glenn Dahlenburg, Wei Xiang, Kan Zheng", "title": "Dynamic Energy Dispatch Based on Deep Reinforcement Learning in\n  IoT-Driven Smart Isolated Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microgrids (MGs) are small, local power grids that can operate independently\nfrom the larger utility grid. Combined with the Internet of Things (IoT), a\nsmart MG can leverage the sensory data and machine learning techniques for\nintelligent energy management. This paper focuses on deep reinforcement\nlearning (DRL)-based energy dispatch for IoT-driven smart isolated MGs with\ndiesel generators (DGs), photovoltaic (PV) panels, and a battery. A\nfinite-horizon Partial Observable Markov Decision Process (POMDP) model is\nformulated and solved by learning from historical data to capture the\nuncertainty in future electricity consumption and renewable power generation.\nIn order to deal with the instability problem of DRL algorithms and unique\ncharacteristics of finite-horizon models, two novel DRL algorithms, namely,\nfinite-horizon deep deterministic policy gradient (FH-DDPG) and finite-horizon\nrecurrent deterministic policy gradient (FH-RDPG), are proposed to derive\nenergy dispatch policies with and without fully observable state information. A\ncase study using real isolated MG data is performed, where the performance of\nthe proposed algorithms are compared with the other baseline DRL and non-DRL\nalgorithms. Moreover, the impact of uncertainties on MG performance is\ndecoupled into two levels and evaluated respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:44:18 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 15:50:04 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lei", "Lei", ""], ["Tan", "Yue", ""], ["Dahlenburg", "Glenn", ""], ["Xiang", "Wei", ""], ["Zheng", "Kan", ""]]}, {"id": "2002.02582", "submitter": "Mohammad Hashir", "authors": "Mohammad Hashir, Hadrien Bertrand and Joseph Paul Cohen", "title": "Quantifying the Value of Lateral Views in Deep Learning for Chest X-rays", "comments": "Under review at MIDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models in chest X-ray prediction utilize the\nposteroanterior (PA) view due to the lack of other views available. PadChest is\na large-scale chest X-ray dataset that has almost 200 labels and multiple views\navailable. In this work, we use PadChest to explore multiple approaches to\nmerging the PA and lateral views for predicting the radiological labels\nassociated with the X-ray image. We find that different methods of merging the\nmodel utilize the lateral view differently. We also find that including the\nlateral view increases performance for 32 labels in the dataset, while being\nneutral for the others. The increase in overall performance is comparable to\nthe one obtained by using only the PA view with twice the amount of patients in\nthe training set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:48:13 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Hashir", "Mohammad", ""], ["Bertrand", "Hadrien", ""], ["Cohen", "Joseph Paul", ""]]}, {"id": "2002.02584", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Adithya M. Devraj, Ana Bu\\v{s}i\\'c, Sean Meyn", "title": "Explicit Mean-Square Error Bounds for Monte-Carlo and Linear Stochastic\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG cs.SY eess.SY math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns error bounds for recursive equations subject to Markovian\ndisturbances. Motivating examples abound within the fields of Markov chain\nMonte Carlo (MCMC) and Reinforcement Learning (RL), and many of these\nalgorithms can be interpreted as special cases of stochastic approximation\n(SA). It is argued that it is not possible in general to obtain a Hoeffding\nbound on the error sequence, even when the underlying Markov chain is\nreversible and geometrically ergodic, such as the M/M/1 queue. This is\nmotivation for the focus on mean square error bounds for parameter estimates.\nIt is shown that mean square error achieves the optimal rate of $O(1/n)$,\nsubject to conditions on the step-size sequence. Moreover, the exact constants\nin the rate are obtained, which is of great value in algorithm design.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:52:21 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Shuhang", ""], ["Devraj", "Adithya M.", ""], ["Bu\u0161i\u0107", "Ana", ""], ["Meyn", "Sean", ""]]}, {"id": "2002.02585", "submitter": "Jing Wang", "authors": "Divinah Nyasaka, Jing Wang, Haron Tinega", "title": "Learning Hyperspectral Feature Extraction and Classification with\n  ResNeXt Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hyperspectral image (HSI) classification is a standard remote sensing\ntask, in which each image pixel is given a label indicating the physical\nland-cover on the earth's surface. The achievements of image semantic\nsegmentation and deep learning approaches on ordinary images have accelerated\nthe research on hyperspectral image classification. Moreover, the utilization\nof both the spectral and spatial cues in hyperspectral images has shown\nimproved classification accuracy in hyperspectral image classification. The use\nof only 3D Convolutional Neural Networks (3D-CNN) to extract both spatial and\nspectral cues from Hyperspectral images results in an explosion of parameters\nhence high computational cost. We propose network architecture called the\nMixedSN that utilizes the 3D convolutions to modeling spectral-spatial\ninformation in the early layers of the architecture and the 2D convolutions at\nthe top layers which majorly deal with semantic abstraction. We constrain our\narchitecture to ResNeXt block because of their performance and simplicity. Our\nmodel drastically reduced the number of parameters and achieved comparable\nclassification performance with state-of-the-art methods on Indian Pine (IP)\nscene dataset, Pavia University scene (PU) dataset, Salinas (SA) Scene dataset,\nand Botswana (BW) dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:54:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Nyasaka", "Divinah", ""], ["Wang", "Jing", ""], ["Tinega", "Haron", ""]]}, {"id": "2002.02589", "submitter": "Shoudong Han", "authors": "Ziqing Yang, Shoudong Han and Jun Zhao", "title": "Poisson Kernel Avoiding Self-Smoothing in Graph Convolutional Networks", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) is now an effective tool to deal with\nnon-Euclidean data, such as social networks in social behavior analysis,\nmolecular structure analysis in the field of chemistry, and skeleton-based\naction recognition. Graph convolutional kernel is one of the most significant\nfactors in GCN to extract nodes' feature, and some improvements of it have\nreached promising performance theoretically and experimentally. However, there\nis limited research about how exactly different data types and graph structures\ninfluence the performance of these kernels. Most existing methods used an\nadaptive convolutional kernel to deal with a given graph structure, which still\nnot reveals the internal reasons. In this paper, we started from theoretical\nanalysis of the spectral graph and studied the properties of existing graph\nconvolutional kernels. While taking some designed datasets with specific\nparameters into consideration, we revealed the self-smoothing phenomenon of\nconvolutional kernels. After that, we proposed the Poisson kernel that can\navoid self-smoothing without training any adaptive kernel. Experimental results\ndemonstrate that our Poisson kernel not only works well on the benchmark\ndataset where state-of-the-art methods work fine, but also is evidently\nsuperior to them in synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 02:25:11 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 10:03:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yang", "Ziqing", ""], ["Han", "Shoudong", ""], ["Zhao", "Jun", ""]]}, {"id": "2002.02600", "submitter": "Jiequn Han", "authors": "Jiequn Han, Jianfeng Lu, Mo Zhou", "title": "Solving high-dimensional eigenvalue problems using deep neural networks:\n  A diffusion Monte Carlo like approach", "comments": "18 pages, 6 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109792", "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method to solve eigenvalue problems for linear and\nsemilinear second order differential operators in high dimensions based on deep\nneural networks. The eigenvalue problem is reformulated as a fixed point\nproblem of the semigroup flow induced by the operator, whose solution can be\nrepresented by Feynman-Kac formula in terms of forward-backward stochastic\ndifferential equations. The method shares a similar spirit with diffusion Monte\nCarlo but augments a direct approximation to the eigenfunction through\nneural-network ansatz. The criterion of fixed point provides a natural loss\nfunction to search for parameters via optimization. Our approach is able to\nprovide accurate eigenvalue and eigenfunction approximations in several\nnumerical examples, including Fokker-Planck operator and the linear and\nnonlinear Schr\\\"odinger operators in high dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:08:31 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 03:34:03 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Han", "Jiequn", ""], ["Lu", "Jianfeng", ""], ["Zhou", "Mo", ""]]}, {"id": "2002.02601", "submitter": "Eric Lock", "authors": "Eric F. Lock, Jun Young Park, and Katherine A. Hoadley", "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer\n  analysis", "comments": "46 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several modern applications require the integration of multiple large data\nmatrices that have shared rows and/or columns. For example, cancer studies that\nintegrate multiple omics platforms across multiple types of cancer, pan-omics\npan-cancer analysis, have extended our knowledge of molecular heterogenity\nbeyond what was observed in single tumor and single platform studies. However,\nthese studies have been limited by available statistical methodology. We\npropose a flexible approach to the simultaneous factorization and decomposition\nof variation across such bidimensionally linked matrices, BIDIFAC+. This\ndecomposes variation into a series of low-rank components that may be shared\nacross any number of row sets (e.g., omics platforms) or column sets (e.g.,\ncancer types). This builds on a growing literature for the factorization and\ndecomposition of linked matrices, which has primarily focused on multiple\nmatrices that are linked in one dimension (rows or columns) only. Our objective\nfunction extends nuclear norm penalization, is motivated by random matrix\ntheory, gives an identifiable decomposition under relatively mild conditions,\nand can be shown to give the mode of a Bayesian posterior distribution. We\napply BIDIFAC+ to pan-omics pan-cancer data from TCGA, identifying shared and\nspecific modes of variability across 4 different omics platforms and 29\ndifferent cancer types.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:11:44 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Lock", "Eric F.", ""], ["Park", "Jun Young", ""], ["Hoadley", "Katherine A.", ""]]}, {"id": "2002.02610", "submitter": "Marianna Pensky", "authors": "Majid Noroozi and Marianna Pensky", "title": "The Hierarchy of Block Models", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist various types of network block models such as the Stochastic\nBlock Model (SBM), the Degree Corrected Block Model (DCBM), and the Popularity\nAdjusted Block Model (PABM). While this leads to a variety of choices, the\nblock models do not have a nested structure. In addition, there is a\nsubstantial jump in the number of parameters from the DCBM to the PABM. The\nobjective of this paper is formulation of a hierarchy of block model which does\nnot rely on arbitrary identifiability conditions. We propose a Nested Block\nModel (NBM) that treats the SBM, the DCBM and the PABM as its particular cases\nwith specific parameter values, and, in addition, allows a multitude of\nversions that are more complicated than DCBM but have fewer unknown parameters\nthan the PABM. The latter allows one to carry out clustering and estimation\nwithout preliminary testing, to see which block model is really true.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 03:47:15 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 22:11:59 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Noroozi", "Majid", ""], ["Pensky", "Marianna", ""]]}, {"id": "2002.02618", "submitter": "Remmy Zen", "authors": "Remmy Zen, Long My, Ryan Tan, Frederic Hebert, Mario Gattobigio,\n  Christian Miniatura, Dario Poletti, Stephane Bressan", "title": "Finding Quantum Critical Points with Neural-Network Quantum States", "comments": "19 pages, 12 figures, extended version of an accepted paper at the\n  24th European Conference on Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the precise location of quantum critical points is of particular\nimportance to characterise quantum many-body systems at zero temperature.\nHowever, quantum many-body systems are notoriously hard to study because the\ndimension of their Hilbert space increases exponentially with their size.\nRecently, machine learning tools known as neural-network quantum states have\nbeen shown to effectively and efficiently simulate quantum many-body systems.\nWe present an approach to finding the quantum critical points of the quantum\nIsing model using neural-network quantum states, analytically constructed\ninnate restricted Boltzmann machines, transfer learning and unsupervised\nlearning. We validate the approach and evaluate its efficiency and\neffectiveness in comparison with other traditional approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 04:39:09 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Zen", "Remmy", ""], ["My", "Long", ""], ["Tan", "Ryan", ""], ["Hebert", "Frederic", ""], ["Gattobigio", "Mario", ""], ["Miniatura", "Christian", ""], ["Poletti", "Dario", ""], ["Bressan", "Stephane", ""]]}, {"id": "2002.02620", "submitter": "Jarrad Courts", "authors": "Jarrad Courts, Adrian Wills and Thomas B. Sch\\\"on", "title": "Gaussian Variational State Estimation for Nonlinear State-Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of state estimation, in the context of both\nfiltering and smoothing, for nonlinear state-space models is considered. Due to\nthe nonlinear nature of the models, the state estimation problem is generally\nintractable as it involves integrals of general nonlinear functions and the\nfiltered and smoothed state distributions lack closed-form solutions. As such,\nit is common to approximate the state estimation problem. In this paper, we\ndevelop an assumed Gaussian solution based on variational inference, which\noffers the key advantage of a flexible, but principled, mechanism for\napproximating the required distributions. Our main contribution lies in a new\nformulation of the state estimation problem as an optimisation problem, which\ncan then be solved using standard optimisation routines that employ exact\nfirst- and second-order derivatives. The resulting state estimation approach\ninvolves a minimal number of assumptions and applies directly to nonlinear\nsystems with both Gaussian and non-Gaussian probabilistic models. The\nperformance of our approach is demonstrated on several examples; a challenging\nscalar system, a model of a simple robotic system, and a target tracking\nproblem using a von Mises-Fisher distribution and outperforms alternative\nassumed Gaussian approaches to state estimation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 04:46:14 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 03:43:29 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 05:21:20 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Courts", "Jarrad", ""], ["Wills", "Adrian", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "2002.02644", "submitter": "Tim Leathart", "authors": "Tim Leathart and Maksymilian Polaczuk", "title": "Temporal Probability Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, accurate class probability estimates are required, but\nmany types of models produce poor quality probability estimates despite\nachieving acceptable classification accuracy. Even though probability\ncalibration has been a hot topic of research in recent times, the majority of\nthis has investigated non-sequential data. In this paper, we consider\ncalibrating models that produce class probability estimates from sequences of\ndata, focusing on the case where predictions are obtained from incomplete\nsequences. We show that traditional calibration techniques are not sufficiently\nexpressive for this task, and propose methods that adapt calibration schemes\ndepending on the length of an input sequence. Experimental evaluation shows\nthat the proposed methods are often substantially more effective at calibrating\nprobability estimates from modern sequential architectures for incomplete\nsequences across a range of application domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 06:59:05 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 02:43:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Leathart", "Tim", ""], ["Polaczuk", "Maksymilian", ""]]}, {"id": "2002.02645", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Arjun Balasubramanian, Shivaram Venkataraman, Aditya\n  Akella", "title": "Accelerating Deep Learning Inference via Freezing", "comments": "11th USENIX Workshop on Hot Topics in Cloud Computing, HotCloud 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, Deep Neural Networks (DNNs) have become ubiquitous\nowing to their high accuracy on real-world tasks. However, this increase in\naccuracy comes at the cost of computationally expensive models leading to\nhigher prediction latencies. Prior efforts to reduce this latency such as\nquantization, model distillation, and any-time prediction models typically\ntrade-off accuracy for performance. In this work, we observe that caching\nintermediate layer outputs can help us avoid running all the layers of a DNN\nfor a sizeable fraction of inference requests. We find that this can\npotentially reduce the number of effective layers by half for 91.58% of\nCIFAR-10 requests run on ResNet-18. We present Freeze Inference, a system that\nintroduces approximate caching at each intermediate layer and we discuss\ntechniques to reduce the cache size and improve the cache hit rate. Finally, we\ndiscuss some of the open research challenges in realizing such a design.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:03:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kumar", "Adarsh", ""], ["Balasubramanian", "Arjun", ""], ["Venkataraman", "Shivaram", ""], ["Akella", "Aditya", ""]]}, {"id": "2002.02651", "submitter": "Alexandros Stergiou MSc", "authors": "Alexandros Stergiou, Ronald Poppe, and Remco C. Veltkamp", "title": "Learning Class Regularized Features for Action Recognition", "comments": null, "journal-ref": null, "doi": "10.3390/app10186241", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training Deep Convolutional Neural Networks (CNNs) is based on the notion of\nusing multiple kernels and non-linearities in their subsequent activations to\nextract useful features. The kernels are used as general feature extractors\nwithout specific correspondence to the target class. As a result, the extracted\nfeatures do not correspond to specific classes. Subtle differences between\nsimilar classes are modeled in the same way as large differences between\ndissimilar classes. To overcome the class-agnostic use of kernels in CNNs, we\nintroduce a novel method named Class Regularization that performs class-based\nregularization of layer activations. We demonstrate that this not only improves\nfeature search during training, but also allows an explicit assignment of\nfeatures per class during each stage of the feature extraction process. We show\nthat using Class Regularization blocks in state-of-the-art CNN architectures\nfor action recognition leads to systematic improvement gains of 1.8%, 1.2% and\n1.4% on the Kinetics, UCF-101 and HMDB-51 datasets, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:27:49 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Stergiou", "Alexandros", ""], ["Poppe", "Ronald", ""], ["Veltkamp", "Remco C.", ""]]}, {"id": "2002.02655", "submitter": "Jakub Swiatkowski", "authors": "Jakub Swiatkowski, Kevin Roth, Bastiaan S. Veeling, Linh Tran, Joshua\n  V. Dillon, Jasper Snoek, Stephan Mandt, Tim Salimans, Rodolphe Jenatton,\n  Sebastian Nowozin", "title": "The k-tied Normal Distribution: A Compact Parameterization of Gaussian\n  Mean Field Posteriors in Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayesian Inference is a popular methodology for approximating\nposterior distributions over Bayesian neural network weights. Recent work\ndeveloping this class of methods has explored ever richer parameterizations of\nthe approximate posterior in the hope of improving performance. In contrast,\nhere we share a curious experimental finding that suggests instead restricting\nthe variational distribution to a more compact parameterization. For a variety\nof deep Bayesian neural networks trained using Gaussian mean-field variational\ninference, we find that the posterior standard deviations consistently exhibit\nstrong low-rank structure after convergence. This means that by decomposing\nthese variational parameters into a low-rank factorization, we can make our\nvariational approximation more compact without decreasing the models'\nperformance. Furthermore, we find that such factorized parameterizations\nimprove the signal-to-noise ratio of stochastic gradient estimates of the\nvariational lower bound, resulting in faster convergence.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 07:33:15 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 19:05:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Swiatkowski", "Jakub", ""], ["Roth", "Kevin", ""], ["Veeling", "Bastiaan S.", ""], ["Tran", "Linh", ""], ["Dillon", "Joshua V.", ""], ["Snoek", "Jasper", ""], ["Mandt", "Stephan", ""], ["Salimans", "Tim", ""], ["Jenatton", "Rodolphe", ""], ["Nowozin", "Sebastian", ""]]}, {"id": "2002.02664", "submitter": "Ellen de Mello Koch Ms", "authors": "Ellen de Melllo Koch, Anita de Mello Koch, Nicholas Kastanos, Ling\n  Cheng", "title": "Short sighted deep learning", "comments": null, "journal-ref": "Phys. Rev. E 102, 013307 (2020)", "doi": "10.1103/PhysRevE.102.013307", "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theory explaining how deep learning works is yet to be developed. Previous\nwork suggests that deep learning performs a coarse graining, similar in spirit\nto the renormalization group (RG). This idea has been explored in the setting\nof a local (nearest neighbor interactions) Ising spin lattice. We extend the\ndiscussion to the setting of a long range spin lattice. Markov Chain Monte\nCarlo (MCMC) simulations determine both the critical temperature and scaling\ndimensions of the system. The model is used to train both a single RBM\n(restricted Boltzmann machine) network, as well as a stacked RBM network.\nFollowing earlier Ising model studies, the trained weights of a single layer\nRBM network define a flow of lattice models. In contrast to results for nearest\nneighbor Ising, the RBM flow for the long ranged model does not converge to the\ncorrect values for the spin and energy scaling dimension. Further, correlation\nfunctions between visible and hidden nodes exhibit key differences between the\nstacked RBM and RG flows. The stacked RBM flow appears to move towards low\ntemperatures whereas the RG flow moves towards high temperature. This again\ndiffers from results obtained for nearest neighbor Ising.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:33:07 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Koch", "Ellen de Melllo", ""], ["Koch", "Anita de Mello", ""], ["Kastanos", "Nicholas", ""], ["Cheng", "Ling", ""]]}, {"id": "2002.02667", "submitter": "Fei Ye", "authors": "Fei Ye, Xuxin Cheng, Pin Wang, Ching-Yao Chan, Jiucai Zhang", "title": "Automated Lane Change Strategy using Proximal Policy Optimization-based\n  Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lane-change maneuvers are commonly executed by drivers to follow a certain\nrouting plan, overtake a slower vehicle, adapt to a merging lane ahead, etc.\nHowever, improper lane change behaviors can be a major cause of traffic flow\ndisruptions and even crashes. While many rule-based methods have been proposed\nto solve lane change problems for autonomous driving, they tend to exhibit\nlimited performance due to the uncertainty and complexity of the driving\nenvironment. Machine learning-based methods offer an alternative approach, as\nDeep reinforcement learning (DRL) has shown promising success in many\napplication domains including robotic manipulation, navigation, and playing\nvideo games. However, applying DRL to autonomous driving still faces many\npractical challenges in terms of slow learning rates, sample inefficiency, and\nsafety concerns. In this study, we propose an automated lane change strategy\nusing proximal policy optimization-based deep reinforcement learning, which\nshows great advantages in learning efficiency while still maintaining stable\nperformance. The trained agent is able to learn a smooth, safe, and efficient\ndriving policy to make lane-change decisions (i.e. when and how) in a\nchallenging situation such as dense traffic scenarios. The effectiveness of the\nproposed policy is validated by using metrics of task success rate and\ncollision rate. The simulation results demonstrate the lane change maneuvers\ncan be efficiently learned and executed in a safe, smooth, and efficient\nmanner.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:43:34 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 23:22:20 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Ye", "Fei", ""], ["Cheng", "Xuxin", ""], ["Wang", "Pin", ""], ["Chan", "Ching-Yao", ""], ["Zhang", "Jiucai", ""]]}, {"id": "2002.02669", "submitter": "Ziyi Yang", "authors": "Ziyi Yang, Teng Zhang, Iman Soltani Bozchalooi, Eric Darve", "title": "Memory Augmented Generative Adversarial Networks for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a memory-augmented algorithm for anomaly detection.\nClassical anomaly detection algorithms focus on learning to model and generate\nnormal data, but typically guarantees for detecting anomalous data are weak.\nThe proposed Memory Augmented Generative Adversarial Networks (MEMGAN)\ninteracts with a memory module for both the encoding and generation processes.\nOur algorithm is such that most of the \\textit{encoded} normal data are inside\nthe convex hull of the memory units, while the abnormal data are isolated\noutside. Such a remarkable property leads to good (resp.\\ poor) reconstruction\nfor normal (resp.\\ abnormal) data and therefore provides a strong guarantee for\nanomaly detection. Decoded memory units in MEMGAN are more interpretable and\ndisentangled than previous methods, which further demonstrates the\neffectiveness of the memory mechanism. Experimental results on twenty anomaly\ndetection datasets of CIFAR-10 and MNIST show that MEMGAN demonstrates\nsignificant improvements over previous anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 08:46:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yang", "Ziyi", ""], ["Zhang", "Teng", ""], ["Bozchalooi", "Iman Soltani", ""], ["Darve", "Eric", ""]]}, {"id": "2002.02675", "submitter": "Thomas Lim", "authors": "Idris Kharroubi (LPSM UMR 8001), Thomas Lim (LaMME, ENSIIE), Xavier\n  Warin (EDF)", "title": "Discretization and Machine Learning Approximation of BSDEs with a\n  Constraint on the Gains-Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of backward stochastic differential equations\n(BSDEs for short) with a constraint on the gains process. We first discretize\nthe constraint by applying a so-called facelift operator at times of a grid. We\nshow that this discretely constrained BSDE converges to the continuously\nconstrained one as the mesh grid converges to zero. We then focus on the\napproximation of the discretely constrained BSDE. For that we adopt a machine\nlearning approach. We show that the facelift can be approximated by an\noptimization problem over a class of neural networks under constraints on the\nneural network and its derivative. We then derive an algorithm converging to\nthe discretely constrained BSDE as the number of neurons goes to infinity. We\nend by numerical experiments. Mathematics Subject Classification (2010): 65C30,\n65M75, 60H35, 93E20, 49L25.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:11:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kharroubi", "Idris", "", "LPSM UMR 8001"], ["Lim", "Thomas", "", "LaMME, ENSIIE"], ["Warin", "Xavier", "", "EDF"]]}, {"id": "2002.02693", "submitter": "Jack Parker-Holder", "authors": "Philip Ball and Jack Parker-Holder and Aldo Pacchiano and Krzysztof\n  Choromanski and Stephen Roberts", "title": "Ready Policy One: World Building Through Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-Based Reinforcement Learning (MBRL) offers a promising direction for\nsample efficient learning, often achieving state of the art results for\ncontinuous control tasks. However, many existing MBRL methods rely on combining\ngreedy policies with exploration heuristics, and even those which utilize\nprincipled exploration bonuses construct dual objectives in an ad hoc fashion.\nIn this paper we introduce Ready Policy One (RP1), a framework that views MBRL\nas an active learning problem, where we aim to improve the world model in the\nfewest samples possible. RP1 achieves this by utilizing a hybrid objective\nfunction, which crucially adapts during optimization, allowing the algorithm to\ntrade off reward v.s. exploration at different stages of learning. In addition,\nwe introduce a principled mechanism to terminate sample collection once we have\na rich enough trajectory batch to improve the model. We rigorously evaluate our\nmethod on a variety of continuous control tasks, and demonstrate statistically\nsignificant gains over existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:57:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ball", "Philip", ""], ["Parker-Holder", "Jack", ""], ["Pacchiano", "Aldo", ""], ["Choromanski", "Krzysztof", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.02701", "submitter": "Henry Wilde", "authors": "Henry Wilde, Vincent Knight, Jonathan Gillard", "title": "A novel initialisation based on hospital-resident assignment for the\n  k-modes algorithm", "comments": "23 pages, 11 figures (31 panels)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new way of selecting an initial solution for the\nk-modes algorithm that allows for a notion of mathematical fairness and a\nleverage of the data that the common initialisations from literature do not.\nThe method, which utilises the Hospital-Resident Assignment Problem to find the\nset of initial cluster centroids, is compared with the current initialisations\non both benchmark datasets and a body of newly generated artificial datasets.\nBased on this analysis, the proposed method is shown to outperform the other\ninitialisations in the majority of cases, especially when the number of\nclusters is optimised. In addition, we find that our method outperforms the\nleading established method specifically for low-density data.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:20:49 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Wilde", "Henry", ""], ["Knight", "Vincent", ""], ["Gillard", "Jonathan", ""]]}, {"id": "2002.02702", "submitter": "Martin Trapp", "authors": "Mohamed Tarek, Kai Xu, Martin Trapp, Hong Ge, Zoubin Ghahramani", "title": "DynamicPPL: Stan-like Speed for Dynamic Probabilistic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the preliminary high-level design and features of DynamicPPL.jl, a\nmodular library providing a lightning-fast infrastructure for probabilistic\nprogramming. Besides a computational performance that is often close to or\nbetter than Stan, DynamicPPL provides an intuitive DSL that allows the rapid\ndevelopment of complex dynamic probabilistic programs. Being entirely written\nin Julia, a high-level dynamic programming language for numerical computing,\nDynamicPPL inherits a rich set of features available through the Julia\necosystem. Since DynamicPPL is a modular, stand-alone library, any\nprobabilistic programming system written in Julia, such as Turing.jl, can use\nDynamicPPL to specify models and trace their model parameters. The main\nfeatures of DynamicPPL are: 1) a meta-programming based DSL for specifying\ndynamic models using an intuitive tilde-based notation; 2) a tracing\ndata-structure for tracking RVs in dynamic probabilistic models; 3) a rich\ncontextual dispatch system allowing tailored behaviour during model execution;\nand 4) a user-friendly syntax for probabilistic queries. Finally, we show in a\nvariety of experiments that DynamicPPL, in combination with Turing.jl, achieves\ncomputational performance that is often close to or better than Stan.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:21:49 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Tarek", "Mohamed", ""], ["Xu", "Kai", ""], ["Trapp", "Martin", ""], ["Ge", "Hong", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2002.02705", "submitter": "Christian Haase-Sch\\\"utz", "authors": "Christian Haase-Sch\\\"utz, Rainer Stal, Heinz Hertlein and Bernhard\n  Sick", "title": "Iterative Label Improvement: Robust Training by Confidence Based\n  Filtering and Dataset Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art, high capacity deep neural networks not only require large\namounts of labelled training data, they are also highly susceptible to label\nerrors in this data, typically resulting in large efforts and costs and\ntherefore limiting the applicability of deep learning. To alleviate this issue,\nwe propose a novel meta training and labelling scheme that is able to use\ninexpensive unlabelled data by taking advantage of the generalization power of\ndeep neural networks. We show experimentally that by solely relying on one\nnetwork architecture and our proposed scheme of iterative training and\nprediction steps, both label quality and resulting model accuracy can be\nimproved significantly. Our method achieves state-of-the-art results, while\nbeing architecture agnostic and therefore broadly applicable. Compared to other\nmethods dealing with erroneous labels, our approach does neither require\nanother network to be trained, nor does it necessarily need an additional,\nhighly accurate reference label set. Instead of removing samples from a\nlabelled set, our technique uses additional sensor data without the need for\nmanual labelling. Furthermore, our approach can be used for semi-supervised\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 10:42:26 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:00:16 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 10:13:54 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Haase-Sch\u00fctz", "Christian", ""], ["Stal", "Rainer", ""], ["Hertlein", "Heinz", ""], ["Sick", "Bernhard", ""]]}, {"id": "2002.02717", "submitter": "Dmitry V. Dylov", "authors": "Nikolay Shvetsov and Nazar Buzun and Dmitry V. Dylov", "title": "Unsupervised non-parametric change point detection in quasi-periodic\n  signals", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": "10.1145/3400903.3400917", "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new unsupervised and non-parametric method to detect change\npoints in intricate quasi-periodic signals. The detection relies on optimal\ntransport theory combined with topological analysis and the bootstrap\nprocedure. The algorithm is designed to detect changes in virtually any\nharmonic or a partially harmonic signal and is verified on three different\nsources of physiological data streams. We successfully find abnormal or\nirregular cardiac cycles in the waveforms for the six of the most frequent\ntypes of clinical arrhythmias using a single algorithm. The validation and the\nefficiency of the method are shown both on synthetic and on real time series.\nOur unsupervised approach reaches the level of performance of the supervised\nstate-of-the-art techniques. We provide conceptual justification for the\nefficiency of the method and prove the convergence of the bootstrap procedure\ntheoretically.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 11:24:50 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Shvetsov", "Nikolay", ""], ["Buzun", "Nazar", ""], ["Dylov", "Dmitry V.", ""]]}, {"id": "2002.02730", "submitter": "Thomas Baumhauer", "authors": "Thomas Baumhauer and Pascal Sch\\\"ottle and Matthias Zeppelzauer", "title": "Machine Unlearning: Linear Filtration for Logit-based Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently enacted legislation grants individuals certain rights to decide in\nwhat fashion their personal data may be used, and in particular a \"right to be\nforgotten\". This poses a challenge to machine learning: how to proceed when an\nindividual retracts permission to use data which has been part of the training\nprocess of a model? From this question emerges the field of machine unlearning,\nwhich could be broadly described as the investigation of how to \"delete\ntraining data from models\". Our work complements this direction of research for\nthe specific setting of class-wide deletion requests for classification models\n(e.g. deep neural networks). As a first step, we propose linear filtration as a\nintuitive, computationally efficient sanitization method. Our experiments\ndemonstrate benefits in an adversarial setting over naive deletion schemes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:16:06 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 06:30:40 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Baumhauer", "Thomas", ""], ["Sch\u00f6ttle", "Pascal", ""], ["Zeppelzauer", "Matthias", ""]]}, {"id": "2002.02735", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Bhargavram Mysore, Prachi Singh,\n  Sriram Ganapathy", "title": "LEAP System for SRE19 CTS Challenge -- Improvements and Error Analysis", "comments": "Published In Proc. Odyssey 2020, the Speaker and Language Recognition\n  Workshop. Link to GitHub Implementation:\n  https://github.com/iiscleap/NeuralPlda", "journal-ref": "in Proc. Odyssey 2020 The Speaker and Language Recognition\n  Workshop, 281--288", "doi": "10.21437/Odyssey.2020-40", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NIST Speaker Recognition Evaluation - Conversational Telephone Speech\n(CTS) challenge 2019 was an open evaluation for the task of speaker\nverification in challenging conditions. In this paper, we provide a detailed\naccount of the LEAP SRE system submitted to the CTS challenge focusing on the\nnovel components in the back-end system modeling. All the systems used the\ntime-delay neural network (TDNN) based x-vector embeddings. The x-vector system\nin our SRE19 submission used a large pool of training speakers (about 14k\nspeakers). Following the x-vector extraction, we explored a neural network\napproach to backend score computation that was optimized for a speaker\nverification cost. The system combination of generative and neural PLDA models\nresulted in significant improvements for the SRE evaluation dataset. We also\nfound additional gains for the SRE systems based on score normalization and\ncalibration. Subsequent to the evaluations, we have performed a detailed\nanalysis of the submitted systems. The analysis revealed the incremental gains\nobtained for different training dataset combinations as well as the modeling\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:28:56 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 05:28:06 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Mysore", "Bhargavram", ""], ["Singh", "Prachi", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2002.02737", "submitter": "Mathilde Hotvedt", "authors": "Mathilde Hotvedt, Bjarne Grimstad, Lars Imsland", "title": "Developing a Hybrid Data-Driven, Mechanistic Virtual Flow Meter -- a\n  Case Study", "comments": "6 pages, 6 figures", "journal-ref": "IFAC-PapersOnline 53 (2), 2020", "doi": "10.1016/j.ifacol.2020.12.663", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual flow meters, mathematical models predicting production flow rates in\npetroleum assets, are useful aids in production monitoring and optimization.\nMechanistic models based on first-principles are most common, however,\ndata-driven models exploiting patterns in measurements are gaining popularity.\nThis research investigates a hybrid modeling approach, utilizing techniques\nfrom both the aforementioned areas of expertise, to model a well production\nchoke. The choke is represented with a simplified set of first-principle\nequations and a neural network to estimate the valve flow coefficient.\nHistorical production data from the petroleum platform Edvard Grieg is used for\nmodel validation. Additionally, a mechanistic and a data-driven model are\nconstructed for comparison of performance. A practical framework for\ndevelopment of models with varying degree of hybridity and stochastic\noptimization of its parameters is established. Results of the hybrid model\nperformance are promising albeit with considerable room for improvements.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:35:33 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 11:41:20 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 08:16:15 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hotvedt", "Mathilde", ""], ["Grimstad", "Bjarne", ""], ["Imsland", "Lars", ""]]}, {"id": "2002.02741", "submitter": "Moshe Kravchik", "authors": "Moshe Kravchik, Asaf Shabtai", "title": "Can't Boil This Frog: Robustness of Online-Trained Autoencoder-Based\n  Anomaly Detectors to Adversarial Poisoning Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a variety of effective neural network-based methods for\nanomaly and cyber attack detection in industrial control systems (ICSs) have\nbeen demonstrated in the literature. Given their successful implementation and\nwidespread use, there is a need to study adversarial attacks on such detection\nmethods to better protect the systems that depend upon them. The extensive\nresearch performed on adversarial attacks on image and malware classification\nhas little relevance to the physical system state prediction domain, which most\nof the ICS attack detection systems belong to. Moreover, such detection systems\nare typically retrained using new data collected from the monitored system,\nthus the threat of adversarial data poisoning is significant, however this\nthreat has not yet been addressed by the research community. In this paper, we\npresent the first study focused on poisoning attacks on online-trained\nautoencoder-based attack detectors. We propose two algorithms for generating\npoison samples, an interpolation-based algorithm and a back-gradient\noptimization-based algorithm, which we evaluate on both synthetic and\nreal-world ICS data. We demonstrate that the proposed algorithms can generate\npoison samples that cause the target attack to go undetected by the autoencoder\ndetector, however the ability to poison the detector is limited to a small set\nof attack types and magnitudes. When the poison-generating algorithms are\napplied to the popular SWaT dataset, we show that the autoencoder detector\ntrained on the physical system state data is resilient to poisoning in the face\nof all ten of the relevant attacks in the dataset. This finding suggests that\nneural network-based attack detectors used in the cyber-physical domain are\nmore robust to poisoning than in other problem domains, such as malware\ndetection and image processing.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 12:41:28 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kravchik", "Moshe", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2002.02750", "submitter": "Mathieu Goutay", "authors": "Mathieu Goutay, Fay\\c{c}al Ait Aoudia, Jakob Hoydis", "title": "Deep HyperNetwork-Based MIMO Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal symbol detection for multiple-input multiple-output (MIMO) systems is\nknown to be an NP-hard problem. Conventional heuristic algorithms are either\ntoo complex to be practical or suffer from poor performance. Recently, several\napproaches tried to address those challenges by implementing the detector as a\ndeep neural network. However, they either still achieve unsatisfying\nperformance on practical spatially correlated channels, or are computationally\ndemanding since they require retraining for each channel realization. In this\nwork, we address both issues by training an additional neural network (NN),\nreferred to as the hypernetwork, which takes as input the channel matrix and\ngenerates the weights of the neural NN-based detector. Results show that the\nproposed approach achieves near state-of-the-art performance without the need\nfor re-training.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:03:22 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:45:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Goutay", "Mathieu", ""], ["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "2002.02751", "submitter": "Amir Mosavi Prof", "authors": "Hossein Bonakdari, Isa Ebtehaj, Bahram Gharabaghi, Ali Sharifi, Amir\n  Mosavi", "title": "Prediction of Discharge Capacity of Labyrinth Weir with Gene Expression\n  Programming", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a model based on gene expression programming for\npredicting the discharge coefficient of triangular labyrinth weirs. The\nparameters influencing discharge coefficient prediction were first examined and\npresented as crest height ratio to the head over the crest of the weir, a crest\nlength of water to channel width, a crest length of water to the head over the\ncrest of the weir, Froude number and vertex angle dimensionless parameters.\nDifferent models were then presented using sensitivity analysis in order to\nexamine each of the dimensionless parameters presented in this study. In\naddition, an equation was presented through the use of nonlinear regression\n(NLR) for the purpose of comparison with GEP. The results of the studies\nconducted by using different statistical indexes indicated that GEP is more\ncapable than NLR. This is to the extent that GEP predicts the discharge\ncoefficient with an average relative error of approximately 2.5% in such a\nmanner that the predicted values have less than 5% relative error in the worst\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 00:48:27 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Bonakdari", "Hossein", ""], ["Ebtehaj", "Isa", ""], ["Gharabaghi", "Bahram", ""], ["Sharifi", "Ali", ""], ["Mosavi", "Amir", ""]]}, {"id": "2002.02753", "submitter": "Tobias Alt", "authors": "Tobias Alt, Joachim Weickert, Pascal Peter", "title": "Translating Diffusion, Wavelets, and Regularisation into Residual\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) often perform well, but their stability\nis poorly understood. To address this problem, we consider the simple\nprototypical problem of signal denoising, where classical approaches such as\nnonlinear diffusion, wavelet-based methods and regularisation offer provable\nstability guarantees. To transfer such guarantees to CNNs, we interpret\nnumerical approximations of these classical methods as a specific residual\nnetwork (ResNet) architecture. This leads to a dictionary which allows to\ntranslate diffusivities, shrinkage functions, and regularisers into activation\nfunctions, and enables a direct communication between the four research\ncommunities. On the CNN side, it does not only inspire new families of\nnonmonotone activation functions, but also introduces intrinsically stable\narchitectures for an arbitrary number of layers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:07:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 06:28:08 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 08:51:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Alt", "Tobias", ""], ["Weickert", "Joachim", ""], ["Peter", "Pascal", ""]]}, {"id": "2002.02755", "submitter": "Shubham Vatsal", "authors": "Shubham Vatsal, Naresh Purre, Sukumar Moharana, Gopi Ramena, Debi\n  Prasanna Mohanty", "title": "On-Device Information Extraction from SMS using Hybrid Hierarchical\n  Classification", "comments": "to be published in IEEE ICSC 2020 proceedings", "journal-ref": null, "doi": "10.1109/ICSC.2020.00036", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cluttering of SMS inbox is one of the serious problems that users today face\nin the digital world where every online login, transaction, along with\npromotions generate multiple SMS. This problem not only prevents users from\nsearching and navigating messages efficiently but often results in users\nmissing out the relevant information associated with the corresponding SMS like\noffer codes, payment reminders etc. In this paper, we propose a unique\narchitecture to organize and extract the appropriate information from SMS and\nfurther display it in an intuitive template. In the proposed architecture, we\nuse a Hybrid Hierarchical Long Short Term Memory (LSTM)-Convolutional Neural\nNetwork (CNN) to categorize SMS into multiple classes followed by a set of\nentity parsers used to extract the relevant information from the classified\nmessage. The architecture using its preprocessing techniques not only takes\ninto account the enormous variations observed in SMS data but also makes it\nefficient for its on-device (mobile phone) functionalities in terms of\ninference timing and size.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 09:24:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Vatsal", "Shubham", ""], ["Purre", "Naresh", ""], ["Moharana", "Sukumar", ""], ["Ramena", "Gopi", ""], ["Mohanty", "Debi Prasanna", ""]]}, {"id": "2002.02758", "submitter": "Parth Shah", "authors": "Parth Shah, Vishvajit Bakrola", "title": "Neural Machine Translation System of Indic Languages -- An Attention\n  based Approach", "comments": null, "journal-ref": "2019 Second International Conference on Advanced Computational and\n  Communication Paradigms (ICACCP), Gangtok, India, 2019, pp. 1-5", "doi": "10.1109/ICACCP.2019.8882969", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) is a recent and effective technique which\nled to remarkable improvements in comparison of conventional machine\ntranslation techniques. Proposed neural machine translation model developed for\nthe Gujarati language contains encoder-decoder with attention mechanism. In\nIndia, almost all the languages are originated from their ancestral language -\nSanskrit. They are having inevitable similarities including lexical and named\nentity similarity. Translating into Indic languages is always be a challenging\ntask. In this paper, we have presented the neural machine translation system\n(NMT) that can efficiently translate Indic languages like Hindi and Gujarati\nthat together covers more than 58.49 percentage of total speakers in the\ncountry. We have compared the performance of our NMT model with automatic\nevaluation matrices such as BLEU, perplexity and TER matrix. The comparison of\nour network with Google translate is also presented where it outperformed with\na margin of 6 BLEU score on English-Gujarati translation.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 07:15:18 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Shah", "Parth", ""], ["Bakrola", "Vishvajit", ""]]}, {"id": "2002.02770", "submitter": "Yaliang Li", "authors": "Liuyi Yao, Zhixuan Chu, Sheng Li, Yaliang Li, Jing Gao, Aidong Zhang", "title": "A Survey on Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is a critical research topic across many domains, such as\nstatistics, computer science, education, public policy and economics, for\ndecades. Nowadays, estimating causal effect from observational data has become\nan appealing research direction owing to the large amount of available data and\nlow budget requirement, compared with randomized controlled trials. Embraced\nwith the rapidly developed machine learning area, various causal effect\nestimation methods for observational data have sprung up. In this survey, we\nprovide a comprehensive review of causal inference methods under the potential\noutcome framework, one of the well known causal inference framework. The\nmethods are divided into two categories depending on whether they require all\nthree assumptions of the potential outcome framework or not. For each category,\nboth the traditional statistical methods and the recent machine learning\nenhanced methods are discussed and compared. The plausible applications of\nthese methods are also presented, including the applications in advertising,\nrecommendation, medicine and so on. Moreover, the commonly used benchmark\ndatasets as well as the open-source codes are also summarized, which facilitate\nresearchers and practitioners to explore, evaluate and apply the causal\ninference methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:35:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Yao", "Liuyi", ""], ["Chu", "Zhixuan", ""], ["Li", "Sheng", ""], ["Li", "Yaliang", ""], ["Gao", "Jing", ""], ["Zhang", "Aidong", ""]]}, {"id": "2002.02775", "submitter": "Yingcheng Sun", "authors": "Yingcheng Sun and Kenneth Loparo", "title": "Context Aware Image Annotation in Active Learning", "comments": "arXiv admin note: text overlap with arXiv:1508.07647, arXiv:1207.3809\n  by other authors", "journal-ref": "2019 19th Industrial Conference on Data Mining", "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image annotation for active learning is labor-intensive. Various automatic\nand semi-automatic labeling methods are proposed to save the labeling cost, but\na reduction in the number of labeled instances does not guarantee a reduction\nin cost because the queries that are most valuable to the learner may be the\nmost difficult or ambiguous cases, and therefore the most expensive for an\noracle to label accurately. In this paper, we try to solve this problem by\nusing image metadata to offer the oracle more clues about the image during\nannotation process. We propose a Context Aware Image Annotation Framework\n(CAIAF) that uses image metadata as similarity metric to cluster images into\ngroups for annotation. We also present useful metadata information as context\nfor each image on the annotation interface. Experiments show that it reduces\nthat annotation cost with CAIAF compared to the conventional framework, while\nmaintaining a high classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:57:05 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Sun", "Yingcheng", ""], ["Loparo", "Kenneth", ""]]}, {"id": "2002.02776", "submitter": "Hasan Ferit Eniser", "authors": "Hasan Ferit Eniser, Maria Christakis, Valentin W\\\"ustholz", "title": "RAID: Randomized Adversarial-Input Detection for Neural Networks", "comments": "10 pages of content plus 2 pages of bibliography. Submitted to ISSTA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have become the default choice for image\nclassification and many other learning tasks, even though they are vulnerable\nto so-called adversarial attacks. To increase their robustness against these\nattacks, there have emerged numerous detection mechanisms that aim to\nautomatically determine if an input is adversarial. However, state-of-the-art\ndetection mechanisms either rely on being tuned for each type of attack, or\nthey do not generalize across different attack types. To alleviate these\nissues, we propose a novel technique for adversarial-image detection, RAID,\nthat trains a secondary classifier to identify differences in neuron activation\nvalues between benign and adversarial inputs. Our technique is both more\nreliable and more effective than the state of the art when evaluated against\nsix popular attacks. Moreover, a straightforward extension of RAID increases\nits robustness against detection-aware adversaries without affecting its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:27:29 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Eniser", "Hasan Ferit", ""], ["Christakis", "Maria", ""], ["W\u00fcstholz", "Valentin", ""]]}, {"id": "2002.02778", "submitter": "Jisu Kim", "authors": "Kwangho Kim, Jisu Kim, Manzil Zaheer, Joon Sik Kim, Frederic Chazal,\n  and Larry Wasserman", "title": "PLLay: Efficient Topological Layer based on Persistence Landscapes", "comments": "29 pages, 7 figures", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose PLLay, a novel topological layer for general deep learning models\nbased on persistence landscapes, in which we can efficiently exploit the\nunderlying topological features of the input data structure. In this work, we\nshow differentiability with respect to layer inputs, for a general persistent\nhomology with arbitrary filtration. Thus, our proposed layer can be placed\nanywhere in the network and feed critical information on the topological\nfeatures of input data into subsequent layers to improve the learnability of\nthe networks toward a given task. A task-optimal structure of PLLay is learned\nduring training via backpropagation, without requiring any input featurization\nor data preprocessing. We provide a novel adaptation for the DTM function-based\nfiltration, and show that the proposed layer is robust against noise and\noutliers through a stability analysis. We demonstrate the effectiveness of our\napproach by classification experiments on various datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:34:22 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 07:05:55 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 04:43:37 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 00:44:49 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Kim", "Kwangho", ""], ["Kim", "Jisu", ""], ["Zaheer", "Manzil", ""], ["Kim", "Joon Sik", ""], ["Chazal", "Frederic", ""], ["Wasserman", "Larry", ""]]}, {"id": "2002.02779", "submitter": "Charles Fisher", "authors": "Jonathan R. Walsh, Aaron M. Smith, Yannick Pouliot, David Li-Bland,\n  Anton Loukianov, and Charles K. Fisher", "title": "Generating Digital Twins with Multiple Sclerosis Using Probabilistic\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Sclerosis (MS) is a neurodegenerative disorder characterized by a\ncomplex set of clinical assessments. We use an unsupervised machine learning\nmodel called a Conditional Restricted Boltzmann Machine (CRBM) to learn the\nrelationships between covariates commonly used to characterize subjects and\ntheir disease progression in MS clinical trials. A CRBM is capable of\ngenerating digital twins, which are simulated subjects having the same baseline\ndata as actual subjects. Digital twins allow for subject-level statistical\nanalyses of disease progression. The CRBM is trained using data from 2395\nsubjects enrolled in the placebo arms of clinical trials across the three\nprimary subtypes of MS. We discuss how CRBMs are trained and show that digital\ntwins generated by the model are statistically indistinguishable from their\nactual subject counterparts along a number of measures.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:57:08 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:39:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Walsh", "Jonathan R.", ""], ["Smith", "Aaron M.", ""], ["Pouliot", "Yannick", ""], ["Li-Bland", "David", ""], ["Loukianov", "Anton", ""], ["Fisher", "Charles K.", ""]]}, {"id": "2002.02782", "submitter": "Mario Wieser", "authors": "Mario Wieser, Sonali Parbhoo, Aleksander Wieczorek, Volker Roth", "title": "Inverse Learning of Symmetries", "comments": "Accepted for publication at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Symmetry transformations induce invariances which are frequently described\nwith deep latent variable models. In many complex domains, such as the chemical\nspace, invariances can be observed, yet the corresponding symmetry\ntransformation cannot be formulated analytically. We propose to learn the\nsymmetry transformation with a model consisting of two latent subspaces, where\nthe first subspace captures the target and the second subspace the remaining\ninvariant information. Our approach is based on the deep information bottleneck\nin combination with a continuous mutual information regulariser. Unlike\nprevious methods, we focus on the challenging task of minimising mutual\ninformation in continuous domains. To this end, we base the calculation of\nmutual information on correlation matrices in combination with a bijective\nvariable transformation. Extensive experiments demonstrate that our model\noutperforms state-of-the-art methods on artificial and molecular datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:48:52 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:46:53 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Wieser", "Mario", ""], ["Parbhoo", "Sonali", ""], ["Wieczorek", "Aleksander", ""], ["Roth", "Volker", ""]]}, {"id": "2002.02794", "submitter": "Tiancheng Yu", "authors": "Chi Jin, Akshay Krishnamurthy, Max Simchowitz, Tiancheng Yu", "title": "Reward-Free Exploration for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is widely regarded as one of the most challenging aspects of\nreinforcement learning (RL), with many naive approaches succumbing to\nexponential sample complexity. To isolate the challenges of exploration, we\npropose a new \"reward-free RL\" framework. In the exploration phase, the agent\nfirst collects trajectories from an MDP $\\mathcal{M}$ without a pre-specified\nreward function. After exploration, it is tasked with computing near-optimal\npolicies under for $\\mathcal{M}$ for a collection of given reward functions.\nThis framework is particularly suitable when there are many reward functions of\ninterest, or when the reward function is shaped by an external agent to elicit\ndesired behavior.\n  We give an efficient algorithm that conducts\n$\\tilde{\\mathcal{O}}(S^2A\\mathrm{poly}(H)/\\epsilon^2)$ episodes of exploration\nand returns $\\epsilon$-suboptimal policies for an arbitrary number of reward\nfunctions. We achieve this by finding exploratory policies that visit each\n\"significant\" state with probability proportional to its maximum visitation\nprobability under any possible policy. Moreover, our planning procedure can be\ninstantiated by any black-box approximate planner, such as value iteration or\nnatural policy gradient. We also give a nearly-matching\n$\\Omega(S^2AH^2/\\epsilon^2)$ lower bound, demonstrating the near-optimality of\nour algorithm in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:03:38 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Jin", "Chi", ""], ["Krishnamurthy", "Akshay", ""], ["Simchowitz", "Max", ""], ["Yu", "Tiancheng", ""]]}, {"id": "2002.02797", "submitter": "Javier Antor\\'an", "authors": "Javier Antor\\'an, James Urquhart Allingham, Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Variational Depth Search in ResNets", "comments": "Appearing at the 1st ICLR workshop on Neural Architecture Search 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot neural architecture search allows joint learning of weights and\nnetwork architecture, reducing computational cost. We limit our search space to\nthe depth of residual networks and formulate an analytically tractable\nvariational objective that allows for obtaining an unbiased approximate\nposterior over depths in one-shot. We propose a heuristic to prune our networks\nbased on this distribution. We compare our proposed method against manual\nsearch over network depths on the MNIST, Fashion-MNIST, SVHN datasets. We find\nthat pruned networks do not incur a loss in predictive performance, obtaining\naccuracies competitive with unpruned networks. Marginalising over depth allows\nus to obtain better-calibrated test-time uncertainty estimates than regular\nnetworks, in a single forward pass.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:00:03 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:12:58 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 10:58:12 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 17:59:13 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Antor\u00e1n", "Javier", ""], ["Allingham", "James Urquhart", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2002.02798", "submitter": "Chris Finlay", "authors": "Chris Finlay, J\\\"orn-Henrik Jacobsen, Levon Nurbekyan, Adam M Oberman", "title": "How to train your neural ODE: the world of Jacobian and kinetic\n  regularization", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural ODEs on large datasets has not been tractable due to the\nnecessity of allowing the adaptive numerical ODE solver to refine its step size\nto very small values. In practice this leads to dynamics equivalent to many\nhundreds or even thousands of layers. In this paper, we overcome this apparent\ndifficulty by introducing a theoretically-grounded combination of both optimal\ntransport and stability regularizations which encourage neural ODEs to prefer\nsimpler dynamics out of all the dynamics that solve a problem well. Simpler\ndynamics lead to faster convergence and to fewer discretizations of the solver,\nconsiderably decreasing wall-clock time without loss in performance. Our\napproach allows us to train neural ODE-based generative models to the same\nperformance as the unregularized dynamics, with significant reductions in\ntraining time. This brings neural ODEs closer to practical relevance in\nlarge-scale applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:15:02 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 18:38:51 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 15:54:19 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Finlay", "Chris", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Nurbekyan", "Levon", ""], ["Oberman", "Adam M", ""]]}, {"id": "2002.02801", "submitter": "Ekram Hossain", "authors": "Yasser Al-Eryani, Mohamed Akrout, and Ekram Hossain", "title": "Multiple Access in Dynamic Cell-Free Networks: Outage Performance and\n  Deep Reinforcement Learning-Based Design", "comments": "This article has been submitted to IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In future cell-free (or cell-less) wireless networks, a large number of\ndevices in a geographical area will be served simultaneously in non-orthogonal\nmultiple access scenarios by a large number of distributed access points (APs),\nwhich coordinate with a centralized processing pool. For such a centralized\ncell-free network with static predefined beamforming design, we first derive a\nclosed-form expression of the uplink per-user probability of outage. To\nsignificantly reduce the complexity of joint processing of users' signals in\npresence of a large number of devices and APs, we propose a novel dynamic\ncell-free network architecture. In this architecture, the distributed APs are\npartitioned (i.e. clustered) among a set of subgroups with each subgroup acting\nas a virtual AP equipped with a distributed antenna system (DAS). The\nconventional static cell-free network is a special case of this dynamic\ncell-free network when the cluster size is one. For this dynamic cell-free\nnetwork, we propose a successive interference cancellation (SIC)-enabled signal\ndetection method and an inter-user-interference (IUI)-aware DAS's receive\ndiversity combining scheme. We then formulate the general problem of clustering\nAPs and designing the beamforming vectors with an objective to maximizing the\nsum rate or maximizing the minimum rate. To this end, we propose a hybrid deep\nreinforcement learning (DRL) model, namely, a deep deterministic policy\ngradient (DDPG)-deep double Q-network (DDQN) model, to solve the optimization\nproblem for online implementation with low complexity. The DRL model for\nsum-rate optimization significantly outperforms that for maximizing the minimum\nrate in terms of average per-user rate performance. Also, in our system\nsetting, the proposed DDPG-DDQN scheme is found to achieve around $78\\%$ of the\nrate achievable through an exhaustive search-based design.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 03:00:22 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:49:40 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Al-Eryani", "Yasser", ""], ["Akrout", "Mohamed", ""], ["Hossain", "Ekram", ""]]}, {"id": "2002.02804", "submitter": "Luis Larios-C\\'ardenas", "authors": "Luis \\'Angel Larios-C\\'ardenas and Frederic Gibou", "title": "A Deep Learning Approach for the Computation of Curvature in the\n  Level-Set Method", "comments": "To appear in SIAM Journal on Scientific Computing", "journal-ref": null, "doi": "10.1137/20M1316755", "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep learning strategy to estimate the mean curvature of\ntwo-dimensional implicit interfaces in the level-set method. Our approach is\nbased on fitting feed-forward neural networks to synthetic data sets\nconstructed from circular interfaces immersed in uniform grids of various\nresolutions. These multilayer perceptrons process the level-set values from\nmesh points next to the free boundary and output the dimensionless curvature at\ntheir closest locations on the interface. Accuracy analyses involving irregular\ninterfaces, in both uniform and adaptive grids, show that our models are\ncompetitive with traditional numerical schemes in the $L^1$ and $L^2$ norms. In\nparticular, our neural networks approximate curvature with comparable precision\nin coarse resolutions, when the interface features steep curvature regions, and\nwhen the number of iterations to reinitialize the level-set function is small.\nAlthough the conventional numerical approach is more robust than our framework,\nour results have unveiled the potential of machine learning for dealing with\ncomputational tasks where the level-set method is known to experience\ndifficulties. We also establish that an application-dependent map of local\nresolutions to neural models can be devised to estimate mean curvature more\neffectively than a universal neural network.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 00:49:47 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 04:46:47 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 03:14:39 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Larios-C\u00e1rdenas", "Luis \u00c1ngel", ""], ["Gibou", "Frederic", ""]]}, {"id": "2002.02805", "submitter": "Nicklas Hansen", "authors": "Ali Mohebbi, Alexander R. Johansen, Nicklas Hansen, Peter E.\n  Christensen, Jens M. Tarp, Morten L. Jensen, Henrik Bengtsson and Morten\n  M{\\o}rup", "title": "Short Term Blood Glucose Prediction based on Continuous Glucose\n  Monitoring Data", "comments": "Accepted to EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous Glucose Monitoring (CGM) has enabled important opportunities for\ndiabetes management. This study explores the use of CGM data as input for\ndigital decision support tools. We investigate how Recurrent Neural Networks\n(RNNs) can be used for Short Term Blood Glucose (STBG) prediction and compare\nthe RNNs to conventional time-series forecasting using Autoregressive\nIntegrated Moving Average (ARIMA). A prediction horizon up to 90 min into the\nfuture is considered. In this context, we evaluate both population-based and\npatient-specific RNNs and contrast them to patient-specific ARIMA models and a\nsimple baseline predicting future observations as the last observed. We find\nthat the population-based RNN model is the best performing model across the\nconsidered prediction horizons without the need of patient-specific data. This\ndemonstrates the potential of RNNs for STBG prediction in diabetes patients\ntowards detecting/mitigating severe events in the STBG, in particular\nhypoglycemic events. However, further studies are needed in regards to the\nrobustness and practical use of the investigated STBG prediction models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 16:39:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 20:18:33 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Mohebbi", "Ali", ""], ["Johansen", "Alexander R.", ""], ["Hansen", "Nicklas", ""], ["Christensen", "Peter E.", ""], ["Tarp", "Jens M.", ""], ["Jensen", "Morten L.", ""], ["Bengtsson", "Henrik", ""], ["M\u00f8rup", "Morten", ""]]}, {"id": "2002.02814", "submitter": "Jianfeng Dong", "authors": "Zhe Ma, Jianfeng Dong, Yao Zhang, Zhongzi Long, Yuan He, Hui Xue,\n  Shouling Ji", "title": "Fine-Grained Fashion Similarity Learning by Attribute-Specific Embedding\n  Network", "comments": "16 pages, 13 figutes. Accepted by AAAI 2020. Code and data are\n  available at https://github.com/Maryeon/asen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper strives to learn fine-grained fashion similarity. In this\nsimilarity paradigm, one should pay more attention to the similarity in terms\nof a specific design/attribute among fashion items, which has potential values\nin many fashion related applications such as fashion copyright protection. To\nthis end, we propose an Attribute-Specific Embedding Network (ASEN) to jointly\nlearn multiple attribute-specific embeddings in an end-to-end manner, thus\nmeasure the fine-grained similarity in the corresponding space. With two\nattention modules, i.e., Attribute-aware Spatial Attention and Attribute-aware\nChannel Attention, ASEN is able to locate the related regions and capture the\nessential patterns under the guidance of the specified attribute, thus make the\nlearned attribute-specific embeddings better reflect the fine-grained\nsimilarity. Extensive experiments on four fashion-related datasets show the\neffectiveness of ASEN for fine-grained fashion similarity learning and its\npotential for fashion reranking.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:42:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Ma", "Zhe", ""], ["Dong", "Jianfeng", ""], ["Zhang", "Yao", ""], ["Long", "Zhongzi", ""], ["He", "Yuan", ""], ["Xue", "Hui", ""], ["Ji", "Shouling", ""]]}, {"id": "2002.02818", "submitter": "Diep Do Ngoc", "authors": "Do Ngoc Diep, Koji Nagata, and Tadao Nakamura", "title": "Nonparametric Regression Quantum Neural Networks", "comments": "4 pages, no figure, LaTeX2e", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two pervious papers \\cite{dndiep3}, \\cite{dndiep4}, the first author\nconstructed the least square quantum neural networks (LS-QNN), and ploynomial\ninterpolation quantum neural networks ( PI-QNN), parametrico-stattistical QNN\nlike: leanr regrassion quantum neural networks (LR-QNN), polynomial regression\nquantum neural networks (PR-QNN), chi-squared quantum neural netowrks\n($\\chi^2$-QNN). We observed that the method works also in the cases by using\nnonparametric statistics. In this paper we analyze and implement the\nnonparametric tests on QNN such as: linear nonparametric regression quantum\nneural networks (LNR-QNN), polynomial nonparametric regression quantum neural\nnetworks (PNR-QNN). The implementation is constructed through the Gauss-Jordan\nElimination quantum neural networks (GJE-QNN).The training rule is to use the\nhigh probability confidence regions or intervals.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:44:45 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Diep", "Do Ngoc", ""], ["Nagata", "Koji", ""], ["Nakamura", "Tadao", ""]]}, {"id": "2002.02820", "submitter": "Lukas P. Fr\\\"ohlich", "authors": "Lukas P. Fr\\\"ohlich, Edgar D. Klenske, Julia Vinogradska, Christian\n  Daniel, Melanie N. Zeilinger", "title": "Noisy-Input Entropy Search for Efficient Robust Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust optimization within the well-established\nBayesian optimization (BO) framework. While BO is intrinsically robust to noisy\nevaluations of the objective function, standard approaches do not consider the\ncase of uncertainty about the input parameters. In this paper, we propose\nNoisy-Input Entropy Search (NES), a novel information-theoretic acquisition\nfunction that is designed to find robust optima for problems with both input\nand measurement noise. NES is based on the key insight that the robust\nobjective in many cases can be modeled as a Gaussian process, however, it\ncannot be observed directly. We evaluate NES on several benchmark problems from\nthe optimization literature and from engineering. The results show that NES\nreliably finds robust optima, outperforming existing methods from the\nliterature on all benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:48:16 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Fr\u00f6hlich", "Lukas P.", ""], ["Klenske", "Edgar D.", ""], ["Vinogradska", "Julia", ""], ["Daniel", "Christian", ""], ["Zeilinger", "Melanie N.", ""]]}, {"id": "2002.02826", "submitter": "Chi-Ken Lu", "authors": "Chi-Ken Lu, Patrick Shafto", "title": "Deep Moment Matching Kernel for Multi-source Gaussian Processes", "comments": "Revised version, title changed, experiments on high dimensional\n  multi-fidelity data added, related works revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learners have the ability to solve new tasks efficiently if previous\nknowledge is relevant, which has motivated research into few-shot learning and\ntransfer learning. We formalize the integration of relevant knowledge as\nmulti-source regression in which the target function is inferred using Gaussian\nProcess (GP) with the deep moment matching (DMM) kernel. We obtain a\nnon-stationary DMM kernel from prior relevant data by analytically calculating\nthe covariance of the target function. We interpret the data-informed DMM\nkernel, which serves as prior for target function, as: (1) a refined similarity\ndetermined by squared distance in the latent space and (2) as propagating\nuncertainty measured in RKHS defined by the posterior covariance from the prior\nlearning. In comparison with the autoregressive models, variational DGP models\nand others, results show GP regression with the DMM kernels is effective when\napplying to the standard synthetic and real-world multi-fidelity data sets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:56:11 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 18:07:01 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Lu", "Chi-Ken", ""], ["Shafto", "Patrick", ""]]}, {"id": "2002.02829", "submitter": "Zhimin Hou", "authors": "Zhimin Hou and Kuangen Zhang and Yi Wan and Dongyu Li and Chenglong Fu\n  and Haoyong Yu", "title": "Off-policy Maximum Entropy Reinforcement Learning : Soft Actor-Critic\n  with Advantage Weighted Mixture Policy(SAC-AWMP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal policy of a reinforcement learning problem is often discontinuous\nand non-smooth. I.e., for two states with similar representations, their\noptimal policies can be significantly different. In this case, representing the\nentire policy with a function approximator (FA) with shared parameters for all\nstates maybe not desirable, as the generalization ability of parameters sharing\nmakes representing discontinuous, non-smooth policies difficult. A common way\nto solve this problem, known as Mixture-of-Experts, is to represent the policy\nas the weighted sum of multiple components, where different components perform\nwell on different parts of the state space. Following this idea and inspired by\na recent work called advantage-weighted information maximization, we propose to\nlearn for each state weights of these components, so that they entail the\ninformation of the state itself and also the preferred action learned so far\nfor the state. The action preference is characterized via the advantage\nfunction. In this case, the weight of each component would only be large for\ncertain groups of states whose representations are similar and preferred action\nrepresentations are also similar. Therefore each component is easy to be\nrepresented. We call a policy parameterized in this way an Advantage Weighted\nMixture Policy (AWMP) and apply this idea to improve soft-actor-critic (SAC),\none of the most competitive continuous control algorithm. Experimental results\ndemonstrate that SAC with AWMP clearly outperforms SAC in four commonly used\ncontinuous control tasks and achieve stable performance across different random\nseeds.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:01:20 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Hou", "Zhimin", ""], ["Zhang", "Kuangen", ""], ["Wan", "Yi", ""], ["Li", "Dongyu", ""], ["Fu", "Chenglong", ""], ["Yu", "Haoyong", ""]]}, {"id": "2002.02835", "submitter": "Francis Bach", "authors": "Francis Bach (LIENS, SIERRA)", "title": "On the Effectiveness of Richardson Extrapolation in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Richardson extrapolation is a classical technique from numerical analysis\nthat can improve the approximation error of an estimation method by combining\nlinearly several estimates obtained from different values of one of its\nhyperparameters, without the need to know in details the inner structure of the\noriginal estimation method. The main goal of this paper is to study when\nRichardson extrapolation can be used within machine learning, beyond the\nexisting applications to step-size adaptations in stochastic gradient descent.\nWe identify two situations where Richardson interpolation can be useful: (1)\nwhen the hyperparameter is the number of iterations of an existing iterative\noptimization algorithm, with applications to averaged gradient descent and\nFrank-Wolfe algorithms (where we obtain asymptotically rates of $O(1/k^2)$ on\npolytopes, where $k$ is the number of iterations), and (2) when it is a\nregularization parameter, with applications to Nesterov smoothing techniques\nfor minimizing non-smooth functions (where we obtain asymptotically rates close\nto $O(1/k^2)$ for non-smooth functions), and ridge regression. In all these\ncases, we show that extrapolation techniques come with no significant loss in\nperformance, but with sometimes strong gains, and we provide theoretical\njustifications based on asymptotic developments for such gains, as well as\nempirical illustrations on classical problems from machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:18:04 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 09:12:42 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 14:38:05 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Bach", "Francis", "", "LIENS, SIERRA"]]}, {"id": "2002.02836", "submitter": "Ivo Danihelka", "authors": "Danilo J. Rezende, Ivo Danihelka, George Papamakarios, Nan Rosemary\n  Ke, Ray Jiang, Theophane Weber, Karol Gregor, Hamza Merzic, Fabio Viola, Jane\n  Wang, Jovana Mitrovic, Frederic Besse, Ioannis Antonoglou, Lars Buesing", "title": "Causally Correct Partial Models for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, we can learn a model of future observations and\nrewards, and use it to plan the agent's next actions. However, jointly modeling\nfuture observations can be computationally expensive or even intractable if the\nobservations are high-dimensional (e.g. images). For this reason, previous\nworks have considered partial models, which model only part of the observation.\nIn this paper, we show that partial models can be causally incorrect: they are\nconfounded by the observations they don't model, and can therefore lead to\nincorrect planning. To address this, we introduce a general family of partial\nmodels that are provably causally correct, yet remain fast because they do not\nneed to fully model future observations.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:18:15 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rezende", "Danilo J.", ""], ["Danihelka", "Ivo", ""], ["Papamakarios", "George", ""], ["Ke", "Nan Rosemary", ""], ["Jiang", "Ray", ""], ["Weber", "Theophane", ""], ["Gregor", "Karol", ""], ["Merzic", "Hamza", ""], ["Viola", "Fabio", ""], ["Wang", "Jane", ""], ["Mitrovic", "Jovana", ""], ["Besse", "Frederic", ""], ["Antonoglou", "Ioannis", ""], ["Buesing", "Lars", ""]]}, {"id": "2002.02842", "submitter": "Satya Narayan Shukla", "authors": "Meet P. Vadera, Satya Narayan Shukla, Brian Jalaian and Benjamin M.\n  Marlin", "title": "Assessing the Adversarial Robustness of Monte Carlo and Distillation\n  Methods for Deep Bayesian Neural Network Classification", "comments": "Presented at SafeAI Workshop, AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of assessing the adversarial\nrobustness of deep neural network models under both Markov chain Monte Carlo\n(MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We\ncharacterize the robustness of each method to two types of adversarial attacks:\nthe fast gradient sign method (FGSM) and projected gradient descent (PGD). We\nshow that full MCMC-based inference has excellent robustness, significantly\noutperforming standard point estimation-based learning. On the other hand, BDK\nprovides marginal improvements. As an additional contribution, we present a\nstorage-efficient approach to computing adversarial examples for large Monte\nCarlo ensembles using both the FGSM and PGD attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:29:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Vadera", "Meet P.", ""], ["Shukla", "Satya Narayan", ""], ["Jalaian", "Brian", ""], ["Marlin", "Benjamin M.", ""]]}, {"id": "2002.02844", "submitter": "Shuisheng Zhou", "authors": "Li Chen, Shuizheng Zhou, Jiajun Ma", "title": "Stable Sparse Subspace Embedding for Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse random projection (RP) is a popular tool for dimensionality reduction\nthat shows promising performance with low computational complexity. However, in\nthe existing sparse RP matrices, the positions of non-zero entries are usually\nrandomly selected. Although they adopt uniform sampling with replacement, due\nto large sampling variance, the number of non-zeros is uneven among rows of the\nprojection matrix which is generated in one trial, and more data information\nmay be lost after dimension reduction. To break this bottleneck, based on\nrandom sampling without replacement in statistics, this paper builds a stable\nsparse subspace embedded matrix (S-SSE), in which non-zeros are uniformly\ndistributed. It is proved that the S-SSE is stabler than the existing matrix,\nand it can maintain Euclidean distance between points well after dimension\nreduction. Our empirical studies corroborate our theoretical findings and\ndemonstrate that our approach can indeed achieve satisfactory performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:30:22 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Shuizheng", ""], ["Ma", "Jiajun", ""]]}, {"id": "2002.02846", "submitter": "Shuisheng Zhou", "authors": "Li Chen, Shuisheng Zhou, Jiajun Ma", "title": "Fast Kernel k-means Clustering Using Incomplete Cholesky Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based clustering algorithm can identify and capture the non-linear\nstructure in datasets, and thereby it can achieve better performance than\nlinear clustering. However, computing and storing the entire kernel matrix\noccupy so large memory that it is difficult for kernel-based clustering to deal\nwith large-scale datasets. In this paper, we employ incomplete Cholesky\nfactorization to accelerate kernel clustering and save memory space. The key\nidea of the proposed kernel $k$-means clustering using incomplete Cholesky\nfactorization is that we approximate the entire kernel matrix by the product of\na low-rank matrix and its transposition. Then linear $k$-means clustering is\napplied to columns of the transpose of the low-rank matrix. We show both\nanalytically and empirically that the performance of the proposed algorithm is\nsimilar to that of the kernel $k$-means clustering algorithm, but our method\ncan deal with large-scale datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:32:14 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Chen", "Li", ""], ["Zhou", "Shuisheng", ""], ["Ma", "Jiajun", ""]]}, {"id": "2002.02848", "submitter": "Morgane Riviere", "authors": "Morgane Rivi\\`ere, Armand Joulin, Pierre-Emmanuel Mazar\\'e, Emmanuel\n  Dupoux", "title": "Unsupervised pretraining transfers well across languages", "comments": "6 pages. Accepted at ICASSP 2020. However the 2 pages of\n  supplementary materials will appear only in the arxiv version", "journal-ref": "ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual and multi-lingual training of Automatic Speech Recognition\n(ASR) has been extensively investigated in the supervised setting. This assumes\nthe existence of a parallel corpus of speech and orthographic transcriptions.\nRecently, contrastive predictive coding (CPC) algorithms have been proposed to\npretrain ASR systems with unlabelled data. In this work, we investigate whether\nunsupervised pretraining transfers well across languages. We show that a slight\nmodification of the CPC pretraining extracts features that transfer well to\nother languages, being on par or even outperforming supervised pretraining.\nThis shows the potential of unsupervised methods for languages with few\nlinguistic resources.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:34:53 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Rivi\u00e8re", "Morgane", ""], ["Joulin", "Armand", ""], ["Mazar\u00e9", "Pierre-Emmanuel", ""], ["Dupoux", "Emmanuel", ""]]}, {"id": "2002.02851", "submitter": "Georg Pichler", "authors": "Georg Pichler and Pablo Piantanida and G\\\"unther Koliander", "title": "On the Estimation of Information Measures of Continuous Distributions", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of information measures of continuous distributions based on\nsamples is a fundamental problem in statistics and machine learning. In this\npaper, we analyze estimates of differential entropy in $K$-dimensional\nEuclidean space, computed from a finite number of samples, when the probability\ndensity function belongs to a predetermined convex family $\\mathcal{P}$. First,\nestimating differential entropy to any accuracy is shown to be infeasible if\nthe differential entropy of densities in $\\mathcal{P}$ is unbounded, clearly\nshowing the necessity of additional assumptions. Subsequently, we investigate\nsufficient conditions that enable confidence bounds for the estimation of\ndifferential entropy. In particular, we provide confidence bounds for simple\nhistogram based estimation of differential entropy from a fixed number of\nsamples, assuming that the probability density function is Lipschitz continuous\nwith known Lipschitz constant and known, bounded support. Our focus is on\ndifferential entropy, but we provide examples that show that similar results\nhold for mutual information and relative entropy as well.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:36:10 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Pichler", "Georg", ""], ["Piantanida", "Pablo", ""], ["Koliander", "G\u00fcnther", ""]]}, {"id": "2002.02852", "submitter": "S\\'ebastien de Blois", "authors": "S\\'ebastien de Blois, Mathieu Garon, Christian Gagn\\'e,\n  Jean-Fran\\c{c}ois Lalonde", "title": "Input Dropout for Spatially Aligned Modalities", "comments": "Accepted in ICIP 2020. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision datasets containing multiple modalities such as color, depth,\nand thermal properties are now commonly accessible and useful for solving a\nwide array of challenging tasks. However, deploying multi-sensor heads is not\npossible in many scenarios. As such many practical solutions tend to be based\non simpler sensors, mostly for cost, simplicity and robustness considerations.\nIn this work, we propose a training methodology to take advantage of these\nadditional modalities available in datasets, even if they are not available at\ntest time. By assuming that the modalities have a strong spatial correlation,\nwe propose Input Dropout, a simple technique that consists in stochastic hiding\nof one or many input modalities at training time, while using only the\ncanonical (e.g. RGB) modalities at test time. We demonstrate that Input Dropout\ntrivially combines with existing deep convolutional architectures, and improves\ntheir performance on a wide range of computer vision tasks such as dehazing,\n6-DOF object tracking, pedestrian detection and object classification.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:39:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 11:35:17 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["de Blois", "S\u00e9bastien", ""], ["Garon", "Mathieu", ""], ["Gagn\u00e9", "Christian", ""], ["Lalonde", "Jean-Fran\u00e7ois", ""]]}, {"id": "2002.02862", "submitter": "Yuling Jiao", "authors": "Yuan Gao and Jian Huang and Yuling Jiao and Jin Liu", "title": "Learning Implicit Generative Models with Theoretical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a \\textbf{uni}fied \\textbf{f}ramework for \\textbf{i}mplicit\n\\textbf{ge}nerative \\textbf{m}odeling (UnifiGem) with theoretical guarantees by\nintegrating approaches from optimal transport, numerical ODE, density-ratio\n(density-difference) estimation and deep neural networks. First, the problem of\nimplicit generative learning is formulated as that of finding the optimal\ntransport map between the reference distribution and the target distribution,\nwhich is characterized by a totally nonlinear Monge-Amp\\`{e}re equation.\nInterpreting the infinitesimal linearization of the Monge-Amp\\`{e}re equation\nfrom the perspective of gradient flows in measure spaces leads to the\ncontinuity equation or the McKean-Vlasov equation. We then solve the\nMcKean-Vlasov equation numerically using the forward Euler iteration, where the\nforward Euler map depends on the density ratio (density difference) between the\ndistribution at current iteration and the underlying target distribution. We\nfurther estimate the density ratio (density difference) via deep density-ratio\n(density-difference) fitting and derive explicit upper bounds on the estimation\nerror. Experimental results on both synthetic datasets and real benchmark\ndatasets support our theoretical findings and demonstrate the effectiveness of\nUnifiGem.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:55:48 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 14:26:17 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Yuan", ""], ["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Liu", "Jin", ""]]}, {"id": "2002.02863", "submitter": "Bogdan Mazoure", "authors": "Bogdan Mazoure, Thang Doan, Tianyu Li, Vladimir Makarenkov, Joelle\n  Pineau, Doina Precup, Guillaume Rabusseau", "title": "Representation of Reinforcement Learning Policies in Reproducing Kernel\n  Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for policy representation for reinforcement\nlearning tasks. This framework involves finding a low-dimensional embedding of\nthe policy on a reproducing kernel Hilbert space (RKHS). The usage of RKHS\nbased methods allows us to derive strong theoretical guarantees on the expected\nreturn of the reconstructed policy. Such guarantees are typically lacking in\nblack-box models, but are very desirable in tasks requiring stability. We\nconduct several experiments on classic RL domains. The results confirm that the\npolicies can be robustly embedded in a low-dimensional space while the embedded\npolicy incurs almost no decrease in return.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:57:57 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 16:00:19 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Mazoure", "Bogdan", ""], ["Doan", "Thang", ""], ["Li", "Tianyu", ""], ["Makarenkov", "Vladimir", ""], ["Pineau", "Joelle", ""], ["Precup", "Doina", ""], ["Rabusseau", "Guillaume", ""]]}, {"id": "2002.02868", "submitter": "Younghan Jeon", "authors": "Younghan Jeon, Minsik Lee, Jin Young Choi", "title": "Differentiable Forward and Backward Fixed-Point Iteration Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several studies proposed methods to utilize some classes of\noptimization problems in designing deep neural networks to encode constraints\nthat conventional layers cannot capture. However, these methods are still in\ntheir infancy and require special treatments, such as analyzing the KKT\ncondition, for deriving the backpropagation formula. In this paper, we propose\na new layer formulation called the fixed-point iteration (FPI) layer that\nfacilitates the use of more complicated operations in deep networks. The\nbackward FPI layer is also proposed for backpropagation, which is motivated by\nthe recurrent back-propagation (RBP) algorithm. But in contrast to RBP, the\nbackward FPI layer yields the gradient by a small network module without an\nexplicit calculation of the Jacobian. In actual applications, both the forward\nand backward FPI layers can be treated as nodes in the computational graphs.\nAll components in the proposed method are implemented at a high level of\nabstraction, which allows efficient higher-order differentiations on the nodes.\nIn addition, we present two practical methods of the FPI layer, FPI_NN and\nFPI_GD, where the update operations of FPI are a small neural network module\nand a single gradient descent step based on a learnable cost function,\nrespectively. FPI\\_NN is intuitive, simple, and fast to train, while FPI_GD can\nbe used for efficient training of energy networks that have been recently\nstudied. While RBP and its related studies have not been applied to practical\nexamples, our experiments show the FPI layer can be successfully applied to\nreal-world problems such as image denoising, optical flow, and multi-label\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:02:44 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 15:16:24 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 03:35:21 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 02:36:24 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jeon", "Younghan", ""], ["Lee", "Minsik", ""], ["Choi", "Jin Young", ""]]}, {"id": "2002.02870", "submitter": "Faezeh Nejati Hatamian", "authors": "Faezeh Nejati Hatamian, Nishant Ravikumar, Sulaiman Vesal, Felix P.\n  Kemeth, Matthias Struck, Andreas Maier", "title": "The Effect of Data Augmentation on Classification of Atrial Fibrillation\n  in Short Single-Lead ECG Signals Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cardiovascular diseases are the most common cause of mortality worldwide.\nDetection of atrial fibrillation (AF) in the asymptomatic stage can help\nprevent strokes. It also improves clinical decision making through the delivery\nof suitable treatment such as, anticoagulant therapy, in a timely manner. The\nclinical significance of such early detection of AF in electrocardiogram (ECG)\nsignals has inspired numerous studies in recent years, of which many aim to\nsolve this task by leveraging machine learning algorithms. ECG datasets\ncontaining AF samples, however, usually suffer from severe class imbalance,\nwhich if unaccounted for, affects the performance of classification algorithms.\nData augmentation is a popular solution to tackle this problem.\n  In this study, we investigate the impact of various data augmentation\nalgorithms, e.g., oversampling, Gaussian Mixture Models (GMMs) and Generative\nAdversarial Networks (GANs), on solving the class imbalance problem. These\nalgorithms are quantitatively and qualitatively evaluated, compared and\ndiscussed in detail. The results show that deep learning-based AF signal\nclassification methods benefit more from data augmentation using GANs and GMMs,\nthan oversampling. Furthermore, the GAN results in circa $3\\%$ better AF\nclassification accuracy in average while performing comparably to the GMM in\nterms of f1-score.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:08:19 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:45:16 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Hatamian", "Faezeh Nejati", ""], ["Ravikumar", "Nishant", ""], ["Vesal", "Sulaiman", ""], ["Kemeth", "Felix P.", ""], ["Struck", "Matthias", ""], ["Maier", "Andreas", ""]]}, {"id": "2002.02879", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and Pranjul Yadav and Khoa Doan and S. Sathiya\n  Keerthi", "title": "Targeted display advertising: the case of preferential attachment", "comments": "IEEE BigData 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An average adult is exposed to hundreds of digital advertisements daily\n(https://www.mediadynamicsinc.com/uploads/files/PR092214-Note-only-150-Ads-2mk.pdf),\nmaking the digital advertisement industry a classic example of a\nbig-data-driven platform. As such, the ad-tech industry relies on historical\nengagement logs (clicks or purchases) to identify potentially interested users\nfor the advertisement campaign of a partner (a seller who wants to target users\nfor its products). The number of advertisements that are shown for a partner,\nand hence the historical campaign data available for a partner depends upon the\nbudget constraints of the partner. Thus, enough data can be collected for the\nhigh-budget partners to make accurate predictions, while this is not the case\nwith the low-budget partners. This skewed distribution of the data leads to\n\"preferential attachment\" of the targeted display advertising platforms towards\nthe high-budget partners. In this paper, we develop \"domain-adaptation\"\napproaches to address the challenge of predicting interested users for the\npartners with insufficient data, i.e., the tail partners. Specifically, we\ndevelop simple yet effective approaches that leverage the similarity among the\npartners to transfer information from the partners with sufficient data to\ncold-start partners, i.e., partners without any campaign data. Our approaches\nreadily adapt to the new campaign data by incremental fine-tuning, and hence\nwork at varying points of a campaign, and not just the cold-start. We present\nan experimental analysis on the historical logs of a major display advertising\nplatform (https://www.criteo.com/). Specifically, we evaluate our approaches\nacross 149 partners, at varying points of their campaigns. Experimental results\nshow that the proposed approaches outperform the other \"domain-adaptation\"\napproaches at different time points of the campaigns.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:23:17 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Manchanda", "Saurav", ""], ["Yadav", "Pranjul", ""], ["Doan", "Khoa", ""], ["Keerthi", "S. Sathiya", ""]]}, {"id": "2002.02881", "submitter": "Thomas O'Leary-Roseberry", "authors": "Thomas O'Leary-Roseberry, Nick Alger, Omar Ghattas", "title": "Low Rank Saddle Free Newton: Scalable Stochastic Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newton methods have fallen out of favor for modern optimization problems\n(e.g. deep learning) because of concerns about per-iteration computational\ncomplexity. In this setting highly subsampled first order methods are\npreferred. In this work we motivate the extension of Newton methods to the\nhighly stochastic regime, and argue for the use of the scalable low rank saddle\nfree Newton (LRSFN) method. In this setting, iterative updates are dominated by\nstochastic noise, and stability of the method is key. In stability analysis, we\ndemonstrate that stochastic errors for Newton methods can be greatly amplified\nby ill-conditioned matrix operators. The LRSFN algorithm mitigates this issue\nby the use of Levenberg-Marquardt damping, but generally second order methods\nwith stochastic Hessian and gradient information may need to take small steps,\nunlike in deterministic problems. Numerical results show that even under\nrestrictive step-length conditions, LRSFN can outperform popular first order\nmethods on nontrivial deep learning tasks in terms of generalizability for\nequivalent computational work.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:33:31 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 01:44:10 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["O'Leary-Roseberry", "Thomas", ""], ["Alger", "Nick", ""], ["Ghattas", "Omar", ""]]}, {"id": "2002.02882", "submitter": "Thomas O'Leary-Roseberry", "authors": "Thomas O'Leary-Roseberry, Omar Ghattas", "title": "Ill-Posedness and Optimization Geometry for Nonlinear Neural Network\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we analyze the role nonlinear activation functions play at\nstationary points of dense neural network training problems. We consider a\ngeneric least squares loss function training formulation. We show that the\nnonlinear activation functions used in the network construction play a critical\nrole in classifying stationary points of the loss landscape. We show that for\nshallow dense networks, the nonlinear activation function determines the\nHessian nullspace in the vicinity of global minima (if they exist), and\ntherefore determines the ill-posedness of the training problem. Furthermore,\nfor shallow nonlinear networks we show that the zeros of the activation\nfunction and its derivatives can lead to spurious local minima, and discuss\nconditions for strict saddle points. We extend these results to deep dense\nneural networks, showing that the last activation function plays an important\nrole in classifying stationary points, due to how it shows up in the gradient\nfrom the chain rule.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:33:34 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["O'Leary-Roseberry", "Thomas", ""], ["Ghattas", "Omar", ""]]}, {"id": "2002.02883", "submitter": "Roger David Soberanis-Mukul", "authors": "Maxime Kayser, Roger D. Soberanis-Mukul, Anna-Maria Zvereva (M.D.),\n  Peter Klare (M.D.), Nassir Navab, Shadi Albarqouni", "title": "Understanding the effects of artifacts on automated polyp detection and\n  incorporating that knowledge via learning without forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival rates for colorectal cancer are higher when polyps are detected at\nan early stage and can be removed before they develop into malignant tumors.\nAutomated polyp detection, which is dominated by deep learning based methods,\nseeks to improve early detection of polyps. However, current efforts rely\nheavily on the size and quality of the training datasets. The quality of these\ndatasets often suffers from various image artifacts that affect the visibility\nand hence, the detection rate. In this work, we conducted a systematic analysis\nto gain a better understanding of how artifacts affect automated polyp\ndetection. We look at how six different artifact classes, and their location in\nan image, affect the performance of a RetinaNet based polyp detection model. We\nfound that, depending on the artifact class, they can either benefit or harm\nthe polyp detector. For instance, bubbles are often misclassified as polyps,\nwhile specular reflections inside of a polyp region can improve detection\ncapabilities. We then investigated different strategies, such as a learning\nwithout forgetting framework, to leverage artifact knowledge to improve\nautomated polyp detection. Our results show that such models can mitigate some\nof the harmful effects of artifacts, but require more work to significantly\nimprove polyp detection capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:34:14 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:54:17 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 09:57:26 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Kayser", "Maxime", "", "M.D."], ["Soberanis-Mukul", "Roger D.", "", "M.D."], ["Zvereva", "Anna-Maria", "", "M.D."], ["Klare", "Peter", "", "M.D."], ["Navab", "Nassir", ""], ["Albarqouni", "Shadi", ""]]}, {"id": "2002.02884", "submitter": "Mark Santolucito", "authors": "Kairo Morton, William Hallahan, Elven Shum, Ruzica Piskac, Mark\n  Santolucito", "title": "Grammar Filtering For Syntax-Guided Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming-by-example (PBE) is a synthesis paradigm that allows users to\ngenerate functions by simply providing input-output examples. While a promising\ninteraction paradigm, synthesis is still too slow for realtime interaction and\nmore widespread adoption. Existing approaches to PBE synthesis have used\nautomated reasoning tools, such as SMT solvers, as well as works applying\nmachine learning techniques. At its core, the automated reasoning approach\nrelies on highly domain specific knowledge of programming languages. On the\nother hand, the machine learning approaches utilize the fact that when working\nwith program code, it is possible to generate arbitrarily large training\ndatasets. In this work, we propose a system for using machine learning in\ntandem with automated reasoning techniques to solve Syntax Guided Synthesis\n(SyGuS) style PBE problems. By preprocessing SyGuS PBE problems with a neural\nnetwork, we can use a data driven approach to reduce the size of the search\nspace, then allow automated reasoning-based solvers to more quickly find a\nsolution analytically. Our system is able to run atop existing SyGuS PBE\nsynthesis tools, decreasing the runtime of the winner of the 2019 SyGuS\nCompetition for the PBE Strings track by 47.65% to outperform all of the\ncompeting tools.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:35:50 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Morton", "Kairo", ""], ["Hallahan", "William", ""], ["Shum", "Elven", ""], ["Piskac", "Ruzica", ""], ["Santolucito", "Mark", ""]]}, {"id": "2002.02885", "submitter": "Rui Liu", "authors": "Rui Liu, Sanjay Krishnan, Aaron J. Elmore, Michael J. Franklin", "title": "Understanding and Optimizing Packed Neural Network Training for\n  Hyper-Parameter Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks are increasingly employed in machine learning practice,\nhow to efficiently share limited training resources among a diverse set of\nmodel training tasks becomes a crucial issue. To achieve better utilization of\nthe shared resources, we explore the idea of jointly training multiple neural\nnetwork models on a single GPU in this paper. We realize this idea by proposing\na primitive, called pack. We further present a comprehensive empirical study of\npack and end-to-end experiments that suggest significant improvements for\nhyperparameter tuning. The results suggest: (1) packing two models can bring up\nto 40% performance improvement over unpacked setups for a single training step\nand the improvement increases when packing more models; (2) the benefit of the\npack primitive largely depends on a number of factors including memory\ncapacity, chip architecture, neural network structure, and batch size; (3)\nthere exists a trade-off between packing and unpacking when training multiple\nneural network models on limited resources; (4) a pack-aware Hyperband is up to\n2.7x faster than the original Hyperband, with this improvement growing as\nmemory size increases and subsequently the density of models packed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:36:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 02:54:36 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 22:07:33 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 02:31:03 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liu", "Rui", ""], ["Krishnan", "Sanjay", ""], ["Elmore", "Aaron J.", ""], ["Franklin", "Michael J.", ""]]}, {"id": "2002.02886", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Ben Poole, Gunnar R\\\"atsch, Bernhard Sch\\\"olkopf,\n  Olivier Bachem, Michael Tschannen", "title": "Weakly-Supervised Disentanglement Without Compromises", "comments": "We updated the description of the generation of the dataset compared\n  to the ICML version", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent agents should be able to learn useful representations by\nobserving changes in their environment. We model such observations as pairs of\nnon-i.i.d. images sharing at least one of the underlying factors of variation.\nFirst, we theoretically show that only knowing how many factors have changed,\nbut not which ones, is sufficient to learn disentangled representations.\nSecond, we provide practical algorithms that learn disentangled representations\nfrom pairs of images without requiring annotation of groups, individual\nfactors, or the number of factors that have changed. Third, we perform a\nlarge-scale empirical study and show that such pairs of observations are\nsufficient to reliably learn disentangled representations on several benchmark\ndata sets. Finally, we evaluate our learned representations and find that they\nare simultaneously useful on a diverse suite of tasks, including generalization\nunder covariate shifts, fairness, and abstract reasoning. Overall, our results\ndemonstrate that weak supervision enables learning of useful disentangled\nrepresentations in realistic scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:39:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 20:58:49 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 15:24:40 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 15:22:16 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Locatello", "Francesco", ""], ["Poole", "Ben", ""], ["R\u00e4tsch", "Gunnar", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bachem", "Olivier", ""], ["Tschannen", "Michael", ""]]}, {"id": "2002.02887", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio", "title": "Meta-learning framework with applications to zero-shot time-series\n  forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can meta-learning discover generic ways of processing time series (TS) from a\ndiverse dataset so as to greatly improve generalization on new TS coming from\ndifferent datasets? This work provides positive evidence to this using a broad\nmeta-learning framework which we show subsumes many existing meta-learning\nalgorithms. Our theoretical analysis suggests that residual connections act as\na meta-learning adaptation mechanism, generating a subset of task-specific\nparameters based on a given TS input, thus gradually expanding the expressive\npower of the architecture on-the-fly. The same mechanism is shown via\nlinearization analysis to have the interpretation of a sequential update of the\nfinal linear layer. Our empirical results on a wide range of data emphasize the\nimportance of the identified meta-learning mechanisms for successful zero-shot\nunivariate forecasting, suggesting that it is viable to train a neural network\non a source TS dataset and deploy it on a different target TS dataset without\nretraining, resulting in performance that is at least as good as that of\nstate-of-practice univariate forecasting models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:39:43 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 02:42:54 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2020 19:33:05 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Carpov", "Dmitri", ""], ["Chapados", "Nicolas", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.02892", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven, Samuel Vaiter", "title": "Sparse and Smooth: improved guarantees for Spectral Clustering in the\n  Dynamic Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyse classical variants of the Spectral Clustering (SC)\nalgorithm in the Dynamic Stochastic Block Model (DSBM). Existing results show\nthat, in the relatively sparse case where the expected degree grows\nlogarithmically with the number of nodes, guarantees in the static case can be\nextended to the dynamic case and yield improved error bounds when the DSBM is\nsufficiently smooth in time, that is, the communities do not change too much\nbetween two time steps. We improve over these results by drawing a new link\nbetween the sparsity and the smoothness of the DSBM: the more regular the DSBM\nis, the more sparse it can be, while still guaranteeing consistent recovery. In\nparticular, a mild condition on the smoothness allows to treat the sparse case\nwith bounded degree. We also extend these guarantees to the normalized\nLaplacian, and as a by-product of our analysis, we obtain to our knowledge the\nbest spectral concentration bound available for the normalized Laplacian of\nmatrices with independent Bernoulli entries.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:49:25 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 15:46:24 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Keriven", "Nicolas", ""], ["Vaiter", "Samuel", ""]]}, {"id": "2002.02897", "submitter": "Yu Zhang", "authors": "Yu Zhang, Tao Gu, Xi Zhang", "title": "MDLdroid: a ChainSGD-reduce Approach to Mobile Deep Learning for\n  Personal Mobile Sensing", "comments": "Published in the International Conference on Information Processing\n  in Sensor Networks (IPSN), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal mobile sensing is fast permeating our daily lives to enable activity\nmonitoring, healthcare and rehabilitation. Combined with deep learning, these\napplications have achieved significant success in recent years. Different from\nconventional cloud-based paradigms, running deep learning on devices offers\nseveral advantages including data privacy preservation and low-latency response\nfor both model inference and update. Since data collection is costly in\nreality, Google's Federated Learning offers not only complete data privacy but\nalso better model robustness based on multiple user data. However, personal\nmobile sensing applications are mostly user-specific and highly affected by\nenvironment. As a result, continuous local changes may seriously affect the\nperformance of a global model generated by Federated Learning. In addition,\ndeploying Federated Learning on a local server, e.g., edge server, may quickly\nreach the bottleneck due to resource constraint and serious failure by attacks.\nTowards pushing deep learning on devices, we present MDLdroid, a novel\ndecentralized mobile deep learning framework to enable resource-aware on-device\ncollaborative learning for personal mobile sensing applications. To address\nresource limitation, we propose a ChainSGD-reduce approach which includes a\nnovel chain-directed Synchronous Stochastic Gradient Descent algorithm to\neffectively reduce overhead among multiple devices. We also design an\nagent-based multi-goal reinforcement learning mechanism to balance resources in\na fair and efficient manner. Our evaluations show that our model training on\noff-the-shelf mobile devices achieves 2x to 3.5x faster than single-device\ntraining, and 1.5x faster than the master-slave approach.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:55:21 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 14:34:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zhang", "Yu", ""], ["Gu", "Tao", ""], ["Zhang", "Xi", ""]]}, {"id": "2002.02901", "submitter": "Azadeh Khaleghi", "authors": "Steffen Gr\\\"unew\\\"alder and Azadeh Khaleghi", "title": "Oblivious Data for Fairness with Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of algorithmic fairness in the case where\nsensitive and non-sensitive features are available and one aims to generate\nnew, `oblivious', features that closely approximate the non-sensitive features,\nand are only minimally dependent on the sensitive ones. We study this question\nin the context of kernel methods. We analyze a relaxed version of the Maximum\nMean Discrepancy criterion which does not guarantee full independence but makes\nthe optimization problem tractable. We derive a closed-form solution for this\nrelaxed optimization problem and complement the result with a study of the\ndependencies between the newly generated features and the sensitive ones. Our\nkey ingredient for generating such oblivious features is a Hilbert-space-valued\nconditional expectation, which needs to be estimated from data. We propose a\nplug-in approach and demonstrate how the estimation errors can be controlled.\nWhile our techniques help reduce the bias, we would like to point out that no\npost-processing of any dataset could possibly serve as an alternative to\nwell-designed experiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 16:59:24 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 19:44:18 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Gr\u00fcnew\u00e4lder", "Steffen", ""], ["Khaleghi", "Azadeh", ""]]}, {"id": "2002.02903", "submitter": "Yiying Fan", "authors": "Yiying Fan and Jiayang Sun", "title": "Subsampling Winner Algorithm for Feature Selection in Large Regression\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection from a large number of covariates (aka features) in a\nregression analysis remains a challenge in data science, especially in terms of\nits potential of scaling to ever-enlarging data and finding a group of\nscientifically meaningful features. For example, to develop new, responsive\ndrug targets for ovarian cancer, the actual false discovery rate (FDR) of a\npractical feature selection procedure must also match the target FDR. The\npopular approach to feature selection, when true features are sparse, is to use\na penalized likelihood or a shrinkage estimation, such as a LASSO, SCAD,\nElastic Net, or MCP procedure (call them benchmark procedures). We present a\ndifferent approach using a new subsampling method, called the Subsampling\nWinner algorithm (SWA). The central idea of SWA is analogous to that used for\nthe selection of US national merit scholars. SWA uses a \"base procedure\" to\nanalyze each of the subsamples, computes the scores of all features according\nto the performance of each feature from all subsample analyses, obtains the\n\"semifinalist\" based on the resulting scores, and then determines the\n\"finalists,\" i.e., the most important features. Due to its subsampling nature,\nSWA can scale to data of any dimension in principle. The SWA also has the\nbest-controlled actual FDR in comparison with the benchmark procedures and the\nrandomForest, while having a competitive true-feature discovery rate. We also\nsuggest practical add-on strategies to SWA with or without a penalized\nbenchmark procedure to further assure the chance of \"true\" discovery. Our\napplication of SWA to the ovarian serous cystadenocarcinoma specimens from the\nBroad Institute revealed functionally important genes and pathways, which we\nverified by additional genomics tools. This second-stage investigation is\nessential in the current discussion of the proper use of P-values.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:01:59 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Fan", "Yiying", ""], ["Sun", "Jiayang", ""]]}, {"id": "2002.02909", "submitter": "Bin Kong", "authors": "Xian Zhang, Xin Wang, Bin Kong, Canghong Shi, Youbing Yin, Qi Song,\n  Siwei Lyu, Jiancheng Lv, Canghong Shi, Xiaojie Li", "title": "Domain Embedded Multi-model Generative Adversarial Networks for\n  Image-based Face Inpainting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior knowledge of face shape and structure plays an important role in face\ninpainting. However, traditional face inpainting methods mainly focus on the\ngenerated image resolution of the missing portion without consideration of the\nspecial particularities of the human face explicitly and generally produce\ndiscordant facial parts. To solve this problem, we present a domain embedded\nmulti-model generative adversarial model for inpainting of face images with\nlarge cropped regions. We firstly represent only face regions using the latent\nvariable as the domain knowledge and combine it with the non-face parts\ntextures to generate high-quality face images with plausible contents. Two\nadversarial discriminators are finally used to judge whether the generated\ndistribution is close to the real distribution or not. It can not only\nsynthesize novel image structures but also explicitly utilize the embedded face\ndomain knowledge to generate better predictions with consistency on structures\nand appearance. Experiments on both CelebA and CelebA-HQ face datasets\ndemonstrate that our proposed approach achieved state-of-the-art performance\nand generates higher quality inpainting results than existing ones.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 17:36:13 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 05:47:05 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhang", "Xian", ""], ["Wang", "Xin", ""], ["Kong", "Bin", ""], ["Shi", "Canghong", ""], ["Yin", "Youbing", ""], ["Song", "Qi", ""], ["Lyu", "Siwei", ""], ["Lv", "Jiancheng", ""], ["Shi", "Canghong", ""], ["Li", "Xiaojie", ""]]}, {"id": "2002.02912", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh", "title": "Universal Equivariant Multilayer Perceptrons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group invariant and equivariant Multilayer Perceptrons (MLP), also known as\nEquivariant Networks, have achieved remarkable success in learning on a variety\nof data structures, such as sequences, images, sets, and graphs. Using tools\nfrom group theory, this paper proves the universality of a broad class of\nequivariant MLPs with a single hidden layer. In particular, it is shown that\nhaving a hidden layer on which the group acts regularly is sufficient for\nuniversal equivariance (invariance). A corollary is unconditional universality\nof equivariant MLPs for Abelian groups, such as CNNs with a single hidden\nlayer. A second corollary is the universality of equivariant MLPs with a\nhigh-order hidden layer, where we give both group-agnostic bounds and means for\ncalculating group-specific bounds on the order of hidden layer that guarantees\nuniversal equivariance (invariance).\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:25:59 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 22:28:22 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ravanbakhsh", "Siamak", ""]]}, {"id": "2002.02913", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Dixin Luo, Ricardo Henao, Svati Shah, Lawrence Carin", "title": "Learning Autoencoders with Relational Regularization", "comments": null, "journal-ref": "International conference on machine learning 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new algorithmic framework is proposed for learning autoencoders of data\ndistributions. We minimize the discrepancy between the model and target\ndistributions, with a \\emph{relational regularization} on the learnable latent\nprior. This regularization penalizes the fused Gromov-Wasserstein (FGW)\ndistance between the latent prior and its corresponding posterior, allowing one\nto flexibly learn a structured prior distribution associated with the\ngenerative model. Moreover, it helps co-training of multiple autoencoders even\nif they have heterogeneous architectures and incomparable latent spaces. We\nimplement the framework with two scalable algorithms, making it applicable for\nboth probabilistic and deterministic autoencoders. Our relational regularized\nautoencoder (RAE) outperforms existing methods, $e.g.$, the variational\nautoencoder, Wasserstein autoencoder, and their variants, on generating images.\nAdditionally, our relational co-training strategy for autoencoders achieves\nencouraging results in both synthesis and real-world multi-view learning tasks.\nThe code is at https://github.com/HongtengXu/ Relational-AutoEncoders.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:27:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:46:10 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 01:40:48 GMT"}, {"version": "v4", "created": "Fri, 26 Jun 2020 01:05:36 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Xu", "Hongteng", ""], ["Luo", "Dixin", ""], ["Henao", "Ricardo", ""], ["Shah", "Svati", ""], ["Carin", "Lawrence", ""]]}, {"id": "2002.02917", "submitter": "Sharon Zhou", "authors": "Sharon Zhou, Jiequan Zhang, Hang Jiang, Torbjorn Lundh, Andrew Y. Ng", "title": "Data augmentation with Mobius transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has led to substantial improvements in the performance and\ngeneralization of deep models, and remain a highly adaptable method to evolving\nmodel architectures and varying amounts of data---in particular, extremely\nscarce amounts of available training data. In this paper, we present a novel\nmethod of applying Mobius transformations to augment input images during\ntraining. Mobius transformations are bijective conformal maps that generalize\nimage translation to operate over complex inversion in pixel space. As a\nresult, Mobius transformations can operate on the sample level and preserve\ndata labels. We show that the inclusion of Mobius transformations during\ntraining enables improved generalization over prior sample-level data\naugmentation techniques such as cutout and standard crop-and-flip\ntransformations, most notably in low data regimes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:45:39 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 08:00:04 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhou", "Sharon", ""], ["Zhang", "Jiequan", ""], ["Jiang", "Hang", ""], ["Lundh", "Torbjorn", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "2002.02919", "submitter": "Qifan Song", "authors": "Qifan Song, Yan Sun, Mao Ye, Faming Liang", "title": "Extended Stochastic Gradient MCMC for Large-Scale Bayesian Variable\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (MCMC) algorithms have received\nmuch attention in Bayesian computing for big data problems, but they are only\napplicable to a small class of problems for which the parameter space has a\nfixed dimension and the log-posterior density is differentiable with respect to\nthe parameters. This paper proposes an extended stochastic gradient MCMC\nlgoriathm which, by introducing appropriate latent variables, can be applied to\nmore general large-scale Bayesian computing problems, such as those involving\ndimension jumping and missing data. Numerical studies show that the proposed\nalgorithm is highly scalable and much more efficient than traditional MCMC\nalgorithms. The proposed algorithms have much alleviated the pain of Bayesian\nmethods in big data computing.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:47:07 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Song", "Qifan", ""], ["Sun", "Yan", ""], ["Ye", "Mao", ""], ["Liang", "Faming", ""]]}, {"id": "2002.02921", "submitter": "Yidan Qin", "authors": "Yidan Qin, Sahba Aghajani Pedram, Seyedshams Feyzabadi, Max Allan, A.\n  Jonathan McLeod, Joel W. Burdick, Mahdi Azizian", "title": "Temporal Segmentation of Surgical Sub-tasks through Deep Learning with\n  Multiple Data Sources", "comments": "Accepted to ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in robot-assisted surgeries (RAS) can be represented by\nfinite-state machines (FSMs), where each state represents either an action\n(such as picking up a needle) or an observation (such as bleeding). A crucial\nstep towards the automation of such surgical tasks is the temporal perception\nof the current surgical scene, which requires a real-time estimation of the\nstates in the FSMs. The objective of this work is to estimate the current state\nof the surgical task based on the actions performed or events occurred as the\ntask progresses. We propose Fusion-KVE, a unified surgical state estimation\nmodel that incorporates multiple data sources including the Kinematics, Vision,\nand system Events. Additionally, we examine the strengths and weaknesses of\ndifferent state estimation models in segmenting states with different\nrepresentative features or levels of granularity. We evaluate our model on the\nJHU-ISI Gesture and Skill Assessment Working Set (JIGSAWS), as well as a more\ncomplex dataset involving robotic intra-operative ultrasound (RIOUS) imaging,\ncreated using the da Vinci Xi surgical system. Our model achieves a superior\nframe-wise state estimation accuracy up to 89.4%, which improves the\nstate-of-the-art surgical state estimation models in both JIGSAWS suturing\ndataset and our RIOUS dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:49:08 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Qin", "Yidan", ""], ["Pedram", "Sahba Aghajani", ""], ["Feyzabadi", "Seyedshams", ""], ["Allan", "Max", ""], ["McLeod", "A. Jonathan", ""], ["Burdick", "Joel W.", ""], ["Azizian", "Mahdi", ""]]}, {"id": "2002.02923", "submitter": "David Alvarez-Melis", "authors": "David Alvarez-Melis and Nicol\\`o Fusi", "title": "Geometric Dataset Distances via Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of task similarity is at the core of various machine learning\nparadigms, such as domain adaptation and meta-learning. Current methods to\nquantify it are often heuristic, make strong assumptions on the label sets\nacross the tasks, and many are architecture-dependent, relying on task-specific\noptimal parameters (e.g., require training a model on each dataset). In this\nwork we propose an alternative notion of distance between datasets that (i) is\nmodel-agnostic, (ii) does not involve training, (iii) can compare datasets even\nif their label sets are completely disjoint and (iv) has solid theoretical\nfooting. This distance relies on optimal transport, which provides it with rich\ngeometry awareness, interpretable correspondences and well-understood\nproperties. Our results show that this novel distance provides meaningful\ncomparison of datasets, and correlates well with transfer learning hardness\nacross various experimental settings and datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:51:26 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Alvarez-Melis", "David", ""], ["Fusi", "Nicol\u00f2", ""]]}, {"id": "2002.02925", "submitter": "Canwen Xu", "authors": "Canwen Xu and Wangchunshu Zhou and Tao Ge and Furu Wei and Ming Zhou", "title": "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel model compression approach to effectively\ncompress BERT by progressive module replacing. Our approach first divides the\noriginal BERT into several modules and builds their compact substitutes. Then,\nwe randomly replace the original modules with their substitutes to train the\ncompact modules to mimic the behavior of the original modules. We progressively\nincrease the probability of replacement through the training. In this way, our\napproach brings a deeper level of interaction between the original and compact\nmodels. Compared to the previous knowledge distillation approaches for BERT\ncompression, our approach does not introduce any additional loss function. Our\napproach outperforms existing knowledge distillation approaches on GLUE\nbenchmark, showing a new perspective of model compression.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 17:52:16 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 18:45:41 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 15:20:44 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 12:18:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Xu", "Canwen", ""], ["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.02948", "submitter": "David E. Shaw", "authors": "Paul Maragakis, Hunter Nisonoff, Brian Cole, and David E. Shaw", "title": "A deep-learning view of chemical space designed to facilitate drug\n  discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery projects entail cycles of design, synthesis, and testing that\nyield a series of chemically related small molecules whose properties, such as\nbinding affinity to a given target protein, are progressively tailored to a\nparticular drug discovery goal. The use of deep learning technologies could\naugment the typical practice of using human intuition in the design cycle, and\nthereby expedite drug discovery projects. Here we present DESMILES, a deep\nneural network model that advances the state of the art in machine learning\napproaches to molecular design. We applied DESMILES to a previously published\nbenchmark that assesses the ability of a method to modify input molecules to\ninhibit the dopamine receptor D2, and DESMILES yielded a 77% lower failure rate\ncompared to state-of-the-art models. To explain the ability of DESMILES to hone\nmolecular properties, we visualize a layer of the DESMILES network, and further\ndemonstrate this ability by using DESMILES to tailor the same molecules used in\nthe D2 benchmark test to dock more potently against seven different receptors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:32:44 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Maragakis", "Paul", ""], ["Nisonoff", "Hunter", ""], ["Cole", "Brian", ""], ["Shaw", "David E.", ""]]}, {"id": "2002.02949", "submitter": "Priyadarshini Panda", "authors": "Timothy Foldy-Porto, Yeshwanth Venkatesha, and Priyadarshini Panda", "title": "Activation Density driven Energy-Efficient Pruning in Training", "comments": "8 pages, 5 figures, 4 tables (Accepted in ICPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning with suitable retraining can yield networks with\nconsiderably fewer parameters than the original with comparable degrees of\naccuracy. Typical pruning methods require large, fully trained networks as a\nstarting point from which they perform a time-intensive iterative pruning and\nretraining procedure to regain the original accuracy. We propose a novel\npruning method that prunes a network real-time during training, reducing the\noverall training time to achieve an efficient compressed network. We introduce\nan activation density based analysis to identify the optimal relative sizing or\ncompression for each layer of the network. Our method is architecture agnostic,\nallowing it to be employed on a wide variety of systems. For VGG-19 and\nResNet18 on CIFAR-10, CIFAR-100, and TinyImageNet, we obtain exceedingly sparse\nnetworks (up to $200 \\times$ reduction in parameters and over $60 \\times$\nreduction in inference compute operations in the best case) with accuracy\ncomparable to the baseline network. By reducing the network size periodically\nduring training, we achieve total training times that are shorter than those of\npreviously proposed pruning methods. Furthermore, training compressed networks\nat different epochs with our proposed method yields considerable reduction in\ntraining compute complexity ($1.6\\times$ to $3.2\\times$ lower) at near\niso-accuracy as compared to a baseline network trained entirely from scratch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:34:31 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 12:16:25 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Foldy-Porto", "Timothy", ""], ["Venkatesha", "Yeshwanth", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2002.02950", "submitter": "Gil Shamir", "authors": "Gil I. Shamir", "title": "Logistic Regression Regret: What's the Catch?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of the achievable regret rates with online logistic\nregression. We derive lower bounds with logarithmic regret under $L_1$, $L_2$,\nand $L_\\infty$ constraints on the parameter values. The bounds are dominated by\n$d/2 \\log T$, where $T$ is the horizon and $d$ is the dimensionality of the\nparameter space. We show their achievability for $d=o(T^{1/3})$ in all these\ncases with Bayesian methods, that achieve them up to a $d/2 \\log d$ term.\nInteresting different behaviors are shown for larger dimensionality.\nSpecifically, on the negative side, if $d = \\Omega(\\sqrt{T})$, any algorithm is\nguaranteed regret of $\\Omega(d \\log T)$ (greater than $\\Omega(\\sqrt{T})$) under\n$L_\\infty$ constraints on the parameters (and the example features). On the\npositive side, under $L_1$ constraints on the parameters, there exist\nalgorithms that can achieve regret that is sub-linear in $d$ for the\nasymptotically larger values of $d$. For $L_2$ constraints, it is shown that\nfor large enough $d$, the regret remains linear in $d$ but no longer\nlogarithmic in $T$. Adapting the redundancy-capacity theorem from information\ntheory, we demonstrate a principled methodology based on grids of parameters to\nderive lower bounds. Grids are also utilized to derive some upper bounds. Our\nresults strengthen results by Kakade and Ng (2005) and Foster et al. (2018) for\nupper bounds for this problem, introduce novel lower bounds, and adapt a\nmethodology that can be used to obtain such bounds for other related problems.\nThey also give a novel characterization of the asymptotic behavior when the\ndimension of the parameter space is allowed to grow with $T$. They additionally\nestablish connections to the information theory literature, demonstrating that\nthe actual regret for logistic regression depends on the richness of the\nparameter class, where even within this problem, richer classes lead to greater\nregret.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:36:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:27:53 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Shamir", "Gil I.", ""]]}, {"id": "2002.02959", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed, Prajit Ramachandran, Jonathon Shlens, Simon\n  Kornblith", "title": "Revisiting Spatial Invariance with Low-Rank Local Connectivity", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are among the most successful architectures in\ndeep learning with this success at least partially attributable to the efficacy\nof spatial invariance as an inductive bias. Locally connected layers, which\ndiffer from convolutional layers only in their lack of spatial invariance,\nusually perform poorly in practice. However, these observations still leave\nopen the possibility that some degree of relaxation of spatial invariance may\nyield a better inductive bias than either convolution or local connectivity. To\ntest this hypothesis, we design a method to relax the spatial invariance of a\nnetwork layer in a controlled manner; we create a \\textit{low-rank} locally\nconnected layer, where the filter bank applied at each position is constructed\nas a linear combination of basis set of filter banks with spatially varying\ncombining weights. By varying the number of basis filter banks, we can control\nthe degree of relaxation of spatial invariance. In experiments with small\nconvolutional networks, we find that relaxing spatial invariance improves\nclassification accuracy over both convolution and locally connected layers\nacross MNIST, CIFAR-10, and CelebA datasets, thus suggesting that spatial\ninvariance may be an overly restrictive prior.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:56:37 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:45:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Ramachandran", "Prajit", ""], ["Shlens", "Jonathon", ""], ["Kornblith", "Simon", ""]]}, {"id": "2002.02991", "submitter": "Zhibin Li PhD", "authors": "Chuanyu Yang, Kai Yuan, Wolfgang Merkt, Taku Komura, Sethu\n  Vijayakumar, Zhibin Li", "title": "Learning Whole-body Motor Skills for Humanoids", "comments": "2018 IEEE-RAS 18th International Conference on Humanoid Robots\n  (Humanoids)", "journal-ref": null, "doi": "10.1109/HUMANOIDS.2018.8625045", "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a hierarchical framework for Deep Reinforcement Learning\nthat acquires motor skills for a variety of push recovery and balancing\nbehaviors, i.e., ankle, hip, foot tilting, and stepping strategies. The policy\nis trained in a physics simulator with realistic setting of robot model and\nlow-level impedance control that are easy to transfer the learned skills to\nreal robots. The advantage over traditional methods is the integration of\nhigh-level planner and feedback control all in one single coherent policy\nnetwork, which is generic for learning versatile balancing and recovery motions\nagainst unknown perturbations at arbitrary locations (e.g., legs, torso).\nFurthermore, the proposed framework allows the policy to be learned quickly by\nmany state-of-the-art learning algorithms. By comparing our learned results to\nstudies of preprogrammed, special-purpose controllers in the literature,\nself-learned skills are comparable in terms of disturbance rejection but with\nadditional advantages of producing a wide range of adaptive, versatile and\nrobust behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 19:40:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yang", "Chuanyu", ""], ["Yuan", "Kai", ""], ["Merkt", "Wolfgang", ""], ["Komura", "Taku", ""], ["Vijayakumar", "Sethu", ""], ["Li", "Zhibin", ""]]}, {"id": "2002.02997", "submitter": "Sergul Aydore", "authors": "Liyan Chen, Philip Gautier, Sergul Aydore", "title": "DropCluster: A structured dropout for convolutional networks", "comments": "11 pages, 10 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout as a regularizer in deep neural networks has been less effective in\nconvolutional layers than in fully connected layers. This is due to the fact\nthat dropout drops features randomly. When features are spatially correlated as\nin the case of convolutional layers, information about the dropped pixels can\nstill propagate to the next layers via neighboring pixels. In order to address\nthis problem, more structured forms of dropout have been proposed. A drawback\nof these methods is that they do not adapt to the data. In this work, we\nintroduce a novel structured regularization for convolutional layers, which we\ncall DropCluster. Our regularizer relies on data-driven structure. It finds\nclusters of correlated features in convolutional layer outputs and drops the\nclusters randomly at each iteration. The clusters are learned and updated\nduring model training so that they adapt both to the data and to the model\nweights. Our experiments on the ResNet-50 architecture demonstrate that our\napproach achieves better performance than DropBlock or other existing\nstructured dropout variants. We also demonstrate the robustness of our approach\nwhen the size of training data is limited and when there is corruption in the\ndata at test time.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:02:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Liyan", ""], ["Gautier", "Philip", ""], ["Aydore", "Sergul", ""]]}, {"id": "2002.02998", "submitter": "Ting-Wu Chin", "authors": "Ting-Wu Chin, Cha Zhang, Diana Marculescu", "title": "Renofeation: A Simple Transfer Learning Method for Improved Adversarial\n  Robustness", "comments": "2021 IEEE CVPR Workshop on Fair, Data Efficient and Trusted Computer\n  Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning through knowledge transfer from a pre-trained model on a\nlarge-scale dataset is a widely spread approach to effectively build models on\nsmall-scale datasets. In this work, we show that a recent adversarial attack\ndesigned for transfer learning via re-training the last linear layer can\nsuccessfully deceive models trained with transfer learning via end-to-end\nfine-tuning. This raises security concerns for many industrial applications. In\ncontrast, models trained with random initialization without transfer are much\nmore robust to such attacks, although these models often exhibit much lower\naccuracy. To this end, we propose noisy feature distillation, a new transfer\nlearning method that trains a network from random initialization while\nachieving clean-data performance competitive with fine-tuning. Code available\nat https://github.com/cmu-enyac/Renofeation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:07:22 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 14:46:56 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Chin", "Ting-Wu", ""], ["Zhang", "Cha", ""], ["Marculescu", "Diana", ""]]}, {"id": "2002.03001", "submitter": "Guannan Zhang", "authors": "Jiaxin Zhang, Hoang Tran, Dan Lu, Guannan Zhang", "title": "A Novel Evolution Strategy with Directional Gaussian Smoothing for\n  Blackbox Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an improved evolution strategy (ES) using a novel nonlocal\ngradient operator for high-dimensional black-box optimization. Standard ES\nmethods with $d$-dimensional Gaussian smoothing suffer from the curse of\ndimensionality due to the high variance of Monte Carlo (MC) based gradient\nestimators. To control the variance, Gaussian smoothing is usually limited in a\nsmall region, so existing ES methods lack nonlocal exploration ability required\nfor escaping from local minima. We develop a nonlocal gradient operator with\ndirectional Gaussian smoothing (DGS) to address this challenge. The DGS\nconducts 1D nonlocal explorations along $d$ orthogonal directions in\n$\\mathbb{R}^d$, each of which defines a nonlocal directional derivative as a 1D\nintegral. We then use Gauss-Hermite quadrature, instead of MC sampling, to\nestimate the $d$ 1D integrals to ensure high accuracy (i.e., small variance).\nOur method enables effective nonlocal exploration to facilitate the global\nsearch in high-dimensional optimization. We demonstrate the superior\nperformance of our method in three sets of examples, including benchmark\nfunctions for global optimization, and real-world science and engineering\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:17:19 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 19:14:44 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Zhang", "Jiaxin", ""], ["Tran", "Hoang", ""], ["Lu", "Dan", ""], ["Zhang", "Guannan", ""]]}, {"id": "2002.03009", "submitter": "Ryan McCarty", "authors": "Ryan J. McCarty, Nimish Ronghe, Mandy Woo, Todd M. Alam", "title": "Blind Source Separation for NMR Spectra with Negative Intensity", "comments": "28 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG physics.chem-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NMR spectral datasets, especially in systems with limited samples, can be\ndifficult to interpret if they contain multiple chemical components (phases,\npolymorphs, molecules, crystals, glasses, etc...) and the possibility of\noverlapping resonances. In this paper, we benchmark several blind source\nseparation techniques for analysis of NMR spectral datasets containing negative\nintensity. For benchmarking purposes, we generated a large synthetic datasbase\nof quadrupolar solid-state NMR-like spectra that model spin-lattice T1\nrelaxation or nutation tip/flip angle experiments. Our benchmarking approach\nfocused exclusively on the ability of blind source separation techniques to\nreproduce the spectra of the underlying pure components. In general, we find\nthat FastICA (Fast Independent Component Analysis), SIMPLISMA\n(SIMPLe-to-use-Interactive Self-modeling Mixture Analysis), and NNMF\n(Non-Negative Matrix Factorization) are top-performing techniques. We\ndemonstrate that dataset normalization approaches prior to blind source\nseparation do not considerably improve outcomes. Within the range of noise\nlevels studied, we did not find drastic changes to the ranking of techniques.\nThe accuracy of FastICA and SIMPLISMA degrades quickly if excess (unreal) pure\ncomponents are predicted. Our results indicate poor performance of SVD\n(Singular Value Decomposition) methods, and we propose alternative techniques\nfor matrix initialization. The benchmarked techniques are also applied to real\nsolid state NMR datasets. In general, the recommendations from the synthetic\ndatasets agree with the recommendations and results from the real data\nanalysis. The discussion provides some additional recommendations for\nspectroscopists applying blind source separation to NMR datasets, and for\nfuture benchmark studies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 20:57:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["McCarty", "Ryan J.", ""], ["Ronghe", "Nimish", ""], ["Woo", "Mandy", ""], ["Alam", "Todd M.", ""]]}, {"id": "2002.03014", "submitter": "Benjamin Stevens", "authors": "Ben Stevens, Tim Colonius", "title": "FiniteNet: A Fully Convolutional LSTM Network Architecture for\n  Time-Dependent Partial Differential Equations", "comments": "8 pages, 12 figures. Under review for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA physics.comp-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a machine learning approach for reducing the error\nwhen numerically solving time-dependent partial differential equations (PDE).\nWe use a fully convolutional LSTM network to exploit the spatiotemporal\ndynamics of PDEs. The neural network serves to enhance finite-difference and\nfinite-volume methods (FDM/FVM) that are commonly used to solve PDEs, allowing\nus to maintain guarantees on the order of convergence of our method. We train\nthe network on simulation data, and show that our network can reduce error by a\nfactor of 2 to 3 compared to the baseline algorithms. We demonstrate our method\non three PDEs that each feature qualitatively different dynamics. We look at\nthe linear advection equation, which propagates its initial conditions at a\nconstant speed, the inviscid Burgers' equation, which develops shockwaves, and\nthe Kuramoto-Sivashinsky (KS) equation, which is chaotic.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:18:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Stevens", "Ben", ""], ["Colonius", "Tim", ""]]}, {"id": "2002.03016", "submitter": "Aaron Kandel", "authors": "Aaron Kandel, Scott J. Moura", "title": "Safe Wasserstein Constrained Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributionally robust Q-Learning algorithm (DrQ)\nwhich leverages Wasserstein ambiguity sets to provide probabilistic\nout-of-sample safety guarantees during online learning. First, we follow past\nwork by separating the constraint functions from the principal objective to\ncreate a hierarchy of machines which estimate the feasible state-action space\nwithin the constrained Markov decision process (CMDP). DrQ works within this\nframework by augmenting constraint costs with tightening offset variables\nobtained through Wasserstein distributionally robust optimization (DRO). These\noffset variables correspond to worst-case distributions of modeling error\ncharacterized by the TD-errors of the constraint Q-functions. This procedure\nallows us to safely approach the nominal constraint boundaries with strong\nprobabilistic safety guarantees. Using a case study of safe lithium-ion battery\nfast charging, we demonstrate dramatic improvements in safety and performance\nrelative to conventional methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:23:46 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 20:08:04 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kandel", "Aaron", ""], ["Moura", "Scott J.", ""]]}, {"id": "2002.03018", "submitter": "Elan Rosenfeld", "authors": "Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, J. Zico Kolter", "title": "Certified Robustness to Label-Flipping Attacks via Randomized Smoothing", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are known to be susceptible to data poisoning\nattacks, where an adversary manipulates the training data to degrade\nperformance of the resulting classifier. In this work, we present a unifying\nview of randomized smoothing over arbitrary functions, and we leverage this\nnovel characterization to propose a new strategy for building classifiers that\nare pointwise-certifiably robust to general data poisoning attacks. As a\nspecific instantiation, we utilize our framework to build linear classifiers\nthat are robust to a strong variant of label flipping, where each test example\nis targeted independently. In other words, for each test point, our classifier\nincludes a certification that its prediction would be the same had some number\nof training labels been changed adversarially. Randomized smoothing has\npreviously been used to guarantee---with high probability---test-time\nrobustness to adversarial manipulation of the input to a classifier; we derive\na variant which provides a deterministic, analytical bound, sidestepping the\nprobabilistic certificates that traditionally result from the sampling\nsubprocedure. Further, we obtain these certified bounds with minimal additional\nruntime complexity over standard classification and no assumptions on the train\nor test distributions. We generalize our results to the multi-class case,\nproviding the first multi-class classification algorithm that is certifiably\nrobust to label-flipping attacks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:28:30 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:16:35 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 03:27:14 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 13:17:30 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Rosenfeld", "Elan", ""], ["Winston", "Ezra", ""], ["Ravikumar", "Pradeep", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.03042", "submitter": "Gilwoo Lee", "authors": "Gilwoo Lee, Brian Hou, Sanjiban Choudhury, Siddhartha S. Srinivasa", "title": "Bayesian Residual Policy Optimization: Scalable Bayesian Reinforcement\n  Learning with Clairvoyant Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informed and robust decision making in the face of uncertainty is critical\nfor robots that perform physical tasks alongside people. We formulate this as\nBayesian Reinforcement Learning over latent Markov Decision Processes (MDPs).\nWhile Bayes-optimality is theoretically the gold standard, existing algorithms\ndo not scale well to continuous state and action spaces. Our proposal builds on\nthe following insight: in the absence of uncertainty, each latent MDP is easier\nto solve. We first obtain an ensemble of experts, one for each latent MDP, and\nfuse their advice to compute a baseline policy. Next, we train a Bayesian\nresidual policy to improve upon the ensemble's recommendation and learn to\nreduce uncertainty. Our algorithm, Bayesian Residual Policy Optimization\n(BRPO), imports the scalability of policy gradient methods and task-specific\nexpert skills. BRPO significantly improves the ensemble of experts and\ndrastically outperforms existing adaptive RL methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 23:10:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lee", "Gilwoo", ""], ["Hou", "Brian", ""], ["Choudhury", "Sanjiban", ""], ["Srinivasa", "Siddhartha S.", ""]]}, {"id": "2002.03043", "submitter": "Goutham Ramakrishnan", "authors": "Goutham Ramakrishnan, Jordan Henkel, Zi Wang, Aws Albarghouthi, Somesh\n  Jha, Thomas Reps", "title": "Semantic Robustness of Models of Source Code", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples - small input\nperturbations that result in incorrect predictions. We study this problem for\nmodels of source code, where we want the network to be robust to source-code\nmodifications that preserve code functionality. (1) We define a powerful\nadversary that can employ sequences of parametric, semantics-preserving program\ntransformations; (2) we show how to perform adversarial training to learn\nmodels robust to such adversaries; (3) we conduct an evaluation on different\nlanguages and architectures, demonstrating significant quantitative gains in\nrobustness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 23:26:17 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:50:05 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Henkel", "Jordan", ""], ["Wang", "Zi", ""], ["Albarghouthi", "Aws", ""], ["Jha", "Somesh", ""], ["Reps", "Thomas", ""]]}, {"id": "2002.03049", "submitter": "Yuliang Li", "authors": "Zhengjie Miao, Yuliang Li, Xiaolan Wang, Wang-Chiew Tan", "title": "Snippext: Semi-supervised Opinion Mining with Augmented Data", "comments": "Accepted to WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380144", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online services are interested in solutions to opinion mining, which is the\nproblem of extracting aspects, opinions, and sentiments from text. One method\nto mine opinions is to leverage the recent success of pre-trained language\nmodels which can be fine-tuned to obtain high-quality extractions from reviews.\nHowever, fine-tuning language models still requires a non-trivial amount of\ntraining data. In this paper, we study the problem of how to significantly\nreduce the amount of labeled training data required in fine-tuning language\nmodels for opinion mining. We describe Snippext, an opinion mining system\ndeveloped over a language model that is fine-tuned through semi-supervised\nlearning with augmented data. A novelty of Snippext is its clever use of a\ntwo-prong approach to achieve state-of-the-art (SOTA) performance with little\nlabeled training data through: (1) data augmentation to automatically generate\nmore labeled training data from existing ones, and (2) a semi-supervised\nlearning technique to leverage the massive amount of unlabeled data in addition\nto the (limited amount of) labeled data. We show with extensive experiments\nthat Snippext performs comparably and can even exceed previous SOTA results on\nseveral opinion mining tasks with only half the training data required.\nFurthermore, it achieves new SOTA results when all training data are leveraged.\nBy comparison to a baseline pipeline, we found that Snippext extracts\nsignificantly more fine-grained opinions which enable new opportunities of\ndownstream applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 23:54:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Miao", "Zhengjie", ""], ["Li", "Yuliang", ""], ["Wang", "Xiaolan", ""], ["Tan", "Wang-Chiew", ""]]}, {"id": "2002.03054", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "Extrapolation Towards Imaginary $0$-Nearest Neighbour and Its Improved\n  Convergence Rate", "comments": "27 pages (with Supplementary Material), 4 figures, NeurIPS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-nearest neighbour ($k$-NN) is one of the simplest and most widely-used\nmethods for supervised classification, that predicts a query's label by taking\nweighted ratio of observed labels of $k$ objects nearest to the query. The\nweights and the parameter $k \\in \\mathbb{N}$ regulate its bias-variance\ntrade-off, and the trade-off implicitly affects the convergence rate of the\nexcess risk for the $k$-NN classifier; several existing studies considered\nselecting optimal $k$ and weights to obtain faster convergence rate. Whereas\n$k$-NN with non-negative weights has been developed widely, it was also proved\nthat negative weights are essential for eradicating the bias terms and\nattaining optimal convergence rate. In this paper, we propose a novel\nmultiscale $k$-NN (MS-$k$-NN), that extrapolates unweighted $k$-NN estimators\nfrom several $k \\ge 1$ values to $k=0$, thus giving an imaginary 0-NN\nestimator. Our method implicitly computes optimal real-valued weights that are\nadaptive to the query and its neighbour points. We theoretically prove that the\nMS-$k$-NN attains the improved rate, which coincides with the existing optimal\nrate under some conditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 00:32:12 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 01:14:14 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "2002.03061", "submitter": "Rui Wang", "authors": "Rui Wang, Robin Walters, Rose Yu", "title": "Incorporating Symmetry into Deep Dynamics Models for Improved\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown deep learning can accelerate the prediction of physical\ndynamics relative to numerical solvers. However, limited physical accuracy and\nan inability to generalize under distributional shift limit its applicability\nto the real world. We propose to improve accuracy and generalization by\nincorporating symmetries into convolutional neural networks. Specifically, we\nemploy a variety of methods each tailored to enforce a different symmetry. Our\nmodels are both theoretically and experimentally robust to distributional shift\nby symmetry group transformations and enjoy favorable sample complexity. We\ndemonstrate the advantage of our approach on a variety of physical dynamics\nincluding Rayleigh B\\'enard convection and real-world ocean currents and\ntemperatures. Compared with image or text applications, our work is a\nsignificant step towards applying equivariant neural networks to\nhigh-dimensional systems with complex dynamics. We open-source our simulation,\ndata, and code at \\url{https://github.com/Rose-STL-Lab/Equivariant-Net}.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:28:17 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 21:29:31 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 15:16:10 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 23:00:39 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Wang", "Rui", ""], ["Walters", "Robin", ""], ["Yu", "Rose", ""]]}, {"id": "2002.03069", "submitter": "Botao Hao", "authors": "Botao Hao, Nevena Lazic, Yasin Abbasi-Yadkori, Pooria Joulani, Csaba\n  Szepesvari", "title": "Adaptive Approximate Policy Iteration", "comments": "Accepted at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free reinforcement learning algorithms combined with value function\napproximation have recently achieved impressive performance in a variety of\napplication domains. However, the theoretical understanding of such algorithms\nis limited, and existing results are largely focused on episodic or discounted\nMarkov decision processes (MDPs). In this work, we present adaptive approximate\npolicy iteration (AAPI), a learning scheme which enjoys a $\\tilde{O}(T^{2/3})$\nregret bound for undiscounted, continuing learning in uniformly ergodic MDPs.\nThis is an improvement over the best existing bound of $\\tilde{O}(T^{3/4})$ for\nthe average-reward case with function approximation. Our algorithm and analysis\nrely on online learning techniques, where value functions are treated as\nlosses. The main technical novelty is the use of a data-dependent adaptive\nlearning rate coupled with a so-called optimistic prediction of upcoming\nlosses. In addition to theoretical guarantees, we demonstrate the advantages of\nour approach empirically on several environments.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:27:03 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 01:25:04 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2020 00:51:31 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 17:01:17 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Hao", "Botao", ""], ["Lazic", "Nevena", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Joulani", "Pooria", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "2002.03072", "submitter": "Theofanis Karaletsos", "authors": "Christian F. Perez, Felipe Petroski Such, Theofanis Karaletsos", "title": "Generalized Hidden Parameter MDPs Transferable Model-based RL in a\n  Handful of Trials", "comments": "paper presented at AAAI 2020 as oral presentation, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is broad interest in creating RL agents that can solve many (related)\ntasks and adapt to new tasks and environments after initial training.\nModel-based RL leverages learned surrogate models that describe dynamics and\nrewards of individual tasks, such that planning in a good surrogate can lead to\ngood control of the true system. Rather than solving each task individually\nfrom scratch, hierarchical models can exploit the fact that tasks are often\nrelated by (unobserved) causal factors of variation in order to achieve\nefficient generalization, as in learning how the mass of an item affects the\nforce required to lift it can generalize to previously unobserved masses. We\npropose Generalized Hidden Parameter MDPs (GHP-MDPs) that describe a family of\nMDPs where both dynamics and reward can change as a function of hidden\nparameters that vary across tasks. The GHP-MDP augments model-based RL with\nlatent variables that capture these hidden parameters, facilitating transfer\nacross tasks. We also explore a variant of the model that incorporates explicit\nlatent structure mirroring the causal factors of variation across tasks (for\ninstance: agent properties, environmental factors, and goals). We\nexperimentally demonstrate state-of-the-art performance and sample-efficiency\non a new challenging MuJoCo task using reward and dynamics latent spaces, while\nbeating a previous state-of-the-art baseline with $>10\\times$ less data. Using\ntest-time inference of the latent variables, our approach generalizes in a\nsingle episode to novel combinations of dynamics and reward, and to novel\nrewards.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:49:33 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Perez", "Christian F.", ""], ["Such", "Felipe Petroski", ""], ["Karaletsos", "Theofanis", ""]]}, {"id": "2002.03073", "submitter": "Yuxing Tang", "authors": "Jia Liang, Yuxing Tang, Youbao Tang, Jing Xiao, Ronald M. Summers", "title": "Bone Suppression on Chest Radiographs With Adversarial Learning", "comments": "Accepted by SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual-energy (DE) chest radiography provides the capability of selectively\nimaging two clinically relevant materials, namely soft tissues, and osseous\nstructures, to better characterize a wide variety of thoracic pathology and\npotentially improve diagnosis in posteroanterior (PA) chest radiographs.\nHowever, DE imaging requires specialized hardware and a higher radiation dose\nthan conventional radiography, and motion artifacts sometimes happen due to\ninvoluntary patient motion. In this work, we learn the mapping between\nconventional radiographs and bone suppressed radiographs. Specifically, we\npropose to utilize two variations of generative adversarial networks (GANs) for\nimage-to-image translation between conventional and bone suppressed radiographs\nobtained by DE imaging technique. We compare the effectiveness of training with\npatient-wisely paired and unpaired radiographs. Experiments show both training\nstrategies yield \"radio-realistic'' radiographs with suppressed bony structures\nand few motion artifacts on a hold-out test set. While training with paired\nimages yields slightly better performance than that of unpaired images when\nmeasuring with two objective image quality metrics, namely Structural\nSimilarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR), training with\nunpaired images demonstrates better generalization ability on unseen\nanteroposterior (AP) radiographs than paired training.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 02:53:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liang", "Jia", ""], ["Tang", "Yuxing", ""], ["Tang", "Youbao", ""], ["Xiao", "Jing", ""], ["Summers", "Ronald M.", ""]]}, {"id": "2002.03079", "submitter": "Tianxiao Shen", "authors": "Tianxiao Shen, Victor Quach, Regina Barzilay, Tommi Jaakkola", "title": "Blank Language Models", "comments": "EMNLP 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Blank Language Model (BLM), a model that generates sequences by\ndynamically creating and filling in blanks. The blanks control which part of\nthe sequence to expand, making BLM ideal for a variety of text editing and\nrewriting tasks. The model can start from a single blank or partially completed\ntext with blanks at specified locations. It iteratively determines which word\nto place in a blank and whether to insert new blanks, and stops generating when\nno blanks are left to fill. BLM can be efficiently trained using a lower bound\nof the marginal data likelihood. On the task of filling missing text snippets,\nBLM significantly outperforms all other baselines in terms of both accuracy and\nfluency. Experiments on style transfer and damaged ancient text restoration\ndemonstrate the potential of this framework for a wide range of applications.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:41:37 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 02:54:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Shen", "Tianxiao", ""], ["Quach", "Victor", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03080", "submitter": "Adam Dziedzic", "authors": "Adam Dziedzic, Sanjay Krishnan", "title": "Analysis of Random Perturbations for Robust Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has extensively shown that randomized perturbations of neural\nnetworks can improve robustness to adversarial attacks. The literature is,\nhowever, lacking a detailed compare-and-contrast of the latest proposals to\nunderstand what classes of perturbations work, when they work, and why they\nwork. We contribute a detailed evaluation that elucidates these questions and\nbenchmarks perturbation based defenses consistently. In particular, we show\nfive main results: (1) all input perturbation defenses, whether random or\ndeterministic, are equivalent in their efficacy, (2) attacks transfer between\nperturbation defenses so the attackers need not know the specific type of\ndefense -- only that it involves perturbations, (3) a tuned sequence of noise\nlayers across a network provides the best empirical robustness, (4)\nperturbation based defenses offer almost no robustness to adaptive attacks\nunless these perturbations are observed during training, and (5) adversarial\nexamples in a close neighborhood of original inputs show an elevated\nsensitivity to perturbations in first and second-order analyses.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:46:07 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:22:31 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 19:56:06 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 19:25:31 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dziedzic", "Adam", ""], ["Krishnan", "Sanjay", ""]]}, {"id": "2002.03082", "submitter": "Nan Jiang", "authors": "Nan Jiang, Sheng Jin, Zhiyao Duan, Changshui Zhang", "title": "RL-Duet: Online Music Accompaniment Generation Using Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep reinforcement learning algorithm for online\naccompaniment generation, with potential for real-time interactive\nhuman-machine duet improvisation. Different from offline music generation and\nharmonization, online music accompaniment requires the algorithm to respond to\nhuman input and generate the machine counterpart in a sequential order. We cast\nthis as a reinforcement learning problem, where the generation agent learns a\npolicy to generate a musical note (action) based on previously generated\ncontext (state). The key of this algorithm is the well-functioning reward\nmodel. Instead of defining it using music composition rules, we learn this\nmodel from monophonic and polyphonic training data. This model considers the\ncompatibility of the machine-generated note with both the machine-generated\ncontext and the human-generated context. Experiments show that this algorithm\nis able to respond to the human part and generate a melodic, harmonic and\ndiverse machine part. Subjective evaluations on preferences show that the\nproposed algorithm generates music pieces of higher quality than the baseline\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:53:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jiang", "Nan", ""], ["Jin", "Sheng", ""], ["Duan", "Zhiyao", ""], ["Zhang", "Changshui", ""]]}, {"id": "2002.03090", "submitter": "Milo\\v{s} Nikoli\\'c", "authors": "Milo\\v{s} Nikoli\\'c, Ghouthi Boukli Hacene, Ciaran Bannon, Alberto\n  Delmas Lascorz, Matthieu Courbariaux, Yoshua Bengio, Vincent Gripon and\n  Andreas Moshovos", "title": "BitPruning: Learning Bitlengths for Aggressive and Accurate Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have demonstrably achieved state-of-the art accuracy using\nlow-bitlength integer quantization, yielding both execution time and energy\nbenefits on existing hardware designs that support short bitlengths. However,\nthe question of finding the minimum bitlength for a desired accuracy remains\nopen. We introduce a training method for minimizing inference bitlength at any\ngranularity while maintaining accuracy. Namely, we propose a regularizer that\npenalizes large bitlength representations throughout the architecture and show\nhow it can be modified to minimize other quantifiable criteria, such as number\nof operations or memory footprint. We demonstrate that our method learns\nthrifty representations while maintaining accuracy. With ImageNet, the method\nproduces an average per layer bitlength of 4.13, 3.76 and 4.36 bits on AlexNet,\nResNet18 and MobileNet V2 respectively, remaining within 2.0%, 0.5% and 0.5% of\nthe base TOP-1 accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 04:58:33 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 20:30:52 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Nikoli\u0107", "Milo\u0161", ""], ["Hacene", "Ghouthi Boukli", ""], ["Bannon", "Ciaran", ""], ["Lascorz", "Alberto Delmas", ""], ["Courbariaux", "Matthieu", ""], ["Bengio", "Yoshua", ""], ["Gripon", "Vincent", ""], ["Moshovos", "Andreas", ""]]}, {"id": "2002.03095", "submitter": "Lu Chen", "authors": "Lu Chen and Wei Xu", "title": "Attacking Optical Character Recognition (OCR) Systems with Adversarial\n  Watermarks", "comments": "9 pages, this http url http://aics.site/AICS2020/AICS20_paper_18.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical character recognition (OCR) is widely applied in real applications\nserving as a key preprocessing tool. The adoption of deep neural network (DNN)\nin OCR results in the vulnerability against adversarial examples which are\ncrafted to mislead the output of the threat model. Different from vanilla\ncolorful images, images of printed text have clear backgrounds usually.\nHowever, adversarial examples generated by most of the existing adversarial\nattacks are unnatural and pollute the background severely. To address this\nissue, we propose a watermark attack method to produce natural distortion that\nis in the disguise of watermarks and evade human eyes' detection. Experimental\nresults show that watermark attacks can yield a set of natural adversarial\nexamples attached with watermarks and attain similar attack performance to the\nstate-of-the-art methods in different attack scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 05:53:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Lu", ""], ["Xu", "Wei", ""]]}, {"id": "2002.03098", "submitter": "Christos Dimitrakakis", "authors": "Hannes Eriksson and Emilio Jorge and Christos Dimitrakakis and\n  Debabrota Basu and Divya Grover", "title": "Inferential Induction: A Novel Framework for Bayesian Reinforcement\n  Learning", "comments": "28 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian reinforcement learning (BRL) offers a decision-theoretic solution\nfor reinforcement learning. While \"model-based\" BRL algorithms have focused\neither on maintaining a posterior distribution on models or value functions and\ncombining this with approximate dynamic programming or tree search, previous\nBayesian \"model-free\" value function distribution approaches implicitly make\nstrong assumptions or approximations. We describe a novel Bayesian framework,\nInferential Induction, for correctly inferring value function distributions\nfrom data, which leads to the development of a new class of BRL algorithms. We\ndesign an algorithm, Bayesian Backwards Induction, with this framework. We\nexperimentally demonstrate that the proposed algorithm is competitive with\nrespect to the state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 06:19:15 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 19:16:51 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Eriksson", "Hannes", ""], ["Jorge", "Emilio", ""], ["Dimitrakakis", "Christos", ""], ["Basu", "Debabrota", ""], ["Grover", "Divya", ""]]}, {"id": "2002.03103", "submitter": "Changjian Chen", "authors": "Changjian Chen, Jun Yuan, Yafeng Lu, Yang Liu, Hang Su, Songtao Yuan,\n  Shixia Liu", "title": "OoDAnalyzer: Interactive Analysis of Out-of-Distribution Samples", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major cause of performance degradation in predictive models is that the\ntest samples are not well covered by the training data. Such not\nwell-represented samples are called OoD samples. In this paper, we propose\nOoDAnalyzer, a visual analysis approach for interactively identifying OoD\nsamples and explaining them in context. Our approach integrates an ensemble OoD\ndetection method and a grid-based visualization. The detection method is\nimproved from deep ensembles by combining more features with algorithms in the\nsame family. To better analyze and understand the OoD samples in context, we\nhave developed a novel kNN-based grid layout algorithm motivated by Hall's\ntheorem. The algorithm approximates the optimal layout and has $O(kN^2)$ time\ncomplexity, faster than the grid layout algorithm with overall best performance\nbut $O(N^3)$ time complexity. Quantitative evaluation and case studies were\nperformed on several datasets to demonstrate the effectiveness and usefulness\nof OoDAnalyzer.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 06:58:33 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Changjian", ""], ["Yuan", "Jun", ""], ["Lu", "Yafeng", ""], ["Liu", "Yang", ""], ["Su", "Hang", ""], ["Yuan", "Songtao", ""], ["Liu", "Shixia", ""]]}, {"id": "2002.03113", "submitter": "Petrus Mikkola", "authors": "Petrus Mikkola, Milica Todorovi\\'c, Jari J\\\"arvi, Patrick Rinke,\n  Samuel Kaski", "title": "Projective Preferential Bayesian Optimization", "comments": "9 pages, 2 figures", "journal-ref": "In Proceedings of the 37th International Conference on Machine\n  Learning, ICML'20, pp. 4050-4058, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimization is an effective method for finding extrema of a\nblack-box function. We propose a new type of Bayesian optimization for learning\nuser preferences in high-dimensional spaces. The central assumption is that the\nunderlying objective function cannot be evaluated directly, but instead a\nminimizer along a projection can be queried, which we call a projective\npreferential query. The form of the query allows for feedback that is natural\nfor a human to give, and which enables interaction. This is demonstrated in a\nuser experiment in which the user feedback comes in the form of optimal\nposition and orientation of a molecule adsorbing to a surface. We demonstrate\nthat our framework is able to find a global minimum of a high-dimensional\nblack-box function, which is an infeasible task for existing preferential\nBayesian optimization frameworks that are based on pairwise comparisons.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 08:29:23 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 11:02:50 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 14:09:29 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 12:10:55 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Mikkola", "Petrus", ""], ["Todorovi\u0107", "Milica", ""], ["J\u00e4rvi", "Jari", ""], ["Rinke", "Patrick", ""], ["Kaski", "Samuel", ""]]}, {"id": "2002.03123", "submitter": "Alon Gonen", "authors": "Alon Gonen and Shachar Lovett and Michal Moshkovitz", "title": "Towards a combinatorial characterization of bounded memory learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial dimensions play an important role in the theory of machine\nlearning. For example, VC dimension characterizes PAC learning, SQ dimension\ncharacterizes weak learning with statistical queries, and Littlestone dimension\ncharacterizes online learning.\n  In this paper we aim to develop combinatorial dimensions that characterize\nbounded memory learning. We propose a candidate solution for the case of\nrealizable strong learning under a known distribution, based on the SQ\ndimension of neighboring distributions. We prove both upper and lower bounds\nfor our candidate solution, that match in some regime of parameters. In this\nparameter regime there is an equivalence between bounded memory and SQ\nlearning. We conjecture that our characterization holds in a much wider regime\nof parameters.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 09:04:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gonen", "Alon", ""], ["Lovett", "Shachar", ""], ["Moshkovitz", "Michal", ""]]}, {"id": "2002.03129", "submitter": "Yunsheng Bai", "authors": "Yunsheng Bai, Derek Xu, Yizhou Sun, Wei Wang", "title": "GLSearch: Maximum Common Subgraph Detection via Learning to Search", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting the Maximum Common Subgraph (MCS) between two input graphs is\nfundamental for applications in drug synthesis, malware detection, cloud\ncomputing, etc. However, MCS computation is NP-hard, and state-of-the-art MCS\nsolvers rely on heuristic search algorithms which in practice cannot find good\nsolution for large graph pairs given a limited computation budget. We propose\nGLSearch, a Graph Neural Network (GNN) based learning to search model. Our\nmodel is built upon the branch and bound algorithm, which selects one pair of\nnodes from the two input graphs to expand at a time. Instead of using\nheuristics, we propose a novel GNN-based Deep Q-Network (DQN) to select the\nnode pair, allowing the search process faster and more adaptive. To further\nenhance the training of DQN, we leverage the search process to provide\nsupervision in a pre-training stage and guide our agent during an imitation\nlearning stage. Experiments on synthetic and real-world large graph pairs\ndemonstrate that our model learns a search strategy that is able to detect\nsignificantly larger common subgraphs given the same computation budget. Our\nGLSearch can be potentially extended to solve many other combinatorial problems\nwith constraints on graphs.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 10:03:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:49:40 GMT"}, {"version": "v3", "created": "Wed, 12 May 2021 17:12:33 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Bai", "Yunsheng", ""], ["Xu", "Derek", ""], ["Sun", "Yizhou", ""], ["Wang", "Wei", ""]]}, {"id": "2002.03141", "submitter": "Yueru Chen", "authors": "Yueru Chen, Mozhdeh Rouhsedaghat, Suya You, Raghuveer Rao and C.-C.\n  Jay Kuo", "title": "PixelHop++: A Small Successive-Subspace-Learning-Based (SSL-based) Model\n  for Image Classification", "comments": "5 pages, 5 figures, 4 tables, Submitted to ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successive subspace learning (SSL) principle was developed and used to\ndesign an interpretable learning model, known as the PixelHop method,for image\nclassification in our prior work. Here, we propose an improved PixelHop method\nand call it PixelHop++. First, to make the PixelHop model size smaller, we\ndecouple a joint spatial-spectral input tensor to multiple spatial tensors (one\nfor each spectral component) under the spatial-spectral separability assumption\nand perform the Saab transform in a channel-wise manner, called the\nchannel-wise (c/w) Saab transform.Second, by performing this operation from one\nhop to another successively, we construct a channel-decomposed feature tree\nwhose leaf nodes contain features of one dimension (1D). Third, these 1D\nfeatures are ranked according to their cross-entropy values, which allows us to\nselect a subset of discriminant features for image classification. In\nPixelHop++, one can control the learning model size of\nfine-granularity,offering a flexible tradeoff between the model size and the\nclassification performance. We demonstrate the flexibility of PixelHop++ on\nMNIST, Fashion MNIST, and CIFAR-10 three datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:08:54 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chen", "Yueru", ""], ["Rouhsedaghat", "Mozhdeh", ""], ["You", "Suya", ""], ["Rao", "Raghuveer", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.03147", "submitter": "Taejoon Byun", "authors": "Taejoon Byun, Sanjai Rayadurgam", "title": "Manifold for Machine Learning Assurance", "comments": null, "journal-ref": null, "doi": "10.1145/3377816.3381734", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of machine-learning (ML) enabled systems in critical tasks\nfuels the quest for novel verification and validation techniques yet grounded\nin accepted system assurance principles. In traditional system development,\nmodel-based techniques have been widely adopted, where the central premise is\nthat abstract models of the required system provide a sound basis for judging\nits implementation. We posit an analogous approach for ML systems using an ML\ntechnique that extracts from the high-dimensional training data implicitly\ndescribing the required system, a low-dimensional underlying structure--a\nmanifold. It is then harnessed for a range of quality assurance tasks such as\ntest adequacy measurement, test input generation, and runtime monitoring of the\ntarget ML system. The approach is built on variational autoencoder, an\nunsupervised method for learning a pair of mutually near-inverse functions\nbetween a given high-dimensional dataset and a low-dimensional representation.\nPreliminary experiments establish that the proposed manifold-based approach,\nfor test adequacy drives diversity in test data, for test generation yields\nfault-revealing yet realistic test cases, and for runtime monitoring provides\nan independent means to assess trustability of the target system's output.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:39:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Byun", "Taejoon", ""], ["Rayadurgam", "Sanjai", ""]]}, {"id": "2002.03153", "submitter": "Hanan Shteingart", "authors": "Hanan Shteingart, Eran Marom, Igor Itkin, Gil Shabat, Michael\n  Kolomenkin, Moshe Salhov, and Liran Katzir", "title": "Majority Voting and the Condorcet's Jury Theorem", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a striking relationship between a three hundred years old Political\nScience theorem named \"Condorcet's jury theorem\" (1785), which states that\nmajorities are more likely to choose correctly when individual votes are often\ncorrect and independent, and a modern Machine Learning concept called \"Strength\nof Weak Learnability\" (1990), which describes a method for converting a weak\nlearning algorithm into one that achieves arbitrarily high accuracy and stands\nin the basis of Ensemble Learning. Albeit the intuitive statement of\nCondorcet's theorem, we could not find a compact and simple rigorous\nmathematical proof of the theorem neither in classical handbooks of Machine\nLearning nor in published papers. By all means we do not claim to discover or\nreinvent a theory nor a result. We humbly want to offer a more publicly\navailable simple derivation of the theorem. We will find joy in seeing more\nteachers of introduction-to-machine-learning courses use the proof we provide\nhere as an exercise to explain the motivation of ensemble learning.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:28:11 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 21:40:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Shteingart", "Hanan", ""], ["Marom", "Eran", ""], ["Itkin", "Igor", ""], ["Shabat", "Gil", ""], ["Kolomenkin", "Michael", ""], ["Salhov", "Moshe", ""], ["Katzir", "Liran", ""]]}, {"id": "2002.03154", "submitter": "Bingbing Sun", "authors": "Bingbing Sun and Tariq Alkhalifah", "title": "A data-driven choice of misfit function for FWI using reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the workflow of Full-Waveform Inversion (FWI), we often tune the\nparameters of the inversion to help us avoid cycle skipping and obtain high\nresolution models. For example, typically start by using objective functions\nthat avoid cycle skipping, like tomographic and image based or using only low\nfrequency, and then later, we utilize the least squares misfit to admit high\nresolution information. We also may perform an isotropic (acoustic) inversion\nto first update the velocity model and then switch to multi-parameter\nanisotropic (elastic) inversions to fully recover the complex physics. Such\nhierarchical approaches are common in FWI, and they often depend on our manual\nintervention based on many factors, and of course, results depend on\nexperience. However, with the large data size often involved in the inversion\nand the complexity of the process, making optimal choices is difficult even for\nan experienced practitioner. Thus, as an example, and within the framework of\nreinforcement learning, we utilize a deep-Q network (DQN) to learn an optimal\npolicy to determine the proper timing to switch between different misfit\nfunctions. Specifically, we train the state-action value function (Q) to\npredict when to use the conventional L2-norm misfit function or the more\nadvanced optimal-transport matching-filter (OTMF) misfit to mitigate the\ncycle-skipping and obtain high resolution, as well as improve convergence. We\nuse a simple while demonstrative shifted-signal inversion examples to\ndemonstrate the basic principles of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:31:33 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sun", "Bingbing", ""], ["Alkhalifah", "Tariq", ""]]}, {"id": "2002.03155", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Random Features Strengthen Graph Neural Networks", "comments": "Accepted to SDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are powerful machine learning models for various\ngraph learning tasks. Recently, the limitations of the expressive power of\nvarious GNN models have been revealed. For example, GNNs cannot distinguish\nsome non-isomorphic graphs and they cannot learn efficient graph algorithms. In\nthis paper, we demonstrate that GNNs become powerful just by adding a random\nfeature to each node. We prove that the random features enable GNNs to learn\nalmost optimal polynomial-time approximation algorithms for the minimum\ndominating set problem and maximum matching problem in terms of approximation\nratios. The main advantage of our method is that it can be combined with\noff-the-shelf GNN models with slight modifications. Through experiments, we\nshow that the addition of random features enables GNNs to solve various\nproblems that normal GNNs, including the graph convolutional networks (GCNs)\nand graph isomorphism networks (GINs), cannot solve.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 12:47:29 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 00:39:03 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 08:52:14 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.03163", "submitter": "Bingbing Sun", "authors": "Bingbing Sun and Tariq Alkhalifah", "title": "ML-misfit: Learning a robust misfit function for full-waveform inversion\n  using machine learning", "comments": "version submitted to journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the available advanced misfit functions for full waveform inversion\n(FWI) are hand-crafted, and the performance of those misfit functions is\ndata-dependent. Thus, we propose to learn a misfit function for FWI, entitled\nML-misfit, based on machine learning. Inspired by the optimal transport of the\nmatching filter misfit, we design a neural network (NN) architecture for the\nmisfit function in a form similar to comparing the mean and variance for two\ndistributions. To guarantee the resulting learned misfit is a metric, we\naccommodate the symmetry of the misfit with respect to its input and a Hinge\nloss regularization term in a meta-loss function to satisfy the \"triangle\ninequality\" rule. In the framework of meta-learning, we train the network by\nrunning FWI to invert for randomly generated velocity models and update the\nparameters of the NN by minimizing the meta-loss, which is defined as\naccumulated difference between the true and inverted models. We first\nillustrate the basic principle of the ML-misfit for learning a convex misfit\nfunction for travel-time shifted signals. Further, we train the NN on 2D\nhorizontally layered models, and we demonstrate the effectiveness and\nrobustness of the learned ML-misfit by applying it to the well-known Marmousi\nmodel.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 13:27:30 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 10:53:05 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Sun", "Bingbing", ""], ["Alkhalifah", "Tariq", ""]]}, {"id": "2002.03165", "submitter": "Chandra Sekhar Ravuri", "authors": "Chandra Sekhar Ravuri (1), Rajesh Sureddi (2), Sathya Veera Reddy\n  Dendi (2), Shanmuganathan Raman (1), Sumohana S. Channappayya (2) ((1)\n  Department of Electrical Engineering, Indian Institute of Technology\n  Gandhinagar, India., (2) Department of Electrical Engineering, Indian\n  Institute of Technology Hyderabad, India.)", "title": "Deep No-reference Tone Mapped Image Quality Assessment", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of rendering high dynamic range (HDR) images to be viewed on\nconventional displays is called tone mapping. However, tone mapping introduces\ndistortions in the final image which may lead to visual displeasure. To\nquantify these distortions, we introduce a novel no-reference quality\nassessment technique for these tone mapped images. This technique is composed\nof two stages. In the first stage, we employ a convolutional neural network\n(CNN) to generate quality aware maps (also known as distortion maps) from tone\nmapped images by training it with the ground truth distortion maps. In the\nsecond stage, we model the normalized image and distortion maps using an\nAsymmetric Generalized Gaussian Distribution (AGGD). The parameters of the AGGD\nmodel are then used to estimate the quality score using support vector\nregression (SVR). We show that the proposed technique delivers competitive\nperformance relative to the state-of-the-art techniques. The novelty of this\nwork is its ability to visualize various distortions as quality maps\n(distortion maps), especially in the no-reference setting, and to use these\nmaps as features to estimate the quality score of tone mapped images.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 13:41:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ravuri", "Chandra Sekhar", ""], ["Sureddi", "Rajesh", ""], ["Dendi", "Sathya Veera Reddy", ""], ["Raman", "Shanmuganathan", ""], ["Channappayya", "Sumohana S.", ""]]}, {"id": "2002.03171", "submitter": "Ingo Steinwart", "authors": "Ingo Steinwart", "title": "Reproducing Kernel Hilbert Spaces Cannot Contain all Continuous\n  Functions on a Compact Metric Space", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an uncountable, compact metric space, we show that there exists no\nreproducing kernel Hilbert space that contains the space of all continuous\nfunctions on this compact space.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:24:18 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 14:28:39 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Steinwart", "Ingo", ""]]}, {"id": "2002.03176", "submitter": "Illia Horenko Dr.", "authors": "Illia Horenko", "title": "On a scalable entropic breaching of the overfitting barrier in machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting and treatment of \"small data\" are among the most challenging\nproblems in the machine learning (ML), when a relatively small data statistics\nsize $T$ is not enough to provide a robust ML fit for a relatively large data\nfeature dimension $D$. Deploying a massively-parallel ML analysis of generic\nclassification problems for different $D$ and $T$, existence of\nstatistically-significant linear overfitting barriers for common ML methods is\ndemonstrated. For example, these results reveal that for a robust\nclassification of bioinformatics-motivated generic problems with the Long\nShort-Term Memory deep learning classifier (LSTM) one needs in a best case a\nstatistics $T$ that is at least 13.8 times larger then the feature dimension\n$D$. It is shown that this overfitting barrier can be breached at a $10^{-12}$\nfraction of the computational cost by means of the entropy-optimal Scalable\nProbabilistic Approximations algorithm (eSPA), performing a joint solution of\nthe entropy-optimal Bayesian network inference and feature space segmentation\nproblems. Application of eSPA to experimental single cell RNA sequencing data\nexhibits a 30-fold classification performance boost when compared to standard\nbioinformatics tools - and a 7-fold boost when compared to the deep learning\nLSTM classifier.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:47:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Horenko", "Illia", ""]]}, {"id": "2002.03179", "submitter": "Jagarlapudi Saketha Nath", "authors": "J. Saketha Nath (IIT Hyderabad, INDIA) and Pratik Jawanpuria\n  (Microsoft IDC, INDIA)", "title": "Statistical Optimal Transport posed as Learning Kernel Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective in statistical Optimal Transport (OT) is to consistently\nestimate the optimal transport plan/map solely using samples from the given\nsource and target marginal distributions. This work takes the novel approach of\nposing statistical OT as that of learning the transport plan's kernel mean\nembedding from sample based estimates of marginal embeddings. The proposed\nestimator controls overfitting by employing maximum mean discrepancy based\nregularization, which is complementary to $\\phi$-divergence (entropy) based\nregularization popularly employed in existing estimators. A key result is that,\nunder very mild conditions, $\\epsilon$-optimal recovery of the transport plan\nas well as the Barycentric-projection based transport map is possible with a\nsample complexity that is completely dimension-free. Moreover, the implicit\nsmoothing in the kernel mean embeddings enables out-of-sample estimation. An\nappropriate representer theorem is proved leading to a kernelized convex\nformulation for the estimator, which can then be potentially used to perform OT\neven in non-standard domains. Empirical results illustrate the efficacy of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:58:53 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 04:55:15 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 18:04:18 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 13:57:02 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 03:55:01 GMT"}, {"version": "v6", "created": "Tue, 10 Nov 2020 08:41:48 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Nath", "J. Saketha", "", "IIT Hyderabad, INDIA"], ["Jawanpuria", "Pratik", "", "Microsoft IDC, INDIA"]]}, {"id": "2002.03181", "submitter": "Thomas Molnar", "authors": "Thomas Molnar and Eugenio Culurciello", "title": "Capsule Network Performance with Autonomous Navigation", "comments": "In IJAIA Vol.11, No.1 for January 2020; 15 pages, 9 figures", "journal-ref": "International Journal of Artificial Intelligence and Applications\n  (IJAIA), Vol. 11, No. 1, January 2020", "doi": "10.5121/ijaia.2020.11101", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CapsNets) have been proposed as an alternative to\nConvolutional Neural Networks (CNNs). This paper showcases how CapsNets are\nmore capable than CNNs for autonomous agent exploration of realistic scenarios.\nIn real world navigation, rewards external to agents may be rare. In turn,\nreinforcement learning algorithms can struggle to form meaningful policy\nfunctions. This paper's approach Capsules Exploration Module (Caps-EM) pairs a\nCapsNets architecture with an Advantage Actor Critic algorithm. Other\napproaches for navigating sparse environments require intrinsic reward\ngenerators, such as the Intrinsic Curiosity Module (ICM) and Augmented\nCuriosity Modules (ACM). Caps-EM uses a more compact architecture without need\nfor intrinsic rewards. Tested using ViZDoom, the Caps-EM uses 44% and 83% fewer\ntrainable network parameters than the ICM and Depth-Augmented Curiosity Module\n(D-ACM), respectively, for 1141% and 437% average time improvement over the ICM\nand D-ACM, respectively, for converging to a policy function across \"My Way\nHome\" scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 15:21:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Molnar", "Thomas", ""], ["Culurciello", "Eugenio", ""]]}, {"id": "2002.03184", "submitter": "Vasileios Lioutas", "authors": "Vasileios Lioutas, Yuhong Guo", "title": "Time-aware Large Kernel Convolutions", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, most state-of-the-art sequence modeling architectures use attention\nto build generative models for language based tasks. Some of these models use\nall the available sequence tokens to generate an attention distribution which\nresults in time complexity of $O(n^2)$. Alternatively, they utilize depthwise\nconvolutions with softmax normalized kernels of size $k$ acting as a\nlimited-window self-attention, resulting in time complexity of $O(k{\\cdot}n)$.\nIn this paper, we introduce Time-aware Large Kernel (TaLK) Convolutions, a\nnovel adaptive convolution operation that learns to predict the size of a\nsummation kernel instead of using a fixed-sized kernel matrix. This method\nyields a time complexity of $O(n)$, effectively making the sequence encoding\nprocess linear to the number of tokens. We evaluate the proposed method on\nlarge-scale standard machine translation, abstractive summarization and\nlanguage modeling datasets and show that TaLK Convolutions constitute an\nefficient improvement over other attention/convolution based approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 15:30:28 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 01:11:18 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lioutas", "Vasileios", ""], ["Guo", "Yuhong", ""]]}, {"id": "2002.03203", "submitter": "Yingcheng Sun", "authors": "Yingcheng Sun and Richard Kolacinski and Kenneth Loparo", "title": "Eliminating Search Intent Bias in Learning to Rank", "comments": null, "journal-ref": "2020 IEEE 14th International Conference on Semantic Computing\n  (ICSC)", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through data has proven to be a valuable resource for improving\nsearch-ranking quality. Search engines can easily collect click data, but\nbiases introduced in the data can make it difficult to use the data\neffectively. In order to measure the effects of biases, many click models have\nbeen proposed in the literature. However, none of the models can explain the\nobservation that users with different search intent (e.g., informational,\nnavigational, etc.) have different click behaviors. In this paper, we study how\ndifferences in user search intent can influence click activities and determined\nthat there exists a bias between user search intent and the relevance of the\ndocument relevance. Based on this observation, we propose a search intent bias\nhypothesis that can be applied to most existing click models to improve their\nability to learn unbiased relevance. Experimental results demonstrate that\nafter adopting the search intent hypothesis, click models can better interpret\nuser clicks and substantially improve retrieval performance.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 17:07:37 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 23:11:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sun", "Yingcheng", ""], ["Kolacinski", "Richard", ""], ["Loparo", "Kenneth", ""]]}, {"id": "2002.03206", "submitter": "Chiyuan Zhang", "authors": "Ziheng Jiang, Chiyuan Zhang, Kunal Talwar, Michael C. Mozer", "title": "Characterizing Structural Regularities of Labeled Data in\n  Overparameterized Models", "comments": "17 pages, 20 figures, ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are accustomed to environments that contain both regularities and\nexceptions. For example, at most gas stations, one pays prior to pumping, but\nthe occasional rural station does not accept payment in advance. Likewise, deep\nneural networks can generalize across instances that share common patterns or\nstructures, yet have the capacity to memorize rare or irregular forms. We\nanalyze how individual instances are treated by a model via a consistency\nscore. The score characterizes the expected accuracy for a held-out instance\ngiven training sets of varying size sampled from the data distribution. We\nobtain empirical estimates of this score for individual instances in multiple\ndata sets, and we show that the score identifies out-of-distribution and\nmislabeled examples at one end of the continuum and strongly regular examples\nat the other end. We identify computationally inexpensive proxies to the\nconsistency score using statistics collected during training. We show examples\nof potential applications to the analysis of deep-learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 17:39:46 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 23:28:09 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 17:22:27 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jiang", "Ziheng", ""], ["Zhang", "Chiyuan", ""], ["Talwar", "Kunal", ""], ["Mozer", "Michael C.", ""]]}, {"id": "2002.03214", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger, Rong Fu, and Yonina C. Eldar", "title": "DeepSIC: Deep Soft Interference Cancellation for Multiuser MIMO\n  Detection", "comments": "arXiv admin note: text overlap with arXiv:2002.07806", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital receivers are required to recover the transmitted symbols from their\nobserved channel output. In multiuser multiple-input multiple-output (MIMO)\nsetups, where multiple symbols are simultaneously transmitted, accurate symbol\ndetection is challenging. A family of algorithms capable of reliably recovering\nmultiple symbols is based on interference cancellation. However, these methods\nassume that the channel is linear, a model which does not reflect many relevant\nchannels, as well as require accurate channel state information (CSI), which\nmay not be available. In this work we propose a multiuser MIMO receiver which\nlearns to jointly detect in a data-driven fashion, without assuming a specific\nchannel model or requiring CSI. In particular, we propose a data-driven\nimplementation of the iterative soft interference cancellation (SIC) algorithm\nwhich we refer to as DeepSIC. The resulting symbol detector is based on\nintegrating dedicated machine-learning (ML) methods into the iterative SIC\nalgorithm. DeepSIC learns to carry out joint detection from a limited set of\ntraining samples without requiring the channel to be linear and its parameters\nto be known. Our numerical evaluations demonstrate that for linear channels\nwith full CSI, DeepSIC approaches the performance of iterative SIC, which is\ncomparable to the optimal performance, and outperforms previously proposed\nML-based MIMO receivers. Furthermore, in the presence of CSI uncertainty,\nDeepSIC significantly outperforms model-based approaches. Finally, we show that\nDeepSIC accurately detects symbols in non-linear channels, where conventional\niterative SIC fails even when accurate CSI is available.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 18:31:00 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 12:02:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Shlezinger", "Nir", ""], ["Fu", "Rong", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2002.03217", "submitter": "Kelly Zhang", "authors": "Kelly W. Zhang, Lucas Janson, Susan A. Murphy", "title": "Inference for Batched Bandits", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As bandit algorithms are increasingly utilized in scientific studies and\nindustrial applications, there is an associated increasing need for reliable\ninference methods based on the resulting adaptively-collected data. In this\nwork, we develop methods for inference on data collected in batches using a\nbandit algorithm. We first prove that the ordinary least squares estimator\n(OLS), which is asymptotically normal on independently sampled data, is not\nasymptotically normal on data collected using standard bandit algorithms when\nthere is no unique optimal arm. This asymptotic non-normality result implies\nthat the naive assumption that the OLS estimator is approximately normal can\nlead to Type-1 error inflation and confidence intervals with below-nominal\ncoverage probabilities. Second, we introduce the Batched OLS estimator (BOLS)\nthat we prove is (1) asymptotically normal on data collected from both\nmulti-arm and contextual bandits and (2) robust to non-stationarity in the\nbaseline reward.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 18:59:47 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 23:01:54 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 22:45:34 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Zhang", "Kelly W.", ""], ["Janson", "Lucas", ""], ["Murphy", "Susan A.", ""]]}, {"id": "2002.03218", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Mohammad Ghavamzadeh, Alessandro Lazaric, Matteo\n  Pirotta", "title": "Conservative Exploration in Reinforcement Learning", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning in an unknown Markov Decision Process (MDP), an agent should\ntrade off exploration to discover new information about the MDP, and\nexploitation of the current knowledge to maximize the reward. Although the\nagent will eventually learn a good or optimal policy, there is no guarantee on\nthe quality of the intermediate policies. This lack of control is undesired in\nreal-world applications where a minimum requirement is that the executed\npolicies are guaranteed to perform at least as well as an existing baseline. In\nthis paper, we introduce the notion of conservative exploration for average\nreward and finite horizon problems. We present two optimistic algorithms that\nguarantee (w.h.p.) that the conservative constraint is never violated during\nlearning. We derive regret bounds showing that being conservative does not\nhinder the learning ability of these algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:09:51 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 12:51:27 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Garcelon", "Evrard", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03219", "submitter": "Gaowen Liu", "authors": "Gaowen Liu, Hao Tang, Hugo Latapie, Yan Yan", "title": "Exocentric to Egocentric Image Generation via Parallel Generative\n  Adversarial Network", "comments": "It has been accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-view image generation has been recently proposed to generate images of\none view from another dramatically different view. In this paper, we\ninvestigate exocentric (third-person) view to egocentric (first-person) view\nimage generation. This is a challenging task since egocentric view sometimes is\nremarkably different from exocentric view. Thus, transforming the appearances\nacross the two views is a non-trivial task. To this end, we propose a novel\nParallel Generative Adversarial Network (P-GAN) with a novel cross-cycle loss\nto learn the shared information for generating egocentric images from\nexocentric view. We also incorporate a novel contextual feature loss in the\nlearning procedure to capture the contextual information in images. Extensive\nexperiments on the Exo-Ego datasets show that our model outperforms the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:10:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Gaowen", ""], ["Tang", "Hao", ""], ["Latapie", "Hugo", ""], ["Yan", "Yan", ""]]}, {"id": "2002.03221", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Mohammad Ghavamzadeh, Alessandro Lazaric, Matteo\n  Pirotta", "title": "Improved Algorithms for Conservative Exploration in Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields such as digital marketing, healthcare, finance, and robotics,\nit is common to have a well-tested and reliable baseline policy running in\nproduction (e.g., a recommender system). Nonetheless, the baseline policy is\noften suboptimal. In this case, it is desirable to deploy online learning\nalgorithms (e.g., a multi-armed bandit algorithm) that interact with the system\nto learn a better/optimal policy under the constraint that during the learning\nprocess the performance is almost never worse than the performance of the\nbaseline itself. In this paper, we study the conservative learning problem in\nthe contextual linear bandit setting and introduce a novel algorithm, the\nConservative Constrained LinUCB (CLUCB2). We derive regret bounds for CLUCB2\nthat match existing results and empirically show that it outperforms\nstate-of-the-art conservative bandit algorithms in a number of synthetic and\nreal-world problems. Finally, we consider a more realistic constraint where the\nperformance is verified only at predefined checkpoints (instead of at every\nstep) and show how this relaxed constraint favorably impacts the regret and\nempirical performance of CLUCB2.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:35:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Garcelon", "Evrard", ""], ["Ghavamzadeh", "Mohammad", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03222", "submitter": "Yue Zhao", "authors": "Yue Zhao and Xueying Ding and Jianing Yang and Haoping Bai", "title": "SUOD: Toward Scalable Unsupervised Outlier Detection", "comments": "In AAAI-20 Workshop on Artificial Intelligence for Cyber Security\n  (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a key field of machine learning for identifying abnormal\ndata objects. Due to the high expense of acquiring ground truth, unsupervised\nmodels are often chosen in practice. To compensate for the unstable nature of\nunsupervised algorithms, practitioners from high-stakes fields like finance,\nhealth, and security, prefer to build a large number of models for further\ncombination and analysis. However, this poses scalability challenges in\nhigh-dimensional large datasets. In this study, we propose a three-module\nacceleration framework called SUOD to expedite the training and prediction with\na large number of unsupervised detection models. SUOD's Random Projection\nmodule can generate lower subspaces for high-dimensional datasets while\nreserving their distance relationship. Balanced Parallel Scheduling module can\nforecast the training and prediction cost of models with high confidence---so\nthe task scheduler could assign nearly equal amount of taskload among workers\nfor efficient parallelization. SUOD also comes with a Pseudo-supervised\nApproximation module, which can approximate fitted unsupervised models by lower\ntime complexity supervised regressors for fast prediction on unseen data. It\nmay be considered as an unsupervised model knowledge distillation process.\nNotably, all three modules are independent with great flexibility to \"mix and\nmatch\"; a combination of modules can be chosen based on use cases. Extensive\nexperiments on more than 30 benchmark datasets have shown the efficacy of SUOD,\nand a comprehensive future development plan is also presented.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:38:47 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhao", "Yue", ""], ["Ding", "Xueying", ""], ["Yang", "Jianing", ""], ["Bai", "Haoping", ""]]}, {"id": "2002.03223", "submitter": "Michelle Ngo", "authors": "Michelle N. Ngo, Dustin S. Pluta, Alexander N. Ngo, Babak Shahbaba", "title": "Conjoined Dirichlet Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a class of techniques that simultaneously clusters the rows\nand columns of a matrix to sort heterogeneous data into homogeneous blocks.\nAlthough many algorithms have been proposed to find biclusters, existing\nmethods suffer from the pre-specification of the number of biclusters or place\nconstraints on the model structure. To address these issues, we develop a\nnovel, non-parametric probabilistic biclustering method based on Dirichlet\nprocesses to identify biclusters with strong co-occurrence in both rows and\ncolumns. The proposed method utilizes dual Dirichlet process mixture models to\nlearn row and column clusters, with the number of resulting clusters determined\nby the data rather than pre-specified. Probabilistic biclusters are identified\nby modeling the mutual dependence between the row and column clusters. We apply\nour method to two different applications, text mining and gene expression\nanalysis, and demonstrate that our method improves bicluster extraction in many\nsettings compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 19:41:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ngo", "Michelle N.", ""], ["Pluta", "Dustin S.", ""], ["Ngo", "Alexander N.", ""], ["Shahbaba", "Babak", ""]]}, {"id": "2002.03226", "submitter": "Rizwan Ahmad", "authors": "Sizhuo Liu, Edward Reehorst, Philip Schniter, and Rizwan Ahmad", "title": "Free-breathing Cardiovascular MRI Using a Plug-and-Play Method with\n  Learned Denoiser", "comments": "IEEE ISBI 2020, International Symposium on Biomedical Imaging", "journal-ref": null, "doi": "10.1109/ISBI45749.2020.9098453", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiac magnetic resonance imaging (CMR) is a noninvasive imaging modality\nthat provides a comprehensive evaluation of the cardiovascular system. The\nclinical utility of CMR is hampered by long acquisition times, however. In this\nwork, we propose and validate a plug-and-play (PnP) method for CMR\nreconstruction from undersampled multi-coil data. To fully exploit the rich\nimage structure inherent in CMR, we pair the PnP framework with a deep learning\n(DL)-based denoiser that is trained using spatiotemporal patches from\nhigh-quality, breath-held cardiac cine images. The resulting \"PnP-DL\" method\niterates over data consistency and denoising subroutines. We compare the\nreconstruction performance of PnP-DL to that of compressed sensing (CS) using\neight breath-held and ten real-time (RT) free-breathing cardiac cine datasets.\nWe find that, for breath-held datasets, PnP-DL offers more than one dB\nadvantage over commonly used CS methods. For RT free-breathing datasets, where\nground truth is not available, PnP-DL receives higher scores in qualitative\nevaluation. The results highlight the potential of PnP-DL to accelerate RT CMR.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 20:27:07 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Liu", "Sizhuo", ""], ["Reehorst", "Edward", ""], ["Schniter", "Philip", ""], ["Ahmad", "Rizwan", ""]]}, {"id": "2002.03229", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, Olivier Teboul, Jonathan Niles-Weed, Jean-Philippe Vert", "title": "Supervised Quantile Normalization for Low-rank Matrix Approximation", "comments": "new version with genomics experiments", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank matrix factorization is a fundamental building block in machine\nlearning, used for instance to summarize gene expression profile data or\nword-document counts. To be robust to outliers and differences in scale across\nfeatures, a matrix factorization step is usually preceded by ad-hoc feature\nnormalization steps, such as \\texttt{tf-idf} scaling or data whitening. We\npropose in this work to learn these normalization operators jointly with the\nfactorization itself. More precisely, given a $d\\times n$ matrix $X$ of $d$\nfeatures measured on $n$ individuals, we propose to learn the parameters of\nquantile normalization operators that can operate row-wise on the values of $X$\nand/or of its factorization $UV$ to improve the quality of the low-rank\nrepresentation of $X$ itself. This optimization is facilitated by the\nintroduction of a new differentiable quantile normalization operator built\nusing optimal transport, providing new results on top of existing work by\n(Cuturi et al. 2019). We demonstrate the applicability of these techniques on\nsynthetic and genomics datasets.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:06:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 18:48:33 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Cuturi", "Marco", ""], ["Teboul", "Olivier", ""], ["Niles-Weed", "Jonathan", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2002.03230", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Hierarchical Generation of Molecular Graphs using Structural Motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation techniques are increasingly being adopted for drug\ndiscovery. Previous graph generation approaches have utilized relatively small\nmolecular building blocks such as atoms or simple cycles, limiting their\neffectiveness to smaller molecules. Indeed, as we demonstrate, their\nperformance degrades significantly for larger molecules. In this paper, we\npropose a new hierarchical graph encoder-decoder that employs significantly\nlarger and more flexible graph motifs as basic building blocks. Our encoder\nproduces a multi-resolution representation for each molecule in a\nfine-to-coarse fashion, from atoms to connected motifs. Each level integrates\nthe encoding of constituents below with the graph at that level. Our\nautoregressive coarse-to-fine decoder adds one motif at a time, interleaving\nthe decision of selecting a new motif with the process of resolving its\nattachments to the emerging molecule. We evaluate our model on multiple\nmolecule generation tasks, including polymers, and show that our model\nsignificantly outperforms previous state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:21:04 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:14:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03231", "submitter": "Aditya Kusupati", "authors": "Aditya Kusupati, Vivek Ramanujan, Raghav Somani, Mitchell Wortsman,\n  Prateek Jain, Sham Kakade, Ali Farhadi", "title": "Soft Threshold Weight Reparameterization for Learnable Sparsity", "comments": "19 pages, 10 figures, Published at International Conference on\n  Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity in Deep Neural Networks (DNNs) is studied extensively with the focus\nof maximizing prediction accuracy given an overall parameter budget. Existing\nmethods rely on uniform or heuristic non-uniform sparsity budgets which have\nsub-optimal layer-wise parameter allocation resulting in a) lower prediction\naccuracy or b) higher inference cost (FLOPs). This work proposes Soft Threshold\nReparameterization (STR), a novel use of the soft-threshold operator on DNN\nweights. STR smoothly induces sparsity while learning pruning thresholds\nthereby obtaining a non-uniform sparsity budget. Our method achieves\nstate-of-the-art accuracy for unstructured sparsity in CNNs (ResNet50 and\nMobileNetV1 on ImageNet-1K), and, additionally, learns non-uniform budgets that\nempirically reduce the FLOPs by up to 50%. Notably, STR boosts the accuracy\nover existing results by up to 10% in the ultra sparse (99%) regime and can\nalso be used to induce low-rank (structured sparsity) in RNNs. In short, STR is\na simple mechanism which learns effective sparsity budgets that contrast with\npopular heuristics. Code, pretrained models and sparsity budgets are at\nhttps://github.com/RAIVNLab/STR.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:31:25 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 22:57:06 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 10:11:37 GMT"}, {"version": "v4", "created": "Wed, 11 Mar 2020 09:57:20 GMT"}, {"version": "v5", "created": "Fri, 17 Apr 2020 12:57:04 GMT"}, {"version": "v6", "created": "Wed, 22 Apr 2020 02:16:28 GMT"}, {"version": "v7", "created": "Tue, 28 Apr 2020 01:12:37 GMT"}, {"version": "v8", "created": "Sun, 10 May 2020 02:39:39 GMT"}, {"version": "v9", "created": "Mon, 22 Jun 2020 23:37:12 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kusupati", "Aditya", ""], ["Ramanujan", "Vivek", ""], ["Somani", "Raghav", ""], ["Wortsman", "Mitchell", ""], ["Jain", "Prateek", ""], ["Kakade", "Sham", ""], ["Farhadi", "Ali", ""]]}, {"id": "2002.03237", "submitter": "Jos\\'e G. G\\'omez Garc\\'ia", "authors": "Jos\\'e G. G\\'omez Garc\\'ia, Jalal Fadili, Christophe Chesneau", "title": "Learning CHARME models with neural networks", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a model called CHARME (Conditional Heteroscedastic\nAutoregressive Mixture of Experts), a class of generalized mixture of nonlinear\nnonparametric AR-ARCH time series. Under certain Lipschitz-type conditions on\nthe autoregressive and volatility functions, we prove that this model is\nstationary, ergodic and $\\tau$-weakly dependent. These conditions are much\nweaker than those presented in the literature that treats this model. Moreover,\nthis result forms the theoretical basis for deriving an asymptotic theory of\nthe underlying (non)parametric estimation, which we present for this model. As\nan application, from the universal approximation property of neural networks\n(NN), we develop a learning theory for the NN-based autoregressive functions of\nthe model, where the strong consistency and asymptotic normality of the\nconsidered estimator of the NN weights and biases are guaranteed under weak\nconditions.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:51:02 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 17:54:08 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Garc\u00eda", "Jos\u00e9 G. G\u00f3mez", ""], ["Fadili", "Jalal", ""], ["Chesneau", "Christophe", ""]]}, {"id": "2002.03238", "submitter": "Ines Rieger", "authors": "Jaspar Pahl, Ines Rieger, Dominik Seuss", "title": "Multi-Label Class Balancing Algorithm for Action Unit Detection", "comments": "This submission is subject to the Action Unit detection task of the\n  Affective Behavior Analysis in-the-wild (ABAW) challenge at the IEEE\n  Conference on Face and Gesture Recognition 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isolated facial movements, so-called Action Units, can describe combined\nemotions or physical states such as pain. As datasets are limited and mostly\nimbalanced, we present an approach incorporating a multi-label class balancing\nalgorithm. This submission is subject to the Action Unit detection task of the\nAffective Behavior Analysis in-the-wild (ABAW) challenge at the IEEE Conference\non Face and Gesture Recognition 2020.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 21:56:28 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pahl", "Jaspar", ""], ["Rieger", "Ines", ""], ["Seuss", "Dominik", ""]]}, {"id": "2002.03239", "submitter": "Aounon Kumar", "authors": "Aounon Kumar, Alexander Levine, Tom Goldstein, Soheil Feizi", "title": "Curse of Dimensionality on Randomized Smoothing for Certifiable\n  Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing, using just a simple isotropic Gaussian distribution,\nhas been shown to produce good robustness guarantees against $\\ell_2$-norm\nbounded adversaries. In this work, we show that extending the smoothing\ntechnique to defend against other attack models can be challenging, especially\nin the high-dimensional regime. In particular, for a vast class of\ni.i.d.~smoothing distributions, we prove that the largest $\\ell_p$-radius that\ncan be certified decreases as $O(1/d^{\\frac{1}{2} - \\frac{1}{p}})$ with\ndimension $d$ for $p > 2$. Notably, for $p \\geq 2$, this dependence on $d$ is\nno better than that of the $\\ell_p$-radius that can be certified using\nisotropic Gaussian smoothing, essentially putting a matching lower bound on the\nrobustness radius. When restricted to {\\it generalized} Gaussian smoothing,\nthese two bounds can be shown to be within a constant factor of each other in\nan asymptotic sense, establishing that Gaussian smoothing provides the best\npossible results, up to a constant factor, when $p \\geq 2$. We present\nexperimental results on CIFAR to validate our theory. For other smoothing\ndistributions, such as, a uniform distribution within an $\\ell_1$ or an\n$\\ell_\\infty$-norm ball, we show upper bounds of the form $O(1 / d)$ and $O(1 /\nd^{1 - \\frac{1}{p}})$ respectively, which have an even worse dependence on $d$.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:02:14 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:02:35 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kumar", "Aounon", ""], ["Levine", "Alexander", ""], ["Goldstein", "Tom", ""], ["Feizi", "Soheil", ""]]}, {"id": "2002.03240", "submitter": "Vincent Micheli", "authors": "Vincent Micheli, Karthigan Sinnathamby, Fran\\c{c}ois Fleuret", "title": "Multi-task Reinforcement Learning with a Planning Quasi-Metric", "comments": "Deep RL Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new reinforcement learning approach combining a planning\nquasi-metric (PQM) that estimates the number of steps required to go from any\nstate to another, with task-specific \"aimers\" that compute a target state to\nreach a given goal. This decomposition allows the sharing across tasks of a\ntask-agnostic model of the quasi-metric that captures the environment's\ndynamics and can be learned in a dense and unsupervised manner. We achieve\nmultiple-fold training speed-up compared to recently published methods on the\nstandard bit-flip problem and in the MuJoCo robotic arm simulator.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:12:59 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:02:31 GMT"}, {"version": "v3", "created": "Sat, 5 Dec 2020 14:21:23 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Micheli", "Vincent", ""], ["Sinnathamby", "Karthigan", ""], ["Fleuret", "Fran\u00e7ois", ""]]}, {"id": "2002.03241", "submitter": "Chong Li", "authors": "Zhun Fan, Chong Li, Ying Chen, Paola Di Mascio, Xiaopeng Chen, Guijie\n  Zhu and Giuseppe Loprencipe", "title": "Ensemble of Deep Convolutional Neural Networks for Automatic Pavement\n  Crack Detection and Measurement", "comments": null, "journal-ref": null, "doi": "10.3390/coatings10020152", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated pavement crack detection and measurement are important road issues.\nAgencies have to guarantee the improvement of road safety. Conventional crack\ndetection and measurement algorithms can be extremely time-consuming and low\nefficiency. Therefore, recently, innovative algorithms have received increased\nattention from researchers. In this paper, we propose an ensemble of\nconvolutional neural networks (without a pooling layer) based on probability\nfusion for automated pavement crack detection and measurement. Specifically, an\nensemble of convolutional neural networks was employed to identify the\nstructure of small cracks with raw images. Secondly, outputs of the individual\nconvolutional neural network model for the ensemble were averaged to produce\nthe final crack probability value of each pixel, which can obtain a predicted\nprobability map. Finally, the predicted morphological features of the cracks\nwere measured by using the skeleton extraction algorithm. To validate the\nproposed method, some experiments were performed on two public crack databases\n(CFD and AigleRN) and the results of the different state-of-the-art methods\nwere compared. The experimental results show that the proposed method\noutperforms the other methods. For crack measurement, the crack length and\nwidth can be measure based on different crack types (complex, common, thin, and\nintersecting cracks.). The results show that the proposed algorithm can be\neffectively applied for crack measurement.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:15:11 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Chong", ""], ["Chen", "Ying", ""], ["Di Mascio", "Paola", ""], ["Chen", "Xiaopeng", ""], ["Zhu", "Guijie", ""], ["Loprencipe", "Giuseppe", ""]]}, {"id": "2002.03244", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Multi-Objective Molecule Generation using Interpretable Substructures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug discovery aims to find novel compounds with specified chemical property\nprofiles. In terms of generative modeling, the goal is to learn to sample\nmolecules in the intersection of multiple property constraints. This task\nbecomes increasingly challenging when there are many property constraints. We\npropose to offset this complexity by composing molecules from a vocabulary of\nsubstructures that we call molecular rationales. These rationales are\nidentified from molecules as substructures that are likely responsible for each\nproperty of interest. We then learn to expand rationales into a full molecule\nusing graph generative models. Our final generative model composes molecules as\nmixtures of multiple rationale completions, and this mixture is fine-tuned to\npreserve the properties of interest. We evaluate our model on various drug\ndesign tasks and demonstrate significant improvements over state-of-the-art\nbaselines in terms of accuracy, diversity, and novelty of generated compounds.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 22:55:37 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 15:10:01 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 19:28:21 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.03261", "submitter": "Sen Wang", "authors": "Sen Wang, J.Morris Chang", "title": "Privacy-Preserving Image Classification in the Local Setting", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image data has been greatly produced by individuals and commercial vendors in\nthe daily life, and it has been used across various domains, like advertising,\nmedical and traffic analysis. Recently, image data also appears to be greatly\nimportant in social utility, like emergency response. However, the privacy\nconcern becomes the biggest obstacle that prevents further exploration of image\ndata, due to that the image could reveal sensitive information, like the\npersonal identity and locations. The recent developed Local Differential\nPrivacy (LDP) brings us a promising solution, which allows the data owners to\nrandomly perturb their input to provide the plausible deniability of the data\nbefore releasing. In this paper, we consider a two-party image classification\nproblem, in which data owners hold the image and the untrustworthy data user\nwould like to fit a machine learning model with these images as input. To\nprotect the image privacy, we propose to locally perturb the image\nrepresentation before revealing to the data user. Subsequently, we analyze how\nthe perturbation satisfies {\\epsilon}-LDP and affect the data utility regarding\ncount-based and distance-based machine learning algorithm, and propose a\nsupervised image feature extractor, DCAConv, which produces an image\nrepresentation with scalable domain size. Our experiments show that DCAConv\ncould maintain a high data utility while preserving the privacy regarding\nmultiple image benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:25:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Sen", ""], ["Chang", "J. Morris", ""]]}, {"id": "2002.03272", "submitter": "Wonjoon Goo", "authors": "Wonjoon Goo, Scott Niekum", "title": "Local Nonparametric Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of meta-learning is to find a learning rule that enables fast\nadaptation across a set of tasks, by learning the appropriate inductive bias\nfor that set. Most meta-learning algorithms try to find a \\textit{global}\nlearning rule that encodes this inductive bias. However, a global learning rule\nrepresented by a fixed-size representation is prone to meta-underfitting or\n-overfitting since the right representational power for a task set is difficult\nto choose a priori. Even when chosen correctly, we show that global, fixed-size\nrepresentations often fail when confronted with certain types of\nout-of-distribution tasks, even when the same inductive bias is appropriate. To\naddress these problems, we propose a novel nonparametric meta-learning\nalgorithm that utilizes a meta-trained local learning rule, building on recent\nideas in attention-based and functional gradient-based meta-learning. In\nseveral meta-regression problems, we show improved meta-generalization results\nusing our local, nonparametric approach and achieve state-of-the-art results in\nthe robotics benchmark, Omnipush.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 03:28:27 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Goo", "Wonjoon", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.03273", "submitter": "Yossi Arjevani", "authors": "Yossi Arjevani, Amit Daniely, Stefanie Jegelka, Hongzhou Lin", "title": "On the Complexity of Minimizing Convex Finite Sums Without Using the\n  Indices of the Individual Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in randomized incremental methods for minimizing $L$-smooth\n$\\mu$-strongly convex finite sums have culminated in tight complexity of\n$\\tilde{O}((n+\\sqrt{n L/\\mu})\\log(1/\\epsilon))$ and $O(n+\\sqrt{nL/\\epsilon})$,\nwhere $\\mu>0$ and $\\mu=0$, respectively, and $n$ denotes the number of\nindividual functions. Unlike incremental methods, stochastic methods for finite\nsums do not rely on an explicit knowledge of which individual function is being\naddressed at each iteration, and as such, must perform at least $\\Omega(n^2)$\niterations to obtain $O(1/n^2)$-optimal solutions. In this work, we exploit the\nfinite noise structure of finite sums to derive a matching $O(n^2)$-upper bound\nunder the global oracle model, showing that this lower bound is indeed tight.\nFollowing a similar approach, we propose a novel adaptation of SVRG which is\nboth \\emph{compatible with stochastic oracles}, and achieves complexity bounds\nof $\\tilde{O}((n^2+n\\sqrt{L/\\mu})\\log(1/\\epsilon))$ and\n$O(n\\sqrt{L/\\epsilon})$, for $\\mu>0$ and $\\mu=0$, respectively. Our bounds hold\nw.h.p. and match in part existing lower bounds of\n$\\tilde{\\Omega}(n^2+\\sqrt{nL/\\mu}\\log(1/\\epsilon))$ and\n$\\tilde{\\Omega}(n^2+\\sqrt{nL/\\epsilon})$, for $\\mu>0$ and $\\mu=0$,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 03:39:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Arjevani", "Yossi", ""], ["Daniely", "Amit", ""], ["Jegelka", "Stefanie", ""], ["Lin", "Hongzhou", ""]]}, {"id": "2002.03276", "submitter": "Haoyu Qin", "authors": "Haoyu Qin", "title": "Asymmetric Rejection Loss for Fairer Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition performance has seen a tremendous gain in recent years,\nmostly due to the availability of large-scale face images dataset that can be\nexploited by deep neural networks to learn powerful face representations.\nHowever, recent research has shown differences in face recognition performance\nacross different ethnic groups mostly due to the racial imbalance in the\ntraining datasets where Caucasian identities largely dominate other\nethnicities. This is actually symptomatic of the under-representation of\nnon-Caucasian ethnic groups in the celebdom from which face datasets are\nusually gathered, rendering the acquisition of labeled data of the\nunder-represented groups challenging. In this paper, we propose an Asymmetric\nRejection Loss, which aims at making full use of unlabeled images of those\nunder-represented groups, to reduce the racial bias of face recognition models.\nWe view each unlabeled image as a unique class, however as we cannot guarantee\nthat two unlabeled samples are from a distinct class we exploit both labeled\nand unlabeled data in an asymmetric manner in our loss formalism. Extensive\nexperiments show our method's strength in mitigating racial bias, outperforming\nstate-of-the-art semi-supervision methods. Performance on the under-represented\nethnicity groups increases while that on the well-represented group is nearly\nunchanged.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:01:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Qin", "Haoyu", ""]]}, {"id": "2002.03278", "submitter": "Kun Zhang", "authors": "Kun Zhang, Mingming Gong, Petar Stojanov, Biwei Huang, Qingsong Liu,\n  Clark Glymour", "title": "Domain Adaptation as a Problem of Inference on Graphical Models", "comments": "19 pages; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with data-driven unsupervised domain adaptation,\nwhere it is unknown in advance how the joint distribution changes across\ndomains, i.e., what factors or modules of the data distribution remain\ninvariant or change across domains. To develop an automated way of domain\nadaptation with multiple source domains, we propose to use a graphical model as\na compact way to encode the change property of the joint distribution, which\ncan be learned from data, and then view domain adaptation as a problem of\nBayesian inference on the graphical models. Such a graphical model\ndistinguishes between constant and varied modules of the distribution and\nspecifies the properties of the changes across domains, which serves as prior\nknowledge of the changing modules for the purpose of deriving the posterior of\nthe target variable $Y$ in the target domain. This provides an end-to-end\nframework of domain adaptation, in which additional knowledge about how the\njoint distribution changes, if available, can be directly incorporated to\nimprove the graphical representation. We discuss how causality-based domain\nadaptation can be put under this umbrella. Experimental results on both\nsynthetic and real data demonstrate the efficacy of the proposed framework for\ndomain adaptation. The code is available at https://github.com/mgong2/DA_Infer .\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:08:15 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 09:47:16 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 16:49:47 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 08:55:05 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Zhang", "Kun", ""], ["Gong", "Mingming", ""], ["Stojanov", "Petar", ""], ["Huang", "Biwei", ""], ["Liu", "Qingsong", ""], ["Glymour", "Clark", ""]]}, {"id": "2002.03281", "submitter": "Min Zhang", "authors": "Min Zhang, Yifan Wang, Pranav Kadam, Shan Liu and C.-C. Jay Kuo", "title": "PointHop++: A Lightweight Learning Model on Point Sets for 3D\n  Classification", "comments": "4pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PointHop method was recently proposed by Zhang et al. for 3D point cloud\nclassification with unsupervised feature extraction. It has an extremely low\ntraining complexity while achieving state-of-the-art classification\nperformance. In this work, we improve the PointHop method furthermore in two\naspects: 1) reducing its model complexity in terms of the model parameter\nnumber and 2) ordering discriminant features automatically based on the\ncross-entropy criterion. The resulting method is called PointHop++. The first\nimprovement is essential for wearable and mobile computing while the second\nimprovement bridges statistics-based and optimization-based machine learning\nmethodologies. With experiments conducted on the ModelNet40 benchmark dataset,\nwe show that the PointHop++ method performs on par with deep neural network\n(DNN) solutions and surpasses other unsupervised feature extraction methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:49:32 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 03:56:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Zhang", "Min", ""], ["Wang", "Yifan", ""], ["Kadam", "Pranav", ""], ["Liu", "Shan", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.03282", "submitter": "Bo Peng", "authors": "Bo Peng and Jiahai Wang and Zizhen Zhang", "title": "A Deep Reinforcement Learning Algorithm Using Dynamic Attention Model\n  for Vehicle Routing Problems", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches show that machine learning has the potential to learn\nbetter heuristics than the one designed by human for solving combinatorial\noptimization problems. The deep neural network is used to characterize the\ninput instance for constructing a feasible solution incrementally. Recently, an\nattention model is proposed to solve routing problems. In this model, the state\nof an instance is represented by node features that are fixed over time.\nHowever, the fact is, the state of an instance is changed according to the\ndecision that the model made at different construction steps, and the node\nfeatures should be updated correspondingly. Therefore, this paper presents a\ndynamic attention model with dynamic encoder-decoder architecture, which\nenables the model to explore node features dynamically and exploit hidden\nstructure information effectively at different construction steps. This paper\nfocuses on a challenging NP-hard problem, vehicle routing problem. The\nexperiments indicate that our model outperforms the previous methods and also\nshows a good generalization performance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:51:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Peng", "Bo", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""]]}, {"id": "2002.03283", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Segmented Graph-Bert for Graph Instance Modeling", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In graph instance representation learning, both the diverse graph instance\nsizes and the graph node orderless property have been the major obstacles that\nrender existing representation learning models fail to work. In this paper, we\nwill examine the effectiveness of GRAPH-BERT on graph instance representation\nlearning, which was designed for node representation learning tasks originally.\nTo adapt GRAPH-BERT to the new problem settings, we re-design it with a\nsegmented architecture instead, which is also named as SEG-BERT (Segmented\nGRAPH-BERT) for reference simplicity in this paper. SEG-BERT involves no\nnode-order-variant inputs or functional components anymore, and it can handle\nthe graph node orderless property naturally. What's more, SEG-BERT has a\nsegmented architecture and introduces three different strategies to unify the\ngraph instance sizes, i.e., full-input, padding/pruning and segment shifting,\nrespectively. SEG-BERT is pre-trainable in an unsupervised manner, which can be\nfurther transferred to new tasks directly or with necessary fine-tuning. We\nhave tested the effectiveness of SEG-BERT with experiments on seven graph\ninstance benchmark datasets, and SEG-BERT can out-perform the comparison\nmethods on six out of them with significant performance advantages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 04:55:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2002.03298", "submitter": "Hristo Paskov", "authors": "Hristo Paskov, Alex Paskov, Robert West", "title": "Learning High Order Feature Interactions with Fine Control Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a methodology for learning sparse statistical models that use as\nfeatures all possible multiplicative interactions among an underlying atomic\nset of features. While the resulting optimization problems are exponentially\nsized, our methodology leads to algorithms that can often solve these problems\nexactly or provide approximate solutions based on combining highly correlated\nfeatures. We also introduce an algorithmic paradigm, the Fine Control Kernel\nframework, so named because it is based on Fenchel Duality and is reminiscent\nof kernel methods. Its theory is tailored to large sparse learning problems,\nand it leads to efficient feature screening rules for interactions. These rules\nare inspired by the Apriori algorithm for market basket analysis -- which also\nfalls under the purview of Fine Control Kernels, and can be applied to a\nplurality of learning problems including the Lasso and sparse matrix\nestimation. Experiments on biomedical datasets demonstrate the efficacy of our\nmethodology in deriving algorithms that efficiently produce interactions models\nwhich achieve state-of-the-art accuracy and are interpretable.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:29:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Paskov", "Hristo", ""], ["Paskov", "Alex", ""], ["West", "Robert", ""]]}, {"id": "2002.03305", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky and Harsh Mehta", "title": "Momentum Improves Normalized SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an improved analysis of normalized SGD showing that adding\nmomentum provably removes the need for large batch sizes on non-convex\nobjectives. Then, we consider the case of objectives with bounded second\nderivative and show that in this case a small tweak to the momentum formula\nallows normalized SGD with momentum to find an $\\epsilon$-critical point in\n$O(1/\\epsilon^{3.5})$ iterations, matching the best-known rates without\naccruing any logarithmic factors or dependence on dimension. We also provide an\nadaptive method that automatically improves convergence rates when the variance\nin the gradients is small. Finally, we show that our method is effective when\nemployed on popular large scale tasks such as ResNet-50 and BERT pretraining,\nmatching the performance of the disparate methods used to get state-of-the-art\nresults on both tasks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 07:00:54 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 03:05:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cutkosky", "Ashok", ""], ["Mehta", "Harsh", ""]]}, {"id": "2002.03309", "submitter": "Hieu Nguyen", "authors": "Han B. Kim, Hieu Nguyen, Qingchu Jin, Sharmila Tamby, Tatiana Gelaf\n  Romer, Eric Sung, Ran Liu, Joseph Greenstein, Jose I. Suarez, Christian\n  Storm, Raimond Winslow, Robert D. Stevens", "title": "A Physiology-Driven Computational Model for Post-Cardiac Arrest Outcome\n  Prediction", "comments": "51 pages, 7 figures, 4 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients resuscitated from cardiac arrest (CA) face a high risk of\nneurological disability and death, however pragmatic methods are lacking for\naccurate and reliable prognostication. The aim of this study was to build\ncomputational models to predict post-CA outcome by leveraging high-dimensional\npatient data available early after admission to the intensive care unit (ICU).\nWe hypothesized that model performance could be enhanced by integrating\nphysiological time series (PTS) data and by training machine learning (ML)\nclassifiers. We compared three models integrating features extracted from the\nelectronic health records (EHR) alone, features derived from PTS collected in\nthe first 24hrs after ICU admission (PTS24), and models integrating PTS24 and\nEHR. Outcomes of interest were survival and neurological outcome at ICU\ndischarge. Combined EHR-PTS24 models had higher discrimination (area under the\nreceiver operating characteristic curve [AUC]) than models which used either\nEHR or PTS24 alone, for the prediction of survival (AUC 0.85, 0.80 and 0.68\nrespectively) and neurological outcome (0.87, 0.83 and 0.78). The best ML\nclassifier achieved higher discrimination than the reference logistic\nregression model (APACHE III) for survival (AUC 0.85 vs 0.70) and neurological\noutcome prediction (AUC 0.87 vs 0.75). Feature analysis revealed previously\nunknown factors to be associated with post-CA recovery. Results attest to the\neffectiveness of ML models for post-CA predictive modeling and suggest that PTS\nrecorded in very early phase after resuscitation encode short-term outcome\nprobabilities.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 07:53:50 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 20:33:10 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kim", "Han B.", ""], ["Nguyen", "Hieu", ""], ["Jin", "Qingchu", ""], ["Tamby", "Sharmila", ""], ["Romer", "Tatiana Gelaf", ""], ["Sung", "Eric", ""], ["Liu", "Ran", ""], ["Greenstein", "Joseph", ""], ["Suarez", "Jose I.", ""], ["Storm", "Christian", ""], ["Winslow", "Raimond", ""], ["Stevens", "Robert D.", ""]]}, {"id": "2002.03327", "submitter": "Chen Tessler", "authors": "Chen Tessler and Shie Mannor", "title": "Reward Tweaking: Maximizing the Total Reward While Planning for Short\n  Horizons", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, the discount factor $\\gamma$ controls the agent's\neffective planning horizon. Traditionally, this parameter was considered part\nof the MDP; however, as deep reinforcement learning algorithms tend to become\nunstable when the effective planning horizon is long, recent works refer to\n$\\gamma$ as a hyper-parameter -- thus changing the underlying MDP and\npotentially leading the agent towards sub-optimal behavior on the original\ntask. In this work, we introduce \\emph{reward tweaking}. Reward tweaking learns\na surrogate reward function $\\tilde r$ for the discounted setting that induces\noptimal behavior on the original finite-horizon total reward task.\nTheoretically, we show that there exists a surrogate reward that leads to\noptimality in the original task and discuss the robustness of our approach.\nAdditionally, we perform experiments in high-dimensional continuous control\ntasks and show that reward tweaking guides the agent towards better\nlong-horizon returns although it plans for short horizons.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:50:07 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 12:45:09 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Tessler", "Chen", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.03328", "submitter": "Yufeng Zhang", "authors": "Yufeng Zhang, Wanwei Liu, Zhenbang Chen, Ji Wang, Zhiming Liu, Kenli\n  Li, Hongmei Wei", "title": "Out-of-Distribution Detection with Distance Guarantee in Deep Generative\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has revealed that deep generative models including flow-based\nmodels and Variational autoencoders may assign higher likelihood to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample out OOD data from the model. This counterintuitive phenomenon has\nnot been satisfactorily explained. In this paper, we prove theorems to\ninvestigate the divergences in flow-based model and give two explanations to\nthe above phenomenon from divergence and geometric perspectives, respectively.\nBased on our analysis, we propose two group anomaly detection methods.\nFurthermore, we decompose the KL divergence and propose a point-wise anomaly\ndetection method. We have conducted extensive experiments on prevalent\nbenchmarks to evaluate our methods. For group anomaly detection (GAD), our\nmethod can achieve near 100\\% AUROC on all problems and has robustness against\ndata manipulations. On the contrary, the state-of-the-art (SOTA) GAD method\nperforms not better than random guessing for challenging problems and can be\nattacked by data manipulation in almost all cases. For point-wise anomaly\ndetection (PAD), our method is comparable to the SOTA PAD method on one\ncategory of problems and outperforms the baseline significantly on another\ncategory of problems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:54:12 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 11:56:54 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 13:56:04 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Yufeng", ""], ["Liu", "Wanwei", ""], ["Chen", "Zhenbang", ""], ["Wang", "Ji", ""], ["Liu", "Zhiming", ""], ["Li", "Kenli", ""], ["Wei", "Hongmei", ""]]}, {"id": "2002.03329", "submitter": "Ahmed Khaled", "authors": "Ahmed Khaled and Peter Richt\\'arik", "title": "Better Theory for SGD in the Nonconvex World", "comments": "33 pages, 3 figures, 4 theorems, and 4 propositions. V3 updates:\n  added several references on error conditions (Tseng, Solodov, Bottou and\n  Tsitsiklis, Grimmer), added a full proof of Corollary 1, cleaned up several\n  proofs, and made minor adjustments to text for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale nonconvex optimization problems are ubiquitous in modern machine\nlearning, and among practitioners interested in solving them, Stochastic\nGradient Descent (SGD) reigns supreme. We revisit the analysis of SGD in the\nnonconvex setting and propose a new variant of the recently introduced expected\nsmoothness assumption which governs the behaviour of the second moment of the\nstochastic gradient. We show that our assumption is both more general and more\nreasonable than assumptions made in all prior work. Moreover, our results yield\nthe optimal $\\mathcal{O}(\\varepsilon^{-4})$ rate for finding a stationary point\nof nonconvex smooth functions, and recover the optimal\n$\\mathcal{O}(\\varepsilon^{-1})$ rate for finding a global solution if the\nPolyak-{\\L}ojasiewicz condition is satisfied. We compare against convergence\nrates under convexity and prove a theorem on the convergence of SGD under\nQuadratic Functional Growth and convexity, which might be of independent\ninterest. Moreover, we perform our analysis in a framework which allows for a\ndetailed study of the effects of a wide array of sampling strategies and\nminibatch sizes for finite-sum optimization problems. We corroborate our\ntheoretical results with experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 09:56:06 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:03:10 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 15:03:18 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Khaled", "Ahmed", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.03335", "submitter": "Hila Levi", "authors": "Hila Levi, Shimon Ullman", "title": "Multi-Task Learning by a Top-Down Control Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the range of tasks performed by a general vision system expands, executing\nmultiple tasks accurately and efficiently in a single network has become an\nimportant and still open problem. Recent computer vision approaches address\nthis problem by branching networks, or by a channel-wise modulation of the\nnetwork feature-maps with task specific vectors. We present a novel\narchitecture that uses a dedicated top-down control network to modify the\nactivation of all the units in the main recognition network in a manner that\ndepends on the selected task, image content, and spatial location. We show the\neffectiveness of our scheme by achieving significantly better results than\nalternative state-of-the-art approaches on four datasets. We further\ndemonstrate our advantages in terms of task selectivity, scaling the number of\ntasks and interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 10:13:17 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 14:02:20 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 19:53:34 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Levi", "Hila", ""], ["Ullman", "Shimon", ""]]}, {"id": "2002.03339", "submitter": "Jiangchao Liu", "authors": "Jiangchao Liu, Liqian Chen, Antoine Mine and Ji Wang", "title": "Input Validation for Neural Networks via Runtime Local Robustness\n  Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local robustness verification can verify that a neural network is robust wrt.\nany perturbation to a specific input within a certain distance. We call this\ndistance Robustness Radius. We observe that the robustness radii of correctly\nclassified inputs are much larger than that of misclassified inputs which\ninclude adversarial examples, especially those from strong adversarial attacks.\nAnother observation is that the robustness radii of correctly classified inputs\noften follow a normal distribution. Based on these two observations, we propose\nto validate inputs for neural networks via runtime local robustness\nverification. Experiments show that our approach can protect neural networks\nfrom adversarial examples and improve their accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 10:24:29 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Jiangchao", ""], ["Chen", "Liqian", ""], ["Mine", "Antoine", ""], ["Wang", "Ji", ""]]}, {"id": "2002.03352", "submitter": "Moran Feldman", "authors": "Ran Haba, Ehsan Kazemi, Moran Feldman and Amin Karbasi", "title": "Streaming Submodular Maximization under a $k$-Set System Constraint", "comments": "28 pages; 8 figures. This paper subsumes arXiv:1906.04449, which was\n  previously posted on arXiv and considered only the case of linear objective\n  functions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework that converts streaming\nalgorithms for monotone submodular maximization into streaming algorithms for\nnon-monotone submodular maximization. This reduction readily leads to the\ncurrently tightest deterministic approximation ratio for submodular\nmaximization subject to a $k$-matchoid constraint. Moreover, we propose the\nfirst streaming algorithm for monotone submodular maximization subject to\n$k$-extendible and $k$-set system constraints. Together with our proposed\nreduction, we obtain $O(k\\log k)$ and $O(k^2\\log k)$ approximation ratio for\nsubmodular maximization subject to the above constraints, respectively. We\nextensively evaluate the empirical performance of our algorithm against the\nexisting work in a series of experiments including finding the maximum\nindependent set in randomly generated graphs, maximizing linear functions over\nsocial networks, movie recommendation, Yelp location summarization, and Twitter\ndata summarization.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 12:32:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Haba", "Ran", ""], ["Kazemi", "Ehsan", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.03375", "submitter": "Jingyu He", "authors": "Jingyu He, P. Richard Hahn", "title": "Stochastic tree ensembles for regularized nonlinear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper develops a novel stochastic tree ensemble method for nonlinear\nregression, which we refer to as XBART, short for Accelerated Bayesian Additive\nRegression Trees. By combining regularization and stochastic search strategies\nfrom Bayesian modeling with computationally efficient techniques from recursive\npartitioning approaches, the new method attains state-of-the-art performance:\nin many settings it is both faster and more accurate than the widely-used\nXGBoost algorithm. Via careful simulation studies, we demonstrate that our new\napproach provides accurate point-wise estimates of the mean function and does\nso faster than popular alternatives, such as BART, XGBoost and neural networks\n(using Keras). We also prove a number of basic theoretical results about the\nnew algorithm, including consistency of the single tree version of the model\nand stationarity of the Markov chain produced by the ensemble version.\nFurthermore, we demonstrate that initializing standard Bayesian additive\nregression trees Markov chain Monte Carlo (MCMC) at XBART-fitted trees\nconsiderably improves credible interval coverage and reduces total run-time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 14:37:02 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 03:55:01 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 16:08:50 GMT"}, {"version": "v4", "created": "Thu, 3 Jun 2021 14:44:02 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["He", "Jingyu", ""], ["Hahn", "P. Richard", ""]]}, {"id": "2002.03387", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Data Vision: Learning to See Through Algorithmic Abstraction", "comments": null, "journal-ref": "In Proceedings of the 2017 ACM Conference on Computer Supported\n  Cooperative Work and Social Computing. ACM, New York, NY, USA, 2436-2447", "doi": "10.1145/2998181.2998331", "report-no": null, "categories": "cs.HC cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to see through data is central to contemporary forms of algorithmic\nknowledge production. While often represented as a mechanical application of\nrules, making algorithms work with data requires a great deal of situated work.\nThis paper examines how the often-divergent demands of mechanization and\ndiscretion manifest in data analytic learning environments. Drawing on research\nin CSCW and the social sciences, and ethnographic fieldwork in two data\nlearning environments, we show how an algorithm's application is seen sometimes\nas a mechanical sequence of rules and at other times as an array of situated\ndecisions. Casting data analytics as a rule-based (rather than rule-bound)\npractice, we show that effective data vision requires would-be analysts to\nstraddle the competing demands of formal abstraction and empirical contingency.\nWe conclude by discussing how the notion of data vision can help better\nleverage the role of human work in data analytic learning, research, and\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03388", "submitter": "Shushan Arakelyan", "authors": "Shushan Arakelyan, Sima Arasteh, Christophe Hauser, Erik Kline and\n  Aram Galstyan", "title": "Bin2vec: Learning Representations of Binary Executable Programs for\n  Security Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling binary program analysis problems has traditionally implied manually\ndefining rules and heuristics, a tedious and time-consuming task for human\nanalysts. In order to improve automation and scalability, we propose an\nalternative direction based on distributed representations of binary programs\nwith applicability to a number of downstream tasks. We introduce Bin2vec, a new\napproach leveraging Graph Convolutional Networks (GCN) along with computational\nprogram graphs in order to learn a high dimensional representation of binary\nexecutable programs. We demonstrate the versatility of this approach by using\nour representations to solve two semantically different binary analysis tasks -\nfunctional algorithm classification and vulnerability discovery. We compare the\nproposed approach to our own strong baseline as well as published results and\ndemonstrate improvement over state-of-the-art methods for both tasks. We\nevaluated Bin2vec on 49191 binaries for the functional algorithm classification\ntask, and on 30 different CWE-IDs including at least 100 CVE entries each for\nthe vulnerability discovery task. We set a new state-of-the-art result by\nreducing the classification error by 40% compared to the source-code-based\ninst2vec approach, while working on binary code. For almost every vulnerability\nclass in our dataset, our prediction accuracy is over 80% (and over 90% in\nmultiple classes).\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:43 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:27:57 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Arakelyan", "Shushan", ""], ["Arasteh", "Sima", ""], ["Hauser", "Christophe", ""], ["Kline", "Erik", ""], ["Galstyan", "Aram", ""]]}, {"id": "2002.03389", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Trust in Data Science: Collaboration, Translation, and Accountability in\n  Corporate Data Science Projects", "comments": null, "journal-ref": "Proc. ACM Hum.-Comput. Interact. 2, CSCW, Article 136 (November\n  2018), 28 pages", "doi": "10.1145/3274405", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trustworthiness of data science systems in applied and real-world\nsettings emerges from the resolution of specific tensions through situated,\npragmatic, and ongoing forms of work. Drawing on research in CSCW, critical\ndata studies, and history and sociology of science, and six months of immersive\nethnographic fieldwork with a corporate data science team, we describe four\ncommon tensions in applied data science work: (un)equivocal numbers,\n(counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We\nshow how organizational actors establish and re-negotiate trust under messy and\nuncertain analytic conditions through practices of skepticism, assessment, and\ncredibility. Highlighting the collaborative and heterogeneous nature of\nreal-world data science, we show how the management of trust in applied\ncorporate data science settings depends not only on pre-processing and\nquantification, but also on negotiation and translation. We conclude by\ndiscussing the implications of our findings for data science research and\npractice, both within and beyond CSCW.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:50:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03392", "submitter": "Sambaran Bandyopadhyay", "authors": "Sambaran Bandyopadhyay, Kishalay Das, M. Narasimha Murty", "title": "Line Hypergraph Convolution Network: Applying Graph Convolution for\n  Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network representation learning and node classification in graphs got\nsignificant attention due to the invent of different types graph neural\nnetworks. Graph convolution network (GCN) is a popular semi-supervised\ntechnique which aggregates attributes within the neighborhood of each node.\nConventional GCNs can be applied to simple graphs where each edge connects only\ntwo nodes. But many modern days applications need to model high order\nrelationships in a graph. Hypergraphs are effective data types to handle such\ncomplex relationships. In this paper, we propose a novel technique to apply\ngraph convolution on hypergraphs with variable hyperedge sizes. We use the\nclassical concept of line graph of a hypergraph for the first time in the\nhypergraph learning literature. Then we propose to use graph convolution on the\nline graph of a hypergraph. Experimental analysis on multiple real world\nnetwork datasets shows the merit of our approach compared to state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 16:05:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Bandyopadhyay", "Sambaran", ""], ["Das", "Kishalay", ""], ["Murty", "M. Narasimha", ""]]}, {"id": "2002.03399", "submitter": "Felix Kuhnke", "authors": "Felix Kuhnke, Lars Rumberg, J\\\"orn Ostermann", "title": "Two-Stream Aural-Visual Affect Analysis in the Wild", "comments": "6 pages, 2 figures, Face and Gesture 2020 Workshop Paper (ABAW2020\n  competition)", "journal-ref": null, "doi": "10.1109/FG47880.2020.00056", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human affect recognition is an essential part of natural human-computer\ninteraction. However, current methods are still in their infancy, especially\nfor in-the-wild data. In this work, we introduce our submission to the\nAffective Behavior Analysis in-the-wild (ABAW) 2020 competition. We propose a\ntwo-stream aural-visual analysis model to recognize affective behavior from\nvideos. Audio and image streams are first processed separately and fed into a\nconvolutional neural network. Instead of applying recurrent architectures for\ntemporal analysis we only use temporal convolutions. Furthermore, the model is\ngiven access to additional features extracted during face-alignment. At\ntraining time, we exploit correlations between different emotion\nrepresentations to improve performance. Our model achieves promising results on\nthe challenging Aff-Wild2 database.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 16:59:56 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:59:01 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kuhnke", "Felix", ""], ["Rumberg", "Lars", ""], ["Ostermann", "J\u00f6rn", ""]]}, {"id": "2002.03401", "submitter": "Hamid Reza Boveiri", "authors": "Hamid Reza Boveiri, Raouf Khayami, Reza Javidan, Ali Reza MehdiZadeh", "title": "Medical Image Registration Using Deep Neural Networks: A Comprehensive\n  Review", "comments": "45 Pages, 39 Figures, 10 Tables, 2 Appendixes", "journal-ref": null, "doi": "10.1016/j.compeleceng.2020.106767", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-guided interventions are saving the lives of a large number of patients\nwhere the image registration problem should indeed be considered as the most\ncomplex and complicated issue to be tackled. On the other hand, the recently\nhuge progress in the field of machine learning made by the possibility of\nimplementing deep neural networks on the contemporary many-core GPUs opened up\na promising window to challenge with many medical applications, where the\nregistration is not an exception. In this paper, a comprehensive review on the\nstate-of-the-art literature known as medical image registration using deep\nneural networks is presented. The review is systematic and encompasses all the\nrelated works previously published in the field. Key concepts, statistical\nanalysis from different points of view, confiding challenges, novelties and\nmain contributions, key-enabling techniques, future directions and prospective\ntrends all are discussed and surveyed in details in this comprehensive review.\nThis review allows a deep understanding and insight for the readers active in\nthe field who are investigating the state-of-the-art and seeking to contribute\nthe future literature.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:22:05 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Boveiri", "Hamid Reza", ""], ["Khayami", "Raouf", ""], ["Javidan", "Reza", ""], ["MehdiZadeh", "Ali Reza", ""]]}, {"id": "2002.03405", "submitter": "Ahmed Magooda", "authors": "Ahmed Magooda and Cezary Marcjan", "title": "Attend to the beginning: A study on using bidirectional attention for\n  extractive summarization", "comments": "To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\n  in he proceedings of AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forum discussion data differ in both structure and properties from generic\nform of textual data such as news. Henceforth, summarization techniques should,\nin turn, make use of such differences, and craft models that can benefit from\nthe structural nature of discussion data. In this work, we propose attending to\nthe beginning of a document, to improve the performance of extractive\nsummarization models when applied to forum discussion data. Evaluations\ndemonstrated that with the help of bidirectional attention mechanism, attending\nto the beginning of a document (initial comment/post) in a discussion thread,\ncan introduce a consistent boost in ROUGE scores, as well as introducing a new\nState Of The Art (SOTA) ROUGE scores on the forum discussions dataset.\nAdditionally, we explored whether this hypothesis is extendable to other\ngeneric forms of textual data. We make use of the tendency of introducing\nimportant information early in the text, by attending to the first few\nsentences in generic textual data. Evaluations demonstrated that attending to\nintroductory sentences using bidirectional attention, improves the performance\nof extractive summarization models when even applied to more generic form of\ntextual data.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:46:22 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 14:23:49 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 03:13:38 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Magooda", "Ahmed", ""], ["Marcjan", "Cezary", ""]]}, {"id": "2002.03407", "submitter": "Ahmed Magooda", "authors": "Ahmed Magooda, Diane Litman", "title": "Abstractive Summarization for Low Resource Data using Domain Transfer\n  and Data Synthesis", "comments": "To be published in FLAIRS33 (https://www.flairs-33.info/) and appear\n  in he proceedings of AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training abstractive summarization models typically requires large amounts of\ndata, which can be a limitation for many domains. In this paper we explore\nusing domain transfer and data synthesis to improve the performance of recent\nabstractive summarization methods when applied to small corpora of student\nreflections. First, we explored whether tuning state of the art model trained\non newspaper data could boost performance on student reflection data.\nEvaluations demonstrated that summaries produced by the tuned model achieved\nhigher ROUGE scores compared to model trained on just student reflection data\nor just newspaper data. The tuned model also achieved higher scores compared to\nextractive summarization baselines, and additionally was judged to produce more\ncoherent and readable summaries in human evaluations. Second, we explored\nwhether synthesizing summaries of student data could additionally boost\nperformance. We proposed a template-based model to synthesize new data, which\nwhen incorporated into training further increased ROUGE scores. Finally, we\nshowed that combining data synthesis with domain transfer achieved higher ROUGE\nscores compared to only using one of the two approaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:49:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Magooda", "Ahmed", ""], ["Litman", "Diane", ""]]}, {"id": "2002.03413", "submitter": "Xin Yi", "authors": "Xin Yi, Scott J. Adams, Robert D. E. Henderson, Paul Babyn", "title": "Computer-Aided Assessment of Catheters and Tubes on Radiographs: How\n  Good is Artificial Intelligence for Assessment?", "comments": "This manuscript has been accepted for publication in Radiology:\n  Artificial Intelligence (https://pubs.rsna.org/journal/ai), which is\n  published by the Radiological Society of North America (RSNA)", "journal-ref": null, "doi": "10.1148/ryai.2020190082", "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catheters are the second most common abnormal finding on radiographs. The\nposition of catheters must be assessed on all radiographs, as serious\ncomplications can arise if catheters are malpositioned. However, due to the\nlarge number of radiographs performed each day, there can be substantial delays\nbetween the time a radiograph is performed and when it is interpreted by a\nradiologist. Computer-aided approaches hold the potential to assist in\nprioritizing radiographs with potentially malpositioned catheters for\ninterpretation and automatically insert text indicating the placement of\ncatheters in radiology reports, thereby improving radiologists' efficiency.\nAfter 50 years of research in computer-aided diagnosis, there is still a\npaucity of study in this area. With the development of deep learning\napproaches, the problem of catheter assessment is far more solvable. Therefore,\nwe have performed a review of current algorithms and identified key challenges\nin building a reliable computer-aided diagnosis system for assessment of\ncatheters on radiographs. This review may serve to further the development of\nmachine learning approaches for this important use case.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:12:40 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yi", "Xin", ""], ["Adams", "Scott J.", ""], ["Henderson", "Robert D. E.", ""], ["Babyn", "Paul", ""]]}, {"id": "2002.03421", "submitter": "Jinyuan Jia", "authors": "Jinyuan Jia, Binghui Wang, Xiaoyu Cao, Neil Zhenqiang Gong", "title": "Certified Robustness of Community Detection against Adversarial\n  Structural Perturbation via Randomized Smoothing", "comments": "Accepted by WWW'20; This is technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection plays a key role in understanding graph structure.\nHowever, several recent studies showed that community detection is vulnerable\nto adversarial structural perturbation. In particular, via adding or removing a\nsmall number of carefully selected edges in a graph, an attacker can manipulate\nthe detected communities. However, to the best of our knowledge, there are no\nstudies on certifying robustness of community detection against such\nadversarial structural perturbation. In this work, we aim to bridge this gap.\nSpecifically, we develop the first certified robustness guarantee of community\ndetection against adversarial structural perturbation. Given an arbitrary\ncommunity detection method, we build a new smoothed community detection method\nvia randomly perturbing the graph structure. We theoretically show that the\nsmoothed community detection method provably groups a given arbitrary set of\nnodes into the same community (or different communities) when the number of\nedges added/removed by an attacker is bounded. Moreover, we show that our\ncertified robustness is tight. We also empirically evaluate our method on\nmultiple real-world graphs with ground truth communities.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:39:39 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 01:58:17 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Jia", "Jinyuan", ""], ["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2002.03425", "submitter": "Felix Wick", "authors": "Felix Wick and Ulrich Kerzel and Michael Feindt", "title": "Cyclic Boosting -- an explainable supervised machine learning algorithm", "comments": "added a discussion about causality", "journal-ref": "2019 18th IEEE International Conference On Machine Learning And\n  Applications (ICMLA)", "doi": "10.1109/ICMLA.2019.00067", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning algorithms have seen spectacular advances and\nsurpassed human level performance in a wide range of specific applications.\nHowever, using complex ensemble or deep learning algorithms typically results\nin black box models, where the path leading to individual predictions cannot be\nfollowed in detail. In order to address this issue, we propose the novel\n\"Cyclic Boosting\" machine learning algorithm, which allows to efficiently\nperform accurate regression and classification tasks while at the same time\nallowing a detailed understanding of how each individual prediction was made.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:52:42 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 13:50:31 GMT"}, {"version": "v3", "created": "Tue, 5 Jan 2021 16:17:14 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Wick", "Felix", ""], ["Kerzel", "Ulrich", ""], ["Feindt", "Michael", ""]]}, {"id": "2002.03427", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Graph Neural Distance Metric Learning with Graph-Bert", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph distance metric learning serves as the foundation for many graph\nlearning problems, e.g., graph clustering, graph classification and graph\nmatching. Existing research works on graph distance metric (or graph kernels)\nlearning fail to maintain the basic properties of such metrics, e.g.,\nnon-negative, identity of indiscernibles, symmetry and triangle inequality,\nrespectively. In this paper, we will introduce a new graph neural network based\ndistance metric learning approaches, namely GB-DISTANCE (GRAPH-BERT based\nNeural Distance). Solely based on the attention mechanism, GB-DISTANCE can\nlearn graph instance representations effectively based on a pre-trained\nGRAPH-BERT model. Different from the existing supervised/unsupervised metrics,\nGB-DISTANCE can be learned effectively in a semi-supervised manner. In\naddition, GB-DISTANCE can also maintain the distance metric basic properties\nmentioned above. Extensive experiments have been done on several benchmark\ngraph datasets, and the results demonstrate that GB-DISTANCE can out-perform\nthe existing baseline methods, especially the recent graph neural network model\nbased graph metrics, with a significant gap in computing the graph distance.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 18:58:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2002.03428", "submitter": "Elizabeth Liner", "authors": "Elizabeth Liner, Risto Miikkulainen", "title": "Improving Neural Network Learning Through Dual Variable Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and evaluates a novel training method for neural\nnetworks: Dual Variable Learning Rates (DVLR). Building on insights from\nbehavioral psychology, the dual learning rates are used to emphasize correct\nand incorrect responses differently, thereby making the feedback to the network\nmore specific. Further, the learning rates are varied as a function of the\nnetwork's performance, thereby making it more efficient. DVLR was implemented\non three types of networks: feedforward, convolutional, and residual, and two\ndomains: MNIST and CIFAR-10. The results suggest a consistently improved\naccuracy, demonstrating that DVLR is a promising, psychologically motivated\ntechnique for training neural network models.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:01:05 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 04:29:17 GMT"}, {"version": "v3", "created": "Tue, 9 Feb 2021 21:22:12 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Liner", "Elizabeth", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.03432", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Arash Vahdat, Yisong Yue, Ming-Yu Liu", "title": "On the distance between two neural networks and the stability of\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper relates parameter distance to gradient breakdown for a broad class\nof nonlinear compositional functions. The analysis leads to a new distance\nfunction called deep relative trust and a descent lemma for neural networks.\nSince the resulting learning rule seems to require little to no learning rate\ntuning, it may unlock a simpler workflow for training deeper and more complex\nneural networks. The Python code used in this paper is here:\nhttps://github.com/jxbz/fromage.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:18:39 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:36:33 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 13:51:25 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Vahdat", "Arash", ""], ["Yue", "Yisong", ""], ["Liu", "Ming-Yu", ""]]}, {"id": "2002.03433", "submitter": "Simos Gerasimou", "authors": "Simos Gerasimou, Hasan Ferit Eniser, Alper Sen, Alper Cakan", "title": "Importance-Driven Deep Learning System Testing", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) systems are key enablers for engineering intelligent\napplications due to their ability to solve complex tasks such as image\nrecognition and machine translation. Nevertheless, using DL systems in safety-\nand security-critical applications requires to provide testing evidence for\ntheir dependable operation. Recent research in this direction focuses on\nadapting testing criteria from traditional software engineering as a means of\nincreasing confidence for their correct behaviour. However, they are inadequate\nin capturing the intrinsic properties exhibited by these systems. We bridge\nthis gap by introducing DeepImportance, a systematic testing methodology\naccompanied by an Importance-Driven (IDC) test adequacy criterion for DL\nsystems. Applying IDC enables to establish a layer-wise functional\nunderstanding of the importance of DL system components and use this\ninformation to assess the semantic diversity of a test set. Our empirical\nevaluation on several DL systems, across multiple DL datasets and with\nstate-of-the-art adversarial generation techniques demonstrates the usefulness\nand effectiveness of DeepImportance and its ability to support the engineering\nof more robust DL systems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:20:56 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Gerasimou", "Simos", ""], ["Eniser", "Hasan Ferit", ""], ["Sen", "Alper", ""], ["Cakan", "Alper", ""]]}, {"id": "2002.03438", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nitish Shirish Keskar, and Richard Socher", "title": "Limits of Detecting Text Generated by Large-Scale Language Models", "comments": "ITA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:53:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Varshney", "Lav R.", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "2002.03444", "submitter": "Usman Roshan", "authors": "Yunzhe Xue, Meiyan Xie, Usman Roshan", "title": "Robust binary classification with the 01 loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 01 loss is robust to outliers and tolerant to noisy data compared to\nconvex loss functions. We conjecture that the 01 loss may also be more robust\nto adversarial attacks. To study this empirically we have developed a\nstochastic coordinate descent algorithm for a linear 01 loss classifier and a\nsingle hidden layer 01 loss neural network. Due to the absence of the gradient\nwe iteratively update coordinates on random subsets of the data for fixed\nepochs. We show our algorithms to be fast and comparable in accuracy to the\nlinear support vector machine and logistic loss single hidden layer network for\nbinary classification on several image benchmarks, thus establishing that our\nmethod is on-par in test accuracy with convex losses. We then subject them to\naccurately trained substitute model black box attacks on the same image\nbenchmarks and find them to be more robust than convex counterparts. On CIFAR10\nbinary classification task between classes 0 and 1 with adversarial\nperturbation of 0.0625 we see that the MLP01 network loses 27\\% in accuracy\nwhereas the MLP-logistic counterpart loses 83\\%. Similarly on STL10 and\nImageNet binary classification between classes 0 and 1 the MLP01 network loses\n21\\% and 20\\% while MLP-logistic loses 67\\% and 45\\% respectively. On MNIST\nthat is a well-separable dataset we find MLP01 comparable to MLP-logistic and\nshow under simulation how and why our 01 loss solver is less robust there. We\nthen propose adversarial training for our linear 01 loss solver that\nsignificantly improves its robustness on MNIST and all other datasets and\nretains clean test accuracy. Finally we show practical applications of our\nmethod to deter traffic sign and facial recognition adversarial attacks. We\ndiscuss attacks with 01 loss, substitute model accuracy, and several future\navenues like multiclass, 01 loss convolutions, and further adversarial\ntraining.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 20:41:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Xue", "Yunzhe", ""], ["Xie", "Meiyan", ""], ["Roshan", "Usman", ""]]}, {"id": "2002.03461", "submitter": "Piotr Koniusz", "authors": "Xianjing Wang, Flora D. Salim, Yongli Ren, Piotr Koniusz", "title": "Relation Embedding for Personalised POI Recommendation", "comments": "12 pages, 3 figures, Accepted in the 24th Pacific-Asia Conference on\n  Knowledge Discovery and Data Mining (PAKDD 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-47426-3_5", "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-Interest (POI) recommendation is one of the most important\nlocation-based services helping people discover interesting venues or services.\nHowever, the extreme user-POI matrix sparsity and the varying spatio-temporal\ncontext pose challenges for POI systems, which affects the quality of POI\nrecommendations. To this end, we propose a translation-based relation embedding\nfor POI recommendation. Our approach encodes the temporal and geographic\ninformation, as well as semantic contents effectively in a low-dimensional\nrelation space by using Knowledge Graph Embedding techniques. To further\nalleviate the issue of user-POI matrix sparsity, a combined matrix\nfactorization framework is built on a user-POI graph to enhance the inference\nof dynamic personal interests by exploiting the side-information. Experiments\non two real-world datasets demonstrate the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 22:26:52 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:40:48 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Wang", "Xianjing", ""], ["Salim", "Flora D.", ""], ["Ren", "Yongli", ""], ["Koniusz", "Piotr", ""]]}, {"id": "2002.03469", "submitter": "Peng Chen", "authors": "Peng Chen, Omar Ghattas", "title": "Projected Stein Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality is a longstanding challenge in Bayesian inference\nin high dimensions. In this work, we propose a projected Stein variational\ngradient descent (pSVGD) method to overcome this challenge by exploiting the\nfundamental property of intrinsic low dimensionality of the data informed\nsubspace stemming from ill-posedness of such problems. We adaptively construct\nthe subspace using a gradient information matrix of the log-likelihood, and\napply pSVGD to the much lower-dimensional coefficients of the parameter\nprojection. The method is demonstrated to be more accurate and efficient than\nSVGD. It is also shown to be more scalable with respect to the number of\nparameters, samples, data points, and processor cores via experiments with\nparameters dimensions ranging from the hundreds to the tens of thousands.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 23:17:30 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:00:24 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Peng", ""], ["Ghattas", "Omar", ""]]}, {"id": "2002.03471", "submitter": "Felipe Tobar", "authors": "Taco de Wolff and Alejandro Cuevas and Felipe Tobar", "title": "MOGPTK: The Multi-Output Gaussian Process Toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MOGPTK, a Python package for multi-channel data modelling using\nGaussian processes (GP). The aim of this toolkit is to make multi-output GP\n(MOGP) models accessible to researchers, data scientists, and practitioners\nalike. MOGPTK uses a Python front-end, relies on the GPflow suite and is built\non a TensorFlow back-end, thus enabling GPU-accelerated training. The toolkit\nfacilitates implementing the entire pipeline of GP modelling, including data\nloading, parameter initialization, model learning, parameter interpretation, up\nto data imputation and extrapolation. MOGPTK implements the main multi-output\ncovariance kernels from literature, as well as spectral-based parameter\ninitialization strategies. The source code, tutorials and examples in the form\nof Jupyter notebooks, together with the API documentation, can be found at\nhttp://github.com/GAMES-UChile/mogptk\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 23:34:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["de Wolff", "Taco", ""], ["Cuevas", "Alejandro", ""], ["Tobar", "Felipe", ""]]}, {"id": "2002.03478", "submitter": "Omer Gottesman", "authors": "Omer Gottesman, Joseph Futoma, Yao Liu, Sonali Parbhoo, Leo Anthony\n  Celi, Emma Brunskill, Finale Doshi-Velez", "title": "Interpretable Off-Policy Evaluation in Reinforcement Learning by\n  Highlighting Influential Transitions", "comments": "ICML final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation in reinforcement learning offers the chance of using\nobservational data to improve future outcomes in domains such as healthcare and\neducation, but safe deployment in high stakes settings requires ways of\nassessing its validity. Traditional measures such as confidence intervals may\nbe insufficient due to noise, limited data and confounding. In this paper we\ndevelop a method that could serve as a hybrid human-AI system, to enable human\nexperts to analyze the validity of policy evaluation estimates. This is\naccomplished by highlighting observations in the data whose removal will have a\nlarge effect on the OPE estimate, and formulating a set of rules for choosing\nwhich ones to present to domain experts for validation. We develop methods to\ncompute exactly the influence functions for fitted Q-evaluation with two\ndifferent function classes: kernel-based and linear least squares, as well as\nimportance sampling methods. Experiments on medical simulations and real-world\nintensive care unit data demonstrate that our method can be used to identify\nlimitations in the evaluation process and make evaluation more robust.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:26:43 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:40:16 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 06:51:45 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Gottesman", "Omer", ""], ["Futoma", "Joseph", ""], ["Liu", "Yao", ""], ["Parbhoo", "Sonali", ""], ["Celi", "Leo Anthony", ""], ["Brunskill", "Emma", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2002.03480", "submitter": "Jeremy Nixon", "authors": "Jeremy Nixon, Jeremiah Liu, David Berthelot", "title": "Semi-Supervised Class Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One promising approach to dealing with datapoints that are outside of the\ninitial training distribution (OOD) is to create new classes that capture\nsimilarities in the datapoints previously rejected as uncategorizable. Systems\nthat generate labels can be deployed against an arbitrary amount of data,\ndiscovering classification schemes that through training create a higher\nquality representation of data. We introduce the Dataset Reconstruction\nAccuracy, a new and important measure of the effectiveness of a model's ability\nto create labels. We introduce benchmarks against this Dataset Reconstruction\nmetric. We apply a new heuristic, class learnability, for deciding whether a\nclass is worthy of addition to the training dataset. We show that our class\ndiscovery system can be successfully applied to vision and language, and we\ndemonstrate the value of semi-supervised learning in automatically discovering\nnovel classes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:29:44 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 01:31:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Nixon", "Jeremy", ""], ["Liu", "Jeremiah", ""], ["Berthelot", "David", ""]]}, {"id": "2002.03485", "submitter": "Dhairya Dalal", "authors": "Dhairya Dalal and Byron V. Galbraith", "title": "Evaluating Sequence-to-Sequence Learning Models for If-Then Program\n  Synthesis", "comments": "AAAI IPA workshop submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing enterprise process automation often requires significant\ntechnical expertise and engineering effort. It would be beneficial for\nnon-technical users to be able to describe a business process in natural\nlanguage and have an intelligent system generate the workflow that can be\nautomatically executed. A building block of process automations are If-Then\nprograms. In the consumer space, sites like IFTTT and Zapier allow users to\ncreate automations by defining If-Then programs using a graphical interface. We\nexplore the efficacy of modeling If-Then programs as a sequence learning task.\nWe find Seq2Seq approaches have high potential (performing strongly on the\nZapier recipes) and can serve as a promising approach to more complex program\nsynthesis challenges.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:45:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dalal", "Dhairya", ""], ["Galbraith", "Byron V.", ""]]}, {"id": "2002.03488", "submitter": "Nazar Waheed", "authors": "Nazar Waheed, Xiangjian He, Muhammad Ikram, Muhammad Usman, Saad Sajid\n  Hashmi, Muhammad Usman", "title": "Security and Privacy in IoT Using Machine Learning and Blockchain:\n  Threats & Countermeasures", "comments": "35 pages, ACM CSUR Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and privacy of the users have become significant concerns due to the\ninvolvement of the Internet of things (IoT) devices in numerous applications.\nCyber threats are growing at an explosive pace making the existing security and\nprivacy measures inadequate. Hence, everyone on the Internet is a product for\nhackers. Consequently, Machine Learning (ML) algorithms are used to produce\naccurate outputs from large complex databases, where the generated outputs can\nbe used to predict and detect vulnerabilities in IoT-based systems.\nFurthermore, Blockchain (BC) techniques are becoming popular in modern IoT\napplications to solve security and privacy issues. Several studies have been\nconducted on either ML algorithms or BC techniques. However, these studies\ntarget either security or privacy issues using ML algorithms or BC techniques,\nthus posing a need for a combined survey on efforts made in recent years\naddressing both security and privacy issues using ML algorithms and BC\ntechniques. In this paper, we provide a summary of research efforts made in the\npast few years, starting from 2008 to 2019, addressing security and privacy\nissues using ML algorithms and BCtechniques in the IoT domain. First, we\ndiscuss and categorize various security and privacy threats reported in the\npast twelve years in the IoT domain. Then, we classify the literature on\nsecurity and privacy efforts based on ML algorithms and BC techniques in the\nIoT domain. Finally, we identify and illuminate several challenges and future\nresearch directions in using ML algorithms and BC techniques to address\nsecurity and privacy issues in the IoT domain.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 01:11:38 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 06:14:27 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 00:06:40 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 03:53:52 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Waheed", "Nazar", ""], ["He", "Xiangjian", ""], ["Ikram", "Muhammad", ""], ["Usman", "Muhammad", ""], ["Hashmi", "Saad Sajid", ""], ["Usman", "Muhammad", ""]]}, {"id": "2002.03494", "submitter": "Pan Danqing", "authors": "Danqing Pan, Tong Wang, Satoshi Hara", "title": "Interpretable Companions for Black-Box Models", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interpretable companion model for any pre-trained black-box\nclassifiers. The idea is that for any input, a user can decide to either\nreceive a prediction from the black-box model, with high accuracy but no\nexplanations, or employ a companion rule to obtain an interpretable prediction\nwith slightly lower accuracy. The companion model is trained from data and the\npredictions of the black-box model, with the objective combining area under the\ntransparency--accuracy curve and model complexity. Our model provides flexible\nchoices for practitioners who face the dilemma of choosing between always using\ninterpretable models and always using black-box models for a predictive task,\nso users can, for any given input, take a step back to resort to an\ninterpretable prediction if they find the predictive performance satisfying, or\nstick to the black-box model if the rules are unsatisfying. To show the value\nof companion models, we design a human evaluation on more than a hundred people\nto investigate the tolerable accuracy loss to gain interpretability for humans.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 01:39:16 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 05:38:05 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Pan", "Danqing", ""], ["Wang", "Tong", ""], ["Hara", "Satoshi", ""]]}, {"id": "2002.03495", "submitter": "Zeke Xie", "authors": "Zeke Xie, Issei Sato, and Masashi Sugiyama", "title": "A Diffusion Theory For Deep Learning Dynamics: Stochastic Gradient\n  Descent Exponentially Favors Flat Minima", "comments": "ICLR 2021; 28 pages; 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) and its variants are mainstream methods for\ntraining deep networks in practice. SGD is known to find a flat minimum that\noften generalizes well. However, it is mathematically unclear how deep learning\ncan select a flat minimum among so many minima. To answer the question\nquantitatively, we develop a density diffusion theory (DDT) to reveal how\nminima selection quantitatively depends on the minima sharpness and the\nhyperparameters. To the best of our knowledge, we are the first to\ntheoretically and empirically prove that, benefited from the Hessian-dependent\ncovariance of stochastic gradient noise, SGD favors flat minima exponentially\nmore than sharp minima, while Gradient Descent (GD) with injected white noise\nfavors flat minima only polynomially more than sharp minima. We also reveal\nthat either a small learning rate or large-batch training requires\nexponentially many iterations to escape from minima in terms of the ratio of\nthe batch size and learning rate. Thus, large-batch training cannot search flat\nminima efficiently in a realistic computational time.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:04:49 GMT"}, {"version": "v10", "created": "Mon, 29 Jun 2020 05:27:27 GMT"}, {"version": "v11", "created": "Sat, 4 Jul 2020 04:54:20 GMT"}, {"version": "v12", "created": "Sat, 26 Sep 2020 11:36:52 GMT"}, {"version": "v13", "created": "Tue, 24 Nov 2020 05:12:13 GMT"}, {"version": "v14", "created": "Fri, 15 Jan 2021 14:57:46 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 06:24:38 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 04:40:24 GMT"}, {"version": "v4", "created": "Wed, 26 Feb 2020 08:27:12 GMT"}, {"version": "v5", "created": "Thu, 5 Mar 2020 12:04:23 GMT"}, {"version": "v6", "created": "Tue, 14 Apr 2020 10:51:51 GMT"}, {"version": "v7", "created": "Mon, 4 May 2020 08:11:19 GMT"}, {"version": "v8", "created": "Thu, 21 May 2020 00:54:13 GMT"}, {"version": "v9", "created": "Mon, 22 Jun 2020 03:52:54 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Xie", "Zeke", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.03497", "submitter": "Takeshi Teshima", "authors": "Takeshi Teshima, Issei Sato, Masashi Sugiyama", "title": "Few-shot Domain Adaptation by Causal Mechanism Transfer", "comments": "33 pages, 3 figures. Camera-ready version for Thirty-seventh\n  International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot supervised domain adaptation (DA) for regression problems,\nwhere only a few labeled target domain data and many labeled source domain data\nare available. Many of the current DA methods base their transfer assumptions\non either parametrized distribution shift or apparent distribution\nsimilarities, e.g., identical conditionals or small distributional\ndiscrepancies. However, these assumptions may preclude the possibility of\nadaptation from intricately shifted and apparently very different\ndistributions. To overcome this problem, we propose mechanism transfer, a\nmeta-distributional scenario in which a data generating mechanism is invariant\namong domains. This transfer assumption can accommodate nonparametric shifts\nresulting in apparently different distributions while providing a solid\nstatistical basis for DA. We take the structural equations in causal modeling\nas an example and propose a novel DA method, which is shown to be useful both\ntheoretically and experimentally. Our method can be seen as the first attempt\nto fully leverage the structural causal models for DA.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:16:53 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 00:10:29 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Teshima", "Takeshi", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.03500", "submitter": "Qing Guo", "authors": "Qing Guo and Felix Juefei-Xu and Xiaofei Xie and Lei Ma and Jian Wang\n  and Bing Yu and Wei Feng and Yang Liu", "title": "Watch out! Motion is Blurring the Vision of Your Deep Neural Networks", "comments": "19 pages, 16 figures. This paper has been accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art deep neural networks (DNNs) are vulnerable against\nadversarial examples with additive random-like noise perturbations. While such\nexamples are hardly found in the physical world, the image blurring effect\ncaused by object motion, on the other hand, commonly occurs in practice, making\nthe study of which greatly important especially for the widely adopted\nreal-time image processing tasks (e.g., object detection, tracking). In this\npaper, we initiate the first step to comprehensively investigate the potential\nhazards of the blur effect for DNN, caused by object motion. We propose a novel\nadversarial attack method that can generate visually natural motion-blurred\nadversarial examples, named motion-based adversarial blur attack (ABBA). To\nthis end, we first formulate the kernel-prediction-based attack where an input\nimage is convolved with kernels in a pixel-wise way, and the misclassification\ncapability is achieved by tuning the kernel weights. To generate visually more\nnatural and plausible examples, we further propose the saliency-regularized\nadversarial kernel prediction, where the salient region serves as a moving\nobject, and the predicted kernel is regularized to achieve naturally visual\neffects. Besides, the attack is further enhanced by adaptively tuning the\ntranslations of object and background. A comprehensive evaluation on the\nNeurIPS'17 adversarial competition dataset demonstrates the effectiveness of\nABBA by considering various kernel sizes, translations, and regions. The\nin-depth study further confirms that our method shows more effective\npenetrating capability to the state-of-the-art GAN-based deblurring mechanisms\ncompared with other blurring methods. We release the code to\nhttps://github.com/tsingqguo/ABBA.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:33:08 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 06:42:29 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 05:52:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Guo", "Qing", ""], ["Juefei-Xu", "Felix", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Wang", "Jian", ""], ["Yu", "Bing", ""], ["Feng", "Wei", ""], ["Liu", "Yang", ""]]}, {"id": "2002.03503", "submitter": "Ehsan Kazemi", "authors": "Ehsan Kazemi and Shervin Minaee and Moran Feldman and Amin Karbasi", "title": "Regularized Submodular Maximization at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose scalable methods for maximizing a regularized\nsubmodular function $f = g - \\ell$ expressed as the difference between a\nmonotone submodular function $g$ and a modular function $\\ell$. Indeed,\nsubmodularity is inherently related to the notions of diversity, coverage, and\nrepresentativeness. In particular, finding the mode of many popular\nprobabilistic models of diversity, such as determinantal point processes,\nsubmodular probabilistic models, and strongly log-concave distributions,\ninvolves maximization of (regularized) submodular functions. Since a\nregularized function $f$ can potentially take on negative values, the classic\ntheory of submodular maximization, which heavily relies on the non-negativity\nassumption of submodular functions, may not be applicable. To circumvent this\nchallenge, we develop the first one-pass streaming algorithm for maximizing a\nregularized submodular function subject to a $k$-cardinality constraint. It\nreturns a solution $S$ with the guarantee that $f(S)\\geq(\\phi^{-2}-\\epsilon)\n\\cdot g(OPT)-\\ell (OPT)$, where $\\phi$ is the golden ratio. Furthermore, we\ndevelop the first distributed algorithm that returns a solution $S$ with the\nguarantee that $\\mathbb{E}[f(S)] \\geq (1-\\epsilon) [(1-e^{-1}) \\cdot\ng(OPT)-\\ell(OPT)]$ in $O(1/ \\epsilon)$ rounds of MapReduce computation, without\nkeeping multiple copies of the entire dataset in each round (as it is usually\ndone). We should highlight that our result, even for the unregularized case\nwhere the modular term $\\ell$ is zero, improves the memory and communication\ncomplexity of the existing work by a factor of $O(1/ \\epsilon)$ while arguably\nprovides a simpler distributed algorithm and a unifying analysis. We also\nempirically study the performance of our scalable methods on a set of real-life\napplications, including finding the mode of distributions, data summarization,\nand product recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:37:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kazemi", "Ehsan", ""], ["Minaee", "Shervin", ""], ["Feldman", "Moran", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.03508", "submitter": "Sainyam Galhotra Mr", "authors": "Saba Ahmadi, Sainyam Galhotra, Barna Saha, Roy Schwartz", "title": "Fair Correlation Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we study the problem of correlation clustering under fairness\nconstraints. In the classic correlation clustering problem, we are given a\ncomplete graph where each edge is labeled positive or negative. The goal is to\nobtain a clustering of the vertices that minimizes disagreements -- the number\nof negative edges trapped inside a cluster plus positive edges between\ndifferent clusters.\n  We consider two variations of fairness constraint for the problem of\ncorrelation clustering where each node has a color, and the goal is to form\nclusters that do not over-represent vertices of any color.\n  The first variant aims to generate clusters with minimum disagreements, where\nthe distribution of a feature (e.g. gender) in each cluster is same as the\nglobal distribution. For the case of two colors when the desired ratio of the\nnumber of colors in each cluster is $1:p$, we get\n$\\mathcal{O}(p^2)$-approximation algorithm. Our algorithm could be extended to\nthe case of multiple colors. We prove this problem is NP-hard.\n  The second variant considers relative upper and lower bounds on the number of\nnodes of any color in a cluster. The goal is to avoid violating upper and lower\nbounds corresponding to each color in each cluster while minimizing the total\nnumber of disagreements. Along with our theoretical results, we show the\neffectiveness of our algorithm to generate fair clusters by empirical\nevaluation on real world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:59:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ahmadi", "Saba", ""], ["Galhotra", "Sainyam", ""], ["Saha", "Barna", ""], ["Schwartz", "Roy", ""]]}, {"id": "2002.03513", "submitter": "Shaojun Ma", "authors": "Shaojun Ma, Shu Liu, Hongyuan Zha, Haomin Zhou", "title": "Learning Stochastic Behaviour from Aggregate Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning nonlinear dynamics from aggregate data is a challenging problem\nbecause the full trajectory of each individual is not available, namely, the\nindividual observed at one time may not be observed at the next time point, or\nthe identity of individual is unavailable. This is in sharp contrast to\nlearning dynamics with full trajectory data, on which the majority of existing\nmethods are based. We propose a novel method using the weak form of Fokker\nPlanck Equation (FPE) -- a partial differential equation -- to describe the\ndensity evolution of data in a sampled form, which is then combined with\nWasserstein generative adversarial network (WGAN) in the training process. In\nsuch a sample-based framework we are able to learn the nonlinear dynamics from\naggregate data without explicitly solving the partial differential equation\n(PDE) FPE. We demonstrate our approach in the context of a series of synthetic\nand real-world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:20:13 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 02:54:51 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 02:55:54 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 03:32:07 GMT"}, {"version": "v5", "created": "Mon, 22 Feb 2021 04:48:44 GMT"}, {"version": "v6", "created": "Sat, 29 May 2021 02:41:01 GMT"}, {"version": "v7", "created": "Mon, 7 Jun 2021 13:41:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ma", "Shaojun", ""], ["Liu", "Shu", ""], ["Zha", "Hongyuan", ""], ["Zhou", "Haomin", ""]]}, {"id": "2002.03516", "submitter": "Ren Liu", "authors": "Ren Liu, Xiaoqun Zhang", "title": "Semi-Implicit Back Propagation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network has attracted great attention for a long time and many\nresearchers are devoted to improve the effectiveness of neural network training\nalgorithms. Though stochastic gradient descent (SGD) and other explicit\ngradient-based methods are widely adopted, there are still many challenges such\nas gradient vanishing and small step sizes, which leads to slow convergence and\ninstability of SGD algorithms. Motivated by error back propagation (BP) and\nproximal methods, we propose a semi-implicit back propagation method for neural\nnetwork training. Similar to BP, the difference on the neurons are propagated\nin a backward fashion and the parameters are updated with proximal mapping. The\nimplicit update for both hidden neurons and parameters allows to choose large\nstep size in the training algorithm. Finally, we also show that any fixed point\nof convergent sequences produced by this algorithm is a stationary point of the\nobjective loss function. The experiments on both MNIST and CIFAR-10 demonstrate\nthat the proposed semi-implicit BP algorithm leads to better performance in\nterms of both loss decreasing and training/validation accuracy, compared to SGD\nand a similar algorithm ProxBP.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:26:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Ren", ""], ["Zhang", "Xiaoqun", ""]]}, {"id": "2002.03517", "submitter": "Hongyang Zhang", "authors": "Avrim Blum, Travis Dick, Naren Manoj, Hongyang Zhang", "title": "Random Smoothing Might be Unable to Certify $\\ell_\\infty$ Robustness for\n  High-Dimensional Images", "comments": "20 pages, 2 figures; Code is available at\n  https://github.com/hongyanz/TRADES-smoothing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a hardness result for random smoothing to achieve certified\nadversarial robustness against attacks in the $\\ell_p$ ball of radius\n$\\epsilon$ when $p>2$. Although random smoothing has been well understood for\nthe $\\ell_2$ case using the Gaussian distribution, much remains unknown\nconcerning the existence of a noise distribution that works for the case of\n$p>2$. This has been posed as an open problem by Cohen et al. (2019) and\nincludes many significant paradigms such as the $\\ell_\\infty$ threat model. In\nthis work, we show that any noise distribution $\\mathcal{D}$ over\n$\\mathbb{R}^d$ that provides $\\ell_p$ robustness for all base classifiers with\n$p>2$ must satisfy\n$\\mathbb{E}\\eta_i^2=\\Omega(d^{1-2/p}\\epsilon^2(1-\\delta)/\\delta^2)$ for 99% of\nthe features (pixels) of vector $\\eta\\sim\\mathcal{D}$, where $\\epsilon$ is the\nrobust radius and $\\delta$ is the score gap between the highest-scored class\nand the runner-up. Therefore, for high-dimensional images with pixel values\nbounded in $[0,255]$, the required noise will eventually dominate the useful\ninformation in the images, leading to trivial smoothed classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:26:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 02:02:22 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 17:16:41 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Blum", "Avrim", ""], ["Dick", "Travis", ""], ["Manoj", "Naren", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2002.03518", "submitter": "Steven Cao", "authors": "Steven Cao, Nikita Kitaev, Dan Klein", "title": "Multilingual Alignment of Contextual Word Representations", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose procedures for evaluating and strengthening contextual embedding\nalignment and show that they are useful in analyzing and improving multilingual\nBERT. In particular, after our proposed alignment procedure, BERT exhibits\nsignificantly improved zero-shot performance on XNLI compared to the base\nmodel, remarkably matching pseudo-fully-supervised translate-train models for\nBulgarian and Greek. Further, to measure the degree of alignment, we introduce\na contextual version of word retrieval and show that it correlates well with\ndownstream zero-shot transfer. Using this word retrieval task, we also analyze\nBERT and find that it exhibits systematic deficiencies, e.g. worse alignment\nfor open-class parts-of-speech and word pairs written in different scripts,\nthat are corrected by the alignment procedure. These results support contextual\nalignment as a useful concept for understanding large multilingual pre-trained\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:27:21 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 23:28:06 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Cao", "Steven", ""], ["Kitaev", "Nikita", ""], ["Klein", "Dan", ""]]}, {"id": "2002.03519", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Self-Attentive Associative Memory", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heretofore, neural networks with external memory are restricted to single\nmemory with lossy representations of memory interactions. A rich representation\nof relationships between memory pieces urges a high-order and segregated\nrelational memory. In this paper, we propose to separate the storage of\nindividual experiences (item memory) and their occurring relationships\n(relational memory). The idea is implemented through a novel Self-attentive\nAssociative Memory (SAM) operator. Found upon outer product, SAM forms a set of\nassociative memories that represent the hypothetical high-order relationships\nbetween arbitrary pairs of memory elements, through which a relational memory\nis constructed from an item memory. The two memories are wired into a single\nsequential model capable of both memorization and relational reasoning. We\nachieve competitive results with our proposed two-memory model in a diversity\nof machine learning tasks, from challenging synthetic problems to practical\ntestbeds such as geometry, graph, reinforcement learning, and question\nanswering.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:27:48 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 02:32:37 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 04:56:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2002.03521", "submitter": "Shahriar Esmaeili", "authors": "Saeideh Roshanfekr, Shahriar Esmaeili, Hassan Ataeian, and Ali Amiri", "title": "UGRWO-Sampling: A modified random walk under-sampling approach based on\n  graphs to imbalanced data classification", "comments": "34 pages, 3 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we propose a new RWO-Sampling (Random Walk Over-Sampling)\nbased on graphs for imbalanced datasets. In this method, two figures based on\nunder-sampling and over-sampling methods are introduced to keep the proximity\ninformation, which is robust to noises and outliers. After the construction of\nthe first graph on minority class, RWO-Sampling will be implemented on selected\nsamples, and the rest of them will remain unchanged. The second graph is\nconstructed for the majority class, and the samples in a low-density area\n(outliers) are removed. In the proposed method, examples of the majority class\nin a high-density area are selected, and the rest of them are eliminated.\nFurthermore, utilizing RWO-sampling, the boundary of minority class is\nincreased though, the outliers are not raised. This method is tested, and the\nnumber of evaluation measures is compared to previous methods on nine\ncontinuous attribute datasets with different over-sampling rates. The\nexperimental results were an indicator of the high efficiency and flexibility\nof the proposed method for the classification of imbalanced data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:29:24 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 20:55:49 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Roshanfekr", "Saeideh", ""], ["Esmaeili", "Shahriar", ""], ["Ataeian", "Hassan", ""], ["Amiri", "Ali", ""]]}, {"id": "2002.03523", "submitter": "Ehsan Kazemi", "authors": "Ashwinkumar Badanidiyuru and Amin Karbasi and Ehsan Kazemi and Jan\n  Vondrak", "title": "Submodular Maximization Through Barrier Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel technique for constrained submodular\nmaximization, inspired by barrier functions in continuous optimization. This\nconnection not only improves the running time for constrained submodular\nmaximization but also provides the state of the art guarantee. More precisely,\nfor maximizing a monotone submodular function subject to the combination of a\n$k$-matchoid and $\\ell$-knapsack constraint (for $\\ell\\leq k$), we propose a\npotential function that can be approximately minimized. Once we minimize the\npotential function up to an $\\epsilon$ error it is guaranteed that we have\nfound a feasible set with a $2(k+1+\\epsilon)$-approximation factor which can\nindeed be further improved to $(k+1+\\epsilon)$ by an enumeration technique. We\nextensively evaluate the performance of our proposed algorithm over several\nreal-world applications, including a movie recommendation system, summarization\ntasks for YouTube videos, Twitter feeds and Yelp business locations, and a set\ncover problem.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:32:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Badanidiyuru", "Ashwinkumar", ""], ["Karbasi", "Amin", ""], ["Kazemi", "Ehsan", ""], ["Vondrak", "Jan", ""]]}, {"id": "2002.03532", "submitter": "Jiaxi Tang", "authors": "Jiaxi Tang, Rakesh Shivanna, Zhe Zhao, Dong Lin, Anima Singh, Ed H.\n  Chi, Sagar Jain", "title": "Understanding and Improving Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a model-agnostic technique to improve model\nquality while having a fixed capacity budget. It is a commonly used technique\nfor model compression, where a larger capacity teacher model with better\nquality is used to train a more compact student model with better inference\nefficiency. Through distillation, one hopes to benefit from student's\ncompactness, without sacrificing too much on model quality. Despite the large\nsuccess of knowledge distillation, better understanding of how it benefits\nstudent model's training dynamics remains under-explored. In this paper, we\ncategorize teacher's knowledge into three hierarchical levels and study its\neffects on knowledge distillation: (1) knowledge of the `universe', where KD\nbrings a regularization effect through label smoothing; (2) domain knowledge,\nwhere teacher injects class relationships prior to student's logit layer\ngeometry; and (3) instance specific knowledge, where teacher rescales student\nmodel's per-instance gradients based on its measurement on the event\ndifficulty. Using systematic analyses and extensive empirical studies on both\nsynthetic and real-world datasets, we confirm that the aforementioned three\nfactors play a major role in knowledge distillation. Furthermore, based on our\nfindings, we diagnose some of the failure cases of applying KD from recent\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:21:41 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 23:31:44 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Tang", "Jiaxi", ""], ["Shivanna", "Rakesh", ""], ["Zhao", "Zhe", ""], ["Lin", "Dong", ""], ["Singh", "Anima", ""], ["Chi", "Ed H.", ""], ["Jain", "Sagar", ""]]}, {"id": "2002.03534", "submitter": "Yuguang Yue", "authors": "Yuguang Yue, Yunhao Tang, Mingzhang Yin, Mingyuan Zhou", "title": "Discrete Action On-Policy Learning with Action-Value Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) in discrete action space is ubiquitous in\nreal-world applications, but its complexity grows exponentially with the\naction-space dimension, making it challenging to apply existing on-policy\ngradient based deep RL algorithms efficiently. To effectively operate in\nmultidimensional discrete action spaces, we construct a critic to estimate\naction-value functions, apply it on correlated actions, and combine these\ncritic estimated action values to control the variance of gradient estimation.\nWe follow rigorous statistical analysis to design how to generate and combine\nthese correlated actions, and how to sparsify the gradients by shutting down\nthe contributions from certain dimensions. These efforts result in a new\ndiscrete action on-policy RL algorithm that empirically outperforms related\non-policy algorithms relying on variance control techniques. We demonstrate\nthese properties on OpenAI Gym benchmark tasks, and illustrate how discretizing\nthe action space could benefit the exploration phase and hence facilitate\nconvergence to a better local optimal solution thanks to the flexibility of\ndiscrete policy.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 04:23:09 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 17:28:01 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Yue", "Yuguang", ""], ["Tang", "Yunhao", ""], ["Yin", "Mingzhang", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2002.03549", "submitter": "Rahul Soni", "authors": "Rahul Soni, Naresh Shah, Chua Tat Seng, Jimmy D. Moore", "title": "Adversarial TCAV -- Robust and Effective Interpretation of Intermediate\n  Layers in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpreting neural network decisions and the information learned in\nintermediate layers is still a challenge due to the opaque internal state and\nshared non-linear interactions. Although (Kim et al, 2017) proposed to\ninterpret intermediate layers by quantifying its ability to distinguish a\nuser-defined concept (from random examples), the questions of robustness\n(variation against the choice of random examples) and effectiveness (retrieval\nrate of concept images) remain. We investigate these two properties and propose\nimprovements to make concept activations reliable for practical use.\n  Effectiveness: If the intermediate layer has effectively learned a\nuser-defined concept, it should be able to recall --- at the testing step ---\nmost of the images containing the proposed concept. For instance, we observed\nthat the recall rate of Tiger shark and Great white shark from the ImageNet\ndataset with \"Fins\" as a user-defined concept was only 18.35% for VGG16. To\nincrease the effectiveness of concept learning, we propose A-CAV --- the\nAdversarial Concept Activation Vector --- this results in larger margins\nbetween user concepts and (negative) random examples. This approach improves\nthe aforesaid recall to 76.83% for VGG16.\n  For robustness, we define it as the ability of an intermediate layer to be\nconsistent in its recall rate (the effectiveness) for different random seeds.\nWe observed that TCAV has a large variance in recalling a concept across\ndifferent random seeds. For example, the recall of cat images (from a layer\nlearning the concept of tail) varies from 18% to 86% with 20.85% standard\ndeviation on VGG16. We propose a simple and scalable modification that employs\na Gram-Schmidt process to sample random noise from concepts and learn an\naverage \"concept classifier\". This approach improves the aforesaid standard\ndeviation from 20.85% to 6.4%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:15:03 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 18:15:30 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Soni", "Rahul", ""], ["Shah", "Naresh", ""], ["Seng", "Chua Tat", ""], ["Moore", "Jimmy D.", ""]]}, {"id": "2002.03553", "submitter": "Aaron Voelker", "authors": "Aaron R. Voelker and Daniel Rasmussen and Chris Eliasmith", "title": "A Spike in Performance: Training Hybrid-Spiking Neural Networks with\n  Quantized Activation Functions", "comments": "8 pages, 7 page supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community has become increasingly interested in the\nenergy efficiency of neural networks. The Spiking Neural Network (SNN) is a\npromising approach to energy-efficient computing, since its activation levels\nare quantized into temporally sparse, one-bit values (i.e., \"spike\" events),\nwhich additionally converts the sum over weight-activity products into a simple\naddition of weights (one weight for each spike). However, the goal of\nmaintaining state-of-the-art (SotA) accuracy when converting a non-spiking\nnetwork into an SNN has remained an elusive challenge, primarily due to spikes\nhaving only a single bit of precision. Adopting tools from signal processing,\nwe cast neural activation functions as quantizers with temporally-diffused\nerror, and then train networks while smoothly interpolating between the\nnon-spiking and spiking regimes. We apply this technique to the Legendre Memory\nUnit (LMU) to obtain the first known example of a hybrid SNN outperforming SotA\nrecurrent architectures -- including the LSTM, GRU, and NRU -- in accuracy,\nwhile reducing activities to at most 3.74 bits on average with 1.26 significant\nbits multiplying each weight. We discuss how these methods can significantly\nimprove the energy efficiency of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:24:27 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 22:02:28 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Voelker", "Aaron R.", ""], ["Rasmussen", "Daniel", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2002.03555", "submitter": "Richard Nock", "authors": "Richard Nock and Aditya Krishna Menon", "title": "Supervised Learning: No Loss No Cry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning requires the specification of a loss function to\nminimise. While the theory of admissible losses from both a computational and\nstatistical perspective is well-developed, these offer a panoply of different\nchoices. In practice, this choice is typically made in an \\emph{ad hoc} manner.\nIn hopes of making this procedure more principled, the problem of\n\\emph{learning the loss function} for a downstream task (e.g., classification)\nhas garnered recent interest. However, works in this area have been generally\nempirical in nature.\n  In this paper, we revisit the {\\sc SLIsotron} algorithm of Kakade et al.\n(2011) through a novel lens, derive a generalisation based on Bregman\ndivergences, and show how it provides a principled procedure for learning the\nloss. In detail, we cast {\\sc SLIsotron} as learning a loss from a family of\ncomposite square losses. By interpreting this through the lens of \\emph{proper\nlosses}, we derive a generalisation of {\\sc SLIsotron} based on Bregman\ndivergences. The resulting {\\sc BregmanTron} algorithm jointly learns the loss\nalong with the classifier. It comes equipped with a simple guarantee of\nconvergence for the loss it learns, and its set of possible outputs comes with\na guarantee of agnostic approximability of Bayes rule. Experiments indicate\nthat the {\\sc BregmanTron} substantially outperforms the {\\sc SLIsotron}, and\nthat the loss it learns can be minimized by other algorithms for different\ntasks, thereby opening the interesting problem of \\textit{loss transfer}\nbetween domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:30:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Nock", "Richard", ""], ["Menon", "Aditya Krishna", ""]]}, {"id": "2002.03559", "submitter": "Jaesung Huh", "authors": "Jaesung Huh, Egil Martinsson, Adrian Kim, Jung-Woo Ha", "title": "Modeling Musical Onset Probabilities via Neural Distribution Learning", "comments": "2 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Musical onset detection can be formulated as a time-to-event (TTE) or\ntime-since-event (TSE) prediction task by defining music as a sequence of onset\nevents. Here we propose a novel method to model the probability of onsets by\nintroducing a sequential density prediction model. The proposed model estimates\nTTE & TSE distributions from mel-spectrograms using convolutional neural\nnetworks (CNNs) as a density predictor. We evaluate our model on the Bock\ndataset show-ing comparable results to previous deep-learning models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:38:51 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Huh", "Jaesung", ""], ["Martinsson", "Egil", ""], ["Kim", "Adrian", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2002.03562", "submitter": "Shreyas Ramoji", "authors": "Shreyas Ramoji, Prashant Krishnan, Sriram Ganapathy", "title": "NPLDA: A Deep Neural PLDA Model for Speaker Verification", "comments": "Published in Odyssey 2020, the Speaker and Language Recognition\n  Workshop (VOiCES Special Session). Link to GitHub Implementation:\n  https://github.com/iiscleap/NeuralPlda. arXiv admin note: substantial text\n  overlap with arXiv:2001.07034", "journal-ref": "in Proc. Odyssey 2020 The Speaker and Language Recognition\n  Workshop, Pages 202-209", "doi": "10.21437/Odyssey.2020-29", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art approach for speaker verification consists of a neural\nnetwork based embedding extractor along with a backend generative model such as\nthe Probabilistic Linear Discriminant Analysis (PLDA). In this work, we propose\na neural network approach for backend modeling in speaker recognition. The\nlikelihood ratio score of the generative PLDA model is posed as a\ndiscriminative similarity function and the learnable parameters of the score\nfunction are optimized using a verification cost. The proposed model, termed as\nneural PLDA (NPLDA), is initialized using the generative PLDA model parameters.\nThe loss function for the NPLDA model is an approximation of the minimum\ndetection cost function (DCF). The speaker recognition experiments using the\nNPLDA model are performed on the speaker verificiation task in the VOiCES\ndatasets as well as the SITW challenge dataset. In these experiments, the NPLDA\nmodel optimized using the proposed loss function improves significantly over\nthe state-of-art PLDA based speaker verification system.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 05:47:35 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 05:40:56 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ramoji", "Shreyas", ""], ["Krishnan", "Prashant", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2002.03566", "submitter": "Ismail Shahin", "authors": "Ismail Shahin", "title": "Emotion Recognition Using Speaker Cues", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research aims at identifying the unknown emotion using speaker cues. In\nthis study, we identify the unknown emotion using a two-stage framework. The\nfirst stage focuses on identifying the speaker who uttered the unknown emotion,\nwhile the next stage focuses on identifying the unknown emotion uttered by the\nrecognized speaker in the prior stage. This proposed framework has been\nevaluated on an Arabic Emirati-accented speech database uttered by fifteen\nspeakers per gender. Mel-Frequency Cepstral Coefficients (MFCCs) have been used\nas the extracted features and Hidden Markov Model (HMM) has been utilized as\nthe classifier in this work. Our findings demonstrate that emotion recognition\naccuracy based on the two-stage framework is greater than that based on the\none-stage approach and the state-of-the-art classifiers and models such as\nGaussian Mixture Model (GMM), Support Vector Machine (SVM), and Vector\nQuantization (VQ). The average emotion recognition accuracy based on the\ntwo-stage approach is 67.5%, while the accuracy reaches to 61.4%, 63.3%, 64.5%,\nand 61.5%, based on the one-stage approach, GMM, SVM, and VQ, respectively. The\nachieved results based on the two-stage framework are very close to those\nattained in subjective assessment by human listeners.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 08:20:30 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shahin", "Ismail", ""]]}, {"id": "2002.03575", "submitter": "Hongmin Zhu", "authors": "Hongmin Zhu, Fuli Feng, Xiangnan He, Xiang Wang, Yan Li, Kai Zheng,\n  Yongdong Zhang", "title": "Bilinear Graph Neural Network with Neighbor Interactions", "comments": "Accepted by IJCAI 2020. SOLE copyright holder is IJCAI (International\n  Joint Conferences on Artificial Intelligence), all rights reserved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Network (GNN) is a powerful model to learn representations and\nmake predictions on graph data. Existing efforts on GNN have largely defined\nthe graph convolution as a weighted sum of the features of the connected nodes\nto form the representation of the target node. Nevertheless, the operation of\nweighted sum assumes the neighbor nodes are independent of each other, and\nignores the possible interactions between them. When such interactions exist,\nsuch as the co-occurrence of two neighbor nodes is a strong signal of the\ntarget node's characteristics, existing GNN models may fail to capture the\nsignal. In this work, we argue the importance of modeling the interactions\nbetween neighbor nodes in GNN. We propose a new graph convolution operator,\nwhich augments the weighted sum with pairwise interactions of the\nrepresentations of neighbor nodes. We term this framework as Bilinear Graph\nNeural Network (BGNN), which improves GNN representation ability with bilinear\ninteractions between neighbor nodes. In particular, we specify two BGNN models\nnamed BGCN and BGAT, based on the well-known GCN and GAT, respectively.\nEmpirical results on three public benchmarks of semi-supervised node\nclassification verify the effectiveness of BGNN -- BGCN (BGAT) outperforms GCN\n(GAT) by 1.6% (1.5%) in classification accuracy.Codes are available at:\nhttps://github.com/zhuhm1996/bgnn.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:43:38 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 08:20:11 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 01:50:32 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 03:51:46 GMT"}, {"version": "v5", "created": "Sat, 30 May 2020 02:41:36 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhu", "Hongmin", ""], ["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Li", "Yan", ""], ["Zheng", "Kai", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2002.03577", "submitter": "Juntae Kim", "authors": "Juntae Kim and Yoonhan Lee", "title": "Accelerating RNN Transducer Inference via One-Step Constrained Beam\n  Search", "comments": "4 pages", "journal-ref": null, "doi": "10.1109/LSP.2020.3036335", "report-no": null, "categories": "cs.LG eess.AS eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a one-step constrained (OSC) beam search to accelerate recurrent\nneural network (RNN) transducer (RNN-T) inference. The original RNN-T beam\nsearch has a while-loop leading to speed down of the decoding process. The OSC\nbeam search eliminates this while-loop by vectorizing multiple hypotheses. This\nvectorization is nontrivial as the expansion of the hypotheses within the\noriginal RNN-T beam search can be different from each other. However, we found\nthat the hypotheses expanded only once at each decoding step in most cases;\nthus, we constrained the maximum expansion number to one, thereby allowing\nvectorization of the hypotheses. For further acceleration, we assign\nconstraints to the prefixes of the hypotheses to prune the redundant search\nspace. In addition, OSC beam search has duplication check among hypotheses\nduring the decoding process as duplication can undesirably shrink the search\nspace. We achieved significant speedup compared with other RNN-T beam search\nmethods with lower phoneme and word error rate.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:51:31 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Kim", "Juntae", ""], ["Lee", "Yoonhan", ""]]}, {"id": "2002.03578", "submitter": "Shraddha Surana", "authors": "Shraddha Surana, Yogesh Wadadekar, Omkar Bait, Hrushikesh Bhosle", "title": "Predicting star formation properties of galaxies using deep learning", "comments": "9 pages, 13 figures, 3 Tables, Accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/staa537", "report-no": null, "categories": "astro-ph.GA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the star-formation properties of galaxies as a function of\ncosmic epoch is a critical exercise in studies of galaxy evolution.\nTraditionally, stellar population synthesis models have been used to obtain\nbest fit parameters that characterise star formation in galaxies. As multiband\nflux measurements become available for thousands of galaxies, an alternative\napproach to characterising star formation using machine learning becomes\nfeasible. In this work, we present the use of deep learning techniques to\npredict three important star formation properties -- stellar mass, star\nformation rate and dust luminosity. We characterise the performance of our deep\nlearning models through comparisons with outputs from a standard stellar\npopulation synthesis code.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:04:21 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Surana", "Shraddha", ""], ["Wadadekar", "Yogesh", ""], ["Bait", "Omkar", ""], ["Bhosle", "Hrushikesh", ""]]}, {"id": "2002.03580", "submitter": "Haoyu Zhao", "authors": "Wei Chen, Liwei Wang, Haoyu Zhao, Kai Zheng", "title": "Combinatorial Semi-Bandit in the Non-Stationary Environment", "comments": "Accepted to UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the non-stationary combinatorial semi-bandit\nproblem, both in the switching case and in the dynamic case. In the general\ncase where (a) the reward function is non-linear, (b) arms may be\nprobabilistically triggered, and (c) only approximate offline oracle exists\n\\cite{wang2017improving}, our algorithm achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{\\mathcal{S} T})$ distribution-dependent regret in\nthe switching case, and $\\tilde{\\mathcal{O}}(\\mathcal{V}^{1/3}T^{2/3})$ in the\ndynamic case, where $\\mathcal S$ is the number of switchings and $\\mathcal V$\nis the sum of the total ``distribution changes''. The regret bounds in both\nscenarios are nearly optimal, but our algorithm needs to know the parameter\n$\\mathcal S$ or $\\mathcal V$ in advance.\n  We further show that by employing another technique, our algorithm no longer\nneeds to know the parameters $\\mathcal S$ or $\\mathcal V$ but the regret bounds\ncould become suboptimal.\n  In a special case where the reward function is linear and we have an exact\noracle, we design a parameter-free algorithm that achieves nearly optimal\nregret both in the switching case and in the dynamic case without knowing the\nparameters in advance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:10:56 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 06:27:35 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Chen", "Wei", ""], ["Wang", "Liwei", ""], ["Zhao", "Haoyu", ""], ["Zheng", "Kai", ""]]}, {"id": "2002.03585", "submitter": "Che Wang", "authors": "Che Wang, Keith Ross", "title": "On the Convergence of the Monte Carlo Exploring Starts Algorithm for\n  Reinforcement Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple and natural algorithm for reinforcement learning is Monte Carlo\nExploring States (MCES), where the Q-function is estimated by averaging the\nMonte Carlo returns, and the policy is improved by choosing actions that\nmaximize the current estimate of the Q-function. Exploration is performed by\n\"exploring starts\", that is, each episode begins with a randomly chosen state\nand action and then follows the current policy. Establishing convergence for\nthis algorithm has been an open problem for more than 20 years. We make headway\nwith this problem by proving convergence for Optimal Policy Feed-Forward MDPs,\nwhich are MDPs whose states are not revisited within any episode for an optimal\npolicy. Such MDPs include all deterministic environments (including Cliff\nWalking and other gridworld examples) and a large class of stochastic\nenvironments (including Blackjack). The convergence results presented here make\nprogress for this long-standing open problem in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:54:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Wang", "Che", ""], ["Ross", "Keith", ""]]}, {"id": "2002.03595", "submitter": "Xian Wu", "authors": "Xian Wu, Chao Huang, Pablo Roblesgranda, Nitesh Chawla", "title": "Representation Learning on Variable Length and Incomplete\n  Wearable-Sensory Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevalence of wearable sensors (e.g., smart wristband) is creating\nunprecedented opportunities to not only inform health and wellness states of\nindividuals, but also assess and infer personal attributes, including\ndemographic and personality attributes. However, the data captured from\nwearables, such as heart rate or number of steps, present two key challenges:\n1) the time series is often of variable-length and incomplete due to different\ndata collection periods (e.g., wearing behavior varies by person); and 2)\ninter-individual variability to external factors like stress and environment.\nThis paper addresses these challenges and brings us closer to the potential of\npersonalized insights about an individual, taking the leap from quantified self\nto qualified self. Specifically, HeartSpace proposed in this paper encodes time\nseries data with variable-length and missing values via the integration of a\ntime series encoding module and a pattern aggregation network. Additionally,\nHeartSpace implements a Siamese-triplet network to optimize representations by\njointly capturing intra- and inter-series correlations during the embedding\nlearning process. The empirical evaluation over two different real-world data\npresents significant performance gains overstate-of-the-art baselines in a\nvariety of applications, including personality prediction, demographics\ninference, and user identification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:20:44 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 05:28:08 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 21:14:48 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Wu", "Xian", ""], ["Huang", "Chao", ""], ["Roblesgranda", "Pablo", ""], ["Chawla", "Nitesh", ""]]}, {"id": "2002.03614", "submitter": "Ghadeer Abuoda", "authors": "Aisha Mohamed, Ghadeer Abuoda, Abdurrahman Ghanem, Zoi Kaoudi, Ashraf\n  Aboulnaga", "title": "RDFFrames: Knowledge Graph Access for Machine Learning Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs represented as RDF datasets are integral to many machine\nlearning applications. RDF is supported by a rich ecosystem of data management\nsystems and tools, most notably RDF database systems that provide a SPARQL\nquery interface. Surprisingly, machine learning tools for knowledge graphs do\nnot use SPARQL, despite the obvious advantages of using a database system. This\nis due to the mismatch between SPARQL and machine learning tools in terms of\ndata model and programming style. Machine learning tools work on data in\ntabular format and process it using an imperative programming style, while\nSPARQL is declarative and has as its basic operation matching graph patterns to\nRDF triples. We posit that a good interface to knowledge graphs from a machine\nlearning software stack should use an imperative, navigational programming\nparadigm based on graph traversal rather than the SPARQL query paradigm based\non graph patterns. In this paper, we present RDFFrames, a framework that\nprovides such an interface. RDFFrames provides an imperative Python API that\ngets internally translated to SPARQL, and it is integrated with the PyData\nmachine learning software stack. RDFFrames enables the user to make a sequence\nof Python calls to define the data to be extracted from a knowledge graph\nstored in an RDF database system, and it translates these calls into a compact\nSPQARL query, executes it on the database system, and returns the results in a\nstandard tabular format. Thus, RDFFrames is a useful tool for data preparation\nthat combines the usability of PyData with the flexibility and performance of\nRDF database systems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 09:39:25 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 22:52:40 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 06:39:37 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Mohamed", "Aisha", ""], ["Abuoda", "Ghadeer", ""], ["Ghanem", "Abdurrahman", ""], ["Kaoudi", "Zoi", ""], ["Aboulnaga", "Ashraf", ""]]}, {"id": "2002.03624", "submitter": "Guillaume Richard", "authors": "Guillaume Richard, Beno\\^it Grossin, Guillaume Germaine, Georges\n  H\\'ebrail, Anne de Moliner", "title": "Autoencoder-based time series clustering with energy applications", "comments": null, "journal-ref": "Conf\\'erence sur l'Apprentissage Automatique 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series clustering is a challenging task due to the specific nature of\nthe data. Classical approaches do not perform well and need to be adapted\neither through a new distance measure or a data transformation. In this paper\nwe investigate the combination of a convolutional autoencoder and a k-medoids\nalgorithm to perfom time series clustering. The convolutional autoencoder\nallows to extract meaningful features and reduce the dimension of the data,\nleading to an improvement of the subsequent clustering. Using simulation and\nenergy related data to validate the approach, experimental results show that\nthe clustering is robust to outliers thus leading to finer clusters than with\nstandard methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:04:29 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Richard", "Guillaume", ""], ["Grossin", "Beno\u00eet", ""], ["Germaine", "Guillaume", ""], ["H\u00e9brail", "Georges", ""], ["de Moliner", "Anne", ""]]}, {"id": "2002.03629", "submitter": "Yang Song", "authors": "Yang Song, Chenlin Meng, Renjie Liao, Stefano Ermon", "title": "Accelerating Feedforward Computation via Parallel Nonlinear Equation\n  Solving", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward computation, such as evaluating a neural network or sampling from\nan autoregressive model, is ubiquitous in machine learning. The sequential\nnature of feedforward computation, however, requires a strict order of\nexecution and cannot be easily accelerated with parallel computing. To enable\nparallelization, we frame the task of feedforward computation as solving a\nsystem of nonlinear equations. We then propose to find the solution using a\nJacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods\nof both. Crucially, Jacobi updates operate independently on each equation and\ncan be executed in parallel. Our method is guaranteed to give exactly the same\nvalues as the original feedforward computation with a reduced (or equal) number\nof parallelizable iterations, and hence reduced time given sufficient parallel\ncomputing power. Experimentally, we demonstrate the effectiveness of our\napproach in accelerating (i) backpropagation of RNNs, (ii) evaluation of\nDenseNets, and (iii) autoregressive sampling of MADE and PixelCNN++, with\nspeedup factors between 2.1 and 26 under various settings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:11:31 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:44:07 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Song", "Yang", ""], ["Meng", "Chenlin", ""], ["Liao", "Renjie", ""], ["Ermon", "Stefano", ""]]}, {"id": "2002.03636", "submitter": "Joseph de Vilmarest", "authors": "Joseph de Vilmarest (LPSM (UMR\\_8001)), Olivier Wintenberger (LPSM\n  (UMR\\_8001))", "title": "Stochastic Online Optimization using Kalman Recursion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the Extended Kalman Filter in constant dynamics, offering a bayesian\nperspective of stochastic optimization. We obtain high probability bounds on\nthe cumulative excess risk in an unconstrained setting. In order to avoid any\nprojection step we propose a two-phase analysis. First, for linear and logistic\nregressions, we prove that the algorithm enters a local phase where the\nestimate stays in a small region around the optimum. We provide explicit bounds\nwith high probability on this convergence time. Second, for generalized linear\nregressions, we provide a martingale analysis of the excess risk in the local\nphase, improving existing ones in bounded stochastic optimization. The EKF\nappears as a parameter-free online algorithm with O(d^2) cost per iteration\nthat optimally solves some unconstrained optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:33:35 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 08:15:29 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["de Vilmarest", "Joseph", "", "LPSM"], ["Wintenberger", "Olivier", "", "LPSM"]]}, {"id": "2002.03647", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Alexander Trott, Caiming Xiong, Richard Socher,\n  Xavier Giro-i-Nieto, Jordi Torres", "title": "Explore, Discover and Learn: Unsupervised Discovery of State-Covering\n  Skills", "comments": "17 pages, 11 figures. Code is publicly available at\n  https://github.com/victorcampos7/edl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring abilities in the absence of a task-oriented reward function is at\nthe frontier of reinforcement learning research. This problem has been studied\nthrough the lens of empowerment, which draws a connection between option\ndiscovery and information theory. Information-theoretic skill discovery methods\nhave garnered much interest from the community, but little research has been\nconducted in understanding their limitations. Through theoretical analysis and\nempirical evidence, we show that existing algorithms suffer from a common\nlimitation -- they discover options that provide a poor coverage of the state\nspace. In light of this, we propose 'Explore, Discover and Learn' (EDL), an\nalternative approach to information-theoretic skill discovery. Crucially, EDL\noptimizes the same information-theoretic objective derived from the empowerment\nliterature, but addresses the optimization problem using different machinery.\nWe perform an extensive evaluation of skill discovery methods on controlled\nenvironments and show that EDL offers significant advantages, such as\novercoming the coverage problem, reducing the dependence of learned skills on\nthe initial state, and allowing the user to define a prior over which behaviors\nshould be learned. Code is publicly available at\nhttps://github.com/victorcampos7/edl.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 10:49:53 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:44:12 GMT"}, {"version": "v3", "created": "Sat, 21 Mar 2020 12:08:59 GMT"}, {"version": "v4", "created": "Mon, 3 Aug 2020 11:06:21 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Trott", "Alexander", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""]]}, {"id": "2002.03657", "submitter": "Tong Chen", "authors": "Tong Chen, Jean-Bernard Lasserre, Victor Magron, Edouard Pauwels", "title": "Semialgebraic Optimization for Lipschitz Constants of ReLU Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lipschitz constant of a network plays an important role in many\napplications of deep learning, such as robustness certification and Wasserstein\nGenerative Adversarial Network. We introduce a semidefinite programming\nhierarchy to estimate the global and local Lipschitz constant of a multiple\nlayer deep neural network. The novelty is to combine a polynomial lifting for\nReLU functions derivatives with a weak generalization of Putinar's positivity\ncertificate. This idea could also apply to other, nearly sparse, polynomial\noptimization problems in machine learning. We empirically demonstrate that our\nmethod provides a trade-off with respect to state of the art linear programming\napproach, and in some cases we obtain better bounds in less time.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:09:37 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 10:09:43 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 10:56:40 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 09:19:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Chen", "Tong", ""], ["Lasserre", "Jean-Bernard", ""], ["Magron", "Victor", ""], ["Pauwels", "Edouard", ""]]}, {"id": "2002.03665", "submitter": "Haoyi Fan", "authors": "Haoyi Fan, Fengbin Zhang, Zuoyong Li", "title": "AnomalyDAE: Dual autoencoder for anomaly detection on attributed\n  networks", "comments": "Accepted by ICASSP2020. Copyright (c) 2020 IEEE. The source codes are\n  publicly available: https://github.com/haoyfan/AnomalyDAE. Only personal use\n  of these materials is permitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection on attributed networks aims at finding nodes whose patterns\ndeviate significantly from the majority of reference nodes, which is pervasive\nin many applications such as network intrusion detection and social spammer\ndetection. However, most existing methods neglect the complex cross-modality\ninteractions between network structure and node attribute. In this paper, we\npropose a deep joint representation learning framework for anomaly detection\nthrough a dual autoencoder (AnomalyDAE), which captures the complex\ninteractions between network structure and node attribute for high-quality\nembeddings. Specifically, AnomalyDAE consists of a structure autoencoder and an\nattribute autoencoder to learn both node embedding and attribute embedding\njointly in latent space. Moreover, attention mechanism is employed in structure\nencoder to learn the importance between a node and its neighbors for an\neffective capturing of structure pattern, which is important to anomaly\ndetection. Besides, by taking both the node embedding and attribute embedding\nas inputs of attribute decoder, the cross-modality interactions between network\nstructure and node attribute are learned during the reconstruction of node\nattribute. Finally, anomalies can be detected by measuring the reconstruction\nerrors of nodes from both the structure and attribute perspectives. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:32:23 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 10:26:44 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Fan", "Haoyi", ""], ["Zhang", "Fengbin", ""], ["Li", "Zuoyong", ""]]}, {"id": "2002.03668", "submitter": "Rajarshi Roy", "authors": "Rajarshi Roy, Dana Fisman and Daniel Neider", "title": "Learning Interpretable Models in the Property Specification Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning human-interpretable descriptions of a\ncomplex system from a finite set of positive and negative examples of its\nbehavior. In contrast to most of the recent work in this area, which focuses on\ndescriptions expressed in Linear Temporal Logic (LTL), we develop a learning\nalgorithm for formulas in the IEEE standard temporal logic PSL (Property\nSpecification Language). Our work is motivated by the fact that many natural\nproperties, such as an event happening at every n-th point in time, cannot be\nexpressed in LTL, whereas it is easy to express such properties in PSL.\nMoreover, formulas in PSL can be more succinct and easier to interpret (due to\nthe use of regular expressions in PSL formulas) than formulas in LTL.\n  Our learning algorithm builds on top of an existing algorithm for learning\nLTL formulas. Roughly speaking, our algorithm reduces the learning task to a\nconstraint satisfaction problem in propositional logic and then uses a SAT\nsolver to search for a solution in an incremental fashion. We have implemented\nour algorithm and performed a comparative study between the proposed method and\nthe existing LTL learning algorithm. Our results illustrate the effectiveness\nof the proposed approach to provide succinct human-interpretable descriptions\nfrom examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:42:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Roy", "Rajarshi", ""], ["Fisman", "Dana", ""], ["Neider", "Daniel", ""]]}, {"id": "2002.03673", "submitter": "Tongliang Liu", "authors": "Yu Yao and Tongliang Liu and Bo Han and Mingming Gong and Gang Niu and\n  Masashi Sugiyama and Dacheng Tao", "title": "Towards Mixture Proportion Estimation without Irreducibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{Mixture proportion estimation} (MPE) is a fundamental problem of\npractical significance, where we are given data from only a \\textit{mixture}\nand one of its two \\textit{components} to identify the proportion of each\ncomponent. All existing MPE methods that are distribution-independent\nexplicitly or implicitly rely on the \\textit{irreducible} assumption---the\nunobserved component is not a mixture containing the observable component. If\nthis is not satisfied, those methods will lead to a critical estimation bias.\nIn this paper, we propose \\textit{Regrouping-MPE} that works without\nirreducible assumption: it builds a new irreducible MPE problem and solves the\nnew problem. It is worthwhile to change the problem: we prove that if the\nassumption holds, our method will not affect anything; if the assumption does\nnot hold, the bias from problem changing is less than the bias from violation\nof the irreducible assumption in the original problem. Experiments show that\nour method outperforms all state-of-the-art MPE methods on various real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:57:30 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yao", "Yu", ""], ["Liu", "Tongliang", ""], ["Han", "Bo", ""], ["Gong", "Mingming", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""], ["Tao", "Dacheng", ""]]}, {"id": "2002.03677", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on, Ana I. Rastrojo", "title": "Minimum adjusted Rand index for two clusterings of a given size", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adjusted Rand index (ARI) is commonly used in cluster analysis to measure\nthe degree of agreement between two data partitions. Since its introduction,\nexploring the situations of extreme agreement and disagreement under different\ncircumstances has been a subject of interest, in order to achieve a better\nunderstanding of this index. Here, an explicit formula for the lowest possible\nvalue of the ARI for two clusterings of given sizes is shown, and moreover a\nspecific pair of clusterings achieving such a bound is provided.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:16:49 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 08:31:06 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 08:35:33 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""], ["Rastrojo", "Ana I.", ""]]}, {"id": "2002.03687", "submitter": "Xunpeng Huang", "authors": "Xunpeng Huang, Xianfeng Liang, Zhengyang Liu, Yitan Li, Linyun Yu, Yue\n  Yu, Lei Li", "title": "SPAN: A Stochastic Projected Approximate Newton Method", "comments": "Appeared in the AAAI 2020, 25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second-order optimization methods have desirable convergence properties.\nHowever, the exact Newton method requires expensive computation for the Hessian\nand its inverse. In this paper, we propose SPAN, a novel approximate and fast\nNewton method. SPAN computes the inverse of the Hessian matrix via low-rank\napproximation and stochastic Hessian-vector products. Our experiments on\nmultiple benchmark datasets demonstrate that SPAN outperforms existing\nfirst-order and second-order optimization methods in terms of the convergence\nwall-clock time. Furthermore, we provide a theoretical analysis of the\nper-iteration complexity, the approximation error, and the convergence rate.\nBoth the theoretical analysis and experimental results show that our proposed\nmethod achieves a better trade-off between the convergence rate and the\nper-iteration efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:42:42 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 02:01:33 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Huang", "Xunpeng", ""], ["Liang", "Xianfeng", ""], ["Liu", "Zhengyang", ""], ["Li", "Yitan", ""], ["Yu", "Linyun", ""], ["Yu", "Yue", ""], ["Li", "Lei", ""]]}, {"id": "2002.03688", "submitter": "Dmitrii Lachinov", "authors": "Dmitrii Lachinov, Elena Shipunova and Vadim Turlapov", "title": "Knowledge Distillation for Brain Tumor Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The segmentation of brain tumors in multimodal MRIs is one of the most\nchallenging tasks in medical image analysis. The recent state of the art\nalgorithms solving this task is based on machine learning approaches and deep\nlearning in particular. The amount of data used for training such models and\nits variability is a keystone for building an algorithm with high\nrepresentation power. In this paper, we study the relationship between the\nperformance of the model and the amount of data employed during the training\nprocess. On the example of brain tumor segmentation challenge, we compare the\nmodel trained with labeled data provided by challenge organizers, and the same\nmodel trained in omni-supervised manner using additional unlabeled data\nannotated with the ensemble of heterogeneous models. As a result, a single\nmodel trained with additional data achieves performance close to the ensemble\nof multiple models and outperforms individual methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:44:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lachinov", "Dmitrii", ""], ["Shipunova", "Elena", ""], ["Turlapov", "Vadim", ""]]}, {"id": "2002.03689", "submitter": "Junhyung Park", "authors": "Junhyung Park and Krikamol Muandet", "title": "A Measure-Theoretic Approach to Kernel Conditional Mean Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an operator-free, measure-theoretic approach to the conditional\nmean embedding (CME) as a random variable taking values in a reproducing kernel\nHilbert space. While the kernel mean embedding of unconditional distributions\nhas been defined rigorously, the existing operator-based approach of the\nconditional version depends on stringent assumptions that hinder its analysis.\nWe overcome this limitation via a measure-theoretic treatment of CMEs. We\nderive a natural regression interpretation to obtain empirical estimates, and\nprovide a thorough theoretical analysis thereof, including universal\nconsistency. As natural by-products, we obtain the conditional analogues of the\nmaximum mean discrepancy and Hilbert-Schmidt independence criterion, and\ndemonstrate their behaviour via simulations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:44:12 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 10:47:43 GMT"}, {"version": "v3", "created": "Thu, 12 Mar 2020 08:31:36 GMT"}, {"version": "v4", "created": "Sat, 18 Apr 2020 15:51:42 GMT"}, {"version": "v5", "created": "Wed, 22 Apr 2020 09:03:33 GMT"}, {"version": "v6", "created": "Fri, 24 Apr 2020 12:14:10 GMT"}, {"version": "v7", "created": "Thu, 22 Oct 2020 11:43:47 GMT"}, {"version": "v8", "created": "Fri, 8 Jan 2021 14:55:23 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Park", "Junhyung", ""], ["Muandet", "Krikamol", ""]]}, {"id": "2002.03700", "submitter": "Antonia Godoy-Lorite Dr.", "authors": "Antonia Godoy-Lorite, Roger Guimera and Marta Sales-Pardo", "title": "Network-based models for social recommender systems", "comments": null, "journal-ref": "\"Business and Consumer Analytics: New Ideas\", edited by Moscato\n  P., de Vries N, (2019)", "doi": "10.1007/978-3-030-06222-4_11", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the overwhelming online products available in recent years, there is an\nincreasing need to filter and deliver relevant personalized advice for users.\nRecommender systems solve this problem by modeling and predicting individual\npreferences for a great variety of items such as movies, books or research\narticles. In this chapter, we explore rigorous network-based models that\noutperform leading approaches for recommendation. The network models we\nconsider are based on the explicit assumption that there are groups of\nindividuals and of items, and that the preferences of an individual for an item\nare determined only by their group memberships. The accurate prediction of\nindividual user preferences over items can be accomplished by different\nmethodologies, such as Monte Carlo sampling or Expectation-Maximization\nmethods, the latter resulting in a scalable algorithm which is suitable for\nlarge datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:06:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Godoy-Lorite", "Antonia", ""], ["Guimera", "Roger", ""], ["Sales-Pardo", "Marta", ""]]}, {"id": "2002.03703", "submitter": "Shihua Zhang", "authors": "Chihao Zhang and Yang Yang and Wei Zhang and Shihua Zhang", "title": "Distributed Bayesian Matrix Decomposition for Big Data Mining and\n  Clustering", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix decomposition is one of the fundamental tools to discover knowledge\nfrom big data generated by modern applications. However, it is still\ninefficient or infeasible to process very big data using such a method in a\nsingle machine. Moreover, big data are often distributedly collected and stored\non different machines. Thus, such data generally bear strong heterogeneous\nnoise. It is essential and useful to develop distributed matrix decomposition\nfor big data analytics. Such a method should scale up well, model the\nheterogeneous noise, and address the communication issue in a distributed\nsystem. To this end, we propose a distributed Bayesian matrix decomposition\nmodel (DBMD) for big data mining and clustering. Specifically, we adopt three\nstrategies to implement the distributed computing including 1) the accelerated\ngradient descent, 2) the alternating direction method of multipliers (ADMM),\nand 3) the statistical inference. We investigate the theoretical convergence\nbehaviors of these algorithms. To address the heterogeneity of the noise, we\npropose an optimal plug-in weighted average that reduces the variance of the\nestimation. Synthetic experiments validate our theoretical results, and\nreal-world experiments show that our algorithms scale up well to big data and\nachieves superior or competing performance compared to other distributed\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:10:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Chihao", ""], ["Yang", "Yang", ""], ["Zhang", "Wei", ""], ["Zhang", "Shihua", ""]]}, {"id": "2002.03704", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Lewis Smith, Yarin Gal", "title": "Liberty or Depth: Deep Bayesian Neural Nets Do Not Need Complex Weight\n  Posterior Approximations", "comments": "Advances In Neural Information Processing Systems. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We challenge the longstanding assumption that the mean-field approximation\nfor variational inference in Bayesian neural networks is severely restrictive,\nand show this is not the case in deep networks. We prove several results\nindicating that deep mean-field variational weight posteriors can induce\nsimilar distributions in function-space to those induced by shallower networks\nwith complex weight posteriors. We validate our theoretical contributions\nempirically, both through examination of the weight posterior using Hamiltonian\nMonte Carlo in small models and by comparing diagonal- to structured-covariance\nin large settings. Since complex variational posteriors are often expensive and\ncumbersome to implement, our results suggest that using mean-field variational\ninference in a deeper model is both a practical and theoretically justified\nalternative to structured approximations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:11:45 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:39:50 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 11:55:29 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 09:19:13 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Smith", "Lewis", ""], ["Gal", "Yarin", ""]]}, {"id": "2002.03712", "submitter": "Conor Durkan", "authors": "Conor Durkan, Iain Murray, George Papamakarios", "title": "On Contrastive Learning for Likelihood-free Inference", "comments": "Appeared at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free methods perform parameter inference in stochastic simulator\nmodels where evaluating the likelihood is intractable but sampling synthetic\ndata is possible. One class of methods for this likelihood-free problem uses a\nclassifier to distinguish between pairs of parameter-observation samples\ngenerated using the simulator and pairs sampled from some reference\ndistribution, which implicitly learns a density ratio proportional to the\nlikelihood. Another popular class of methods fits a conditional distribution to\nthe parameter posterior directly, and a particular recent variant allows for\nthe use of flexible neural density estimators for this task. In this work, we\nshow that both of these approaches can be unified under a general contrastive\nlearning scheme, and clarify how they should be run and compared.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:14:01 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 12:44:53 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Durkan", "Conor", ""], ["Murray", "Iain", ""], ["Papamakarios", "George", ""]]}, {"id": "2002.03716", "submitter": "Yongming Li", "authors": "Xiaoheng Zhang, Yongming Li, Pin Wang, Xiaoheng Tan, and Yuchuan Liu", "title": "Classification Algorithm of Speech Data of Parkinsons Disease Based on\n  Convolution Sparse Kernel Transfer Learning with Optimal Kernel and Parallel\n  Sample Feature Selection", "comments": "12 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeled speech data from patients with Parkinsons disease (PD) are scarce,\nand the statistical distributions of training and test data differ\nsignificantly in the existing datasets. To solve these problems, dimensional\nreduction and sample augmentation must be considered. In this paper, a novel PD\nclassification algorithm based on sparse kernel transfer learning combined with\na parallel optimization of samples and features is proposed. Sparse transfer\nlearning is used to extract effective structural information of PD speech\nfeatures from public datasets as source domain data, and the fast ADDM\niteration is improved to enhance the information extraction performance. To\nimplement the parallel optimization, the potential relationships between\nsamples and features are considered to obtain high-quality combined features.\nFirst, features are extracted from a specific public speech dataset to\nconstruct a feature dataset as the source domain. Then, the PD target domain,\nincluding the training and test datasets, is encoded by convolution sparse\ncoding, which can extract more in-depth information. Next, parallel\noptimization is implemented. To further improve the classification performance,\na convolution kernel optimization mechanism is designed. Using two\nrepresentative public datasets and one self-constructed dataset, the\nexperiments compare over thirty relevant algorithms. The results show that when\ntaking the Sakar dataset, MaxLittle dataset and DNSH dataset as target domains,\nthe proposed algorithm achieves obvious improvements in classification\naccuracy. The study also found large improvements in the algorithms in this\npaper compared with nontransfer learning approaches, demonstrating that\ntransfer learning is both more effective and has a more acceptable time cost.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:20:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Xiaoheng", ""], ["Li", "Yongming", ""], ["Wang", "Pin", ""], ["Tan", "Xiaoheng", ""], ["Liu", "Yuchuan", ""]]}, {"id": "2002.03721", "submitter": "Matthias Perkonigg", "authors": "Matthias Perkonigg and Daniel Sobotka and Ahmed Ba-Ssalamah and Georg\n  Langs", "title": "Unsupervised deep clustering for predictive texture pattern discovery in\n  medical images", "comments": "Medical Imaging meets NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive marker patterns in imaging data are a means to quantify disease\nand progression, but their identification is challenging, if the underlying\nbiology is poorly understood. Here, we present a method to identify predictive\ntexture patterns in medical images in an unsupervised way. Based on deep\nclustering networks, we simultaneously encode and cluster medical image patches\nin a low-dimensional latent space. The resulting clusters serve as features for\ndisease staging, linking them to the underlying disease. We evaluate the method\non 70 T1-weighted magnetic resonance images of patients with different stages\nof liver steatosis. The deep clustering approach is able to find predictive\nclusters with a stable ranking, differentiating between low and high steatosis\nwith an F1-Score of 0.78.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:57:59 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Perkonigg", "Matthias", ""], ["Sobotka", "Daniel", ""], ["Ba-Ssalamah", "Ahmed", ""], ["Langs", "Georg", ""]]}, {"id": "2002.03722", "submitter": "Pierre Ablin", "authors": "Pierre Ablin, Gabriel Peyr\\'e and Thomas Moreau", "title": "Super-efficiency of automatic differentiation for functions defined as a\n  minimum", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In min-min optimization or max-min optimization, one has to compute the\ngradient of a function defined as a minimum. In most cases, the minimum has no\nclosed-form, and an approximation is obtained via an iterative algorithm. There\nare two usual ways of estimating the gradient of the function: using either an\nanalytic formula obtained by assuming exactness of the approximation, or\nautomatic differentiation through the algorithm. In this paper, we study the\nasymptotic error made by these estimators as a function of the optimization\nerror. We find that the error of the automatic estimator is close to the square\nof the error of the analytic estimator, reflecting a super-efficiency\nphenomenon. The convergence of the automatic estimator greatly depends on the\nconvergence of the Jacobian of the algorithm. We analyze it for gradient\ndescent and stochastic gradient descent and derive convergence rates for the\nestimators in these cases. Our analysis is backed by numerical experiments on\ntoy problems and on Wasserstein barycenter computation. Finally, we discuss the\ncomputational complexity of these estimators and give practical guidelines to\nchose between them.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:23:01 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ablin", "Pierre", ""], ["Peyr\u00e9", "Gabriel", ""], ["Moreau", "Thomas", ""]]}, {"id": "2002.03723", "submitter": "Ying Huang", "authors": "Ying Huang, Wenwei Zhang, and Jinzhuo Wang", "title": "Deep Frequent Spatial Temporal Learning for Face Anti-Spoofing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face anti-spoofing is crucial for the security of face recognition system, by\navoiding invaded with presentation attack. Previous works have shown the\neffectiveness of using depth and temporal supervision for this task. However,\ndepth supervision is often considered only in a single frame, and temporal\nsupervision is explored by utilizing certain signals which is not robust to the\nchange of scenes. In this work, motivated by two stream ConvNets, we propose a\nnovel two stream FreqSaptialTemporalNet for face anti-spoofing which\nsimultaneously takes advantage of frequent, spatial and temporal information.\nCompared with existing methods which mine spoofing cues in multi-frame RGB\nimage, we make multi-frame spectrum image as one input stream for the\ndiscriminative deep neural network, encouraging the primary difference between\nlive and fake video to be automatically unearthed. Extensive experiments show\npromising improvement results using the proposed architecture. Meanwhile, we\nproposed a concise method to obtain a large amount of spoofing training data by\nutilizing a frequent augmentation pipeline, which contributes detail\nvisualization between live and fake images as well as data insufficiency issue\nwhen training large networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 06:02:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Huang", "Ying", ""], ["Zhang", "Wenwei", ""], ["Wang", "Jinzhuo", ""]]}, {"id": "2002.03731", "submitter": "Ievgen Redko", "authors": "Ievgen Redko, Titouan Vayer, R\\'emi Flamary, Nicolas Courty", "title": "CO-Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport (OT) is a powerful geometric and probabilistic tool for\nfinding correspondences and measuring similarity between two distributions.\nYet, its original formulation relies on the existence of a cost function\nbetween the samples of the two distributions, which makes it impractical when\nthey are supported on different spaces. To circumvent this limitation, we\npropose a novel OT problem, named COOT for CO-Optimal Transport, that\nsimultaneously optimizes two transport maps between both samples and features,\ncontrary to other approaches that either discard the individual features by\nfocusing on pairwise distances between samples or need to model explicitly the\nrelations between them. We provide a thorough theoretical analysis of our\nproblem, establish its rich connections with other OT-based distances and\ndemonstrate its versatility with two machine learning applications in\nheterogeneous domain adaptation and co-clustering/data summarization, where\nCOOT leads to performance improvements over the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:33:15 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 17:40:35 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 14:31:21 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Redko", "Ievgen", ""], ["Vayer", "Titouan", ""], ["Flamary", "R\u00e9mi", ""], ["Courty", "Nicolas", ""]]}, {"id": "2002.03732", "submitter": "Subrata Goswami", "authors": "Subrata Goswami", "title": "Impact of Data Quality on Deep Neural Network Training", "comments": "5 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that data is critical for training neural networks. Lot have\nbeen written about quantities of data required to train networks well. However,\nthere is not much publications on how data quality effects convergence of such\nnetworks. There is dearth of information on what is considered good data ( for\nthe task ). This empirical experimental study explores some impacts of data\nquality. Specific results are shown in the paper how simple changes can have\nimpact on Mean Average Precision (mAP).\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 04:09:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Goswami", "Subrata", ""]]}, {"id": "2002.03735", "submitter": "G C Nandi", "authors": "Sayantan Chatterjee, Faheem H. Zunjani, Souvik Sen and Gora C. Nandi", "title": "Real-Time Object Detection and Recognition on Low-Compute Humanoid\n  Robots using Deep Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We envision that in the near future, humanoid robots would share home space\nand assist us in our daily and routine activities through object manipulations.\nOne of the fundamental technologies that need to be developed for robots is to\nenable them to detect objects and recognize them for effective manipulations\nand take real-time decisions involving those objects. In this paper, we\ndescribe a novel architecture that enables multiple low-compute NAO robots to\nperform real-time detection, recognition and localization of objects in its\ncamera view and take programmable actions based on the detected objects. The\nproposed algorithm for object detection and localization is an empirical\nmodification of YOLOv3, based on indoor experiments in multiple scenarios, with\na smaller weight size and lesser computational requirements. Quantization of\nthe weights and re-adjusting filter sizes and layer arrangements for\nconvolutions improved the inference time for low-resolution images from the\nrobot s camera feed. YOLOv3 was chosen after a comparative study of bounding\nbox algorithms was performed with an objective to choose one that strikes the\nperfect balance among information retention, low inference time and high\naccuracy for real-time object detection and localization. The architecture also\ncomprises of an effective end-to-end pipeline to feed the real-time frames from\nthe camera feed to the neural net and use its results for guiding the robot\nwith customizable actions corresponding to the detected class labels.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:24:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chatterjee", "Sayantan", ""], ["Zunjani", "Faheem H.", ""], ["Sen", "Souvik", ""], ["Nandi", "Gora C.", ""]]}, {"id": "2002.03736", "submitter": "Yaozu Ye", "authors": "Yaozu Ye, Kailun Yang, Kaite Xiang, Juan Wang and Kaiwei Wang", "title": "Universal Semantic Segmentation for Fisheye Urban Driving Images", "comments": "SMC2020 recieved", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is a critical method in the field of autonomous\ndriving. When performing semantic image segmentation, a wider field of view\n(FoV) helps to obtain more information about the surrounding environment,\nmaking automatic driving safer and more reliable, which could be offered by\nfisheye cameras. However, large public fisheye datasets are not available, and\nthe fisheye images captured by the fisheye camera with large FoV comes with\nlarge distortion, so commonly-used semantic segmentation model cannot be\ndirectly utilized. In this paper, a seven degrees of freedom (DoF) augmentation\nmethod is proposed to transform rectilinear image to fisheye image in a more\ncomprehensive way. In the training process, rectilinear images are transformed\ninto fisheye images in seven DoF, which simulates the fisheye images taken by\ncameras of different positions, orientations and focal lengths. The result\nshows that training with the seven-DoF augmentation can improve the model's\naccuracy and robustness against different distorted fisheye data. This\nseven-DoF augmentation provides a universal semantic segmentation solution for\nfisheye cameras in different autonomous driving applications. Also, we provide\nspecific parameter settings of the augmentation for autonomous driving. At\nlast, we tested our universal semantic segmentation model on real fisheye\nimages and obtained satisfactory results. The code and configurations are\nreleased at https://github.com/Yaozhuwa/FisheyeSeg.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:19:00 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 13:02:09 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Ye", "Yaozu", ""], ["Yang", "Kailun", ""], ["Xiang", "Kaite", ""], ["Wang", "Juan", ""], ["Wang", "Kaiwei", ""]]}, {"id": "2002.03746", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Anna Monreale, Stan Matwin, Dino Pedreschi", "title": "Black Box Explanation by Learning Image Exemplars in the Latent Feature\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to explain the decisions of black box models for image\nclassification. While using the black box to label images, our explanation\nmethod exploits the latent feature space learned through an adversarial\nautoencoder. The proposed method first generates exemplar images in the latent\nfeature space and learns a decision tree classifier. Then, it selects and\ndecodes exemplars respecting local decision rules. Finally, it visualizes them\nin a manner that shows to the user how the exemplars can be modified to either\nstay within their class, or to become counter-factuals by \"morphing\" into\nanother class. Since we focus on black box decision systems for image\nclassification, the explanation obtained from the exemplars also provides a\nsaliency map highlighting the areas of the image that contribute to its\nclassification, and areas of the image that push it into another class. We\npresent the results of an experimental evaluation on three datasets and two\nblack box models. Besides providing the most useful and interpretable\nexplanations, we show that the proposed method outperforms existing explainers\nin terms of fidelity, relevance, coherence, and stability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:42:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Matwin", "Stan", ""], ["Pedreschi", "Dino", ""]]}, {"id": "2002.03749", "submitter": "Hartmut Feld", "authors": "Hartmut Feld, Bruno Mirbach, Jigyasa Katrolia, Mohamed Selim, Oliver\n  Wasenm\\\"uller, Didier Stricker", "title": "DFKI Cabin Simulator: A Test Platform for Visual In-Cabin Monitoring\n  Functions", "comments": "corrected typos and bad reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a test platform for visual in-cabin scene analysis and occupant\nmonitoring functions. The test platform is based on a driving simulator\ndeveloped at the DFKI, consisting of a realistic in-cabin mock-up and a\nwide-angle projection system for a realistic driving experience. The platform\nhas been equipped with a wide-angle 2D/3D camera system monitoring the entire\ninterior of the vehicle mock-up of the simulator. It is also supplemented with\na ground truth reference sensor system that allows to track and record the\noccupant's body movements synchronously with the 2D and 3D video streams of the\ncamera. Thus, the resulting test platform will serve as a basis to validate\nnumerous in-cabin monitoring functions, which are important for the realization\nof novel human-vehicle interfaces, advanced driver assistant systems, and\nautomated driving. Among the considered functions are occupant presence\ndetection, size and 3D-pose estimation and driver intention recognition. In\naddition, our platform will be the basis for the creation of large-scale\nin-cabin benchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 07:15:50 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:27:42 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Feld", "Hartmut", ""], ["Mirbach", "Bruno", ""], ["Katrolia", "Jigyasa", ""], ["Selim", "Mohamed", ""], ["Wasenm\u00fcller", "Oliver", ""], ["Stricker", "Didier", ""]]}, {"id": "2002.03754", "submitter": "Andrey Voynov", "authors": "Andrey Voynov, Artem Babenko", "title": "Unsupervised Discovery of Interpretable Directions in the GAN Latent\n  Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The latent spaces of GAN models often have semantically meaningful\ndirections. Moving in these directions corresponds to human-interpretable image\ntransformations, such as zooming or recoloring, enabling a more controllable\ngeneration process. However, the discovery of such directions is currently\nperformed in a supervised manner, requiring human labels, pretrained models, or\nsome form of self-supervision. These requirements severely restrict a range of\ndirections existing approaches can discover. In this paper, we introduce an\nunsupervised method to identify interpretable directions in the latent space of\na pretrained GAN model. By a simple model-agnostic procedure, we find\ndirections corresponding to sensible semantic manipulations without any form of\n(self-)supervision. Furthermore, we reveal several non-trivial findings, which\nwould be difficult to obtain by existing methods, e.g., a direction\ncorresponding to background removal. As an immediate practical benefit of our\nwork, we show how to exploit this finding to achieve competitive performance\nfor weakly-supervised saliency detection.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:57:14 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:08:49 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 12:12:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Voynov", "Andrey", ""], ["Babenko", "Artem", ""]]}, {"id": "2002.03755", "submitter": "Haitham Bou Ammar PhD", "authors": "Rasul Tutunov and Minne Li and Alexander I. Cowen-Rivers and Jun Wang\n  and Haitham Bou-Ammar", "title": "Compositional ADAM: An Adaptive Compositional Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present C-ADAM, the first adaptive solver for compositional\nproblems involving a non-linear functional nesting of expected values. We proof\nthat C-ADAM converges to a stationary point in $\\mathcal{O}(\\delta^{-2.25})$\nwith $\\delta$ being a precision parameter. Moreover, we demonstrate the\nimportance of our results by bridging, for the first time, model-agnostic\nmeta-learning (MAML) and compositional optimisation showing fastest known rates\nfor deep network adaptation to-date. Finally, we validate our findings in a set\nof experiments from portfolio optimisation and meta-learning. Our results\nmanifest significant sample complexity reductions compared to both standard and\ncompositional solvers.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:00:45 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 15:10:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tutunov", "Rasul", ""], ["Li", "Minne", ""], ["Cowen-Rivers", "Alexander I.", ""], ["Wang", "Jun", ""], ["Bou-Ammar", "Haitham", ""]]}, {"id": "2002.03757", "submitter": "Shao-Bo Lin", "authors": "Shao-Bo Lin", "title": "Distributed Learning with Dependent Samples", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on learning rate analysis of distributed kernel ridge\nregression for strong mixing sequences. Using a recently developed integral\noperator approach and a classical covariance inequality for Banach-valued\nstrong mixing sequences, we succeed in deriving optimal learning rate for\ndistributed kernel ridge regression. As a byproduct, we also deduce a\nsufficient condition for the mixing property to guarantee the optimal learning\nrates for kernel ridge regression. Our results extend the applicable range of\ndistributed learning from i.i.d. samples to non-i.i.d. sequences.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:03:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lin", "Shao-Bo", ""]]}, {"id": "2002.03763", "submitter": "Shenghua He", "authors": "Shenghua He and Weimin Zhou and Hua Li and Mark A. Anastasio", "title": "Learning Numerical Observers using Unsupervised Domain Adaptation", "comments": "SPIE Medical Imaging 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging systems are commonly assessed by use of objective image\nquality measures. Supervised deep learning methods have been investigated to\nimplement numerical observers for task-based image quality assessment. However,\nlabeling large amounts of experimental data to train deep neural networks is\ntedious, expensive, and prone to subjective errors. Computer-simulated image\ndata can potentially be employed to circumvent these issues; however, it is\noften difficult to computationally model complicated anatomical structures,\nnoise sources, and the response of real world imaging systems. Hence, simulated\nimage data will generally possess physical and statistical differences from the\nexperimental image data they seek to emulate. Within the context of machine\nlearning, these differences between the sets of two images is referred to as\ndomain shift. In this study, we propose and investigate the use of an\nadversarial domain adaptation method to mitigate the deleterious effects of\ndomain shift between simulated and experimental image data for deep\nlearning-based numerical observers (DL-NOs) that are trained on simulated\nimages but applied to experimental ones. In the proposed method, a DL-NO will\ninitially be trained on computer-simulated image data and subsequently adapted\nfor use with experimental image data, without the need for any labeled\nexperimental images. As a proof of concept, a binary signal detection task is\nconsidered. The success of this strategy as a function of the degree of domain\nshift present between the simulated and experimental image data is\ninvestigated.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:58:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 16:56:25 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["He", "Shenghua", ""], ["Zhou", "Weimin", ""], ["Li", "Hua", ""], ["Anastasio", "Mark A.", ""]]}, {"id": "2002.03767", "submitter": "Yuuya Takayama", "authors": "Yuuya Takayama", "title": "Geometric Formulation for Discrete Points and its Applications", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph cs.DM cs.LG math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel formulation for geometry on discrete points. It is based\non a universal differential calculus, which gives a geometric description of a\ndiscrete set by the algebra of functions. We expand this mathematical framework\nso that it is consistent with differential geometry, and works on spectral\ngraph theory and random walks. Consequently, our formulation comprehensively\ndemonstrates many discrete frameworks in probability theory, physics, applied\nharmonic analysis, and machine learning. Our approach would suggest the\nexistence of an intrinsic theory and a unified picture of those discrete\nframeworks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:12:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Takayama", "Yuuya", ""]]}, {"id": "2002.03772", "submitter": "Gon\\c{c}alo Mordido", "authors": "Julian Niedermeier, Gon\\c{c}alo Mordido, Christoph Meinel", "title": "Improving the Evaluation of Generative Models with Fuzzy Logic", "comments": "AAAI 2020 Meta-Eval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective and interpretable metrics to evaluate current artificial\nintelligent systems are of great importance, not only to analyze the current\nstate of such systems but also to objectively measure progress in the future.\nIn this work, we focus on the evaluation of image generation tasks. We propose\na novel approach, called Fuzzy Topology Impact (FTI), that determines both the\nquality and diversity of an image set using topology representations combined\nwith fuzzy logic. When compared to current evaluation methods, FTI shows better\nand more stable performance on multiple experiments evaluating the sensitivity\nto noise, mode dropping and mode inventing.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 13:42:53 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Niedermeier", "Julian", ""], ["Mordido", "Gon\u00e7alo", ""], ["Meinel", "Christoph", ""]]}, {"id": "2002.03773", "submitter": "Kashif Ahmad", "authors": "Kashif Ahmad, Syed Zohaib, Nicola Conci and Ala Al-Fuqaha", "title": "Deriving Emotions and Sentiments from Visual Content: A Disaster\n  Analysis Use Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis aims to extract and express a person's perception,\nopinions and emotions towards an entity, object, product and a service,\nenabling businesses to obtain feedback from the consumers. The increasing\npopularity of the social networks and users' tendency towards sharing their\nfeelings, expressions and opinions in text, visual and audio content has opened\nnew opportunities and challenges in sentiment analysis. While sentiment\nanalysis of text streams has been widely explored in the literature, sentiment\nanalysis of images and videos is relatively new. This article introduces visual\nsentiment analysis and contrasts it with textual sentiment analysis with\nemphasis on the opportunities and challenges in this nascent research area. We\nalso propose a deep visual sentiment analyzer for disaster-related images as a\nuse-case, covering different aspects of visual sentiment analysis starting from\ndata collection, annotation, model selection, implementation and evaluations.\nWe believe such rigorous analysis will provide a baseline for future research\nin the domain.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 08:48:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ahmad", "Kashif", ""], ["Zohaib", "Syed", ""], ["Conci", "Nicola", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2002.03774", "submitter": "Bugra Turan", "authors": "Bugra Turan and Sinem Coleri", "title": "Machine Learning Based Channel Modeling for Vehicular Visible Light\n  Communication", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Wireless Communication (OWC) propagation channel characterization\nplays a key role on the design and performance analysis of Vehicular Visible\nLight Communication (VVLC) systems. Current OWC channel models based on\ndeterministic and stochastic methods, fail to address mobility induced ambient\nlight, optical turbulence and road reflection effects on channel\ncharacterization. Therefore, alternative machine learning (ML) based schemes,\nconsidering ambient light, optical turbulence, road reflection effects in\naddition to intervehicular distance and geometry, are proposed to obtain\naccurate VVLC channel loss and channel frequency response (CFR). This work\ndemonstrates synthesis of ML based VVLC channel model frameworks through multi\nlayer perceptron feed-forward neural network (MLP), radial basis function\nneural network (RBF-NN) and Random Forest ensemble learning algorithms.\nPredictor and response variables, collected through practical road\nmeasurements, are employed to train and validate proposed models for various\nconditions. Additionally, the importance of different predictor variables on\nchannel loss and CFR is assessed, normalized importance of features for\nmeasured VVLC channel is introduced. We show that RBF-NN, Random Forest and MLP\nbased models yield more accurate channel loss estimations with 3.53 dB, 3.81\ndB, 3.95 dB root mean square error (RMSE), respectively, when compared to\nfitting curve based VVLC channel model with 7 dB RMSE. Moreover, RBF-NN and MLP\nmodels are demonstrated to predict VVLC CFR with respect to distance, ambient\nlight and receiver inclination angle predictor variables with 3.78 dB and 3.60\ndB RMSE respectively.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 12:38:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Turan", "Bugra", ""], ["Coleri", "Sinem", ""]]}, {"id": "2002.03776", "submitter": "Eduardo Soares Mr", "authors": "Plamen Angelov, Eduardo Soares", "title": "Towards Deep Machine Reasoning: a Prototype-based Deep Neural Network\n  with Decision Tree Inference", "comments": "Submitted to the IEEE Joint Conference on Neural Networks (IJCNN -\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the DMR -- a prototype-based method and network\narchitecture for deep learning which is using a decision tree (DT)-based\ninference and synthetic data to balance the classes. It builds upon the\nrecently introduced xDNN method addressing more complex multi-class problems,\nspecifically when classes are highly imbalanced. DMR moves away from a direct\ndecision based on all classes towards a layered DT of pair-wise class\ncomparisons. In addition, it forces the prototypes to be balanced between\nclasses regardless of possible class imbalances of the training data. It has\ntwo novel mechanisms, namely i) using a DT to determine the winning class\nlabel, and ii) balancing the classes by synthesizing data around the prototypes\ndetermined from the available training data. As a result, we improved\nsignificantly the performance of the resulting fully explainable DNN as\nevidenced by the best reported result on the well know benchmark problem\nCaltech-101 surpassing our own recently published \"world record\". Furthermore,\nwe also achieved another \"world record\" for another very hard benchmark\nproblem, namely Caltech-256 as well as surpassed the results of other\napproaches on Faces-1999 problem. In summary, we propose a new approach\nspecifically advantageous for imbalanced multi-class problems that achieved two\nworld records on well known hard benchmark problems and the best result on\nanother problem in terms of accuracy. Moreover, DMR offers full explainability,\ndoes not require GPUs and can continue to learn from new data by adding new\nprototypes preserving the previous ones but not requiring full retraining.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 14:11:07 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Angelov", "Plamen", ""], ["Soares", "Eduardo", ""]]}, {"id": "2002.03780", "submitter": "Volker Sorger", "authors": "Mario Miscuglio, Volker J. Sorger", "title": "Photonic tensor cores for machine learning", "comments": null, "journal-ref": "Applied Physics Reviews 7, 031404 (2020)", "doi": "10.1063/5.0001942", "report-no": null, "categories": "cond-mat.dis-nn cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an ongoing trend in computing hardware towards increased heterogeneity,\ndomain-specific co-processors are emerging as alternatives to centralized\nparadigms. The tensor core unit (TPU) has shown to outperform graphic process\nunits by almost 3-orders of magnitude enabled by higher signal throughout and\nenergy efficiency. In this context, photons bear a number of synergistic\nphysical properties while phase-change materials allow for local nonvolatile\nmnemonic functionality in these emerging distributed non van-Neumann\narchitectures. While several photonic neural network designs have been\nexplored, a photonic TPU to perform matrix vector multiplication and summation\nis yet outstanding. Here we introduced an integrated photonics-based TPU by\nstrategically utilizing a) photonic parallelism via wavelength division\nmultiplexing, b) high 2 Peta-operations-per second throughputs enabled by 10s\nof picosecond-short delays from optoelectronics and compact photonic integrated\ncircuitry, and c) zero power-consuming novel photonic multi-state memories\nbased on phase-change materials featuring vanishing losses in the amorphous\nstate. Combining these physical synergies of material, function, and system, we\nshow that the performance of this 8-bit photonic TPU can be 2-3 orders higher\ncompared to an electrical TPU whilst featuring similar chip areas. This work\nshows that photonic specialized processors have the potential to augment\nelectronic systems and may perform exceptionally well in network-edge devices\nin the looming 5G networks and beyond.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:11:27 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 16:01:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Miscuglio", "Mario", ""], ["Sorger", "Volker J.", ""]]}, {"id": "2002.03781", "submitter": "Robin Yancey", "authors": "Robin Elizabeth Yancey", "title": "Multi-stream Faster RCNN for Mitosis Counting in Breast Cancer Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitotic count is a commonly used method to assess the level of progression of\nbreast cancer, which is now the fourth most prevalent cancer. Unfortunately,\ncounting mitosis is a tedious and subjective task with poor reproducibility,\nespecially for non-experts. Luckily, since the machine can read and compare\nmore data with greater efficiency this could be the next modern technique to\ncount mitosis. Furthermore, technological advancements in medicine have led to\nthe increase in image data available for use in training. In this work, we\npropose a network constructed using a similar approach to one that has been\nused for image fraud detection with the segmented image map as the second\nstream input to Faster RCNN. This region-based detection model combines a fully\nconvolutional Region Proposal Network to generate proposals and a\nclassification network to classify each of these proposals as containing\nmitosis or not. Features from both streams are fused in the bilinear pooling\nlayer to maintain the spatial concurrence of each. After training this model on\nthe ICPR 2014 MITOSIS contest dataset, we received an F-measure score of 0.507,\nhigher than both the winners score and scores from recent tests on the same\ndata. Our method is clinically applicable, taking only around five min per ten\nfull High Power Field slides when tested on a Quadro P6000 cloud GPU.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 20:20:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yancey", "Robin Elizabeth", ""]]}, {"id": "2002.03785", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Yu Zhang, Ron J. Weiss, Yuan Cao, Heiga Zen, Yonghui Wu", "title": "Fully-hierarchical fine-grained prosody modeling for interpretable\n  speech synthesis", "comments": "to appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hierarchical, fine-grained and interpretable latent\nvariable model for prosody based on the Tacotron 2 text-to-speech model. It\nachieves multi-resolution modeling of prosody by conditioning finer level\nrepresentations on coarser level ones. Additionally, it imposes hierarchical\nconditioning across all latent dimensions using a conditional variational\nauto-encoder (VAE) with an auto-regressive structure. Evaluation of\nreconstruction performance illustrates that the new structure does not degrade\nthe model while allowing better interpretability. Interpretations of prosody\nattributes are provided together with the comparison between word-level and\nphone-level prosody representations. Moreover, both qualitative and\nquantitative evaluations are used to demonstrate the improvement in the\ndisentanglement of the latent dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:52:03 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Cao", "Yuan", ""], ["Zen", "Heiga", ""], ["Wu", "Yonghui", ""]]}, {"id": "2002.03786", "submitter": "Amin Mazloumian", "authors": "Amin Mazloumian (1), Matthias Rosenthal (1), Hans Gelke (1) ((1)\n  Institute of Embedded Systems, Zurich University of Applied Sciences)", "title": "Deep Learning for Classifying Food Waste", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One third of food produced in the world for human consumption --\napproximately 1.3 billion tons -- is lost or wasted every year. By classifying\nfood waste of individual consumers and raising awareness of the measures,\navoidable food waste can be significantly reduced. In this research, we use\ndeep learning to classify food waste in half a million images captured by\ncameras installed on top of food waste bins. We specifically designed a deep\nneural network that classifies food waste for every time food waste is thrown\nin the waste bins. Our method presents how deep learning networks can be\ntailored to best learn from available training data.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:40:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mazloumian", "Amin", ""], ["Rosenthal", "Matthias", ""], ["Gelke", "Hans", ""]]}, {"id": "2002.03788", "submitter": "Guangzhi Sun", "authors": "Guangzhi Sun, Yu Zhang, Ron J. Weiss, Yuan Cao, Heiga Zen, Andrew\n  Rosenberg, Bhuvana Ramabhadran, Yonghui Wu", "title": "Generating diverse and natural text-to-speech samples using a quantized\n  fine-grained VAE and auto-regressive prosody prior", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent neural text-to-speech (TTS) models with fine-grained latent features\nenable precise control of the prosody of synthesized speech. Such models\ntypically incorporate a fine-grained variational autoencoder (VAE) structure,\nextracting latent features at each input token (e.g., phonemes). However,\ngenerating samples with the standard VAE prior often results in unnatural and\ndiscontinuous speech, with dramatic prosodic variation between tokens. This\npaper proposes a sequential prior in a discrete latent space which can generate\nmore naturally sounding samples. This is accomplished by discretizing the\nlatent features using vector quantization (VQ), and separately training an\nautoregressive (AR) prior model over the result. We evaluate the approach using\nlistening tests, objective metrics of automatic speech recognition (ASR)\nperformance, and measurements of prosody attributes. Experimental results show\nthat the proposed model significantly improves the naturalness in random sample\ngeneration. Furthermore, initial experiments demonstrate that randomly sampling\nfrom the proposed model can be used as data augmentation to improve the ASR\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:35:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sun", "Guangzhi", ""], ["Zhang", "Yu", ""], ["Weiss", "Ron J.", ""], ["Cao", "Yuan", ""], ["Zen", "Heiga", ""], ["Rosenberg", "Andrew", ""], ["Ramabhadran", "Bhuvana", ""], ["Wu", "Yonghui", ""]]}, {"id": "2002.03793", "submitter": "Yingdong Hu", "authors": "Yingdong Hu, Liang Zhang, Wei Shan, Xiaoxiao Qin, Jing Qi, Zhenzhou\n  Wu, Yang Yuan", "title": "Adversarial Data Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the big data era, many organizations face the dilemma of data sharing.\nRegular data sharing is often necessary for human-centered discussion and\ncommunication, especially in medical scenarios. However, unprotected data\nsharing may also lead to data leakage. Inspired by adversarial attack, we\npropose a method for data encryption, so that for human beings the encrypted\ndata look identical to the original version, but for machine learning methods\nthey are misleading. To show the effectiveness of our method, we collaborate\nwith the Beijing Tiantan Hospital, which has a world leading neurological\ncenter. We invite $3$ doctors to manually inspect our encryption method based\non real world medical images. The results show that the encrypted images can be\nused for diagnosis by the doctors, but not by machine learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:32:57 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 05:52:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Hu", "Yingdong", ""], ["Zhang", "Liang", ""], ["Shan", "Wei", ""], ["Qin", "Xiaoxiao", ""], ["Qi", "Jing", ""], ["Wu", "Zhenzhou", ""], ["Yuan", "Yang", ""]]}, {"id": "2002.03794", "submitter": "Mingzhen Li", "authors": "Mingzhen Li, Yi Liu, Xiaoyan Liu, Qingxiao Sun, Xin You, Hailong Yang,\n  Zhongzhi Luan, Lin Gan, Guangwen Yang, Depei Qian", "title": "The Deep Learning Compiler: A Comprehensive Survey", "comments": null, "journal-ref": "IEEE Transactions on Parallel & Distributed Systems, vol. 32, no.\n  03, pp. 708-727, 2021", "doi": "10.1109/TPDS.2020.3030548", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of deploying various deep learning (DL) models on diverse DL\nhardware has boosted the research and development of DL compilers in the\ncommunity. Several DL compilers have been proposed from both industry and\nacademia such as Tensorflow XLA and TVM. Similarly, the DL compilers take the\nDL models described in different DL frameworks as input, and then generate\noptimized codes for diverse DL hardware as output. However, none of the\nexisting survey has analyzed the unique design architecture of the DL compilers\ncomprehensively. In this paper, we perform a comprehensive survey of existing\nDL compilers by dissecting the commonly adopted design in details, with\nemphasis on the DL oriented multi-level IRs, and frontend/backend\noptimizations. Specifically, we provide a comprehensive comparison among\nexisting DL compilers from various aspects. In addition, we present detailed\nanalysis on the design of multi-level IRs and illustrate the commonly adopted\noptimization techniques. Finally, several insights are highlighted as the\npotential research directions of DL compiler. This is the first survey paper\nfocusing on the design architecture of DL compilers, which we hope can pave the\nroad for future research towards DL compiler.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 07:29:08 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 05:08:44 GMT"}, {"version": "v3", "created": "Sun, 5 Apr 2020 10:34:01 GMT"}, {"version": "v4", "created": "Fri, 28 Aug 2020 09:19:43 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Mingzhen", ""], ["Liu", "Yi", ""], ["Liu", "Xiaoyan", ""], ["Sun", "Qingxiao", ""], ["You", "Xin", ""], ["Yang", "Hailong", ""], ["Luan", "Zhongzhi", ""], ["Gan", "Lin", ""], ["Yang", "Guangwen", ""], ["Qian", "Depei", ""]]}, {"id": "2002.03795", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "Unboxing MAC Protocol Design Optimization Using Deep Learning", "comments": "2020 IEEE International Conference on Pervasive Computing and\n  Communications Workshops (PerCom Workshops). arXiv admin note: substantial\n  text overlap with arXiv:2002.02075", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolving amendments of 802.11 standards feature a large set of physical and\nMAC layer control parameters to support the increasing communication objectives\nspanning application requirements and network dynamics. The significant growth\nand penetration of various devices come along with a tremendous increase in the\nnumber of applications supporting various domains and services which will\nimpose a never-before-seen burden on wireless networks. The challenge however,\nis that each scenario requires a different wireless protocol functionality and\nparameter setting to optimally determine how to tune these functionalities and\nparameters to adapt to varying network scenarios. The traditional trial-error\napproach of manual tuning of parameters is not just becoming difficult to\nrepeat but also sub-optimal for different networking scenarios. In this paper,\nwe describe how we can leverage a deep reinforcement learning framework to be\ntrained to learn the relation between different parameters in the physical and\nMAC layer and show that how our learning-based approach could help us in\ngetting insights about protocol design optimization task.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 03:17:19 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2002.03797", "submitter": "Hannaneh Barahouei Pasandi", "authors": "Hannaneh Barahouei Pasandi, Tamer Nadeem", "title": "CONVINCE: Collaborative Cross-Camera Video Analytics at the Edge", "comments": "6 pages, 4 figures, 2020 IEEE International Conference on Pervasive\n  Computing and Communications Workshops (PerCom Workshops)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, video cameras are deployed in dense for monitoring physical places\ne.g., city, industrial, or agricultural sites. In the current systems, each\ncamera node sends its feed to a cloud server individually. However, this\napproach suffers from several hurdles including higher computation cost, large\nbandwidth requirement for analyzing the enormous data, and privacy concerns. In\ndense deployment, video nodes typically demonstrate a significant\nspatio-temporal correlation. To overcome these obstacles in current approaches,\nthis paper introduces CONVINCE, a new approach to look at the network cameras\nas a collective entity that enables collaborative video analytics pipeline\namong cameras. CONVINCE aims at 1) reducing the computation cost and bandwidth\nrequirements by leveraging spatio-temporal correlations among cameras in\neliminating redundant frames intelligently, and ii) improving vision\nalgorithms' accuracy by enabling collaborative knowledge sharing among relevant\ncameras. Our results demonstrate that CONVINCE achieves an object\nidentification accuracy of $\\sim$91\\%, by transmitting only about $\\sim$25\\% of\nall the recorded frames.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 23:55:45 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pasandi", "Hannaneh Barahouei", ""], ["Nadeem", "Tamer", ""]]}, {"id": "2002.03801", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Ville Hautam\\\"aki, Tomi Kinnunen, Junichi Yamagishi", "title": "An initial investigation on optimizing tandem speaker verification and\n  countermeasure systems using reinforcement learning", "comments": "Odyssey 2020 The Speaker and Language Recognition Workshop. Code\n  available at https://github.com/Miffyli/asv-cm-reinforce", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spoofing countermeasure (CM) systems in automatic speaker verification\n(ASV) are not typically used in isolation of each other. These systems can be\ncombined, for example, into a cascaded system where CM produces first a\ndecision whether the input is synthetic or bona fide speech. In case the CM\ndecides it is a bona fide sample, then the ASV system will consider it for\nspeaker verification. End users of the system are not interested in the\nperformance of the individual sub-modules, but instead are interested in the\nperformance of the combined system. Such combination can be evaluated with\ntandem detection cost function (t-DCF) measure, yet the individual components\nare trained separately from each other using their own performance metrics. In\nthis work we study training the ASV and CM components together for a better\nt-DCF measure by using reinforcement learning. We demonstrate that such\ntraining procedure indeed is able to improve the performance of the combined\nsystem, and does so with more reliable results than with the standard\nsupervised learning techniques we compare against.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:13:49 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 11:09:14 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Hautam\u00e4ki", "Ville", ""], ["Kinnunen", "Tomi", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "2002.03802", "submitter": "Luciana Ferrer", "authors": "Luciana Ferrer and Mitchell McLaren", "title": "A Speaker Verification Backend for Improved Calibration Performance\n  across Varying Conditions", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.11622", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work, we presented a discriminative backend for speaker\nverification that achieved good out-of-the-box calibration performance on most\ntested conditions containing varying levels of mismatch to the training\nconditions. This backend mimics the standard PLDA-based backend process used in\nmost current speaker verification systems, including the calibration stage. All\nparameters of the backend are jointly trained to optimize the binary\ncross-entropy for the speaker verification task. Calibration robustness is\nachieved by making the parameters of the calibration stage a function of\nvectors representing the conditions of the signal, which are extracted using a\nmodel trained to predict condition labels. In this work, we propose a\nsimplified version of this backend where the vectors used to compute the\ncalibration parameters are estimated within the backend, without the need for a\ncondition prediction model. We show that this simplified method provides\nsimilar performance to the previously proposed method while being simpler to\nimplement, and having less requirements on the training data. Further, we\nprovide an analysis of different aspects of the method including the effect of\ninitialization, the nature of the vectors used to compute the calibration\nparameters, and the effect that the random seed and the number of training\nepochs has on performance. We also compare the proposed method with the\ntrial-based calibration (TBC) method that, to our knowledge, was the\nstate-of-the-art for achieving good calibration across varying conditions. We\nshow that the proposed method outperforms TBC while also being several orders\nof magnitude faster to run, comparable to the standard PLDA baseline.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 15:37:46 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Ferrer", "Luciana", ""], ["McLaren", "Mitchell", ""]]}, {"id": "2002.03807", "submitter": "Johanna \\\"Arje", "authors": "Johanna \\\"Arje, Claus Melvad, Mads Rosenh{\\o}j Jeppesen, Sigurd\n  Agerskov Madsen, Jenni Raitoharju, Maria Strandg{\\aa}rd Rasmussen, Alexandros\n  Iosifidis, Ville Tirronen, Kristian Meissner, Moncef Gabbouj, Toke Thomas\n  H{\\o}ye", "title": "Automatic image-based identification and biomass estimation of\n  invertebrates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how biological communities respond to environmental changes is\na key challenge in ecology and ecosystem management. The apparent decline of\ninsect populations necessitates more biomonitoring but the time-consuming\nsorting and identification of taxa pose strong limitations on how many insect\nsamples can be processed. In turn, this affects the scale of efforts to map\ninvertebrate diversity altogether. Given recent advances in computer vision, we\npropose to replace the standard manual approach of human expert-based sorting\nand identification with an automatic image-based technology. We describe a\nrobot-enabled image-based identification machine, which can automate the\nprocess of invertebrate identification, biomass estimation and sample sorting.\nWe use the imaging device to generate a comprehensive image database of\nterrestrial arthropod species. We use this database to test the classification\naccuracy i.e. how well the species identity of a specimen can be predicted from\nimages taken by the machine. We also test sensitivity of the classification\naccuracy to the camera settings (aperture and exposure time) in order to move\nforward with the best possible image quality. We use state-of-the-art Resnet-50\nand InceptionV3 CNNs for the classification task. The results for the initial\ndataset are very promising ($\\overline{ACC}=0.980$). The system is general and\ncan easily be used for other groups of invertebrates as well. As such, our\nresults pave the way for generating more data on spatial and temporal variation\nin invertebrate abundance, diversity and biomass.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 21:38:57 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["\u00c4rje", "Johanna", ""], ["Melvad", "Claus", ""], ["Jeppesen", "Mads Rosenh\u00f8j", ""], ["Madsen", "Sigurd Agerskov", ""], ["Raitoharju", "Jenni", ""], ["Rasmussen", "Maria Strandg\u00e5rd", ""], ["Iosifidis", "Alexandros", ""], ["Tirronen", "Ville", ""], ["Meissner", "Kristian", ""], ["Gabbouj", "Moncef", ""], ["H\u00f8ye", "Toke Thomas", ""]]}, {"id": "2002.03808", "submitter": "June-Woo Kim", "authors": "June-Woo Kim, Ho-Young Jung, Minho Lee", "title": "Vocoder-free End-to-End Voice Conversion with Transformer Network", "comments": "Work in progress", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207653", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mel-frequency filter bank (MFB) based approaches have the advantage of\nlearning speech compared to raw spectrum since MFB has less feature size.\nHowever, speech generator with MFB approaches require additional vocoder that\nneeds a huge amount of computation expense for training process. The additional\npre/post processing such as MFB and vocoder is not essential to convert real\nhuman speech to others. It is possible to only use the raw spectrum along with\nthe phase to generate different style of voices with clear pronunciation. In\nthis regard, we propose a fast and effective approach to convert realistic\nvoices using raw spectrum in a parallel manner. Our transformer-based model\narchitecture which does not have any CNN or RNN layers has shown the advantage\nof learning fast and solved the limitation of sequential computation of\nconventional RNN. In this paper, we introduce a vocoder-free end-to-end voice\nconversion method using transformer network. The presented conversion model can\nalso be used in speaker adaptation for speech recognition. Our approach can\nconvert the source voice to a target voice without using MFB and vocoder. We\ncan get an adapted MFB for speech recognition by multiplying the converted\nmagnitude with phase. We perform our voice conversion experiments on TIDIGITS\ndataset using the metrics such as naturalness, similarity, and clarity with\nmean opinion score, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 06:19:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kim", "June-Woo", ""], ["Jung", "Ho-Young", ""], ["Lee", "Minho", ""]]}, {"id": "2002.03809", "submitter": "Andr\\'e Wyzykowski", "authors": "Andr\\'e Brasil Vieira Wyzykowski, Mauricio Pamplona Segundo, Rubisley\n  de Paula Lemes", "title": "Level Three Synthetic Fingerprint Generation", "comments": "Database are available at https://andrewyzy.github.io/L3-SF/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's legal restrictions that protect the privacy of biometric data are\nhampering fingerprint recognition researches. For instance, all high-resolution\nfingerprint databases ceased to be publicly available. To address this problem,\nwe present a novel hybrid approach to synthesize realistic, high-resolution\nfingerprints. First, we improved Anguli, a handcrafted fingerprint generator,\nto obtain dynamic ridge maps with sweat pores and scratches. Then, we trained a\nCycleGAN to transform these maps into realistic fingerprints. Unlike other\nCNN-based works, we can generate several images for the same identity. We used\nour approach to create a synthetic database with 7400 images in an attempt to\npropel further studies in this field without raising legal issues. We included\nsweat pore annotations in 740 images to encourage research developments in pore\ndetection. In our experiments, we employed two fingerprint matching approaches\nto confirm that real and synthetic databases have similar performance. We\nconducted a human perception analysis where sixty volunteers could hardly\ndiffer between real and synthesized fingerprints. Given that we also favorably\ncompare our results with the most advanced works in the literature, our\nexperimentation suggests that our approach is the new state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 14:09:47 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 18:33:01 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 19:18:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Wyzykowski", "Andr\u00e9 Brasil Vieira", ""], ["Segundo", "Mauricio Pamplona", ""], ["Lemes", "Rubisley de Paula", ""]]}, {"id": "2002.03820", "submitter": "Andreas Kofler", "authors": "Andreas Kofler, Marc Dewey, Tobias Schaeffter, Christoph Kolbitsch and\n  Markus Haltmeier", "title": "Unsupervised Adaptive Neural Network Regularization for Accelerated\n  Radial Cine MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an iterative reconstruction scheme (ALONE - Adaptive\nLearning Of NEtworks) for 2D radial cine MRI based on ground truth-free\nunsupervised learning of shallow convolutional neural networks. The network is\ntrained to approximate patches of the current estimate of the solution during\nthe reconstruction. By imposing a shallow network topology and constraining the\n$L_2$-norm of the learned filters, the network's representation power is\nlimited in order not to be able to recover noise. Therefore, the network can be\ninterpreted to perform a low dimensional approximation of the patches for\nstabilizing the inversion process. We compare the proposed reconstruction\nscheme to two ground truth-free reconstruction methods, namely a well known\nTotal Variation (TV) minimization and an unsupervised adaptive Dictionary\nLearning (DIC) method. The proposed method outperforms both methods with\nrespect to all reported quantitative measures. Further, in contrast to DIC,\nwhere the sparse approximation of the patches involves the solution of a\ncomplex optimization problem, ALONE only requires a forward pass of all patches\nthrough the shallow network and therefore significantly accelerates the\nreconstruction.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:47:20 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Kofler", "Andreas", ""], ["Dewey", "Marc", ""], ["Schaeffter", "Tobias", ""], ["Kolbitsch", "Christoph", ""], ["Haltmeier", "Markus", ""]]}, {"id": "2002.03827", "submitter": "Yunhan Huang", "authors": "Yunhan Huang and Quanyan Zhu", "title": "Manipulating Reinforcement Learning: Poisoning Attacks on Cost Signals", "comments": "This chapter is written for the forthcoming book \"Game Theory and\n  Machine Learning for Cyber Security\" (Wiley-IEEE Press), edited by Charles\n  Kamhoua et. al. arXiv admin note: text overlap with arXiv:1906.10571", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter studies emerging cyber-attacks on reinforcement learning (RL)\nand introduces a quantitative approach to analyze the vulnerabilities of RL.\nFocusing on adversarial manipulation on the cost signals, we analyze the\nperformance degradation of TD($\\lambda$) and $Q$-learning algorithms under the\nmanipulation. For TD($\\lambda$), the approximation learned from the manipulated\ncosts has an approximation error bound proportional to the magnitude of the\nattack. The effect of the adversarial attacks on the bound does not depend on\nthe choice of $\\lambda$. In $Q$-learning, we show that $Q$-learning algorithms\nconverge under stealthy attacks and bounded falsifications on cost signals. We\ncharacterize the relation between the falsified cost and the $Q$-factors as\nwell as the policy learned by the learning agent which provides fundamental\nlimits for feasible offensive and defensive moves. We propose a robust region\nin terms of the cost within which the adversary can never achieve the targeted\npolicy. We provide conditions on the falsified cost which can mislead the agent\nto learn an adversary's favored policy. A case study of TD($\\lambda$) learning\nis provided to corroborate the results.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:42:02 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 22:55:26 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Huang", "Yunhan", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2002.03830", "submitter": "David W. Romero", "authors": "David W. Romero, Erik J. Bekkers, Jakub M. Tomczak, Mark Hoogendoorn", "title": "Attentive Group Equivariant Convolutional Networks", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although group convolutional networks are able to learn powerful\nrepresentations based on symmetry patterns, they lack explicit means to learn\nmeaningful relationships among them (e.g., relative positions and poses). In\nthis paper, we present attentive group equivariant convolutions, a\ngeneralization of the group convolution, in which attention is applied during\nthe course of convolution to accentuate meaningful symmetry combinations and\nsuppress non-plausible, misleading ones. We indicate that prior work on visual\nattention can be described as special cases of our proposed framework and show\nempirically that our attentive group equivariant convolutional networks\nconsistently outperform conventional group convolutional networks on benchmark\nimage datasets. Simultaneously, we provide interpretability to the learned\nconcepts through the visualization of equivariant attention maps.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 14:06:24 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 12:34:17 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 07:41:35 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Romero", "David W.", ""], ["Bekkers", "Erik J.", ""], ["Tomczak", "Jakub M.", ""], ["Hoogendoorn", "Mark", ""]]}, {"id": "2002.03839", "submitter": "Evrard Garcelon", "authors": "Evrard Garcelon, Baptiste Roziere, Laurent Meunier, Jean Tarbouriech,\n  Olivier Teytaud, Alessandro Lazaric, Matteo Pirotta", "title": "Adversarial Attacks on Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are applied in a wide range of domains, from\nadvertising to recommender systems, from clinical trials to education. In many\nof these domains, malicious agents may have incentives to attack the bandit\nalgorithm to induce it to perform a desired behavior. For instance, an\nunscrupulous ad publisher may try to increase their own revenue at the expense\nof the advertisers; a seller may want to increase the exposure of their\nproducts, or thwart a competitor's advertising campaign. In this paper, we\nstudy several attack scenarios and show that a malicious agent can force a\nlinear contextual bandit algorithm to pull any desired arm $T - o(T)$ times\nover a horizon of $T$ steps, while applying adversarial modifications to either\nrewards or contexts that only grow logarithmically as $O(\\log T)$. We also\ninvestigate the case when a malicious agent is interested in affecting the\nbehavior of the bandit algorithm in a single context (e.g., a specific user).\nWe first provide sufficient conditions for the feasibility of the attack and we\nthen propose an efficient algorithm to perform the attack. We validate our\ntheoretical results on experiments performed on both synthetic and real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:04:09 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:54:10 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 08:18:10 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Garcelon", "Evrard", ""], ["Roziere", "Baptiste", ""], ["Meunier", "Laurent", ""], ["Tarbouriech", "Jean", ""], ["Teytaud", "Olivier", ""], ["Lazaric", "Alessandro", ""], ["Pirotta", "Matteo", ""]]}, {"id": "2002.03843", "submitter": "Stefania Russo", "authors": "Stefania Russo, Andy Disch, Frank Blumensaat, Kris Villez", "title": "Anomaly Detection using Deep Autoencoders for in-situ Wastewater Systems\n  Monitoring Data", "comments": "10th IWA Symposium on Modelling and Integrated Assessment (Watermatex\n  2019)", "journal-ref": "10th IWA Symposium on Modelling and Integrated Assessment\n  (Watermatex 2019)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growing amount of data from in-situ sensors in wastewater systems,\nit becomes necessary to automatically identify abnormal behaviours and ensure\nhigh data quality. This paper proposes an anomaly detection method based on a\ndeep autoencoder for in-situ wastewater systems monitoring data. The\nautoencoder architecture is based on 1D Convolutional Neural Network (CNN)\nlayers where the convolutions are performed over the inputs across the temporal\naxis of the data. Anomaly detection is then performed based on the\nreconstruction error of the decoding stage. The approach is validated on\nmultivariate time series from in-sewer process monitoring data. We discuss the\nresults and the challenge of labelling anomalies in complex time series. We\nsuggest that our proposed approach can support the domain experts in the\nidentification of anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:53:46 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:35:20 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:36:27 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Russo", "Stefania", ""], ["Disch", "Andy", ""], ["Blumensaat", "Frank", ""], ["Villez", "Kris", ""]]}, {"id": "2002.03844", "submitter": "Palash Goyal", "authors": "Palash Goyal, Saurabh Sahu, Shalini Ghosh, Chul Lee", "title": "Exploiting Temporal Coherence for Multi-modal Video Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal ML models can process data in multiple modalities (e.g., video,\nimages, audio, text) and are useful for video content analysis in a variety of\nproblems (e.g., object detection, scene understanding). In this paper, we focus\non the problem of video categorization by using a multimodal approach. We have\ndeveloped a novel temporal coherence-based regularization approach, which\napplies to different types of models (e.g., RNN, NetVLAD, Transformer). We\ndemonstrate through experiments how our proposed multimodal video\ncategorization models with temporal coherence out-perform strong\nstate-of-the-art baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 06:42:12 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 00:17:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Goyal", "Palash", ""], ["Sahu", "Saurabh", ""], ["Ghosh", "Shalini", ""], ["Lee", "Chul", ""]]}, {"id": "2002.03846", "submitter": "Felipe Giuste", "authors": "Felipe O. Giuste and Juan C. Vizcarra", "title": "CIFAR-10 Image Classification Using Feature Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification requires the generation of features capable of detecting\nimage patterns informative of group identity. The objective of this study was\nto classify images from the public CIFAR-10 image dataset by leveraging\ncombinations of disparate image feature sources from both manual and deep\nlearning approaches. Histogram of oriented gradients (HOG) and pixel\nintensities successfully inform classification (53% and 59% classification\naccuracy, respectively), yet there is much room for improvement. VGG16 with\nImageNet trained weights and a CIFAR-10 optimized model (CIFAR-VGG) further\nimprove upon image classification (60% and 93.43% accuracy, respectively). We\nfurther improved classification by utilizing transfer learning to re-establish\noptimal network weights for VGG16 (TL-VGG) and Inception ResNet v2\n(TL-Inception) resulting in significant performance increases (85% and 90.74%,\nrespectively), yet fail to surpass CIFAR-VGG. We hypothesized that if each\ngenerated feature set obtained some unique insight into the classification\nproblem, then combining these features would result in greater classification\naccuracy, surpassing that of CIFAR-VGG. Upon selection of the top 1000\nprincipal components from TL-VGG, TL-Inception, HOG, pixel intensities, and\nCIFAR-VGG, we achieved testing accuracy of 94.6%, lending support to our\nhypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 01:53:46 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:33:53 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Giuste", "Felipe O.", ""], ["Vizcarra", "Juan C.", ""]]}, {"id": "2002.03847", "submitter": "Tobias Brudermueller", "authors": "Tobias Brudermueller, Dennis L. Shung, Adrian J. Stanley, Johannes\n  Stegmaier, Smita Krishnaswamy", "title": "Making Logic Learnable With Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are good at learning unspecified functions from\ntraining samples, they cannot be directly implemented in hardware and are often\nnot interpretable or formally verifiable. On the other hand, logic circuits are\nimplementable, verifiable, and interpretable but are not able to learn from\ntraining data in a generalizable way. We propose a novel logic learning\npipeline that combines the advantages of neural networks and logic circuits.\nOur pipeline first trains a neural network on a classification task, and then\ntranslates this, first to random forests, and then to AND-Inverter logic. We\nshow that our pipeline maintains greater accuracy than naive translations to\nlogic, and minimizes the logic such that it is more interpretable and has\ndecreased hardware cost. We show the utility of our pipeline on a network that\nis trained on biomedical data. This approach could be applied to patient care\nto provide risk stratification and guide clinical decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:11:40 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:49:30 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 18:07:58 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Brudermueller", "Tobias", ""], ["Shung", "Dennis L.", ""], ["Stanley", "Adrian J.", ""], ["Stegmaier", "Johannes", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2002.03848", "submitter": "Romain Tavenard", "authors": "Titouan Vayer and Laetitia Chapel and Nicolas Courty and R\\'emi\n  Flamary and Yann Soullard and Romain Tavenard", "title": "Time Series Alignment with Global Invariances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we address the problem of comparing time series while taking\ninto account both feature space transformation and temporal variability. The\nproposed framework combines a latent global transformation of the feature space\nwith the widely used Dynamic Time Warping (DTW). The latent global\ntransformation captures the feature invariance while the DTW (or its smooth\ncounterpart soft-DTW) deals with the temporal shifts. We cast the problem as a\njoint optimization over the global transformation and the temporal alignments.\nThe versatility of our framework allows for several variants depending on the\ninvariance class at stake. Among our contributions we define a differentiable\nloss for time series and present two algorithms for the computation of time\nseries barycenters under our new geometry. We illustrate the interest of our\napproach on both simulated and real world data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:11:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Vayer", "Titouan", ""], ["Chapel", "Laetitia", ""], ["Courty", "Nicolas", ""], ["Flamary", "R\u00e9mi", ""], ["Soullard", "Yann", ""], ["Tavenard", "Romain", ""]]}, {"id": "2002.03850", "submitter": "Rohit Zambre", "authors": "Rohit Zambre, Lars Bergstrom, Laleh Aghababaie Beni, Aparna\n  Chandramowliswharan", "title": "Parallel Performance-Energy Predictive Modeling of Browsers: Case Study\n  of Servo", "comments": "In Proceedings of the 23rd IEEE International Conference on High\n  Performance Computing, Data, and Analytics (HiPC), Hyderabad, India, December\n  2016", "journal-ref": null, "doi": "10.1109/HiPC.2016.013", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mozilla Research is developing Servo, a parallel web browser engine, to\nexploit the benefits of parallelism and concurrency in the web rendering\npipeline. Parallelization results in improved performance for pinterest.com but\nnot for google.com. This is because the workload of a browser is dependent on\nthe web page it is rendering. In many cases, the overhead of creating,\ndeleting, and coordinating parallel work outweighs any of its benefits. In this\npaper, we model the relationship between web page primitives and a web\nbrowser's parallel performance using supervised learning. We discover a feature\nspace that is representative of the parallelism available in a web page and\ncharacterize it using seven key features. Additionally, we consider energy\nusage trade-offs for different levels of performance improvements using\nautomated labeling algorithms. Such a model allows us to predict the degree of\nparallelism available in a web page and decide whether or not to render a web\npage in parallel. This modeling is critical for improving the browser's\nperformance and minimizing its energy usage. We evaluate our model by using\nServo's layout stage as a case study. Experiments on a quad-core Intel Ivy\nBridge (i7-3615QM) laptop show that we can improve performance and energy usage\nby up to 94.52% and 46.32% respectively on the 535 web pages considered in this\nstudy. Looking forward, we identify opportunities to apply this model to other\nstages of a browser's architecture as well as other performance- and\nenergy-critical devices.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 20:16:14 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zambre", "Rohit", ""], ["Bergstrom", "Lars", ""], ["Beni", "Laleh Aghababaie", ""], ["Chandramowliswharan", "Aparna", ""]]}, {"id": "2002.03851", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed Tewfik", "title": "Continuous Silent Speech Recognition using EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore continuous silent speech recognition using\nelectroencephalography (EEG) signals. We implemented a connectionist temporal\nclassification (CTC) automatic speech recognition (ASR) model to translate EEG\nsignals recorded in parallel while subjects were reading English sentences in\ntheir mind without producing any voice to text. Our results demonstrate the\nfeasibility of using EEG signals for performing continuous silent speech\nrecognition. We demonstrate our results for a limited English vocabulary\nconsisting of 30 unique sentences.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 18:28:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 21:51:51 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 05:59:33 GMT"}, {"version": "v4", "created": "Sat, 29 Feb 2020 16:43:06 GMT"}, {"version": "v5", "created": "Sun, 8 Mar 2020 23:18:15 GMT"}, {"version": "v6", "created": "Sun, 15 Mar 2020 19:04:57 GMT"}, {"version": "v7", "created": "Mon, 4 May 2020 20:37:29 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed", ""]]}, {"id": "2002.03854", "submitter": "Prerana Mukherjee", "authors": "Gullapalli Keerti, A N Vaishnavi, Prerana Mukherjee, A Sree Vidya,\n  Gattineni Sai Sreenithya, Deeksha Nayab", "title": "Attentional networks for music generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic music generation has always remained as a challenging problem as it\nmay lack structure or rationality. In this work, we propose a deep learning\nbased music generation method in order to produce old style music particularly\nJAZZ with rehashed melodic structures utilizing a Bi-directional Long Short\nTerm Memory (Bi-LSTM) Neural Network with Attention. Owing to the success in\nmodelling long-term temporal dependencies in sequential data and its success in\ncase of videos, Bi-LSTMs with attention serve as the natural choice and early\nutilization in music generation. We validate in our experiments that Bi-LSTMs\nwith attention are able to preserve the richness and technical nuances of the\nmusic performed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 13:26:17 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Keerti", "Gullapalli", ""], ["Vaishnavi", "A N", ""], ["Mukherjee", "Prerana", ""], ["Vidya", "A Sree", ""], ["Sreenithya", "Gattineni Sai", ""], ["Nayab", "Deeksha", ""]]}, {"id": "2002.03860", "submitter": "Boris Muzellec", "authors": "Boris Muzellec, Julie Josse, Claire Boyer, Marco Cuturi", "title": "Missing Data Imputation using Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a crucial issue when applying machine learning algorithms to\nreal-world datasets. Starting from the simple assumption that two batches\nextracted randomly from the same dataset should share the same distribution, we\nleverage optimal transport distances to quantify that criterion and turn it\ninto a loss function to impute missing data values. We propose practical\nmethods to minimize these losses using end-to-end learning, that can exploit or\nnot parametric assumptions on the underlying distributions of values. We\nevaluate our methods on datasets from the UCI repository, in MCAR, MAR and MNAR\nsettings. These experiments show that OT-based methods match or out-perform\nstate-of-the-art imputation methods, even for high percentages of missing\nvalues.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:23:42 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:06:16 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 09:16:41 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Muzellec", "Boris", ""], ["Josse", "Julie", ""], ["Boyer", "Claire", ""], ["Cuturi", "Marco", ""]]}, {"id": "2002.03862", "submitter": "Axel Chemla--Romeu-Santos", "authors": "Axel Chemla--Romeu-Santos, Stavros Ntalampiras, Philippe Esling,\n  Goffredo Haus, G\\'erard Assayag", "title": "Cross-modal variational inference for bijective signal-symbol\n  translation", "comments": "Proceedings of the 22nd International Conference on Digital Audio\n  Effects (DAFx-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extraction of symbolic information from signals is an active field of\nresearch enabling numerous applications especially in the Musical Information\nRetrieval domain. This complex task, that is also related to other topics such\nas pitch extraction or instrument recognition, is a demanding subject that gave\nbirth to numerous approaches, mostly based on advanced signal processing-based\nalgorithms. However, these techniques are often non-generic, allowing the\nextraction of definite physical properties of the signal (pitch, octave), but\nnot allowing arbitrary vocabularies or more general annotations. On top of\nthat, these techniques are one-sided, meaning that they can extract symbolic\ndata from an audio signal, but cannot perform the reverse process and make\nsymbol-to-signal generation. In this paper, we propose an bijective approach\nfor signal/symbol translation by turning this problem into a density estimation\ntask over signal and symbolic domains, considered both as related random\nvariables. We estimate this joint distribution with two different variational\nauto-encoders, one for each domain, whose inner representations are forced to\nmatch with an additive constraint, allowing both models to learn and generate\nseparately while allowing signal-to-symbol and symbol-to-signal inference. In\nthis article, we test our models on pitch, octave and dynamics symbols, which\ncomprise a fundamental step towards music transcription and label-constrained\naudio generation. In addition to its versatility, this system is rather light\nduring training and generation while allowing several interesting creative uses\nthat we outline at the end of the article.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:25:48 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chemla--Romeu-Santos", "Axel", ""], ["Ntalampiras", "Stavros", ""], ["Esling", "Philippe", ""], ["Haus", "Goffredo", ""], ["Assayag", "G\u00e9rard", ""]]}, {"id": "2002.03864", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, C\\u{a}t\\u{a}lina Cangea, Pietro Li\\`o", "title": "Deep Graph Mapper: Seeing Graphs through the Neural Lens", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in graph representation learning have led to the\nemergence of condensed encodings that capture the main properties of a graph.\nHowever, even though these abstract representations are powerful for downstream\ntasks, they are not equally suitable for visualisation purposes. In this work,\nwe merge Mapper, an algorithm from the field of Topological Data Analysis\n(TDA), with the expressive power of Graph Neural Networks (GNNs) to produce\nhierarchical, topologically-grounded visualisations of graphs. These\nvisualisations do not only help discern the structure of complex graphs but\nalso provide a means of understanding the models applied to them for solving\nvarious tasks. We further demonstrate the suitability of Mapper as a\ntopological framework for graph pooling by mathematically proving an\nequivalence with Min-Cut and Diff Pool. Building upon this framework, we\nintroduce a novel pooling algorithm based on PageRank, which obtains\ncompetitive results with state of the art methods on graph classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:29:09 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 12:03:17 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bodnar", "Cristian", ""], ["Cangea", "C\u0103t\u0103lina", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2002.03866", "submitter": "Rita Pucci", "authors": "Rita Pucci and Alessio Micheli and Stefano Chessa and Jane Hunter", "title": "Machine learning approaches for identifying prey handling activity in\n  otariid pinnipeds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems developed in wearable devices with sensors onboard are widely used to\ncollect data of humans and animals activities with the perspective of an\non-board automatic classification of data. An interesting application of these\nsystems is to support animals' behaviour monitoring gathered by sensors' data\nanalysis. This is a challenging area and in particular with fixed memories\ncapabilities because the devices should be able to operate autonomously for\nlong periods before being retrieved by human operators, and being able to\nclassify activities onboard can significantly improve their autonomy. In this\npaper, we focus on the identification of prey handling activity in seals (when\nthe animal start attaching and biting the prey), which is one of the main\nmovement that identifies a successful foraging activity. Data taken into\nconsideration are streams of 3D accelerometers and depth sensors values\ncollected by devices attached directly on seals. To analyse these data, we\npropose an automatic model based on Machine Learning (ML) algorithms. In\nparticular, we compare the performance (in terms of accuracy and F1score) of\nthree ML algorithms: Input Delay Neural Networks, Support Vector Machines, and\nEcho State Networks. We attend to the final aim of developing an automatic\nclassifier on-board. For this purpose, in this paper, the comparison is\nperformed concerning the performance obtained by each ML approach developed and\nits memory footprint. In the end, we highlight the advantage of using an ML\nalgorithm, in terms of feasibility in wild animals' monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:30:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pucci", "Rita", ""], ["Micheli", "Alessio", ""], ["Chessa", "Stefano", ""], ["Hunter", "Jane", ""]]}, {"id": "2002.03869", "submitter": "Anastasia Volkova", "authors": "Christoph Lauter and Anastasia Volkova", "title": "A Framework for Semi-Automatic Precision and Accuracy Analysis for Fast\n  and Rigorous Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) represent a performance-hungry application.\nFloating-Point (FP) and custom floating-point-like arithmetic satisfies this\nhunger. While there is need for speed, inference in DNNs does not seem to have\nany need for precision. Many papers experimentally observe that DNNs can\nsuccessfully run at almost ridiculously low precision.\n  The aim of this paper is two-fold: first, to shed some theoretical light upon\nwhy a DNN's FP accuracy stays high for low FP precision. We observe that the\nloss of relative accuracy in the convolutional steps is recovered by the\nactivation layers, which are extremely well-conditioned. We give an\ninterpretation for the link between precision and accuracy in DNNs.\n  Second, the paper presents a software framework for semi-automatic FP error\nanalysis for the inference phase of deep-learning. Compatible with common\nTensorflow/Keras models, it leverages the frugally-deep Python/C++ library to\ntransform a neural network into C++ code in order to analyze the network's need\nfor precision. This rigorous analysis is based on Interval and Affine\narithmetics to compute absolute and relative error bounds for a DNN. We\ndemonstrate our tool with several examples.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:33:19 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lauter", "Christoph", ""], ["Volkova", "Anastasia", ""]]}, {"id": "2002.03872", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl, Fares Meghdouri, Joachim Fabini, Tanja Zseby", "title": "SparseIDS: Learning Packet Sampling with Reinforcement Learning", "comments": null, "journal-ref": "2020 IEEE Conference on Communications and Network Security (CNS),\n  Avignon, France", "doi": "10.1109/CNS48642.2020.9162253", "report-no": null, "categories": "cs.LG cs.CR cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been shown to be valuable for\nconstructing Intrusion Detection Systems (IDSs) for network data. They allow\ndetermining if a flow is malicious or not already before it is over, making it\npossible to take action immediately. However, considering the large number of\npackets that has to be inspected, for example in cloud/fog and edge computing,\nthe question of computational efficiency arises. We show that by using a novel\nReinforcement Learning (RL)-based approach called SparseIDS, we can reduce the\nnumber of consumed packets by more than three fourths while keeping\nclassification accuracy high. To minimize the computational expenses of the\nRL-based sampling we show that a shared neural network can be used for both the\nclassifier and the RL logic. Thus, no additional resources are consumed by the\nsampling in deployment. Comparing to various other sampling techniques,\nSparseIDS consistently achieves higher classification accuracy by learning to\nsample only relevant packets. A major novelty of our RL-based approach is that\nit can not only skip up to a predefined maximum number of samples like other\napproaches proposed in the domain of Natural Language Processing but can even\nskip arbitrarily many packets in one step. This enables saving even more\ncomputational resources for long sequences. Inspecting SparseIDS's behavior of\nchoosing packets shows that it adopts different sampling strategies for\ndifferent attack types and network flows. Finally we build an automatic\nsteering mechanism that can guide SparseIDS in deployment to achieve a desired\nlevel of sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:38:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 12:18:44 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 15:22:43 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Bachl", "Maximilian", ""], ["Meghdouri", "Fares", ""], ["Fabini", "Joachim", ""], ["Zseby", "Tanja", ""]]}, {"id": "2002.03875", "submitter": "Jayaraman J. Thiagarajan", "authors": "Bindya Venkatesh, Jayaraman J. Thiagarajan, Kowshik Thopalli and\n  Prasanna Sattigeri", "title": "Calibrate and Prune: Improving Reliability of Lottery Tickets Through\n  Prediction Calibration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis that sub-network initializations (lottery) exist within the\ninitializations of over-parameterized networks, which when trained in isolation\nproduce highly generalizable models, has led to crucial insights into network\ninitialization and has enabled efficient inferencing. Supervised models with\nuncalibrated confidences tend to be overconfident even when making wrong\nprediction. In this paper, for the first time, we study how explicit confidence\ncalibration in the over-parameterized network impacts the quality of the\nresulting lottery tickets. More specifically, we incorporate a suite of\ncalibration strategies, ranging from mixup regularization, variance-weighted\nconfidence calibration to the newly proposed likelihood-based calibration and\nnormalized bin assignment strategies. Furthermore, we explore different\ncombinations of architectures and datasets, and make a number of key findings\nabout the role of confidence calibration. Our empirical studies reveal that\nincluding calibration mechanisms consistently lead to more effective lottery\ntickets, in terms of accuracy as well as empirical calibration metrics, even\nwhen retrained using data with challenging distribution shifts with respect to\nthe source dataset.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:42:36 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:56:46 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 05:17:25 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Venkatesh", "Bindya", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Thopalli", "Kowshik", ""], ["Sattigeri", "Prasanna", ""]]}, {"id": "2002.03893", "submitter": "Craigory Coppola", "authors": "Craigory Coppola, Heba Elgazzar", "title": "Novel Machine Learning Algorithms for Centrality and Cliques Detection\n  in Youtube Social Networks", "comments": null, "journal-ref": "IJAIA Volume 11, No. 1, January 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this research project is to analyze the dynamics of social\nnetworks using machine learning techniques to locate maximal cliques and to\nfind clusters for the purpose of identifying a target demographic. Unsupervised\nmachine learning techniques are designed and implemented in this project to\nanalyze a dataset from YouTube to discover communities in the social network\nand find central nodes. Different clustering algorithms are implemented and\napplied to the YouTube dataset. The well-known Bron-Kerbosch algorithm is used\neffectively in this research to find maximal cliques. The results obtained from\nthis research could be used for advertising purposes and for building smart\nrecommendation systems. All algorithms were implemented using Python\nprogramming language. The experimental results show that we were able to\nsuccessfully find central nodes through clique-centrality and degree\ncentrality. By utilizing clique detection algorithms, the research shown how\nmachine learning algorithms can detect close knit groups within a larger\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:05:09 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Coppola", "Craigory", ""], ["Elgazzar", "Heba", ""]]}, {"id": "2002.03894", "submitter": "Lam Pham", "authors": "Lam Pham, Ian McLoughlin, Huy Phan, Minh Tran, Truc Nguyen, Ramaswamy\n  Palaniappan", "title": "Robust Deep Learning Framework For Predicting Respiratory Anomalies and\n  Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a robust deep learning framework developed to detect\nrespiratory diseases from recordings of respiratory sounds. The complete\ndetection process firstly involves front end feature extraction where\nrecordings are transformed into spectrograms that convey both spectral and\ntemporal information. Then a back-end deep learning model classifies the\nfeatures into classes of respiratory disease or anomaly. Experiments, conducted\nover the ICBHI benchmark dataset of respiratory sounds, evaluate the ability of\nthe framework to classify sounds. Two main contributions are made in this\npaper. Firstly, we provide an extensive analysis of how factors such as\nrespiratory cycle length, time resolution, and network architecture, affect\nfinal prediction accuracy. Secondly, a novel deep learning based framework is\nproposed for detection of respiratory diseases and shown to perform extremely\nwell compared to state of the art methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:26:52 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Pham", "Lam", ""], ["McLoughlin", "Ian", ""], ["Phan", "Huy", ""], ["Tran", "Minh", ""], ["Nguyen", "Truc", ""], ["Palaniappan", "Ramaswamy", ""]]}, {"id": "2002.03896", "submitter": "Sam Earle", "authors": "Sam Earle", "title": "Using Fractal Neural Networks to Play SimCity 1 and Conway's Game of\n  Life at Variable Scales", "comments": "8 pages, 5 figures, presented at EXAG, an AIIDE workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce gym-city, a Reinforcement Learning environment that uses SimCity\n1's game engine to simulate an urban environment, wherein agents might seek to\noptimize one or a combination of any number of city-wide metrics, on gameboards\nof various sizes. We focus on population, and analyze our agents' ability to\ngeneralize to larger map-sizes than those seen during training. The environment\nis interactive, allowing a human player to build alongside agents during\ntraining and inference, potentially influencing the course of their learning,\nor manually probing and evaluating their performance. To test our agents'\nability to capture distance-agnostic relationships between elements of the\ngameboard, we design a minigame within the environment which is, by design,\nunsolvable at large enough scales given strictly local strategies. Given the\ngame engine's extensive use of Cellular Automata, we also train our agents to\n\"play\" Conway's Game of Life -- again optimizing for population -- and examine\ntheir behaviour at multiple scales. To make our models compatible with\nvariable-scale gameplay, we use Neural Networks with recursive weights and\nstructure -- fractals to be truncated at different depths, dependent upon the\nsize of the gameboard.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:10:31 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Earle", "Sam", ""]]}, {"id": "2002.03898", "submitter": "Pritam Sarkar", "authors": "Pritam Sarkar and Ali Etemad", "title": "Self-supervised ECG Representation Learning for Emotion Recognition", "comments": "Accepted in IEEE Transactions of Affective Computing", "journal-ref": null, "doi": "10.1109/TAFFC.2020.3014842", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We exploit a self-supervised deep multi-task learning framework for\nelectrocardiogram (ECG) -based emotion recognition. The proposed solution\nconsists of two stages of learning a) learning ECG representations and b)\nlearning to classify emotions. ECG representations are learned by a signal\ntransformation recognition network. The network learns high-level abstract\nrepresentations from unlabeled ECG data. Six different signal transformations\nare applied to the ECG signals, and transformation recognition is performed as\npretext tasks. Training the model on pretext tasks helps the network learn\nspatiotemporal representations that generalize well across different datasets\nand different emotion categories. We transfer the weights of the\nself-supervised network to an emotion recognition network, where the\nconvolutional layers are kept frozen and the dense layers are trained with\nlabelled ECG data. We show that the proposed solution considerably improves the\nperformance compared to a network trained using fully-supervised learning. New\nstate-of-the-art results are set in classification of arousal, valence,\naffective states, and stress for the four utilized datasets. Extensive\nexperiments are performed, providing interesting insights into the impact of\nusing a multi-task self-supervised structure instead of a single-task model, as\nwell as the optimum level of difficulty required for the pretext\nself-supervised tasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 17:15:37 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 07:09:41 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sarkar", "Pritam", ""], ["Etemad", "Ali", ""]]}, {"id": "2002.03909", "submitter": "Will Shand", "authors": "Will Shand and Stephen Becker", "title": "Locality-sensitive hashing in function spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of performing similarity search over function spaces.\nTo perform search over such spaces in a reasonable amount of time, we use {\\it\nlocality-sensitive hashing} (LSH). We present two methods that allow LSH\nfunctions on $\\mathbb{R}^N$ to be extended to $L^p$ spaces: one using function\napproximation in an orthonormal basis, and another using (quasi-)Monte\nCarlo-style techniques. We use the presented hashing schemes to construct an\nLSH family for Wasserstein distance over one-dimensional, continuous\nprobability distributions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:16:26 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Shand", "Will", ""], ["Becker", "Stephen", ""]]}, {"id": "2002.03911", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali, Daniel Kifer, C. Lee Giles", "title": "Large-Scale Gradient-Free Deep Learning with Recursive Local\n  Representation Alignment", "comments": "Further revised submission -- main description of rec-LRA revamped\n  and architecture-agnostic pseudo-code moved to appendix with additional\n  results/derivation updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks on large-scale datasets requires significant\nhardware resources whose costs (even on cloud platforms) put them out of reach\nof smaller organizations, groups, and individuals. Backpropagation, the\nworkhorse for training these networks, is an inherently sequential process that\nis difficult to parallelize. Furthermore, it requires researchers to\ncontinually develop various tricks, such as specialized weight initializations\nand activation functions, in order to ensure a stable parameter optimization.\nOur goal is to seek an effective, neuro-biologically-plausible alternative to\nbackprop that can be used to train deep networks. In this paper, we propose a\ngradient-free learning procedure, recursive local representation alignment, for\ntraining large-scale neural architectures. Experiments with residual networks\non CIFAR-10 and the large benchmark, ImageNet, show that our algorithm\ngeneralizes as well as backprop while converging sooner due to weight updates\nthat are parallelizable and computationally less demanding. This is empirical\nevidence that a backprop-free algorithm can scale up to larger datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:20:02 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 04:46:28 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 06:16:08 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "2002.03912", "submitter": "Junxian He", "authors": "Junxian He, Xinyi Wang, Graham Neubig, Taylor Berg-Kirkpatrick", "title": "A Probabilistic Formulation of Unsupervised Text Style Transfer", "comments": "ICLR 2020 conference paper (spotlight). The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep generative model for unsupervised text style transfer that\nunifies previously proposed non-generative techniques. Our probabilistic\napproach models non-parallel data from two domains as a partially observed\nparallel corpus. By hypothesizing a parallel latent sequence that generates\neach observed sequence, our model learns to transform sequences from one domain\nto another in a completely unsupervised fashion. In contrast with traditional\ngenerative sequence models (e.g. the HMM), our model makes few assumptions\nabout the data it generates: it uses a recurrent language model as a prior and\nan encoder-decoder as a transduction distribution. While computation of\nmarginal data likelihood is intractable in this model class, we show that\namortized variational inference admits a practical surrogate. Further, by\ndrawing connections between our variational objective and other recent\nunsupervised style transfer and machine translation techniques, we show how our\nprobabilistic view can unify some known non-generative objectives such as\nbacktranslation and adversarial loss. Finally, we demonstrate the effectiveness\nof our method on a wide range of unsupervised style transfer tasks, including\nsentiment transfer, formality transfer, word decipherment, author imitation,\nand related language translation. Across all style transfer tasks, our approach\nyields substantial gains over state-of-the-art non-generative baselines,\nincluding the state-of-the-art unsupervised machine translation techniques that\nour approach generalizes. Further, we conduct experiments on a standard\nunsupervised machine translation task and find that our unified approach\nmatches the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:20:49 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 02:44:13 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 23:26:16 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["He", "Junxian", ""], ["Wang", "Xinyi", ""], ["Neubig", "Graham", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "2002.03924", "submitter": "Raj Dasgupta", "authors": "Prithviraj Dasgupta, Joseph B. Collins, Michael McCarrick", "title": "Playing to Learn Better: Repeated Games for Adversarial Learning with\n  Multiple Classifiers", "comments": "Presented at Artificial Intelligence for Cyber Security (AICS) 2020\n  workshop (non-archival), New York, NY. February 8, 2020", "journal-ref": null, "doi": null, "report-no": "NRL/CP/5580--19-0044", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of prediction by a machine learning algorithm, called\nlearner, within an adversarial learning setting. The learner's task is to\ncorrectly predict the class of data passed to it as a query. However, along\nwith queries containing clean data, the learner could also receive malicious or\nadversarial queries from an adversary. The objective of the adversary is to\nevade the learner's prediction mechanism by sending adversarial queries that\nresult in erroneous class prediction by the learner, while the learner's\nobjective is to reduce the incorrect prediction of these adversarial queries\nwithout degrading the prediction quality of clean queries. We propose a game\ntheory-based technique called a Repeated Bayesian Sequential Game where the\nlearner interacts repeatedly with a model of the adversary using self play to\ndetermine the distribution of adversarial versus clean queries. It then\nstrategically selects a classifier from a set of pre-trained classifiers that\nbalances the likelihood of correct prediction for the query along with reducing\nthe costs to use the classifier. We have evaluated our proposed technique using\nclean and adversarial text data with deep neural network-based classifiers and\nshown that the learner can select an appropriate classifier that is\ncommensurate with the query type (clean or adversarial) while remaining aware\nof the cost to use the classifier.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:33:42 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Dasgupta", "Prithviraj", ""], ["Collins", "Joseph B.", ""], ["McCarrick", "Michael", ""]]}, {"id": "2002.03932", "submitter": "Wei-Cheng Chang", "authors": "Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yiming Yang, Sanjiv Kumar", "title": "Pre-training Tasks for Embedding-based Large-scale Retrieval", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the large-scale query-document retrieval problem: given a query\n(e.g., a question), return the set of relevant documents (e.g., paragraphs\ncontaining the answer) from a large document corpus. This problem is often\nsolved in two steps. The retrieval phase first reduces the solution space,\nreturning a subset of candidate documents. The scoring phase then re-ranks the\ndocuments. Critically, the retrieval algorithm not only desires high recall but\nalso requires to be highly efficient, returning candidates in time sublinear to\nthe number of documents. Unlike the scoring phase witnessing significant\nadvances recently due to the BERT-style pre-training tasks on cross-attention\nmodels, the retrieval phase remains less well studied. Most previous works rely\non classic Information Retrieval (IR) methods such as BM-25 (token matching +\nTF-IDF weights). These models only accept sparse handcrafted features and can\nnot be optimized for different downstream tasks of interest. In this paper, we\nconduct a comprehensive study on the embedding-based retrieval models. We show\nthat the key ingredient of learning a strong embedding-based Transformer model\nis the set of pre-training tasks. With adequately designed paragraph-level\npre-training tasks, the Transformer models can remarkably improve over the\nwidely-used BM-25 as well as embedding models without Transformers. The\nparagraph-level pre-training tasks we studied are Inverse Cloze Task (ICT),\nBody First Selection (BFS), Wiki Link Prediction (WLP), and the combination of\nall three.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:44:00 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Chang", "Wei-Cheng", ""], ["Yu", "Felix X.", ""], ["Chang", "Yin-Wen", ""], ["Yang", "Yiming", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2002.03936", "submitter": "Rafael M\\\"uller", "authors": "Rafael M\\\"uller, Simon Kornblith, Geoffrey Hinton", "title": "Subclass Distillation", "comments": "Under review, corrected citation spelling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a large \"teacher\" neural network has been trained on labeled data, the\nprobabilities that the teacher assigns to incorrect classes reveal a lot of\ninformation about the way in which the teacher generalizes. By training a small\n\"student\" model to match these probabilities, it is possible to transfer most\nof the generalization ability of the teacher to the student, often producing a\nmuch better small model than directly training the student on the training\ndata. The transfer works best when there are many possible classes because more\nis then revealed about the function learned by the teacher, but in cases where\nthere are only a few possible classes we show that we can improve the transfer\nby forcing the teacher to divide each class into many subclasses that it\ninvents during the supervised training. The student is then trained to match\nthe subclass probabilities. For datasets where there are known, natural\nsubclasses we demonstrate that the teacher learns similar subclasses and these\nimprove distillation. For clickthrough datasets where the subclasses are\nunknown we demonstrate that subclass distillation allows the student to learn\nfaster and better.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:45:30 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 18:32:14 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["M\u00fcller", "Rafael", ""], ["Kornblith", "Simon", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.03938", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Wenjing Liao, Hongyuan Zha, Tuo Zhao", "title": "Statistical Guarantees of Generative Adversarial Networks for\n  Distribution Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have achieved great success in\nunsupervised learning. Despite the remarkable empirical performance, there are\nlimited theoretical understandings on the statistical properties of GANs. This\npaper provides statistical guarantees of GANs for the estimation of data\ndistributions which have densities in a H\\\"{o}lder space. Our main result shows\nthat, if the generator and discriminator network architectures are properly\nchosen (universally for all distributions with H\\\"{o}lder densities), GANs are\nconsistent estimators of the data distributions under strong discrepancy\nmetrics, such as the Wasserstein distance. To our best knowledge, this is the\nfirst statistical theory of GANs for H\\\"{o}lder densities. In comparison with\nexisting works, our theory requires minimum assumptions on data distributions.\nOur generator and discriminator networks utilize general weight matrices and\nthe non-invertible ReLU activation function, while many existing works only\napply to invertible weight matrices and invertible activation functions. In our\nanalysis, we decompose the error into a statistical error and an approximation\nerror by a new oracle inequality, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 16:47:57 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:04:00 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chen", "Minshuo", ""], ["Liao", "Wenjing", ""], ["Zha", "Hongyuan", ""], ["Zhao", "Tuo", ""]]}, {"id": "2002.03963", "submitter": "Ashok Cutkosky", "authors": "Ashok Cutkosky", "title": "Adaptive Online Learning with Varying Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given any increasing sequence of norms $\\|\\cdot\\|_0,\\dots,\\|\\cdot\\|_{T-1}$,\nwe provide an online convex optimization algorithm that outputs points $w_t$ in\nsome domain $W$ in response to convex losses $\\ell_t:W\\to \\mathbb{R}$ that\nguarantees regret $R_T(u)=\\sum_{t=1}^T \\ell_t(w_t)-\\ell_t(u)\\le \\tilde\nO\\left(\\|u\\|_{T-1}\\sqrt{\\sum_{t=1}^T \\|g_t\\|_{t-1,\\star}^2}\\right)$ where $g_t$\nis a subgradient of $\\ell_t$ at $w_t$. Our method does not require tuning to\nthe value of $u$ and allows for arbitrary convex $W$. We apply this result to\nobtain new \"full-matrix\"-style regret bounds. Along the way, we provide a new\nexamination of the full-matrix AdaGrad algorithm, suggesting a better learning\nrate value that improves significantly upon prior analysis. We use our new\ntechniques to tune AdaGrad on-the-fly, realizing our improved bound in a\nconcrete algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:22:08 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Cutkosky", "Ashok", ""]]}, {"id": "2002.03967", "submitter": "Fran\\c{c}ois-Pierre Paty", "authors": "Fran\\c{c}ois-Pierre Paty, Marco Cuturi", "title": "Regularized Optimal Transport is Ground Cost Adversarial", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularizing the optimal transport (OT) problem has proven crucial for OT\ntheory to impact the field of machine learning. For instance, it is known that\nregularizing OT problems with entropy leads to faster computations and better\ndifferentiation using the Sinkhorn algorithm, as well as better sample\ncomplexity bounds than classic OT. In this work we depart from this practical\nperspective and propose a new interpretation of regularization as a robust\nmechanism, and show using Fenchel duality that any convex regularization of OT\ncan be interpreted as ground cost adversarial. This incidentally gives access\nto a robust dissimilarity measure on the ground space, which can in turn be\nused in other applications. We propose algorithms to compute this robust cost,\nand illustrate the interest of this approach empirically.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:28:35 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 14:23:25 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 07:14:41 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Paty", "Fran\u00e7ois-Pierre", ""], ["Cuturi", "Marco", ""]]}, {"id": "2002.03977", "submitter": "Ross Cutler", "authors": "Ross Cutler, Ramin Mehran, Sam Johnson, Cha Zhang, Adam Kirk, Oliver\n  Whyte, Adarsh Kowdle", "title": "Multimodal active speaker detection and virtual cinematography for video\n  conferencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active speaker detection (ASD) and virtual cinematography (VC) can\nsignificantly improve the remote user experience of a video conference by\nautomatically panning, tilting and zooming of a video conferencing camera:\nusers subjectively rate an expert video cinematographer's video significantly\nhigher than unedited video. We describe a new automated ASD and VC that\nperforms within 0.3 MOS of an expert cinematographer based on subjective\nratings with a 1-5 scale. This system uses a 4K wide-FOV camera, a depth\ncamera, and a microphone array; it extracts features from each modality and\ntrains an ASD using an AdaBoost machine learning system that is very efficient\nand runs in real-time. A VC is similarly trained using machine learning to\noptimize the subjective quality of the overall experience. To avoid distracting\nthe room participants and reduce switching latency the system has no moving\nparts -- the VC works by cropping and zooming the 4K wide-FOV video stream. The\nsystem was tuned and evaluated using extensive crowdsourcing techniques and\nevaluated on a dataset with N=100 meetings, each 2-5 minutes in length.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:41:51 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 06:09:28 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Cutler", "Ross", ""], ["Mehran", "Ramin", ""], ["Johnson", "Sam", ""], ["Zhang", "Cha", ""], ["Kirk", "Adam", ""], ["Whyte", "Oliver", ""], ["Kowdle", "Adarsh", ""]]}, {"id": "2002.03979", "submitter": "Wanrong Zhu", "authors": "Wanrong Zhu, Xi Chen, Wei Biao Wu", "title": "Online Covariance Matrix Estimation in Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic gradient descent (SGD) algorithm is widely used for parameter\nestimation, especially for huge data sets and online learning. While this\nrecursive algorithm is popular for computation and memory efficiency,\nquantifying variability and randomness of the solutions has been rarely\nstudied. This paper aims at conducting statistical inference of SGD-based\nestimates in an online setting. In particular, we propose a fully online\nestimator for the covariance matrix of averaged SGD iterates (ASGD) only using\nthe iterates from SGD. We formally establish our online estimator's consistency\nand show that the convergence rate is comparable to offline counterparts. Based\non the classic asymptotic normality results of ASGD, we construct\nasymptotically valid confidence intervals for model parameters. Upon receiving\nnew observations, we can quickly update the covariance matrix estimate and the\nconfidence intervals. This approach fits in an online setting and takes full\nadvantage of SGD: efficiency in computation and memory.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 17:46:10 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 02:16:56 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 15:16:16 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhu", "Wanrong", ""], ["Chen", "Xi", ""], ["Wu", "Wei Biao", ""]]}, {"id": "2002.03989", "submitter": "Jun Liu", "authors": "Jun Liu, Xiangyue Wang, Xue-cheng Tai", "title": "Deep Convolutional Neural Networks with Spatial Regularization, Volume\n  and Star-shape Priori for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Deep Convolutional Neural Networks (DCNNs) for image segmentation\nproblems. DCNNs can well extract the features from natural images. However, the\nclassification functions in the existing network architecture of CNNs are\nsimple and lack capabilities to handle important spatial information in a way\nthat have been done for many well-known traditional variational models. Prior\nsuch as spatial regularity, volume prior and object shapes cannot be well\nhandled by existing DCNNs. We propose a novel Soft Threshold Dynamics (STD)\nframework which can easily integrate many spatial priors of the classical\nvariational models into the DCNNs for image segmentation. The novelty of our\nmethod is to interpret the softmax activation function as a dual variable in a\nvariational problem, and thus many spatial priors can be imposed in the dual\nspace. From this viewpoint, we can build a STD based framework which can enable\nthe outputs of DCNNs to have many special priors such as spatial regularity,\nvolume constraints and star-shape priori. The proposed method is a general\nmathematical framework and it can be applied to any semantic segmentation\nDCNNs. To show the efficiency and accuracy of our method, we applied it to the\npopular DeepLabV3+ image segmentation network, and the experiments results show\nthat our method can work efficiently on data-driven image segmentation DCNNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:03:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Jun", ""], ["Wang", "Xiangyue", ""], ["Tai", "Xue-cheng", ""]]}, {"id": "2002.03996", "submitter": "Chandrashekar Lakshminarayanan", "authors": "Chandrashekar Lakshminarayanan and Amit Vikram Singh", "title": "Deep Gated Networks: A framework to understand training and\n  generalisation in deep learning", "comments": "18 Pages, submitted to ICML, added convnets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the role of (stochastic) gradient descent (SGD) in the training\nand generalisation of deep neural networks (DNNs) with ReLU activation has been\nthe object study in the recent past. In this paper, we make use of deep gated\nnetworks (DGNs) as a framework to obtain insights about DNNs with ReLU\nactivation. In DGNs, a single neuronal unit has two components namely the\npre-activation input (equal to the inner product the weights of the layer and\nthe previous layer outputs), and a gating value which belongs to $[0,1]$ and\nthe output of the neuronal unit is equal to the multiplication of\npre-activation input and the gating value. The standard DNN with ReLU\nactivation, is a special case of the DGNs, wherein the gating value is $1/0$\nbased on whether or not the pre-activation input is positive or negative. We\ntheoretically analyse and experiment with several variants of DGNs, each\nvariant suited to understand a particular aspect of either training or\ngeneralisation in DNNs with ReLU activation. Our theory throws light on two\nquestions namely i) why increasing depth till a point helps in training and ii)\nwhy increasing depth beyond a point hurts training? We also present\nexperimental evidence to show that gate adaptation, i.e., the change of gating\nvalue through the course of training is key for generalisation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:12:20 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:25:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lakshminarayanan", "Chandrashekar", ""], ["Singh", "Amit Vikram", ""]]}, {"id": "2002.04010", "submitter": "Yu Bai", "authors": "Yu Bai, Ben Krause, Huan Wang, Caiming Xiong, Richard Socher", "title": "Taylorized Training: Towards Better Approximation of Neural Network\n  Training at Finite Width", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose \\emph{Taylorized training} as an initiative towards better\nunderstanding neural network training at finite width. Taylorized training\ninvolves training the $k$-th order Taylor expansion of the neural network at\ninitialization, and is a principled extension of linearized training---a\nrecently proposed theory for understanding the success of deep learning.\n  We experiment with Taylorized training on modern neural network\narchitectures, and show that Taylorized training (1) agrees with full neural\nnetwork training increasingly better as we increase $k$, and (2) can\nsignificantly close the performance gap between linearized and full training.\nCompared with linearized training, higher-order training works in more\nrealistic settings such as standard parameterization and large (initial)\nlearning rate. We complement our experiments with theoretical results showing\nthat the approximation error of $k$-th order Taylorized models decay\nexponentially over $k$ in wide neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:37:04 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 21:12:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bai", "Yu", ""], ["Krause", "Ben", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "2002.04013", "submitter": "Max Ryabinin", "authors": "Max Ryabinin, Anton Gusev", "title": "Towards Crowdsourced Training of Large Neural Networks using\n  Decentralized Mixture-of-Experts", "comments": "Advances in Neural Information Processing Systems, 2020. Code URL:\n  https://github.com/mryab/learning-at-home. 16 pages, 6 figures", "journal-ref": "Advances in Neural Information Processing Systems 33 (2020)\n  3659-3672", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent breakthroughs in deep learning were achieved by training\nincreasingly larger models on massive datasets. However, training such models\ncan be prohibitively expensive. For instance, the cluster used to train GPT-3\ncosts over \\$250 million. As a result, most researchers cannot afford to train\nstate of the art models and contribute to their development. Hypothetically, a\nresearcher could crowdsource the training of large neural networks with\nthousands of regular PCs provided by volunteers. The raw computing power of a\nhundred thousand \\$2500 desktops dwarfs that of a \\$250M server pod, but one\ncannot utilize that power efficiently with conventional distributed training\nmethods. In this work, we propose Learning@home: a novel neural network\ntraining paradigm designed to handle large amounts of poorly connected\nparticipants. We analyze the performance, reliability, and architectural\nconstraints of this paradigm and compare it against existing distributed\ntraining techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:39:25 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 15:15:44 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 16:36:55 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ryabinin", "Max", ""], ["Gusev", "Anton", ""]]}, {"id": "2002.04014", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Statistically Efficient Off-Policy Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods in reinforcement learning update policy parameters by\ntaking steps in the direction of an estimated gradient of policy value. In this\npaper, we consider the statistically efficient estimation of policy gradients\nfrom off-policy data, where the estimation is particularly non-trivial. We\nderive the asymptotic lower bound on the feasible mean-squared error in both\nMarkov and non-Markov decision processes and show that existing estimators fail\nto achieve it in general settings. We propose a meta-algorithm that achieves\nthe lower bound without any parametric assumptions and exhibits a unique 3-way\ndouble robustness property. We discuss how to estimate nuisances that the\nalgorithm relies on. Finally, we establish guarantees on the rate at which we\napproach a stationary point when we take steps in the direction of our new\nestimated policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:41:25 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 14:40:50 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "2002.04017", "submitter": "Yu Bai", "authors": "Yu Bai, Chi Jin", "title": "Provable Self-Play Algorithms for Competitive Reinforcement Learning", "comments": "Appearing at ICML 2020. Fixed typos from v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-play, where the algorithm learns by playing against itself without\nrequiring any direct supervision, has become the new weapon in modern\nReinforcement Learning (RL) for achieving superhuman performance in practice.\nHowever, the majority of exisiting theory in reinforcement learning only\napplies to the setting where the agent plays against a fixed environment; it\nremains largely open whether self-play algorithms can be provably effective,\nespecially when it is necessary to manage the exploration/exploitation\ntradeoff. We study self-play in competitive reinforcement learning under the\nsetting of Markov games, a generalization of Markov decision processes to the\ntwo-player case. We introduce a self-play algorithm---Value Iteration with\nUpper/Lower Confidence Bound (VI-ULCB)---and show that it achieves regret\n$\\tilde{\\mathcal{O}}(\\sqrt{T})$ after playing $T$ steps of the game, where the\nregret is measured by the agent's performance against a \\emph{fully\nadversarial} opponent who can exploit the agent's strategy at \\emph{any} step.\nWe also introduce an explore-then-exploit style algorithm, which achieves a\nslightly worse regret of $\\tilde{\\mathcal{O}}(T^{2/3})$, but is guaranteed to\nrun in polynomial time even in the worst case. To the best of our knowledge,\nour work presents the first line of provably sample-efficient self-play\nalgorithms for competitive reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:44:50 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 22:29:39 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 17:07:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Bai", "Yu", ""], ["Jin", "Chi", ""]]}, {"id": "2002.04019", "submitter": "Sreyas Mohan", "authors": "Aakash Kaku, Sreyas Mohan, Avinash Parnandi, Heidi Schambra and Carlos\n  Fernandez-Granda", "title": "Be Like Water: Robustness to Extraneous Variables Via Adaptive Feature\n  Normalization", "comments": "Aakash and Sreyas contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extraneous variables are variables that are irrelevant for a certain task,\nbut heavily affect the distribution of the available data. In this work, we\nshow that the presence of such variables can degrade the performance of\ndeep-learning models. We study three datasets where there is a strong influence\nof known extraneous variables: classification of upper-body movements in stroke\npatients, annotation of surgical activities, and recognition of corrupted\nimages. Models trained with batch normalization learn features that are highly\ndependent on the extraneous variables. In batch normalization, the statistics\nused to normalize the features are learned from the training set and fixed at\ntest time, which produces a mismatch in the presence of varying extraneous\nvariables. We demonstrate that estimating the feature statistics adaptively\nduring inference, as in instance normalization, addresses this issue, producing\nnormalized features that are more robust to changes in the extraneous\nvariables. This results in a significant gain in performance for different\nnetwork architectures and choices of feature statistics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:47:08 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 21:35:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kaku", "Aakash", ""], ["Mohan", "Sreyas", ""], ["Parnandi", "Avinash", ""], ["Schambra", "Heidi", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2002.04023", "submitter": "Yao Xia", "authors": "Yao Xia", "title": "Upper, Middle and Lower Region Learning for Facial Action Unit Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial action units (AUs) detection is fundamental to facial expression\nanalysis. As AU occurs only in a small area of the face, region-based learning\nhas been widely recognized useful for AU detection. Most region-based studies\nfocus on a small region where the AU occurs. Focusing on a specific region\nhelps eliminate the influence of identity, but bringing a risk for losing\ninformation. It is challenging to find balance. In this study, I propose a\nsimple strategy. I divide the face into three broad regions, upper, middle, and\nlower region, and group AUs based on where it occurs. I propose a new\nend-to-end deep learning framework named three regions based attention network\n(TRA-Net). After extracting the global feature, TRA-Net uses a hard attention\nmodule to extract three feature maps, each of which contains only a specific\nregion. Each region-specific feature map is fed to an independent branch. For\neach branch, three continuous soft attention modules are used to extract\nhigher-level features for final AU detection. In the DISFA dataset, this model\nachieves the highest F1 scores for the detection of AU1, AU2, and AU4, and\nproduces the highest accuracy in comparison with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:51:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:58:35 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Xia", "Yao", ""]]}, {"id": "2002.04025", "submitter": "Zhengdao Chen", "authors": "Zhengdao Chen, Lei Chen, Soledad Villar, Joan Bruna", "title": "Can Graph Neural Networks Count Substructures?", "comments": "Improved the descriptions of the Local Relational Pooling (LRP) model\n  and its practical implementation; Added more experimental results on\n  synthetic and molecular datasets; Added the LRP-l-1 model in the experiments", "journal-ref": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect and count certain substructures in graphs is important\nfor solving many tasks on graph-structured data, especially in the contexts of\ncomputational chemistry and biology as well as social network analysis.\nInspired by this, we propose to study the expressive power of graph neural\nnetworks (GNNs) via their ability to count attributed graph substructures,\nextending recent works that examine their power in graph isomorphism testing\nand function approximation. We distinguish between two types of substructure\ncounting: induced-subgraph-count and subgraph-count, and establish both\npositive and negative answers for popular GNN architectures. Specifically, we\nprove that Message Passing Neural Networks (MPNNs), 2-Weisfeiler-Lehman (2-WL)\nand 2-Invariant Graph Networks (2-IGNs) cannot perform induced-subgraph-count\nof substructures consisting of 3 or more nodes, while they can perform\nsubgraph-count of star-shaped substructures. As an intermediary step, we prove\nthat 2-WL and 2-IGNs are equivalent in distinguishing non-isomorphic graphs,\npartly answering an open problem raised in Maron et al. (2019). We also prove\npositive results for k-WL and k-IGNs as well as negative results for k-WL with\na finite number of iterations. We then conduct experiments that support the\ntheoretical results for MPNNs and 2-IGNs. Moreover, motivated by substructure\ncounting and inspired by Murphy et al. (2019), we propose the Local Relational\nPooling model and demonstrate that it is not only effective for substructure\ncounting but also able to achieve competitive performance on molecular\nprediction tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:53:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 04:39:59 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 17:59:28 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 18:03:30 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Chen", "Zhengdao", ""], ["Chen", "Lei", ""], ["Villar", "Soledad", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.04026", "submitter": "Quanquan Gu", "authors": "Zixiang Chen and Yuan Cao and Quanquan Gu and Tong Zhang", "title": "A Generalized Neural Tangent Kernel Analysis for Two-layer Neural\n  Networks", "comments": "33 pages. This version changes the title and improves the\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent breakthrough in deep learning theory shows that the training of\nover-parameterized deep neural networks can be characterized by a kernel\nfunction called \\textit{neural tangent kernel} (NTK). However, it is known that\nthis type of results does not perfectly match the practice, as NTK-based\nanalysis requires the network weights to stay very close to their\ninitialization throughout training, and cannot handle regularizers or gradient\nnoises. In this paper, we provide a generalized neural tangent kernel analysis\nand show that noisy gradient descent with weight decay can still exhibit a\n\"kernel-like\" behavior. This implies that the training loss converges linearly\nup to a certain accuracy. We also establish a novel generalization error bound\nfor two-layer neural networks trained by noisy gradient descent with weight\ndecay.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:56:15 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 17:45:59 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Chen", "Zixiang", ""], ["Cao", "Yuan", ""], ["Gu", "Quanquan", ""], ["Zhang", "Tong", ""]]}, {"id": "2002.04033", "submitter": "Theofanis Karaletsos", "authors": "Theofanis Karaletsos, Thang D. Bui", "title": "Hierarchical Gaussian Process Priors for Bayesian Neural Network Weights", "comments": "12 pages main paper, 13 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic neural networks are typically modeled with independent weight\npriors, which do not capture weight correlations in the prior and do not\nprovide a parsimonious interface to express properties in function space. A\ndesirable class of priors would represent weights compactly, capture\ncorrelations between weights, facilitate calibrated reasoning about\nuncertainty, and allow inclusion of prior knowledge about the function space\nsuch as periodicity or dependence on contexts such as inputs. To this end, this\npaper introduces two innovations: (i) a Gaussian process-based hierarchical\nmodel for network weights based on unit embeddings that can flexibly encode\ncorrelated weight structures, and (ii) input-dependent versions of these weight\npriors that can provide convenient ways to regularize the function space\nthrough the use of kernels defined on contextual inputs. We show these models\nprovide desirable test-time uncertainty estimates on out-of-distribution data,\ndemonstrate cases of modeling inductive biases for neural networks with kernels\nwhich help both interpolation and extrapolation from training data, and\ndemonstrate competitive predictive performance on an active learning benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 07:19:52 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Karaletsos", "Theofanis", ""], ["Bui", "Thang D.", ""]]}, {"id": "2002.04034", "submitter": "Abolfazl Attar", "authors": "Mohammad reza Mohammadi, Mohammad Rahimzadeh and Abolfazl Attar", "title": "Sperm Detection and Tracking in Phase-Contrast Microscopy Image\n  Sequences using Deep Learning and Modified CSR-DCF", "comments": null, "journal-ref": null, "doi": null, "report-no": "arXiv:2002.04034", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, computer-aided sperm analysis (CASA) systems have made a big leap\nin extracting the characteristics of spermatozoa for studies or measuring human\nfertility. The first step in sperm characteristics analysis is sperm detection\nin the frames of the video sample. In this article, we used RetinaNet, a deep\nfully convolutional neural network as the object detector. Sperms are small\nobjects with few attributes, that makes the detection more difficult in\nhigh-density samples and especially when there are other particles in semen,\nwhich could be like sperm heads. One of the main attributes of sperms is their\nmovement, but this attribute cannot be extracted when only one frame would be\nfed to the network. To improve the performance of the sperm detection network,\nwe concatenated some consecutive frames to use as the input of the network.\nWith this method, the motility attribute has also been extracted, and then with\nthe help of the deep convolutional network, we have achieved high accuracy in\nsperm detection. The second step is tracking the sperms, for extracting the\nmotility parameters that are essential for indicating fertility and other\nstudies on sperms. In the tracking phase, we modify the CSR-DCF algorithm. This\nmethod also has shown excellent results in sperm tracking even in high-density\nsperm samples, occlusions, sperm colliding, and when sperms exit from a frame\nand re-enter in the next frames. The average precision of the detection phase\nis 99.1%, and the F1 score of the tracking method evaluation is 96.61%. These\nresults can be a great help in studies investigating sperm behavior and\nanalyzing fertility possibility.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 00:38:47 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 19:54:46 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 23:16:23 GMT"}, {"version": "v4", "created": "Sat, 4 Apr 2020 06:21:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Mohammadi", "Mohammad reza", ""], ["Rahimzadeh", "Mohammad", ""], ["Attar", "Abolfazl", ""]]}, {"id": "2002.04060", "submitter": "Behnam Asadi", "authors": "Behnam Asadi, Hui Jiang", "title": "On Approximation Capabilities of ReLU Activation and Softmax Output\n  Layer in Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have extended the well-established universal approximator\ntheory to neural networks that use the unbounded ReLU activation function and a\nnonlinear softmax output layer. We have proved that a sufficiently large neural\nnetwork using the ReLU activation function can approximate any function in\n$L^1$ up to any arbitrary precision. Moreover, our theoretical results have\nshown that a large enough neural network using a nonlinear softmax output layer\ncan also approximate any indicator function in $L^1$, which is equivalent to\nmutually-exclusive class labels in any realistic multiple-class pattern\nclassification problems. To the best of our knowledge, this work is the first\ntheoretical justification for using the softmax output layers in neural\nnetworks for pattern classification.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 19:48:47 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Asadi", "Behnam", ""], ["Jiang", "Hui", ""]]}, {"id": "2002.04069", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh", "title": "On the Communication Latency of Wireless Decentralized Learning", "comments": "Submitted to the 2020 IEEE International Symposium on Information\n  Theory (ISIT 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a wireless network comprising $n$ nodes located within a circular\narea of radius $R$, which are participating in a decentralized learning\nalgorithm to optimize a global objective function using their local datasets.\nTo enable gradient exchanges across the network, we assume each node\ncommunicates only with a set of neighboring nodes, which are within a distance\n$R n^{-\\beta}$ of itself, where $\\beta\\in(0,\\frac{1}{2})$. We use tools from\nnetwork information theory and random geometric graph theory to show that the\ncommunication delay for a single round of exchanging gradients on all the links\nthroughout the network scales as\n$\\mathcal{O}\\left(\\frac{n^{2-3\\beta}}{\\beta\\log n}\\right)$, increasing (at\ndifferent rates) with both the number of nodes and the gradient exchange\nthreshold distance.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:10:07 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Naderializadeh", "Navid", ""]]}, {"id": "2002.04076", "submitter": "Prateek Verma", "authors": "Prateek Verma, Kenneth Salisbury", "title": "Unsupervised Learning of Audio Perception for Robotics Applications:\n  Learning to Project Data to T-SNE/UMAP space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.RO eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio perception is a key to solving a variety of problems ranging from\nacoustic scene analysis, music meta-data extraction, recommendation, synthesis\nand analysis. It can potentially also augment computers in doing tasks that\nhumans do effortlessly in day-to-day activities. This paper builds upon key\nideas to build perception of touch sounds without access to any ground-truth\ndata. We show how we can leverage ideas from classical signal processing to get\nlarge amounts of data of any sound of interest with a high precision. These\nsounds are then used, along with the images to map the sounds to a clustered\nspace of the latent representation of these images. This approach, not only\nallows us to learn semantic representation of the possible sounds of interest,\nbut also allows association of different modalities to the learned\ndistinctions. The model trained to map sounds to this clustered representation,\ngives reasonable performance as opposed to expensive methods collecting a lot\nof human annotated data. Such approaches can be used to build a state of art\nperceptual model for any sound of interest described using a few signal\nprocessing features. Daisy chaining high precision sound event detectors using\nsignal processing combined with neural architectures and high dimensional\nclustering of unlabelled data is a vastly powerful idea, and can be explored in\na variety of ways in future.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:33:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Verma", "Prateek", ""], ["Salisbury", "Kenneth", ""]]}, {"id": "2002.04083", "submitter": "Ioana Bica", "authors": "Ioana Bica, Ahmed M. Alaa, James Jordon, Mihaela van der Schaar", "title": "Estimating Counterfactual Treatment Outcomes over Time Through\n  Adversarially Balanced Representations", "comments": null, "journal-ref": "In Proc. 8th International Conference on Learning Representations\n  (ICLR 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying when to give treatments to patients and how to select among\nmultiple treatments over time are important medical problems with a few\nexisting solutions. In this paper, we introduce the Counterfactual Recurrent\nNetwork (CRN), a novel sequence-to-sequence model that leverages the\nincreasingly available patient observational data to estimate treatment effects\nover time and answer such medical questions. To handle the bias from\ntime-varying confounders, covariates affecting the treatment assignment policy\nin the observational data, CRN uses domain adversarial training to build\nbalancing representations of the patient history. At each timestep, CRN\nconstructs a treatment invariant representation which removes the association\nbetween patient history and treatment assignments and thus can be reliably used\nfor making counterfactual predictions. On a simulated model of tumour growth,\nwith varying degree of time-dependent confounding, we show how our model\nachieves lower error in estimating counterfactuals and in choosing the correct\ntreatment and timing of treatment than current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 20:47:36 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bica", "Ioana", ""], ["Alaa", "Ahmed M.", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2002.04090", "submitter": "Joao Paulo Jansch-Porto", "authors": "Joao Paulo Jansch-Porto, Bin Hu, Geir Dullerud", "title": "Convergence Guarantees of Policy Optimization Methods for Markovian Jump\n  Linear Systems", "comments": "Accepted to ACC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, policy optimization for control purposes has received renewed\nattention due to the increasing interest in reinforcement learning. In this\npaper, we investigate the convergence of policy optimization for quadratic\ncontrol of Markovian jump linear systems (MJLS). First, we study the\noptimization landscape of direct policy optimization for MJLS, and, in\nparticular, show that despite the non-convexity of the resultant problem the\nunique stationary point is the global optimal solution. Next, we prove that the\nGauss-Newton method and the natural policy gradient method converge to the\noptimal state feedback controller for MJLS at a linear rate if initialized at a\ncontroller which stabilizes the closed-loop dynamics in the mean square sense.\nWe propose a novel Lyapunov argument to fix a key stability issue in the\nconvergence proof. Finally, we present a numerical example to support our\ntheory. Our work brings new insights for understanding the performance of\npolicy learning methods on controlling unknown MJLS.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:13:42 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jansch-Porto", "Joao Paulo", ""], ["Hu", "Bin", ""], ["Dullerud", "Geir", ""]]}, {"id": "2002.04094", "submitter": "Subhro Das", "authors": "Subhro Das, Prasanth Lade, Soundar Srinivasan", "title": "Model adaptation and unsupervised learning with non-stationary batch\n  data under smooth concept drift", "comments": "11 pages, 4 figures, 3 tables, 2016 NIPS Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most predictive models assume that training and test data are generated from\na stationary process. However, this assumption does not hold true in practice.\nIn this paper, we consider the scenario of a gradual concept drift due to the\nunderlying non-stationarity of the data source. While previous work has\ninvestigated this scenario under a supervised-learning and adaption conditions,\nfew have addressed the common, real-world scenario when labels are only\navailable during training. We propose a novel, iterative algorithm for\nunsupervised adaptation of predictive models. We show that the performance of\nour batch adapted prediction algorithm is better than that of its corresponding\nunadapted version. The proposed algorithm provides similar (or better, in most\ncases) performance within significantly less run time compared to other state\nof the art methods. We validate our claims though extensive numerical\nevaluations on both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:29:09 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Das", "Subhro", ""], ["Lade", "Prasanth", ""], ["Srinivasan", "Soundar", ""]]}, {"id": "2002.04108", "submitter": "Swabha Swayamdipta", "authors": "Ronan Le Bras, Swabha Swayamdipta, Chandra Bhagavatula, Rowan Zellers,\n  Matthew E. Peters, Ashish Sabharwal, Yejin Choi", "title": "Adversarial Filters of Dataset Biases", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural models have demonstrated human-level performance on language and\nvision benchmarks, while their performance degrades considerably on adversarial\nor out-of-distribution samples. This raises the question of whether these\nmodels have learned to solve a dataset rather than the underlying task by\noverfitting to spurious dataset biases. We investigate one recently proposed\napproach, AFLite, which adversarially filters such dataset biases, as a means\nto mitigate the prevalent overestimation of machine performance. We provide a\ntheoretical understanding for AFLite, by situating it in the generalized\nframework for optimum bias reduction. We present extensive supporting evidence\nthat AFLite is broadly applicable for reduction of measurable dataset biases,\nand that models trained on the filtered datasets yield better generalization to\nout-of-distribution tasks. Finally, filtering results in a large drop in model\nperformance (e.g., from 92% to 62% for SNLI), while human performance still\nremains high. Our work thus shows that such filtered datasets can pose new\nresearch challenges for robust generalization by serving as upgraded\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:59:21 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 05:37:37 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 00:44:43 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Bras", "Ronan Le", ""], ["Swayamdipta", "Swabha", ""], ["Bhagavatula", "Chandra", ""], ["Zellers", "Rowan", ""], ["Peters", "Matthew E.", ""], ["Sabharwal", "Ashish", ""], ["Choi", "Yejin", ""]]}, {"id": "2002.04109", "submitter": "Beril Sirmacek", "authors": "Nicol\\`o Botteghi, Beril Sirmacek, Khaled A. A. Mustafa, Mannes Poel\n  and Stefano Stramigioli", "title": "On Reward Shaping for Mobile Robot Navigation: A Reinforcement Learning\n  and SLAM Based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a map-less path planning algorithm based on Deep Reinforcement\nLearning (DRL) for mobile robots navigating in unknown environment that only\nrelies on 40-dimensional raw laser data and odometry information. The planner\nis trained using a reward function shaped based on the online knowledge of the\nmap of the training environment, obtained using grid-based Rao-Blackwellized\nparticle filter, in an attempt to enhance the obstacle awareness of the agent.\nThe agent is trained in a complex simulated environment and evaluated in two\nunseen ones. We show that the policy trained using the introduced reward\nfunction not only outperforms standard reward functions in terms of convergence\nspeed, by a reduction of 36.9\\% of the iteration steps, and reduction of the\ncollision samples, but it also drastically improves the behaviour of the agent\nin unseen environments, respectively by 23\\% in a simpler workspace and by 45\\%\nin a more clustered one. Furthermore, the policy trained in the simulation\nenvironment can be directly and successfully transferred to the real robot. A\nvideo of our experiments can be found at: https://youtu.be/UEV7W6e6ZqI\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:00:16 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Botteghi", "Nicol\u00f2", ""], ["Sirmacek", "Beril", ""], ["Mustafa", "Khaled A. A.", ""], ["Poel", "Mannes", ""], ["Stramigioli", "Stefano", ""]]}, {"id": "2002.04112", "submitter": "Haoyang Cao", "authors": "Haoyang Cao, Xin Guo, Mathieu Lauri\\`ere", "title": "Connecting GANs, MFGs, and OT", "comments": "Previous version was under the title \"Connecting GANs and MFGs\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have enjoyed tremendous success in\nimage generation and processing, and have recently attracted growing interests\nin financial modelings. This paper analyzes GANs from the perspective of mean\nfield games (MFGs) and optimal transport (OT). It first shows a conceptual\nconnection between GANs and MFGs: MFGs have the structure of GANs, and GANs are\nMFGs under the Pareto Optimality criterion. Interpreting MFGs as GANs, on one\nhand, enables a GANs-based algorithm (MFGANs) to solve MFGs: one neural network\n(NN) for the backward HJB equation and one NN for the forward FP equation, with\nthe two NNs trained in an adversarial way. Viewing GANs as MFGs, on the other\nhand, reveals a new and probabilistic aspect of GANs. This new perspective,\nmoreover, leads to an analytical connection between GANs and Optimal Transport\n(OT) problems, and sufficient conditions for the minimax games of GANs to be\nreformulated in the framework of OT. Numerical experiments demonstrate superior\nperformance of this proposed algorithm, especially in higher dimensional case,\nwhen compared with existing NN approaches.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:14:30 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 06:49:19 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 09:51:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Cao", "Haoyang", ""], ["Guo", "Xin", ""], ["Lauri\u00e8re", "Mathieu", ""]]}, {"id": "2002.04116", "submitter": "Weiwen Jiang", "authors": "Lei Yang, Zheyu Yan, Meng Li, Hyoukjun Kwon, Liangzhen Lai, Tushar\n  Krishna, Vikas Chandra, Weiwen Jiang, Yiyu Shi", "title": "Co-Exploration of Neural Architectures and Heterogeneous ASIC\n  Accelerator Designs Targeting Multiple Tasks", "comments": "Accepted by DAC'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has demonstrated its power on various AI\naccelerating platforms such as Field Programmable Gate Arrays (FPGAs) and\nGraphic Processing Units (GPUs). However, it remains an open problem, how to\nintegrate NAS with Application-Specific Integrated Circuits (ASICs), despite\nthem being the most powerful AI accelerating platforms. The major bottleneck\ncomes from the large design freedom associated with ASIC designs. Moreover,\nwith the consideration that multiple DNNs will run in parallel for different\nworkloads with diverse layer operations and sizes, integrating heterogeneous\nASIC sub-accelerators for distinct DNNs in one design can significantly boost\nperformance, and at the same time further complicate the design space. To\naddress these challenges, in this paper we build ASIC template set based on\nexisting successful designs, described by their unique dataflows, so that the\ndesign space is significantly reduced. Based on the templates, we further\npropose a framework, namely NASAIC, which can simultaneously identify multiple\nDNN architectures and the associated heterogeneous ASIC accelerator design,\nsuch that the design specifications (specs) can be satisfied, while the\naccuracy can be maximized. Experimental results show that compared with\nsuccessive NAS and ASIC design optimizations which lead to design spec\nviolations, NASAIC can guarantee the results to meet the design specs with\n17.77%, 2.49x, and 2.32x reductions on latency, energy, and area and with 0.76%\naccuracy loss. To the best of the authors' knowledge, this is the first work on\nneural architecture and ASIC accelerator design co-exploration.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:22:19 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yang", "Lei", ""], ["Yan", "Zheyu", ""], ["Li", "Meng", ""], ["Kwon", "Hyoukjun", ""], ["Lai", "Liangzhen", ""], ["Krishna", "Tushar", ""], ["Chandra", "Vikas", ""], ["Jiang", "Weiwen", ""], ["Shi", "Yiyu", ""]]}, {"id": "2002.04121", "submitter": "Kevin Tian", "authors": "Yin Tat Lee, Ruoqi Shen, Kevin Tian", "title": "Logsmooth Gradient Concentration and Tighter Runtimes for Metropolized\n  Hamiltonian Monte Carlo", "comments": "31 pages. v2 propagates changes from COLT 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the gradient norm $\\|\\nabla f(x)\\|$ for $x \\sim \\exp(-f(x))$,\nwhere $f$ is strongly convex and smooth, concentrates tightly around its mean.\nThis removes a barrier in the prior state-of-the-art analysis for the\nwell-studied Metropolized Hamiltonian Monte Carlo (HMC) algorithm for sampling\nfrom a strongly logconcave distribution. We correspondingly demonstrate that\nMetropolized HMC mixes in $\\tilde{O}(\\kappa d)$ iterations, improving upon the\n$\\tilde{O}(\\kappa^{1.5}\\sqrt{d} + \\kappa d)$ runtime of (Dwivedi et. al. '18,\nChen et. al. '19) by a factor $(\\kappa/d)^{1/2}$ when the condition number\n$\\kappa$ is large. Our mixing time analysis introduces several techniques which\nto our knowledge have not appeared in the literature and may be of independent\ninterest, including restrictions to a nonconvex set with good conductance\nbehavior, and a new reduction technique for boosting a constant-accuracy total\nvariation guarantee under weak warmness assumptions. This is the first\nhigh-accuracy mixing time result for logconcave distributions using only\nfirst-order function information which achieves linear dependence on $\\kappa$;\nwe also give evidence that this dependence is likely to be necessary for\nstandard Metropolized first-order methods.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:44:50 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 05:24:03 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 02:12:45 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lee", "Yin Tat", ""], ["Shen", "Ruoqi", ""], ["Tian", "Kevin", ""]]}, {"id": "2002.04122", "submitter": "Clarke Safsten", "authors": "Leonid Berlyand, Pierre-Emmanuel Jabin, C. Alex Safsten", "title": "Stability for the Training of Deep Neural Networks and Other Classifiers", "comments": "30 pages; 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the stability of loss-minimizing training processes that are used\nfor deep neural networks (DNN) and other classifiers. While a classifier is\noptimized during training through a so-called loss function, the performance of\nclassifiers is usually evaluated by some measure of accuracy, such as the\noverall accuracy which quantifies the proportion of objects that are well\nclassified. This leads to the guiding question of stability: does decreasing\nloss through training always result in increased accuracy? We formalize the\nnotion of stability, and provide examples of instability. Our main result\nconsists of two novel conditions on the classifier which, if either is\nsatisfied, ensure stability of training, that is we derive tight bounds on\naccuracy as loss decreases. We also derive a sufficient condition for stability\non the training set alone, identifying flat portions of the data manifold as\npotential sources of instability. The latter condition is explicitly verifiable\non the training dataset. Our results do not depend on the algorithm used for\ntraining, as long as loss decreases with training.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:48:13 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 21:10:26 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 21:16:08 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Berlyand", "Leonid", ""], ["Jabin", "Pierre-Emmanuel", ""], ["Safsten", "C. Alex", ""]]}, {"id": "2002.04127", "submitter": "Maria Ines Silva", "authors": "Maria In\\^es Silva and Roberto Henriques", "title": "Finding manoeuvre motifs in vehicle telematics", "comments": "11 pages, 3 figures, submitted to Accident Analysis & Prevention", "journal-ref": null, "doi": "10.1016/j.aap.2020.105467", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driving behaviour has a great impact on road safety. A popular way of\nanalysing driving behaviour is to move the focus to the manoeuvres as they give\nuseful information about the driver who is performing them. In this paper, we\ninvestigate a new way of identifying manoeuvres from vehicle telematics data,\nthrough motif detection in time-series. We implement a modified version of the\nExtended Motif Discovery (EMD) algorithm, a classical variable-length motif\ndetection algorithm for time-series and we applied it to the UAH-DriveSet, a\npublicly available naturalistic driving dataset. After a systematic exploration\nof the extracted motifs, we were able to conclude that the EMD algorithm was\nnot only capable of extracting simple manoeuvres such as accelerations, brakes\nand curves, but also more complex manoeuvres, such as lane changes and\novertaking manoeuvres, which validates motif discovery as a worthwhile line for\nfuture research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:07:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Silva", "Maria In\u00eas", ""], ["Henriques", "Roberto", ""]]}, {"id": "2002.04130", "submitter": "Jingzhao Zhang", "authors": "Jingzhao Zhang, Hongzhou Lin, Stefanie Jegelka, Ali Jadbabaie, Suvrit\n  Sra", "title": "Complexity of Finding Stationary Points of Nonsmooth Nonconvex Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first non-asymptotic analysis for finding stationary points of\nnonsmooth, nonconvex functions. In particular, we study the class of Hadamard\nsemi-differentiable functions, perhaps the largest class of nonsmooth functions\nfor which the chain rule of calculus holds. This class contains examples such\nas ReLU neural networks and others with non-differentiable activation\nfunctions. We first show that finding an $\\epsilon$-stationary point with\nfirst-order methods is impossible in finite time. We then introduce the notion\nof $(\\delta, \\epsilon)$-stationarity, which allows for an\n$\\epsilon$-approximate gradient to be the convex combination of generalized\ngradients evaluated at points within distance $\\delta$ to the solution. We\npropose a series of randomized first-order methods and analyze their complexity\nof finding a $(\\delta, \\epsilon)$-stationary point. Furthermore, we provide a\nlower bound and show that our stochastic algorithm has min-max optimal\ndependence on $\\delta$. Empirically, our methods perform well for training ReLU\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:23:04 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 14:11:35 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 14:53:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Zhang", "Jingzhao", ""], ["Lin", "Hongzhou", ""], ["Jegelka", "Stefanie", ""], ["Jadbabaie", "Ali", ""], ["Sra", "Suvrit", ""]]}, {"id": "2002.04131", "submitter": "Haotian Gu", "authors": "Haotian Gu, Xin Guo, Xiaoli Wei, Renyuan Xu", "title": "Mean-Field Controls with Q-learning for Cooperative MARL: Convergence\n  and Complexity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL), despite its popularity and\nempirical success, suffers from the curse of dimensionality. This paper builds\nthe mathematical framework to approximate cooperative MARL by a mean-field\ncontrol (MFC) framework, and shows that the approximation error is of\n$O(\\frac{1}{\\sqrt{N}})$. By establishing appropriate form of the dynamic\nprogramming principle for both the value function and the Q function, it\nproposes a model-free kernel-based Q-learning algorithm (MFC-K-Q), which is\nshown to be of linear convergence rate, the first of its kind in the MARL\nliterature. It further establishes that the convergence rate and the sample\ncomplexity of MFC-K-Q are independent of the number of agents $N$. Empirical\nstudies for the network traffic congestion problem demonstrate that MFC-K-Q\noutperforms existing MARL algorithms when $N$ is large, for instance when\n$N>50$.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:30:39 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 22:47:46 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 21:22:10 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gu", "Haotian", ""], ["Guo", "Xin", ""], ["Wei", "Xiaoli", ""], ["Xu", "Renyuan", ""]]}, {"id": "2002.04137", "submitter": "Zifan Liu", "authors": "Zifan Liu and Jongho Park and Theodoros Rekatsinas and Christos Tzamos", "title": "On Robust Mean Estimation under Coordinate-level Corruption", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robust mean estimation and introduce a novel Hamming\ndistance-based measure of distribution shift for coordinate-level corruptions.\nWe show that this measure yields adversary models that capture more realistic\ncorruptions than those used in prior works, and present an\ninformation-theoretic analysis of robust mean estimation in these settings. We\nshow that for structured distributions, methods that leverage the structure\nyield information theoretically more accurate mean estimation. We also focus on\npractical algorithms for robust mean estimation and study when data\ncleaning-inspired approaches that first fix corruptions in the input data and\nthen perform robust mean estimation can match the information theoretic bounds\nof our analysis. We finally demonstrate experimentally that this two-step\napproach outperforms structure-agnostic robust estimation and provides accurate\nmean estimation even for high-magnitude corruption.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:48:50 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:47:37 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 18:01:16 GMT"}, {"version": "v4", "created": "Tue, 23 Feb 2021 06:51:52 GMT"}, {"version": "v5", "created": "Fri, 11 Jun 2021 03:26:42 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Zifan", ""], ["Park", "Jongho", ""], ["Rekatsinas", "Theodoros", ""], ["Tzamos", "Christos", ""]]}, {"id": "2002.04138", "submitter": "Joseph Janizek", "authors": "Joseph D. Janizek, Pascal Sturmfels, Su-In Lee", "title": "Explaining Explanations: Axiomatic Feature Interactions for Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown great promise in explaining neural network behavior. In\nparticular, feature attribution methods explain which features were most\nimportant to a model's prediction on a given input. However, for many tasks,\nsimply knowing which features were important to a model's prediction may not\nprovide enough insight to understand model behavior. The interactions between\nfeatures within the model may better help us understand not only the model, but\nalso why certain features are more important than others. In this work, we\npresent Integrated Hessians, an extension of Integrated Gradients that explains\npairwise feature interactions in neural networks. Integrated Hessians overcomes\nseveral theoretical limitations of previous methods to explain interactions,\nand unlike such previous methods is not limited to a specific architecture or\nclass of neural network. Additionally, we find that our method is faster than\nexisting methods when the number of features is large, and outperforms previous\nmethods on existing quantitative benchmarks. Code available at\nhttps://github.com/suinleelab/path_explain\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:49:00 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:00:08 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:54:05 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Janizek", "Joseph D.", ""], ["Sturmfels", "Pascal", ""], ["Lee", "Su-In", ""]]}, {"id": "2002.04155", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski, YiFan Zhang, Ashfaqur Rahman", "title": "ForecastNet: A Time-Variant Deep Feed-Forward Neural Network\n  Architecture for Multi-Step-Ahead Time-Series Forecasting", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2020", "doi": "10.1007/978-3-030-63836-8_48", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent and convolutional neural networks are the most common architectures\nused for time series forecasting in deep learning literature. These networks\nuse parameter sharing by repeating a set of fixed architectures with fixed\nparameters over time or space. The result is that the overall architecture is\ntime-invariant (shift-invariant in the spatial domain) or stationary. We argue\nthat time-invariance can reduce the capacity to perform multi-step-ahead\nforecasting, where modelling the dynamics at a range of scales and resolutions\nis required. We propose ForecastNet which uses a deep feed-forward architecture\nto provide a time-variant model. An additional novelty of ForecastNet is\ninterleaved outputs, which we show assist in mitigating vanishing gradients.\nForecastNet is demonstrated to outperform statistical and deep learning\nbenchmark models on several datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:03:33 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 23:24:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["Zhang", "YiFan", ""], ["Rahman", "Ashfaqur", ""]]}, {"id": "2002.04156", "submitter": "Jinhyun So", "authors": "Jinhyun So, Basak Guler, and A. Salman Avestimehr", "title": "Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed framework for training machine learning\nmodels over the data residing at mobile devices, while protecting the privacy\nof individual users. A major bottleneck in scaling federated learning to a\nlarge number of users is the overhead of secure model aggregation across many\nusers. In particular, the overhead of the state-of-the-art protocols for secure\nmodel aggregation grows quadratically with the number of users. In this paper,\nwe propose the first secure aggregation framework, named Turbo-Aggregate, that\nin a network with $N$ users achieves a secure aggregation overhead of\n$O(N\\log{N})$, as opposed to $O(N^2)$, while tolerating up to a user dropout\nrate of $50\\%$. Turbo-Aggregate employs a multi-group circular strategy for\nefficient model aggregation, and leverages additive secret sharing and novel\ncoding techniques for injecting aggregation redundancy in order to handle user\ndropouts while guaranteeing user privacy. We experimentally demonstrate that\nTurbo-Aggregate achieves a total running time that grows almost linear in the\nnumber of users, and provides up to $40\\times$ speedup over the\nstate-of-the-art protocols with up to $N=200$ users. Our experiments also\ndemonstrate the impact of model size and bandwidth on the performance of\nTurbo-Aggregate.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:15:41 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 16:52:26 GMT"}, {"version": "v3", "created": "Sat, 20 Feb 2021 20:20:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["So", "Jinhyun", ""], ["Guler", "Basak", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "2002.04162", "submitter": "Avinash Ravichandran", "authors": "Qing Liu, Orchid Majumder, Alessandro Achille, Avinash Ravichandran,\n  Rahul Bhotika, Stefano Soatto", "title": "Incremental Meta-Learning via Indirect Discriminant Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Majority of the modern meta-learning methods for few-shot classification\ntasks operate in two phases: a meta-training phase where the meta-learner\nlearns a generic representation by solving multiple few-shot tasks sampled from\na large dataset and a testing phase, where the meta-learner leverages its\nlearnt internal representation for a specific few-shot task involving classes\nwhich were not seen during the meta-training phase. To the best of our\nknowledge, all such meta-learning methods use a single base dataset for\nmeta-training to sample tasks from and do not adapt the algorithm after\nmeta-training. This strategy may not scale to real-world use-cases where the\nmeta-learner does not potentially have access to the full meta-training dataset\nfrom the very beginning and we need to update the meta-learner in an\nincremental fashion when additional training data becomes available. Through\nour experimental setup, we develop a notion of incremental learning during the\nmeta-training phase of meta-learning and propose a method which can be used\nwith multiple existing metric-based meta-learning algorithms. Experimental\nresults on benchmark dataset show that our approach performs favorably at test\ntime as compared to training a model with the full meta-training set and incurs\nnegligible amount of catastrophic forgetting\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 01:39:12 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 18:19:18 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Liu", "Qing", ""], ["Majumder", "Orchid", ""], ["Achille", "Alessandro", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2002.04170", "submitter": "Jie Yang", "authors": "Jie Yang, Zhiquan Qi, Yong Shi", "title": "Learning to Incorporate Structure Knowledge for Image Inpainting", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a multi-task learning framework that attempts to\nincorporate the image structure knowledge to assist image inpainting, which is\nnot well explored in previous works. The primary idea is to train a shared\ngenerator to simultaneously complete the corrupted image and corresponding\nstructures --- edge and gradient, thus implicitly encouraging the generator to\nexploit relevant structure knowledge while inpainting. In the meantime, we also\nintroduce a structure embedding scheme to explicitly embed the learned\nstructure features into the inpainting process, thus to provide possible\npreconditions for image completion. Specifically, a novel pyramid structure\nloss is proposed to supervise structure learning and embedding. Moreover, an\nattention mechanism is developed to further exploit the recurrent structures\nand patterns in the image to refine the generated structures and contents.\nThrough multi-task learning, structure embedding besides with attention, our\nframework takes advantage of the structure knowledge and outperforms several\nstate-of-the-art methods on benchmark datasets quantitatively and\nqualitatively.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 02:22:38 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 03:12:04 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yang", "Jie", ""], ["Qi", "Zhiquan", ""], ["Shi", "Yong", ""]]}, {"id": "2002.04180", "submitter": "Chonggang Song", "authors": "Chonggang Song, Qian Lin, Guohui Ling, Zongyi Zhang, Hongzhao Chen,\n  Jun Liao, Chuan Chen", "title": "LoCEC: Local Community-based Edge Classification in Large Online Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relationships in online social networks often imply social connections in the\nreal world. An accurate understanding of relationship types benefits many\napplications, e.g. social advertising and recommendation. Some recent attempts\nhave been proposed to classify user relationships into predefined types with\nthe help of pre-labeled relationships or abundant interaction features on\nrelationships. Unfortunately, both relationship feature data and label data are\nvery sparse in real social platforms like WeChat, rendering existing methods\ninapplicable. In this paper, we present an in-depth analysis of WeChat\nrelationships to identify the major challenges for the relationship\nclassification task. To tackle the challenges, we propose a Local\nCommunity-based Edge Classification (LoCEC) framework that classifies user\nrelationships in a social network into real-world social connection types.\nLoCEC enforces a three-phase processing, namely local community detection,\ncommunity classification and relationship classification, to address the\nsparsity issue of relationship features and relationship labels. Moreover,\nLoCEC is designed to handle large-scale networks by allowing parallel and\ndistributed processing. We conduct extensive experiments on the real-world\nWeChat network with hundreds of billions of edges to validate the effectiveness\nand efficiency of LoCEC.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 02:58:56 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 05:53:26 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Song", "Chonggang", ""], ["Lin", "Qian", ""], ["Ling", "Guohui", ""], ["Zhang", "Zongyi", ""], ["Chen", "Hongzhao", ""], ["Liao", "Jun", ""], ["Chen", "Chuan", ""]]}, {"id": "2002.04181", "submitter": "Mona Jalal", "authors": "Mona Jalal, Kate K. Mays, Lei Guo, Margrit Betke", "title": "Performance Comparison of Crowdworkers and NLP Tools on Named-Entity\n  Recognition and Sentiment Analysis of Political Tweets", "comments": "4 pages, 1 figure, Accepted at WiNLP Workshop at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report results of a comparison of the accuracy of crowdworkers and seven\nNatural Language Processing (NLP) toolkits in solving two important NLP tasks,\nnamed-entity recognition (NER) and entity-level sentiment (ELS) analysis. We\nhere focus on a challenging dataset, 1,000 political tweets that were collected\nduring the U.S. presidential primary election in February 2016. Each tweet\nrefers to at least one of four presidential candidates, i.e., four named\nentities. The groundtruth, established by experts in political communication,\nhas entity-level sentiment information for each candidate mentioned in the\ntweet. We tested several commercial and open-source tools. Our experiments show\nthat, for our dataset of political tweets, the most accurate NER system, Google\nCloud NL, performed almost on par with crowdworkers, but the most accurate ELS\nanalysis system, TensiStrength, did not match the accuracy of crowdworkers by a\nlarge margin of more than 30 percent points.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:03:20 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 22:04:46 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Jalal", "Mona", ""], ["Mays", "Kate K.", ""], ["Guo", "Lei", ""], ["Betke", "Margrit", ""]]}, {"id": "2002.04185", "submitter": "Casey Chu", "authors": "Casey Chu, Kentaro Minami, Kenji Fukumizu", "title": "Smoothness and Stability in GANs", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks, or GANs, commonly display unstable behavior\nduring training. In this work, we develop a principled theoretical framework\nfor understanding the stability of various types of GANs. In particular, we\nderive conditions that guarantee eventual stationarity of the generator when it\nis trained with gradient descent, conditions that must be satisfied by the\ndivergence that is minimized by the GAN and the generator's architecture. We\nfind that existing GAN variants satisfy some, but not all, of these conditions.\nUsing tools from convex analysis, optimal transport, and reproducing kernels,\nwe construct a GAN that fulfills these conditions simultaneously. In the\nprocess, we explain and clarify the need for various existing GAN stabilization\ntechniques, including Lipschitz constraints, gradient penalties, and smooth\nactivation functions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:08:28 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Chu", "Casey", ""], ["Minami", "Kentaro", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2002.04186", "submitter": "Jianfei Gao", "authors": "Jianfei Gao, Mohamed A. Zahran, Amit Sheoran, Sonia Fahmy, Bruno\n  Ribeiro", "title": "Infinity Learning: Learning Markov Chains from Aggregate Steady-State\n  Observations", "comments": null, "journal-ref": "Published as a conference paper at the Thirty-Fourth AAAI\n  Conference on Artificial Intelligence (AAAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider the task of learning a parametric Continuous Time Markov Chain\n(CTMC) sequence model without examples of sequences, where the training data\nconsists entirely of aggregate steady-state statistics. Making the problem\nharder, we assume that the states we wish to predict are unobserved in the\ntraining data. Specifically, given a parametric model over the transition rates\nof a CTMC and some known transition rates, we wish to extrapolate its steady\nstate distribution to states that are unobserved. A technical roadblock to\nlearn a CTMC from its steady state has been that the chain rule to compute\ngradients will not work over the arbitrarily long sequences necessary to reach\nsteady state ---from where the aggregate statistics are sampled. To overcome\nthis optimization challenge, we propose $\\infty$-SGD, a principled stochastic\ngradient descent method that uses randomly-stopped estimators to avoid infinite\nsums required by the steady state computation, while learning even when only a\nsubset of the CTMC states can be observed. We apply $\\infty$-SGD to a\nreal-world testbed and synthetic experiments showcasing its accuracy, ability\nto extrapolate the steady state distribution to unobserved states under\nunobserved conditions (heavy loads, when training under light loads), and\nsucceeding in difficult scenarios where even a tailor-made extension of\nexisting methods fails.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:29:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Jianfei", ""], ["Zahran", "Mohamed A.", ""], ["Sheoran", "Amit", ""], ["Fahmy", "Sonia", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2002.04187", "submitter": "Zhengxin Li", "authors": "Zhengxin Li", "title": "Exact Indexing of Time Series under Dynamic Time Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic time warping (DTW) is a robust similarity measure of time series.\nHowever, it does not satisfy triangular inequality and has high computational\ncomplexity, severely limiting its applications in similarity search on\nlarge-scale datasets. Usually, we resort to lower bounding distances to speed\nup similarity search under DTW. Unfortunately, there is still a lack of an\neffective lower bounding distance that can measure unequal-length time series\nand has desirable tightness. In the paper, we propose a novel lower bounding\ndistance LB_Keogh+, which is a seamless combination of sequence extension and\nLB_Keogh. It can be used for unequal-length sequences and has low computational\ncomplexity. Besides, LB_Keogh+ can extend sequences to an arbitrary suitable\nlength, without significantly reducing tightness. Next, based on LB_Keogh+, an\nexact index of time series under DTW is devised. Then, we introduce several\ntheorems and complete the relevant proofs to guarantee no false dismissals in\nour similarity search. Finally, extensive experiments are conducted on\nreal-world datasets. Experimental results indicate that our proposed method can\nperform similarity search of unequal-length sequences with high tightness and\ngood pruning power.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:34:48 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Li", "Zhengxin", ""]]}, {"id": "2002.04189", "submitter": "Rohit Jammula", "authors": "Rohit Jammula, Vishnu Rajan Tejus, Shreya Shankar", "title": "Optimal Transfer Learning Model for Binary Classification of Funduscopic\n  Images through Simple Heuristics", "comments": "5 pages. 4 tables. Accepted to present in Machine Learning in\n  Computational Biology (MLCB) 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have the capacity to fundamentally revolutionize medical\nimaging analysis, and they have particularly interesting applications in\ncomputer-aided diagnosis. We attempt to use deep learning neural networks to\ndiagnose funduscopic images, visual representations of the interior of the eye.\nRecently, a few robust deep learning approaches have performed binary\nclassification to infer the presence of a specific ocular disease, such as\nglaucoma or diabetic retinopathy. In an effort to broaden the applications of\ncomputer-aided ocular disease diagnosis, we propose a unifying model for\ndisease classification: low-cost inference of a fundus image to determine\nwhether it is healthy or diseased. To achieve this, we use transfer learning\ntechniques, which retain the more overarching capabilities of a pre-trained\nbase architecture but can adapt to another dataset. For comparisons, we then\ndevelop a custom heuristic equation and evaluation metric ranking system to\ndetermine the optimal base architecture and hyperparameters. The Xception base\narchitecture, Adam optimizer, and mean squared error loss function perform\nbest, achieving 90% accuracy, 94% sensitivity, and 86% specificity. For\nadditional ease of use, we contain the model in a web interface whose file\nchooser can access the local filesystem, allowing for use on any\ninternet-connected device: mobile, PC, or otherwise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:49:14 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:33:06 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 21:41:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jammula", "Rohit", ""], ["Tejus", "Vishnu Rajan", ""], ["Shankar", "Shreya", ""]]}, {"id": "2002.04193", "submitter": "Zeqian Li", "authors": "Zeqian Li, Michael C. Mozer, Jacob Whitehill", "title": "Compositional Embeddings for Multi-Label One-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a compositional embedding framework that infers not just a single\nclass per input image, but a set of classes, in the setting of one-shot\nlearning. Specifically, we propose and evaluate several novel models consisting\nof (1) an embedding function f trained jointly with a \"composition\" function g\nthat computes set union operations between the classes encoded in two embedding\nvectors; and (2) embedding f trained jointly with a \"query\" function h that\ncomputes whether the classes encoded in one embedding subsume the classes\nencoded in another embedding. In contrast to prior work, these models must both\nperceive the classes associated with the input examples and encode the\nrelationships between different class label sets, and they are trained using\nonly weak one-shot supervision consisting of the label-set relationships among\ntraining examples. Experiments on the OmniGlot, Open Images, and COCO datasets\nshow that the proposed compositional embedding models outperform existing\nembedding methods. Our compositional embedding models have applications to\nmulti-label object recognition for both one-shot and supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 03:54:30 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 20:10:02 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 17:54:56 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 20:01:24 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 14:31:59 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Li", "Zeqian", ""], ["Mozer", "Michael C.", ""], ["Whitehill", "Jacob", ""]]}, {"id": "2002.04195", "submitter": "Shahin Shahrampour", "authors": "Liang Ding, Rui Tuo, Shahin Shahrampour", "title": "Generalization Guarantees for Sparse Kernel Approximation with Entropic\n  Optimal Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their success, kernel methods suffer from a massive computational\ncost in practice. In this paper, in lieu of commonly used kernel expansion with\nrespect to $N$ inputs, we develop a novel optimal design maximizing the entropy\namong kernel features. This procedure results in a kernel expansion with\nrespect to entropic optimal features (EOF), improving the data representation\ndramatically due to features dissimilarity. Under mild technical assumptions,\nour generalization bound shows that with only $O(N^{\\frac{1}{4}})$ features\n(disregarding logarithmic factors), we can achieve the optimal statistical\naccuracy (i.e., $O(1/\\sqrt{N})$). The salient feature of our design is its\nsparsity that significantly reduces the time and space cost. Our numerical\nexperiments on benchmark datasets verify the superiority of EOF over the\nstate-of-the-art in kernel approximation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 04:12:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Ding", "Liang", ""], ["Tuo", "Rui", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.04197", "submitter": "Zac Cranko", "authors": "Zac Cranko, Zhan Shi, Xinhua Zhang, Richard Nock, Simon Kornblith", "title": "Generalised Lipschitz Regularisation Equals Distributional Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of adversarial examples has highlighted the need for a theory of\nregularisation that is general enough to apply to exotic function classes, such\nas universal approximators. In response, we give a very general equality result\nregarding the relationship between distributional robustness and\nregularisation, as defined with a transportation cost uncertainty set. The\ntheory allows us to (tightly) certify the robustness properties of a\nLipschitz-regularised model with very mild assumptions. As a theoretical\napplication we show a new result explicating the connection between adversarial\nlearning and distributional robustness. We then give new results for how to\nachieve Lipschitz regularisation of kernel classifiers, which are demonstrated\nexperimentally.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 04:19:43 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Cranko", "Zac", ""], ["Shi", "Zhan", ""], ["Zhang", "Xinhua", ""], ["Nock", "Richard", ""], ["Kornblith", "Simon", ""]]}, {"id": "2002.04205", "submitter": "Rahul Soni", "authors": "Rahul Soni, Naresh Shah, Jimmy D. Moore", "title": "Fine-grained Uncertainty Modeling in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing uncertainty modeling approaches try to detect an out-of-distribution\npoint from the in-distribution dataset. We extend this argument to detect\nfiner-grained uncertainty that distinguishes between (a). certain points, (b).\nuncertain points but within the data distribution, and (c). out-of-distribution\npoints. Our method corrects overconfident NN decisions, detects outlier points\nand learns to say ``I don't know'' when uncertain about a critical point\nbetween the top two predictions. In addition, we provide a mechanism to\nquantify class distributions overlap in the decision manifold and investigate\nits implications in model interpretability.\n  Our method is two-step: in the first step, the proposed method builds a class\ndistribution using Kernel Activation Vectors (kav) extracted from the Network.\nIn the second step, the algorithm determines the confidence of a test point by\na hierarchical decision rule based on the chi-squared distribution of squared\nMahalanobis distances.\n  Our method sits on top of a given Neural Network, requires a single scan of\ntraining data to estimate class distribution statistics, and is highly scalable\nto deep networks and wider pre-softmax layer. As a positive side effect, our\nmethod helps to prevent adversarial attacks without requiring any additional\ntraining. It is directly achieved when the Softmax layer is substituted by our\nrobust uncertainty layer at the evaluation phase.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 05:06:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Soni", "Rahul", ""], ["Shah", "Naresh", ""], ["Moore", "Jimmy D.", ""]]}, {"id": "2002.04219", "submitter": "Alperen Kantarc{\\i}", "authors": "Alperen Kantarc{\\i}, Haz{\\i}m Kemal Ekenel", "title": "Thermal to Visible Face Recognition Using Deep Autoencoders", "comments": "5 pages, 3 figures, 2019 International Conference of the Biometrics\n  Special Interest Group (BIOSIG)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visible face recognition systems achieve nearly perfect recognition\naccuracies using deep learning. However, in lack of light, these systems\nperform poorly. A way to deal with this problem is thermal to visible\ncross-domain face matching. This is a desired technology because of its\nusefulness in night time surveillance. Nevertheless, due to differences between\ntwo domains, it is a very challenging face recognition problem. In this paper,\nwe present a deep autoencoder based system to learn the mapping between visible\nand thermal face images. Also, we assess the impact of alignment in thermal to\nvisible face recognition. For this purpose, we manually annotate the facial\nlandmarks on the Carl and EURECOM datasets. The proposed approach is\nextensively tested on three publicly available datasets: Carl, UND-X1, and\nEURECOM. Experimental results show that the proposed approach improves the\nstate-of-the-art significantly. We observe that alignment increases the\nperformance by around 2%. Annotated facial landmark positions in this study can\nbe downloaded from the following link:\ngithub.com/Alpkant/Thermal-to-Visible-Face-Recognition-Using-Deep-Autoencoders .\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 11:58:36 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Kantarc\u0131", "Alperen", ""], ["Ekenel", "Haz\u0131m Kemal", ""]]}, {"id": "2002.04225", "submitter": "Jason Liang", "authors": "Jason Liang, Santiago Gonzalez, Hormoz Shahrzad, and Risto\n  Miikkulainen", "title": "Regularized Evolutionary Population-Based Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metalearning of deep neural network (DNN) architectures and hyperparameters\nhas become an increasingly important area of research. At the same time,\nnetwork regularization has been recognized as a crucial dimension to effective\ntraining of DNNs. However, the role of metalearning in establishing effective\nregularization has not yet been fully explored. There is recent evidence that\nloss-function optimization could play this role, however it is computationally\nimpractical as an outer loop to full training. This paper presents an algorithm\ncalled Evolutionary Population-Based Training (EPBT) that interleaves the\ntraining of a DNN's weights with the metalearning of loss functions. They are\nparameterized using multivariate Taylor expansions that EPBT can directly\noptimize. Such simultaneous adaptation of weights and loss functions can be\ndeceptive, and therefore EPBT uses a quality-diversity heuristic called Novelty\nPulsation as well as knowledge distillation to prevent overfitting during\ntraining. On the CIFAR-10 and SVHN image classification benchmarks, EPBT\nresults in faster, more accurate learning. The discovered hyperparameters adapt\nto the training process and serve to regularize the learning task by\ndiscouraging overfitting to the labels. EPBT thus demonstrates a practical\ninstantiation of regularization metalearning based on simultaneous training.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 06:28:13 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 20:16:37 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 08:52:37 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 04:04:51 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Liang", "Jason", ""], ["Gonzalez", "Santiago", ""], ["Shahrzad", "Hormoz", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.04232", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Saravanan Kandasamy, Ashwin Maran,\n  N. V. Vinodchandran", "title": "Learning and Sampling of Atomic Interventions from Observations", "comments": "26 pages, 4 figures, a version appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of efficiently estimating the effect of an intervention\non a single variable (atomic interventions) using observational samples in a\ncausal Bayesian network. Our goal is to give algorithms that are efficient in\nboth time and sample complexity in a non-parametric setting.\n  Tian and Pearl (AAAI `02) have exactly characterized the class of causal\ngraphs for which causal effects of atomic interventions can be identified from\nobservational data. We make their result quantitative. Suppose P is a causal\nmodel on a set $\\vec{V}$ of n observable variables with respect to a given\ncausal graph G with observable distribution $P$. Let $P_x$ denote the\ninterventional distribution over the observables with respect to an\nintervention of a designated variable X with x. Assuming that $G$ has bounded\nin-degree, bounded c-components ($k$), and that the observational distribution\nis identifiable and satisfies certain strong positivity condition, we give an\nalgorithm that takes $m=\\tilde{O}(n\\epsilon^{-2})$ samples from $P$ and $O(mn)$\ntime, and outputs with high probability a description of a distribution\n$\\hat{P}$ such that $d_{\\mathrm{TV}}(P_x, \\hat{P}) \\leq \\epsilon$, and:\n  1. [Evaluation] the description can return in $O(n)$ time the probability\n$\\hat{P}(\\vec{v})$ for any assignment $\\vec{v}$ to $\\vec{V}$\n  2. [Generation] the description can return an iid sample from $\\hat{P}$ in\n$O(n)$ time.\n  We also show lower bounds for the sample complexity showing that our sample\ncomplexity has an optimal dependence on the parameters $n$ and $\\epsilon$, as\nwell as if $k=1$ on the strong positivity parameter.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:15:32 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 06:11:17 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Kandasamy", "Saravanan", ""], ["Maran", "Ashwin", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2002.04235", "submitter": "Xiangfeng Wang", "authors": "Junjie Sheng, Xiangfeng Wang, Bo Jin, Junchi Yan, Wenhao Li, Tsung-Hui\n  Chang, Jun Wang, Hongyuan Zha", "title": "Learning Structured Communication for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the large-scale multi-agent communication mechanism under\na multi-agent reinforcement learning (MARL) setting. We summarize the general\ncategories of topology for communication structures in MARL literature, which\nare often manually specified. Then we propose a novel framework termed as\nLearning Structured Communication (LSC) by using a more flexible and efficient\ncommunication topology. Our framework allows for adaptive agent grouping to\nform different hierarchical formations over episodes, which is generated by an\nauxiliary task combined with a hierarchical routing protocol. Given each formed\ntopology, a hierarchical graph neural network is learned to enable effective\nmessage information generation and propagation among inter- and intra-group\ncommunications. In contrast to existing communication mechanisms, our method\nhas an explicit while learnable design for hierarchical communication.\nExperiments on challenging tasks show the proposed LSC enjoys high\ncommunication efficiency, scalability, and global cooperation capability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:19:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Sheng", "Junjie", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Yan", "Junchi", ""], ["Li", "Wenhao", ""], ["Chang", "Tsung-Hui", ""], ["Wang", "Jun", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.04236", "submitter": "Ane Bl\\'azquez-Garc\\'ia", "authors": "Ane Bl\\'azquez-Garc\\'ia, Angel Conde, Usue Mori, Jose A. Lozano", "title": "A review on outlier/anomaly detection in time series data", "comments": "32 pages, 21 figures, submitted to ACM Computing Surveys (CSUR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in technology have brought major breakthroughs in data\ncollection, enabling a large amount of data to be gathered over time and thus\ngenerating time series. Mining this data has become an important task for\nresearchers and practitioners in the past few years, including the detection of\noutliers or anomalies that may represent errors or events of interest. This\nreview aims to provide a structured and comprehensive state-of-the-art on\noutlier detection techniques in the context of time series. To this end, a\ntaxonomy is presented based on the main aspects that characterize an outlier\ndetection technique.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:25:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bl\u00e1zquez-Garc\u00eda", "Ane", ""], ["Conde", "Angel", ""], ["Mori", "Usue", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2002.04237", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta, Parijat Dube, Ashish Verma", "title": "Improving the affordability of robustness training for DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projected Gradient Descent (PGD) based adversarial training has become one of\nthe most prominent methods for building robust deep neural network models.\nHowever, the computational complexity associated with this approach, due to the\nmaximization of the loss function when finding adversaries, is a longstanding\nproblem and may be prohibitive when using larger and more complex models. In\nthis paper we show that the initial phase of adversarial training is redundant\nand can be replaced with natural training which significantly improves the\ncomputational efficiency. We demonstrate that this efficiency gain can be\nachieved without any loss in accuracy on natural and adversarial test samples.\nWe support our argument with insights on the nature of the adversaries and\ntheir relative strength during the training process. We show that our proposed\nmethod can reduce the training time by a factor of up to 2.5 with comparable or\nbetter model test accuracy and generalization on various strengths of\nadversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:29:45 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 04:17:09 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Gupta", "Sidharth", ""], ["Dube", "Parijat", ""], ["Verma", "Ashish", ""]]}, {"id": "2002.04238", "submitter": "Xiangfeng Wang", "authors": "Yun Hua, Xiangfeng Wang, Bo Jin, Wenhao Li, Junchi Yan, Xiaofeng He,\n  Hongyuan Zha", "title": "HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning\n  Problem", "comments": "13 pages", "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the success of existing meta reinforcement learning methods, they\nstill have difficulty in learning a meta policy effectively for RL problems\nwith sparse reward. In this respect, we develop a novel meta reinforcement\nlearning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.\nIt is consisted with three modules including the cross-environment meta state\nembedding module which constructs a common meta state space to adapt to\ndifferent environments; the meta state based environment-specific meta reward\nshaping which effectively extends the original sparse reward trajectory by\ncross-environmental knowledge complementarity and as a consequence the meta\npolicy achieves better generalization and efficiency with the shaped meta\nreward. Experiments with sparse-reward environments show the superiority of\nHMRL on both transferability and policy learning efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:31:11 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 06:36:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Hua", "Yun", ""], ["Wang", "Xiangfeng", ""], ["Jin", "Bo", ""], ["Li", "Wenhao", ""], ["Yan", "Junchi", ""], ["He", "Xiaofeng", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.04254", "submitter": "Joseph Lam-Weil", "authors": "Joseph Lam-Weil, B\\'eatrice Laurent, Jean-Michel Loubes", "title": "Minimax optimal goodness-of-fit testing for densities and multinomials\n  under a local differential privacy constraint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding anonymization mechanisms to protect personal data is at the heart of\nrecent machine learning research. Here, we consider the consequences of local\ndifferential privacy constraints on goodness-of-fit testing, i.e. the\nstatistical problem assessing whether sample points are generated from a fixed\ndensity $f_0$, or not. The observations are kept hidden and replaced by a\nstochastic transformation satisfying the local differential privacy constraint.\nIn this setting, we propose a testing procedure which is based on an estimation\nof the quadratic distance between the density $f$ of the unobserved samples and\n$f_0$. We establish an upper bound on the separation distance associated with\nthis test, and a matching lower bound on the minimax separation rates of\ntesting under non-interactive privacy in the case that $f_0$ is uniform, in\ndiscrete and continuous settings. To the best of our knowledge, we provide the\nfirst minimax optimal test and associated private transformation under a local\ndifferential privacy constraint over Besov balls in the continuous setting,\nquantifying the price to pay for data privacy. We also present a test that is\nadaptive to the smoothness parameter of the unknown density and remains minimax\noptimal up to a logarithmic factor. Finally, we note that our results can be\ntranslated to the discrete case, where the treatment of probability vectors is\nshown to be equivalent to that of piecewise constant densities in our setting.\nThat is why we work with a unified setting for both the continuous and the\ndiscrete cases.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:41:05 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 08:53:58 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 07:12:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Lam-Weil", "Joseph", ""], ["Laurent", "B\u00e9atrice", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "2002.04258", "submitter": "Manuel Gomez Rodriguez", "authors": "Vahid Balazadeh Meresht and Abir De and Adish Singla and Manuel\n  Gomez-Rodriguez", "title": "Learning to Switch Between Machines and Humans", "comments": "Added support for unknown transition probabilities and multiple teams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents have been mostly developed and evaluated under\nthe assumption that they will operate in a fully autonomous manner -- they will\ntake all actions. In this work, our goal is to develop algorithms that, by\nlearning to switch control between machine and human agents, allow existing\nreinforcement learning agents to operate under different automation levels. To\nthis end, we first formally define the problem of learning to switch control\namong agents in a team via a 2-layer Markov decision process. Then, we develop\nan online learning algorithm that uses upper confidence bounds on the agents'\npolicies and the environment's transition probabilities to find a sequence of\nswitching policies. We prove that the total regret of our algorithm with\nrespect to the optimal switching policy is sublinear in the number of learning\nsteps. Moreover, we also show that our algorithm can be used to find multiple\nsequences of switching policies across several independent teams of agents\noperating in similar environments, where it greatly benefits from maintaining\nshared confidence bounds for the environments' transition probabilities.\nSimulation experiments in obstacle avoidance in a semi-autonomous driving\nscenario illustrate our theoretical findings and demonstrate that, by\nexploiting the specific structure of the problem, our proposed algorithm is\nsuperior to problem-agnostic algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:50:52 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:43:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Meresht", "Vahid Balazadeh", ""], ["De", "Abir", ""], ["Singla", "Adish", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04267", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Przemyslaw Biecek", "title": "Lifting Interpretability-Performance Trade-off via Automated Feature\n  Engineering", "comments": "12 pages, 5 figures, 4 tables. arXiv admin note: substantial text\n  overlap with arXiv:1902.11035", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex black-box predictive models may have high performance, but lack of\ninterpretability causes problems like lack of trust, lack of stability,\nsensitivity to concept drift. On the other hand, achieving satisfactory\naccuracy of interpretable models require more time-consuming work related to\nfeature engineering. Can we train interpretable and accurate models, without\ntimeless feature engineering? We propose a method that uses elastic black-boxes\nas surrogate models to create a simpler, less opaque, yet still accurate and\ninterpretable glass-box models. New models are created on newly engineered\nfeatures extracted with the help of a surrogate model. We supply the analysis\nby a large-scale benchmark on several tabular data sets from the OpenML\ndatabase. There are two results 1) extracting information from complex models\nmay improve the performance of linear models, 2) questioning a common myth that\ncomplex machine learning models outperform linear models.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:16:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2002.04274", "submitter": "Nanyi Fei", "authors": "Nanyi Fei, Zhiwu Lu, Yizhao Gao, Jia Tian, Tao Xiang and Ji-Rong Wen", "title": "Meta-Learning across Meta-Tasks for Few-Shot Learning", "comments": "There are some mistakes in the experiments. We thus choose to\n  withdraw this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing meta-learning based few-shot learning (FSL) methods typically adopt\nan episodic training strategy whereby each episode contains a meta-task. Across\nepisodes, these tasks are sampled randomly and their relationships are ignored.\nIn this paper, we argue that the inter-meta-task relationships should be\nexploited and those tasks are sampled strategically to assist in meta-learning.\nSpecifically, we consider the relationships defined over two types of meta-task\npairs and propose different strategies to exploit them. (1) Two meta-tasks with\ndisjoint sets of classes: this pair is interesting because it is reminiscent of\nthe relationship between the source seen classes and target unseen classes,\nfeatured with domain gap caused by class differences. A novel learning\nobjective termed meta-domain adaptation (MDA) is proposed to make the\nmeta-learned model more robust to the domain gap. (2) Two meta-tasks with\nidentical sets of classes: this pair is useful because it can be employed to\nlearn models that are robust against poorly sampled few-shots. To that end, a\nnovel meta-knowledge distillation (MKD) objective is formulated. There are some\nmistakes in the experiments. We thus choose to withdraw this paper.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:25:13 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 15:26:20 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 07:30:28 GMT"}, {"version": "v4", "created": "Sat, 26 Sep 2020 05:02:10 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fei", "Nanyi", ""], ["Lu", "Zhiwu", ""], ["Gao", "Yizhao", ""], ["Tian", "Jia", ""], ["Xiang", "Tao", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2002.04275", "submitter": "Viktor Bengs", "authors": "Adil El Mesaoudi-Paul, Viktor Bengs, Eyke H\\\"ullermeier", "title": "Online Preselection with Context Information under the Plackett-Luce\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an extension of the contextual multi-armed bandit problem, in\nwhich, instead of selecting a single alternative (arm), a learner is supposed\nto make a preselection in the form of a subset of alternatives. More\nspecifically, in each iteration, the learner is presented a set of arms and a\ncontext, both described in terms of feature vectors. The task of the learner is\nto preselect $k$ of these arms, among which a final choice is made in a second\nstep. In our setup, we assume that each arm has a latent (context-dependent)\nutility, and that feedback on a preselection is produced according to a\nPlackett-Luce model. We propose the CPPL algorithm, which is inspired by the\nwell-known UCB algorithm, and evaluate this algorithm on synthetic and real\ndata. In particular, we consider an online algorithm selection scenario, which\nserved as a main motivation of our problem setting. Here, an instance (which\ndefines the context) from a certain problem class (such as SAT) can be solved\nby different algorithms (the arms), but only $k$ of these algorithms can\nactually be run.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:27:24 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mesaoudi-Paul", "Adil El", ""], ["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2002.04276", "submitter": "Katarzyna Wo\\'znica", "authors": "Katarzyna Wo\\'znica and Przemys{\\l}aw Biecek", "title": "Towards explainable meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning is a field that aims at discovering how different machine\nlearning algorithms perform on a wide range of predictive tasks. Such knowledge\nspeeds up the hyperparameter tuning or feature engineering. With the use of\nsurrogate models various aspects of the predictive task such as meta-features,\nlandmarker models e.t.c. are used to predict the expected performance. State of\nthe art approaches are focused on searching for the best meta-model but do not\nexplain how these different aspects contribute to its performance. However, to\nbuild a new generation of meta-models we need a deeper understanding of the\nimportance and effect of meta-features on the model tunability. In this paper,\nwe propose techniques developed for eXplainable Artificial Intelligence (XAI)\nto examine and extract knowledge from black-box surrogate models. To our\nknowledge, this is the first paper that shows how post-hoc explainability can\nbe used to improve the meta-learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 09:42:29 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 12:23:23 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wo\u017anica", "Katarzyna", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.04289", "submitter": "Alo\\\"is Pourchot", "authors": "Alo\\\"is Pourchot, Alexis Ducarouge, Olivier Sigaud", "title": "To Share or Not To Share: A Comprehensive Appraisal of Weight-Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight-sharing (WS) has recently emerged as a paradigm to accelerate the\nautomated search for efficient neural architectures, a process dubbed Neural\nArchitecture Search (NAS). Although very appealing, this framework is not\nwithout drawbacks and several works have started to question its capabilities\non small hand-crafted benchmarks. In this paper, we take advantage of the\n\\nasbench dataset to challenge the efficiency of WS on a representative search\nspace. By comparing a SOTA WS approach to a plain random search we show that,\ndespite decent correlations between evaluations using weight-sharing and\nstandalone ones, WS is only rarely significantly helpful to NAS. In particular\nwe highlight the impact of the search space itself on the benefits.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:29:31 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:11:20 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Pourchot", "Alo\u00efs", ""], ["Ducarouge", "Alexis", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2002.04301", "submitter": "Yangzi Guo", "authors": "Yangzi Guo, Yiyuan She, Adrian Barbu", "title": "Network Pruning via Annealing and Direct Sparsity Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) especially deep convolutional networks are\nvery popular these days and have been proved to successfully offer quite\nreliable solutions to many vision problems. However, the use of deep neural\nnetworks is widely impeded by their intensive computational and memory cost. In\nthis paper, we propose a novel efficient network pruning method that is\nsuitable for both non-structured and structured channel-level pruning. Our\nproposed method tightens a sparsity constraint by gradually removing network\nparameters or filter channels based on a criterion and a schedule. The\nattractive fact that the network size keeps dropping throughout the iterations\nmakes it suitable for the pruning of any untrained or pre-trained network.\nBecause our method uses a $L_0$ constraint instead of the $L_1$ penalty, it\ndoes not introduce any bias in the training parameters or filter channels.\nFurthermore, the $L_0$ constraint makes it easy to directly specify the desired\nsparsity level during the network pruning process. Finally, experimental\nvalidation on extensive synthetic and real vision datasets show that the\nproposed method obtains better or competitive performance compared to other\nstates of art network pruning methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:51:12 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 00:28:09 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 02:48:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Guo", "Yangzi", ""], ["She", "Yiyuan", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04306", "submitter": "Philip Arthur", "authors": "Philip Arthur, Trevor Cohn, Gholamreza Haffari", "title": "Learning Coupled Policies for Simultaneous Machine Translation using\n  Imitation Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to efficiently learn a simultaneous translation\nmodel with coupled programmer-interpreter policies. First, wepresent an\nalgorithmic oracle to produce oracle READ/WRITE actions for training bilingual\nsentence-pairs using the notion of word alignments. This oracle actions are\ndesigned to capture enough information from the partial input before writing\nthe output. Next, we perform a coupled scheduled sampling to effectively\nmitigate the exposure bias when learning both policies jointly with imitation\nlearning. Experiments on six language-pairs show our method outperforms strong\nbaselines in terms of translation quality while keeping the translation delay\nlow.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:56:42 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 05:48:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Arthur", "Philip", ""], ["Cohn", "Trevor", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "2002.04312", "submitter": "Saulo Martiello Mastelini", "authors": "Everton Jose Santana and Felipe Rodrigues dos Santos and Saulo\n  Martiello Mastelini and Fabio Luiz Melquiades and Sylvio Barbon Jr", "title": "Improved prediction of soil properties with Multi-target Stacked\n  Generalisation on EDXRF spectra", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms have been used for assessing soil quality\nparameters along with non-destructive methodologies. Among spectroscopic\nanalytical methodologies, energy dispersive X-ray fluorescence (EDXRF) is one\nof the more quick, environmentally friendly and less expensive when compared to\nconventional methods. However, some challenges in EDXRF spectral data analysis\nstill demand more efficient methods capable of providing accurate outcomes.\nUsing Multi-target Regression (MTR) methods, multiple parameters can be\npredicted, and also taking advantage of inter-correlated parameters the overall\npredictive performance can be improved. In this study, we proposed the\nMulti-target Stacked Generalisation (MTSG), a novel MTR method relying on\nlearning from different regressors arranged in stacking structure for a boosted\noutcome. We compared MTSG and 5 MTR methods for predicting 10 parameters of\nsoil fertility. Random Forest and Support Vector Machine (with linear and\nradial kernels) were used as learning algorithms embedded into each MTR method.\nResults showed the superiority of MTR methods over the Single-target Regression\n(the traditional ML method), reducing the predictive error for 5 parameters.\nParticularly, MTSG obtained the lowest error for phosphorus, total organic\ncarbon and cation exchange capacity. When observing the relative performance of\nSupport Vector Machine with a radial kernel, the prediction of base saturation\npercentage was improved in 19%. Finally, the proposed method was able to reduce\nthe average error from 0.67 (single-target) to 0.64 analysing all targets,\nrepresenting a global improvement of 4.48%.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:05:03 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Santana", "Everton Jose", ""], ["Santos", "Felipe Rodrigues dos", ""], ["Mastelini", "Saulo Martiello", ""], ["Melquiades", "Fabio Luiz", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "2002.04317", "submitter": "Baptiste Caramiaux", "authors": "Baptiste Caramiaux, Jules Fran\\c{c}oise, Wanyu Liu, T\\'eo Sanchez and\n  Fr\\'ed\\'eric Bevilacqua", "title": "Machine Learning Approaches For Motor Learning: A Short Review", "comments": "Mini Review, Frontiers Comput. Sci. - Human-Media Interaction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning approaches have seen considerable applications in human\nmovement modeling, but remain limited for motor learning. Motor learning\nrequires accounting for motor variability, and poses new challenges as the\nalgorithms need to be able to differentiate between new movements and variation\nof known ones. In this short review, we outline existing machine learning\nmodels for motor learning and their adaptation capabilities. We identify and\ndescribe three types of adaptation: Parameter adaptation in probabilistic\nmodels, Transfer and meta-learning in deep neural networks, and Planning\nadaptation by reinforcement learning. To conclude, we discuss challenges for\napplying these models in the domain of motor learning support systems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:11:26 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 07:40:27 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 13:07:49 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 15:00:42 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Caramiaux", "Baptiste", ""], ["Fran\u00e7oise", "Jules", ""], ["Liu", "Wanyu", ""], ["Sanchez", "T\u00e9o", ""], ["Bevilacqua", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.04319", "submitter": "Yangzi Guo", "authors": "Gitesh Dawer, Yangzi Guo, Sida Liu, Adrian Barbu", "title": "Neural Rule Ensembles: Encoding Sparse Feature Interactions into Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks form the basis of very powerful learning methods.\nIt has been observed that a naive application of fully connected neural\nnetworks to data with many irrelevant variables often leads to overfitting. In\nan attempt to circumvent this issue, a prior knowledge pertaining to what\nfeatures are relevant and their possible feature interactions can be encoded\ninto these networks. In this work, we use decision trees to capture such\nrelevant features and their interactions and define a mapping to encode\nextracted relationships into a neural network. This addresses the\ninitialization related concern of fully connected neural networks. At the same\ntime through feature selection it enables learning of compact representations\ncompared to state of the art tree-based approaches. Empirical evaluations and\nsimulation studies show the superiority of such an approach over fully\nconnected neural networks and tree-based approaches\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:22:20 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Dawer", "Gitesh", ""], ["Guo", "Yangzi", ""], ["Liu", "Sida", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04320", "submitter": "Mathias Staudigl", "authors": "Pavel Dvurechensky, Petr Ostroukhov, Kamil Safin, Shimrit Shtern,\n  Mathias Staudigl", "title": "Self-Concordant Analysis of Frank-Wolfe Algorithms", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projection-free optimization via different variants of the Frank-Wolfe (FW),\na.k.a. Conditional Gradient method has become one of the cornerstones in\noptimization for machine learning since in many cases the linear minimization\noracle is much cheaper to implement than projections and some sparsity needs to\nbe preserved. In a number of applications, e.g. Poisson inverse problems or\nquantum state tomography, the loss is given by a self-concordant (SC) function\nhaving unbounded curvature, implying absence of theoretical guarantees for the\nexisting FW methods. We use the theory of SC functions to provide a new\nadaptive step size for FW methods and prove global convergence rate O(1/k)\nafter k iterations. If the problem admits a stronger local linear minimization\noracle, we construct a novel FW method with linear convergence rate for SC\nfunctions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:30:33 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 17:08:42 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 04:35:35 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Dvurechensky", "Pavel", ""], ["Ostroukhov", "Petr", ""], ["Safin", "Kamil", ""], ["Shtern", "Shimrit", ""], ["Staudigl", "Mathias", ""]]}, {"id": "2002.04322", "submitter": "Yangzi Guo", "authors": "Yangzi Guo, Adrian Barbu", "title": "A study of local optima for learning feature interactions using neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many fields such as bioinformatics, high energy physics, power\ndistribution, etc., it is desirable to learn non-linear models where a small\nnumber of variables are selected and the interaction between them is explicitly\nmodeled to predict the response. In principle, neural networks (NNs) could\naccomplish this task since they can model non-linear feature interactions very\nwell. However, NNs require large amounts of training data to have a good\ngeneralization. In this paper we study the datastarved regime where a NN is\ntrained on a relatively small amount of training data. For that purpose we\nstudy feature selection for NNs, which is known to improve generalization for\nlinear models. As an extreme case of data with feature selection and feature\ninteractions we study the XOR-like data with irrelevant variables. We\nexperimentally observed that the cross-entropy loss function on XOR-like data\nhas many non-equivalent local optima, and the number of local optima grows\nexponentially with the number of irrelevant variables. To deal with the local\nminima and for feature selection we propose a node pruning and feature\nselection algorithm that improves the capability of NNs to find better local\nminima even when there are irrelevant variables. Finally, we show that the\nperformance of a NN on real datasets can be improved using pruning, obtaining\ncompact networks on a small number of features, with good prediction and\ninterpretability.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:38:45 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Guo", "Yangzi", ""], ["Barbu", "Adrian", ""]]}, {"id": "2002.04326", "submitter": "Weihao Yu", "authors": "Weihao Yu, Zihang Jiang, Yanfei Dong, Jiashi Feng", "title": "ReClor: A Reading Comprehension Dataset Requiring Logical Reasoning", "comments": "ICLR 2020 paper. Project page: http://whyu.me/reclor/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent powerful pre-trained language models have achieved remarkable\nperformance on most of the popular datasets for reading comprehension. It is\ntime to introduce more challenging datasets to push the development of this\nfield towards more comprehensive reasoning of text. In this paper, we introduce\na new Reading Comprehension dataset requiring logical reasoning (ReClor)\nextracted from standardized graduate admission examinations. As earlier studies\nsuggest, human-annotated datasets usually contain biases, which are often\nexploited by models to achieve high accuracy without truly understanding the\ntext. In order to comprehensively evaluate the logical reasoning ability of\nmodels on ReClor, we propose to identify biased data points and separate them\ninto EASY set while the rest as HARD set. Empirical results show that\nstate-of-the-art models have an outstanding ability to capture biases contained\nin the dataset with high accuracy on EASY set. However, they struggle on HARD\nset with poor performance near that of random guess, indicating more research\nis needed to essentially enhance the logical reasoning ability of current\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:54:29 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:23:26 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 07:14:30 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Yu", "Weihao", ""], ["Jiang", "Zihang", ""], ["Dong", "Yanfei", ""], ["Feng", "Jiashi", ""]]}, {"id": "2002.04328", "submitter": "Giuseppe Brandi", "authors": "Giuseppe Brandi and T. Di Matteo", "title": "Predicting Multidimensional Data via Tensor Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of multidimensional data is becoming a more and more relevant\ntopic in statistical and machine learning research. Given their complexity,\nsuch data objects are usually reshaped into matrices or vectors and then\nanalysed. However, this methodology presents several drawbacks. First of all,\nit destroys the intrinsic interconnections among datapoints in the\nmultidimensional space and, secondly, the number of parameters to be estimated\nin a model increases exponentially. We develop a model that overcomes such\ndrawbacks. In particular, in this paper, we propose a parsimonious tensor\nregression model that retains the intrinsic multidimensional structure of the\ndataset. Tucker structure is employed to achieve parsimony and a shrinkage\npenalization is introduced to deal with over-fitting and collinearity. To\nestimate the model parameters, an Alternating Least Squares algorithm is\ndeveloped. In order to validate the model performance and robustness, a\nsimulation exercise is produced. Moreover, we perform an empirical analysis\nthat highlight the forecasting power of the model with respect to benchmark\nmodels. This is achieved by implementing an autoregressive specification on the\nFoursquares spatio-temporal dataset together with a macroeconomic panel\ndataset. Overall, the proposed model is able to outperform benchmark models\npresent in the forecasting literature.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:57:07 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:37:28 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 18:13:53 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Brandi", "Giuseppe", ""], ["Di Matteo", "T.", ""]]}, {"id": "2002.04333", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis and Manuel Gomez-Rodriguez", "title": "Decisions, Counterfactual Explanations and Strategic Behavior", "comments": "Transportation of mass experiment in main. Clarification of model\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.GT cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data-driven predictive models are increasingly used to inform decisions,\nit has been argued that decision makers should provide explanations that help\nindividuals understand what would have to change for these decisions to be\nbeneficial ones. However, there has been little discussion on the possibility\nthat individuals may use the above counterfactual explanations to invest effort\nstrategically and maximize their chances of receiving a beneficial decision. In\nthis paper, our goal is to find policies and counterfactual explanations that\nare optimal in terms of utility in such a strategic setting. We first show\nthat, given a pre-defined policy, the problem of finding the optimal set of\ncounterfactual explanations is NP-hard. Then, we show that the corresponding\nobjective is nondecreasing and satisfies submodularity and this allows a\nstandard greedy algorithm to enjoy approximation guarantees. In addition, we\nfurther show that the problem of jointly finding both the optimal policy and\nset of counterfactual explanations reduces to maximizing a non-monotone\nsubmodular function. As a result, we can use a recent randomized algorithm to\nsolve the problem, which also offers approximation guarantees. Finally, we\ndemonstrate that, by incorporating a matroid constraint into the problem\nformulation, we can increase the diversity of the optimal set of counterfactual\nexplanations and incentivize individuals across the whole spectrum of the\npopulation to self improve. Experiments on synthetic and real lending and\ncredit card data illustrate our theoretical findings and show that the\ncounterfactual explanations and decision policies found by our algorithms\nachieve higher utility than several competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:04:41 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:28:00 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 16:55:44 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04335", "submitter": "Eren Sezener", "authors": "Eren Sezener and Peter Dayan", "title": "Static and Dynamic Values of Computation in MCTS", "comments": "Presented in UAI 2020", "journal-ref": "PMLR 124:31-40, 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo Tree Search (MCTS) is one of the most-widely used methods for\nplanning, and has powered many recent advances in artificial intelligence. In\nMCTS, one typically performs computations (i.e., simulations) to collect\nstatistics about the possible future consequences of actions, and then chooses\naccordingly. Many popular MCTS methods such as UCT and its variants decide\nwhich computations to perform by trading-off exploration and exploitation. In\nthis work, we take a more direct approach, and explicitly quantify the value of\na computation based on its expected impact on the quality of the action\neventually chosen. Our approach goes beyond the \"myopic\" limitations of\nexisting computation-value-based methods in two senses: (I) we are able to\naccount for the impact of non-immediate (ie, future) computations (II) on\nnon-immediate actions. We show that policies that greedily optimize computation\nvalues are optimal under certain assumptions and obtain results that are\ncompetitive with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:05:58 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 12:28:19 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Sezener", "Eren", ""], ["Dayan", "Peter", ""]]}, {"id": "2002.04337", "submitter": "Felix Opolka", "authors": "Felix L. Opolka, Pietro Li\\`o", "title": "Graph Convolutional Gaussian Processes For Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction aims to reveal missing edges in a graph. We address this task\nwith a Gaussian process that is transformed using simplified graph convolutions\nto better leverage the inductive bias of the domain. To scale the Gaussian\nprocess model to large graphs, we introduce a variational inducing point method\nthat places pseudo inputs on a graph-structured domain. We evaluate our model\non eight large graphs with up to thousands of nodes and report consistent\nimprovements over existing Gaussian process models as well as competitive\nperformance when compared to state-of-the-art graph neural network approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:12:21 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Opolka", "Felix L.", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2002.04348", "submitter": "Kateryna Chumachenko", "authors": "Kateryna Chumachenko, Jenni Raitoharju, Moncef Gabbouj, Alexandros\n  Iosifidis", "title": "Incremental Fast Subclass Discriminant Analysis", "comments": "\\c{opyright} 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an incremental solution to Fast Subclass Discriminant\nAnalysis (fastSDA). We present an exact and an approximate linear solution,\nalong with an approximate kernelized variant. Extensive experiments on eight\nimage datasets with different incremental batch sizes show the superiority of\nthe proposed approach in terms of training time and accuracy being equal or\nclose to fastSDA solution and outperforming other methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:38:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Chumachenko", "Kateryna", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2002.04355", "submitter": "\\c{S}eymanur Akt{\\i}", "authors": "\\c{S}eymanur Akt{\\i}, G\\\"ozde Ay\\c{s}e Tataro\\u{g}lu, Haz{\\i}m Kemal\n  Ekenel", "title": "Vision-based Fight Detection from Surveillance Cameras", "comments": "6 pages, 5 figures, 4 tables, International Conference on Image\n  Processing Theory, Tools and Applications, IPTA 2019", "journal-ref": null, "doi": "10.1109/IPTA.2019.8936070", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based action recognition is one of the most challenging research\ntopics of computer vision and pattern recognition. A specific application of\nit, namely, detecting fights from surveillance cameras in public areas,\nprisons, etc., is desired to quickly get under control these violent incidents.\nThis paper addresses this research problem and explores LSTM-based approaches\nto solve it. Moreover, the attention layer is also utilized. Besides, a new\ndataset is collected, which consists of fight scenes from surveillance camera\nvideos available at YouTube. This dataset is made publicly available. From the\nextensive experiments conducted on Hockey Fight, Peliculas, and the newly\ncollected fight datasets, it is observed that the proposed approach, which\nintegrates Xception model, Bi-LSTM, and attention, improves the\nstate-of-the-art accuracy for fight scene classification.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:56:29 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Akt\u0131", "\u015eeymanur", ""], ["Tataro\u011flu", "G\u00f6zde Ay\u015fe", ""], ["Ekenel", "Haz\u0131m Kemal", ""]]}, {"id": "2002.04359", "submitter": "Ginevra Carbone", "authors": "Ginevra Carbone, Matthew Wicker, Luca Laurenti, Andrea Patane, Luca\n  Bortolussi, Guido Sanguinetti", "title": "Robustness of Bayesian Neural Networks to Gradient-Based Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability to adversarial attacks is one of the principal hurdles to the\nadoption of deep learning in safety-critical applications. Despite significant\nefforts, both practical and theoretical, the problem remains open. In this\npaper, we analyse the geometry of adversarial attacks in the large-data,\noverparametrized limit for Bayesian Neural Networks (BNNs). We show that, in\nthe limit, vulnerability to gradient-based attacks arises as a result of\ndegeneracy in the data distribution, i.e., when the data lies on a\nlower-dimensional submanifold of the ambient space. As a direct consequence, we\ndemonstrate that in the limit BNN posteriors are robust to gradient-based\nadversarial attacks. Experimental results on the MNIST and Fashion MNIST\ndatasets with BNNs trained with Hamiltonian Monte Carlo and Variational\nInference support this line of argument, showing that BNNs can display both\nhigh accuracy and robustness to gradient based adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:03:57 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 16:29:29 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 10:57:33 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Carbone", "Ginevra", ""], ["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Bortolussi", "Luca", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "2002.04363", "submitter": "Kelvin Shuangjian Zhang", "authors": "Kelvin Shuangjian Zhang, Gabriel Peyr\\'e, Jalal Fadili, Marcelo\n  Pereyra", "title": "Wasserstein Control of Mirror Langevin Monte Carlo", "comments": "22 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discretized Langevin diffusions are efficient Monte Carlo methods for\nsampling from high dimensional target densities that are log-Lipschitz-smooth\nand (strongly) log-concave. In particular, the Euclidean Langevin Monte Carlo\nsampling algorithm has received much attention lately, leading to a detailed\nunderstanding of its non-asymptotic convergence properties and of the role that\nsmoothness and log-concavity play in the convergence rate. Distributions that\ndo not possess these regularity properties can be addressed by considering a\nRiemannian Langevin diffusion with a metric capturing the local geometry of the\nlog-density. However, the Monte Carlo algorithms derived from discretizations\nof such Riemannian Langevin diffusions are notoriously difficult to analyze. In\nthis paper, we consider Langevin diffusions on a Hessian-type manifold and\nstudy a discretization that is closely related to the mirror-descent scheme. We\nestablish for the first time a non-asymptotic upper-bound on the sampling error\nof the resulting Hessian Riemannian Langevin Monte Carlo algorithm. This bound\nis measured according to a Wasserstein distance induced by a Riemannian metric\nground cost capturing the Hessian structure and closely related to a\nself-concordance-like condition. The upper-bound implies, for instance, that\nthe iterates contract toward a Wasserstein ball around the target density whose\nradius is made explicit. Our theory recovers existing Euclidean results and can\ncope with a wide variety of Hessian metrics related to highly non-flat\ngeometries.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:16:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Kelvin Shuangjian", ""], ["Peyr\u00e9", "Gabriel", ""], ["Fadili", "Jalal", ""], ["Pereyra", "Marcelo", ""]]}, {"id": "2002.04374", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "J. C. V\\'asquez-Correa, T. Arias-Vergara, C. D. Rios-Urrego, M.\n  Schuster, J. Rusz, J. R. Orozco-Arroyave, E. N\\\"oth", "title": "Convolutional Neural Networks and a Transfer Learning Strategy to\n  Classify Parkinson's Disease from Speech in Three Different Languages", "comments": null, "journal-ref": "In Iberoamerican Congress on Pattern Recognition (pp. 697-706)\n  2019", "doi": "10.1007/978-3-030-33904-3_66", "report-no": null, "categories": "cs.LG cs.CL eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease patients develop different speech impairments that affect\ntheir communication capabilities. The automatic assessment of the speech of the\npatients allows the development of computer aided tools to support the\ndiagnosis and the evaluation of the disease severity. This paper introduces a\nmethodology to classify Parkinson's disease from speech in three different\nlanguages: Spanish, German, and Czech. The proposed approach considers\nconvolutional neural networks trained with time frequency representations and a\ntransfer learning strategy among the three languages. The transfer learning\nscheme aims to improve the accuracy of the models when the weights of the\nneural network are initialized with utterances from a different language than\nthe used for the test set. The results suggest that the proposed strategy\nimproves the accuracy of the models in up to 8\\% when the base model used to\ninitialize the weights of the classifier is robust enough. In addition, the\nresults obtained after the transfer learning are in most cases more balanced in\nterms of specificity-sensitivity than those trained without the transfer\nlearning strategy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:48:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["V\u00e1squez-Correa", "J. C.", ""], ["Arias-Vergara", "T.", ""], ["Rios-Urrego", "C. D.", ""], ["Schuster", "M.", ""], ["Rusz", "J.", ""], ["Orozco-Arroyave", "J. R.", ""], ["N\u00f6th", "E.", ""]]}, {"id": "2002.04375", "submitter": "Patrick Heas", "authors": "Patrick Heas, Cedric Herzet, Benoit Combes", "title": "Generalized Kernel-Based Dynamic Mode Decomposition", "comments": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP 2020). arXiv admin note: substantial text overlap with\n  arXiv:1710.10919", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced modeling in high-dimensional reproducing kernel Hilbert spaces offers\nthe opportunity to approximate efficiently non-linear dynamics. In this work,\nwe devise an algorithm based on low rank constraint optimization and\nkernel-based computation that generalizes a recent approach called\n\"kernel-based dynamic mode decomposition\". This new algorithm is characterized\nby a gain in approximation accuracy, as evidenced by numerical simulations, and\nin computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 13:50:00 GMT"}], "update_date": "2020-02-23", "authors_parsed": [["Heas", "Patrick", ""], ["Herzet", "Cedric", ""], ["Combes", "Benoit", ""]]}, {"id": "2002.04392", "submitter": "Sven Koehler", "authors": "Sven Koehler and Animesh Tandon and Tarique Hussain and Heiner Latus\n  and Thomas Pickardt and Samir Sarikouch and Philipp Beerbaum and Gerald Greil\n  and Sandy Engelhardt and Ivo Wolf", "title": "How well do U-Net-based segmentation trained on adult cardiac magnetic\n  resonance imaging data generalise to rare congenital heart diseases for\n  surgical planning?", "comments": "Accepted for SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Planning the optimal time of intervention for pulmonary valve replacement\nsurgery in patients with the congenital heart disease Tetralogy of Fallot (TOF)\nis mainly based on ventricular volume and function according to current\nguidelines. Both of these two biomarkers are most reliably assessed by\nsegmentation of 3D cardiac magnetic resonance (CMR) images. In several grand\nchallenges in the last years, U-Net architectures have shown impressive results\non the provided data. However, in clinical practice, data sets are more diverse\nconsidering individual pathologies and image properties derived from different\nscanner properties. Additionally, specific training data for complex rare\ndiseases like TOF is scarce.\n  For this work, 1) we assessed the accuracy gap when using a publicly\navailable labelled data set (the Automatic Cardiac Diagnosis Challenge (ACDC)\ndata set) for training and subsequent applying it to CMR data of TOF patients\nand vice versa and 2) whether we can achieve similar results when applying the\nmodel to a more heterogeneous data base.\n  Multiple deep learning models were trained with four-fold cross validation.\nAfterwards they were evaluated on the respective unseen CMR images from the\nother collection. Our results confirm that current deep learning models can\nachieve excellent results (left ventricle dice of\n$0.951\\pm{0.003}$/$0.941\\pm{0.007}$ train/validation) within a single data\ncollection. But once they are applied to other pathologies, it becomes apparent\nhow much they overfit to the training pathologies (dice score drops between\n$0.072\\pm{0.001}$ for the left and $0.165\\pm{0.001}$ for the right ventricle).\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 08:50:51 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Koehler", "Sven", ""], ["Tandon", "Animesh", ""], ["Hussain", "Tarique", ""], ["Latus", "Heiner", ""], ["Pickardt", "Thomas", ""], ["Sarikouch", "Samir", ""], ["Beerbaum", "Philipp", ""], ["Greil", "Gerald", ""], ["Engelhardt", "Sandy", ""], ["Wolf", "Ivo", ""]]}, {"id": "2002.04397", "submitter": "Yuxiang Ren", "authors": "Yuxiang Ren, Jiawei Zhang", "title": "Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:09:13 GMT"}, {"version": "v2", "created": "Sat, 13 Feb 2021 03:16:22 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2002.04401", "submitter": "Yuren Zhou", "authors": "Yuren Zhou, Billy Pik Lik Lau, Zann Koh, Chau Yuen, Benny Kai Kiat Ng", "title": "Understanding Crowd Behaviors in a Social Event by Passive WiFi Sensing\n  and Data Mining", "comments": "This manuscript has been accepted by IEEE Internet of Things journal.\n  Copyright (c) 2020 IEEE. Personal use of this material is permitted. However,\n  permission to use this material for any other purposes must be obtained from\n  the IEEE by sending a request to pubs-permissions@ieee.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding crowd behaviors in a large social event is crucial for event\nmanagement. Passive WiFi sensing, by collecting WiFi probe requests sent from\nmobile devices, provides a better way to monitor crowds compared with people\ncounters and cameras in terms of free interference, larger coverage, lower\ncost, and more information on people's movement. In existing studies, however,\nnot enough attention has been paid to the thorough analysis and mining of\ncollected data. Especially, the power of machine learning has not been fully\nexploited. In this paper, therefore, we propose a comprehensive data analysis\nframework to fully analyze the collected probe requests to extract three types\nof patterns related to crowd behaviors in a large social event, with the help\nof statistics, visualization, and unsupervised machine learning. First,\ntrajectories of the mobile devices are extracted from probe requests and\nanalyzed to reveal the spatial patterns of the crowds' movement. Hierarchical\nagglomerative clustering is adopted to find the interconnections between\ndifferent locations. Next, k-means and k-shape clustering algorithms are\napplied to extract temporal visiting patterns of the crowds by days and\nlocations, respectively. Finally, by combining with time, trajectories are\ntransformed into spatiotemporal patterns, which reveal how trajectory duration\nchanges over the length and how the overall trends of crowd movement change\nover time. The proposed data analysis framework is fully demonstrated using\nreal-world data collected in a large social event. Results show that one can\nextract comprehensive patterns from data collected by a network of passive WiFi\nsensors.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 03:36:00 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhou", "Yuren", ""], ["Lau", "Billy Pik Lik", ""], ["Koh", "Zann", ""], ["Yuen", "Chau", ""], ["Ng", "Benny Kai Kiat", ""]]}, {"id": "2002.04406", "submitter": "Saif Jabari", "authors": "Ouafa Benkraouda, Bilal Thonnam Thodi, Hwasoo Yeo, Monica Menendez,\n  and Saif Eddin Jabari", "title": "Traffic Data Imputation using Deep Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access, 8, 2020, pp. 104740-104752", "doi": "10.1109/ACCESS.2020.2999662", "report-no": null, "categories": "physics.soc-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical learning-based traffic speed estimation method that\nuses sparse vehicle trajectory information. Using a convolutional\nencoder-decoder based architecture, we show that a well trained neural network\ncan learn spatio-temporal traffic speed dynamics from time-space diagrams. We\ndemonstrate this for a homogeneous road section using simulated vehicle\ntrajectories and then validate it using real-world data from NGSIM. Our results\nshow that with probe vehicle penetration levels as low as 5\\%, the proposed\nestimation method can provide a sound reconstruction of macroscopic traffic\nspeeds and reproduce realistic shockwave patterns, implying applicability in a\nvariety of traffic conditions. We further discuss the model's reconstruction\nmechanisms and confirm its ability to differentiate various traffic behaviors\nsuch as congested and free-flow traffic states, transition dynamics, and\nshockwave propagation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:52:58 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Benkraouda", "Ouafa", ""], ["Thodi", "Bilal Thonnam", ""], ["Yeo", "Hwasoo", ""], ["Menendez", "Monica", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2002.04407", "submitter": "Dario Zanca", "authors": "Dario Zanca, Stefano Melacci, Marco Gori", "title": "Toward Improving the Evaluation of Visual Attention Models: a\n  Crowdsourcing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human visual attention is a complex phenomenon. A computational modeling of\nthis phenomenon must take into account where people look in order to evaluate\nwhich are the salient locations (spatial distribution of the fixations), when\nthey look in those locations to understand the temporal development of the\nexploration (temporal order of the fixations), and how they move from one\nlocation to another with respect to the dynamics of the scene and the mechanics\nof the eyes (dynamics). State-of-the-art models focus on learning saliency maps\nfrom human data, a process that only takes into account the spatial component\nof the phenomenon and ignore its temporal and dynamical counterparts. In this\nwork we focus on the evaluation methodology of models of human visual\nattention. We underline the limits of the current metrics for saliency\nprediction and scanpath similarity, and we introduce a statistical measure for\nthe evaluation of the dynamics of the simulated eye movements. While deep\nlearning models achieve astonishing performance in saliency prediction, our\nanalysis shows their limitations in capturing the dynamics of the process. We\nfind that unsupervised gravitational models, despite of their simplicity,\noutperform all competitors. Finally, exploiting a crowd-sourcing platform, we\npresent a study aimed at evaluating how strongly the scanpaths generated with\nthe unsupervised gravitational models appear plausible to naive and expert\nhuman observers.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:27:47 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 13:34:36 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Zanca", "Dario", ""], ["Melacci", "Stefano", ""], ["Gori", "Marco", ""]]}, {"id": "2002.04425", "submitter": "Lu Bai", "authors": "Lu Bai, Lixin Cui, Edwin R. Hancock", "title": "A Hierarchical Transitive-Aligned Graph Kernel for Un-attributed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a new graph kernel, namely the Hierarchical\nTransitive-Aligned kernel, by transitively aligning the vertices between graphs\nthrough a family of hierarchical prototype graphs. Comparing to most existing\nstate-of-the-art graph kernels, the proposed kernel has three theoretical\nadvantages. First, it incorporates the locational correspondence information\nbetween graphs into the kernel computation, and thus overcomes the shortcoming\nof ignoring structural correspondences arising in most R-convolution kernels.\nSecond, it guarantees the transitivity between the correspondence information\nthat is not available for most existing matching kernels. Third, it\nincorporates the information of all graphs under comparisons into the kernel\ncomputation process, and thus encapsulates richer characteristics. By\ntransductively training the C-SVM classifier, experimental evaluations\ndemonstrate the effectiveness of the new transitive-aligned kernel. The\nproposed kernel can outperform state-of-the-art graph kernels on standard\ngraph-based datasets in terms of the classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 11:46:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Bai", "Lu", ""], ["Cui", "Lixin", ""], ["Hancock", "Edwin R.", ""]]}, {"id": "2002.04439", "submitter": "Maurice Quach", "authors": "Maurice Quach, Giuseppe Valenzise and Frederic Dufaux", "title": "Folding-based compression of point cloud attributes", "comments": "Published in ICIP 2020. The source code can be found at\n  https://github.com/mauriceqch/pcc_attr_folding", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.GR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing techniques to compress point cloud attributes leverage either\ngeometric or video-based compression tools. We explore a radically different\napproach inspired by recent advances in point cloud representation learning.\nPoint clouds can be interpreted as 2D manifolds in 3D space. Specifically, we\nfold a 2D grid onto a point cloud and we map attributes from the point cloud\nonto the folded 2D grid using a novel optimized mapping method. This mapping\nresults in an image, which opens a way to apply existing image processing\ntechniques on point cloud attributes. However, as this mapping process is lossy\nin nature, we propose several strategies to refine it so that attributes can be\nmapped to the 2D grid with minimal distortion. Moreover, this approach can be\nflexibly applied to point cloud patches in order to better adapt to local\ngeometric complexity. In this work, we consider point cloud attribute\ncompression; thus, we compress this image with a conventional 2D image codec.\nOur preliminary results show that the proposed folding-based coding scheme can\nalready reach performance similar to the latest MPEG Geometry-based PCC (G-PCC)\ncodec.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:55:58 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 09:04:51 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 07:17:57 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Quach", "Maurice", ""], ["Valenzise", "Giuseppe", ""], ["Dufaux", "Frederic", ""]]}, {"id": "2002.04457", "submitter": "Dong Xia", "authors": "Bing-Yi Jing and Ting Li and Zhongyuan Lyu and Dong Xia", "title": "Community Detection on Mixture Multi-layer Networks via Regularized\n  Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG math.IT math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of community detection in multi-layer networks, where\npairs of nodes can be related in multiple modalities. We introduce a general\nframework, i.e., mixture multi-layer stochastic block model (MMSBM), which\nincludes many earlier models as special cases. We propose a tensor-based\nalgorithm (TWIST) to reveal both global/local memberships of nodes, and\nmemberships of layers. We show that the TWIST procedure can accurately detect\nthe communities with small misclassification error as the number of nodes\nand/or the number of layers increases. Numerical studies confirm our\ntheoretical findings. To our best knowledge, this is the first systematic study\non the mixture multi-layer networks using tensor decomposition. The method is\napplied to two real datasets: worldwide trading networks and malaria parasite\ngenes networks, yielding new and interesting findings.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 06:19:50 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Jing", "Bing-Yi", ""], ["Li", "Ting", ""], ["Lyu", "Zhongyuan", ""], ["Xia", "Dong", ""]]}, {"id": "2002.04458", "submitter": "Luna Zhang", "authors": "Luna M. Zhang", "title": "Pairwise Neural Networks (PairNets) with Low Memory for Fast On-Device\n  Applications", "comments": "arXiv admin note: text overlap with arXiv:2001.08886", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A traditional artificial neural network (ANN) is normally trained slowly by a\ngradient descent algorithm, such as the backpropagation algorithm, since a\nlarge number of hyperparameters of the ANN need to be fine-tuned with many\ntraining epochs. Since a large number of hyperparameters of a deep neural\nnetwork, such as a convolutional neural network, occupy much memory, a\nmemory-inefficient deep learning model is not ideal for real-time Internet of\nThings (IoT) applications on various devices, such as mobile phones. Thus, it\nis necessary to develop fast and memory-efficient Artificial Intelligence of\nThings (AIoT) systems for real-time on-device applications. We created a novel\nwide and shallow 4-layer ANN called \"Pairwise Neural Network\" (\"PairNet\") with\nhigh-speed non-gradient-descent hyperparameter optimization. The PairNet is\ntrained quickly with only one epoch since its hyperparameters are directly\noptimized one-time via simply solving a system of linear equations by using the\nmultivariate least squares fitting method. In addition, an n-input space is\npartitioned into many n-input data subspaces, and a local PairNet is built in a\nlocal n-input subspace. This divide-and-conquer approach can train the local\nPairNet using specific local features to improve model performance. Simulation\nresults indicate that the three PairNets with incremental learning have smaller\naverage prediction mean squared errors, and achieve much higher speeds than\ntraditional ANNs. An important future work is to develop better and faster\nnon-gradient-descent hyperparameter optimization algorithms to generate\neffective, fast, and memory-efficient PairNets with incremental learning on\noptimal subspaces for real-time AIoT on-device applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 02:12:59 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Luna M.", ""]]}, {"id": "2002.04461", "submitter": "Alexander Tong", "authors": "Alexander Tong, Jessie Huang, Guy Wolf, David van Dijk, Smita\n  Krishnaswamy", "title": "TrajectoryNet: A Dynamic Optimal Transport Network for Modeling Cellular\n  Dynamics", "comments": "Presented at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is increasingly common to encounter data from dynamic processes captured\nby static cross-sectional measurements over time, particularly in biomedical\nsettings. Recent attempts to model individual trajectories from this data use\noptimal transport to create pairwise matchings between time points. However,\nthese methods cannot model continuous dynamics and non-linear paths that\nentities can take in these systems. To address this issue, we establish a link\nbetween continuous normalizing flows and dynamic optimal transport, that allows\nus to model the expected paths of points over time. Continuous normalizing\nflows are generally under constrained, as they are allowed to take an arbitrary\npath from the source to the target distribution. We present TrajectoryNet,\nwhich controls the continuous paths taken between distributions to produce\ndynamic optimal transport. We show how this is particularly applicable for\nstudying cellular dynamics in data from single-cell RNA sequencing (scRNA-seq)\ntechnologies, and that TrajectoryNet improves upon recently proposed static\noptimal transport-based models that can be used for interpolating cellular\ndistributions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 21:00:38 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 13:42:19 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tong", "Alexander", ""], ["Huang", "Jessie", ""], ["Wolf", "Guy", ""], ["van Dijk", "David", ""], ["Krishnaswamy", "Smita", ""]]}, {"id": "2002.04464", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Sa\\v{s}o D\\v{z}eroski, Nada Lavra\\v{c} and Matej\n  Petkovi\\v{c}", "title": "Feature Importance Estimation with Self-Attention Networks", "comments": "Accepted for publication in ECAI 2020", "journal-ref": null, "doi": "10.3233/FAIA200256", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box neural network models are widely used in industry and science, yet\nare hard to understand and interpret. Recently, the attention mechanism was\nintroduced, offering insights into the inner workings of neural language\nmodels. This paper explores the use of attention-based neural networks\nmechanism for estimating feature importance, as means for explaining the models\nlearned from propositional (tabular) data. Feature importance estimates,\nassessed by the proposed Self-Attention Network (SAN) architecture, are\ncompared with the established ReliefF, Mutual Information and Random\nForest-based estimates, which are widely used in practice for model\ninterpretation. For the first time we conduct scale-free comparisons of feature\nimportance estimates across algorithms on ten real and synthetic data sets to\nstudy the similarities and differences of the resulting feature importance\nestimates, showing that SANs identify similar high-ranked features as the other\nmethods. We demonstrate that SANs identify feature interactions which in some\ncases yield better predictive performance than the baselines, suggesting that\nattention extends beyond interactions of just a few key features and detects\nlarger feature subsets relevant for the considered learning task.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:15:58 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Lavra\u010d", "Nada", ""], ["Petkovi\u010d", "Matej", ""]]}, {"id": "2002.04486", "submitter": "Lenaic Chizat", "authors": "Lenaic Chizat (LMO), Francis Bach (LIENS, SIERRA)", "title": "Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks\n  Trained with the Logistic Loss", "comments": null, "journal-ref": "Conference on Learning Theory, Jul 2020, Graz, Austria", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained to minimize the logistic (a.k.a. cross-entropy) loss\nwith gradient-based methods are observed to perform well in many supervised\nclassification tasks. Towards understanding this phenomenon, we analyze the\ntraining and generalization behavior of infinitely wide two-layer neural\nnetworks with homogeneous activations. We show that the limits of the gradient\nflow on exponentially tailed losses can be fully characterized as a max-margin\nclassifier in a certain non-Hilbertian space of functions. In presence of\nhidden low-dimensional structures, the resulting margin is independent of the\nambiant dimension, which leads to strong generalization bounds. In contrast,\ntraining only the output layer implicitly solves a kernel support vector\nmachine, which a priori does not enjoy such an adaptivity. Our analysis of\ntraining is non-quantitative in terms of running time but we prove\ncomputational guarantees in simplified settings by showing equivalences with\nonline mirror descent. Finally, numerical experiments suggest that our analysis\ndescribes well the practical behavior of two-layer neural networks with ReLU\nactivation and confirm the statistical benefits of this implicit bias.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:42:09 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 15:07:48 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 13:50:38 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 15:50:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chizat", "Lenaic", "", "LMO"], ["Bach", "Francis", "", "LIENS, SIERRA"]]}, {"id": "2002.04495", "submitter": "Alireza Doostan", "authors": "Subhayan De, Jolene Britton, Matthew Reynolds, Ryan Skinner, Kenneth\n  Jansen, and Alireza Doostan", "title": "On transfer learning of neural networks using bi-fidelity data for\n  uncertainty propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their high degree of expressiveness, neural networks have recently\nbeen used as surrogate models for mapping inputs of an engineering system to\noutputs of interest. Once trained, neural networks are computationally\ninexpensive to evaluate and remove the need for repeated evaluations of\ncomputationally expensive models in uncertainty quantification applications.\nHowever, given the highly parameterized construction of neural networks,\nespecially deep neural networks, accurate training often requires large amounts\nof simulation data that may not be available in the case of computationally\nexpensive systems. In this paper, to alleviate this issue for uncertainty\npropagation, we explore the application of transfer learning techniques using\ntraining data generated from both high- and low-fidelity models. We explore two\nstrategies for coupling these two datasets during the training procedure,\nnamely, the standard transfer learning and the bi-fidelity weighted learning.\nIn the former approach, a neural network model mapping the inputs to the\noutputs of interest is trained based on the low-fidelity data. The\nhigh-fidelity data is then used to adapt the parameters of the upper layer(s)\nof the low-fidelity network, or train a simpler neural network to map the\noutput of the low-fidelity network to that of the high-fidelity model. In the\nlatter approach, the entire low-fidelity network parameters are updated using\ndata generated via a Gaussian process model trained with a small high-fidelity\ndataset. The parameter updates are performed via a variant of stochastic\ngradient descent with learning rates given by the Gaussian process model. Using\nthree numerical examples, we illustrate the utility of these bi-fidelity\ntransfer learning methods where we focus on accuracy improvement achieved by\ntransfer learning over standard training approaches.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:56:11 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["De", "Subhayan", ""], ["Britton", "Jolene", ""], ["Reynolds", "Matthew", ""], ["Skinner", "Ryan", ""], ["Jansen", "Kenneth", ""], ["Doostan", "Alireza", ""]]}, {"id": "2002.04497", "submitter": "Wenyi Xiao", "authors": "Wenyi Xiao, Huan Zhao, Vincent W. Zheng, Yangqiu Song", "title": "Vertex-reinforced Random Walk for Network Embedding", "comments": "Accepted by SDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the fundamental problem of random walk for network\nembedding. We propose to use non-Markovian random walk, variants of\nvertex-reinforced random walk (VRRW), to fully use the history of a random walk\npath. To solve the getting stuck problem of VRRW, we introduce an\nexploitation-exploration mechanism to help the random walk jump out of the\nstuck set. The new random walk algorithms share the same convergence property\nof VRRW and thus can be used to learn stable network embeddings. Experimental\nresults on two link prediction benchmark datasets and three node classification\nbenchmark datasets show that our proposed approach reinforce2vec can outperform\nstate-of-the-art random walk based embedding methods by a large margin.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:58:31 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Xiao", "Wenyi", ""], ["Zhao", "Huan", ""], ["Zheng", "Vincent W.", ""], ["Song", "Yangqiu", ""]]}, {"id": "2002.04504", "submitter": "Julian Blank", "authors": "Julian Blank, Kalyanmoy Deb", "title": "pymoo: Multi-objective Optimization in Python", "comments": null, "journal-ref": "IEEE Access 8 (2020) 89497-89509", "doi": "10.1109/ACCESS.2020.2990567", "report-no": "COIN-2020001", "categories": "cs.NE cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Python has become the programming language of choice for research and\nindustry projects related to data science, machine learning, and deep learning.\nSince optimization is an inherent part of these research fields, more\noptimization related frameworks have arisen in the past few years. Only a few\nof them support optimization of multiple conflicting objectives at a time, but\ndo not provide comprehensive tools for a complete multi-objective optimization\ntask. To address this issue, we have developed pymoo, a multi-objective\noptimization framework in Python. We provide a guide to getting started with\nour framework by demonstrating the implementation of an exemplary constrained\nmulti-objective optimization scenario. Moreover, we give a high-level overview\nof the architecture of pymoo to show its capabilities followed by an\nexplanation of each module and its corresponding sub-modules. The\nimplementations in our framework are customizable and algorithms can be\nmodified/extended by supplying custom operators. Moreover, a variety of single,\nmulti and many-objective test problems are provided and gradients can be\nretrieved by automatic differentiation out of the box. Also, pymoo addresses\npractical needs, such as the parallelization of function evaluations, methods\nto visualize low and high-dimensional spaces, and tools for multi-criteria\ndecision making. For more information about pymoo, readers are encouraged to\nvisit: https://pymoo.org\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:04:24 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Blank", "Julian", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2002.04518", "submitter": "Angela Zhou", "authors": "Nathan Kallus and Angela Zhou", "title": "Confounding-Robust Policy Evaluation in Infinite-Horizon Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation of sequential decision policies from observational data\nis necessary in applications of batch reinforcement learning such as education\nand healthcare. In such settings, however, unobserved variables confound\nobserved actions, rendering exact evaluation of new policies impossible, i.e.,\nunidentifiable. We develop a robust approach that estimates sharp bounds on the\n(unidentifiable) value of a given policy in an infinite-horizon problem given\ndata from another policy with unobserved confounding, subject to a sensitivity\nmodel. We consider stationary or baseline unobserved confounding and compute\nbounds by optimizing over the set of all stationary state-occupancy ratios that\nagree with a new partially identified estimating equation and the sensitivity\nmodel. We prove convergence to the sharp bounds as we collect more confounded\ndata. Although checking set membership is a linear program, the support\nfunction is given by a difficult nonconvex optimization problem. We develop\napproximations based on nonconvex projected gradient descent and demonstrate\nthe resulting bounds empirically.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:18:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:03:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "2002.04523", "submitter": "Nathan Lambert", "authors": "Nathan Lambert, Brandon Amos, Omry Yadan, Roberto Calandra", "title": "Objective Mismatch in Model-based Reinforcement Learning", "comments": "9 pages, 2 pages references, 5 pages appendices", "journal-ref": "Proceedings of the 2nd Conference on Learning for Dynamics and\n  Control, PMLR 120:761-770, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has been shown to be a powerful\nframework for data-efficiently learning control of continuous tasks. Recent\nwork in MBRL has mostly focused on using more advanced function approximators\nand planning schemes, with little development of the general framework. In this\npaper, we identify a fundamental issue of the standard MBRL framework -- what\nwe call the objective mismatch issue. Objective mismatch arises when one\nobjective is optimized in the hope that a second, often uncorrelated, metric\nwill also be optimized. In the context of MBRL, we characterize the objective\nmismatch between training the forward dynamics model w.r.t.~the likelihood of\nthe one-step ahead prediction, and the overall goal of improving performance on\na downstream control task. For example, this issue can emerge with the\nrealization that dynamics models effective for a specific task do not\nnecessarily need to be globally accurate, and vice versa globally accurate\nmodels might not be sufficiently accurate locally to obtain good control\nperformance on a specific task. In our experiments, we study this objective\nmismatch issue and demonstrate that the likelihood of one-step ahead\npredictions is not always correlated with control performance. This observation\nhighlights a critical limitation in the MBRL framework which will require\nfurther research to be fully understood and addressed. We propose an initial\nmethod to mitigate the mismatch issue by re-weighting dynamics model training.\nBuilding on it, we conclude with a discussion about other potential directions\nof research for addressing this issue.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:26:07 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 22:21:48 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 03:02:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Lambert", "Nathan", ""], ["Amos", "Brandon", ""], ["Yadan", "Omry", ""], ["Calandra", "Roberto", ""]]}, {"id": "2002.04555", "submitter": "Andrew Brereton", "authors": "Andrew E. Brereton, Stephen MacKinnon, Zhaleh Safikhani, Shawn Reeves,\n  Sana Alwash, Vijay Shahani, Andreas Windemuth", "title": "Predicting drug properties with parameter-free machine learning:\n  Pareto-Optimal Embedded Modeling (POEM)", "comments": "37 pages, 9 figures, supplemental included, submitted to \"Machine\n  Learning: Science and Technology\"", "journal-ref": null, "doi": "10.1088/2632-2153/ab891b", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of absorption, distribution, metabolism, excretion, and\ntoxicity (ADMET) of small molecules from their molecular structure is a central\nproblem in medicinal chemistry with great practical importance in drug\ndiscovery. Creating predictive models conventionally requires substantial\ntrial-and-error for the selection of molecular representations, machine\nlearning (ML) algorithms, and hyperparameter tuning. A generally applicable\nmethod that performs well on all datasets without tuning would be of great\nvalue but is currently lacking. Here, we describe Pareto-Optimal Embedded\nModeling (POEM), a similarity-based method for predicting molecular properties.\nPOEM is a non-parametric, supervised ML algorithm developed to generate\nreliable predictive models without need for optimization. POEMs predictive\nstrength is obtained by combining multiple different representations of\nmolecular structures in a context-specific manner, while maintaining low\ndimensionality. We benchmark POEM relative to industry-standard ML algorithms\nand published results across 17 classifications tasks. POEM performs well in\nall cases and reduces the risk of overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:20:28 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 19:13:45 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Brereton", "Andrew E.", ""], ["MacKinnon", "Stephen", ""], ["Safikhani", "Zhaleh", ""], ["Reeves", "Shawn", ""], ["Alwash", "Sana", ""], ["Shahani", "Vijay", ""], ["Windemuth", "Andreas", ""]]}, {"id": "2002.04571", "submitter": "Mohamed Mejri", "authors": "Mohamed Mejri, Antoine Richard, C\\'edric Pradalier", "title": "A Survey On 3D Inner Structure Prediction from its Outer Shape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The analysis of the internal structure of trees is highly important for both\nforest experts, biological scientists, and the wood industry. Traditionally,\nCT-scanners are considered as the most efficient way to get an accurate inner\nrepresentation of the tree. However, this method requires an important\ninvestment and reduces the cost-effectiveness of this operation. Our goal is to\ndesign neural-network-based methods to predict the internal density of the tree\nfrom its external bark shape. This paper compares different image-to-image(2D),\nvolume-to-volume(3D) and Convolutional Long Short Term Memory based neural\nnetwork architectures in the context of the prediction of the defect\ndistribution inside trees from their external bark shape. Those models are\ntrained on a synthetic dataset of 1800 CT-scanned look-like volumetric\nstructures of the internal density of the trees and their corresponding\nexternal surface.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:56:38 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Mejri", "Mohamed", ""], ["Richard", "Antoine", ""], ["Pradalier", "C\u00e9dric", ""]]}, {"id": "2002.04599", "submitter": "Florian Tram\\`er", "authors": "Florian Tram\\`er and Jens Behrmann and Nicholas Carlini and Nicolas\n  Papernot and J\\\"orn-Henrik Jacobsen", "title": "Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial\n  Perturbations", "comments": "ICML 2020 (Supersedes the workshop paper \"Exploiting Excessive\n  Invariance caused by Norm-Bounded Adversarial Robustness\", arXiv:1903.10484)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are malicious inputs crafted to induce\nmisclassification. Commonly studied sensitivity-based adversarial examples\nintroduce semantically-small changes to an input that result in a different\nmodel prediction. This paper studies a complementary failure mode,\ninvariance-based adversarial examples, that introduce minimal semantic changes\nthat modify an input's true label yet preserve the model's prediction. We\ndemonstrate fundamental tradeoffs between these two types of adversarial\nexamples.\n  We show that defenses against sensitivity-based attacks actively harm a\nmodel's accuracy on invariance-based attacks, and that new approaches are\nneeded to resist both attack types. In particular, we break state-of-the-art\nadversarially-trained and certifiably-robust models by generating small\nperturbations that the models are (provably) robust to, yet that change an\ninput's class according to human labelers. Finally, we formally show that the\nexistence of excessively invariant classifiers arises from the presence of\noverly-robust predictive features in standard datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:50:23 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 16:53:43 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Tram\u00e8r", "Florian", ""], ["Behrmann", "Jens", ""], ["Carlini", "Nicholas", ""], ["Papernot", "Nicolas", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""]]}, {"id": "2002.04608", "submitter": "Mike Kuehne", "authors": "Michael Kuehne and Marius Radu", "title": "Constructing a Highlight Classifier with an Attention Based LSTM Neural\n  Network", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is being produced in larger quantities than ever before in human\nhistory. It's only natural to expect a rise in demand for technology that aids\nhumans in sifting through and analyzing this inexhaustible supply of\ninformation. This need exists in the market research industry, where large\namounts of consumer research data is collected through video recordings. At\npresent, the standard method for analyzing video data is human labor. Market\nresearchers manually review the vast majority of consumer research video in\norder to identify relevant portions - highlights. The industry state of the art\nturnaround ratio is 2.2 - for every hour of video content 2.2 hours of manpower\nare required. In this study we present a novel approach for NLP-based highlight\nidentification and extraction based on a supervised learning model that aides\nmarket researchers in sifting through their data. Our approach hinges on a\nmanually curated user-generated highlight clips constructed from long and\nshort-form video data. The problem is best suited for an NLP approach due to\nthe availability of video transcription. We evaluate multiple classes of\nmodels, from gradient boosting to recurrent neural networks, comparing their\nperformance in extraction and identification of highlights. The best performing\nmodels are then evaluated using four sampling methods designed to analyze\ndocuments much larger than the maximum input length of the classifiers. We\nreport very high performances for the standalone classifiers, ROC AUC scores in\nthe range 0.93-0.94, but observe a significant drop in effectiveness when\nevaluated on large documents. Based on our results we suggest combinations of\nmodels/sampling algorithms for various use cases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:18:31 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Kuehne", "Michael", ""], ["Radu", "Marius", ""]]}, {"id": "2002.04613", "submitter": "Attila Szab\\'o", "authors": "Attila Szab\\'o, Claudio Castelnovo", "title": "Neural network wave functions and the sign problem", "comments": "12 pages, 7 figures. v3: authors' final version", "journal-ref": "Phys. Rev. Research 2, 033075 (2020)", "doi": "10.1103/PhysRevResearch.2.033075", "report-no": null, "categories": "cond-mat.str-el cond-mat.dis-nn cs.LG physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural quantum states (NQS) are a promising approach to study many-body\nquantum physics. However, they face a major challenge when applied to lattice\nmodels: Convolutional networks struggle to converge to ground states with a\nnontrivial sign structure. We tackle this problem by proposing a neural network\narchitecture with a simple, explicit, and interpretable phase ansatz, which can\nrobustly represent such states and achieve state-of-the-art variational\nenergies for both conventional and frustrated antiferromagnets. In the latter\ncase, our approach uncovers low-energy states that exhibit the Marshall sign\nrule and are therefore inconsistent with the expected ground state. Such states\nare the likely cause of the obstruction for NQS-based variational Monte Carlo\nto access the true ground states of these systems. We discuss the implications\nof this observation and suggest potential strategies to overcome the problem.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:00:01 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 12:35:40 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 16:17:21 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Szab\u00f3", "Attila", ""], ["Castelnovo", "Claudio", ""]]}, {"id": "2002.04626", "submitter": "Jacob Reinhold", "authors": "Jacob C. Reinhold, Yufan He, Shizhong Han, Yunqiang Chen, Dashan Gao,\n  Junghoon Lee, Jerry L. Prince, Aaron Carass", "title": "Finding novelty with uncertainty", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images are often used to detect and characterize pathology and\ndisease; however, automatically identifying and segmenting pathology in medical\nimages is challenging because the appearance of pathology across diseases\nvaries widely. To address this challenge, we propose a Bayesian deep learning\nmethod that learns to translate healthy computed tomography images to magnetic\nresonance images and simultaneously calculates voxel-wise uncertainty. Since\nhigh uncertainty occurs in pathological regions of the image, this uncertainty\ncan be used for unsupervised anomaly segmentation. We show encouraging\nexperimental results on an unsupervised anomaly segmentation task by combining\ntwo types of uncertainty into a novel quantity we call scibilic uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:00:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Reinhold", "Jacob C.", ""], ["He", "Yufan", ""], ["Han", "Shizhong", ""], ["Chen", "Yunqiang", ""], ["Gao", "Dashan", ""], ["Lee", "Junghoon", ""], ["Prince", "Jerry L.", ""], ["Carass", "Aaron", ""]]}, {"id": "2002.04632", "submitter": "Sergey Shirobokov", "authors": "Sergey Shirobokov, Vladislav Belavin, Michael Kagan, Andrey\n  Ustyuzhanin, At{\\i}l{\\i}m G\\\"une\\c{s} Baydin", "title": "Black-Box Optimization with Local Generative Surrogates", "comments": null, "journal-ref": "In Advances in Neural Information Processing Systems 34 (NeurIPS),\n  2020", "doi": null, "report-no": null, "categories": "cs.LG hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for gradient-based optimization of black-box\nsimulators using differentiable local surrogate models. In fields such as\nphysics and engineering, many processes are modeled with non-differentiable\nsimulators with intractable likelihoods. Optimization of these forward models\nis particularly challenging, especially when the simulator is stochastic. To\naddress such cases, we introduce the use of deep generative models to\niteratively approximate the simulator in local neighborhoods of the parameter\nspace. We demonstrate that these local surrogates can be used to approximate\nthe gradient of the simulator, and thus enable gradient-based optimization of\nsimulator parameters. In cases where the dependence of the simulator on the\nparameter space is constrained to a low dimensional submanifold, we observe\nthat our method attains minima faster than baseline methods, including Bayesian\noptimization, numerical optimization, and approaches using score function\ngradient estimators.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:02:57 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 19:49:24 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Shirobokov", "Sergey", ""], ["Belavin", "Vladislav", ""], ["Kagan", "Michael", ""], ["Ustyuzhanin", "Andrey", ""], ["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""]]}, {"id": "2002.04634", "submitter": "Bruno Iochins Grisci", "authors": "Jonas da Silveira Bohrer, Bruno Iochins Grisci and Marcio Dorn", "title": "Neuroevolution of Neural Network Architectures Using CoDeepNEAT and\n  Keras", "comments": "The original work was presented by Jonas da Silveira Bohrer in\n  partial fulfillment of the requirements for the degree of Bachelor in\n  Computer Engineering at the Institute of Informatics of the Federal\n  University of Rio Grande do Sul (UFRGS), Brazil, with Marcio Dorn as advisor\n  and Bruno Iochins Grisci as co-advisor. The original text is available at\n  Lume: https://lume.ufrgs.br/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is a huge field of study in computer science and statistics\ndedicated to the execution of computational tasks through algorithms that do\nnot require explicit instructions but instead rely on learning patterns from\ndata samples to automate inferences. A large portion of the work involved in a\nmachine learning project is to define the best type of algorithm to solve a\ngiven problem. Neural networks - especially deep neural networks - are the\npredominant type of solution in the field. However, the networks themselves can\nproduce very different results according to the architectural choices made for\nthem. Finding the optimal network topology and configurations for a given\nproblem is a challenge that requires domain knowledge and testing efforts due\nto a large number of parameters that need to be considered. The purpose of this\nwork is to propose an adapted implementation of a well-established evolutionary\ntechnique from the neuroevolution field that manages to automate the tasks of\ntopology and hyperparameter selection. It uses a popular and accessible machine\nlearning framework - Keras - as the back-end, presenting results and proposed\nchanges concerning the original algorithm. The implementation is available at\nGitHub (https://github.com/sbcblab/Keras-CoDeepNEAT) with documentation and\nexamples to reproduce the experiments performed for this work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:03:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bohrer", "Jonas da Silveira", ""], ["Grisci", "Bruno Iochins", ""], ["Dorn", "Marcio", ""]]}, {"id": "2002.04639", "submitter": "Jacob Reinhold", "authors": "Jacob C. Reinhold, Yufan He, Shizhong Han, Yunqiang Chen, Dashan Gao,\n  Junghoon Lee, Jerry L. Prince, Aaron Carass", "title": "Validating uncertainty in medical image translation", "comments": "IEEE ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images are increasingly used as input to deep neural networks to\nproduce quantitative values that aid researchers and clinicians. However,\nstandard deep neural networks do not provide a reliable measure of uncertainty\nin those quantitative values. Recent work has shown that using dropout during\ntraining and testing can provide estimates of uncertainty. In this work, we\ninvestigate using dropout to estimate epistemic and aleatoric uncertainty in a\nCT-to-MR image translation task. We show that both types of uncertainty are\ncaptured, as defined, providing confidence in the output uncertainty estimates.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:06:54 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Reinhold", "Jacob C.", ""], ["He", "Yufan", ""], ["Han", "Shizhong", ""], ["Chen", "Yunqiang", ""], ["Gao", "Dashan", ""], ["Lee", "Junghoon", ""], ["Prince", "Jerry L.", ""], ["Carass", "Aaron", ""]]}, {"id": "2002.04640", "submitter": "Raoni Louren\\c{c}o", "authors": "Raoni Louren\\c{c}o and Juliana Freire and Dennis Shasha", "title": "Debugging Machine Learning Pipelines", "comments": "10 pages", "journal-ref": "Proceedings of the 3rd International Workshop on Data Management\n  for End-to-End Machine Learning, June 2019, Article No.: 3", "doi": "10.1145/3329486.3329489", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning tasks entail the use of complex computational pipelines to\nreach quantitative and qualitative conclusions. If some of the activities in a\npipeline produce erroneous or uninformative outputs, the pipeline may fail or\nproduce incorrect results. Inferring the root cause of failures and unexpected\nbehavior is challenging, usually requiring much human thought, and is both\ntime-consuming and error-prone. We propose a new approach that makes use of\niteration and provenance to automatically infer the root causes and derive\nsuccinct explanations of failures. Through a detailed experimental evaluation,\nwe assess the cost, precision, and recall of our approach compared to the state\nof the art. Our source code and experimental data will be available for\nreproducibility and enhancement.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:13:12 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Louren\u00e7o", "Raoni", ""], ["Freire", "Juliana", ""], ["Shasha", "Dennis", ""]]}, {"id": "2002.04658", "submitter": "Tong Qin", "authors": "Jun Hou, Tong Qin, Kailiang Wu, Dongbin Xiu", "title": "A Non-Intrusive Correction Algorithm for Classification Problems with\n  Corrupted Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel correction algorithm is proposed for multi-class classification\nproblems with corrupted training data. The algorithm is non-intrusive, in the\nsense that it post-processes a trained classification model by adding a\ncorrection procedure to the model prediction. The correction procedure can be\ncoupled with any approximators, such as logistic regression, neural networks of\nvarious architectures, etc. When training dataset is sufficiently large, we\nprove that the corrected models deliver correct classification results as if\nthere is no corruption in the training data. For datasets of finite size, the\ncorrected models produce significantly better recovery results, compared to the\nmodels without the correction algorithm. All of the theoretical findings in the\npaper are verified by our numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:07:05 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hou", "Jun", ""], ["Qin", "Tong", ""], ["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "2002.04663", "submitter": "Lijing Wang", "authors": "Lijing Wang, Jiangzhuo Chen, and Madhav Marathe", "title": "TDEFSI: Theory Guided Deep Learning Based Epidemic Forecasting with\n  Synthetic Information", "comments": "This article has been accepted by ACM TSAS journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influenza-like illness (ILI) places a heavy social and economic burden on our\nsociety. Traditionally, ILI surveillance data is updated weekly and provided at\na spatially coarse resolution. Producing timely and reliable high-resolution\nspatiotemporal forecasts for ILI is crucial for local preparedness and optimal\ninterventions. We present TDEFSI (Theory Guided Deep Learning Based Epidemic\nForecasting with Synthetic Information), an epidemic forecasting framework that\nintegrates the strengths of deep neural networks and high-resolution\nsimulations of epidemic processes over networks. TDEFSI yields accurate\nhigh-resolution spatiotemporal forecasts using low-resolution time series data.\nDuring the training phase, TDEFSI uses high-resolution simulations of epidemics\nthat explicitly model spatial and social heterogeneity inherent in urban\nregions as one component of training data. We train a two-branch recurrent\nneural network model to take both within-season and between-season\nlow-resolution observations as features, and output high-resolution detailed\nforecasts. The resulting forecasts are not just driven by observed data but\nalso capture the intricate social, demographic and geographic attributes of\nspecific urban regions and mathematical theories of disease propagation over\nnetworks. We focus on forecasting the incidence of ILI and evaluate TDEFSI's\nperformance using synthetic and real-world testing datasets at the state and\ncounty levels in the USA. The results show that, at the state level, our method\nachieves comparable/better performance than several state-of-the-art methods.\nAt the county level, TDEFSI outperforms the other methods. The proposed method\ncan be applied to other infectious diseases as well.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 20:51:49 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Wang", "Lijing", ""], ["Chen", "Jiangzhuo", ""], ["Marathe", "Madhav", ""]]}, {"id": "2002.04665", "submitter": "William Whiteley", "authors": "William Whiteley, Vladimir Panin, Chuanyu Zhou, Jorge Cabello, Deepak\n  Bharkhada and Jens Gregor", "title": "FastPET: Near Real-Time PET Reconstruction from Histo-Images Using a\n  Neural Network", "comments": "Submitted to Transactions on Radiation and Plasma Medical Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct reconstruction of positron emission tomography (PET) data using deep\nneural networks is a growing field of research. Initial results are promising,\nbut often the networks are complex, memory utilization inefficient, produce\nrelatively small 2D image slices (e.g., 128x128), and low count rate\nreconstructions are of varying quality. This paper proposes FastPET, a novel\ndirect reconstruction convolutional neural network that is architecturally\nsimple, memory space efficient, works for non-trivial 3D image volumes and is\ncapable of processing a wide spectrum of PET data including low-dose and\nmulti-tracer applications. FastPET uniquely operates on a histo-image (i.e.,\nimage-space) representation of the raw data enabling it to reconstruct 3D image\nvolumes 67x faster than Ordered subsets Expectation Maximization (OSEM). We\ndetail the FastPET method trained on whole-body and low-dose whole-body data\nsets and explore qualitative and quantitative aspects of reconstructed images\nfrom clinical and phantom studies. Additionally, we explore the application of\nFastPET on a neurology data set containing multiple different tracers. The\nresults show that not only are the reconstructions very fast, but the images\nare high quality and lower noise than iterative reconstructions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:32:47 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 15:07:59 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Whiteley", "William", ""], ["Panin", "Vladimir", ""], ["Zhou", "Chuanyu", ""], ["Cabello", "Jorge", ""], ["Bharkhada", "Deepak", ""], ["Gregor", "Jens", ""]]}, {"id": "2002.04670", "submitter": "Filip Hanzely", "authors": "Filip Hanzely, Dmitry Kovalev and Peter Richtarik", "title": "Variance Reduced Coordinate Descent with Acceleration: New Method With a\n  Surprising Application to Finite-Sum Problems", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an accelerated version of stochastic variance reduced coordinate\ndescent -- ASVRCD. As other variance reduced coordinate descent methods such as\nSEGA or SVRCD, our method can deal with problems that include a non-separable\nand non-smooth regularizer, while accessing a random block of partial\nderivatives in each iteration only. However, ASVRCD incorporates Nesterov's\nmomentum, which offers favorable iteration complexity guarantees over both SEGA\nand SVRCD. As a by-product of our theory, we show that a variant of Allen-Zhu\n(2017) is a specific case of ASVRCD, recovering the optimal oracle complexity\nfor the finite sum objective.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:42:37 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hanzely", "Filip", ""], ["Kovalev", "Dmitry", ""], ["Richtarik", "Peter", ""]]}, {"id": "2002.04676", "submitter": "Dmitrii Beloborodov", "authors": "Dmitrii Beloborodov (1), A. E. Ulanov (1), Jakob N. Foerster (2),\n  Shimon Whiteson (2), A. I. Lvovsky (1 and 2) ((1) Russian Quantum Center, (2)\n  University of Oxford)", "title": "Reinforcement Learning Enhanced Quantum-inspired Algorithm for\n  Combinatorial Optimization", "comments": "Submitted to ICML 2020. 9 pages, 3 pdf figures. V2: fixed\n  acknowledgements", "journal-ref": "Machine Learning: Science and Technology, 2, 025009 (2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum hardware and quantum-inspired algorithms are becoming increasingly\npopular for combinatorial optimization. However, these algorithms may require\ncareful hyperparameter tuning for each problem instance. We use a reinforcement\nlearning agent in conjunction with a quantum-inspired algorithm to solve the\nIsing energy minimization problem, which is equivalent to the Maximum Cut\nproblem. The agent controls the algorithm by tuning one of its parameters with\nthe goal of improving recently seen solutions. We propose a new Rescaled Ranked\nReward (R3) method that enables stable single-player version of self-play\ntraining that helps the agent to escape local optima. The training on any\nproblem instance can be accelerated by applying transfer learning from an agent\ntrained on randomly generated problems. Our approach allows sampling\nhigh-quality solutions to the Ising problem with high probability and\noutperforms both baseline heuristics and a black-box hyperparameter\noptimization approach.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:55:07 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:47:49 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Beloborodov", "Dmitrii", "", "1 and 2"], ["Ulanov", "A. E.", "", "1 and 2"], ["Foerster", "Jakob N.", "", "1 and 2"], ["Whiteson", "Shimon", "", "1 and 2"], ["Lvovsky", "A. I.", "", "1 and 2"]]}, {"id": "2002.04679", "submitter": "Marc Pfetsch", "authors": "Marc E. Pfetsch and Sebastian Pokutta", "title": "IPBoost -- Non-Convex Boosting via Integer Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently non-convex optimization approaches for solving machine learning\nproblems have gained significant attention. In this paper we explore non-convex\nboosting in classification by means of integer programming and demonstrate\nreal-world practicability of the approach while circumventing shortcomings of\nconvex boosting approaches. We report results that are comparable to or better\nthan the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:00:03 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pfetsch", "Marc E.", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2002.04683", "submitter": "Turab Iqbal", "authors": "Turab Iqbal, Yin Cao, Qiuqiang Kong, Mark D. Plumbley, Wenwu Wang", "title": "Learning with Out-of-Distribution Data for Audio Classification", "comments": "Paper accepted for 45th International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised machine learning, the assumption that training data is labelled\ncorrectly is not always satisfied. In this paper, we investigate an instance of\nlabelling error for classification tasks in which the dataset is corrupted with\nout-of-distribution (OOD) instances: data that does not belong to any of the\ntarget classes, but is labelled as such. We show that detecting and relabelling\ncertain OOD instances, rather than discarding them, can have a positive effect\non learning. The proposed method uses an auxiliary classifier, trained on data\nthat is known to be in-distribution, for detection and relabelling. The amount\nof data required for this is shown to be small. Experiments are carried out on\nthe FSDnoisy18k audio dataset, where OOD instances are very prevalent. The\nproposed method is shown to improve the performance of convolutional neural\nnetworks by a significant margin. Comparisons with other noise-robust\ntechniques are similarly encouraging.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:08:06 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Iqbal", "Turab", ""], ["Cao", "Yin", ""], ["Kong", "Qiuqiang", ""], ["Plumbley", "Mark D.", ""], ["Wang", "Wenwu", ""]]}, {"id": "2002.04687", "submitter": "Paul Norridge", "authors": "Paul Norridge", "title": "Think Global, Act Local: Relating DNN generalisation and node-level SNR", "comments": "15 pages, 5 figures; for associated colab files see\n  http://github.com/pnorridge/think-global-act-local/settings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The reasons behind good DNN generalisation remain an open question. In this\npaper we explore the problem by looking at the Signal-to-Noise Ratio of nodes\nin the network. Starting from information theory principles, it is possible to\nderive an expression for the SNR of a DNN node output. Using this expression we\nconstruct figures-of-merit that quantify how well the weights of a node\noptimise SNR (or, equivalently, information rate). Applying these\nfigures-of-merit, we give examples indicating that weight sets that promote\ngood SNR performance also exhibit good generalisation. In addition, we are able\nto identify the qualities of weight sets that exhibit good SNR behaviour and\nhence promote good generalisation. This leads to a discussion of how these\nresults relate to network training and regularisation. Finally, we identify\nsome ways that these observations can be used in training design.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:16:37 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Norridge", "Paul", ""]]}, {"id": "2002.04688", "submitter": "Jeremy Howard", "authors": "Jeremy Howard and Sylvain Gugger", "title": "fastai: A Layered API for Deep Learning", "comments": null, "journal-ref": "Information 2020, 11(2), 108", "doi": "10.3390/info11020108", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  fastai is a deep learning library which provides practitioners with\nhigh-level components that can quickly and easily provide state-of-the-art\nresults in standard deep learning domains, and provides researchers with\nlow-level components that can be mixed and matched to build new approaches. It\naims to do both things without substantial compromises in ease of use,\nflexibility, or performance. This is possible thanks to a carefully layered\narchitecture, which expresses common underlying patterns of many deep learning\nand data processing techniques in terms of decoupled abstractions. These\nabstractions can be expressed concisely and clearly by leveraging the dynamism\nof the underlying Python language and the flexibility of the PyTorch library.\nfastai includes: a new type dispatch system for Python along with a semantic\ntype hierarchy for tensors; a GPU-optimized computer vision library which can\nbe extended in pure Python; an optimizer which refactors out the common\nfunctionality of modern optimizers into two basic pieces, allowing optimization\nalgorithms to be implemented in 4-5 lines of code; a novel 2-way callback\nsystem that can access any part of the data, model, or optimizer and change it\nat any point during training; a new data block API; and much more. We have used\nthis library to successfully create a complete deep learning course, which we\nwere able to write more quickly than using previous approaches, and the code\nwas more clear. The library is already in wide use in research, industry, and\nteaching. NB: This paper covers fastai v2, which is currently in pre-release at\nhttp://dev.fast.ai/\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:16:48 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 18:17:51 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Howard", "Jeremy", ""], ["Gugger", "Sylvain", ""]]}, {"id": "2002.04692", "submitter": "Kartik Ahuja", "authors": "Kartik Ahuja, Karthikeyan Shanmugam, Kush R. Varshney, Amit Dhurandhar", "title": "Invariant Risk Minimization Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard risk minimization paradigm of machine learning is brittle when\noperating in environments whose test distributions are different from the\ntraining distribution due to spurious correlations. Training on data from many\nenvironments and finding invariant predictors reduces the effect of spurious\nfeatures by concentrating models on features that have a causal relationship\nwith the outcome. In this work, we pose such invariant risk minimization as\nfinding the Nash equilibrium of an ensemble game among several environments. By\ndoing so, we develop a simple training algorithm that uses best response\ndynamics and, in our experiments, yields similar or better empirical accuracy\nwith much lower variance than the challenging bi-level optimization problem of\nArjovsky et al. (2019). One key theoretical contribution is showing that the\nset of Nash equilibria for the proposed game are equivalent to the set of\ninvariant predictors for any finite number of environments, even with nonlinear\nclassifiers and transformations. As a result, our method also retains the\ngeneralization guarantees to a large set of environments shown in Arjovsky et\nal. (2019). The proposed algorithm adds to the collection of successful\ngame-theoretic machine learning algorithms such as generative adversarial\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:25:14 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 21:18:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Ahuja", "Kartik", ""], ["Shanmugam", "Karthikeyan", ""], ["Varshney", "Kush R.", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2002.04694", "submitter": "Pavol Bielik", "authors": "Pavol Bielik and Martin Vechev", "title": "Adversarial Robustness for Code", "comments": "Proceedings of the 37th International Conference on Machine Learning,\n  Online, PMLR 119, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning in particular has been recently used to\nsuccessfully address many tasks in the domain of code such as finding and\nfixing bugs, code completion, decompilation, type inference and many others.\nHowever, the issue of adversarial robustness of models for code has gone\nlargely unnoticed. In this work, we explore this issue by: (i) instantiating\nadversarial attacks for code (a domain with discrete and highly structured\ninputs), (ii) showing that, similar to other domains, neural models for code\nare vulnerable to adversarial attacks, and (iii) combining existing and novel\ntechniques to improve robustness while preserving high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:32:14 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 12:35:28 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bielik", "Pavol", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.04700", "submitter": "Ziyang Wang", "authors": "Ziyang Wang", "title": "A Single RGB Camera Based Gait Analysis with a Mobile Tele-Robot for\n  Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing awareness of high-quality life, there is a growing need\nfor health monitoring devices running robust algorithms in home environment.\nHealth monitoring technologies enable real-time analysis of users' health\nstatus, offering long-term healthcare support and reducing hospitalization\ntime. The purpose of this work is twofold, the software focuses on the analysis\nof gait, which is widely adopted for joint correction and assessing any lower\nlimb or spinal problem. On the hardware side, we design a novel marker-less\ngait analysis device using a low-cost RGB camera mounted on a mobile\ntele-robot. As gait analysis with a single camera is much more challenging\ncompared to previous works utilizing multi-cameras, a RGB-D camera or wearable\nsensors, we propose using vision-based human pose estimation approaches. More\nspecifically, based on the output of two state-of-the-art human pose estimation\nmodels (Openpose and VNect), we devise measurements for four bespoke gait\nparameters: inversion/eversion, dorsiflexion/plantarflexion, ankle and foot\nprogression angles. We thereby classify walking patterns into normal,\nsupination, pronation and limp. We also illustrate how to run the purposed\nmachine learning models in low-resource environments such as a single\nentry-level CPU. Experiments show that our single RGB camera method achieves\ncompetitive performance compared to state-of-the-art methods based on depth\ncameras or multi-camera motion capture system, at smaller hardware costs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:42:22 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 16:24:28 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 14:53:55 GMT"}, {"version": "v4", "created": "Sun, 15 Mar 2020 03:27:52 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wang", "Ziyang", ""]]}, {"id": "2002.04704", "submitter": "Robert Hu", "authors": "Robert Hu, Geoff K. Nicholls, Dino Sejdinovic", "title": "Large Scale Tensor Regression using Kernels and Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We outline an inherent weakness of tensor factorization models when latent\nfactors are expressed as a function of side information and propose a novel\nmethod to mitigate this weakness. We coin our method \\textit{Kernel Fried\nTensor}(KFT) and present it as a large scale forecasting tool for high\ndimensional data. Our results show superior performance against\n\\textit{LightGBM} and \\textit{Field Aware Factorization Machines}(FFM), two\nalgorithms with proven track records widely used in industrial forecasting. We\nalso develop a variational inference framework for KFT and associate our\nforecasts with calibrated uncertainty estimates on three large scale datasets.\nFurthermore, KFT is empirically shown to be robust against uninformative side\ninformation in terms of constants and Gaussian noise.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:46:52 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hu", "Robert", ""], ["Nicholls", "Geoff K.", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2002.04709", "submitter": "Se Young Chun", "authors": "Kwanyoung Kim, Dongwon Park, Kwang In Kim, Se Young Chun", "title": "Task-Aware Variational Adversarial Active Learning", "comments": "14 pages, 13 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often, labeling large amount of data is challenging due to high labeling cost\nlimiting the application domain of deep learning techniques. Active learning\n(AL) tackles this by querying the most informative samples to be annotated\namong unlabeled pool. Two promising directions for AL that have been recently\nexplored are task-agnostic approach to select data points that are far from the\ncurrent labeled pool and task-aware approach that relies on the perspective of\ntask model. Unfortunately, the former does not exploit structures from tasks\nand the latter does not seem to well-utilize overall data distribution. Here,\nwe propose task-aware variational adversarial AL (TA-VAAL) that modifies\ntask-agnostic VAAL, that considered data distribution of both label and\nunlabeled pools, by relaxing task learning loss prediction to ranking loss\nprediction and by using ranking conditional generative adversarial network to\nembed normalized ranking loss information on VAAL. Our proposed TA-VAAL\noutperforms state-of-the-arts on various benchmark datasets for classifications\nwith balanced / imbalanced labels as well as semantic segmentation and its\ntask-aware and task-agnostic AL properties were confirmed with our in-depth\nanalyses.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:00:48 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 05:36:08 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Kim", "Kwanyoung", ""], ["Park", "Dongwon", ""], ["Kim", "Kwang In", ""], ["Chun", "Se Young", ""]]}, {"id": "2002.04710", "submitter": "Rotem Mulayoff", "authors": "Rotem Mulayoff, Tomer Michaeli", "title": "Unique Properties of Flat Minima in Deep Networks", "comments": "Presented at ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that (stochastic) gradient descent has an implicit bias\ntowards flat minima. In deep neural network training, this mechanism serves to\nscreen out minima. However, the precise effect that this has on the trained\nnetwork is not yet fully understood. In this paper, we characterize the flat\nminima in linear neural networks trained with a quadratic loss. First, we show\nthat linear ResNets with zero initialization necessarily converge to the\nflattest of all minima. We then prove that these minima correspond to nearly\nbalanced networks whereby the gain from the input to any intermediate\nrepresentation does not change drastically from one layer to the next. Finally,\nwe show that consecutive layers in flat minima solutions are coupled. That is,\none of the left singular vectors of each weight matrix, equals one of the right\nsingular vectors of the next matrix. This forms a distinct path from input to\noutput, that, as we show, is dedicated to the signal that experiences the\nlargest gain end-to-end. Experiments indicate that these properties are\ncharacteristic of both linear and nonlinear models trained in practice.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:01:19 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 22:13:17 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mulayoff", "Rotem", ""], ["Michaeli", "Tomer", ""]]}, {"id": "2002.04720", "submitter": "Kevin Yang", "authors": "Kevin Yang, Wengong Jin, Kyle Swanson, Regina Barzilay, Tommi Jaakkola", "title": "Improving Molecular Design by Stochastic Iterative Target Augmentation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models in molecular design tend to be richly parameterized,\ndata-hungry neural models, as they must create complex structured objects as\noutputs. Estimating such models from data may be challenging due to the lack of\nsufficient training data. In this paper, we propose a surprisingly effective\nself-training approach for iteratively creating additional molecular targets.\nWe first pre-train the generative model together with a simple property\npredictor. The property predictor is then used as a likelihood model for\nfiltering candidate structures from the generative model. Additional targets\nare iteratively produced and used in the course of stochastic EM iterations to\nmaximize the log-likelihood that the candidate structures are accepted. A\nsimple rejection (re-weighting) sampler suffices to draw posterior samples\nsince the generative model is already reasonable after pre-training. We\ndemonstrate significant gains over strong baselines for both unconditional and\nconditional molecular design. In particular, our approach outperforms the\nprevious state-of-the-art in conditional molecular design by over 10% in\nabsolute gain. Finally, we show that our approach is useful in other domains as\nwell, such as program synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:40:04 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 21:00:24 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Yang", "Kevin", ""], ["Jin", "Wengong", ""], ["Swanson", "Kyle", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.04723", "submitter": "Li Zhang", "authors": "John Anderson, Qingqing Huang, Walid Krichene, Steffen Rendle, Li\n  Zhang", "title": "Superbloom: Bloom filter meets Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the idea of word pieces in natural language models to machine\nlearning tasks on opaque ids. This is achieved by applying hash functions to\nmap each id to multiple hash tokens in a much smaller space, similarly to a\nBloom filter. We show that by applying a multi-layer Transformer to these Bloom\nfilter digests, we are able to obtain models with high accuracy. They\noutperform models of a similar size without hashing and, to a large degree,\nmodels of a much larger size trained using sampled softmax with the same\ncomputational budget. Our key observation is that it is important to use a\nmulti-layer Transformer for Bloom filter digests to remove ambiguity in the\nhashed input. We believe this provides an alternative method to solving\nproblems with large vocabulary size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:52:40 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Anderson", "John", ""], ["Huang", "Qingqing", ""], ["Krichene", "Walid", ""], ["Rendle", "Steffen", ""], ["Zhang", "Li", ""]]}, {"id": "2002.04724", "submitter": "Zhengli Zhao", "authors": "Zhengli Zhao, Sameer Singh, Honglak Lee, Zizhao Zhang, Augustus Odena,\n  Han Zhang", "title": "Improved Consistency Regularization for GANs", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has increased the performance of Generative Adversarial Networks\n(GANs) by enforcing a consistency cost on the discriminator. We improve on this\ntechnique in several ways. We first show that consistency regularization can\nintroduce artifacts into the GAN samples and explain how to fix this issue. We\nthen propose several modifications to the consistency regularization procedure\ndesigned to improve its performance. We carry out extensive experiments\nquantifying the benefit of our improvements. For unconditional image synthesis\non CIFAR-10 and CelebA, our modifications yield the best known FID scores on\nvarious GAN architectures. For conditional image synthesis on CIFAR-10, we\nimprove the state-of-the-art FID score from 11.48 to 9.21. Finally, on\nImageNet-2012, we apply our technique to the original BigGAN model and improve\nthe FID from 6.66 to 5.38, which is the best score at that model size.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 22:53:21 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 21:33:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhao", "Zhengli", ""], ["Singh", "Sameer", ""], ["Lee", "Honglak", ""], ["Zhang", "Zizhao", ""], ["Odena", "Augustus", ""], ["Zhang", "Han", ""]]}, {"id": "2002.04725", "submitter": "Lin Chen", "authors": "Lin Chen, Yifei Min, Mingrui Zhang, Amin Karbasi", "title": "More Data Can Expand the Generalization Gap Between Adversarially Robust\n  and Standard Models", "comments": "Accepted to ICML'20. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable success in practice, modern machine learning models have\nbeen found to be susceptible to adversarial attacks that make\nhuman-imperceptible perturbations to the data, but result in serious and\npotentially dangerous prediction errors. To address this issue, practitioners\noften use adversarial training to learn models that are robust against such\nattacks at the cost of higher generalization error on unperturbed test sets.\nThe conventional wisdom is that more training data should shrink the gap\nbetween the generalization error of adversarially-trained models and standard\nmodels. However, we study the training of robust classifiers for both Gaussian\nand Bernoulli models under $\\ell_\\infty$ attacks, and we prove that more data\nmay actually increase this gap. Furthermore, our theoretical results identify\nif and when additional data will finally begin to shrink the gap. Lastly, we\nexperimentally demonstrate that our results also hold for linear regression\nmodels, which may indicate that this phenomenon occurs more broadly.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:01:29 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:55:55 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 23:36:51 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Chen", "Lin", ""], ["Min", "Yifei", ""], ["Zhang", "Mingrui", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.04726", "submitter": "Manish Purohit", "authors": "Aditya Bhaskara, Ashok Cutkosky, Ravi Kumar and Manish Purohit", "title": "Online Learning with Imperfect Hints", "comments": "appeared in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the classical online linear optimization problem in\nwhich at every step, the online player receives a \"hint\" vector before choosing\nthe action for that round. Rather surprisingly, it was shown that if the hint\nvector is guaranteed to have a positive correlation with the cost vector, then\nthe online player can achieve a regret of $O(\\log T)$, thus significantly\nimproving over the $O(\\sqrt{T})$ regret in the general setting. However, the\nresult and analysis require the correlation property at \\emph{all} time steps,\nthus raising the natural question: can we design online learning algorithms\nthat are resilient to bad hints?\n  In this paper we develop algorithms and nearly matching lower bounds for\nonline learning with imperfect directional hints. Our algorithms are oblivious\nto the quality of the hints, and the regret bounds interpolate between the\nalways-correlated hints case and the no-hints case. Our results also\ngeneralize, simplify, and improve upon previous results on optimistic regret\nbounds, which can be viewed as an additive version of hints.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:06:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 17:28:35 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Bhaskara", "Aditya", ""], ["Cutkosky", "Ashok", ""], ["Kumar", "Ravi", ""], ["Purohit", "Manish", ""]]}, {"id": "2002.04742", "submitter": "Klas Leino", "authors": "Aymeric Fromherz, Klas Leino, Matt Fredrikson, Bryan Parno, Corina\n  P\\u{a}s\\u{a}reanu", "title": "Fast Geometric Projections for Local Robustness Certification", "comments": "Appearing in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local robustness ensures that a model classifies all inputs within an\n$\\ell_2$-ball consistently, which precludes various forms of adversarial\ninputs. In this paper, we present a fast procedure for checking local\nrobustness in feed-forward neural networks with piecewise-linear activation\nfunctions. Such networks partition the input space into a set of convex\npolyhedral regions in which the network's behavior is linear; hence, a\nsystematic search for decision boundaries within the regions around a given\ninput is sufficient for assessing robustness. Crucially, we show how the\nregions around a point can be analyzed using simple geometric projections, thus\nadmitting an efficient, highly-parallel GPU implementation that excels\nparticularly for the $\\ell_2$ norm, where previous work has been less\neffective. Empirically we find this approach to be far more precise than many\napproximate verification approaches, while at the same time performing multiple\norders of magnitude faster than complete verifiers, and scaling to much deeper\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:21:55 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 03:20:39 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 18:42:52 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Fromherz", "Aymeric", ""], ["Leino", "Klas", ""], ["Fredrikson", "Matt", ""], ["Parno", "Bryan", ""], ["P\u0103s\u0103reanu", "Corina", ""]]}, {"id": "2002.04745", "submitter": "Di He", "authors": "Ruibin Xiong, Yunchang Yang, Di He, Kai Zheng, Shuxin Zheng, Chen\n  Xing, Huishuai Zhang, Yanyan Lan, Liwei Wang, Tie-Yan Liu", "title": "On Layer Normalization in the Transformer Architecture", "comments": null, "journal-ref": "Published on ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Transformer is widely used in natural language processing tasks. To train\na Transformer however, one usually needs a carefully designed learning rate\nwarm-up stage, which is shown to be crucial to the final performance but will\nslow down the optimization and bring more hyper-parameter tunings. In this\npaper, we first study theoretically why the learning rate warm-up stage is\nessential and show that the location of layer normalization matters.\nSpecifically, we prove with mean field theory that at initialization, for the\noriginal-designed Post-LN Transformer, which places the layer normalization\nbetween the residual blocks, the expected gradients of the parameters near the\noutput layer are large. Therefore, using a large learning rate on those\ngradients makes the training unstable. The warm-up stage is practically helpful\nfor avoiding this problem. On the other hand, our theory also shows that if the\nlayer normalization is put inside the residual blocks (recently proposed as\nPre-LN Transformer), the gradients are well-behaved at initialization. This\nmotivates us to remove the warm-up stage for the training of Pre-LN\nTransformers. We show in our experiments that Pre-LN Transformers without the\nwarm-up stage can reach comparable results with baselines while requiring\nsignificantly less training time and hyper-parameter tuning on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:33:03 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 07:55:12 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Ruibin", ""], ["Yang", "Yunchang", ""], ["He", "Di", ""], ["Zheng", "Kai", ""], ["Zheng", "Shuxin", ""], ["Xing", "Chen", ""], ["Zhang", "Huishuai", ""], ["Lan", "Yanyan", ""], ["Wang", "Liwei", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.04747", "submitter": "Samory Kpotufe", "authors": "Steve Hanneke and Samory Kpotufe", "title": "On the Value of Target Data in Transfer Learning", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to understand the value of additional labeled or unlabeled target data\nin transfer learning, for any given amount of source data; this is motivated by\npractical questions around minimizing sampling costs, whereby, target data is\nusually harder or costlier to acquire than source data, but can yield better\naccuracy. To this aim, we establish the first minimax-rates in terms of both\nsource and target sample sizes, and show that performance limits are captured\nby new notions of discrepancy between source and target, which we refer to as\ntransfer exponents.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:37:18 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hanneke", "Steve", ""], ["Kpotufe", "Samory", ""]]}, {"id": "2002.04752", "submitter": "Rachel Draelos", "authors": "Rachel Lea Draelos, David Dov, Maciej A. Mazurowski, Joseph Y. Lo,\n  Ricardo Henao, Geoffrey D. Rubin, Lawrence Carin", "title": "Machine-Learning-Based Multiple Abnormality Prediction with Large-Scale\n  Chest Computed Tomography Volumes", "comments": "20 pages, 3 figures, 5 tables (appendices additional). Published in\n  Medical Image Analysis (October 2020)", "journal-ref": null, "doi": "10.1016/j.media.2020.101857", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models for radiology benefit from large-scale data sets with\nhigh quality labels for abnormalities. We curated and analyzed a chest computed\ntomography (CT) data set of 36,316 volumes from 19,993 unique patients. This is\nthe largest multiply-annotated volumetric medical imaging data set reported. To\nannotate this data set, we developed a rule-based method for automatically\nextracting abnormality labels from free-text radiology reports with an average\nF-score of 0.976 (min 0.941, max 1.0). We also developed a model for\nmulti-organ, multi-disease classification of chest CT volumes that uses a deep\nconvolutional neural network (CNN). This model reached a classification\nperformance of AUROC greater than 0.90 for 18 abnormalities, with an average\nAUROC of 0.773 for all 83 abnormalities, demonstrating the feasibility of\nlearning from unfiltered whole volume CT data. We show that training on more\nlabels improves performance significantly: for a subset of 9 labels - nodule,\nopacity, atelectasis, pleural effusion, consolidation, mass, pericardial\neffusion, cardiomegaly, and pneumothorax - the model's average AUROC increased\nby 10% when the number of training labels was increased from 9 to all 83. All\ncode for volume preprocessing, automated label extraction, and the volume\nabnormality prediction model will be made publicly available. The 36,316 CT\nvolumes and labels will also be made publicly available pending institutional\napproval.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 00:59:23 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:39:03 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 23:57:17 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Draelos", "Rachel Lea", ""], ["Dov", "David", ""], ["Mazurowski", "Maciej A.", ""], ["Lo", "Joseph Y.", ""], ["Henao", "Ricardo", ""], ["Rubin", "Geoffrey D.", ""], ["Carin", "Lawrence", ""]]}, {"id": "2002.04753", "submitter": "Ting-Jui Chang", "authors": "Ting-Jui Chang, Shahin Shahrampour", "title": "RFN: A Random-Feature Based Newton Method for Empirical Risk\n  Minimization in Reproducing Kernel Hilbert Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In supervised learning using kernel methods, we encounter a large-scale\nfinite-sum minimization over a reproducing kernel Hilbert space (RKHS). Often\ntimes large-scale finite-sum problems can be solved using efficient variants of\nNewton's method where the Hessian is approximated via sub-samples. In RKHS,\nhowever, the dependence of the penalty function to kernel makes standard\nsub-sampling approaches inapplicable, since the gram matrix is not readily\navailable in a low-rank form. In this paper, we observe that for this class of\nproblems, one can naturally use kernel approximation to speed up the Newton's\nmethod. Focusing on randomized features for kernel approximation, we provide a\nnovel second-order algorithm that enjoys local superlinear convergence and\nglobal convergence in the high probability sense. The key to our analysis is\nshowing that the approximated Hessian via random features preserves the\nspectrum of the original Hessian. We provide numerical experiments verifying\nthe efficiency of our approach, compared to variants of sub-sampling methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:14:44 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 03:04:44 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 22:03:46 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Chang", "Ting-Jui", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.04756", "submitter": "Fabian Pedregosa", "authors": "Fabian Pedregosa, Damien Scieur", "title": "Average-case Acceleration Through Spectral Density Estimation", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a framework for the average-case analysis of random quadratic\nproblems and derive algorithms that are optimal under this analysis. This\nyields a new class of methods that achieve acceleration given a model of the\nHessian's eigenvalue distribution. We develop explicit algorithms for the\nuniform, Marchenko-Pastur, and exponential distributions. These methods are\nmomentum-based algorithms, whose hyper-parameters can be estimated without\nknowledge of the Hessian's smallest singular value, in contrast with classical\naccelerated methods like Nesterov acceleration and Polyak momentum. Through\nempirical benchmarks on quadratic and logistic regression problems, we identify\nregimes in which the the proposed methods improve over classical (worst-case)\naccelerated methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:44:26 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 16:06:21 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2020 14:51:46 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 16:36:42 GMT"}, {"version": "v5", "created": "Wed, 19 Aug 2020 18:23:53 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Pedregosa", "Fabian", ""], ["Scieur", "Damien", ""]]}, {"id": "2002.04758", "submitter": "Tao Yu", "authors": "Tao Yu, Eugene Bagdasaryan, Vitaly Shmatikov", "title": "Salvaging Federated Learning by Local Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a heavily promoted approach for training ML models\non sensitive data, e.g., text typed by users on their smartphones. FL is\nexpressly designed for training on data that are unbalanced and non-iid across\nthe participants. To ensure privacy and integrity of the federated model,\nlatest FL approaches use differential privacy or robust aggregation to limit\nthe influence of \"outlier\" participants.\n  First, we show that on standard tasks such as next-word prediction, many\nparticipants gain no benefit from FL because the federated model is less\naccurate on their data than the models they can train locally on their own.\nSecond, we show that differential privacy and robust aggregation make this\nproblem worse by further destroying the accuracy of the federated model for\nmany participants.\n  Then, we evaluate three techniques for local adaptation of federated models:\nfine-tuning, multi-task learning, and knowledge distillation. We analyze where\neach technique is applicable and demonstrate that all participants benefit from\nlocal adaptation. Participants whose local models are poor obtain big accuracy\nimprovements over conventional FL. Participants whose local models are better\nthan the federated model and who have no incentive to participate in FL today\nimprove less, but sufficiently to make the adapted federated model better than\ntheir local models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:56:16 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Yu", "Tao", ""], ["Bagdasaryan", "Eugene", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "2002.04759", "submitter": "Chi Zhang", "authors": "Chi Zhang, Yong Sheng Soh, Ling Feng, Tianyi Zhou, Qianxiao Li", "title": "Collaborative Inference for Efficient Remote Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While current machine learning models have impressive performance over a wide\nrange of applications, their large size and complexity render them unsuitable\nfor tasks such as remote monitoring on edge devices with limited storage and\ncomputational power. A naive approach to resolve this on the model level is to\nuse simpler architectures, but this sacrifices prediction accuracy and is\nunsuitable for monitoring applications requiring accurate detection of the\nonset of adverse events. In this paper, we propose an alternative solution to\nthis problem by decomposing the predictive model as the sum of a simple\nfunction which serves as a local monitoring tool, and a complex correction term\nto be evaluated on the server. A sign requirement is imposed on the latter to\nensure that the local monitoring function is safe, in the sense that it can\neffectively serve as an early warning system. Our analysis quantifies the\ntrade-offs between model complexity and performance, and serves as a guidance\nfor architecture design. We validate our proposed framework on a series of\nmonitoring experiments, where we succeed at learning monitoring models with\nsignificantly reduced complexity that minimally violate the safety requirement.\nMore broadly, our framework is useful for learning classifiers in applications\nwhere false negatives are significantly more costly compared to false\npositives.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:57:17 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhang", "Chi", ""], ["Soh", "Yong Sheng", ""], ["Feng", "Ling", ""], ["Zhou", "Tianyi", ""], ["Li", "Qianxiao", ""]]}, {"id": "2002.04760", "submitter": "Michele Tufano", "authors": "Michele Tufano, Jason Kimko, Shiya Wang, Cody Watson, Gabriele Bavota,\n  Massimiliano Di Penta, Denys Poshyvanyk", "title": "DeepMutation: A Neural Mutation Tool", "comments": "Accepted to the 42nd ACM/IEEE International Conference on Software\n  Engineering (ICSE 2020), Demonstrations Track - Seoul, South Korea, May\n  23-29, 2020, 4 pages", "journal-ref": null, "doi": "10.1145/3377812.3382146", "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutation testing can be used to assess the fault-detection capabilities of a\ngiven test suite. To this aim, two characteristics of mutation testing\nframeworks are of paramount importance: (i) they should generate mutants that\nare representative of real faults; and (ii) they should provide a complete tool\nchain able to automatically generate, inject, and test the mutants. To address\nthe first point, we recently proposed an approach using a Recurrent Neural\nNetwork Encoder-Decoder architecture to learn mutants from ~787k faults mined\nfrom real programs. The empirical evaluation of this approach confirmed its\nability to generate mutants representative of real faults. In this paper, we\naddress the second point, presenting DeepMutation, a tool wrapping our deep\nlearning model into a fully automated tool chain able to generate, inject, and\ntest mutants learned from real faults. Video:\nhttps://sites.google.com/view/learning-mutation/deepmutation\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:57:41 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 01:32:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tufano", "Michele", ""], ["Kimko", "Jason", ""], ["Wang", "Shiya", ""], ["Watson", "Cody", ""], ["Bavota", "Gabriele", ""], ["Di Penta", "Massimiliano", ""], ["Poshyvanyk", "Denys", ""]]}, {"id": "2002.04763", "submitter": "Bo Liu", "authors": "Bo Liu", "title": "Understanding Global Loss Landscape of One-hidden-layer ReLU Networks,\n  Part 1: Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For one-hidden-layer ReLU networks, we prove that all differentiable local\nminima are global inside differentiable regions. We give the locations and\nlosses of differentiable local minima, and show that these local minima can be\nisolated points or continuous hyperplanes, depending on an interplay between\ndata, activation pattern of hidden neurons and network size. Furthermore, we\ngive necessary and sufficient conditions for the existence of saddle points as\nwell as non-differentiable local minima, and their locations if they exist.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:04:55 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 01:57:24 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Liu", "Bo", ""]]}, {"id": "2002.04764", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai, Nitish Srivastava, Hanlin Goh, Ruslan\n  Salakhutdinov", "title": "Capsules with Inverted Dot-Product Attention Routing", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new routing algorithm for capsule networks, in which a child\ncapsule is routed to a parent based only on agreement between the parent's\nstate and the child's vote. The new mechanism 1) designs routing via inverted\ndot-product attention; 2) imposes Layer Normalization as normalization; and 3)\nreplaces sequential iterative routing with concurrent iterative routing. When\ncompared to previously proposed routing algorithms, our method improves\nperformance on benchmark datasets such as CIFAR-10 and CIFAR-100, and it\nperforms at-par with a powerful CNN (ResNet-18) with 4x fewer parameters. On a\ndifferent task of recognizing digits from overlayed digit images, the proposed\ncapsule model performs favorably against CNNs given the same number of layers\nand neurons per layer. We believe that our work raises the possibility of\napplying capsule networks to complex real-world tasks. Our code is publicly\navailable at: https://github.com/apple/ml-capsules-inverted-attention-routing\nAn alternative implementation is available at:\nhttps://github.com/yaohungt/Capsules-Inverted-Attention-Routing/blob/master/README.md\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:09:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:48:16 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Srivastava", "Nitish", ""], ["Goh", "Hanlin", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2002.04766", "submitter": "Liam Collins", "authors": "Liam Collins, Aryan Mokhtari, Sanjay Shakkottai", "title": "Task-Robust Model-Agnostic Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning methods have shown an impressive ability to train models that\nrapidly learn new tasks. However, these methods only aim to perform well in\nexpectation over tasks coming from some particular distribution that is\ntypically equivalent across meta-training and meta-testing, rather than\nconsidering worst-case task performance. In this work we introduce the notion\nof \"task-robustness\" by reformulating the popular Model-Agnostic Meta-Learning\n(MAML) objective [Finn et al. 2017] such that the goal is to minimize the\nmaximum loss over the observed meta-training tasks. The solution to this novel\nformulation is task-robust in the sense that it places equal importance on even\nthe most difficult and/or rare tasks. This also means that it performs well\nover all distributions of the observed tasks, making it robust to shifts in the\ntask distribution between meta-training and meta-testing. We present an\nalgorithm to solve the proposed min-max problem, and show that it converges to\nan $\\epsilon$-accurate point at the optimal rate of $\\mathcal{O}(1/\\epsilon^2)$\nin the convex setting and to an $(\\epsilon, \\delta)$-stationary point at the\nrate of $\\mathcal{O}(\\max\\{1/\\epsilon^5, 1/\\delta^5\\})$ in nonconvex settings.\nWe also provide an upper bound on the new task generalization error that\ncaptures the advantage of minimizing the worst-case task loss, and demonstrate\nthis advantage in sinusoid regression and image classification experiments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:20:51 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 03:06:25 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Collins", "Liam", ""], ["Mokhtari", "Aryan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2002.04770", "submitter": "Hugh Chen", "authors": "Hugh Chen, Scott Lundberg, Gabe Erion, Jerry H. Kim, Su-In Lee", "title": "Forecasting adverse surgical events using self-supervised transfer\n  learning for physiological signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hundreds of millions of surgical procedures take place annually across the\nworld, which generate a prevalent type of electronic health record (EHR) data\ncomprising time series physiological signals. Here, we present a transferable\nembedding method (i.e., a method to transform time series signals into input\nfeatures for predictive machine learning models) named PHASE (PHysiologicAl\nSignal Embeddings) that enables us to more accurately forecast adverse surgical\noutcomes based on physiological signals. We evaluate PHASE on minute-by-minute\nEHR data of more than 50,000 surgeries from two operating room (OR) datasets\nand patient stays in an intensive care unit (ICU) dataset. PHASE outperforms\nother state-of-the-art approaches, such as long-short term memory networks\ntrained on raw data and gradient boosted trees trained on handcrafted features,\nin predicting five distinct outcomes: hypoxemia, hypocapnia, hypotension,\nhypertension, and phenylephrine administration. In a transfer learning setting\nwhere we train embedding models in one dataset then embed signals and predict\nadverse events in unseen data, PHASE achieves significantly higher prediction\naccuracy at lower computational cost compared to conventional approaches.\nFinally, given the importance of understanding models in clinical applications\nwe demonstrate that PHASE is explainable and validate our predictive models\nusing local feature attribution methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 02:49:15 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 21:27:17 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Chen", "Hugh", ""], ["Lundberg", "Scott", ""], ["Erion", "Gabe", ""], ["Kim", "Jerry H.", ""], ["Lee", "Su-In", ""]]}, {"id": "2002.04776", "submitter": "Mohammad Saeed Abrishami", "authors": "Mohammad Saeed Abrishami, Amir Erfan Eshratifar, David Eigen, Yanzhi\n  Wang, Shahin Nazarian, Massoud Pedram", "title": "Efficient Training of Deep Convolutional Neural Networks by Augmentation\n  in Embedding Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the field of artificial intelligence have been made\npossible by deep neural networks. In applications where data are scarce,\ntransfer learning and data augmentation techniques are commonly used to improve\nthe generalization of deep learning models. However, fine-tuning a transfer\nmodel with data augmentation in the raw input space has a high computational\ncost to run the full network for every augmented input. This is particularly\ncritical when large models are implemented on embedded devices with limited\ncomputational and energy resources. In this work, we propose a method that\nreplaces the augmentation in the raw input space with an approximate one that\nacts purely in the embedding space. Our experimental results show that the\nproposed method drastically reduces the computation, while the accuracy of\nmodels is negligibly compromised.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:26:33 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Abrishami", "Mohammad Saeed", ""], ["Eshratifar", "Amir Erfan", ""], ["Eigen", "David", ""], ["Wang", "Yanzhi", ""], ["Nazarian", "Shahin", ""], ["Pedram", "Massoud", ""]]}, {"id": "2002.04784", "submitter": "Jie Chen", "authors": "Xiao Zang, Yi Xie, Jie Chen, Bo Yuan", "title": "Graph Universal Adversarial Attacks: A Few Bad Actors Ruin Graph\n  Learning Models", "comments": "IJCAI 2021. Code is available at\n  https://github.com/chisam0217/Graph-Universal-Attack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, while generalize well, are known to be sensitive to\nsmall adversarial perturbations. This phenomenon poses severe security threat\nand calls for in-depth investigation of the robustness of deep learning models.\nWith the emergence of neural networks for graph structured data, similar\ninvestigations are urged to understand their robustness. It has been found that\nadversarially perturbing the graph structure and/or node features may result in\na significant degradation of the model performance. In this work, we show from\na different angle that such fragility similarly occurs if the graph contains a\nfew bad-actor nodes, which compromise a trained graph neural network through\nflipping the connections to any targeted victim. Worse, the bad actors found\nfor one graph model severely compromise other models as well. We call the bad\nactors ``anchor nodes'' and propose an algorithm, named GUA, to identify them.\nThorough empirical investigations suggest an interesting finding that the\nanchor nodes often belong to the same class; and they also corroborate the\nintuitive trade-off between the number of anchor nodes and the attack success\nrate. For the dataset Cora which contains 2708 nodes, as few as six anchor\nnodes will result in an attack success rate higher than 80\\% for GCN and other\nthree models.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 03:52:11 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 03:41:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zang", "Xiao", ""], ["Xie", "Yi", ""], ["Chen", "Jie", ""], ["Yuan", "Bo", ""]]}, {"id": "2002.04788", "submitter": "Hao Wang", "authors": "Hao Wang, Hsiang Hsu, Mario Diaz, Flavio P. Calmon", "title": "To Split or Not to Split: The Impact of Disparate Treatment in\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:05:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:13:28 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 21:05:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Hao", ""], ["Hsu", "Hsiang", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2002.04792", "submitter": "Yu Zhang", "authors": "Sicong Liang and Yu Zhang", "title": "A Simple General Approach to Balance Task Difficulty in Multi-Task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task learning, difficulty levels of different tasks are varying.\nThere are many works to handle this situation and we classify them into five\ncategories, including the direct sum approach, the weighted sum approach, the\nmaximum approach, the curriculum learning approach, and the multi-objective\noptimization approach. Those approaches have their own limitations, for\nexample, using manually designed rules to update task weights, non-smooth\nobjective function, and failing to incorporate other functions than training\nlosses. In this paper, to alleviate those limitations, we propose a Balanced\nMulti-Task Learning (BMTL) framework. Different from existing studies which\nrely on task weighting, the BMTL framework proposes to transform the training\nloss of each task to balance difficulty levels among tasks based on an\nintuitive idea that tasks with larger training losses will receive more\nattention during the optimization procedure. We analyze the transformation\nfunction and derive necessary conditions. The proposed BMTL framework is very\nsimple and it can be combined with most multi-task learning models. Empirical\nstudies show the state-of-the-art performance of the proposed BMTL framework.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:31:34 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Liang", "Sicong", ""], ["Zhang", "Yu", ""]]}, {"id": "2002.04799", "submitter": "Yu Zhang", "authors": "Yi Zhang, Yu Zhang, Wei Wang", "title": "Deep Multi-Task Learning via Generalized Tensor Trace Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trace norm is widely used in multi-task learning as it can discover\nlow-rank structures among tasks in terms of model parameters. Nowadays, with\nthe emerging of big datasets and the popularity of deep learning techniques,\ntensor trace norms have been used for deep multi-task models. However, existing\ntensor trace norms cannot discover all the low-rank structures and they require\nusers to manually determine the importance of their components. To solve those\ntwo issues together, in this paper, we propose a Generalized Tensor Trace Norm\n(GTTN). The GTTN is defined as a convex combination of matrix trace norms of\nall possible tensor flattenings and hence it can discover all the possible\nlow-rank structures. In the induced objective function, we will learn\ncombination coefficients in the GTTN to automatically determine the importance.\nExperiments on real-world datasets demonstrate the effectiveness of the\nproposed GTTN.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:06:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhang", "Yi", ""], ["Zhang", "Yu", ""], ["Wang", "Wei", ""]]}, {"id": "2002.04803", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka, Joshua Patterson, Corey Nolet", "title": "Machine Learning in Python: Main developments and technology trends in\n  data science, machine learning, and artificial intelligence", "comments": "Preprint of a manuscript accepted for publication in \"Machine\n  Learning with Python,\" a special issue of Information (ISSN 2078-2489)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smarter applications are making better use of the insights gleaned from data,\nhaving an impact on every industry and research discipline. At the core of this\nrevolution lies the tools and the methods that are driving it, from processing\nthe massive piles of data generated each day to learning from and taking useful\naction. Deep neural networks, along with advancements in classical ML and\nscalable general-purpose GPU computing, have become critical components of\nartificial intelligence, enabling many of these astounding breakthroughs and\nlowering the barrier to adoption. Python continues to be the most preferred\nlanguage for scientific computing, data science, and machine learning, boosting\nboth performance and productivity by enabling the use of low-level libraries\nand clean high-level APIs. This survey offers insight into the field of machine\nlearning with Python, taking a tour through important topics to identify some\nof the core hardware and software paradigms that have enabled it. We cover\nwidely-used libraries and concepts, collected together for holistic comparison,\nwith the goal of educating the reader and driving the field of Python machine\nlearning forward.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:20:59 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 16:58:28 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Raschka", "Sebastian", ""], ["Patterson", "Joshua", ""], ["Nolet", "Corey", ""]]}, {"id": "2002.04805", "submitter": "Christoph David Hofer PhD MSc", "authors": "Christoph D. Hofer, Florian Graf, Marc Niethammer, Roland Kwitt", "title": "Topologically Densified Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study regularization in the context of small sample-size learning with\nover-parameterized neural networks. Specifically, we shift focus from\narchitectural properties, such as norms on the network weights, to properties\nof the internal representations before a linear classifier. Specifically, we\nimpose a topological constraint on samples drawn from the probability measure\ninduced in that space. This provably leads to mass concentration effects around\nthe representations of training instances, i.e., a property beneficial for\ngeneralization. By leveraging previous work to impose topological constraints\nin a neural network setting, we provide empirical evidence (across various\nvision benchmarks) to support our claim for better generalization.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:25:15 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 04:15:03 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hofer", "Christoph D.", ""], ["Graf", "Florian", ""], ["Niethammer", "Marc", ""], ["Kwitt", "Roland", ""]]}, {"id": "2002.04806", "submitter": "Terrence Sejnowski", "authors": "Terrence J. Sejnowski", "title": "The Unreasonable Effectiveness of Deep Learning in Artificial\n  Intelligence", "comments": null, "journal-ref": "Proceedings of the National Academy of Sciences U.S.A. (2020)\n  https://www.pnas.org/content/early/2020/01/23/1907373117", "doi": "10.1073/pnas.1907373117", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning networks have been trained to recognize speech, caption\nphotographs and translate text between languages at high levels of performance.\nAlthough applications of deep learning networks to real world problems have\nbecome ubiquitous, our understanding of why they are so effective is lacking.\nThese empirical results should not be possible according to sample complexity\nin statistics and non-convex optimization theory. However, paradoxes in the\ntraining and effectiveness of deep learning networks are being investigated and\ninsights are being found in the geometry of high-dimensional spaces. A\nmathematical theory of deep learning would illuminate how they function, allow\nus to assess the strengths and weaknesses of different network architectures\nand lead to major improvements. Deep learning has provided natural ways for\nhumans to communicate with digital devices and is foundational for building\nartificial general intelligence. Deep learning was inspired by the architecture\nof the cerebral cortex and insights into autonomy and general intelligence may\nbe found in other brain regions that are essential for planning and survival,\nbut major breakthroughs will be needed to achieve these goals.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:25:15 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Sejnowski", "Terrence J.", ""]]}, {"id": "2002.04809", "submitter": "Jaeho Lee", "authors": "Sejun Park, Jaeho Lee, Sangwoo Mo, Jinwoo Shin", "title": "Lookahead: A Far-Sighted Alternative of Magnitude-based Pruning", "comments": "ICLR 2020, camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnitude-based pruning is one of the simplest methods for pruning neural\nnetworks. Despite its simplicity, magnitude-based pruning and its variants\ndemonstrated remarkable performances for pruning modern architectures. Based on\nthe observation that magnitude-based pruning indeed minimizes the Frobenius\ndistortion of a linear operator corresponding to a single layer, we develop a\nsimple pruning method, coined lookahead pruning, by extending the single layer\noptimization to a multi-layer optimization. Our experimental results\ndemonstrate that the proposed method consistently outperforms magnitude-based\npruning on various networks, including VGG and ResNet, particularly in the\nhigh-sparsity regime. See https://github.com/alinlab/lookahead_pruning for\ncodes.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:38:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Park", "Sejun", ""], ["Lee", "Jaeho", ""], ["Mo", "Sangwoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2002.04813", "submitter": "Yu Zhang Dr.", "authors": "Pengxin Guo, Chang Deng, Linjie Xu, Xiaonan Huang, Yu Zhang", "title": "Deep Multi-Task Augmented Feature Learning via Hierarchical Graph Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep multi-task learning attracts much attention in recent years as it\nachieves good performance in many applications. Feature learning is important\nto deep multi-task learning for sharing common information among tasks. In this\npaper, we propose a Hierarchical Graph Neural Network (HGNN) to learn augmented\nfeatures for deep multi-task learning. The HGNN consists of two-level graph\nneural networks. In the low level, an intra-task graph neural network is\nresponsible of learning a powerful representation for each data point in a task\nby aggregating its neighbors. Based on the learned representation, a task\nembedding can be generated for each task in a similar way to max pooling. In\nthe second level, an inter-task graph neural network updates task embeddings of\nall the tasks based on the attention mechanism to model task relations. Then\nthe task embedding of one task is used to augment the feature representation of\ndata points in this task. Moreover, for classification tasks, an inter-class\ngraph neural network is introduced to conduct similar operations on a finer\ngranularity, i.e., the class level, to generate class embeddings for each class\nin all the tasks use class embeddings to augment the feature representation.\nThe proposed feature augmentation strategy can be used in many deep multi-task\nlearning models. we analyze the HGNN in terms of training and generalization\nlosses. Experiments on real-world datastes show the significant performance\nimprovement when using this strategy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 06:02:20 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Guo", "Pengxin", ""], ["Deng", "Chang", ""], ["Xu", "Linjie", ""], ["Huang", "Xiaonan", ""], ["Zhang", "Yu", ""]]}, {"id": "2002.04815", "submitter": "Zhiwei Liang", "authors": "Youwei Song, Jiahai Wang, Zhiwei Liang, Zhiyue Liu, Tao Jiang", "title": "Utilizing BERT Intermediate Layers for Aspect Based Sentiment Analysis\n  and Natural Language Inference", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect based sentiment analysis aims to identify the sentimental tendency\ntowards a given aspect in text. Fine-tuning of pretrained BERT performs\nexcellent on this task and achieves state-of-the-art performances. Existing\nBERT-based works only utilize the last output layer of BERT and ignore the\nsemantic knowledge in the intermediate layers. This paper explores the\npotential of utilizing BERT intermediate layers to enhance the performance of\nfine-tuning of BERT. To the best of our knowledge, no existing work has been\ndone on this research. To show the generality, we also apply this approach to a\nnatural language inference task. Experimental results demonstrate the\neffectiveness and generality of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 06:11:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Song", "Youwei", ""], ["Wang", "Jiahai", ""], ["Liang", "Zhiwei", ""], ["Liu", "Zhiyue", ""], ["Jiang", "Tao", ""]]}, {"id": "2002.04833", "submitter": "Smitha Milli", "authors": "Hong Jun Jeon, Smitha Milli, Anca D. Dragan", "title": "Reward-rational (implicit) choice: A unifying formalism for reward\n  learning", "comments": "Published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often difficult to hand-specify what the correct reward function is for\na task, so researchers have instead aimed to learn reward functions from human\nbehavior or feedback. The types of behavior interpreted as evidence of the\nreward function have expanded greatly in recent years. We've gone from\ndemonstrations, to comparisons, to reading into the information leaked when the\nhuman is pushing the robot away or turning it off. And surely, there is more to\ncome. How will a robot make sense of all these diverse types of behavior? Our\nkey insight is that different types of behavior can be interpreted in a single\nunifying formalism - as a reward-rational choice that the human is making,\noften implicitly. The formalism offers both a unifying lens with which to view\npast work, as well as a recipe for interpreting new sources of information that\nare yet to be uncovered. We provide two examples to showcase this: interpreting\na new feedback type, and reading into how the choice of feedback itself leaks\ninformation about the reward.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:07:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 18:21:03 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 05:17:25 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 17:56:03 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jeon", "Hong Jun", ""], ["Milli", "Smitha", ""], ["Dragan", "Anca D.", ""]]}, {"id": "2002.04836", "submitter": "Mehmet Burak Say{\\i}c{\\i}", "authors": "Mehmet Burak Say{\\i}c{\\i}, Rikiya Yamashita, Jeanne Shen", "title": "Analysis Of Multi Field Of View Cnn And Attention Cnn On H&E Stained\n  Whole-slide Images On Hepatocellular Carcinoma", "comments": "This paper has been withdrawn by the authors due to need for heavy\n  revise", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hepatocellular carcinoma (HCC) is a leading cause of cancer-related death\nworldwide. Whole-slide imaging which is a method of scanning glass slides have\nbeen employed for diagnosis of HCC. Using high resolution Whole-slide images is\ninfeasible for Convolutional Neural Network applications. Hence tiling the\nWhole-slide images is a common methodology for assigning Convolutional Neural\nNetworks for classification and segmentation. Determination of the tile size\naffects the performance of the algorithms since small field of view can not\ncapture the information on a larger scale and large field of view can not\ncapture the information on a cellular scale. In this work, the effect of tile\nsize on performance for classification problem is analysed. In addition, Multi\nField of View CNN is assigned for taking advantage of the information provided\nby different tile sizes and Attention CNN is assigned for giving the capability\nof voting most contributing tile size. It is found that employing more than one\ntile size significantly increases the performance of the classification by\n3.97% and both algorithms are found successful over the algorithm which uses\nonly one tile size.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:18:40 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 23:25:48 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Say\u0131c\u0131", "Mehmet Burak", ""], ["Yamashita", "Rikiya", ""], ["Shen", "Jeanne", ""]]}, {"id": "2002.04839", "submitter": "Zhikang Wang Mr.", "authors": "Liu Ziyin, Zhikang T.Wang, Masahito Ueda", "title": "LaProp: Separating Momentum and Adaptivity in Adam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identity a by-far-unrecognized problem of Adam-style optimizers which\nresults from unnecessary coupling between momentum and adaptivity. The coupling\nleads to instability and divergence when the momentum and adaptivity parameters\nare mismatched. In this work, we propose a method, Laprop, which decouples\nmomentum and adaptivity in the Adam-style methods. We show that the decoupling\nleads to greater flexibility in the hyperparameters and allows for a\nstraightforward interpolation between the signed gradient methods and the\nadaptive gradient methods. We experimentally show that Laprop has consistently\nimproved speed and stability over Adam on a variety of tasks. We also bound the\nregret of Laprop on a convex problem and show that our bound differs from that\nof Adam by a key factor, which demonstrates its advantage.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:19 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 11:58:21 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 21:13:02 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ziyin", "Liu", ""], ["Wang", "Zhikang T.", ""], ["Ueda", "Masahito", ""]]}, {"id": "2002.04840", "submitter": "Chicheng Zhang", "authors": "Chicheng Zhang and Jie Shen and Pranjal Awasthi", "title": "Efficient active learning of sparse halfspaces with arbitrary bounded\n  noise", "comments": "43 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study active learning of homogeneous $s$-sparse halfspaces in\n$\\mathbb{R}^d$ under label noise. Even in the presence of mild label noise this\nis a challenging problem and only recently have label complexity bounds of the\nform $\\tilde{\\mathcal{O}} (s \\cdot \\mathrm{polylog}(d, \\frac{1}{\\epsilon}) )$\nbeen established in \\cite{zhang2018efficient} for computationally efficient\nalgorithms under the broad class of isotropic log-concave distributions. In\ncontrast, under high levels of label noise, the label complexity bounds\nachieved by computationally efficient algorithms are much worse. When the label\nnoise satisfies the {\\em Massart} condition \\cite{massart2006risk}, i.e., each\nlabel is flipped with probability at most $\\eta$ for a parameter $\\eta \\in\n\\big[0, \\frac12\\big)$, state-of-the-art result \\cite{awasthi2016learning}\nprovides a computationally efficient active learning algorithm under isotropic\nlog-concave distributions with label complexity\n$\\tilde{\\mathcal{O}}(s^{\\mathrm{poly}({1/(1-2\\eta)})} \\mathrm{poly}(\\ln d,\n\\frac{1}{\\epsilon}) )$, which is label-efficient only when the noise rate\n$\\eta$ is a constant. In this work, we substantially improve on it by designing\na polynomial time algorithm for active learning of $s$-sparse halfspaces under\nbounded noise and isotropic log-concave distributions, with a label complexity\nof $\\tilde{\\mathcal{O}}\\Big(\\frac{s}{(1-2\\eta)^4} \\mathrm{polylog} (d, \\frac 1\n\\epsilon) \\Big)$. This is the first efficient algorithm with label complexity\npolynomial in $\\frac{1}{1-2\\eta}$ in this setting, which is label-efficient\neven for $\\eta$ arbitrarily close to $\\frac12$. Our guarantees also immediately\ntranslate to new state-of-the-art label complexity results for full-dimensional\nactive and passive halfspace learning under arbitrary bounded noise and\nisotropic log-concave distributions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 08:28:24 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 06:05:13 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Zhang", "Chicheng", ""], ["Shen", "Jie", ""], ["Awasthi", "Pranjal", ""]]}, {"id": "2002.04861", "submitter": "David Holzm\\\"uller", "authors": "David Holzm\\\"uller and Ingo Steinwart", "title": "Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent", "comments": "Changes in v2: Single-column layout, NTK discussion, new experiment,\n  updated introduction, improved explanations. 20 pages + 33 pages appendix.\n  Code available at https://github.com/dholzmueller/nn_inconsistency", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that two-layer (Leaky)ReLU networks initialized by e.g. the widely\nused method proposed by He et al. (2015) and trained using gradient descent on\na least-squares loss are not universally consistent. Specifically, we describe\na large class of one-dimensional data-generating distributions for which, with\nhigh probability, gradient descent only finds a bad local minimum of the\noptimization landscape. It turns out that in these cases, the found network\nessentially performs linear regression even if the target function is\nnon-linear. We further provide numerical evidence that this happens in\npractical situations, for some multi-dimensional distributions and that\nstochastic gradient descent exhibits similar behavior.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:22:45 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 17:33:31 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Holzm\u00fcller", "David", ""], ["Steinwart", "Ingo", ""]]}, {"id": "2002.04862", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Convex Density Constraints for Computing Plausible Counterfactual\n  Explanations", "comments": "Accepted at ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing deployment of machine learning as well as legal regulations\nsuch as EU's GDPR cause a need for user-friendly explanations of decisions\nproposed by machine learning models. Counterfactual explanations are considered\nas one of the most popular techniques to explain a specific decision of a\nmodel. While the computation of \"arbitrary\" counterfactual explanations is well\nstudied, it is still an open research problem how to efficiently compute\nplausible and feasible counterfactual explanations. We build upon recent work\nand propose and study a formal definition of plausible counterfactual\nexplanations. In particular, we investigate how to use density estimators for\nenforcing plausibility and feasibility of counterfactual explanations. For the\npurpose of efficient computations, we propose convex density constraints that\nensure that the resulting counterfactual is located in a region of the data\nspace of high density.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:23:42 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:14:22 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "2002.04881", "submitter": "Nutan Chen Ph.D.", "authors": "Nutan Chen, Alexej Klushyn, Francesco Ferroni, Justin Bayer, Patrick\n  van der Smagt", "title": "Learning Flat Latent Manifolds with VAEs", "comments": "Thirty-seventh International Conference on Machine Learning (ICML)\n  2020", "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the similarity between data points often requires domain knowledge,\nwhich can in parts be compensated by relying on unsupervised methods such as\nlatent-variable models, where similarity/distance is estimated in a more\ncompact latent space. Prevalent is the use of the Euclidean metric, which has\nthe drawback of ignoring information about similarity of data stored in the\ndecoder, as captured by the framework of Riemannian geometry. We propose an\nextension to the framework of variational auto-encoders allows learning flat\nlatent manifolds, where the Euclidean metric is a proxy for the similarity\nbetween data points. This is achieved by defining the latent space as a\nRiemannian manifold and by regularising the metric tensor to be a scaled\nidentity matrix. Additionally, we replace the compact prior typically used in\nvariational auto-encoders with a recently presented, more expressive\nhierarchical one---and formulate the learning problem as a constrained\noptimisation problem. We evaluate our method on a range of data-sets, including\na video-tracking benchmark, where the performance of our unsupervised approach\nnears that of state-of-the-art supervised approaches, while retaining the\ncomputational efficiency of straight-line-based approaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:54:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 15:31:15 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 08:18:19 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Chen", "Nutan", ""], ["Klushyn", "Alexej", ""], ["Ferroni", "Francesco", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "2002.04908", "submitter": "Feng Liu", "authors": "Haozhe Liu, Wentian Zhang, Guojie Liu and Feng Liu", "title": "A Zero-Shot based Fingerprint Presentation Attack Detection System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of presentation attacks, Automated Fingerprint\nRecognition Systems(AFRSs) are vulnerable to presentation attack. Thus,\nnumerous methods of presentation attack detection(PAD) have been proposed to\nensure the normal utilization of AFRS. However, the demand of large-scale\npresentation attack images and the low-level generalization ability always\nastrict existing PAD methods' actual performances. Therefore, we propose a\nnovel Zero-Shot Presentation Attack Detection Model to guarantee the\ngeneralization of the PAD model. The proposed ZSPAD-Model based on generative\nmodel does not utilize any negative samples in the process of establishment,\nwhich ensures the robustness for various types or materials based presentation\nattack. Different from other auto-encoder based model, the Fine-grained Map\narchitecture is proposed to refine the reconstruction error of the auto-encoder\nnetworks and a task-specific gaussian model is utilized to improve the quality\nof clustering. Meanwhile, in order to improve the performance of the proposed\nmodel, 9 confidence scores are discussed in this article. Experimental results\nshowed that the ZSPAD-Model is the state of the art for ZSPAD, and the MS-Score\nis the best confidence score. Compared with existing methods, the proposed\nZSPAD-Model performs better than the feature-based method and under the\nmulti-shot setting, the proposed method overperforms the learning based method\nwith little training data. When large training data is available, their results\nare similar.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 10:52:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Haozhe", ""], ["Zhang", "Wentian", ""], ["Liu", "Guojie", ""], ["Liu", "Feng", ""]]}, {"id": "2002.04911", "submitter": "Johannes Andreas Stork", "authors": "Johannes A. Stork and Todor Stoyanov", "title": "Ensemble of Sparse Gaussian Process Experts for Implicit Surface Mapping\n  with Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating maps is an essential task in robotics and provides the basis for\neffective planning and navigation. In this paper, we learn a compact and\ncontinuous implicit surface map of an environment from a stream of range data\nwith known poses. For this, we create and incrementally adjust an ensemble of\napproximate Gaussian process (GP) experts which are each responsible for a\ndifferent part of the map. Instead of inserting all arriving data into the GP\nmodels, we greedily trade-off between model complexity and prediction error.\nOur algorithm therefore uses less resources on areas with few geometric\nfeatures and more where the environment is rich in variety. We evaluate our\napproach on synthetic and real-world data sets and analyze sensitivity to\nparameters and measurement noise. The results show that we can learn compact\nand accurate implicit surface models under different conditions, with a\nperformance comparable to or better than that of exact GP regression with\nsubsampled data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:06:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Stork", "Johannes A.", ""], ["Stoyanov", "Todor", ""]]}, {"id": "2002.04926", "submitter": "Dylan Foster", "authors": "Dylan J. Foster and Alexander Rakhlin", "title": "Beyond UCB: Optimal and Efficient Contextual Bandits with Regression\n  Oracles", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in contextual bandits is to develop flexible,\ngeneral-purpose algorithms with computational requirements no worse than\nclassical supervised learning tasks such as classification and regression.\nAlgorithms based on regression have shown promising empirical success, but\ntheoretical guarantees have remained elusive except in special cases. We\nprovide the first universal and optimal reduction from contextual bandits to\nonline regression. We show how to transform any oracle for online regression\nwith a given value function class into an algorithm for contextual bandits with\nthe induced policy class, with no overhead in runtime or memory requirements.\nWe characterize the minimax rates for contextual bandits with general,\npotentially nonparametric function classes, and show that our algorithm is\nminimax optimal whenever the oracle obtains the optimal rate for regression.\nCompared to previous results, our algorithm requires no distributional\nassumptions beyond realizability, and works even when contexts are chosen\nadversarially.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:33:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:44:25 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""]]}, {"id": "2002.04930", "submitter": "Shuai Wang", "authors": "Shuai Wang and Tsung-Hui Chang", "title": "Federated Matrix Factorization: Algorithm Design and Application to Data\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent demands on data privacy have called for federated learning (FL) as a\nnew distributed learning paradigm in massive and heterogeneous networks.\nAlthough many FL algorithms have been proposed, few of them have considered the\nmatrix factorization (MF) model, which is known to have a vast number of signal\nprocessing and machine learning applications. Different from the existing FL\nalgorithms that are designed for smooth problems with single block of\nvariables, in federated MF (FedMF), one has to deal with challenging non-convex\nand non-smooth problems (due to constraints or regularization) with two blocks\nof variables. In this paper, we address the challenge by proposing two new\nFedMF algorithms, namely, FedMAvg and FedMGS, based on the model averaging and\ngradient sharing principles, respectively. Both FedMAvg and FedMGS adopt\nmultiple steps of local updates per communication round to speed up\nconvergence, and allow only a randomly sampled subset of clients to communicate\nwith the server for reducing the communication cost. Convergence analyses for\nthe two algorithms are respectively presented, which delineate the impacts of\ndata distribution, local update number, and partial client communication on the\nalgorithm performance. By focusing on a data clustering task, extensive\nexperiment results are presented to examine the practical performance of both\nalgorithms, as well as demonstrating their efficacy over the existing\ndistributed clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:48:54 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 09:49:24 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Shuai", ""], ["Chang", "Tsung-Hui", ""]]}, {"id": "2002.04933", "submitter": "Pritish Chandna", "authors": "Pritish Chandna, Merlijn Blaauw, Jordi Bonada, Emilia Gomez", "title": "Content Based Singing Voice Extraction From a Musical Mixture", "comments": "To be published in ICASSP 2020", "journal-ref": "2020 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep learning based methodology for extracting the singing voice\nsignal from a musical mixture based on the underlying linguistic content. Our\nmodel follows an encoder decoder architecture and takes as input the magnitude\ncomponent of the spectrogram of a musical mixture with vocals. The encoder part\nof the model is trained via knowledge distillation using a teacher network to\nlearn a content embedding, which is decoded to generate the corresponding\nvocoder features. Using this methodology, we are able to extract the\nunprocessed raw vocal signal from the mixture even for a processed mixture\ndataset with singers not seen during training. While the nature of our system\nmakes it incongruous with traditional objective evaluation metrics, we use\nsubjective evaluation via listening tests to compare the methodology to\nstate-of-the-art deep learning based source separation algorithms. We also\nprovide sound examples and source code for reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 12:03:40 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 12:21:58 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chandna", "Pritish", ""], ["Blaauw", "Merlijn", ""], ["Bonada", "Jordi", ""], ["Gomez", "Emilia", ""]]}, {"id": "2002.04945", "submitter": "Tianyu Zeng", "authors": "Tianyu Zeng, Yunong Zhang, Zhenyu Li, Xiao Liu, and Binbin Qiu", "title": "Predictions of 2019-nCoV Transmission Ending via Comprehensive Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the SARS outbreak in 2003, a lot of predictive epidemiological models\nhave been proposed. At the end of 2019, a novel coronavirus, termed as\n2019-nCoV, has broken out and is propagating in China and the world. Here we\npropose a multi-model ordinary differential equation set neural network\n(MMODEs-NN) and model-free methods to predict the interprovincial transmissions\nin mainland China, especially those from Hubei Province. Compared with the\npreviously proposed epidemiological models, the proposed network can simulate\nthe transportations with the ODEs activation method, while the model-free\nmethods based on the sigmoid function, Gaussian function, and Poisson\ndistribution are linear and fast to generate reasonable predictions. According\nto the numerical experiments and the realities, the special policies for\ncontrolling the disease are successful in some provinces, and the transmission\nof the epidemic, whose outbreak time is close to the beginning of China Spring\nFestival travel rush, is more likely to decelerate before February 18 and to\nend before April 2020. The proposed mathematical and artificial intelligence\nmethods can give consistent and reasonable predictions of the 2019-nCoV ending.\nWe anticipate our work to be a starting point for comprehensive prediction\nresearches of the 2019-nCoV.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 12:26:08 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 06:08:07 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zeng", "Tianyu", ""], ["Zhang", "Yunong", ""], ["Li", "Zhenyu", ""], ["Liu", "Xiao", ""], ["Qiu", "Binbin", ""]]}, {"id": "2002.04971", "submitter": "Paarth Neekhara", "authors": "Shehzeen Hussain, Mojan Javaheripi, Paarth Neekhara, Ryan Kastner and\n  Farinaz Koushanfar", "title": "FastWave: Accelerating Autoregressive Convolutional Neural Networks on\n  FPGA", "comments": "Published as a conference paper at ICCAD 2019", "journal-ref": "@inproceedings {1143,booktitle = {IEEE/ACM 2019 International\n  Conference On Computer Aided Design (ICCAD)},year = {2019},month =\n  {November}}", "doi": "10.1109/ICCAD45719.2019.8942122", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive convolutional neural networks (CNNs) have been widely\nexploited for sequence generation tasks such as audio synthesis, language\nmodeling and neural machine translation. WaveNet is a deep autoregressive CNN\ncomposed of several stacked layers of dilated convolution that is used for\nsequence generation. While WaveNet produces state-of-the art audio generation\nresults, the naive inference implementation is quite slow; it takes a few\nminutes to generate just one second of audio on a high-end GPU. In this work,\nwe develop the first accelerator platform~\\textit{FastWave} for autoregressive\nconvolutional neural networks, and address the associated design challenges. We\ndesign the Fast-Wavenet inference model in Vivado HLS and perform a wide range\nof optimizations including fixed-point implementation, array partitioning and\npipelining. Our model uses a fully parameterized parallel architecture for fast\nmatrix-vector multiplication that enables per-layer customized latency\nfine-tuning for further throughput improvement. Our experiments comparatively\nassess the trade-off between throughput and resource utilization for various\noptimizations. Our best WaveNet design on the Xilinx XCVU13P FPGA that uses\nonly on-chip memory, achieves 66 faster generation speed compared to CPU\nimplementation and 11 faster generation speed than GPU implementation.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 06:15:09 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hussain", "Shehzeen", ""], ["Javaheripi", "Mojan", ""], ["Neekhara", "Paarth", ""], ["Kastner", "Ryan", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2002.04985", "submitter": "Ay\\c{c}a \\\"Oz\\c{c}elikkale", "authors": "Ayca Ozcelikkale", "title": "Sparse Recovery With Non-Linear Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random non-linear Fourier features have recently shown remarkable performance\nin a wide-range of regression and classification applications. Motivated by\nthis success, this article focuses on a sparse non-linear Fourier feature (NFF)\nmodel. We provide a characterization of the sufficient number of data points\nthat guarantee perfect recovery of the unknown parameters with\nhigh-probability. In particular, we show how the sufficient number of data\npoints depends on the kernel matrix associated with the probability\ndistribution function of the input data. We compare our results with the\nrecoverability bounds for the bounded orthonormal systems and provide examples\nthat illustrate sparse recovery under the NFF model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 13:41:25 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Ozcelikkale", "Ayca", ""]]}, {"id": "2002.04991", "submitter": "Maximilian Weininger", "authors": "Pranav Ashok, Mathias Jackermeier, Pushpak Jagtap, Jan\n  K\\v{r}et\\'insk\\'y, Maximilian Weininger, Majid Zamani", "title": "dtControl: Decision Tree Learning Algorithms for Controller\n  Representation", "comments": null, "journal-ref": null, "doi": "10.1145/3365365.3383468", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision tree learning is a popular classification technique most commonly\nused in machine learning applications. Recent work has shown that decision\ntrees can be used to represent provably-correct controllers concisely. Compared\nto representations using lookup tables or binary decision diagrams, decision\ntrees are smaller and more explainable. We present dtControl, an easily\nextensible tool for representing memoryless controllers as decision trees. We\ngive a comprehensive evaluation of various decision tree learning algorithms\napplied to 10 case studies arising out of correct-by-construction controller\nsynthesis. These algorithms include two new techniques, one for using arbitrary\nlinear binary classifiers in the decision tree learning, and one novel approach\nfor determinizing controllers during the decision tree construction. In\nparticular the latter turns out to be extremely efficient, yielding decision\ntrees with a single-digit number of decision nodes on 5 of the case studies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:13:17 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Ashok", "Pranav", ""], ["Jackermeier", "Mathias", ""], ["Jagtap", "Pushpak", ""], ["K\u0159et\u00ednsk\u00fd", "Jan", ""], ["Weininger", "Maximilian", ""], ["Zamani", "Majid", ""]]}, {"id": "2002.04992", "submitter": "Yossi Adi", "authors": "Felix Kreuk, Yaniv Sheena, Joseph Keshet, and Yossi Adi", "title": "Phoneme Boundary Detection using Learnable Segmental Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phoneme boundary detection plays an essential first step for a variety of\nspeech processing applications such as speaker diarization, speech science,\nkeyword spotting, etc. In this work, we propose a neural architecture coupled\nwith a parameterized structured loss function to learn segmental\nrepresentations for the task of phoneme boundary detection. First, we evaluated\nour model when the spoken phonemes were not given as input. Results on the\nTIMIT and Buckeye corpora suggest that the proposed model is superior to the\nbaseline models and reaches state-of-the-art performance in terms of F1 and\nR-value. We further explore the use of phonetic transcription as additional\nsupervision and show this yields minor improvements in performance but\nsubstantially better convergence rates. We additionally evaluate the model on a\nHebrew corpus and demonstrate such phonetic supervision can be beneficial in a\nmulti-lingual setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 14:03:08 GMT"}, {"version": "v2", "created": "Sun, 16 Feb 2020 07:26:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kreuk", "Felix", ""], ["Sheena", "Yaniv", ""], ["Keshet", "Joseph", ""], ["Adi", "Yossi", ""]]}, {"id": "2002.04993", "submitter": "Anthony Cioppa", "authors": "Anthony Cioppa and Marc Van Droogenbroeck and Marc Braham", "title": "Real-Time Semantic Background Subtraction", "comments": "Accepted and Published at ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic background subtraction SBS has been shown to improve the performance\nof most background subtraction algorithms by combining them with semantic\ninformation, derived from a semantic segmentation network. However, SBS\nrequires high-quality semantic segmentation masks for all frames, which are\nslow to compute. In addition, most state-of-the-art background subtraction\nalgorithms are not real-time, which makes them unsuitable for real-world\napplications. In this paper, we present a novel background subtraction\nalgorithm called Real-Time Semantic Background Subtraction (denoted RT-SBS)\nwhich extends SBS for real-time constrained applications while keeping similar\nperformances. RT-SBS effectively combines a real-time background subtraction\nalgorithm with high-quality semantic information which can be provided at a\nslower pace, independently for each pixel. We show that RT-SBS coupled with\nViBe sets a new state of the art for real-time background subtraction\nalgorithms and even competes with the non real-time state-of-the-art ones. Note\nthat we provide python CPU and GPU implementations of RT-SBS at\nhttps://github.com/cioppaanthony/rt-sbs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 13:46:01 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 09:33:32 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 08:49:42 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cioppa", "Anthony", ""], ["Van Droogenbroeck", "Marc", ""], ["Braham", "Marc", ""]]}, {"id": "2002.04997", "submitter": "Zhanhong Tan", "authors": "Zhanhong Tan, Jiebo Song, Xiaolong Ma, Sia-Huat Tan, Hongyang Chen,\n  Yuanqing Miao, Yifu Wu, Shaokai Ye, Yanzhi Wang, Dehui Li, Kaisheng Ma", "title": "PCNN: Pattern-based Fine-Grained Regular Pruning towards Optimizing CNN\n  Accelerators", "comments": "6 pages, DAC 2020 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning is a powerful technique to realize model compression. We\npropose PCNN, a fine-grained regular 1D pruning method. A novel index format\ncalled Sparsity Pattern Mask (SPM) is presented to encode the sparsity in PCNN.\nLeveraging SPM with limited pruning patterns and non-zero sequences with equal\nlength, PCNN can be efficiently employed in hardware. Evaluated on VGG-16 and\nResNet-18, our PCNN achieves the compression rate up to 8.4X with only 0.2%\naccuracy loss. We also implement a pattern-aware architecture in 55nm process,\nachieving up to 9.0X speedup and 28.39 TOPS/W efficiency with only 3.1% on-chip\nmemory overhead of indices.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:49:21 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:05:01 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tan", "Zhanhong", ""], ["Song", "Jiebo", ""], ["Ma", "Xiaolong", ""], ["Tan", "Sia-Huat", ""], ["Chen", "Hongyang", ""], ["Miao", "Yuanqing", ""], ["Wu", "Yifu", ""], ["Ye", "Shaokai", ""], ["Wang", "Yanzhi", ""], ["Li", "Dehui", ""], ["Ma", "Kaisheng", ""]]}, {"id": "2002.04999", "submitter": "Anees Kazi", "authors": "Anees Kazi, Luca Cosmo, Nassir Navab and Michael Bronstein", "title": "Differentiable Graph Module (DGM) for Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph deep learning has recently emerged as a powerful ML concept allowing to\ngeneralize successful deep neural architectures to non-Euclidean structured\ndata. Such methods have shown promising results on a broad spectrum of\napplications ranging from social science, biomedicine, and particle physics to\ncomputer vision, graphics, and chemistry. One of the limitations of the\nmajority of the current graph neural network architectures is that they are\noften restricted to the transductive setting and rely on the assumption that\nthe underlying graph is known and fixed. In many settings, such as those\narising in medical and healthcare applications, this assumption is not\nnecessarily true since the graph may be noisy, partially- or even completely\nunknown, and one is thus interested in inferring it from the data. This is\nespecially important in inductive settings when dealing with nodes not present\nin the graph at training time. Furthermore, sometimes such a graph itself may\nconvey insights that are even more important than the downstream task. In this\npaper, we introduce Differentiable Graph Module (DGM), a learnable function\npredicting the edge probability in the graph relevant for the task, that can be\ncombined with convolutional graph neural network layers and trained in an\nend-to-end fashion. We provide an extensive evaluation of applications from the\ndomains of healthcare (disease prediction), brain imaging (gender and age\nprediction), computer graphics (3D point cloud segmentation), and computer\nvision (zero-shot learning). We show that our model provides a significant\nimprovement over baselines both in transductive and inductive settings and\nachieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:59:35 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 17:22:42 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 12:04:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kazi", "Anees", ""], ["Cosmo", "Luca", ""], ["Navab", "Nassir", ""], ["Bronstein", "Michael", ""]]}, {"id": "2002.05022", "submitter": "Mohamed Abdelfattah", "authors": "Mohamed S. Abdelfattah, {\\L}ukasz Dudziak, Thomas Chau, Royson Lee,\n  Hyeji Kim, Nicholas D. Lane", "title": "Best of Both Worlds: AutoML Codesign of a CNN and its Hardware\n  Accelerator", "comments": "accepted at DAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has been very successful at outperforming\nhuman-designed convolutional neural networks (CNN) in accuracy, and when\nhardware information is present, latency as well. However, NAS-designed CNNs\ntypically have a complicated topology, therefore, it may be difficult to design\na custom hardware (HW) accelerator for such CNNs. We automate HW-CNN codesign\nusing NAS by including parameters from both the CNN model and the HW\naccelerator, and we jointly search for the best model-accelerator pair that\nboosts accuracy and efficiency. We call this Codesign-NAS. In this paper we\nfocus on defining the Codesign-NAS multiobjective optimization problem,\ndemonstrating its effectiveness, and exploring different ways of navigating the\ncodesign search space. For CIFAR-10 image classification, we enumerate close to\n4 billion model-accelerator pairs, and find the Pareto frontier within that\nlarge search space. This allows us to evaluate three different\nreinforcement-learning-based search strategies. Finally, compared to ResNet on\nits most optimal HW accelerator from within our HW design space, we improve on\nCIFAR-100 classification accuracy by 1.3% while simultaneously increasing\nperformance/area by 41% in just~1000 GPU-hours of running Codesign-NAS.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 10:00:36 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:28:29 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Abdelfattah", "Mohamed S.", ""], ["Dudziak", "\u0141ukasz", ""], ["Chau", "Thomas", ""], ["Lee", "Royson", ""], ["Kim", "Hyeji", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2002.05033", "submitter": "Shuyang Zhao", "authors": "Shuyang Zhao, Toni Heittola, Tuomas Virtanen", "title": "Active Learning for Sound Event Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an active learning system for sound event detection\n(SED). It aims at maximizing the accuracy of a learned SED model with limited\nannotation effort. The proposed system analyzes an initially unlabeled audio\ndataset, from which it selects sound segments for manual annotation. The\ncandidate segments are generated based on a proposed change point detection\napproach, and the selection is based on the principle of mismatch-first\nfarthest-traversal. During the training of SED models, recordings are used as\ntraining inputs, preserving the long-term context for annotated segments. The\nproposed system clearly outperforms reference methods in the two datasets used\nfor evaluation (TUT Rare Sound 2017 and TAU Spatial Sound 2019). Training with\nrecordings as context outperforms training with only annotated segments.\nMismatch-first farthest-traversal outperforms reference sample selection\nmethods based on random sampling and uncertainty sampling. Remarkably, the\nrequired annotation effort can be greatly reduced on the dataset where target\nsound events are rare: by annotating only 2% of the training data, the achieved\nSED performance is similar to annotating all the training data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:46:55 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:49:55 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhao", "Shuyang", ""], ["Heittola", "Toni", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "2002.05038", "submitter": "Jia Qian", "authors": "Jia Qian, Xenofon Fafoutis, Lars Kai Hansen", "title": "Towards Federated Learning: Robustness Analytics to Data Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning allows remote centralized server training models without\nto access the data stored in distributed (edge) devices. Most work assume the\ndata generated from edge devices is identically and independently sampled from\na common population distribution. However, such ideal sampling may not be\nrealistic in many contexts where edge devices correspond to units in variable\ncontext. Also, models based on intrinsic agency, such as active sampling\nschemes, may lead to highly biased sampling. So an imminent question is how\nrobust Federated Learning is to biased sampling? In this work, we investigate\ntwo such scenarios. First, we study Federated Learning of a classifier from\ndata with edge device class distribution heterogeneity. Second, we study\nFederated Learning of a classifier with active sampling at the edge. We present\nevidence in both scenarios, that federated learning is robust to data\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:11:17 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Qian", "Jia", ""], ["Fafoutis", "Xenofon", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "2002.05039", "submitter": "Raghavendra Reddy Pappagari", "authors": "Raghavendra Pappagari, Tianzi Wang, Jesus Villalba, Nanxin Chen, Najim\n  Dehak", "title": "x-vectors meet emotions: A study on dependencies between emotion and\n  speaker recognition", "comments": "45th International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we explore the dependencies between speaker recognition and\nemotion recognition. We first show that knowledge learned for speaker\nrecognition can be reused for emotion recognition through transfer learning.\nThen, we show the effect of emotion on speaker recognition. For emotion\nrecognition, we show that using a simple linear model is enough to obtain good\nperformance on the features extracted from pre-trained models such as the\nx-vector model. Then, we improve emotion recognition performance by fine-tuning\nfor emotion classification. We evaluated our experiments on three different\ntypes of datasets: IEMOCAP, MSP-Podcast, and Crema-D. By fine-tuning, we\nobtained 30.40%, 7.99%, and 8.61% absolute improvement on IEMOCAP, MSP-Podcast,\nand Crema-D respectively over baseline model with no pre-training. Finally, we\npresent results on the effect of emotion on speaker verification. We observed\nthat speaker verification performance is prone to changes in test speaker\nemotions. We found that trials with angry utterances performed worst in all\nthree datasets. We hope our analysis will initiate a new line of research in\nthe speaker recognition community.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:13:07 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Pappagari", "Raghavendra", ""], ["Wang", "Tianzi", ""], ["Villalba", "Jesus", ""], ["Chen", "Nanxin", ""], ["Dehak", "Najim", ""]]}, {"id": "2002.05049", "submitter": "Christian Wachinger", "authors": "Christian Wachinger and Anna Rieckmann and Sebastian P\\\"olsterl", "title": "Detect and Correct Bias in Multi-Site Neuroimaging Datasets", "comments": null, "journal-ref": "Medical Image Analysis, 2020", "doi": "10.1016/j.media.2020.101879", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The desire to train complex machine learning algorithms and to increase the\nstatistical power in association studies drives neuroimaging research to use\never-larger datasets. The most obvious way to increase sample size is by\npooling scans from independent studies. However, simple pooling is often\nill-advised as selection, measurement, and confounding biases may creep in and\nyield spurious correlations. In this work, we combine 35,320 magnetic resonance\nimages of the brain from 17 studies to examine bias in neuroimaging. In the\nfirst experiment, Name That Dataset, we provide empirical evidence for the\npresence of bias by showing that scans can be correctly assigned to their\nrespective dataset with 71.5% accuracy. Given such evidence, we take a closer\nlook at confounding bias, which is often viewed as the main shortcoming in\nobservational studies. In practice, we neither know all potential confounders\nnor do we have data on them. Hence, we model confounders as unknown, latent\nvariables. Kolmogorov complexity is then used to decide whether the confounded\nor the causal model provides the simplest factorization of the graphical model.\nFinally, we present methods for dataset harmonization and study their ability\nto remove bias in imaging features. In particular, we propose an extension of\nthe recently introduced ComBat algorithm to control for global variation across\nimage features, inspired by adjusting for population stratification in\ngenetics. Our results demonstrate that harmonization can reduce\ndataset-specific information in image features. Further, confounding bias can\nbe reduced and even turned into a causal relationship. However, harmonziation\nalso requires caution as it can easily remove relevant subject-specific\ninformation. Code is available at https://github.com/ai-med/Dataset-Bias.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:32:24 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 20:11:25 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wachinger", "Christian", ""], ["Rieckmann", "Anna", ""], ["P\u00f6lsterl", "Sebastian", ""]]}, {"id": "2002.05056", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Reevu Maity", "title": "Quantum Boosting", "comments": "37 pages; v2: minor edits to improve presentation", "journal-ref": "Proceedings of ICML 2020", "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we have a weak learning algorithm $\\mathcal{A}$ for a Boolean-valued\nproblem: $\\mathcal{A}$ produces hypotheses whose bias $\\gamma$ is small, only\nslightly better than random guessing (this could, for instance, be due to\nimplementing $\\mathcal{A}$ on a noisy device), can we boost the performance of\n$\\mathcal{A}$ so that $\\mathcal{A}$'s output is correct on $2/3$ of the inputs?\n  Boosting is a technique that converts a weak and inaccurate machine learning\nalgorithm into a strong accurate learning algorithm. The AdaBoost algorithm by\nFreund and Schapire (for which they were awarded the G\\\"odel prize in 2003) is\none of the widely used boosting algorithms, with many applications in theory\nand practice. Suppose we have a $\\gamma$-weak learner for a Boolean concept\nclass $C$ that takes time $R(C)$, then the time complexity of AdaBoost scales\nas $VC(C)\\cdot poly(R(C), 1/\\gamma)$, where $VC(C)$ is the $VC$-dimension of\n$C$. In this paper, we show how quantum techniques can improve the time\ncomplexity of classical AdaBoost. To this end, suppose we have a $\\gamma$-weak\nquantum learner for a Boolean concept class $C$ that takes time $Q(C)$, we\nintroduce a quantum boosting algorithm whose complexity scales as\n$\\sqrt{VC(C)}\\cdot poly(Q(C),1/\\gamma);$ thereby achieving a quadratic quantum\nimprovement over classical AdaBoost in terms of $VC(C)$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:47:54 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 23:06:52 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Maity", "Reevu", ""]]}, {"id": "2002.05058", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou and Ke Xu", "title": "Learning to Compare for Better Training and Evaluation of Open Domain\n  Natural Language Generation Models", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated evaluation of open domain natural language generation (NLG) models\nremains a challenge and widely used metrics such as BLEU and Perplexity can be\nmisleading in some cases. In our paper, we propose to evaluate natural language\ngeneration models by learning to compare a pair of generated sentences by\nfine-tuning BERT, which has been shown to have good natural language\nunderstanding ability. We also propose to evaluate the model-level quality of\nNLG models with sample-level comparison results with skill rating system. While\nable to be trained in a fully self-supervised fashion, our model can be further\nfine-tuned with a little amount of human preference annotation to better\nimitate human judgment. In addition to evaluating trained models, we propose to\napply our model as a performance indicator during training for better\nhyperparameter tuning and early-stopping. We evaluate our approach on both\nstory generation and chit-chat dialogue response generation. Experimental\nresults show that our model correlates better with human preference compared\nwith previous automated evaluation approaches. Training with the proposed\nmetric yields better performance in human evaluation, which further\ndemonstrates the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:52:21 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Xu", "Ke", ""]]}, {"id": "2002.05059", "submitter": "Jan Rosenzweig", "authors": "Jan Rosenzweig, Zoran Cvetkovic and Ivana Roenzweig", "title": "Goldilocks Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the new \"Goldilocks\" class of activation functions, which\nnon-linearly deform the input signal only locally when the input signal is in\nthe appropriate range. The small local deformation of the signal enables better\nunderstanding of how and why the signal is transformed through the layers.\nNumerical results on CIFAR-10 and CIFAR-100 data sets show that Goldilocks\nnetworks perform better than, or comparably to SELU and RELU, while introducing\ntractability of data deformation through the layers.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 07:26:30 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 11:20:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rosenzweig", "Jan", ""], ["Cvetkovic", "Zoran", ""], ["Roenzweig", "Ivana", ""]]}, {"id": "2002.05070", "submitter": "Jianren Wang", "authors": "Jianren Wang, Zhaoyuan Fang, Hang Zhao", "title": "AlignNet: A Unifying Approach to Audio-Visual Alignment", "comments": "WACV2020. Project video and code are available at\n  https://jianrenw.github.io/AlignNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AlignNet, a model that synchronizes videos with reference audios\nunder non-uniform and irregular misalignments. AlignNet learns the end-to-end\ndense correspondence between each frame of a video and an audio. Our method is\ndesigned according to simple and well-established principles: attention,\npyramidal processing, warping, and affinity function. Together with the model,\nwe release a dancing dataset Dance50 for training and evaluation. Qualitative,\nquantitative and subjective evaluation results on dance-music alignment and\nspeech-lip alignment demonstrate that our method far outperforms the\nstate-of-the-art methods. Project video and code are available at\nhttps://jianrenw.github.io/AlignNet.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:19:28 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Wang", "Jianren", ""], ["Fang", "Zhaoyuan", ""], ["Zhao", "Hang", ""]]}, {"id": "2002.05076", "submitter": "Michele Ceriotti", "authors": "Benjamin A. Helfrecht, Rose K. Cersonsky, Guillaume Fraux, and Michele\n  Ceriotti", "title": "Structure-Property Maps with Kernel Principal Covariates Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analyses based on linear methods constitute the simplest, most robust,\nand transparent approaches to the automatic processing of large amounts of data\nfor building supervised or unsupervised machine learning models. Principal\ncovariates regression (PCovR) is an underappreciated method that interpolates\nbetween principal component analysis and linear regression, and can be used to\nconveniently reveal structure-property relations in terms of\nsimple-to-interpret, low-dimensional maps. Here we provide a pedagogic overview\nof these data analysis schemes, including the use of the kernel trick to\nintroduce an element of non-linearity, while maintaining most of the\nconvenience and the simplicity of linear approaches. We then introduce a\nkernelized version of PCovR and a sparsified extension, and demonstrate the\nperformance of this approach in revealing and predicting structure-property\nrelations in chemistry and materials science, showing a variety of examples\nincluding elemental carbon, porous silicate frameworks, organic molecules,\namino acid conformers, and molecular materials.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:29:24 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 15:58:36 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Helfrecht", "Benjamin A.", ""], ["Cersonsky", "Rose K.", ""], ["Fraux", "Guillaume", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2002.05079", "submitter": "Kirandeep Kour", "authors": "Kirandeep Kour, Sergey Dolgov, Martin Stoll and Peter Benner", "title": "Efficient Structure-preserving Support Tensor Train Machine", "comments": "21 pages, 6 figures, 2 table, 1 Algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of collected data are high-dimensional and it is crucial\nfor efficient learning algorithms to exploit the tensorial structure as much as\npossible. The ever present curse of dimensionality for high dimensional data\nand the loss of structure when vectorizing the data motivates the use of\ntailored low-rank tensor methods. In the presence of small amounts of training\ndata kernel methods offer an attractive choice as they provide the possibility\nfor a nonlinear decision boundary. We introduce the Tensor Train Multi-way\nMulti-level Kernel (TT-MMK) as a method that combines the simplicity of\nCanonical Polyadic (CP) with the robustness of the tensor train (TT)\ndecomposition. We embed this approach into a Dual Structure-preserving Support\nVector Machine and show that the TT-MMK method is more reliable\ncomputationally, less sensitive to tuning parameters, and gives higher\nprediction accuracy in the SVM classification when benchmarked against other\nstate-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:35:10 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 16:33:37 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kour", "Kirandeep", ""], ["Dolgov", "Sergey", ""], ["Stoll", "Martin", ""], ["Benner", "Peter", ""]]}, {"id": "2002.05082", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris", "title": "Results on the algebraic matroid of the determinantal variety", "comments": "11 pages, reduced the problem to a purely combinatorial conjecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of base sets of the algebraic matroid of the determinantal\nvariety, which we also conjecture they characterize the matroid. This\nconjecture is then reduced to a purely combinatorial statement. Our technique\nconsists of interpreting matrix completion from a point of view of linear\nsections on the Grassmannian and invoking a class of local coordinates\ndescribed by Sturmfels $\\&$ Zelevinsky.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 16:35:56 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:54:05 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 18:50:38 GMT"}, {"version": "v4", "created": "Sun, 7 Jun 2020 12:43:06 GMT"}, {"version": "v5", "created": "Mon, 23 Nov 2020 14:03:33 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Tsakiris", "Manolis C.", ""]]}, {"id": "2002.05095", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Compressive Learning of Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative networks implicitly approximate complex densities from their\nsampling with impressive accuracy. However, because of the enormous scale of\nmodern datasets, this training process is often computationally expensive. We\ncast generative network training into the recent framework of compressive\nlearning: we reduce the computational burden of large-scale datasets by first\nharshly compressing them in a single pass as a single sketch vector. We then\npropose a cost function, which approximates the Maximum Mean Discrepancy\nmetric, but requires only this sketch, which makes it time- and\nmemory-efficient to optimize.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:03:43 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 10:52:43 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2002.05096", "submitter": "Sattar Vakili", "authors": "Sattar Vakili, Victor Picheny, Nicolas Durrande", "title": "Regret Bounds for Noise-Free Bayesian Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a powerful method for non-convex black-box\noptimization in low data regimes. However, the question of establishing tight\nupper bounds for common algorithms in the noiseless setting remains a largely\nopen question. In this paper, we establish new and tightest bounds for two\nalgorithms, namely GP-UCB and Thompson sampling, under the assumption that the\nobjective function is smooth in terms of having a bounded norm in a Mat\\'ern\nRKHS. Importantly, unlike several related works, we do not consider perfect\nknowledge of the kernel of the Gaussian process emulator used within the\nBayesian optimization loop. This allows us to provide results for practical\nalgorithms that sequentially estimate the Gaussian process kernel parameters\nfrom the available data.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:06:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Vakili", "Sattar", ""], ["Picheny", "Victor", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2002.05104", "submitter": "Camila Kolling", "authors": "Camila Kolling, J\\^onatas Wehrmann, and Rodrigo C. Barros", "title": "Component Analysis for Visual Question Answering Architectures", "comments": null, "journal-ref": "2020 - The International Joint Conference on Neural Networks\n  (IJCNN)", "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research advances in Computer Vision and Natural Language Processing\nhave introduced novel tasks that are paving the way for solving AI-complete\nproblems. One of those tasks is called Visual Question Answering (VQA). A VQA\nsystem must take an image and a free-form, open-ended natural language question\nabout the image, and produce a natural language answer as the output. Such a\ntask has drawn great attention from the scientific community, which generated a\nplethora of approaches that aim to improve the VQA predictive accuracy. Most of\nthem comprise three major components: (i) independent representation learning\nof images and questions; (ii) feature fusion so the model can use information\nfrom both sources to answer visual questions; and (iii) the generation of the\ncorrect answer in natural language. With so many approaches being recently\nintroduced, it became unclear the real contribution of each component for the\nultimate performance of the model. The main goal of this paper is to provide a\ncomprehensive analysis regarding the impact of each component in VQA models.\nOur extensive set of experiments cover both visual and textual elements, as\nwell as the combination of these representations in form of fusion and\nattention mechanisms. Our major contribution is to identify core components for\ntraining VQA models so as to maximize their predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:25:50 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 01:08:38 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Kolling", "Camila", ""], ["Wehrmann", "J\u00f4natas", ""], ["Barros", "Rodrigo C.", ""]]}, {"id": "2002.05105", "submitter": "Shisheng Cui", "authors": "Shisheng Cui and Chia-Jung Chang", "title": "Development of modeling and control strategies for an approximated\n  Gaussian process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gaussian process (GP) model, which has been extensively applied as priors\nof functions, has demonstrated excellent performance. The specification of a\nlarge number of parameters affects the computational efficiency and the\nfeasibility of implementation of a control strategy. We propose a linear model\nto approximate GPs; this model expands the GP model by a series of basis\nfunctions. Several examples and simulation studies are presented to demonstrate\nthe advantages of the proposed method. A control strategy is provided with the\nproposed linear model.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:28:24 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Cui", "Shisheng", ""], ["Chang", "Chia-Jung", ""]]}, {"id": "2002.05111", "submitter": "Anna Shalova", "authors": "Anna Shalova and Ivan Oseledets", "title": "Deep Representation Learning for Dynamical Systems Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.LG cs.NA math.NA nlin.CD physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proper states' representations are the key to the successful dynamics\nmodeling of chaotic systems. Inspired by recent advances of deep\nrepresentations in various areas such as natural language processing and\ncomputer vision, we propose the adaptation of the state-of-art Transformer\nmodel in application to the dynamical systems modeling. The model demonstrates\npromising results in trajectories generation as well as in the general\nattractors' characteristics approximation, including states' distribution and\nLyapunov exponent.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:57:16 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Shalova", "Anna", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2002.05115", "submitter": "Lukas Gemein", "authors": "Lukas Alexander Wilhelm Gemein, Robin Tibor Schirrmeister, Patryk\n  Chrab\\k{a}szcz, Daniel Wilson, Joschka Boedecker, Andreas Schulze-Bonhage,\n  Frank Hutter, Tonio Ball", "title": "Machine-Learning-Based Diagnostics of EEG Pathology", "comments": null, "journal-ref": "NeuroImage, Volume 220, 15 October 2020, 117021", "doi": "10.1016/j.neuroimage.2020.117021", "report-no": null, "categories": "eess.IV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods have the potential to automate clinical EEG\nanalysis. They can be categorized into feature-based (with handcrafted\nfeatures), and end-to-end approaches (with learned features). Previous studies\non EEG pathology decoding have typically analyzed a limited number of features,\ndecoders, or both. For a I) more elaborate feature-based EEG analysis, and II)\nin-depth comparisons of both approaches, here we first develop a comprehensive\nfeature-based framework, and then compare this framework to state-of-the-art\nend-to-end methods. To this aim, we apply the proposed feature-based framework\nand deep neural networks including an EEG-optimized temporal convolutional\nnetwork (TCN) to the task of pathological versus non-pathological EEG\nclassification. For a robust comparison, we chose the Temple University\nHospital (TUH) Abnormal EEG Corpus (v2.0.0), which contains approximately 3000\nEEG recordings. The results demonstrate that the proposed feature-based\ndecoding framework can achieve accuracies on the same level as state-of-the-art\ndeep neural networks. We find accuracies across both approaches in an\nastonishingly narrow range from 81--86\\%. Moreover, visualizations and analyses\nindicated that both approaches used similar aspects of the data, e.g., delta\nand theta band power at temporal electrode locations. We argue that the\naccuracies of current binary EEG pathology decoders could saturate near 90\\%\ndue to the imperfect inter-rater agreement of the clinical labels, and that\nsuch decoders are already clinically useful, such as in areas where clinical\nEEG experts are rare. We make the proposed feature-based framework available\nopen source and thus offer a new tool for EEG machine learning research.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 17:12:24 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Gemein", "Lukas Alexander Wilhelm", ""], ["Schirrmeister", "Robin Tibor", ""], ["Chrab\u0105szcz", "Patryk", ""], ["Wilson", "Daniel", ""], ["Boedecker", "Joschka", ""], ["Schulze-Bonhage", "Andreas", ""], ["Hutter", "Frank", ""], ["Ball", "Tonio", ""]]}, {"id": "2002.05120", "submitter": "Jason Jo", "authors": "Giulia Zarpellon, Jason Jo, Andrea Lodi and Yoshua Bengio", "title": "Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies", "comments": "AAAI 2021 camera-ready version with supplementary materials, improved\n  readability of figures in main article. Code, data and trained models are\n  available at https://github.com/ds4dm/branch-search-trees", "journal-ref": "Proceedings of the AAAI Conference on Artificial Intelligence\n  2021, 35(5), 3931-3939", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch and Bound (B&B) is the exact tree search method typically used to\nsolve Mixed-Integer Linear Programming problems (MILPs). Learning branching\npolicies for MILP has become an active research area, with most works proposing\nto imitate the strong branching rule and specialize it to distinct classes of\nproblems. We aim instead at learning a policy that generalizes across\nheterogeneous MILPs: our main hypothesis is that parameterizing the state of\nthe B&B search tree can aid this type of generalization. We propose a novel\nimitation learning framework, and introduce new input features and\narchitectures to represent branching. Experiments on MILP benchmark instances\nclearly show the advantages of incorporating an explicit parameterization of\nthe state of the search tree to modulate the branching decisions, in terms of\nboth higher accuracy and smaller B&B trees. The resulting policies\nsignificantly outperform the current state-of-the-art method for \"learning to\nbranch\" by effectively allowing generalization to generic unseen instances.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:43:23 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:32:08 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 18:30:16 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 20:11:03 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zarpellon", "Giulia", ""], ["Jo", "Jason", ""], ["Lodi", "Andrea", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.05123", "submitter": "Roi Pony", "authors": "Roi Pony, Itay Naeh, Shie Mannor", "title": "Over-the-Air Adversarial Flickering Attacks against Video Recognition\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for video classification, just like image classification\nnetworks, may be subjected to adversarial manipulation. The main difference\nbetween image classifiers and video classifiers is that the latter usually use\ntemporal information contained within the video. In this work we present a\nmanipulation scheme for fooling video classifiers by introducing a flickering\ntemporal perturbation that in some cases may be unnoticeable by human observers\nand is implementable in the real world. After demonstrating the manipulation of\naction classification of single videos, we generalize the procedure to make\nuniversal adversarial perturbation, achieving high fooling ratio. In addition,\nwe generalize the universal perturbation and produce a temporal-invariant\nperturbation, which can be applied to the video without synchronizing the\nperturbation to the input. The attack was implemented on several target models\nand the transferability of the attack was demonstrated. These properties allow\nus to bridge the gap between simulated environment and real-world application,\nas will be demonstrated in this paper for the first time for an over-the-air\nflickering attack.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 17:58:12 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 10:17:19 GMT"}, {"version": "v3", "created": "Fri, 27 Nov 2020 14:39:25 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 22:11:54 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Pony", "Roi", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.05135", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Kristian Georgiev, Aryan Mokhtari, Asuman Ozdaglar", "title": "Provably Convergent Policy Gradient Methods for Model-Agnostic\n  Meta-Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Model-Agnostic Meta-Learning (MAML) methods for Reinforcement\nLearning (RL) problems where the goal is to find a policy using data from\nseveral tasks represented by Markov Decision Processes (MDPs) that can be\nupdated by one step of stochastic policy gradient for the realized MDP. In\nparticular, using stochastic gradients in MAML update step is crucial for RL\nproblems since computation of exact gradients requires access to a large number\nof possible trajectories. For this formulation, we propose a variant of the\nMAML method, named Stochastic Gradient Meta-Reinforcement Learning (SG-MRL),\nand study its convergence properties. We derive the iteration and sample\ncomplexity of SG-MRL to find an $\\epsilon$-first-order stationary point, which,\nto the best of our knowledge, provides the first convergence guarantee for\nmodel-agnostic meta-reinforcement learning algorithms. We further show how our\nresults extend to the case where more than one step of stochastic policy\ngradient method is used in the update during the test time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:29:09 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 03:39:02 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Fallah", "Alireza", ""], ["Georgiev", "Kristian", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.05138", "submitter": "Shuang Liu", "authors": "Shuang Liu and Hao Su", "title": "Regret Bounds for Discounted MDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has traditionally been understood from an\nepisodic perspective; the concept of non-episodic RL, where there is no restart\nand therefore no reliable recovery, remains elusive. A fundamental question in\nnon-episodic RL is how to measure the performance of a learner and derive\nalgorithms to maximize such performance. Conventional wisdom is to maximize the\ndifference between the average reward received by the learner and the maximal\nlong-term average reward. In this paper, we argue that if the total time budget\nis relatively limited compared to the complexity of the environment, such\ncomparison may fail to reflect the finite-time optimality of the learner. We\npropose a family of measures, called $\\gamma$-regret, which we believe to\nbetter capture the finite-time optimality. We give motivations and derive lower\nand upper bounds for such measures. Note: A follow-up work (arXiv:2010.00587)\nhas improved both our lower and upper bound, the gap is now closed at\n$\\tilde{\\Theta}\\left(\\frac{\\sqrt{SAT}}{(1 - \\gamma)^{\\frac{1}{2}}}\\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:30:09 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:26:46 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 22:32:32 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Liu", "Shuang", ""], ["Su", "Hao", ""]]}, {"id": "2002.05139", "submitter": "Pravesh K Kothari", "authors": "Ainesh Bakshi and Pravesh K. Kothari", "title": "List-Decodable Subspace Recovery: Dimension Independent Error in\n  Polynomial Time", "comments": "To appear in SODA 2021. This version fixes an issue in a technical\n  claim bounding the variance of degree 2 polynomials and improves exposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In list-decodable subspace recovery, the input is a collection of $n$ points\n$\\alpha n$ (for some $\\alpha \\ll 1/2$) of which are drawn i.i.d. from a\ndistribution $\\mathcal{D}$ with a isotropic rank $r$ covariance $\\Pi_*$ (the\n\\emph{inliers}) and the rest are arbitrary, potential adversarial outliers. The\ngoal is to recover a $O(1/\\alpha)$ size list of candidate covariances that\ncontains a $\\hat{\\Pi}$ close to $\\Pi_*$. Two recent independent works\n(Raghavendra-Yau, Bakshi-Kothari 2020) gave the first efficient algorithm for\nthis problem. These results, however, obtain an error that grows with the\ndimension (linearly in [RY] and logarithmically in BK) at the cost of\nquasi-polynomial running time) and rely on \\emph{certifiable\nanti-concentration} - a relatively strict condition satisfied essentially only\nby the Gaussian distribution.\n  In this work, we improve on these results on all three fronts:\n\\emph{dimension-independent} error via a faster fixed-polynomial running time\nunder less restrictive distributional assumptions. Specifically, we give a\n$poly(1/\\alpha) d^{O(1)}$ time algorithm that outputs a list containing a\n$\\hat{\\Pi}$ satisfying $\\|\\hat{\\Pi} -\\Pi_*\\|_F \\leq O(1/\\alpha)$. Our result\nonly needs $\\mathcal{D}$ to have \\emph{certifiably hypercontractive} degree 2\npolynomials. As a result, in addition to Gaussians, our algorithm applies to\nthe uniform distribution on the hypercube and $q$-ary cubes and arbitrary\nproduct distributions with subgaussian marginals. Prior work (Raghavendra and\nYau, 2020) had identified such distributions as potential hard examples as such\ndistributions do not exhibit strong enough anti-concentration. When\n$\\mathcal{D}$ satisfies certifiable anti-concentration, we obtain a stronger\nerror guarantee of $\\|\\hat{\\Pi}-\\Pi_*\\|_F \\leq \\eta$ for any arbitrary $\\eta >\n0$ in $d^{O(poly(1/\\alpha) + \\log (1/\\eta))}$ time.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:30:09 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 04:53:41 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 17:54:57 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Kothari", "Pravesh K.", ""]]}, {"id": "2002.05141", "submitter": "Anastasios Tsiamis", "authors": "Anastasios Tsiamis and George Pappas", "title": "Online Learning of the Kalman Filter with Logarithmic Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of predicting observations generated\nonline by an unknown, partially observed linear system, which is driven by\nstochastic noise. For such systems the optimal predictor in the mean square\nsense is the celebrated Kalman filter, which can be explicitly computed when\nthe system model is known. When the system model is unknown, we have to learn\nhow to predict observations online based on finite data, suffering possibly a\nnon-zero regret with respect to the Kalman filter's prediction. We show that it\nis possible to achieve a regret of the order of $\\mathrm{poly}\\log(N)$ with\nhigh probability, where $N$ is the number of observations collected. Our work\nis the first to provide logarithmic regret guarantees for the widely used\nKalman filter. This is achieved using an online least-squares algorithm, which\nexploits the approximately linear relation between future observations and past\nobservations. The regret analysis is based on the stability properties of the\nKalman filter, recent statistical tools for finite sample analysis of system\nidentification, and classical results for the analysis of least-squares\nalgorithms for time series. Our regret analysis can also be applied for state\nprediction of the hidden state, in the case of unknown noise statistics but\nknown state-space basis. A fundamental technical contribution is that our\nbounds hold even for the class of non-explosive systems, which includes the\nclass of marginally stable systems, which was an open problem for the case of\nonline prediction under stochastic noise.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:31:31 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Tsiamis", "Anastasios", ""], ["Pappas", "George", ""]]}, {"id": "2002.05145", "submitter": "Robin Vogel", "authors": "Robin Vogel, Mastane Achab, St\\'ephan Cl\\'emen\\c{c}on, Charles Tillier", "title": "Weighted Empirical Risk Minimization: Sample Selection Bias Correction\n  based on Importance Sampling", "comments": "20 pages, 7 tables and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical learning problems, when the distribution $P'$ of the\ntraining observations $Z'_1,\\; \\ldots,\\; Z'_n$ differs from the distribution\n$P$ involved in the risk one seeks to minimize (referred to as the test\ndistribution) but is still defined on the same measurable space as $P$ and\ndominates it. In the unrealistic case where the likelihood ratio\n$\\Phi(z)=dP/dP'(z)$ is known, one may straightforwardly extends the Empirical\nRisk Minimization (ERM) approach to this specific transfer learning setup using\nthe same idea as that behind Importance Sampling, by minimizing a weighted\nversion of the empirical risk functional computed from the 'biased' training\ndata $Z'_i$ with weights $\\Phi(Z'_i)$. Although the importance function\n$\\Phi(z)$ is generally unknown in practice, we show that, in various situations\nfrequently encountered in practice, it takes a simple form and can be directly\nestimated from the $Z'_i$'s and some auxiliary information on the statistical\npopulation $P$. By means of linearization techniques, we then prove that the\ngeneralization capacity of the approach aforementioned is preserved when\nplugging the resulting estimates of the $\\Phi(Z'_i)$'s into the weighted\nempirical risk. Beyond these theoretical guarantees, numerical results provide\nstrong empirical evidence of the relevance of the approach promoted in this\narticle.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:42:47 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:50:34 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Vogel", "Robin", ""], ["Achab", "Mastane", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""], ["Tillier", "Charles", ""]]}, {"id": "2002.05149", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Self-explaining AI as an alternative to interpretable AI", "comments": "10pgs, 2 column format", "journal-ref": null, "doi": "10.1007/978-3-030-52152-3_10", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to explain decisions made by AI systems is highly sought after,\nespecially in domains where human lives are at stake such as medicine or\nautonomous vehicles. While it is often possible to approximate the input-output\nrelations of deep neural networks with a few human-understandable rules, the\ndiscovery of the double descent phenomena suggests that such approximations do\nnot accurately capture the mechanism by which deep neural networks work. Double\ndescent indicates that deep neural networks typically operate by smoothly\ninterpolating between data points rather than by extracting a few high level\nrules. As a result, neural networks trained on complex real world data are\ninherently hard to interpret and prone to failure if asked to extrapolate. To\nshow how we might be able to trust AI despite these problems we introduce the\nconcept of self-explaining AI. Self-explaining AIs are capable of providing a\nhuman-understandable explanation of each decision along with confidence levels\nfor both the decision and explanation. For this approach to work, it is\nimportant that the explanation actually be related to the decision, ideally\ncapturing the mechanism used to arrive at the explanation. Finally, we argue it\nis important that deep learning based systems include a \"warning light\" based\non techniques from applicability domain analysis to warn the user if a model is\nasked to extrapolate outside its training distribution. For a video\npresentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:50:11 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:13:25 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 18:56:25 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 15:26:15 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 13:38:58 GMT"}, {"version": "v6", "created": "Thu, 2 Jul 2020 19:03:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2002.05150", "submitter": "Julian Salazar", "authors": "Phillip Keung, Wei Niu, Yichao Lu, Julian Salazar, Vikas Bhardwaj", "title": "Attentional Speech Recognition Models Misbehave on Out-of-domain\n  Utterances", "comments": "Artifacts like our filtered Audio BNC dataset can be found at\n  https://github.com/aws-samples/seq2seq-asr-misbehaves", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of echographic transcription in autoregressive\nsequence-to-sequence attentional architectures for automatic speech\nrecognition, where a model produces very long sequences of repetitive outputs\nwhen presented with out-of-domain utterances. We decode audio from the British\nNational Corpus with an attentional encoder-decoder model trained solely on the\nLibriSpeech corpus. We observe that there are many 5-second recordings that\nproduce more than 500 characters of decoding output (i.e. more than 100\ncharacters per second). A frame-synchronous hybrid (DNN-HMM) model trained on\nthe same data does not produce these unusually long transcripts. These decoding\nissues are reproducible in a speech transformer model from ESPnet, and to a\nlesser extent in a self-attention CTC model, suggesting that these issues are\nintrinsic to the use of the attention mechanism. We create a separate length\nprediction model to predict the correct number of wordpieces in the output,\nwhich allows us to identify and truncate problematic decoding results without\nincreasing word error rates on the LibriSpeech task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:53:56 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Keung", "Phillip", ""], ["Niu", "Wei", ""], ["Lu", "Yichao", ""], ["Salazar", "Julian", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "2002.05152", "submitter": "Mohsen Bayati", "authors": "Nima Hamidi, Mohsen Bayati", "title": "Toward Better Use of Data in Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the well-known stochastic linear bandit problem where\na decision-maker sequentially chooses among a set of given actions, observes\ntheir noisy reward, and aims to maximize her cumulative expected reward over a\nhorizon of length $T$. In this paper, we first introduce a general analysis\nframework and a family of rate optimal algorithms for the problem. We show that\nthis family of algorithms includes well-known algorithms such as optimism in\nthe face of uncertainty linear bandit (OFUL) and Thompson sampling (TS) as\nspecial cases. The proposed analysis technique directly captures complexity of\nuncertainty in the action sets that we show is tied to regret analysis of any\npolicy. This insight allows us to design a new rate-optimal policy, called\nSieved-Greedy (SG), that reduces the over-exploration problem in existing\nalgorithms. SG utilizes data to discard the actions with relatively low\nuncertainty and then choosing one among the remaining actions greedily. In\naddition to proving that SG is theoretically rate-optimal, our empirical\nsimulations show that SG significantly outperforms existing benchmarks such as\ngreedy, OFUL, and TS. Moreover, our analysis technique yields a number of new\nresults such as obtaining poly-logarithmic (in $T$) regret bounds for OFUL and\nTS, under a generalized gap assumption and a margin condition, as in literature\non contextual bandits. We also improve regret bounds of these algorithms for\nthe sub-class of $k$-armed contextual bandit problems by a factor $\\sqrt{k}$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:54:41 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:40:55 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 17:49:47 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Hamidi", "Nima", ""], ["Bayati", "Mohsen", ""]]}, {"id": "2002.05153", "submitter": "Andrew Bennett", "authors": "Andrew Bennett and Nathan Kallus", "title": "Efficient Policy Learning from Surrogate-Loss Classification Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on policy learning from observational data has highlighted the\nimportance of efficient policy evaluation and has proposed reductions to\nweighted (cost-sensitive) classification. But, efficient policy evaluation need\nnot yield efficient estimation of policy parameters. We consider the estimation\nproblem given by a weighted surrogate-loss classification reduction of policy\nlearning with any score function, either direct, inverse-propensity weighted,\nor doubly robust. We show that, under a correct specification assumption, the\nweighted classification formulation need not be efficient for policy\nparameters. We draw a contrast to actual (possibly weighted) binary\nclassification, where correct specification implies a parametric model, while\nfor policy learning it only implies a semiparametric model. In light of this,\nwe instead propose an estimation approach based on generalized method of\nmoments, which is efficient for the policy parameters. We propose a particular\nmethod based on recent developments on solving moment problems using neural\nnetworks and demonstrate the efficiency and regret benefits of this method\nempirically.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:54:41 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""]]}, {"id": "2002.05155", "submitter": "Shahin Boluki", "authors": "Shahin Boluki, Randy Ardywibowo, Siamak Zamani Dadaneh, Mingyuan Zhou,\n  Xiaoning Qian", "title": "Learnable Bernoulli Dropout for Bayesian Deep Learning", "comments": "To appear in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose learnable Bernoulli dropout (LBD), a new\nmodel-agnostic dropout scheme that considers the dropout rates as parameters\njointly optimized with other model parameters. By probabilistic modeling of\nBernoulli dropout, our method enables more robust prediction and uncertainty\nquantification in deep models. Especially, when combined with variational\nauto-encoders (VAEs), LBD enables flexible semi-implicit posterior\nrepresentations, leading to new semi-implicit VAE~(SIVAE) models. We solve the\noptimization for training with respect to the dropout parameters using\nAugment-REINFORCE-Merge (ARM), an unbiased and low-variance gradient estimator.\nOur experiments on a range of tasks show the superior performance of our\napproach compared with other commonly used dropout schemes. Overall, LBD leads\nto improved accuracy and uncertainty estimates in image classification and\nsemantic segmentation. Moreover, using SIVAE, we can achieve state-of-the-art\nperformance on collaborative filtering for implicit feedback on several public\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:57:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Boluki", "Shahin", ""], ["Ardywibowo", "Randy", ""], ["Dadaneh", "Siamak Zamani", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "2002.05158", "submitter": "Mustafa Hajij", "authors": "Mustafa Hajij, Elizabeth Munch, Paul Rosen", "title": "Fast and Scalable Complex Network Descriptor Using PageRank and\n  Persistent Homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PageRank of a graph is a scalar function defined on the node set of the\ngraph which encodes nodes centrality information of the graph. In this article,\nwe use the PageRank function along with persistent homology to obtain a\nscalable graph descriptor and utilize it to compare the similarities between\ngraphs. For a given graph $G(V,E)$, our descriptor can be computed in\n$O(|E|\\alpha(|V|))$, where $\\alpha$ is the inverse Ackermann function which\nmakes it scalable and computable on massive graphs. We show the effectiveness\nof our method by utilizing it on multiple shape mesh datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:08:48 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 03:33:20 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Hajij", "Mustafa", ""], ["Munch", "Elizabeth", ""], ["Rosen", "Paul", ""]]}, {"id": "2002.05160", "submitter": "Mathilde Fekom", "authors": "Mathilde Fekom, Nicolas Vayatis, Argyris Kalogeratos", "title": "Optimal Multiple Stopping Rule for Warm-Starting Sequential Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Warm-starting Dynamic Thresholding algorithm,\ndeveloped using dynamic programming, for a variant of the standard online\nselection problem. The problem allows job positions to be either free or\nalready occupied at the beginning of the process. Throughout the selection\nprocess, the decision maker interviews one after the other the new candidates\nand reveals a quality score for each of them. Based on that information, she\ncan (re)assign each job at most once by taking immediate and irrevocable\ndecisions. We relax the hard requirement of the class of dynamic programming\nalgorithms to perfectly know the distribution from which the scores of\ncandidates are drawn, by presenting extensions for the partial and\nno-information cases, in which the decision maker can learn the underlying\nscore distribution sequentially while interviewing candidates.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:04:43 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fekom", "Mathilde", ""], ["Vayatis", "Nicolas", ""], ["Kalogeratos", "Argyris", ""]]}, {"id": "2002.05169", "submitter": "Sven Krippendorf", "authors": "Philip Betzler, Sven Krippendorf", "title": "Connecting Dualities and Machine Learning", "comments": "35 pages, 19 figures", "journal-ref": null, "doi": "10.1002/prop.202000022", "report-no": "LMU-ASC 05/20, MPP-2020-14", "categories": "physics.comp-ph cond-mat.dis-nn cs.LG hep-ph hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dualities are widely used in quantum field theories and string theory to\nobtain correlation functions at high accuracy. Here we present examples where\ndual data representations are useful in supervised classification, linking\nmachine learning and typical tasks in theoretical physics. We then discuss how\nsuch beneficial representations can be enforced in the latent dimension of\nneural networks. We find that additional contributions to the loss based on\nfeature separation, feature matching with respect to desired representations,\nand a good performance on a `simple' correlation function can lead to known and\nunknown dual representations. This is the first proof of concept that computers\ncan find dualities. We discuss how our examples, based on discrete Fourier\ntransformation and Ising models, connect to other dualities in theoretical\nphysics, for instance Seiberg duality.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:00:02 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Betzler", "Philip", ""], ["Krippendorf", "Sven", ""]]}, {"id": "2002.05183", "submitter": "Luiz F. O. Chamon", "authors": "Luiz F. O. Chamon and Santiago Paternain and Miguel Calvo-Fullana and\n  Alejandro Ribeiro", "title": "The empirical duality gap of constrained statistical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the study of constrained statistical learning\nproblems, the unconstrained version of which are at the core of virtually all\nof modern information processing. Accounting for constraints, however, is\nparamount to incorporate prior knowledge and impose desired structural and\nstatistical properties on the solutions. Still, solving constrained statistical\nproblems remains challenging and guarantees scarce, leaving them to be tackled\nusing regularized formulations. Though practical and effective, selecting\nregularization parameters so as to satisfy requirements is challenging, if at\nall possible, due to the lack of a straightforward relation between parameters\nand constraints. In this work, we propose to directly tackle the constrained\nstatistical problem overcoming its infinite dimensionality, unknown\ndistributions, and constraints by leveraging finite dimensional\nparameterizations, sample averages, and duality theory. Aside from making the\nproblem tractable, these tools allow us to bound the empirical duality gap,\ni.e., the difference between our approximate tractable solutions and the actual\nsolutions of the original statistical problem. We demonstrate the effectiveness\nand usefulness of this constrained formulation in a fair learning application.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:12:29 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chamon", "Luiz F. O.", ""], ["Paternain", "Santiago", ""], ["Calvo-Fullana", "Miguel", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2002.05185", "submitter": "Edward Gillman", "authors": "Edward Gillman, Dominic C. Rose and Juan P. Garrahan", "title": "A Tensor Network Approach to Finite Markov Decision Processes", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor network (TN) techniques - often used in the context of quantum\nmany-body physics - have shown promise as a tool for tackling machine learning\n(ML) problems. The application of TNs to ML, however, has mostly focused on\nsupervised and unsupervised learning. Yet, with their direct connection to\nhidden Markov chains, TNs are also naturally suited to Markov decision\nprocesses (MDPs) which provide the foundation for reinforcement learning (RL).\nHere we introduce a general TN formulation of finite, episodic and discrete\nMDPs. We show how this formulation allows us to exploit algorithms developed\nfor TNs for policy optimisation, the key aim of RL. As an application we\nconsider the issue - formulated as an RL problem - of finding a stochastic\nevolution that satisfies specific dynamical conditions, using the simple\nexample of random walk excursions as an illustration.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:18:27 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Gillman", "Edward", ""], ["Rose", "Dominic C.", ""], ["Garrahan", "Juan P.", ""]]}, {"id": "2002.05189", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Shubham Tulsiani, Saurabh Gupta, Abhinav Gupta", "title": "Intrinsic Motivation for Encouraging Synergistic Behavior", "comments": "ICLR 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the role of intrinsic motivation as an exploration bias for\nreinforcement learning in sparse-reward synergistic tasks, which are tasks\nwhere multiple agents must work together to achieve a goal they could not\nindividually. Our key idea is that a good guiding principle for intrinsic\nmotivation in synergistic tasks is to take actions which affect the world in\nways that would not be achieved if the agents were acting on their own. Thus,\nwe propose to incentivize agents to take (joint) actions whose effects cannot\nbe predicted via a composition of the predicted effect for each individual\nagent. We study two instantiations of this idea, one based on the true states\nencountered, and another based on a dynamics model trained concurrently with\nthe policy. While the former is simpler, the latter has the benefit of being\nanalytically differentiable with respect to the action taken. We validate our\napproach in robotic bimanual manipulation and multi-agent locomotion tasks with\nsparse rewards; we find that our approach yields more efficient learning than\nboth 1) training with only the sparse reward and 2) using the typical\nsurprise-based formulation of intrinsic motivation, which does not bias toward\nsynergistic behavior. Videos are available on the project webpage:\nhttps://sites.google.com/view/iclr2020-synergistic.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:34:51 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Chitnis", "Rohan", ""], ["Tulsiani", "Shubham", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""]]}, {"id": "2002.05193", "submitter": "Momin M. Malik", "authors": "Momin M. Malik", "title": "A Hierarchy of Limitations in Machine Learning", "comments": "68 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \"All models are wrong, but some are useful\", wrote George E. P. Box (1979).\nMachine learning has focused on the usefulness of probability models for\nprediction in social systems, but is only now coming to grips with the ways in\nwhich these models are wrong---and the consequences of those shortcomings. This\npaper attempts a comprehensive, structured overview of the specific conceptual,\nprocedural, and statistical limitations of models in machine learning when\napplied to society. Machine learning modelers themselves can use the described\nhierarchy to identify possible failure points and think through how to address\nthem, and consumers of machine learning models can know what to question when\nconfronted with the decision about if, where, and how to apply machine\nlearning. The limitations go from commitments inherent in quantification\nitself, through to showing how unmodeled dependencies can lead to\ncross-validation being overly optimistic as a way of assessing model\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:39:29 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:04:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Malik", "Momin M.", ""]]}, {"id": "2002.05194", "submitter": "Oberon Berlage", "authors": "Oberon Berlage, Klaus-Michael Lux, David Graus", "title": "Improving automated segmentation of radio shows with audio embeddings", "comments": "5 pages, 2 figures, submitted to ICASSP2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054315", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio features have been proven useful for increasing the performance of\nautomated topic segmentation systems. This study explores the novel task of\nusing audio embeddings for automated, topically coherent segmentation of radio\nshows. We created three different audio embedding generators using multi-class\nclassification tasks on three datasets from different domains. We evaluate\ntopic segmentation performance of the audio embeddings and compare it against a\ntext-only baseline. We find that a set-up including audio embeddings generated\nthrough a non-speech sound event classification task significantly outperforms\nour text-only baseline by 32.3% in F1-measure. In addition, we find that\ndifferent classification tasks yield audio embeddings that vary in segmentation\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:40:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Berlage", "Oberon", ""], ["Lux", "Klaus-Michael", ""], ["Graus", "David", ""]]}, {"id": "2002.05198", "submitter": "Fabricio Breve", "authors": "Fabricio Aparecido Breve, Liang Zhao, Marcos Gon\\c{c}alves Quiles", "title": "Particle Competition and Cooperation for Semi-Supervised Learning with\n  Label Noise", "comments": null, "journal-ref": "Neurocomputing (Amsterdam), v.160, p.63 - 72, 2015", "doi": "10.1016/j.neucom.2014.08.082", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning methods are usually employed in the classification\nof data sets where only a small subset of the data items is labeled. In these\nscenarios, label noise is a crucial issue, since the noise may easily spread to\na large portion or even the entire data set, leading to major degradation in\nclassification accuracy. Therefore, the development of new techniques to reduce\nthe nasty effects of label noise in semi-supervised learning is a vital issue.\nRecently, a graph-based semi-supervised learning approach based on Particle\ncompetition and cooperation was developed. In this model, particles walk in the\ngraphs constructed from the data sets. Competition takes place among particles\nrepresenting different class labels, while the cooperation occurs among\nparticles with the same label. This paper presents a new particle competition\nand cooperation algorithm, specifically designed to increase the robustness to\nthe presence of label noise, improving its label noise tolerance. Different\nfrom other methods, the proposed one does not require a separate technique to\ndeal with label noise. It performs classification of unlabeled nodes and\nreclassification of the nodes affected by label noise in a unique process.\nComputer simulations show the classification accuracy of the proposed method\nwhen applied to some artificial and real-world data sets, in which we introduce\nincreasing amounts of label noise. The classification accuracy is compared to\nthose achieved by previous particle competition and cooperation algorithms and\nother representative graph-based semi-supervised learning methods using the\nsame scenarios. Results show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:44:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Breve", "Fabricio Aparecido", ""], ["Zhao", "Liang", ""], ["Quiles", "Marcos Gon\u00e7alves", ""]]}, {"id": "2002.05202", "submitter": "Noam Shazeer", "authors": "Noam Shazeer", "title": "GLU Variants Improve Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated Linear Units (arXiv:1612.08083) consist of the component-wise product\nof two linear projections, one of which is first passed through a sigmoid\nfunction. Variations on GLU are possible, using different nonlinear (or even\nlinear) functions in place of sigmoid. We test these variants in the\nfeed-forward sublayers of the Transformer (arXiv:1706.03762)\nsequence-to-sequence model, and find that some of them yield quality\nimprovements over the typically-used ReLU or GELU activations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:57:13 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Shazeer", "Noam", ""]]}, {"id": "2002.05205", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Jawad Chowdhury, Rezaur Rashid, Asif Chowdhury", "title": "Explainable Deep Modeling of Tabular Data using TableGraphNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of research on explainability focuses on\npost-explainability rather than explainable modeling. Namely, an explanation\nmodel is derived to explain a complex black box model built with the sole\npurpose of achieving the highest performance possible. In part, this trend\nmight be driven by the misconception that there is a trade-off between\nexplainability and accuracy. Furthermore, the consequential work on Shapely\nvalues, grounded in game theory, has also contributed to a new wave of\npost-explainability research on better approximations for various machine\nlearning models, including deep learning models. We propose a new architecture\nthat inherently produces explainable predictions in the form of additive\nfeature attributions. Our approach learns a graph representation for each\nrecord in the dataset. Attribute centric features are then derived from the\ngraph and fed into a contribution deep set model to produce the final\npredictions. We show that our explainable model attains the same level of\nperformance as black box models. Finally, we provide an augmented model\ntraining approach that leverages the missingness property and yields high\nlevels of consistency (as required for the Shapely values) without loss of\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:02:10 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Chowdhury", "Jawad", ""], ["Rashid", "Rezaur", ""], ["Chowdhury", "Asif", ""]]}, {"id": "2002.05212", "submitter": "Tianhui Zhou", "authors": "Tianhui Zhou, Yitong Li, Yuan Wu, David Carlson", "title": "Estimating Uncertainty Intervals from Collaborating Networks", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective decision making requires understanding the uncertainty inherent in\na prediction. To estimate uncertainty in regression, one could modify a deep\nneural network to predict coverage intervals, such as by predicting the mean\nand standard deviation. Unfortunately, in our empirical evaluations the\npredicted coverage from existing approaches is either overconfident or lacks\nsharpness (gives imprecise intervals). To address this challenge, we propose a\nnovel method to estimate uncertainty based on two distinct neural networks with\ntwo distinct loss functions in a similar vein to Generative Adversarial\nNetworks. Specifically, one network tries to learn the cumulative distribution\nfunction, and the second network tries to learn its inverse. Theoretical\nanalysis demonstrates that the idealized solution is a fixed point and that\nunder certain conditions the approach is asymptotically consistent to ground\ntruth. We benchmark the approach on one synthetic and five real-world datasets,\nincluding forecasting A1c values in diabetic patients from electronic health\nrecords, where uncertainty is critical. In synthetic data, the proposed\napproach essentially matches the theoretically optimal solution in all aspects.\nIn the real datasets, the proposed approach is empirically more faithful in its\ncoverage estimates and typically gives sharper intervals than competing\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:10:27 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 17:42:21 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Zhou", "Tianhui", ""], ["Li", "Yitong", ""], ["Wu", "Yuan", ""], ["Carlson", "David", ""]]}, {"id": "2002.05217", "submitter": "Sergei Volodin", "authors": "Sergei Volodin, Nevan Wichers, Jeremy Nixon", "title": "Resolving Spurious Correlations in Causal Models of Environments via\n  Interventions", "comments": "9 pages, 7 figures, 3 pages supplementary material", "journal-ref": "Causal Learning for Decision Making (CLDM) ICLR CLDM 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal models bring many benefits to decision-making systems (or agents) by\nmaking them interpretable, sample-efficient, and robust to changes in the input\ndistribution. However, spurious correlations can lead to wrong causal models\nand predictions. We consider the problem of inferring a causal model of a\nreinforcement learning environment and we propose a method to deal with\nspurious correlations. Specifically, our method designs a reward function that\nincentivizes an agent to do an intervention to find errors in the causal model.\nThe data obtained from doing the intervention is used to improve the causal\nmodel. We propose several intervention design methods and compare them. The\nexperimental results in a grid-world environment show that our approach leads\nto better causal models compared to baselines: learning the model on data from\na random policy or a policy trained on the environment's reward. The main\ncontribution consists of methods to design interventions to resolve spurious\ncorrelations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:20:47 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 19:40:05 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Volodin", "Sergei", ""], ["Wichers", "Nevan", ""], ["Nixon", "Jeremy", ""]]}, {"id": "2002.05226", "submitter": "Jose M. Pe\\~na", "authors": "Jose M. Pe\\~na", "title": "Conditional Path Analysis in Singly-Connected Path Diagrams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the classical path analysis by showing that, for a singly-connected\npath diagram, the partial covariance of two random variables factorizes over\nthe nodes and edges in the path between the variables. This result allows us to\nshow that Simpson's paradox cannot occur in singly-connected path diagrams.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:31:02 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 15:12:41 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 21:08:06 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 10:50:18 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Pe\u00f1a", "Jose M.", ""]]}, {"id": "2002.05227", "submitter": "Dimitris Kalatzis", "authors": "Dimitris Kalatzis, David Eklund, Georgios Arvanitidis, S{\\o}ren\n  Hauberg", "title": "Variational Autoencoders with Riemannian Brownian Motion Priors", "comments": "Published in ICML 2020", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Autoencoders (VAEs) represent the given data in a low-dimensional\nlatent space, which is generally assumed to be Euclidean. This assumption\nnaturally leads to the common choice of a standard Gaussian prior over\ncontinuous latent variables. Recent work has, however, shown that this prior\nhas a detrimental effect on model capacity, leading to subpar performance. We\npropose that the Euclidean assumption lies at the heart of this failure mode.\nTo counter this, we assume a Riemannian structure over the latent space, which\nconstitutes a more principled geometric view of the latent codes, and replace\nthe standard Gaussian prior with a Riemannian Brownian motion prior. We propose\nan efficient inference scheme that does not rely on the unknown normalizing\nfactor of this prior. Finally, we demonstrate that this prior significantly\nincreases model capacity using only one additional scalar parameter.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:35:21 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:08:37 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 16:01:28 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Kalatzis", "Dimitris", ""], ["Eklund", "David", ""], ["Arvanitidis", "Georgios", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2002.05229", "submitter": "Ge Liu", "authors": "Ge Liu, Rui Wu, Heng-Tze Cheng, Jing Wang, Jayden Ooi, Lihong Li, Ang\n  Li, Wai Lok Sibon Li, Craig Boutilier, Ed Chi", "title": "Data Efficient Training for Reinforcement Learning with Adaptive\n  Behavior Policy Sharing", "comments": "on Deep Reinforcement Learning workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Reinforcement Learning (RL) is proven powerful for decision making in\nsimulated environments. However, training deep RL model is challenging in real\nworld applications such as production-scale health-care or recommender systems\nbecause of the expensiveness of interaction and limitation of budget at\ndeployment. One aspect of the data inefficiency comes from the expensive\nhyper-parameter tuning when optimizing deep neural networks. We propose\nAdaptive Behavior Policy Sharing (ABPS), a data-efficient training algorithm\nthat allows sharing of experience collected by behavior policy that is\nadaptively selected from a pool of agents trained with an ensemble of\nhyper-parameters. We further extend ABPS to evolve hyper-parameters during\ntraining by hybridizing ABPS with an adapted version of Population Based\nTraining (ABPS-PBT). We conduct experiments with multiple Atari games with up\nto 16 hyper-parameter/architecture setups. ABPS achieves superior overall\nperformance, reduced variance on top 25% agents, and equivalent performance on\nthe best agent compared to conventional hyper-parameter tuning with independent\ntraining, even though ABPS only requires the same number of environmental\ninteractions as training a single agent. We also show that ABPS-PBT further\nimproves the convergence speed and reduces the variance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:35:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Liu", "Ge", ""], ["Wu", "Rui", ""], ["Cheng", "Heng-Tze", ""], ["Wang", "Jing", ""], ["Ooi", "Jayden", ""], ["Li", "Lihong", ""], ["Li", "Ang", ""], ["Li", "Wai Lok Sibon", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed", ""]]}, {"id": "2002.05233", "submitter": "Emanuele Pesce Mr.", "authors": "Emanuele Pesce, Giovanni Montana", "title": "Learning Multi-Agent Coordination through Graph-driven Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the problem of learning collaborative behaviour through\ncommunication in multi-agent systems using deep reinforcement learning. A\nconnectivity-driven communication (CDC) algorithm is proposed to address three\nkey aspects: what agents to involve in the communication, what information\ncontent to share, and how often to share it. The multi-agent system is modelled\nas a weighted graph with nodes representing agents. The unknown edge weights\nreflect the degree of communication between pairs of agents, which depends on a\ndiffusion process on the graph - the heat kernel. An optimal communication\nstrategy, tightly coupled with overall graph topology, is learned end-to-end\nconcurrently with the agents' policy so as to maximise future expected returns.\nEmpirical results show that CDC is capable of superior performance over\nalternative algorithms for a range of cooperative navigation tasks, and that\nthe learned graph structures can be interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 20:58:33 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 20:00:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Pesce", "Emanuele", ""], ["Montana", "Giovanni", ""]]}, {"id": "2002.05235", "submitter": "Bowen Li", "authors": "Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz", "title": "Image-to-Image Translation with Text Guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to embed controllable factors, i.e., natural\nlanguage descriptions, into image-to-image translation with generative\nadversarial networks, which allows text descriptions to determine the visual\nattributes of synthetic images. We propose four key components: (1) the\nimplementation of part-of-speech tagging to filter out non-semantic words in\nthe given description, (2) the adoption of an affine combination module to\neffectively fuse different modality text and image features, (3) a novel\nrefined multi-stage architecture to strengthen the differential ability of\ndiscriminators and the rectification ability of generators, and (4) a new\nstructure loss to further improve discriminators to better distinguish real and\nsynthetic images. Extensive experiments on the COCO dataset demonstrate that\nour method has a superior performance on both visual realism and semantic\nconsistency with given descriptions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:09:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Li", "Bowen", ""], ["Qi", "Xiaojuan", ""], ["Torr", "Philip H. S.", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2002.05242", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Mona Jalal, Vitaly Ablavsky, Danielle Allessio, John\n  Magee, Jacob Whitehill, Ivon Arroyo, Beverly Woolf, Stan Sclaroff, Margrit\n  Betke", "title": "Leveraging Affect Transfer Learning for Behavior Prediction in an\n  Intelligent Tutoring System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of building an intelligent tutoring system (ITS), which\nimproves student learning outcomes by intervention, we set out to improve\nprediction of student problem outcome. In essence, we want to predict the\noutcome of a student answering a problem in an ITS from a video feed by\nanalyzing their face and gestures. For this, we present a novel transfer\nlearning facial affect representation and a user-personalized training scheme\nthat unlocks the potential of this representation. We model the temporal\nstructure of video sequences of students solving math problems using a\nrecurrent neural network architecture. Additionally, we extend the largest\ndataset of student interactions with an intelligent online math tutor by a\nfactor of two. Our final model, coined ATL-BP (Affect Transfer Learning for\nBehavior Prediction) achieves an increase in mean F-score over state-of-the-art\nof 45% on this new dataset in the general case and 50% in a more challenging\nleave-users-out experimental setting when we use a user-personalized training\nscheme.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:30:34 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Jalal", "Mona", ""], ["Ablavsky", "Vitaly", ""], ["Allessio", "Danielle", ""], ["Magee", "John", ""], ["Whitehill", "Jacob", ""], ["Arroyo", "Ivon", ""], ["Woolf", "Beverly", ""], ["Sclaroff", "Stan", ""], ["Betke", "Margrit", ""]]}, {"id": "2002.05257", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Joerg Schloetterer, Michael Granitzer", "title": "Shortest path distance approximation using deep learning techniques", "comments": null, "journal-ref": null, "doi": "10.1109/ASONAM.2018.8508763", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Computing shortest path distances between nodes lies at the heart of many\ngraph algorithms and applications. Traditional exact methods such as\nbreadth-first-search (BFS) do not scale up to contemporary, rapidly evolving\ntoday's massive networks. Therefore, it is required to find approximation\nmethods to enable scalable graph processing with a significant speedup. In this\npaper, we utilize vector embeddings learnt by deep learning techniques to\napproximate the shortest paths distances in large graphs. We show that a\nfeedforward neural network fed with embeddings can approximate distances with\nrelatively low distortion error. The suggested method is evaluated on the\nFacebook, BlogCatalog, Youtube and Flickr social networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:59:25 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Schloetterer", "Joerg", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.05259", "submitter": "Philip Bontrager", "authors": "Philip Bontrager and Julian Togelius", "title": "Fully Differentiable Procedural Content Generation through Generative\n  Playing Networks", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To procedurally create interactive content such as environments or game\nlevels, we need agents that can evaluate the content; but to train such agents,\nwe need content they can train on. Generative Playing Networks is a framework\nthat learns agent policies and generates environments in tandem through a\nsymbiotic process. Policies are learned using an actor-critic reinforcement\nlearning algorithm so as to master the environment, and environments are\ncreated by a generator network which tries to provide an appropriate level of\nchallenge for the agent. This is accomplished by the generator learning to make\ncontent based on estimates by the critic. Thus, this process provides an\nimplicit curriculum for the agent, creating more complex environments over\ntime. Unlike previous approaches to procedural content generation, Generative\nPlaying Networks is end-to-end differentiable and does not require\nhuman-designed examples or domain knowledge. We demonstrate the capability of\nthis framework by training an agent and level generator for a 2D dungeon\ncrawler game.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 22:07:23 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Bontrager", "Philip", ""], ["Togelius", "Julian", ""]]}, {"id": "2002.05262", "submitter": "Sajad Mousavi", "authors": "Sajad Mousavi, Fatemeh Afghah, and U. Rajendra Acharya", "title": "HAN-ECG: An Interpretable Atrial Fibrillation Detection Model Using\n  Hierarchical Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atrial fibrillation (AF) is one of the most prevalent cardiac arrhythmias\nthat affects the lives of more than 3 million people in the U.S. and over 33\nmillion people around the world and is associated with a five-fold increased\nrisk of stroke and mortality. like other problems in healthcare domain,\nartificial intelligence (AI)-based algorithms have been used to reliably detect\nAF from patients' physiological signals. The cardiologist level performance in\ndetecting this arrhythmia is often achieved by deep learning-based methods,\nhowever, they suffer from the lack of interpretability. In other words, these\napproaches are unable to explain the reasons behind their decisions. The lack\nof interpretability is a common challenge toward a wide application of machine\nlearning-based approaches in the healthcare which limits the trust of\nclinicians in such methods. To address this challenge, we propose HAN-ECG, an\ninterpretable bidirectional-recurrent-neural-network-based approach for the AF\ndetection task. The HAN-ECG employs three attention mechanism levels to provide\na multi-resolution analysis of the patterns in ECG leading to AF. The first\nlevel, wave level, computes the wave weights, the second level, heartbeat\nlevel, calculates the heartbeat weights, and third level, window (i.e.,\nmultiple heartbeats) level, produces the window weights in triggering a class\nof interest. The detected patterns by this hierarchical attention model\nfacilitate the interpretation of the neural network decision process in\nidentifying the patterns in the signal which contributed the most to the final\nprediction. Experimental results on two AF databases demonstrate that our\nproposed model performs significantly better than the existing algorithms.\nVisualization of these attention layers illustrates that our model decides upon\nthe important waves and heartbeats which are clinically meaningful in the\ndetection task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 22:23:06 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Mousavi", "Sajad", ""], ["Afghah", "Fatemeh", ""], ["Acharya", "U. Rajendra", ""]]}, {"id": "2002.05271", "submitter": "Min Chen", "authors": "Qianwen Wang, William Alexander, Jack Pegg, Huamin Qu, and Min Chen", "title": "HypoML: Visual Analysis for Hypothesis-based Evaluation of Machine\n  Learning Models", "comments": "This article was submitted to EuroVis 2020 on 5 December 2020. It was\n  not accepted. Because the reviews have not identified any technical problems\n  that would undermine the novelty and validity of this work, we think that the\n  article is ready to be released as an arXiv report. The EuroVis 2020 reviews\n  and authors' short feedback can be found in the anc folder", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, Feb.\n  2021", "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a visual analytics tool for enabling\nhypothesis-based evaluation of machine learning (ML) models. We describe a\nnovel ML-testing framework that combines the traditional statistical hypothesis\ntesting (commonly used in empirical research) with logical reasoning about the\nconclusions of multiple hypotheses. The framework defines a controlled\nconfiguration for testing a number of hypotheses as to whether and how some\nextra information about a \"concept\" or \"feature\" may benefit or hinder a ML\nmodel. Because reasoning multiple hypotheses is not always straightforward, we\nprovide HypoML as a visual analysis tool, with which, the multi-thread testing\ndata is transformed to a visual representation for rapid observation of the\nconclusions and the logical flow between the testing data and hypotheses.We\nhave applied HypoML to a number of hypothesized concepts, demonstrating the\nintuitive and explainable nature of the visual analysis.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:03:44 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Wang", "Qianwen", ""], ["Alexander", "William", ""], ["Pegg", "Jack", ""], ["Qu", "Huamin", ""], ["Chen", "Min", ""]]}, {"id": "2002.05273", "submitter": "Xiaoyu Li", "authors": "Xiaoyu Li, Zhenxun Zhuang, Francesco Orabona", "title": "A Second look at Exponential and Cosine Step Sizes: Simplicity,\n  Adaptivity, and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is a popular tool in training large-scale\nmachine learning models. Its performance, however, is highly variable,\ndepending crucially on the choice of the step sizes. Accordingly, a variety of\nstrategies for tuning the step sizes have been proposed, ranging from\ncoordinate-wise approaches (a.k.a. ``adaptive'' step sizes) to sophisticated\nheuristics to change the step size in each iteration. In this paper, we study\ntwo step size schedules whose power has been repeatedly confirmed in practice:\nthe exponential and the cosine step sizes. For the first time, we provide\ntheoretical support for them proving convergence rates for smooth non-convex\nfunctions, with and without the Polyak-\\L{}ojasiewicz (PL) condition. Moreover,\nwe show the surprising property that these two strategies are \\emph{adaptive}\nto the noise level in the stochastic gradients of PL functions. That is,\ncontrary to polynomial step sizes, they achieve almost optimal performance\nwithout needing to know the noise level nor tuning their hyperparameters based\non it. Finally, we conduct a fair and comprehensive empirical evaluation of\nreal-world datasets with deep learning architectures. Results show that, even\nif only requiring at most two hyperparameters to tune, these two strategies\nbest or match the performance of various finely-tuned state-of-the-art\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:10:38 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 15:22:38 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 19:27:19 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 18:26:34 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Li", "Xiaoyu", ""], ["Zhuang", "Zhenxun", ""], ["Orabona", "Francesco", ""]]}, {"id": "2002.05274", "submitter": "Han Zhang Mr", "authors": "Han Zhang, Fangyi Chen, Zhiqiang Shen, Qiqi Hao, Chenchen Zhu, Marios\n  Savvides", "title": "Solving Missing-Annotation Object Detection with Background\n  Recalibration Loss", "comments": "5 pages. Paper has been accepted by ICASSP 2020 for presentation in a\n  lecture (oral) session", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a novel and challenging detection scenario: A majority\nof true objects/instances is unlabeled in the datasets, so these\nmissing-labeled areas will be regarded as the background during training.\nPrevious art on this problem has proposed to use soft sampling to re-weight the\ngradients of RoIs based on the overlaps with positive instances, while their\nmethod is mainly based on the two-stage detector (i.e. Faster RCNN) which is\nmore robust and friendly for the missing label scenario. In this paper, we\nintroduce a superior solution called Background Recalibration Loss (BRL) that\ncan automatically re-calibrate the loss signals according to the pre-defined\nIoU threshold and input image. Our design is built on the one-stage detector\nwhich is faster and lighter. Inspired by the Focal Loss formulation, we make\nseveral significant modifications to fit on the missing-annotation\ncircumstance. We conduct extensive experiments on the curated PASCAL VOC and MS\nCOCO datasets. The results demonstrate that our proposed method outperforms the\nbaseline and other state-of-the-arts by a large margin. Code available:\nhttps://github.com/Dwrety/mmdetection-selective-iou.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:11:46 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 19:21:26 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhang", "Han", ""], ["Chen", "Fangyi", ""], ["Shen", "Zhiqiang", ""], ["Hao", "Qiqi", ""], ["Zhu", "Chenchen", ""], ["Savvides", "Marios", ""]]}, {"id": "2002.05283", "submitter": "Xiangning Chen", "authors": "Xiangning Chen, Cho-Jui Hsieh", "title": "Stabilizing Differentiable Architecture Search via Perturbation-based\n  Regularization", "comments": "ICML 2020, code is available at\n  https://github.com/xiangning-chen/SmoothDARTS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable architecture search (DARTS) is a prevailing NAS solution to\nidentify architectures. Based on the continuous relaxation of the architecture\nspace, DARTS learns a differentiable architecture weight and largely reduces\nthe search cost. However, its stability has been challenged for yielding\ndeteriorating architectures as the search proceeds. We find that the\nprecipitous validation loss landscape, which leads to a dramatic performance\ndrop when distilling the final architecture, is an essential factor that causes\ninstability. Based on this observation, we propose a perturbation-based\nregularization - SmoothDARTS (SDARTS), to smooth the loss landscape and improve\nthe generalizability of DARTS-based methods. In particular, our new\nformulations stabilize DARTS-based methods by either random smoothing or\nadversarial attack. The search trajectory on NAS-Bench-1Shot1 demonstrates the\neffectiveness of our approach and due to the improved stability, we achieve\nperformance gain across various search spaces on 4 datasets. Furthermore, we\nmathematically show that SDARTS implicitly regularizes the Hessian norm of the\nvalidation loss, which accounts for a smoother loss landscape and improved\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:46:58 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 21:56:42 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 19:17:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chen", "Xiangning", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.05287", "submitter": "Bingzhe Wei", "authors": "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, Bo Yang", "title": "Geom-GCN: Geometric Graph Convolutional Networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message-passing neural networks (MPNNs) have been successfully applied to\nrepresentation learning on graphs in a variety of real-world applications.\nHowever, two fundamental weaknesses of MPNNs' aggregators limit their ability\nto represent graph-structured data: losing the structural information of nodes\nin neighborhoods and lacking the ability to capture long-range dependencies in\ndisassortative graphs. Few studies have noticed the weaknesses from different\nperspectives. From the observations on classical neural network and network\ngeometry, we propose a novel geometric aggregation scheme for graph neural\nnetworks to overcome the two weaknesses. The behind basic idea is the\naggregation on a graph can benefit from a continuous space underlying the\ngraph. The proposed aggregation scheme is permutation-invariant and consists of\nthree modules, node embedding, structural neighborhood, and bi-level\naggregation. We also present an implementation of the scheme in graph\nconvolutional networks, termed Geom-GCN (Geometric Graph Convolutional\nNetworks), to perform transductive learning on graphs. Experimental results\nshow the proposed Geom-GCN achieved state-of-the-art performance on a wide\nrange of open datasets of graphs. Code is available at\nhttps://github.com/graphdml-uiuc-jlu/geom-gcn.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:03:09 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 01:47:35 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pei", "Hongbin", ""], ["Wei", "Bingzhe", ""], ["Chang", "Kevin Chen-Chuan", ""], ["Lei", "Yu", ""], ["Yang", "Bo", ""]]}, {"id": "2002.05289", "submitter": "Qin Ding Miss", "authors": "Qin Ding, Cho-Jui Hsieh, James Sharpnack", "title": "Multiscale Non-stationary Stochastic Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic contextual bandit algorithms for linear models, such as LinUCB,\nassume that the reward distribution for an arm is modeled by a stationary\nlinear regression. When the linear regression model is non-stationary over\ntime, the regret of LinUCB can scale linearly with time. In this paper, we\npropose a novel multiscale changepoint detection method for the non-stationary\nlinear bandit problems, called Multiscale-LinUCB, which actively adapts to the\nchanging environment. We also provide theoretical analysis of regret bound for\nMultiscale-LinUCB algorithm. Experimental results show that our proposed\nMultiscale-LinUCB algorithm outperforms other state-of-the-art algorithms in\nnon-stationary contextual environments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:24:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ding", "Qin", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "2002.05291", "submitter": "Mohammad Saeed Abrishami", "authors": "Mohammad Saeed Abrishami, Massoud Pedram, Shahin Nazarian", "title": "CSM-NN: Current Source Model Based Logic Circuit Simulation -- A Neural\n  Network Approach", "comments": "37th IEEE International Conference on Computer Design (ICCD), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The miniaturization of transistors down to 5nm and beyond, plus the\nincreasing complexity of integrated circuits, significantly aggravate short\nchannel effects, and demand analysis and optimization of more design corners\nand modes. Simulators need to model output variables related to circuit timing,\npower, noise, etc., which exhibit nonlinear behavior. The existing simulation\nand sign-off tools, based on a combination of closed-form expressions and\nlookup tables are either inaccurate or slow, when dealing with circuits with\nmore than billions of transistors. In this work, we present CSM-NN, a scalable\nsimulation framework with optimized neural network structures and processing\nalgorithms. CSM-NN is aimed at optimizing the simulation time by accounting for\nthe latency of the required memory query and computation, given the underlying\nCPU and GPU parallel processing capabilities. Experimental results show that\nCSM-NN reduces the simulation time by up to $6\\times$ compared to a\nstate-of-the-art current source model based simulator running on a CPU. This\nspeedup improves by up to $15\\times$ when running on a GPU. CSM-NN also\nprovides high accuracy levels, with less than $2\\%$ error, compared to HSPICE.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:29:44 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""], ["Nazarian", "Shahin", ""]]}, {"id": "2002.05292", "submitter": "Mohammad Saeed Abrishami", "authors": "Mohammad Saeed Abrishami, Hao Ge, Justin F. Calderon, Massoud Pedram,\n  Shahin Nazarian", "title": "NN-PARS: A Parallelized Neural Network Based Circuit Simulation\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shrinking of transistor geometries as well as the increasing complexity\nof integrated circuits, significantly aggravate nonlinear design behavior. This\ndemands accurate and fast circuit simulation to meet the design quality and\ntime-to-market constraints. The existing circuit simulators which utilize\nlookup tables and/or closed-form expressions are either slow or inaccurate in\nanalyzing the nonlinear behavior of designs with billions of transistors. To\naddress these shortcomings, we present NN-PARS, a neural network (NN) based and\nparallelized circuit simulation framework with optimized event-driven\nscheduling of simulation tasks to maximize concurrency, according to the\nunderlying GPU parallel processing capabilities. NN-PARS replaces the required\nmemory queries in traditional techniques with parallelized NN-based computation\ntasks. Experimental results show that compared to a state-of-the-art\ncurrent-based simulation method, NN-PARS reduces the simulation time by over\ntwo orders of magnitude in large circuits. NN-PARS also provides high accuracy\nlevels in signal waveform calculations, with less than $2\\%$ error compared to\nHSPICE.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:34:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Abrishami", "Mohammad Saeed", ""], ["Ge", "Hao", ""], ["Calderon", "Justin F.", ""], ["Pedram", "Massoud", ""], ["Nazarian", "Shahin", ""]]}, {"id": "2002.05293", "submitter": "Meng Li", "authors": "Meng Li and Yilei Li and Pierce Chuang and Liangzhen Lai and Vikas\n  Chandra", "title": "Improving Efficiency in Neural Network Accelerator Using Operands\n  Hamming Distance optimization", "comments": "12 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network accelerator is a key enabler for the on-device AI inference,\nfor which energy efficiency is an important metric. The data-path energy,\nincluding the computation energy and the data movement energy among the\narithmetic units, claims a significant part of the total accelerator energy. By\nrevisiting the basic physics of the arithmetic logic circuits, we show that the\ndata-path energy is highly correlated with the bit flips when streaming the\ninput operands into the arithmetic units, defined as the hamming distance of\nthe input operand matrices. Based on the insight, we propose a post-training\noptimization algorithm and a hamming-distance-aware training algorithm to\nco-design and co-optimize the accelerator and the network synergistically. The\nexperimental results based on post-layout simulation with MobileNetV2\ndemonstrate on average 2.85X data-path energy reduction and up to 8.51X\ndata-path energy reduction for certain layers.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:36:36 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Li", "Meng", ""], ["Li", "Yilei", ""], ["Chuang", "Pierce", ""], ["Lai", "Liangzhen", ""], ["Chandra", "Vikas", ""]]}, {"id": "2002.05295", "submitter": "Viet Lai", "authors": "Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen", "title": "Exploiting the Matching Information in the Support Set for Few Shot\n  Event Classification", "comments": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2020", "journal-ref": null, "doi": "10.1007/978-3-030-47436-2_18", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The existing event classification (EC) work primarily focuseson the\ntraditional supervised learning setting in which models are unableto extract\nevent mentions of new/unseen event types. Few-shot learninghas not been\ninvestigated in this area although it enables EC models toextend their\noperation to unobserved event types. To fill in this gap, inthis work, we\ninvestigate event classification under the few-shot learningsetting. We propose\na novel training method for this problem that exten-sively exploit the support\nset during the training process of a few-shotlearning model. In particular, in\naddition to matching the query exam-ple with those in the support set for\ntraining, we seek to further matchthe examples within the support set\nthemselves. This method providesmore training signals for the models and can be\napplied to every metric-learning-based few-shot learning methods. Our extensive\nexperiments ontwo benchmark EC datasets show that the proposed method can\nimprovethe best reported few-shot learning models by up to 10% on accuracyfor\nevent classification\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 00:40:36 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 07:37:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lai", "Viet Dac", ""], ["Dernoncourt", "Franck", ""], ["Nguyen", "Thien Huu", ""]]}, {"id": "2002.05304", "submitter": "Guang Cheng", "authors": "Yue Xing, Qifan Song, Guang Cheng", "title": "Predictive Power of Nearest Neighbors Algorithm under Random\n  Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a data corruption scenario in the classical $k$ Nearest Neighbors\n($k$-NN) algorithm, that is, the testing data are randomly perturbed. Under\nsuch a scenario, the impact of corruption level on the asymptotic regret is\ncarefully characterized. In particular, our theoretical analysis reveals a\nphase transition phenomenon that, when the corruption level $\\omega$ is below a\ncritical order (i.e., small-$\\omega$ regime), the asymptotic regret remains the\nsame; when it is beyond that order (i.e., large-$\\omega$ regime), the\nasymptotic regret deteriorates polynomially. Surprisingly, we obtain a negative\nresult that the classical noise-injection approach will not help improve the\ntesting performance in the beginning stage of the large-$\\omega$ regime, even\nin the level of the multiplicative constant of asymptotic regret. As a\ntechnical by-product, we prove that under different model assumptions, the\npre-processed 1-NN proposed in \\cite{xue2017achieving} will at most achieve a\nsub-optimal rate when the data dimension $d>4$ even if $k$ is chosen optimally\nin the pre-processing step.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 01:35:35 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xing", "Yue", ""], ["Song", "Qifan", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.05308", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Takuya Ishihara, Junya Honda, Yusuke Narita", "title": "Adaptive Experimental Design for Efficient Treatment Effect Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of many scientific experiments including A/B testing is to estimate\nthe average treatment effect (ATE), which is defined as the difference between\nthe expected outcomes of two or more treatments. In this paper, we consider a\nsituation where an experimenter can assign a treatment to research subjects\nsequentially. In adaptive experimental design, the experimenter is allowed to\nchange the probability of assigning a treatment using past observations for\nestimating the ATE efficiently. However, with this approach, it is difficult to\napply a standard statistical method to construct an estimator because the\nobservations are not independent and identically distributed. We thus propose\nan algorithm for efficient experiments with estimators constructed from\ndependent samples. We also introduce a sequential testing framework using the\nproposed estimator. To justify our proposed approach, we provide finite and\ninfinite sample analyses. Finally, we experimentally show that the proposed\nalgorithm exhibits preferable performance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:04:17 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:15:49 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:24:34 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kato", "Masahiro", ""], ["Ishihara", "Takuya", ""], ["Honda", "Junya", ""], ["Narita", "Yusuke", ""]]}, {"id": "2002.05309", "submitter": "Yan Yan", "authors": "Yan Yan and Yi Xu and Qihang Lin and Wei Liu and Tianbao Yang", "title": "Optimal Epoch Stochastic Gradient Descent Ascent Methods for Min-Max\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epoch gradient descent method (a.k.a. Epoch-GD) proposed by Hazan and Kale\n(2011) was deemed a breakthrough for stochastic strongly convex minimization,\nwhich achieves the optimal convergence rate of $O(1/T)$ with $T$ iterative\nupdates for the {\\it objective gap}. However, its extension to solving\nstochastic min-max problems with strong convexity and strong concavity still\nremains open, and it is still unclear whether a fast rate of $O(1/T)$ for the\n{\\it duality gap} is achievable for stochastic min-max optimization under\nstrong convexity and strong concavity. Although some recent studies have\nproposed stochastic algorithms with fast convergence rates for min-max\nproblems, they require additional assumptions about the problem, e.g.,\nsmoothness, bi-linear structure, etc. In this paper, we bridge this gap by\nproviding a sharp analysis of epoch-wise stochastic gradient descent ascent\nmethod (referred to as Epoch-GDA) for solving strongly convex strongly concave\n(SCSC) min-max problems, without imposing any additional assumption about\nsmoothness or the function's structure. To the best of our knowledge, our\nresult is the first one that shows Epoch-GDA can achieve the optimal rate of\n$O(1/T)$ for the duality gap of general SCSC min-max problems. We emphasize\nthat such generalization of Epoch-GD for strongly convex minimization problems\nto Epoch-GDA for SCSC min-max problems is non-trivial and requires novel\ntechnical analysis. Moreover, we notice that the key lemma can also be used for\nproving the convergence of Epoch-GDA for weakly-convex strongly-concave min-max\nproblems, leading to a nearly optimal complexity without resorting to\nsmoothness or other structural conditions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:16:57 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:02:49 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Yan", "Yan", ""], ["Xu", "Yi", ""], ["Lin", "Qihang", ""], ["Liu", "Wei", ""], ["Yang", "Tianbao", ""]]}, {"id": "2002.05314", "submitter": "Yifan Ding", "authors": "Yifan Ding, Yong Xu, Shi-Xiong Zhang, Yahuan Cong and Liqiang Wang", "title": "Self-supervised learning for audio-visual speaker diarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker diarization, which is to find the speech segments of specific\nspeakers, has been widely used in human-centered applications such as video\nconferences or human-computer interaction systems. In this paper, we propose a\nself-supervised audio-video synchronization learning method to address the\nproblem of speaker diarization without massive labeling effort. We improve the\nprevious approaches by introducing two new loss functions: the dynamic triplet\nloss and the multinomial loss. We test them on a real-world human-computer\ninteraction system and the results show our best model yields a remarkable gain\nof +8%F1-scoresas well as diarization error rate reduction. Finally, we\nintroduce a new large scale audio-video corpus designed to fill the vacancy of\naudio-video datasets in Chinese.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:36:32 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ding", "Yifan", ""], ["Xu", "Yong", ""], ["Zhang", "Shi-Xiong", ""], ["Cong", "Yahuan", ""], ["Wang", "Liqiang", ""]]}, {"id": "2002.05318", "submitter": "Guanya Shi", "authors": "Guanya Shi, Yiheng Lin, Soon-Jo Chung, Yisong Yue, Adam Wierman", "title": "Online Optimization with Memory and Competitive Control", "comments": "Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents competitive algorithms for a novel class of online\noptimization problems with memory. We consider a setting where the learner\nseeks to minimize the sum of a hitting cost and a switching cost that depends\non the previous $p$ decisions. This setting generalizes Smoothed Online Convex\nOptimization. The proposed approach, Optimistic Regularized Online Balanced\nDescent, achieves a constant, dimension-free competitive ratio. Further, we\nshow a connection between online optimization with memory and online control\nwith adversarial disturbances. This connection, in turn, leads to a new\nconstant-competitive policy for a rich class of online control problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 02:58:11 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 00:50:24 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 06:24:19 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Shi", "Guanya", ""], ["Lin", "Yiheng", ""], ["Chung", "Soon-Jo", ""], ["Yue", "Yisong", ""], ["Wierman", "Adam", ""]]}, {"id": "2002.05321", "submitter": "Shaojie Tang", "authors": "Shaojie Tang and Jing Yuan", "title": "Assortment Optimization with Repeated Exposures and Product-dependent\n  Patience Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the assortment optimization problem faced by many\nonline retailers such as Amazon. We develop a \\emph{cascade multinomial logit\nmodel}, based on the classic multinomial logit model, to capture the consumers'\npurchasing behavior across multiple stages. Different from existing studies,\nour model allows for repeated exposures of a product, i.e., the same product\ncan be displayed multiple times across different stages. In addition, each\nconsumer has a \\emph{patience budget} that is sampled from a known distribution\nand each product is associated with a \\emph{patience cost}, which captures the\ncognitive efforts spent on browsing that product. Given an assortment of\nproducts, a consumer sequentially browses them stage by stage. After browsing\nall products in one stage, if the utility of a product exceeds the utility of\nthe outside option, the consumer proceeds to purchase the product and leave the\nplatform. Otherwise, if the patience cost of all products browsed up to that\npoint is no larger than her patience budget, she continues to view the next\nstage. We propose an approximation solution to this problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 03:12:49 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:32:29 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Tang", "Shaojie", ""], ["Yuan", "Jing", ""]]}, {"id": "2002.05322", "submitter": "Ying Da Wang", "authors": "Ying Da Wang, Mehdi Shabaninejad, Ryan T. Armstrong, Peyman Mostaghimi", "title": "Physical Accuracy of Deep Neural Networks for 2D and 3D Multi-Mineral\n  Segmentation of Rock micro-CT Images", "comments": "16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of 3D micro-Computed Tomographic uCT) images of rock samples is\nessential for further Digital Rock Physics (DRP) analysis, however,\nconventional methods such as thresholding, watershed segmentation, and\nconverging active contours are susceptible to user-bias. Deep Convolutional\nNeural Networks (CNNs) have produced accurate pixelwise semantic segmentation\nresults with natural images and $\\mu$CT rock images, however, physical accuracy\nis not well documented. The performance of 4 CNN architectures is tested for 2D\nand 3D cases in 10 configurations. Manually segmented uCT images of Mt. Simon\nSandstone are treated as ground truth and used as training and validation data,\nwith a high voxelwise accuracy (over 99%) achieved. Downstream analysis is then\nused to validate physical accuracy. The topology of each segmented phase is\ncalculated, and the absolute permeability and multiphase flow is modelled with\ndirect simulation in single and mixed wetting cases. These physical measures of\nconnectivity, and flow characteristics show high variance and uncertainty, with\nmodels that achieve 95\\%+ in voxelwise accuracy possessing permeabilities and\nconnectivities orders of magnitude off. A new network architecture is also\nintroduced as a hybrid fusion of U-net and ResNet, combining short and long\nskip connections in a Network-in-Network configuration. The 3D implementation\noutperforms all other tested models in voxelwise and physical accuracy\nmeasures. The network architecture and the volume fraction in the dataset (and\nassociated weighting), are factors that not only influence the accuracy\ntrade-off in the voxelwise case, but is especially important in training a\nphysically accurate model for segmentation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 03:14:17 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 11:14:47 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Da Wang", "Ying", ""], ["Shabaninejad", "Mehdi", ""], ["Armstrong", "Ryan T.", ""], ["Mostaghimi", "Peyman", ""]]}, {"id": "2002.05350", "submitter": "Shuyuan Lin", "authors": "Shuyuan Lin, Guobao Xiao, Yan Yan, David Suter, Hanzi Wang", "title": "Hypergraph Optimization for Multi-structural Geometric Model Fitting", "comments": null, "journal-ref": null, "doi": "10.1609/aaai.v33i01.33018730", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some hypergraph-based methods have been proposed to deal with the\nproblem of model fitting in computer vision, mainly due to the superior\ncapability of hypergraph to represent the complex relationship between data\npoints. However, a hypergraph becomes extremely complicated when the input data\ninclude a large number of data points (usually contaminated with noises and\noutliers), which will significantly increase the computational burden. In order\nto overcome the above problem, we propose a novel hypergraph optimization based\nmodel fitting (HOMF) method to construct a simple but effective hypergraph.\nSpecifically, HOMF includes two main parts: an adaptive inlier estimation\nalgorithm for vertex optimization and an iterative hyperedge optimization\nalgorithm for hyperedge optimization. The proposed method is highly efficient,\nand it can obtain accurate model fitting results within a few iterations.\nMoreover, HOMF can then directly apply spectral clustering, to achieve good\nfitting performance. Extensive experimental results show that HOMF outperforms\nseveral state-of-the-art model fitting methods on both synthetic data and real\nimages, especially in sampling efficiency and in handling data with severe\noutliers.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 05:07:11 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Lin", "Shuyuan", ""], ["Xiao", "Guobao", ""], ["Yan", "Yan", ""], ["Suter", "David", ""], ["Wang", "Hanzi", ""]]}, {"id": "2002.05359", "submitter": "Samuel Horv\\'ath", "authors": "Samuel Horv\\'ath, Lihua Lei, Peter Richt\\'arik, Michael I. Jordan", "title": "Adaptivity of Stochastic Gradient Methods for Nonconvex Optimization", "comments": "11 pages, 4 Figures, 20 pages Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptivity is an important yet under-studied property in modern optimization\ntheory. The gap between the state-of-the-art theory and the current practice is\nstriking in that algorithms with desirable theoretical guarantees typically\ninvolve drastically different settings of hyperparameters, such as step-size\nschemes and batch sizes, in different regimes. Despite the appealing\ntheoretical results, such divisive strategies provide little, if any, insight\nto practitioners to select algorithms that work broadly without tweaking the\nhyperparameters. In this work, blending the \"geometrization\" technique\nintroduced by Lei & Jordan 2016 and the \\texttt{SARAH} algorithm of Nguyen et\nal., 2017, we propose the Geometrized \\texttt{SARAH} algorithm for non-convex\nfinite-sum and stochastic optimization. Our algorithm is proved to achieve\nadaptivity to both the magnitude of the target accuracy and the\nPolyak-\\L{}ojasiewicz (PL) constant if present. In addition, it achieves the\nbest-available convergence rate for non-PL objectives simultaneously while\noutperforming existing algorithms for PL objectives.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 05:42:27 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Horv\u00e1th", "Samuel", ""], ["Lei", "Lihua", ""], ["Richt\u00e1rik", "Peter", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.05364", "submitter": "Yuan-Gen Wang", "authors": "Pei-Gen Ye, Yuan-Gen Wang, Jin Li, Liang Xiao", "title": "Fast Reinforcement Learning for Anti-jamming Communications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter presents a fast reinforcement learning algorithm for anti-jamming\ncommunications which chooses previous action with probability $\\tau$ and\napplies $\\epsilon$-greedy with probability $(1-\\tau)$. A dynamic threshold\nbased on the average value of previous several actions is designed and\nprobability $\\tau$ is formulated as a Gaussian-like function to guide the\nwireless devices. As a concrete example, the proposed algorithm is implemented\nin a wireless communication system against multiple jammers. Experimental\nresults demonstrate that the proposed algorithm exceeds Q-learing, deep\nQ-networks (DQN), double DQN (DDQN), and prioritized experience reply based\nDDQN (PDDQN), in terms of signal-to-interference-plus-noise ratio and\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 06:37:27 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ye", "Pei-Gen", ""], ["Wang", "Yuan-Gen", ""], ["Li", "Jin", ""], ["Xiao", "Liang", ""]]}, {"id": "2002.05366", "submitter": "Taejong Joo", "authors": "Taejong Joo, Donggu Kang, Byunghoon Kim", "title": "Regularizing activations in neural networks via distribution matching\n  with the Wasserstein metric", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization and normalization have become indispensable components in\ntraining deep neural networks, resulting in faster training and improved\ngeneralization performance. We propose the projected error function\nregularization loss (PER) that encourages activations to follow the standard\nnormal distribution. PER randomly projects activations onto one-dimensional\nspace and computes the regularization loss in the projected space. PER is\nsimilar to the Pseudo-Huber loss in the projected space, thus taking advantage\nof both $L^1$ and $L^2$ regularization losses. Besides, PER can capture the\ninteraction between hidden units by projection vector drawn from a unit sphere.\nBy doing so, PER minimizes the upper bound of the Wasserstein distance of order\none between an empirical distribution of activations and the standard normal\ndistribution. To the best of the authors' knowledge, this is the first work to\nregularize activations via distribution matching in the probability\ndistribution space. We evaluate the proposed method on the image classification\ntask and the word-level language modeling task.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 06:42:01 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 02:31:16 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Joo", "Taejong", ""], ["Kang", "Donggu", ""], ["Kim", "Byunghoon", ""]]}, {"id": "2002.05368", "submitter": "Risto Miikkulainen", "authors": "Olivier Francon, Santiago Gonzalez, Babak Hodjat, Elliot Meyerson,\n  Risto Miikkulainen, Xin Qiu, and Hormoz Shahrzad", "title": "Effective Reinforcement Learning through Evolutionary Surrogate-Assisted\n  Prescription", "comments": null, "journal-ref": "Proceedings of the Genetic and Evolutionary Computation Conference\n  (GECCO-2020)", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is now significant historical data available on decision making in\norganizations, consisting of the decision problem, what decisions were made,\nand how desirable the outcomes were. Using this data, it is possible to learn a\nsurrogate model, and with that model, evolve a decision strategy that optimizes\nthe outcomes. This paper introduces a general such approach, called\nEvolutionary Surrogate-Assisted Prescription, or ESP. The surrogate is, for\nexample, a random forest or a neural network trained with gradient descent, and\nthe strategy is a neural network that is evolved to maximize the predictions of\nthe surrogate model. ESP is further extended in this paper to sequential\ndecision-making tasks, which makes it possible to evaluate the framework in\nreinforcement learning (RL) benchmarks. Because the majority of evaluations are\ndone on the surrogate, ESP is more sample efficient, has lower variance, and\nlower regret than standard RL approaches. Surprisingly, its solutions are also\nbetter because both the surrogate and the strategy network regularize the\ndecision-making behavior. ESP thus forms a promising foundation to decision\noptimization in real-world problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 06:59:26 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 03:27:46 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Francon", "Olivier", ""], ["Gonzalez", "Santiago", ""], ["Hodjat", "Babak", ""], ["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""], ["Qiu", "Xin", ""], ["Shahrzad", "Hormoz", ""]]}, {"id": "2002.05373", "submitter": "Usman Khan", "authors": "Ran Xin, Soummya Kar, Usman A. Khan", "title": "Gradient tracking and variance reduction for decentralized optimization\n  and machine learning", "comments": "accepted for publication, IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized methods to solve finite-sum minimization problems are important\nin many signal processing and machine learning tasks where the data is\ndistributed over a network of nodes and raw data sharing is not permitted due\nto privacy and/or resource constraints. In this article, we review\ndecentralized stochastic first-order methods and provide a unified algorithmic\nframework that combines variance-reduction with gradient tracking to achieve\nboth robust performance and fast convergence. We provide explicit theoretical\nguarantees of the corresponding methods when the objective functions are smooth\nand strongly-convex, and show their applicability to non-convex problems via\nnumerical experiments. Throughout the article, we provide intuitive\nillustrations of the main technical ideas by casting appropriate tradeoffs and\ncomparisons among the methods of interest and by highlighting applications to\ndecentralized training of machine learning models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:17:07 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "2002.05377", "submitter": "Rafael Dowsley", "authors": "Martine De Cock and Rafael Dowsley and Anderson C. A. Nascimento and\n  Davis Railsback and Jianwei Shen and Ariel Todoki", "title": "High Performance Logistic Regression for Privacy-Preserving Genome\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a secure logistic regression training protocol and\nits implementation, with a new subprotocol to securely compute the activation\nfunction. To the best of our knowledge, we present the fastest existing secure\nMulti-Party Computation implementation for training logistic regression models\non high dimensional genome data distributed across a local area network.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:37:08 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 11:00:01 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["De Cock", "Martine", ""], ["Dowsley", "Rafael", ""], ["Nascimento", "Anderson C. A.", ""], ["Railsback", "Davis", ""], ["Shen", "Jianwei", ""], ["Todoki", "Ariel", ""]]}, {"id": "2002.05378", "submitter": "Sutanu Gayen", "authors": "Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S. Meel, N. V.\n  Vinodchandran", "title": "Efficient Distance Approximation for Structured High-Dimensional\n  Distributions via Learning", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design efficient distance approximation algorithms for several classes of\nstructured high-dimensional distributions. Specifically, we show algorithms for\nthe following problems:\n  - Given sample access to two Bayesian networks $P_1$ and $P_2$ over known\ndirected acyclic graphs $G_1$ and $G_2$ having $n$ nodes and bounded in-degree,\napproximate $d_{tv}(P_1,P_2)$ to within additive error $\\epsilon$ using\n$poly(n,\\epsilon)$ samples and time\n  - Given sample access to two ferromagnetic Ising models $P_1$ and $P_2$ on\n$n$ variables with bounded width, approximate $d_{tv}(P_1, P_2)$ to within\nadditive error $\\epsilon$ using $poly(n,\\epsilon)$ samples and time\n  - Given sample access to two $n$-dimensional Gaussians $P_1$ and $P_2$,\napproximate $d_{tv}(P_1, P_2)$ to within additive error $\\epsilon$ using\n$poly(n,\\epsilon)$ samples and time\n  - Given access to observations from two causal models $P$ and $Q$ on $n$\nvariables that are defined over known causal graphs, approximate $d_{tv}(P_a,\nQ_a)$ to within additive error $\\epsilon$ using $poly(n,\\epsilon)$ samples,\nwhere $P_a$ and $Q_a$ are the interventional distributions obtained by the\nintervention $do(A=a)$ on $P$ and $Q$ respectively for a particular variable\n$A$.\n  Our results are the first efficient distance approximation algorithms for\nthese well-studied problems. They are derived using a simple and general\nconnection to distribution learning algorithms. The distance approximation\nalgorithms imply new efficient algorithms for {\\em tolerant} testing of\ncloseness of the above-mentioned structured high-dimensional distributions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:42:06 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 03:03:10 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bhattacharyya", "Arnab", ""], ["Gayen", "Sutanu", ""], ["Meel", "Kuldeep S.", ""], ["Vinodchandran", "N. V.", ""]]}, {"id": "2002.05379", "submitter": "Ian Fischer", "authors": "Ian Fischer", "title": "The Conditional Entropy Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the field of Machine Learning exhibits a prominent set of failure\nmodes, including vulnerability to adversarial examples, poor\nout-of-distribution (OoD) detection, miscalibration, and willingness to\nmemorize random labelings of datasets. We characterize these as failures of\nrobust generalization, which extends the traditional measure of generalization\nas accuracy or related metrics on a held-out set. We hypothesize that these\nfailures to robustly generalize are due to the learning systems retaining too\nmuch information about the training data. To test this hypothesis, we propose\nthe Minimum Necessary Information (MNI) criterion for evaluating the quality of\na model. In order to train models that perform well with respect to the MNI\ncriterion, we present a new objective function, the Conditional Entropy\nBottleneck (CEB), which is closely related to the Information Bottleneck (IB).\nWe experimentally test our hypothesis by comparing the performance of CEB\nmodels with deterministic models and Variational Information Bottleneck (VIB)\nmodels on a variety of different datasets and robustness challenges. We find\nstrong empirical evidence supporting our hypothesis that MNI models improve on\nthese problems of robust generalization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:46:38 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Fischer", "Ian", ""]]}, {"id": "2002.05380", "submitter": "Ian Fischer", "authors": "Ian Fischer and Alexander A. Alemi", "title": "CEB Improves Model Robustness", "comments": null, "journal-ref": null, "doi": "10.3390/e22101081", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that the Conditional Entropy Bottleneck (CEB) can improve\nmodel robustness. CEB is an easy strategy to implement and works in tandem with\ndata augmentation procedures. We report results of a large scale adversarial\nrobustness study on CIFAR-10, as well as the ImageNet-C Common Corruptions\nBenchmark, ImageNet-A, and PGD attacks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 07:49:22 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Fischer", "Ian", ""], ["Alemi", "Alexander A.", ""]]}, {"id": "2002.05392", "submitter": "Nadav Merlis", "authors": "Nadav Merlis, Shie Mannor", "title": "Tight Lower Bounds for Combinatorial Multi-Armed Bandits", "comments": "Accepted to COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Combinatorial Multi-Armed Bandit problem is a sequential decision-making\nproblem in which an agent selects a set of arms on each round, observes\nfeedback for each of these arms and aims to maximize a known reward function of\nthe arms it chose. While previous work proved regret upper bounds in this\nsetting for general reward functions, only a few works provided matching lower\nbounds, all for specific reward functions. In this work, we prove regret lower\nbounds for combinatorial bandits that hold under mild assumptions for all\nsmooth reward functions. We derive both problem-dependent and\nproblem-independent bounds and show that the recently proposed Gini-weighted\nsmoothness parameter (Merlis and Mannor, 2019) also determines the lower bounds\nfor monotone reward functions. Notably, this implies that our lower bounds are\ntight up to log-factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 08:53:43 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 12:00:09 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 11:26:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Merlis", "Nadav", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.05397", "submitter": "Johan Simonsson", "authors": "Johan Simonsson, Khalid Tourkey Atta, Dave Zachariah, Wolfgang Birk", "title": "A latent variable approach to heat load prediction in thermal grids", "comments": "Paper submitted to 2020 European Control Conference, Saint\n  Petersburg, Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new method for heat load prediction in district energy\nsystems is proposed. The method uses a nominal model for the prediction of the\noutdoor temperature dependent space heating load, and a data driven latent\nvariable model to predict the time dependent residual heat load. The residual\nheat load arises mainly from time dependent operation of space heating and\nventilation, and domestic hot water production. The resulting model is\nrecursively updated on the basis of a hyper-parameter free implementation that\nresults in a parsimonious model allowing for high computational performance.\nThe approach is applied to a single multi-dwelling building in Lulea, Sweden,\npredicting the heat load using a relatively small number of model parameters\nand easily obtained measurements. The results are compared with predictions\nusing an artificial neural network, showing that the proposed method achieves\nbetter prediction accuracy for the validation case. Additionally, the proposed\nmethods exhibits explainable behavior through the use of an interpretable\nphysical model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:21:17 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Simonsson", "Johan", ""], ["Atta", "Khalid Tourkey", ""], ["Zachariah", "Dave", ""], ["Birk", "Wolfgang", ""]]}, {"id": "2002.05398", "submitter": "Sebastian Scher", "authors": "Sebastian Scher and Gabriele Messori", "title": "Ensemble methods for neural network-based weather forecasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble weather forecasts enable a measure of uncertainty to be attached to\neach forecast, by computing the ensemble's spread. However, generating an\nensemble with a good spread-error relationship is far from trivial, and a wide\nrange of approaches to achieve this have been explored -- chiefly in the\ncontext of numerical weather prediction models. Here, we aim to transform a\ndeterministic neural network weather forecasting system into an ensemble\nforecasting system. We test four methods to generate the ensemble: random\ninitial perturbations, retraining of the neural network, use of random dropout\nin the network, and the creation of initial perturbations with singular vector\ndecomposition. The latter method is widely used in numerical weather prediction\nmodels, but is yet to be tested on neural networks. The ensemble mean forecasts\nobtained from these four approaches all beat the unperturbed neural network\nforecasts, with the retraining method yielding the highest improvement.\nHowever, the skill of the neural network forecasts is systematically lower than\nthat of state-of-the-art numerical weather prediction models.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:28:21 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 17:34:59 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 13:19:14 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Scher", "Sebastian", ""], ["Messori", "Gabriele", ""]]}, {"id": "2002.05406", "submitter": "Josef Urban", "authors": "Jan Jakub\\r{u}v, Karel Chvalovsk\\'y, Miroslav Ol\\v{s}\\'ak, Bartosz\n  Piotrowski, Martin Suda, Josef Urban", "title": "ENIGMA Anonymous: Symbol-Independent Inference Guiding Machine (system\n  description)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an implementation of gradient boosting and neural guidance of\nsaturation-style automated theorem provers that does not depend on consistent\nsymbol names across problems. For the gradient-boosting guidance, we manually\ncreate abstracted features by considering arity-based encodings of formulas.\nFor the neural guidance, we use symbol-independent graph neural networks (GNNs)\nand their embedding of the terms and clauses. The two methods are efficiently\nimplemented in the E prover and its ENIGMA learning-guided framework.\n  To provide competitive real-time performance of the GNNs, we have developed a\nnew context-based approach to evaluation of generated clauses in E. Clauses are\nevaluated jointly in larger batches and with respect to a large number of\nalready selected clauses (context) by the GNN that estimates their collectively\nmost useful subset in several rounds of message passing. This means that\napproximative inference rounds done by the GNN are efficiently interleaved with\nprecise symbolic inference rounds done inside E. The methods are evaluated on\nthe MPTP large-theory benchmark and shown to achieve comparable real-time\nperformance to state-of-the-art symbol-based methods. The methods also show\nhigh complementarity, solving a large number of hard Mizar problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:44:38 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:59:26 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jakub\u016fv", "Jan", ""], ["Chvalovsk\u00fd", "Karel", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Piotrowski", "Bartosz", ""], ["Suda", "Martin", ""], ["Urban", "Josef", ""]]}, {"id": "2002.05411", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "C. D. Rios-Urrego, J. C. V\\'asquez-Correa, J. F. Vargas-Bonilla, E.\n  N\\\"oth, F. Lopera, J. R. Orozco-Arroyave", "title": "Analysis and Evaluation of Handwriting in Patients with Parkinson's\n  Disease Using kinematic, Geometrical, and Non-linear Features", "comments": null, "journal-ref": "Computer methods and programs in biomedicine, 173, 43-52 (2019)", "doi": "10.1016/j.cmpb.2019.03.005", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and objectives: Parkinson's disease is a neurological disorder\nthat affects the motor system producing lack of coordination, resting tremor,\nand rigidity. Impairments in handwriting are among the main symptoms of the\ndisease. Handwriting analysis can help in supporting the diagnosis and in\nmonitoring the progress of the disease. This paper aims to evaluate the\nimportance of different groups of features to model handwriting deficits that\nappear due to Parkinson's disease; and how those features are able to\ndiscriminate between Parkinson's disease patients and healthy subjects.\n  Methods: Features based on kinematic, geometrical and non-linear dynamics\nanalyses were evaluated to classify Parkinson's disease and healthy subjects.\nClassifiers based on K-nearest neighbors, support vector machines, and random\nforest were considered.\n  Results: Accuracies of up to $93.1\\%$ were obtained in the classification of\npatients and healthy control subjects. A relevance analysis of the features\nindicated that those related to speed, acceleration, and pressure are the most\ndiscriminant. The automatic classification of patients in different stages of\nthe disease shows $\\kappa$ indexes between $0.36$ and $0.44$. Accuracies of up\nto $83.3\\%$ were obtained in a different dataset used only for validation\npurposes.\n  Conclusions: The results confirmed the negative impact of aging in the\nclassification process when we considered different groups of healthy subjects.\nIn addition, the results reported with the separate validation set comprise a\nstep towards the development of automated tools to support the diagnosis\nprocess in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:54:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Rios-Urrego", "C. D.", ""], ["V\u00e1squez-Correa", "J. C.", ""], ["Vargas-Bonilla", "J. F.", ""], ["N\u00f6th", "E.", ""], ["Lopera", "F.", ""], ["Orozco-Arroyave", "J. R.", ""]]}, {"id": "2002.05412", "submitter": "Juan Camilo V\\'asquez-Correa", "authors": "J. C. Vasquez-Correa, T. Bocklet, J. R. Orozco-Arroyave, E. N\\\"oth", "title": "Comparison of user models based on GMM-UBM and i-vectors for speech,\n  handwriting, and gait assessment of Parkinson's disease patients", "comments": "Proceedings of ICASSP (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parkinson's disease is a neurodegenerative disorder characterized by the\npresence of different motor impairments. Information from speech, handwriting,\nand gait signals have been considered to evaluate the neurological state of the\npatients. On the other hand, user models based on Gaussian mixture models -\nuniversal background models (GMM-UBM) and i-vectors are considered the\nstate-of-the-art in biometric applications like speaker verification because\nthey are able to model specific speaker traits. This study introduces the use\nof GMM-UBM and i-vectors to evaluate the neurological state of Parkinson's\npatients using information from speech, handwriting, and gait. The results show\nthe importance of different feature sets from each type of signal in the\nassessment of the neurological state of the patients.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:01:08 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Vasquez-Correa", "J. C.", ""], ["Bocklet", "T.", ""], ["Orozco-Arroyave", "J. R.", ""], ["N\u00f6th", "E.", ""]]}, {"id": "2002.05424", "submitter": "Carlo Ciliberto", "authors": "Carlo Ciliberto, Lorenzo Rosasco, Alessandro Rudi", "title": "A General Framework for Consistent Structured Prediction with Implicit\n  Loss Embeddings", "comments": "53 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a novel theoretical and algorithmic framework for\nstructured prediction. While so far the term has referred to discrete output\nspaces, here we consider more general settings, such as manifolds or spaces of\nprobability measures. We define structured prediction as a problem where the\noutput space lacks a vectorial structure. We identify and study a large class\nof loss functions that implicitly defines a suitable geometry on the problem.\nThe latter is the key to develop an algorithmic framework amenable to a sharp\nstatistical analysis and yielding efficient computations. When dealing with\noutput spaces with infinite cardinality, a suitable implicit formulation of the\nestimator is shown to be crucial.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:30:04 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ciliberto", "Carlo", ""], ["Rosasco", "Lorenzo", ""], ["Rudi", "Alessandro", ""]]}, {"id": "2002.05426", "submitter": "Ramona Leenings", "authors": "Ramona Leenings, Nils Ralf Winter, Lucas Plagwitz, Vincent Holstein,\n  Jan Ernsting, Jakob Steenweg, Julian Gebker, Kelvin Sarink, Daniel Emden,\n  Dominik Grotegerd, Nils Opel, Benjamin Risse, Xiaoyi Jiang, Udo Dannlowski,\n  Tim Hahn", "title": "PHOTONAI -- A Python API for Rapid Machine Learning Model Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PHOTONAI is a high-level Python API designed to simplify and accelerate\nmachine learning model development. It functions as a unifying framework\nallowing the user to easily access and combine algorithms from different\ntoolboxes into custom algorithm sequences. It is especially designed to support\nthe iterative model development process and automates the repetitive training,\nhyperparameter optimization and evaluation tasks. Importantly, the workflow\nensures unbiased performance estimates while still allowing the user to fully\ncustomize the machine learning analysis. PHOTONAI extends existing solutions\nwith a novel pipeline implementation supporting more complex data streams,\nfeature combinations, and algorithm selection. Metrics and results can be\nconveniently visualized using the PHOTONAI Explorer and predictive models are\nshareable in a standardized format for further external validation or\napplication. A growing add-on ecosystem allows researchers to offer data\nmodality specific algorithms to the community and enhance machine learning in\nthe areas of the life sciences. Its practical utility is demonstrated on an\nexemplary medical machine learning problem, achieving a state-of-the-art\nsolution in few lines of code. Source code is publicly available on Github,\nwhile examples and documentation can be found at www.photon-ai.com.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:33:05 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 13:05:32 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 09:29:35 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 14:34:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Leenings", "Ramona", ""], ["Winter", "Nils Ralf", ""], ["Plagwitz", "Lucas", ""], ["Holstein", "Vincent", ""], ["Ernsting", "Jan", ""], ["Steenweg", "Jakob", ""], ["Gebker", "Julian", ""], ["Sarink", "Kelvin", ""], ["Emden", "Daniel", ""], ["Grotegerd", "Dominik", ""], ["Opel", "Nils", ""], ["Risse", "Benjamin", ""], ["Jiang", "Xiaoyi", ""], ["Dannlowski", "Udo", ""], ["Hahn", "Tim", ""]]}, {"id": "2002.05432", "submitter": "Ramona Leenings", "authors": "Ramona Leenings, Nils Ralf Winter, Kelvin Sarink, Jan Ernsting, Xiaoyi\n  Jiang, Udo Dannlowski, Tim Hahn", "title": "The PHOTON Wizard -- Towards Educational Machine Learning Code\n  Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous efforts to democratize machine learning, especially in\napplied-science, the application is still often hampered by the lack of coding\nskills. As we consider programmatic understanding key to building effective and\nefficient machine learning solutions, we argue for a novel educational approach\nthat builds upon the accessibility and acceptance of graphical user interfaces\nto convey programming skills to an applied-science target group. We outline a\nproof-of-concept, open-source web application, the PHOTON Wizard, which\ndynamically translates GUI interactions into valid source code for the Python\nmachine learning framework PHOTON. Thereby, users possessing theoretical\nmachine learning knowledge gain key insights into the model development\nworkflow as well as an intuitive understanding of custom implementations.\nSpecifically, the PHOTON Wizard integrates the concept of Educational Machine\nLearning Code Generators to teach users how to write code for designing,\ntraining, optimizing and evaluating custom machine learning pipelines.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 10:42:39 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Leenings", "Ramona", ""], ["Winter", "Nils Ralf", ""], ["Sarink", "Kelvin", ""], ["Ernsting", "Jan", ""], ["Jiang", "Xiaoyi", ""], ["Dannlowski", "Udo", ""], ["Hahn", "Tim", ""]]}, {"id": "2002.05442", "submitter": "Triet Le", "authors": "Triet H. M. Le, Hao Chen, M. Ali Babar", "title": "Deep Learning for Source Code Modeling and Generation: Models,\n  Applications and Challenges", "comments": null, "journal-ref": "ACM Comput. Surv., 53, 3 (2020), Article 62", "doi": "10.1145/3383458", "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) techniques for Natural Language Processing have been\nevolving remarkably fast. Recently, the DL advances in language modeling,\nmachine translation and paragraph understanding are so prominent that the\npotential of DL in Software Engineering cannot be overlooked, especially in the\nfield of program learning. To facilitate further research and applications of\nDL in this field, we provide a comprehensive review to categorize and\ninvestigate existing DL methods for source code modeling and generation. To\naddress the limitations of the traditional source code models, we formulate\ncommon program learning tasks under an encoder-decoder framework. After that,\nwe introduce recent DL mechanisms suitable to solve such problems. Then, we\npresent the state-of-the-art practices and discuss their challenges with some\nrecommendations for practitioners and researchers as well.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:02:51 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Le", "Triet H. M.", ""], ["Chen", "Hao", ""], ["Babar", "M. Ali", ""]]}, {"id": "2002.05459", "submitter": "Abdulkadir Gokce", "authors": "Yasin Almalioglu, Kutsev Bengisu Ozyoruk, Abdulkadir Gokce, Kagan\n  Incetan, Guliz Irem Gokceler, Muhammed Ali Simsek, Kivanc Ararat, Richard J.\n  Chen, Nicholas J. Durr, Faisal Mahmood, Mehmet Turan", "title": "EndoL2H: Deep Super-Resolution for Capsule Endoscopy", "comments": "23 pages, submitted to IEEE Transactions on Medical Imaging,\n  corresponding Author: Mehmet Turan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although wireless capsule endoscopy is the preferred modality for diagnosis\nand assessment of small bowel diseases, the poor camera resolution is a\nsubstantial limitation for both subjective and automated diagnostics.\nEnhanced-resolution endoscopy has shown to improve adenoma detection rate for\nconventional endoscopy and is likely to do the same for capsule endoscopy. In\nthis work, we propose and quantitatively validate a novel framework to learn a\nmapping from low-to-high resolution endoscopic images. We combine conditional\nadversarial networks with a spatial attention block to improve the resolution\nby up to factors of 8x, 10x, 12x, respectively. Quantitative and qualitative\nstudies performed demonstrate the superiority of EndoL2H over state-of-the-art\ndeep super-resolution methods DBPN, RCAN and SRGAN. MOS tests performed by 30\ngastroenterologists qualitatively assess and confirm the clinical relevance of\nthe approach. EndoL2H is generally applicable to any endoscopic capsule system\nand has the potential to improve diagnosis and better harness computational\napproaches for polyp detection and characterization. Our code and trained\nmodels are available at https://github.com/CapsuleEndoscope/EndoL2H.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:52:47 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 19:18:33 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Almalioglu", "Yasin", ""], ["Ozyoruk", "Kutsev Bengisu", ""], ["Gokce", "Abdulkadir", ""], ["Incetan", "Kagan", ""], ["Gokceler", "Guliz Irem", ""], ["Simsek", "Muhammed Ali", ""], ["Ararat", "Kivanc", ""], ["Chen", "Richard J.", ""], ["Durr", "Nicholas J.", ""], ["Mahmood", "Faisal", ""], ["Turan", "Mehmet", ""]]}, {"id": "2002.05462", "submitter": "Bark{\\i}n Tuncer", "authors": "Bark{\\i}n Tuncer, Murat Kumru, Emre \\\"Ozkan", "title": "Extended Target Tracking and Classification Using Neural Networks", "comments": null, "journal-ref": "22nd International Conference on Information Fusion, 2019", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended target/object tracking (ETT) problem involves tracking objects which\npotentially generate multiple measurements at a single sensor scan.\nState-of-the-art ETT algorithms can efficiently exploit the available\ninformation in these measurements such that they can track the dynamic\nbehaviour of objects and learn their shapes simultaneously. Once the shape\nestimate of an object is formed, it can naturally be utilized by high-level\ntasks such as classification of the object type. In this work, we propose to\nuse a naively deep neural network, which consists of one input, two hidden and\none output layers, to classify dynamic objects regarding their shape estimates.\nThe proposed method shows superior performance in comparison to a Bayesian\nclassifier for simulation experiments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:02:52 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Tuncer", "Bark\u0131n", ""], ["Kumru", "Murat", ""], ["\u00d6zkan", "Emre", ""]]}, {"id": "2002.05463", "submitter": "Victor Akinwande", "authors": "Victor Akinwande, Celia Cintas, Skyler Speakman, Srihari Sridharan", "title": "Identifying Audio Adversarial Examples via Anomalous Pattern Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio processing models based on deep neural networks are susceptible to\nadversarial attacks even when the adversarial audio waveform is 99.9% similar\nto a benign sample. Given the wide application of DNN-based audio recognition\nsystems, detecting the presence of adversarial examples is of high practical\nrelevance. By applying anomalous pattern detection techniques in the activation\nspace of these models, we show that 2 of the recent and current\nstate-of-the-art adversarial attacks on audio processing systems systematically\nlead to higher-than-expected activation at some subset of nodes and we can\ndetect these with up to an AUC of 0.98 with no degradation in performance on\nbenign samples.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:08:34 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 06:25:22 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Akinwande", "Victor", ""], ["Cintas", "Celia", ""], ["Speakman", "Skyler", ""], ["Sridharan", "Srihari", ""]]}, {"id": "2002.05466", "submitter": "Vien Van Mai", "authors": "Vien V. Mai and Mikael Johansson", "title": "Convergence of a Stochastic Gradient Method with Momentum for Non-Smooth\n  Non-Convex Optimization", "comments": "ICML-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient methods with momentum are widely used in applications and\nat the core of optimization subroutines in many popular machine learning\nlibraries. However, their sample complexities have not been obtained for\nproblems beyond those that are convex or smooth. This paper establishes the\nconvergence rate of a stochastic subgradient method with a momentum term of\nPolyak type for a broad class of non-smooth, non-convex, and constrained\noptimization problems. Our key innovation is the construction of a special\nLyapunov function for which the proven complexity can be achieved without any\ntuning of the momentum parameter. For smooth problems, we extend the known\ncomplexity bound to the constrained case and demonstrate how the unconstrained\ncase can be analyzed under weaker assumptions than the state-of-the-art.\nNumerical results confirm our theoretical developments.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:10:17 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:52:42 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Mai", "Vien V.", ""], ["Johansson", "Mikael", ""]]}, {"id": "2002.05474", "submitter": "Christopher Jung", "authors": "Yahav Bechavod, Christopher Jung, Zhiwei Steven Wu", "title": "Metric-Free Individual Fairness in Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an online learning problem subject to the constraint of individual\nfairness, which requires that similar individuals are treated similarly. Unlike\nprior work on individual fairness, we do not assume the similarity measure\namong individuals is known, nor do we assume that such measure takes a certain\nparametric form. Instead, we leverage the existence of an auditor who detects\nfairness violations without enunciating the quantitative measure. In each\nround, the auditor examines the learner's decisions and attempts to identify a\npair of individuals that are treated unfairly by the learner. We provide a\ngeneral reduction framework that reduces online classification in our model to\nstandard online classification, which allows us to leverage existing online\nlearning algorithms to achieve sub-linear regret and number of fairness\nviolations. Surprisingly, in the stochastic setting where the data are drawn\nindependently from a distribution, we are also able to establish PAC-style\nfairness and accuracy generalization guarantees (Yona and Rothblum [2018]),\ndespite only having access to a very restricted form of fairness feedback. Our\nfairness generalization bound qualitatively matches the uniform convergence\nbound of Yona and Rothblum [2018], while also providing a meaningful accuracy\ngeneralization guarantee. Our results resolve an open question by Gillen et al.\n[2018] by showing that online learning under an unknown individual fairness\nconstraint is possible even without assuming a strong parametric form of the\nunderlying similarity measure.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:25:27 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 16:34:03 GMT"}, {"version": "v3", "created": "Sun, 24 Jan 2021 14:39:52 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bechavod", "Yahav", ""], ["Jung", "Christopher", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.05477", "submitter": "Yuichi Yoshida", "authors": "Chien-Chung Huang and Naonori Kakimura and Simon Mauras and Yuichi\n  Yoshida", "title": "Approximability of Monotone Submodular Function Maximization under\n  Cardinality and Matroid Constraints in the Streaming Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing a monotone submodular function under various constraints is a\nclassical and intensively studied problem. However, in the single-pass\nstreaming model, where the elements arrive one by one and an algorithm can\nstore only a small fraction of input elements, there is much gap in our\nknowledge, even though several approximation algorithms have been proposed in\nthe literature.\n  In this work, we present the first lower bound on the approximation ratios\nfor cardinality and matroid constraints that beat $1-\\frac{1}{e}$ in the\nsingle-pass streaming model. Let $n$ be the number of elements in the stream.\nThen, we prove that any (randomized) streaming algorithm for a cardinality\nconstraint with approximation ratio $\\frac{2}{2+\\sqrt{2}}+\\varepsilon$ requires\n$\\Omega\\left(\\frac{n}{K^2}\\right)$ space for any $\\varepsilon>0$, where $K$ is\nthe size limit of the output set. We also prove that any (randomized) streaming\nalgorithm for a (partition) matroid constraint with approximation ratio\n$\\frac{K}{2K-1}+\\varepsilon$ requires $\\Omega\\left(\\frac{n}{K}\\right)$ space\nfor any $\\varepsilon>0$, where $K$ is the rank of the given matroid.\n  In addition, we give streaming algorithms when we only have a weak oracle\nwith which we can only evaluate function values on feasible sets. Specifically,\nwe show weak-oracle streaming algorithms for cardinality and matroid\nconstraints with approximation ratios $\\frac{K}{2K-1}$ and $\\frac{1}{2}$,\nrespectively, whose space complexity is exponential in $K$ but is independent\nof $n$. The former one exactly matches the known inapproximability result for a\ncardinality constraint in the weak oracle model.\n  The latter one almost matches our lower bound of $\\frac{K}{2K-1}$ for a\nmatroid constraint, which almost settles the approximation ratio for a matroid\nconstraint that can be obtained by a streaming algorithm whose space complexity\nis independent of $n$.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:33:46 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Huang", "Chien-Chung", ""], ["Kakimura", "Naonori", ""], ["Mauras", "Simon", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2002.05484", "submitter": "Hong Wu", "authors": "Hong Wu, Jiahai Wang and Zizhen Zhang", "title": "MODRL/D-AM: Multiobjective Deep Reinforcement Learning Algorithm Using\n  Decomposition and Attention Model for Multiobjective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a deep reinforcement learning method is proposed to solve\nmultiobjective optimization problem. In this method, the multiobjective\noptimization problem is decomposed to a number of single-objective optimization\nsubproblems and all the subproblems are optimized in a collaborative manner.\nEach subproblem is modeled with a pointer network and the model is trained with\nreinforcement learning. However, when pointer network extracts the features of\nan instance, it ignores the underlying structure information of the input\nnodes. Thus, this paper proposes a multiobjective deep reinforcement learning\nmethod using decomposition and attention model to solve multiobjective\noptimization problem. In our method, each subproblem is solved by an attention\nmodel, which can exploit the structure features as well as node features of\ninput nodes. The experiment results on multiobjective travelling salesman\nproblem show the proposed algorithm achieves better performance compared with\nthe previous method.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 12:59:39 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Wu", "Hong", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""]]}, {"id": "2002.05487", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Jose Gomez-Tames, Akimasa Hirata", "title": "End-to-end semantic segmentation of personalized deep brain structures\n  for non-invasive brain stimulation", "comments": "To appear in Neural Networks", "journal-ref": "Neural Networks 125, pp. 233-244, 2020", "doi": "10.1016/j.neunet.2020.02.006", "report-no": null, "categories": "eess.IV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electro-stimulation or modulation of deep brain regions is commonly used in\nclinical procedures for the treatment of several nervous system disorders. In\nparticular, transcranial direct current stimulation (tDCS) is widely used as an\naffordable clinical application that is applied through electrodes attached to\nthe scalp. However, it is difficult to determine the amount and distribution of\nthe electric field (EF) in the different brain regions due to anatomical\ncomplexity and high inter-subject variability. Personalized tDCS is an emerging\nclinical procedure that is used to tolerate electrode montage for accurate\ntargeting. This procedure is guided by computational head models generated from\nanatomical images such as MRI. Distribution of the EF in segmented head models\ncan be calculated through simulation studies. Therefore, fast, accurate, and\nfeasible segmentation of different brain structures would lead to a better\nadjustment for customized tDCS studies. In this study, a single-encoder\nmulti-decoders convolutional neural network is proposed for deep brain\nsegmentation. The proposed architecture is trained to segment seven deep brain\nstructures using T1-weighted MRI. Network generated models are compared with a\nreference model constructed using a semi-automatic method, and it presents a\nhigh matching especially in Thalamus (Dice Coefficient (DC) = 94.70%), Caudate\n(DC = 91.98%) and Putamen (DC = 90.31%) structures. Electric field distribution\nduring tDCS in generated and reference models matched well each other,\nsuggesting its potential usefulness in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 13:17:25 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Rashed", "Essam A.", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2002.05493", "submitter": "Fabricio Breve", "authors": "Fabricio A Breve, Marcos G Quiles, Liang Zhao, and Elbert E. N. Macau", "title": "Chaotic Phase Synchronization and Desynchronization in an Oscillator\n  Network for Object Selection", "comments": null, "journal-ref": "BREVE, FA; ZHAO, L; QUILES, MG; MACAU, EEN. Chaotic Phase\n  Synchronization and Desynchronization in an Oscillator Network for Object\n  Selection. Neural Networks, v. 22, p. 728-737, 2009", "doi": "10.1016/j.neunet.2009.06.027", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object selection refers to the mechanism of extracting objects of interest\nwhile ignoring other objects and background in a given visual scene. It is a\nfundamental issue for many computer vision and image analysis techniques and it\nis still a challenging task to artificial visual systems. Chaotic phase\nsynchronization takes place in cases involving almost identical dynamical\nsystems and it means that the phase difference between the systems is kept\nbounded over the time, while their amplitudes remain chaotic and may be\nuncorrelated. Instead of complete synchronization, phase synchronization is\nbelieved to be a mechanism for neural integration in brain. In this paper, an\nobject selection model is proposed. Oscillators in the network representing the\nsalient object in a given scene are phase synchronized, while no phase\nsynchronization occurs for background objects. In this way, the salient object\ncan be extracted. In this model, a shift mechanism is also introduced to change\nattention from one object to another. Computer simulations show that the model\nproduces some results similar to those observed in natural vision systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 13:39:25 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Breve", "Fabricio A", ""], ["Quiles", "Marcos G", ""], ["Zhao", "Liang", ""], ["Macau", "Elbert E. N.", ""]]}, {"id": "2002.05502", "submitter": "Ren Yangang", "authors": "Yangang Ren, Jingliang Duan, Shengbo Eben Li, Yang Guan and Qi Sun", "title": "Improving Generalization of Reinforcement Learning with Minimax\n  Distributional Soft Actor-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has achieved remarkable performance in numerous\nsequential decision making and control tasks. However, a common problem is that\nlearned nearly optimal policy always overfits to the training environment and\nmay not be extended to situations never encountered during training. For\npractical applications, the randomness of environment usually leads to some\ndevastating events, which should be the focus of safety-critical systems such\nas autonomous driving. In this paper, we introduce the minimax formulation and\ndistributional framework to improve the generalization ability of RL algorithms\nand develop the Minimax Distributional Soft Actor-Critic (Minimax DSAC)\nalgorithm. Minimax formulation aims to seek optimal policy considering the most\nsevere variations from environment, in which the protagonist policy maximizes\naction-value function while the adversary policy tries to minimize it.\nDistributional framework aims to learn a state-action return distribution, from\nwhich we can model the risk of different returns explicitly, thereby\nformulating a risk-averse protagonist policy and a risk-seeking adversarial\npolicy. We implement our method on the decision-making tasks of autonomous\nvehicles at intersections and test the trained policy in distinct environments.\nResults demonstrate that our method can greatly improve the generalization\nability of the protagonist agent to different environmental variations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:09:22 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 07:59:32 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Ren", "Yangang", ""], ["Duan", "Jingliang", ""], ["Li", "Shengbo Eben", ""], ["Guan", "Yang", ""], ["Sun", "Qi", ""]]}, {"id": "2002.05505", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Dongmin Shin,\n  Hangyeol Yu, Yugeun Shim, Seewoo Lee, Jonghun Shin, Chan Bae, Byungsoo Kim,\n  Jaewe Heo", "title": "Assessment Modeling: Fundamental Pre-training Tasks for Interactive\n  Educational Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like many other domains in Artificial Intelligence (AI), there are specific\ntasks in the field of AI in Education (AIEd) for which labels are scarce and\nexpensive, such as predicting exam score or review correctness. A common way of\ncircumventing label-scarce problems is pre-training a model to learn\nrepresentations of the contents of learning items. However, such methods fail\nto utilize the full range of student interaction data available and do not\nmodel student learning behavior. To this end, we propose Assessment Modeling, a\nclass of fundamental pre-training tasks for general interactive educational\nsystems. An assessment is a feature of student-system interactions which can\nserve as a pedagogical evaluation. Examples include the correctness and\ntimeliness of a student's answer. Assessment Modeling is the prediction of\nassessments conditioned on the surrounding context of interactions. Although it\nis natural to pre-train on interactive features available in large amounts,\nlimiting the prediction targets to assessments focuses the tasks' relevance to\nthe label-scarce educational problems and reduces less-relevant noise. While\nthe effectiveness of different combinations of assessments is open for\nexploration, we suggest Assessment Modeling as a first-order guiding principle\nfor selecting proper pre-training tasks for label-scarce educational problems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 02:00:07 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:57:54 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 06:45:40 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 07:00:48 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 01:31:13 GMT"}, {"version": "v6", "created": "Mon, 28 Jun 2021 05:00:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Cho", "Junghyun", ""], ["Baek", "Jineon", ""], ["Shin", "Dongmin", ""], ["Yu", "Hangyeol", ""], ["Shim", "Yugeun", ""], ["Lee", "Seewoo", ""], ["Shin", "Jonghun", ""], ["Bae", "Chan", ""], ["Kim", "Byungsoo", ""], ["Heo", "Jaewe", ""]]}, {"id": "2002.05508", "submitter": "Alessio Pagani Dr", "authors": "Alessio Pagani, Zhuangkun Wei, Ricardo Silva, Weisi Guo", "title": "Neural Network Approximation of Graph Fourier Transforms for Sparse\n  Sampling of Networked Flow Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrastructure monitoring is critical for safe operations and sustainability.\nWater distribution networks (WDNs) are large-scale networked critical systems\nwith complex cascade dynamics which are difficult to predict. Ubiquitous\nmonitoring is expensive and a key challenge is to infer the contaminant\ndynamics from partial sparse monitoring data. Existing approaches use\nmulti-objective optimisation to find the minimum set of essential monitoring\npoints, but lack performance guarantees and a theoretical framework.\n  Here, we first develop Graph Fourier Transform (GFT) operators to compress\nnetworked contamination spreading dynamics to identify the essential principle\ndata collection points with inference performance guarantees. We then build\nautoencoder (AE) inspired neural networks (NN) to generalize the GFT sampling\nprocess and under-sample further from the initial sampling set, allowing a very\nsmall set of data points to largely reconstruct the contamination dynamics over\nreal and artificial WDNs. Various sources of the contamination are tested and\nwe obtain high accuracy reconstruction using around 5-10% of the sample set.\nThis general approach of compression and under-sampled recovery via neural\nnetworks can be applied to a wide range of networked infrastructures to enable\ndigital twins.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 20:18:37 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Pagani", "Alessio", ""], ["Wei", "Zhuangkun", ""], ["Silva", "Ricardo", ""], ["Guo", "Weisi", ""]]}, {"id": "2002.05511", "submitter": "Sanna Wager C", "authors": "Sanna Wager, George Tzanetakis, Cheng-i Wang, Minje Kim", "title": "Deep Autotuner: a Pitch Correcting Network for Singing Performances", "comments": "arXiv admin note: text overlap with arXiv:1902.00956", "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce a data-driven approach to automatic pitch correction of solo\nsinging performances. The proposed approach predicts note-wise pitch shifts\nfrom the relationship between the respective spectrograms of the singing and\naccompaniment. This approach differs from commercial systems, where vocal track\nnotes are usually shifted to be centered around pitches in a user-defined\nscore, or mapped to the closest pitch among the twelve equal-tempered scale\ndegrees. The proposed system treats pitch as a continuous value rather than\nrelying on a set of discretized notes found in musical scores, thus allowing\nfor improvisation and harmonization in the singing performance. We train our\nneural network model using a dataset of 4,702 amateur karaoke performances\nselected for good intonation. Our model is trained on both incorrect\nintonation, for which it learns a correction, and intentional pitch variation,\nwhich it learns to preserve. The proposed deep neural network with gated\nrecurrent units on top of convolutional layers shows promising performance on\nthe real-world score-free singing pitch correction task of autotuning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 01:33:56 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wager", "Sanna", ""], ["Tzanetakis", "George", ""], ["Wang", "Cheng-i", ""], ["Kim", "Minje", ""]]}, {"id": "2002.05512", "submitter": "Yuanbo Xiangli", "authors": "Yuanbo Xiangli, Yubin Deng, Bo Dai, Chen Change Loy, Dahua Lin", "title": "Real or Not Real, that is the Question", "comments": "ICLR2020 spotlight. 1) train GAN by maximizing kl-divergence. 2)\n  train non-progressive GAN (DCGAN) architecture at 1024*1024 resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While generative adversarial networks (GAN) have been widely adopted in\nvarious topics, in this paper we generalize the standard GAN to a new\nperspective by treating realness as a random variable that can be estimated\nfrom multiple angles. In this generalized framework, referred to as\nRealnessGAN, the discriminator outputs a distribution as the measure of\nrealness. While RealnessGAN shares similar theoretical guarantees with the\nstandard GAN, it provides more insights on adversarial learning. Compared to\nmultiple baselines, RealnessGAN provides stronger guidance for the generator,\nachieving improvements on both synthetic and real-world datasets. Moreover, it\nenables the basic DCGAN architecture to generate realistic images at 1024*1024\nresolution when trained from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:41:55 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xiangli", "Yuanbo", ""], ["Deng", "Yubin", ""], ["Dai", "Bo", ""], ["Loy", "Chen Change", ""], ["Lin", "Dahua", ""]]}, {"id": "2002.05514", "submitter": "Alexander Wikner", "authors": "Alexander Wikner, Jaideep Pathak, Brian Hunt, Michelle Girvan, Troy\n  Arcomano, Istvan Szunyogh, Andrew Pomerance, and Edward Ott", "title": "Combining Machine Learning with Knowledge-Based Modeling for Scalable\n  Forecasting and Subgrid-Scale Closure of Large, Complex, Spatiotemporal\n  Systems", "comments": "45 pages, 15 figures", "journal-ref": null, "doi": "10.1063/5.0005541", "report-no": null, "categories": "cs.LG nlin.CD physics.ao-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the commonly encountered situation (e.g., in weather forecasting)\nwhere the goal is to predict the time evolution of a large, spatiotemporally\nchaotic dynamical system when we have access to both time series data of\nprevious system states and an imperfect model of the full system dynamics.\nSpecifically, we attempt to utilize machine learning as the essential tool for\nintegrating the use of past data into predictions. In order to facilitate\nscalability to the common scenario of interest where the spatiotemporally\nchaotic system is very large and complex, we propose combining two\napproaches:(i) a parallel machine learning prediction scheme; and (ii) a hybrid\ntechnique, for a composite prediction system composed of a knowledge-based\ncomponent and a machine-learning-based component. We demonstrate that not only\ncan this method combining (i) and (ii) be scaled to give excellent performance\nfor very large systems, but also that the length of time series data needed to\ntrain our multiple, parallel machine learning components is dramatically less\nthan that necessary without parallelization. Furthermore, considering cases\nwhere computational realization of the knowledge-based component does not\nresolve subgrid-scale processes, our scheme is able to use training data to\nincorporate the effect of the unresolved short-scale dynamics upon the resolved\nlonger-scale dynamics (\"subgrid-scale closure\").\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 23:21:50 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Wikner", "Alexander", ""], ["Pathak", "Jaideep", ""], ["Hunt", "Brian", ""], ["Girvan", "Michelle", ""], ["Arcomano", "Troy", ""], ["Szunyogh", "Istvan", ""], ["Pomerance", "Andrew", ""], ["Ott", "Edward", ""]]}, {"id": "2002.05515", "submitter": "Malay Haldar", "authors": "Malay Haldar, Mustafa Abdool, Prashant Ramanathan, Tyler Sax, Lanbo\n  Zhang, Aamir Mansawala, Shulin Yang, Bradley Turnbull, Junshuo Liao", "title": "Improving Deep Learning For Airbnb Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to search ranking was one of the most\nimpactful product improvements at Airbnb. But what comes next after you launch\na deep learning model? In this paper we describe the journey beyond, discussing\nwhat we refer to as the ABCs of improving search: A for architecture, B for\nbias and C for cold start. For architecture, we describe a new ranking neural\nnetwork, focusing on the process that evolved our existing DNN beyond a fully\nconnected two layer network. On handling positional bias in ranking, we\ndescribe a novel approach that led to one of the most significant improvements\nin tackling inventory that the DNN historically found challenging. To solve\ncold start, we describe our perspective on the problem and changes we made to\nimprove the treatment of new listings on the platform. We hope ranking teams\ntransitioning to deep learning will find this a practical case study of how to\niterate on DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:47:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Haldar", "Malay", ""], ["Abdool", "Mustafa", ""], ["Ramanathan", "Prashant", ""], ["Sax", "Tyler", ""], ["Zhang", "Lanbo", ""], ["Mansawala", "Aamir", ""], ["Yang", "Shulin", ""], ["Turnbull", "Bradley", ""], ["Liao", "Junshuo", ""]]}, {"id": "2002.05516", "submitter": "Filip Hanzely", "authors": "Filip Hanzely and Peter Richt\\'arik", "title": "Federated Learning of a Mixture of Global and Local Models", "comments": "40 pages, 8 algorithms, 6 figures, 1 table (minor changes compared to\n  the previous versions)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new optimization formulation for training federated learning\nmodels. The standard formulation has the form of an empirical risk minimization\nproblem constructed to find a single global model trained from the private data\nstored across all participating devices. In contrast, our formulation seeks an\nexplicit trade-off between this traditional global model and the local models,\nwhich can be learned by each device from its own private data without any\ncommunication. Further, we develop several efficient variants of SGD (with and\nwithout partial participation and with and without variance reduction) for\nsolving the new formulation and prove communication complexity guarantees.\nNotably, our methods are similar but not identical to federated averaging /\nlocal SGD, thus shedding some light on the role of local steps in federated\nlearning. In particular, we are the first to i) show that local steps can\nimprove communication for problems with heterogeneous data, and ii) point out\nthat personalization yields reduced communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 09:17:08 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 15:05:50 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 06:30:47 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hanzely", "Filip", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.05517", "submitter": "Keith Dillon", "authors": "Keith Dillon", "title": "Feature-level Malware Obfuscation in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting malware with deep learning models, where\nthe malware may be combined with significant amounts of benign code. Examples\nof this include piggybacking and trojan horse attacks on a system, where\nmalicious behavior is hidden within a useful application. Such added\nflexibility in augmenting the malware enables significantly more code\nobfuscation. Hence we focus on the use of static features, particularly\nIntents, Permissions, and API calls, which we presume cannot be ultimately\nhidden from the Android system, but only augmented with yet more such features.\nWe first train a deep neural network classifier for malware classification\nusing features of benign and malware samples. Then we demonstrate a steep\nincrease in false negative rate (i.e., attacks succeed), simply by randomly\nadding features of a benign app to malware. Finally we test the use of data\naugmentation to harden the classifier against such attacks. We find that for\nAPI calls, it is possible to reject the vast majority of attacks, where using\nIntents or Permissions is less successful.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 00:47:23 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Dillon", "Keith", ""]]}, {"id": "2002.05518", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, David Abel, Michael L. Littman", "title": "Learning State Abstractions for Transfer in Continuous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can simple algorithms with a good representation solve challenging\nreinforcement learning problems? In this work, we answer this question in the\naffirmative, where we take \"simple learning algorithm\" to be tabular\nQ-Learning, the \"good representations\" to be a learned state abstraction, and\n\"challenging problems\" to be continuous control tasks. Our main contribution is\na learning algorithm that abstracts a continuous state-space into a discrete\none. We transfer this learned representation to unseen problems to enable\neffective learning. We provide theory showing that learned abstractions\nmaintain a bounded value loss, and we report experiments showing that the\nabstractions empower tabular Q-Learning to learn efficiently in unseen tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 20:42:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Asadi", "Kavosh", ""], ["Abel", "David", ""], ["Littman", "Michael L.", ""]]}, {"id": "2002.05519", "submitter": "Yixuan Qiu", "authors": "Yixuan Qiu and Xiao Wang", "title": "Stochastic Approximate Gradient Descent via the Langevin Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel and efficient algorithm called the stochastic\napproximate gradient descent (SAGD), as an alternative to the stochastic\ngradient descent for cases where unbiased stochastic gradients cannot be\ntrivially obtained. Traditional methods for such problems rely on\ngeneral-purpose sampling techniques such as Markov chain Monte Carlo, which\ntypically requires manual intervention for tuning parameters and does not work\nefficiently in practice. Instead, SAGD makes use of the Langevin algorithm to\nconstruct stochastic gradients that are biased in finite steps but accurate\nasymptotically, enabling us to theoretically establish the convergence\nguarantee for SAGD. Inspired by our theoretical analysis, we also provide\nuseful guidelines for its practical implementation. Finally, we show that SAGD\nperforms well experimentally in popular statistical and machine learning\nproblems such as the expectation-maximization algorithm and the variational\nautoencoders.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:29:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Qiu", "Yixuan", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.05520", "submitter": "Mu Yuan", "authors": "Mu Yuan, Lan Zhang, Xiang-Yang Li, Hui Xiong", "title": "Comprehensive and Efficient Data Labeling via Adaptive Model Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Labeling data (e.g., labeling the people, objects, actions and scene in\nimages) comprehensively and efficiently is a widely needed but challenging\ntask. Numerous models were proposed to label various data and many approaches\nwere designed to enhance the ability of deep learning models or accelerate\nthem. Unfortunately, a single machine-learning model is not powerful enough to\nextract various semantic information from data. Given certain applications,\nsuch as image retrieval platforms and photo album management apps, it is often\nrequired to execute a collection of models to obtain sufficient labels. With\nlimited computing resources and stringent delay, given a data stream and a\ncollection of applicable resource-hungry deep-learning models, we design a\nnovel approach to adaptively schedule a subset of these models to execute on\neach data item, aiming to maximize the value of the model output (e.g., the\nnumber of high-confidence labels). Achieving this lofty goal is nontrivial\nsince a model's output on any data item is content-dependent and unknown until\nwe execute it. To tackle this, we propose an Adaptive Model Scheduling\nframework, consisting of 1) a deep reinforcement learning-based approach to\npredict the value of unexecuted models by mining semantic relationship among\ndiverse models, and 2) two heuristic algorithms to adaptively schedule the\nmodel execution order under a deadline or deadline-memory constraints\nrespectively. The proposed framework doesn't require any prior knowledge of the\ndata, which works as a powerful complement to existing model optimization\ntechnologies. We conduct extensive evaluations on five diverse image datasets\nand 30 popular image labeling models to demonstrate the effectiveness of our\ndesign: our design could save around 53\\% execution time without loss of any\nvaluable labels.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:54:39 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Yuan", "Mu", ""], ["Zhang", "Lan", ""], ["Li", "Xiang-Yang", ""], ["Xiong", "Hui", ""]]}, {"id": "2002.05521", "submitter": "Fabricio Breve", "authors": "B\\'arbara Ribeiro da Silva and Fabricio Aparecido Breve", "title": "Segmenta\\c{c}\\~ao de imagens utilizando competi\\c{c}\\~ao e\n  coopera\\c{c}\\~ao entre part\\'iculas", "comments": null, "journal-ref": "Interci\\^encia & Sociedade - Revista Eletr\\^onica. v.4, p.75 - 85,\n  2015", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension proposal of the semi-supervised learning\nmethod known as Particle Competition and Cooperation for carrying out tasks of\nimage segmentation. Preliminary results show that this is a promising approach.\n  Este artigo apresenta uma proposta de extens\\~ao do modelo de aprendizado\nsemi-supervisionado conhecido como Competi\\c{c}\\~ao e Coopera\\c{c}\\~ao entre\nPart\\'iculas para a realiza\\c{c}\\~ao de tarefas de segmenta\\c{c}\\~ao de\nimagens. Resultados preliminares mostram que esta \\'e uma abordagem promissora.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 03:02:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["da Silva", "B\u00e1rbara Ribeiro", ""], ["Breve", "Fabricio Aparecido", ""]]}, {"id": "2002.05522", "submitter": "Jayden Ooi", "authors": "Sungryull Sohn and Yinlam Chow and Jayden Ooi and Ofir Nachum and\n  Honglak Lee and Ed Chi and Craig Boutilier", "title": "BRPO: Batch Residual Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In batch reinforcement learning (RL), one often constrains a learned policy\nto be close to the behavior (data-generating) policy, e.g., by constraining the\nlearned action distribution to differ from the behavior policy by some maximum\ndegree that is the same at each state. This can cause batch RL to be overly\nconservative, unable to exploit large policy changes at frequently-visited,\nhigh-confidence states without risking poor performance at sparsely-visited\nstates. To remedy this, we propose residual policies, where the allowable\ndeviation of the learned policy is state-action-dependent. We derive a new for\nRL method, BRPO, which learns both the policy and allowable deviation that\njointly maximize a lower bound on policy performance. We show that BRPO\nachieves the state-of-the-art performance in a number of tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:59:33 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 00:45:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Sohn", "Sungryull", ""], ["Chow", "Yinlam", ""], ["Ooi", "Jayden", ""], ["Nachum", "Ofir", ""], ["Lee", "Honglak", ""], ["Chi", "Ed", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.05526", "submitter": "Byungik Ahn", "authors": "Byungik Ahn", "title": "Near-Optimal Hardware Design for Convolutional Neural Networks", "comments": "8 pages, 8 figures, Submitted to IJCNN 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the demand of low-power deep-learning hardware for industrial\napplications has been increasing. Most existing artificial intelligence (AI)\nchips have evolved to rely on new chip technologies rather than on radically\nnew hardware architectures, to maintain their generality. This study proposes a\nnovel, special-purpose, and high-efficiency hardware architecture for\nconvolutional neural networks. The proposed architecture maximizes the\nutilization of multipliers by designing the computational circuit with the same\nstructure as that of the computational flow of the model, rather than mapping\ncomputations to fixed hardware. In addition, a specially designed filter\ncircuit simultaneously provides all the data of the receptive field, using only\none memory read operation during each clock cycle; this allows the computation\ncircuit to operate seamlessly without idle cycles. Our reference system based\non the proposed architecture uses 97% of the peak-multiplication capability in\nactual computations required by the computation model throughout the\ncomputation period. In addition, overhead components are minimized so that the\nproportion of the resources constituting the non-multiplier components is\nsmaller than that constituting the multiplier components, which are\nindispensable for the computational model. The efficiency of the proposed\narchitecture is close to an ideally efficient system that cannot be improved\nfurther in terms of the performance-to-resource ratio. An implementation based\non the proposed hardware architecture has been applied in commercial AI\nproducts.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 09:15:03 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ahn", "Byungik", ""]]}, {"id": "2002.05534", "submitter": "Menghan Hu", "authors": "Yunlu Wang, Menghan Hu, Qingli Li, Xiao-Ping Zhang, Guangtao Zhai, Nan\n  Yao", "title": "Abnormal respiratory patterns classifier may contribute to large-scale\n  screening of people infected with COVID-19 in an accurate and unobtrusive\n  manner", "comments": "6 page, 3 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research significance: The extended version of this paper has been accepted\nby IEEE Internet of Things journal (DOI: 10.1109/JIOT.2020.2991456), please\ncite the journal version. During the epidemic prevention and control period,\nour study can be helpful in prognosis, diagnosis and screening for the patients\ninfected with COVID-19 (the novel coronavirus) based on breathing\ncharacteristics. According to the latest clinical research, the respiratory\npattern of COVID-19 is different from the respiratory patterns of flu and the\ncommon cold. One significant symptom that occurs in the COVID-19 is Tachypnea.\nPeople infected with COVID-19 have more rapid respiration. Our study can be\nutilized to distinguish various respiratory patterns and our device can be\npreliminarily put to practical use. Demo videos of this method working in\nsituations of one subject and two subjects can be downloaded online. Research\ndetails: Accurate detection of the unexpected abnormal respiratory pattern of\npeople in a remote and unobtrusive manner has great significance. In this work,\nwe innovatively capitalize on depth camera and deep learning to achieve this\ngoal. The challenges in this task are twofold: the amount of real-world data is\nnot enough for training to get the deep model; and the intra-class variation of\ndifferent types of respiratory patterns is large and the outer-class variation\nis small. In this paper, considering the characteristics of actual respiratory\nsignals, a novel and efficient Respiratory Simulation Model (RSM) is first\nproposed to fill the gap between the large amount of training data and scarce\nreal-world data. The proposed deep model and the modeling ideas have the great\npotential to be extended to large scale applications such as public places,\nsleep scenario, and office environment.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:42:57 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 03:57:55 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wang", "Yunlu", ""], ["Hu", "Menghan", ""], ["Li", "Qingli", ""], ["Zhang", "Xiao-Ping", ""], ["Zhai", "Guangtao", ""], ["Yao", "Nan", ""]]}, {"id": "2002.05536", "submitter": "Yan Li", "authors": "Yang Li, Yan Li, Hua Tian", "title": "Deep Learning-based End-to-end Diagnosis System for Avascular Necrosis\n  of Femoral Head", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": "10.1109/JBHI.2020.3037079", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the first diagnostic imaging modality of avascular necrosis of the femoral\nhead (AVNFH), accurately staging AVNFH from a plain radiograph is critical yet\nchallenging for orthopedists. Thus, we propose a deep learning-based AVNFH\ndiagnosis system (AVN-net). The proposed AVN-net reads plain radiographs of the\npelvis, conducts diagnosis, and visualizes results automatically. Deep\nconvolutional neural networks are trained to provide an end-to-end diagnosis\nsolution, covering tasks of femoral head detection, exam-view identification,\nside classification, AVNFH diagnosis, and key clinical notes generation.\nAVN-net is able to obtain state-of-the-art testing AUC of 0.97 (95% CI:\n0.97-0.98) in AVNFH detection and significantly greater F1 scores than\nless-to-moderately experienced orthopedists in all diagnostic tests (p<0.01).\nFurthermore, two real-world pilot studies were conducted for diagnosis support\nand education assistance, respectively, to assess the utility of AVN-net. The\nexperimental results are promising. With the AVN-net diagnosis as a reference,\nthe diagnostic accuracy and consistency of all orthopedists considerably\nimproved while requiring only 1/4 of the time. Students self-studying the AVNFH\ndiagnosis using AVN-net can learn better and faster than the control group. To\nthe best of our knowledge, this study is the first research on the prospective\nuse of a deep learning-based diagnosis system for AVNFH by conducting two pilot\nstudies representing real-world application scenarios. We have demonstrated\nthat the proposed AVN-net achieves expert-level AVNFH diagnosis performance,\nprovides efficient support in clinical decision-making, and effectively passes\nclinical experience to students.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:55:50 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 14:06:56 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Li", "Yang", ""], ["Li", "Yan", ""], ["Tian", "Hua", ""]]}, {"id": "2002.05542", "submitter": "Amir Mosavi Prof", "authors": "Mohammad Hossein Ahmadi, Alireza Baghban, Milad Sadeghzadeh, Mohammad\n  Zamen, Amir Mosavi, Shahaboddin Shamshirband, Ravinder Kumar, Mohammad\n  Mohammadi-Khanaposhtani", "title": "Evaluation of electrical efficiency of photovoltaic thermal solar\n  collector", "comments": "49 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solar energy is a renewable resource of energy that is broadly utilized and\nhas the least emissions among renewable energies. In this study, machine\nlearning methods of artificial neural networks (ANNs), least squares support\nvector machines (LSSVM), and neuro-fuzzy are used for advancing prediction\nmodels for the thermal performance of a photovoltaic-thermal solar collector\n(PV/T). In the proposed models, the inlet temperature, flow rate, heat, solar\nradiation, and the sun heat have been considered as the inputs variables. Data\nset has been extracted through experimental measurements from a novel solar\ncollector system. Different analyses are performed to examine the credibility\nof the introduced approaches and evaluate their performance. The proposed LSSVM\nmodel outperformed ANFIS and ANNs models. LSSVM model is reported suitable when\nthe laboratory measurements are costly and time-consuming, or achieving such\nvalues requires sophisticated interpretations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 21:11:54 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Ahmadi", "Mohammad Hossein", ""], ["Baghban", "Alireza", ""], ["Sadeghzadeh", "Milad", ""], ["Zamen", "Mohammad", ""], ["Mosavi", "Amir", ""], ["Shamshirband", "Shahaboddin", ""], ["Kumar", "Ravinder", ""], ["Mohammadi-Khanaposhtani", "Mohammad", ""]]}, {"id": "2002.05544", "submitter": "Anderson Tavares", "authors": "Pedro H. C. Avelar, Anderson R. Tavares, Thiago L. T. da Silveira,\n  Cl\\'audio R. Jung, Lu\\'is C. Lamb", "title": "Superpixel Image Classification with Graph Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for image classification using Graph Neural\nNetwork (GNN) models. We transform the input images into region adjacency\ngraphs (RAGs), in which regions are superpixels and edges connect neighboring\nsuperpixels. Our experiments suggest that Graph Attention Networks (GATs),\nwhich combine graph convolutions with self-attention mechanisms, outperforms\nother GNN models. Although raw image classifiers perform better than GATs due\nto information loss during the RAG generation, our methodology opens an\ninteresting avenue of research on deep learning beyond rectangular-gridded\nimages, such as 360-degree field of view panoramas. Traditional convolutional\nkernels of current state-of-the-art methods cannot handle panoramas, whereas\nthe adapted superpixel algorithms and the resulting region adjacency graphs can\nnaturally feed a GNN, without topology issues.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:52:32 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 17:04:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Tavares", "Anderson R.", ""], ["da Silveira", "Thiago L. T.", ""], ["Jung", "Cl\u00e1udio R.", ""], ["Lamb", "Lu\u00eds C.", ""]]}, {"id": "2002.05545", "submitter": "Martin Morin", "authors": "Martin Morin and Pontus Giselsson", "title": "Sampling and Update Frequencies in Proximal Variance Reduced Stochastic\n  Gradient Methods", "comments": "Fixed unicode-character problems in bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduced stochastic gradient methods have gained popularity in recent\ntimes. Several variants exist with different strategies for the storing and\nsampling of gradients. In this work we focus on the analysis of the interaction\nof these two aspects. We present and analyze a general proximal variance\nreduced gradient method under strong convexity assumptions. Special cases of\nthe algorithm include SAGA, L-SVRG and their proximal variants. Our analysis\nsheds light on epoch-length selection and the need to balance the convergence\nof the iterates and how often gradients are stored. The analysis improves on\nother convergence rates found in literature and produces a new and faster\nconverging sampling strategy for SAGA. Problem instances for which the\npredicted rates are the same as the practical rates are presented together with\nproblems based on real world data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:56:05 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:58:04 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Morin", "Martin", ""], ["Giselsson", "Pontus", ""]]}, {"id": "2002.05551", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss and Vincent Fortuin and Martin Josifoski and Andreas\n  Krause", "title": "PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees", "comments": "International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-learning can successfully acquire useful inductive biases from data.\nYet, its generalization properties to unseen learning tasks are poorly\nunderstood. Particularly if the number of meta-training tasks is small, this\nraises concerns about overfitting. We provide a theoretical analysis using the\nPAC-Bayesian framework and derive novel generalization bounds for\nmeta-learning. Using these bounds, we develop a class of PAC-optimal\nmeta-learning algorithms with performance guarantees and a principled\nmeta-level regularization. Unlike previous PAC-Bayesian meta-learners, our\nmethod results in a standard stochastic optimization problem which can be\nsolved efficiently and scales well. When instantiating our PAC-optimal\nhyper-posterior (PACOH) with Gaussian processes and Bayesian Neural Networks as\nbase learners, the resulting methods yield state-of-the-art performance, both\nin terms of predictive accuracy and the quality of uncertainty estimates.\nThanks to their principled treatment of uncertainty, our meta-learners can also\nbe successfully employed for sequential decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:01:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 08:50:08 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 08:39:52 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 17:27:31 GMT"}, {"version": "v5", "created": "Fri, 18 Jun 2021 07:08:24 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Fortuin", "Vincent", ""], ["Josifoski", "Martin", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.05564", "submitter": "Zhiyuan Jiang", "authors": "Yan Liu, Zhiyuan Jiang, Shunqing Zhang, Shugong Xu", "title": "Deep Reinforcement Learning-Based Beam Tracking for Low-Latency Services\n  in Vehicular Networks", "comments": "7 pages, 8 figures, to appear in ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultra-Reliable and Low-Latency Communications (URLLC) services in vehicular\nnetworks on millimeter-wave bands present a significant challenge, considering\nthe necessity of constantly adjusting the beam directions. Conventional methods\nare mostly based on classical control theory, e.g., Kalman filter and its\nvariations, which mainly deal with stationary scenarios. Therefore, severe\napplication limitations exist, especially with complicated, dynamic\nVehicle-to-Everything (V2X) channels. This paper gives a thorough study of this\nsubject, by first modifying the classical approaches, e.g., Extended Kalman\nFilter (EKF) and Particle Filter (PF), for non-stationary scenarios, and then\nproposing a Reinforcement Learning (RL)-based approach that can achieve the\nURLLC requirements in a typical intersection scenario. Simulation results based\non a commercial ray-tracing simulator show that enhanced EKF and PF methods\nachieve packet delay more than $10$ ms, whereas the proposed deep RL-based\nmethod can reduce the latency to about $6$ ms, by extracting context\ninformation from the training data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:21:24 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Liu", "Yan", ""], ["Jiang", "Zhiyuan", ""], ["Zhang", "Shunqing", ""], ["Xu", "Shugong", ""]]}, {"id": "2002.05576", "submitter": "Andrej Risteski", "authors": "Ankur Moitra, Andrej Risteski", "title": "Fast Convergence for Langevin Diffusion with Manifold Structure", "comments": "52 pages, in submission to NeurIPS 2020. This version: various typos\n  fixed, minor reorganization", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of sampling from distributions of the\nform p(x) \\propto e^{-\\beta f(x)} for some function f whose values and\ngradients we can query. This mode of access to f is natural in the scenarios in\nwhich such problems arise, for instance sampling from posteriors in parametric\nBayesian models. Classical results show that a natural random walk, Langevin\ndiffusion, mixes rapidly when f is convex. Unfortunately, even in simple\nexamples, the applications listed above will entail working with functions f\nthat are nonconvex -- for which sampling from p may in general require an\nexponential number of queries.\n  In this paper, we focus on an aspect of nonconvexity relevant for modern\nmachine learning applications: existence of invariances (symmetries) in the\nfunction f, as a result of which the distribution p will have manifolds of\npoints with equal probability. First, we give a recipe for proving mixing time\nbounds for Langevin diffusion as a function of the geometry of these manifolds.\nSecond, we specialize our arguments to classic matrix factorization-like\nBayesian inference problems where we get noisy measurements A(XX^T), X \\in R^{d\n\\times k} of a low-rank matrix, i.e. f(X) = \\|A(XX^T) - b\\|^2_2, X \\in R^{d\n\\times k}, and \\beta the inverse of the variance of the noise. Such functions f\nare invariant under orthogonal transformations, and include problems like\nmatrix factorization, sensing, completion. Beyond sampling, Langevin dynamics\nis a popular toy model for studying stochastic gradient descent. Along these\nlines, we believe that our work is an important first step towards\nunderstanding how SGD behaves when there is a high degree of symmetry in the\nspace of parameters the produce the same output.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:49:04 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:48:52 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Moitra", "Ankur", ""], ["Risteski", "Andrej", ""]]}, {"id": "2002.05578", "submitter": "Jung Yeon Park", "authors": "Jung Yeon Park, Kenneth Theo Carr, Stephan Zheng, Yisong Yue, and Rose\n  Yu", "title": "Multiresolution Tensor Learning for Efficient and Interpretable Spatial\n  Analysis", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and interpretable spatial analysis is crucial in many fields such\nas geology, sports, and climate science. Tensor latent factor models can\ndescribe higher-order correlations for spatial data. However, they are\ncomputationally expensive to train and are sensitive to initialization, leading\nto spatially incoherent, uninterpretable results. We develop a novel\nMultiresolution Tensor Learning (MRTL) algorithm for efficiently learning\ninterpretable spatial patterns. MRTL initializes the latent factors from an\napproximate full-rank tensor model for improved interpretability and\nprogressively learns from a coarse resolution to the fine resolution to reduce\ncomputation. We also prove the theoretical convergence and computational\ncomplexity of MRTL. When applied to two real-world datasets, MRTL demonstrates\n4~5x speedup compared to a fixed resolution approach while yielding accurate\nand interpretable latent factors.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:50:48 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 16:40:26 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:19:08 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 13:54:04 GMT"}, {"version": "v5", "created": "Fri, 14 Aug 2020 23:34:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Park", "Jung Yeon", ""], ["Carr", "Kenneth Theo", ""], ["Zheng", "Stephan", ""], ["Yue", "Yisong", ""], ["Yu", "Rose", ""]]}, {"id": "2002.05582", "submitter": "Shi Hu", "authors": "Shi Hu and Nicola Pezzotti and Max Welling", "title": "Learning to Predict Error for MRI Reconstruction", "comments": "Accepted to MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In healthcare applications, predictive uncertainty has been used to assess\npredictive accuracy. In this paper, we demonstrate that predictive uncertainty\nestimated by the current methods does not highly correlate with prediction\nerror by decomposing the latter into random and systematic errors, and showing\nthat the former is equivalent to the variance of the random error. In addition,\nwe observe that current methods unnecessarily compromise performance by\nmodifying the model and training loss to estimate the target and uncertainty\njointly. We show that estimating them separately without modifications improves\nperformance. Following this, we propose a novel method that estimates the\ntarget labels and magnitude of the prediction error in two steps. We\ndemonstrate this method on a large-scale MRI reconstruction task, and achieve\nsignificantly better results than the state-of-the-art uncertainty estimation\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:55:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 13:38:21 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 00:14:13 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Hu", "Shi", ""], ["Pezzotti", "Nicola", ""], ["Welling", "Max", ""]]}, {"id": "2002.05616", "submitter": "Will Grathwohl", "authors": "Will Grathwohl, Kuan-Chieh Wang, Jorn-Henrik Jacobsen, David Duvenaud,\n  Richard Zemel", "title": "Learning the Stein Discrepancy for Training and Evaluating Energy-Based\n  Models without Sampling", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for evaluating and training unnormalized density\nmodels. Our approach only requires access to the gradient of the unnormalized\nmodel's log-density. We estimate the Stein discrepancy between the data density\n$p(x)$ and the model density $q(x)$ defined by a vector function of the data.\nWe parameterize this function with a neural network and fit its parameters to\nmaximize the discrepancy. This yields a novel goodness-of-fit test which\noutperforms existing methods on high dimensional data. Furthermore, optimizing\n$q(x)$ to minimize this discrepancy produces a novel method for training\nunnormalized models which scales more gracefully than existing methods. The\nability to both learn and compare models is a unique feature of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:39:07 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:03:42 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 14:38:26 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:32:47 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Grathwohl", "Will", ""], ["Wang", "Kuan-Chieh", ""], ["Jacobsen", "Jorn-Henrik", ""], ["Duvenaud", "David", ""], ["Zemel", "Richard", ""]]}, {"id": "2002.05628", "submitter": "Anthony Stein", "authors": "Anthony Stein, Roland Maier, Lukas Rosenbauer, J\\\"org H\\\"ahner", "title": "XCS Classifier System with Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XCS constitutes the most deeply investigated classifier system today. It\nbears strong potentials and comes with inherent capabilities for mastering a\nvariety of different learning tasks. Besides outstanding successes in various\nclassification and regression tasks, XCS also proved very effective in certain\nmulti-step environments from the domain of reinforcement learning. Especially\nin the latter domain, recent advances have been mainly driven by algorithms\nwhich model their policies based on deep neural networks -- among which the\nDeep-Q-Network (DQN) is a prominent representative. Experience Replay (ER)\nconstitutes one of the crucial factors for the DQN's successes, since it\nfacilitates stabilized training of the neural network-based Q-function\napproximators. Surprisingly, XCS barely takes advantage of similar mechanisms\nthat leverage stored raw experiences encountered so far. To bridge this gap,\nthis paper investigates the benefits of extending XCS with ER. On the one hand,\nwe demonstrate that for single-step tasks ER bears massive potential for\nimprovements in terms of sample efficiency. On the shady side, however, we\nreveal that the use of ER might further aggravate well-studied issues not yet\nsolved for XCS when applied to sequential decision problems demanding for\nlong-action-chains.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:55:08 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Stein", "Anthony", ""], ["Maier", "Roland", ""], ["Rosenbauer", "Lukas", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.05630", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Michael Garcia-Ortiz, David Filliat", "title": "On the Sensory Commutativity of Action Sequences for Embodied Agents", "comments": "Accepted to RSS'20 Workshop on Self-Supervised Robot Learning & to\n  the Workshop on Learning in Artificial Open Worlds at ICML20 & Extended\n  abstract at AAMAS21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception of artificial agents is one the grand challenges of AI research.\nDeep Learning and data-driven approaches are successful on constrained problems\nwhere perception can be learned using supervision, but do not scale to\nopen-worlds. In such case, for autonomous embodied agents with first-person\nsensors, perception can be learned end-to-end to solve particular tasks.\nHowever, literature shows that perception is not a purely passive compression\nmechanism, and that actions play an important role in the formulation of\nabstract representations. We propose to study perception for these embodied\nagents, under the mathematical formalism of group theory in order to make the\nlink between perception and action. In particular, we consider the commutative\nproperties of continuous action sequences with respect to sensory information\nperceived by such an embodied agent. We introduce the Sensory Commutativity\nProbability (SCP) criterion which measures how much an agent's degree of\nfreedom affects the environment in embodied scenarios. We show how to compute\nthis criterion in different environments, including realistic robotic setups.\nWe empirically illustrate how SCP and the commutative properties of action\nsequences can be used to learn about objects in the environment and improve\nsample-efficiency in Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 16:58:23 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 14:32:44 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 10:15:08 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Garcia-Ortiz", "Michael", ""], ["Filliat", "David", ""]]}, {"id": "2002.05632", "submitter": "Vasilis Kontonis", "authors": "Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, and Nikos\n  Zarifis", "title": "Learning Halfspaces with Massart Noise Under Structured Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning halfspaces with Massart noise in the\ndistribution-specific PAC model. We give the first computationally efficient\nalgorithm for this problem with respect to a broad family of distributions,\nincluding log-concave distributions. This resolves an open question posed in a\nnumber of prior works. Our approach is extremely simple: We identify a smooth\n{\\em non-convex} surrogate loss with the property that any approximate\nstationary point of this loss defines a halfspace that is close to the target\nhalfspace. Given this structural result, we can use SGD to solve the underlying\nlearning problem.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:02:37 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zarifis", "Nikos", ""]]}, {"id": "2002.05635", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ilya Tyagin, Michael Shtutman, Ilya Safro", "title": "AGATHA: Automatic Graph-mining And Transformer based Hypothesis\n  generation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical research is risky and expensive. Drug discovery, as an example,\nrequires that researchers efficiently winnow thousands of potential targets to\na small candidate set for more thorough evaluation. However, research groups\nspend significant time and money to perform the experiments necessary to\ndetermine this candidate set long before seeing intermediate results.\nHypothesis generation systems address this challenge by mining the wealth of\npublicly available scientific information to predict plausible research\ndirections. We present AGATHA, a deep-learning hypothesis generation system\nthat can introduce data-driven insights earlier in the discovery process.\nThrough a learned ranking criteria, this system quickly prioritizes plausible\nterm-pairs among entity sets, allowing us to recommend new research directions.\nWe massively validate our system with a temporal holdout wherein we predict\nconnections first introduced after 2015 using data published beforehand. We\nadditionally explore biomedical sub-domains, and demonstrate AGATHA's\npredictive capacity across the twenty most popular relationship types. This\nsystem achieves best-in-class performance on an established benchmark, and\ndemonstrates high recommendation scores across subdomains. Reproducibility: All\ncode, experimental data, and pre-trained models are available online:\nsybrandt.com/2020/agatha\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:06:47 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sybrandt", "Justin", ""], ["Tyagin", "Ilya", ""], ["Shtutman", "Michael", ""], ["Safro", "Ilya", ""]]}, {"id": "2002.05636", "submitter": "Ryan Steed", "authors": "Ryan Steed and Aylin Caliskan", "title": "A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of\n  Appearance Bias in the Wild", "comments": "11 pages, 7 figures. Revision for AI Ethics", "journal-ref": "AI Ethics (2021)", "doi": "10.1007/s43681-020-00035-y", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research in social psychology has shown that people's biased, subjective\njudgments about another's personality based solely on their appearance are not\npredictive of their actual personality traits. But researchers and companies\noften utilize computer vision models to predict similarly subjective\npersonality attributes such as \"employability.\" We seek to determine whether\nstate-of-the-art, black box face processing technology can learn human-like\nappearance biases. With features extracted with FaceNet, a widely used face\nrecognition framework, we train a transfer learning model on human subjects'\nfirst impressions of personality traits in other faces as measured by social\npsychologists. We find that features extracted with FaceNet can be used to\npredict human appearance bias scores for deliberately manipulated faces but not\nfor randomly generated faces scored by humans. Additionally, in contrast to\nwork with human biases in social psychology, the model does not find a\nsignificant signal correlating politicians' vote shares with perceived\ncompetence bias. With Local Interpretable Model-Agnostic Explanations (LIME),\nwe provide several explanations for this discrepancy. Our results suggest that\nsome signals of appearance bias documented in social psychology are not\nembedded by the machine learning techniques we investigate. We shed light on\nthe ways in which appearance bias could be embedded in face processing\ntechnology and cast further doubt on the practice of predicting subjective\ntraits based on appearances.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:09:27 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:39:57 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:15:05 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Steed", "Ryan", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2002.05637", "submitter": "Justin Sybrandt", "authors": "Justin Sybrandt, Ilya Safro", "title": "CBAG: Conditional Biomedical Abstract Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical research papers use significantly different language and jargon\nwhen compared to typical English text, which reduces the utility of pre-trained\nNLP models in this domain. Meanwhile Medline, a database of biomedical\nabstracts, introduces nearly a million new documents per-year. Applications\nthat could benefit from understanding this wealth of publicly available\ninformation, such as scientific writing assistants, chat-bots, or descriptive\nhypothesis generation systems, require new domain-centered approaches. A\nconditional language model, one that learns the probability of words given some\na priori criteria, is a fundamental building block in many such applications.\nWe propose a transformer-based conditional language model with a shallow\nencoder \"condition\" stack, and a deep \"language model\" stack of multi-headed\nattention blocks. The condition stack encodes metadata used to alter the output\nprobability distribution of the language model stack. We sample this\ndistribution in order to generate biomedical abstracts given only a proposed\ntitle, an intended publication year, and a set of keywords. Using typical\nnatural language generation metrics, we demonstrate that this proposed approach\nis more capable of producing non-trivial relevant entities within the abstract\nbody than the 1.5B parameter GPT-2 language model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:11:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Sybrandt", "Justin", ""], ["Safro", "Ilya", ""]]}, {"id": "2002.05643", "submitter": "Stelios Mylonas", "authors": "Stelios K. Mylonas (1), Apostolos Axenopoulos (1), Petros Daras (1)\n  ((1) Information Technologies Institute, Centre for Research and Technology\n  Hellas, Thessaloniki, Greece)", "title": "DeepSurf: A surface-based deep learning approach for the prediction of\n  ligand binding sites on proteins", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btab009", "report-no": null, "categories": "q-bio.BM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The knowledge of potentially druggable binding sites on proteins is an\nimportant preliminary step towards the discovery of novel drugs. The\ncomputational prediction of such areas can be boosted by following the recent\nmajor advances in the deep learning field and by exploiting the increasing\navailability of proper data. In this paper, a novel computational method for\nthe prediction of potential binding sites is proposed, called DeepSurf.\nDeepSurf combines a surface-based representation, where a number of 3D\nvoxelized grids are placed on the protein's surface, with state-of-the-art deep\nlearning architectures. After being trained on the large database of scPDB,\nDeepSurf demonstrates superior results on three diverse testing datasets, by\nsurpassing all its main deep learning-based competitors, while attaining\ncompetitive performance to a set of traditional non-data-driven approaches.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:22:39 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 16:23:19 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Mylonas", "Stelios K.", ""], ["Axenopoulos", "Apostolos", ""], ["Daras", "Petros", ""]]}, {"id": "2002.05645", "submitter": "Maral Mesmakhosroshahi", "authors": "Bharadwaj Pudipeddi, Maral Mesmakhosroshahi, Jinwen Xi, and Sujeeth\n  Bharadwaj", "title": "Training Large Neural Networks with Constant Memory using a New\n  Execution Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Widely popular transformer-based NLP models such as BERT and Turing-NLG have\nenormous capacity trending to billions of parameters. Current execution methods\ndemand brute-force resources such as HBM devices and high speed\ninterconnectivity for data parallelism. In this paper, we introduce a new\nrelay-style execution technique called L2L (layer-to-layer) where at any given\nmoment, the device memory is primarily populated only with the executing\nlayer(s)'s footprint. The model resides in the DRAM memory attached to either a\nCPU or an FPGA as an entity we call eager param-server (EPS). To overcome the\nbandwidth issues of shuttling parameters to and from EPS, the model is executed\na layer at a time across many micro-batches instead of the conventional method\nof minibatches over whole model. L2L is implemented using 16GB V100 devices for\nBERT-Large running it with a device batch size of up to 256. Our results show\n45% reduction in memory and 40% increase in the throughput compared to the\nstate-of-the-art baseline. L2L is also able to fit models up to 50 Billion\nparameters on a machine with a single 16GB V100 and 512GB CPU memory and\nwithout requiring any model partitioning. L2L scales to arbitrary depth\nallowing researchers to develop on affordable devices which is a big step\ntoward democratizing AI. By running the optimizer in the host EPS, we show a\nnew form of mixed precision for faster throughput and convergence. In addition,\nthe EPS enables dynamic neural architecture approaches by varying layers across\niterations. Finally, we also propose and demonstrate a constant memory\nvariation of L2L and we propose future enhancements. This work has been\nperformed on GPUs first, but also targeted towards all high TFLOPS/Watt\naccelerators.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:29:47 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 18:21:52 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 22:51:58 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 23:54:24 GMT"}, {"version": "v5", "created": "Fri, 5 Jun 2020 03:00:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Pudipeddi", "Bharadwaj", ""], ["Mesmakhosroshahi", "Maral", ""], ["Xi", "Jinwen", ""], ["Bharadwaj", "Sujeeth", ""]]}, {"id": "2002.05646", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Magnus Nystr\\\"om, John Lambert, Andrew\n  Marshall, Mario Goertzel, Andi Comissoneru, Matt Swann, Sharon Xia", "title": "Adversarial Machine Learning -- Industry Perspectives", "comments": "Minor Typos corrected 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on interviews with 28 organizations, we found that industry\npractitioners are not equipped with tactical and strategic tools to protect,\ndetect and respond to attacks on their Machine Learning (ML) systems. We\nleverage the insights from the interviews and we enumerate the gaps in\nperspective in securing machine learning systems when viewed in the context of\ntraditional software security development. We write this paper from the\nperspective of two personas: developers/ML engineers and security incident\nresponders who are tasked with securing ML systems as they are designed,\ndeveloped and deployed ML systems. The goal of this paper is to engage\nresearchers to revise and amend the Security Development Lifecycle for\nindustrial-grade software in the adversarial ML era.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:28:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:33:37 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 16:02:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Nystr\u00f6m", "Magnus", ""], ["Lambert", "John", ""], ["Marshall", "Andrew", ""], ["Goertzel", "Mario", ""], ["Comissoneru", "Andi", ""], ["Swann", "Matt", ""], ["Xia", "Sharon", ""]]}, {"id": "2002.05648", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Jonathon Penney, Bruce Schneier, Ram Shankar Siva Kumar", "title": "Politics of Adversarial Machine Learning", "comments": "Authors ordered alphabetically; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to their security properties, adversarial machine-learning\nattacks and defenses have political dimensions. They enable or foreclose\ncertain options for both the subjects of the machine learning systems and for\nthose who deploy them, creating risks for civil liberties and human rights. In\nthis paper, we draw on insights from science and technology studies,\nanthropology, and human rights literature, to inform how defenses against\nadversarial attacks can be used to suppress dissent and limit attempts to\ninvestigate machine learning systems. To make this concrete, we use real-world\nexamples of how attacks such as perturbation, model inversion, or membership\ninference can be used for socially desirable ends. Although the predictions of\nthis analysis may seem dire, there is hope. Efforts to address human rights\nconcerns in the commercial spyware industry provide guidance for similar\nmeasures to ensure ML systems serve democratic, not authoritarian ends\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:15:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:34:56 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 04:59:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Albert", "Kendra", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2002.05651", "submitter": "Peter Henderson", "authors": "Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan\n  Jurafsky, Joelle Pineau", "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate reporting of energy and carbon usage is essential for understanding\nthe potential climate impacts of machine learning research. We introduce a\nframework that makes this easier by providing a simple interface for tracking\nrealtime energy consumption and carbon emissions, as well as generating\nstandardized online appendices. Utilizing this framework, we create a\nleaderboard for energy efficient reinforcement learning algorithms to\nincentivize responsible research in this area as an example for other areas of\nmachine learning. Finally, based on case studies using our framework, we\npropose strategies for mitigation of carbon emissions and reduction of energy\nconsumption. By making accounting easier, we hope to further the sustainable\ndevelopment of machine learning experiments and spur more research into energy\nefficient algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:12:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Henderson", "Peter", ""], ["Hu", "Jieru", ""], ["Romoff", "Joshua", ""], ["Brunskill", "Emma", ""], ["Jurafsky", "Dan", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.05655", "submitter": "Subhro Das", "authors": "Subhro Das, Sebastian Steffen, Wyatt Clarke, Prabhat Reddy, Erik\n  Brynjolfsson, Martin Fleming", "title": "Learning Occupational Task-Shares Dynamics for the Future of Work", "comments": "9 pages, 5 figures, 6 tables, Proceedings of the AAAI/ACM Conference\n  on AI, Ethics, and Society (AIES), 2020", "journal-ref": null, "doi": "10.1145/3375627.3375826", "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent wave of AI and automation has been argued to differ from previous\nGeneral Purpose Technologies (GPTs), in that it may lead to rapid change in\noccupations' underlying task requirements and persistent technological\nunemployment. In this paper, we apply a novel methodology of dynamic task\nshares to a large dataset of online job postings to explore how exactly\noccupational task demands have changed over the past decade of AI innovation,\nespecially across high, mid and low wage occupations. Notably, big data and AI\nhave risen significantly among high wage occupations since 2012 and 2016,\nrespectively. We built an ARIMA model to predict future occupational task\ndemands and showcase several relevant examples in Healthcare, Administration,\nand IT. Such task demands predictions across occupations will play a pivotal\nrole in retraining the workforce of the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 21:20:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Das", "Subhro", ""], ["Steffen", "Sebastian", ""], ["Clarke", "Wyatt", ""], ["Reddy", "Prabhat", ""], ["Brynjolfsson", "Erik", ""], ["Fleming", "Martin", ""]]}, {"id": "2002.05660", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Adam Kalai, Katrina Ligett, and Zhiwei Steven Wu", "title": "Learn to Expect the Unexpected: Probably Approximately Correct Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization is the problem of machine learning when the training\ndata and the test data come from different data domains. We present a simple\ntheoretical model of learning to generalize across domains in which there is a\nmeta-distribution over data distributions, and those data distributions may\neven have different supports. In our model, the training data given to a\nlearning algorithm consists of multiple datasets each from a single domain\ndrawn in turn from the meta-distribution. We study this model in three\ndifferent problem settings---a multi-domain Massart noise setting, a decision\ntree multi-dataset setting, and a feature selection setting, and find that\ncomputationally efficient, polynomial-sample domain generalization is possible\nin each. Experiments demonstrate that our feature selection algorithm indeed\nignores spurious correlations and improves generalization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:37:53 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Garg", "Vikas K.", ""], ["Kalai", "Adam", ""], ["Ligett", "Katrina", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.05665", "submitter": "Hatem Hajri", "authors": "Jeanine Harb, Nicolas R\\'eb\\'ena, Rapha\\\"el Chosidow, Gr\\'egoire\n  Roblin, Roman Potarusov and Hatem Hajri", "title": "FRSign: A Large-Scale Traffic Light Dataset for Autonomous Trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the realm of autonomous transportation, there have been many initiatives\nfor open-sourcing self-driving cars datasets, but much less for alternative\nmethods of transportation such as trains. In this paper, we aim to bridge the\ngap by introducing FRSign, a large-scale and accurate dataset for vision-based\nrailway traffic light detection and recognition. Our recordings were made on\nselected running trains in France and benefited from carefully hand-labeled\nannotations. An illustrative dataset which corresponds to ten percent of the\nacquired data to date is published in open source with the paper. It contains\nmore than 100,000 images illustrating six types of French railway traffic\nlights and their possible color combinations, together with the relevant\ninformation regarding their acquisition such as date, time, sensor parameters,\nand bounding boxes. This dataset is published in open-source at the address\n\\url{https://frsign.irt-systemx.fr}. We compare, analyze various properties of\nthe dataset and provide metrics to express its variability. We also discuss\nspecific challenges and particularities related to autonomous trains in\ncomparison to autonomous cars.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 15:08:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Harb", "Jeanine", ""], ["R\u00e9b\u00e9na", "Nicolas", ""], ["Chosidow", "Rapha\u00ebl", ""], ["Roblin", "Gr\u00e9goire", ""], ["Potarusov", "Roman", ""], ["Hajri", "Hatem", ""]]}, {"id": "2002.05674", "submitter": "Micha{\\l} Ku\\'zba", "authors": "Micha{\\l} Ku\\'zba, Przemys{\\l}aw Biecek", "title": "What Would You Ask the Machine Learning Model? Identification of User\n  Needs for Model Explanations Based on Human-Model Conversations", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we see a rising number of methods in the field of eXplainable\nArtificial Intelligence. To our surprise, their development is driven by model\ndevelopers rather than a study of needs for human end users. The analysis of\nneeds, if done, takes the form of an A/B test rather than a study of open\nquestions. To answer the question \"What would a human operator like to ask the\nML model?\" we propose a conversational system explaining decisions of the\npredictive model. In this experiment, we developed a chatbot called dr_ant to\ntalk about machine learning model trained to predict survival odds on Titanic.\nPeople can talk with dr_ant about different aspects of the model to understand\nthe rationale behind its predictions. Having collected a corpus of 1000+\ndialogues, we analyse the most common types of questions that users would like\nto ask. To our knowledge, it is the first study which uses a conversational\nsystem to collect the needs of human operators from the interactive and\niterative dialogue explorations of a predictive model.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:59:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:14:08 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 13:49:43 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ku\u017aba", "Micha\u0142", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.05678", "submitter": "Abram Magner", "authors": "Abram Magner and Mayank Baranwal and Alfred O. Hero III", "title": "The Power of Graph Convolutional Networks to Distinguish Random Graph\n  Models: Short Version", "comments": "Conference version of arXiv:1910.12954", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are a widely used method for graph\nrepresentation learning. We investigate the power of GCNs, as a function of\ntheir number of layers, to distinguish between different random graph models on\nthe basis of the embeddings of their sample graphs. In particular, the graph\nmodels that we consider arise from graphons, which are the most general\npossible parameterizations of infinite exchangeable graph models and which are\nthe central objects of study in the theory of dense graph limits. We exhibit an\ninfinite class of graphons that are well-separated in terms of cut distance and\nare indistinguishable by a GCN with nonlinear activation functions coming from\na certain broad class if its depth is at least logarithmic in the size of the\nsample graph. These results theoretically match empirical observations of\nseveral prior works. Finally, we show a converse result that for pairs of\ngraphons satisfying a degree profile separation property, a very simple GCN\narchitecture suffices for distinguishability. To prove our results, we exploit\na connection to random walks on graphs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:58:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Magner", "Abram", ""], ["Baranwal", "Mayank", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "2002.05683", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Asuman Ozdaglar, Sarath Pattathil", "title": "An Optimal Multistage Stochastic Gradient Method for Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the minimax optimization problem in the smooth and\nstrongly convex-strongly concave setting when we have access to noisy estimates\nof gradients. In particular, we first analyze the stochastic Gradient Descent\nAscent (GDA) method with constant stepsize, and show that it converges to a\nneighborhood of the solution of the minimax problem. We further provide tight\nbounds on the convergence rate and the size of this neighborhood. Next, we\npropose a multistage variant of stochastic GDA (M-GDA) that runs in multiple\nstages with a particular learning rate decay schedule and converges to the\nexact solution of the minimax problem. We show M-GDA achieves the lower bounds\nin terms of noise dependence without any assumptions on the knowledge of noise\ncharacteristics. We also show that M-GDA obtains a linear decay rate with\nrespect to the error's dependence on the initial error, although the dependence\non condition number is suboptimal. In order to improve this dependence, we\napply the multistage machinery to the stochastic Optimistic Gradient Descent\nAscent (OGDA) algorithm and propose the M-OGDA algorithm which also achieves\nthe optimal linear decay rate with respect to the initial error. To the best of\nour knowledge, this method is the first to simultaneously achieve the best\ndependence on noise characteristic as well as the initial error and condition\nnumber.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:01:18 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Fallah", "Alireza", ""], ["Ozdaglar", "Asuman", ""], ["Pattathil", "Sarath", ""]]}, {"id": "2002.05685", "submitter": "Umut \\c{S}im\\c{s}ekli", "authors": "Umut \\c{S}im\\c{s}ekli, Lingjiong Zhu, Yee Whye Teh, Mert\n  G\\\"urb\\\"uzbalaban", "title": "Fractional Underdamped Langevin Dynamics: Retargeting SGD with Momentum\n  under Heavy-Tailed Gradient Noise", "comments": "20 pages, Published at International Conference on Machine Learning\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent with momentum (SGDm) is one of the most popular\noptimization algorithms in deep learning. While there is a rich theory of SGDm\nfor convex problems, the theory is considerably less developed in the context\nof deep learning where the problem is non-convex and the gradient noise might\nexhibit a heavy-tailed behavior, as empirically observed in recent studies. In\nthis study, we consider a \\emph{continuous-time} variant of SGDm, known as the\nunderdamped Langevin dynamics (ULD), and investigate its asymptotic properties\nunder heavy-tailed perturbations. Supported by recent studies from statistical\nphysics, we argue both theoretically and empirically that the heavy-tails of\nsuch perturbations can result in a bias even when the step-size is small, in\nthe sense that \\emph{the optima of stationary distribution} of the dynamics\nmight not match \\emph{the optima of the cost function to be optimized}. As a\nremedy, we develop a novel framework, which we coin as \\emph{fractional} ULD\n(FULD), and prove that FULD targets the so-called Gibbs distribution, whose\noptima exactly match the optima of the original cost. We observe that the Euler\ndiscretization of FULD has noteworthy algorithmic similarities with\n\\emph{natural gradient} methods and \\emph{gradient clipping}, bringing a new\nperspective on understanding their role in deep learning. We support our theory\nwith experiments conducted on a synthetic model and neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:04:27 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:17:37 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["\u015eim\u015fekli", "Umut", ""], ["Zhu", "Lingjiong", ""], ["Teh", "Yee Whye", ""], ["G\u00fcrb\u00fczbalaban", "Mert", ""]]}, {"id": "2002.05687", "submitter": "Emma Pierce-Hoffman", "authors": "Isaac Robinson, Emma Pierce-Hoffman", "title": "Tree-SNE: Hierarchical Clustering and Visualization Using t-SNE", "comments": "19 pages, 19 figures (from 36 image files)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-SNE and hierarchical clustering are popular methods of exploratory data\nanalysis, particularly in biology. Building on recent advances in speeding up\nt-SNE and obtaining finer-grained structure, we combine the two to create\ntree-SNE, a hierarchical clustering and visualization algorithm based on\nstacked one-dimensional t-SNE embeddings. We also introduce alpha-clustering,\nwhich recommends the optimal cluster assignment, without foreknowledge of the\nnumber of clusters, based off of the cluster stability across multiple scales.\nWe demonstrate the effectiveness of tree-SNE and alpha-clustering on images of\nhandwritten digits, mass cytometry (CyTOF) data from blood cells, and\nsingle-cell RNA-sequencing (scRNA-seq) data from retinal cells. Furthermore, to\ndemonstrate the validity of the visualization, we use alpha-clustering to\nobtain unsupervised clustering results competitive with the state of the art on\nseveral image data sets. Software is available at\nhttps://github.com/isaacrob/treesne.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:11:00 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Robinson", "Isaac", ""], ["Pierce-Hoffman", "Emma", ""]]}, {"id": "2002.05688", "submitter": "Gabriel Eilertsen", "authors": "Gabriel Eilertsen, Daniel J\\\"onsson, Timo Ropinski, Jonas Unger,\n  Anders Ynnerman", "title": "Classifying the classifier: dissecting the weight space of neural\n  networks", "comments": "ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical study on the weights of neural networks,\nwhere we interpret each model as a point in a high-dimensional space -- the\nneural weight space. To explore the complex structure of this space, we sample\nfrom a diverse selection of training variations (dataset, optimization\nprocedure, architecture, etc.) of neural network classifiers, and train a large\nnumber of models to represent the weight space. Then, we use a machine learning\napproach for analyzing and extracting information from this space. Most\ncentrally, we train a number of novel deep meta-classifiers with the objective\nof classifying different properties of the training setup by identifying their\nfootprints in the weight space. Thus, the meta-classifiers probe for patterns\ninduced by hyper-parameters, so that we can quantify how much, where, and when\nthese are encoded through the optimization process. This provides a novel and\ncomplementary view for explainable AI, and we show how meta-classifiers can\nreveal a great deal of information about the training setup and optimization,\nby only considering a small subset of randomly selected consecutive weights. To\npromote further research on the weight space, we release the neural weight\nspace (NWS) dataset -- a collection of 320K weight snapshots from 16K\nindividually trained deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:12:02 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Eilertsen", "Gabriel", ""], ["J\u00f6nsson", "Daniel", ""], ["Ropinski", "Timo", ""], ["Unger", "Jonas", ""], ["Ynnerman", "Anders", ""]]}, {"id": "2002.05700", "submitter": "Gregory Kahn", "authors": "Gregory Kahn, Pieter Abbeel, Sergey Levine", "title": "BADGR: An Autonomous Self-Supervised Learning-Based Navigation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robot navigation is typically regarded as a geometric problem, in\nwhich the robot's objective is to perceive the geometry of the environment in\norder to plan collision-free paths towards a desired goal. However, a purely\ngeometric view of the world can can be insufficient for many navigation\nproblems. For example, a robot navigating based on geometry may avoid a field\nof tall grass because it believes it is untraversable, and will therefore fail\nto reach its desired goal. In this work, we investigate how to move beyond\nthese purely geometric-based approaches using a method that learns about\nphysical navigational affordances from experience. Our approach, which we call\nBADGR, is an end-to-end learning-based mobile robot navigation system that can\nbe trained with self-supervised off-policy data gathered in real-world\nenvironments, without any simulation or human supervision. BADGR can navigate\nin real-world urban and off-road environments with geometrically distracting\nobstacles. It can also incorporate terrain preferences, generalize to novel\nenvironments, and continue to improve autonomously by gathering more data.\nVideos, code, and other supplemental material are available on our website\nhttps://sites.google.com/view/badgr\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:40:21 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 18:31:03 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kahn", "Gregory", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "2002.05702", "submitter": "Pietro Nardelli", "authors": "Pietro Nardelli, James C. Ross, Ra\\'ul San Jos\\'e Est\\'epar", "title": "Generative-based Airway and Vessel Morphology Quantification on Chest CT\n  Images", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.media.2020.101691", "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately and precisely characterizing the morphology of small pulmonary\nstructures from Computed Tomography (CT) images, such as airways and vessels,\nis becoming of great importance for diagnosis of pulmonary diseases. The\nsmaller conducting airways are the major site of increased airflow resistance\nin chronic obstructive pulmonary disease (COPD), while accurately sizing\nvessels can help identify arterial and venous changes in lung regions that may\ndetermine future disorders. However, traditional methods are often limited due\nto image resolution and artifacts.\n  We propose a Convolutional Neural Regressor (CNR) that provides\ncross-sectional measurement of airway lumen, airway wall thickness, and vessel\nradius. CNR is trained with data created by a generative model of synthetic\nstructures which is used in combination with Simulated and Unsupervised\nGenerative Adversarial Network (SimGAN) to create simulated and refined airways\nand vessels with known ground-truth.\n  For validation, we first use synthetically generated airways and vessels\nproduced by the proposed generative model to compute the relative error and\ndirectly evaluate the accuracy of CNR in comparison with traditional methods.\nThen, in-vivo validation is performed by analyzing the association between the\npercentage of the predicted forced expiratory volume in one second (FEV1\\%) and\nthe value of the Pi10 parameter, two well-known measures of lung function and\nairway disease, for airways. For vessels, we assess the correlation between our\nestimate of the small-vessel blood volume and the lungs' diffusing capacity for\ncarbon monoxide (DLCO).\n  The results demonstrate that Convolutional Neural Networks (CNNs) provide a\npromising direction for accurately measuring vessels and airways on chest CT\nimages with physiological correlates.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:45:31 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 16:32:10 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Nardelli", "Pietro", ""], ["Ross", "James C.", ""], ["Est\u00e9par", "Ra\u00fal San Jos\u00e9", ""]]}, {"id": "2002.05706", "submitter": "Junqi Wang", "authors": "Junqi Wang, Pei Wang, Patrick Shafto", "title": "Sequential Cooperative Bayesian Inference", "comments": "25 pages, 22 figures, accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation is often implicitly assumed when learning from other agents.\nCooperation implies that the agent selecting the data, and the agent learning\nfrom the data, have the same goal, that the learner infer the intended\nhypothesis. Recent models in human and machine learning have demonstrated the\npossibility of cooperation. We seek foundational theoretical results for\ncooperative inference by Bayesian agents through sequential data. We develop\nnovel approaches analyzing consistency, rate of convergence and stability of\nSequential Cooperative Bayesian Inference (SCBI). Our analysis of the\neffectiveness, sample efficiency and robustness show that cooperation is not\nonly possible in specific instances but theoretically well-founded in general.\nWe discuss implications for human-human and human-machine cooperation.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:48:06 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 21:21:52 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 13:25:21 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wang", "Junqi", ""], ["Wang", "Pei", ""], ["Shafto", "Patrick", ""]]}, {"id": "2002.05707", "submitter": "Ke Chen", "authors": "William Woof and Ke Chen", "title": "A Framework for End-to-End Learning on Semantic Tree-Structured Data", "comments": "This is a preliminary version of our work. The project is still\n  ongoing. The source code for a JSON-based implementation of our framework\n  along with experiments can be downloaded at\n  https://github.com/EndingCredits/json2vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning models are typically studied for inputs in the form of a fixed\ndimensional feature vector, real world data is rarely found in this form. In\norder to meet the basic requirement of traditional learning models, structural\ndata generally have to be converted into fix-length vectors in a handcrafted\nmanner, which is tedious and may even incur information loss. A common form of\nstructured data is what we term \"semantic tree-structures\", corresponding to\ndata where rich semantic information is encoded in a compositional manner, such\nas those expressed in JavaScript Object Notation (JSON) and eXtensible Markup\nLanguage (XML). For tree-structured data, several learning models have been\nstudied to allow for working directly on raw tree-structure data, However such\nlearning models are limited to either a specific tree-topology or a specific\ntree-structured data format, e.g., synthetic parse trees. In this paper, we\npropose a novel framework for end-to-end learning on generic semantic\ntree-structured data of arbitrary topology and heterogeneous data types, such\nas data expressed in JSON, XML and so on. Motivated by the works in recursive\nand recurrent neural networks, we develop exemplar neural implementations of\nour framework for the JSON format. We evaluate our approach on several UCI\nbenchmark datasets, including ablation and data-efficiency studies, and on a\ntoy reinforcement learning task. Experimental results suggest that our\nframework yields comparable performance to use of standard models with\ndedicated feature-vectors in general, and even exceeds baseline performance in\ncases where compositional nature of the data is particularly important.\n  The source code for a JSON-based implementation of our framework along with\nexperiments can be downloaded at https://github.com/EndingCredits/json2vec.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:49:29 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Woof", "William", ""], ["Chen", "Ke", ""]]}, {"id": "2002.05708", "submitter": "Fabricio Breve", "authors": "Fabricio Aparecido Breve", "title": "Simple Interactive Image Segmentation using Label Propagation through\n  kNN graphs", "comments": null, "journal-ref": "BREVE, Fabricio A. Simple Interactive Image Segmentation using\n  Label Propagation through kNN graphs In: National Meeting on Artificial and\n  Computational Intelligence (ENIAC'2017), 2017, Uberl\\^andia, Minas Gerais,\n  2017", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interactive image segmentation techniques are based on semi-supervised\nlearning. The user may label some pixels from each object and the SSL algorithm\nwill propagate the labels from the labeled to the unlabeled pixels, finding\nobject boundaries. This paper proposes a new SSL graph-based interactive image\nsegmentation approach, using undirected and unweighted kNN graphs, from which\nthe unlabeled nodes receive contributions from other nodes (either labeled or\nunlabeled). It is simpler than many other techniques, but it still achieves\nsignificant classification accuracy in the image segmentation task. Computer\nsimulations are performed using some real-world images, extracted from the\nMicrosoft GrabCut dataset. The segmentation results show the effectiveness of\nthe proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:50:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Breve", "Fabricio Aparecido", ""]]}, {"id": "2002.05709", "submitter": "Ting Chen", "authors": "Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton", "title": "A Simple Framework for Contrastive Learning of Visual Representations", "comments": "ICML'2020. Code and pretrained models at\n  https://github.com/google-research/simclr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents SimCLR: a simple framework for contrastive learning of\nvisual representations. We simplify recently proposed contrastive\nself-supervised learning algorithms without requiring specialized architectures\nor a memory bank. In order to understand what enables the contrastive\nprediction tasks to learn useful representations, we systematically study the\nmajor components of our framework. We show that (1) composition of data\naugmentations plays a critical role in defining effective predictive tasks, (2)\nintroducing a learnable nonlinear transformation between the representation and\nthe contrastive loss substantially improves the quality of the learned\nrepresentations, and (3) contrastive learning benefits from larger batch sizes\nand more training steps compared to supervised learning. By combining these\nfindings, we are able to considerably outperform previous methods for\nself-supervised and semi-supervised learning on ImageNet. A linear classifier\ntrained on self-supervised representations learned by SimCLR achieves 76.5%\ntop-1 accuracy, which is a 7% relative improvement over previous\nstate-of-the-art, matching the performance of a supervised ResNet-50. When\nfine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy,\noutperforming AlexNet with 100X fewer labels.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:50:45 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 15:32:51 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 00:09:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Chen", "Ting", ""], ["Kornblith", "Simon", ""], ["Norouzi", "Mohammad", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.05712", "submitter": "Zhuliang Yao", "authors": "Zhuliang Yao, Yue Cao, Shuxin Zheng, Gao Huang, Stephen Lin", "title": "Cross-Iteration Batch Normalization", "comments": "Accepted to CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-known issue of Batch Normalization is its significantly reduced\neffectiveness in the case of small mini-batch sizes. When a mini-batch contains\nfew examples, the statistics upon which the normalization is defined cannot be\nreliably estimated from it during a training iteration. To address this\nproblem, we present Cross-Iteration Batch Normalization (CBN), in which\nexamples from multiple recent iterations are jointly utilized to enhance\nestimation quality. A challenge of computing statistics over multiple\niterations is that the network activations from different iterations are not\ncomparable to each other due to changes in network weights. We thus compensate\nfor the network weight changes via a proposed technique based on Taylor\npolynomials, so that the statistics can be accurately estimated and batch\nnormalization can be effectively applied. On object detection and image\nclassification with small mini-batch sizes, CBN is found to outperform the\noriginal batch normalization and a direct calculation of statistics over\nprevious iterations without the proposed compensation technique. Code is\navailable at https://github.com/Howal/Cross-iterationBatchNorm .\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:52:57 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 11:10:04 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 06:57:36 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Yao", "Zhuliang", ""], ["Cao", "Yue", ""], ["Zheng", "Shuxin", ""], ["Huang", "Gao", ""], ["Lin", "Stephen", ""]]}, {"id": "2002.05715", "submitter": "Hossein Mobahi", "authors": "Hossein Mobahi, Mehrdad Farajtabar, Peter L. Bartlett", "title": "Self-Distillation Amplifies Regularization in Hilbert Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation introduced in the deep learning context is a method to\ntransfer knowledge from one architecture to another. In particular, when the\narchitectures are identical, this is called self-distillation. The idea is to\nfeed in predictions of the trained model as new target values for retraining\n(and iterate this loop possibly a few times). It has been empirically observed\nthat the self-distilled model often achieves higher accuracy on held out data.\nWhy this happens, however, has been a mystery: the self-distillation dynamics\ndoes not receive any new information about the task and solely evolves by\nlooping over training. To the best of our knowledge, there is no rigorous\nunderstanding of this phenomenon. This work provides the first theoretical\nanalysis of self-distillation. We focus on fitting a nonlinear function to\ntraining data, where the model space is Hilbert space and fitting is subject to\n$\\ell_2$ regularization in this function space. We show that self-distillation\niterations modify regularization by progressively limiting the number of basis\nfunctions that can be used to represent the solution. This implies (as we also\nverify empirically) that while a few rounds of self-distillation may reduce\nover-fitting, further rounds may lead to under-fitting and thus worse\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 18:56:06 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:46:19 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 17:29:22 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mobahi", "Hossein", ""], ["Farajtabar", "Mehrdad", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "2002.05747", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo", "title": "Multiple Metric Learning for Structured Data", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.MG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of merging graph and feature-space information while\nlearning a metric from structured data. Existing algorithms tackle the problem\nin an asymmetric way, by either extracting vectorized summaries of the graph\nstructure or adding hard constraints to feature-space algorithms. Following a\ndifferent path, we define a metric regression scheme where we train\nmetric-constrained linear combinations of dissimilarity matrices. The idea is\nthat the input matrices can be pre-computed dissimilarity measures obtained\nfrom any kind of available data (e.g. node attributes or edge structure). As\nthe model inputs are distance measures, we do not need to assume the existence\nof any underlying feature space. Main challenge is that metric constraints\n(especially positive-definiteness and sub-additivity), are not automatically\nrespected if, for example, the coefficients of the linear combination are\nallowed to be negative. Both positive and sub-additive constraints are linear\ninequalities, but the computational complexity of imposing them scales as\nO(D3), where D is the size of the input matrices (i.e. the size of the data\nset). This becomes quickly prohibitive, even when D is relatively small. We\npropose a new graph-based technique for optimizing under such constraints and\nshow that, in some cases, our approach may reduce the original computational\ncomplexity of the optimization process by one order of magnitude. Contrarily to\nexisting methods, our scheme applies to any (possibly non-convex)\nmetric-constrained objective function.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 19:11:32 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Colombo", "Nicolo", ""]]}, {"id": "2002.05753", "submitter": "Michinari Momma", "authors": "Michinari Momma, Alireza Bagheri Garakani, Nanxun Ma, Yi Sun", "title": "Multi-objective Ranking via Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an Augmented Lagrangian based method to\nincorporate the multiple objectives (MO) in a search ranking algorithm.\nOptimizing MOs is an essential and realistic requirement for building ranking\nmodels in production. The proposed method formulates MO in constrained\noptimization and solves the problem in the popular Boosting framework -- a\nnovel contribution of our work. Furthermore, we propose a procedure to set up\nall optimization parameters in the problem. The experimental results show that\nthe method successfully achieves MO criteria much more efficiently than\nexisting methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 19:30:32 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Momma", "Michinari", ""], ["Garakani", "Alireza Bagheri", ""], ["Ma", "Nanxun", ""], ["Sun", "Yi", ""]]}, {"id": "2002.05770", "submitter": "Yang Liu", "authors": "Yang Liu, Tiexing Wang, Yuexin Jiang, Biao Chen", "title": "Harvesting Ambient RF for Presence Detection Through Deep Learning", "comments": "Source code and datasets are available at Github:\n  https://github.com/bigtreeyanger/presence_detection_cnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the use of ambient radio frequency (RF) signals for human\npresence detection through deep learning. Using WiFi signal as an example, we\ndemonstrate that the channel state information (CSI) obtained at the receiver\ncontains rich information about the propagation environment. Through judicious\npre-processing of the estimated CSI followed by deep learning, reliable\npresence detection can be achieved. Several challenges in passive RF sensing\nare addressed. With presence detection, how to collect training data with human\npresence can have a significant impact on the performance. This is in contrast\nto activity detection when a specific motion pattern is of interest. A second\nchallenge is that RF signals are complex-valued. Handling complex-valued input\nin deep learning requires careful data representation and network architecture\ndesign. Finally, human presence affects CSI variation along multiple\ndimensions; such variation, however, is often masked by system impediments such\nas timing or frequency offset. Addressing these challenges, the proposed\nlearning system uses pre-processing to preserve human motion induced channel\nvariation while insulating against other impairments. A convolutional neural\nnetwork (CNN) properly trained with both magnitude and phase information is\nthen designed to achieve reliable presence detection. Extensive experiments are\nconducted. Using off-the-shelf WiFi devices, the proposed deep learning based\nRF sensing achieves near perfect presence detection during multiple extended\nperiods of test and exhibits superior performance compared with leading edge\npassive infrared sensors. Comparison with existing RF based human presence\ndetection also demonstrates its robustness in performance, especially when\ndeployed in a completely new environment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:35:55 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 16:56:47 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 01:03:59 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Liu", "Yang", ""], ["Wang", "Tiexing", ""], ["Jiang", "Yuexin", ""], ["Chen", "Biao", ""]]}, {"id": "2002.05777", "submitter": "David R\\\"ugamer", "authors": "David R\\\"ugamer, Chris Kolb, Nadja Klein", "title": "Semi-Structured Deep Distributional Regression: Combining Structured\n  Additive Models and Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining additive models and neural networks allows to broaden the scope of\nstatistical regression and extends deep learning-based approaches by\ninterpretable structured additive predictors at the same time. Existing\napproaches uniting the two modeling approaches are, however, limited to very\nspecific combinations and, more importantly, involve an identifiability issue.\nAs a consequence, interpretability and stable estimation is typically lost. We\npropose a general framework to combine structured regression models and deep\nneural networks into a unifying network architecture. To overcome the inherent\nidentifiability issues between different model parts, we construct an\northogonalization cell that projects the deep neural network into the\northogonal complement of the statistical model predictor. This enables proper\nestimation of structured model parts and thereby interpretability. We\ndemonstrate the framework's efficacy in numerical experiments and illustrate\nits special merits in benchmarks and real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 21:01:26 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:06:39 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 13:32:23 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 14:44:21 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["R\u00fcgamer", "David", ""], ["Kolb", "Chris", ""], ["Klein", "Nadja", ""]]}, {"id": "2002.05780", "submitter": "Yunan Ye", "authors": "Yunan Ye, Hengzhi Pei, Boxin Wang, Pin-Yu Chen, Yada Zhu, Jun Xiao, Bo\n  Li", "title": "Reinforcement-Learning based Portfolio Management with Augmented Asset\n  Movement Prediction States", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management (PM) is a fundamental financial planning task that aims\nto achieve investment goals such as maximal profits or minimal risks. Its\ndecision process involves continuous derivation of valuable information from\nvarious data sources and sequential decision optimization, which is a\nprospective research direction for reinforcement learning (RL). In this paper,\nwe propose SARL, a novel State-Augmented RL framework for PM. Our framework\naims to address two unique challenges in financial PM: (1) data heterogeneity\n-- the collected information for each asset is usually diverse, noisy and\nimbalanced (e.g., news articles); and (2) environment uncertainty -- the\nfinancial market is versatile and non-stationary. To incorporate heterogeneous\ndata and enhance robustness against environment uncertainty, our SARL augments\nthe asset information with their price movement prediction as additional\nstates, where the prediction can be solely based on financial data (e.g., asset\nprices) or derived from alternative sources such as news. Experiments on two\nreal-world datasets, (i) Bitcoin market and (ii) HighTech stock market with\n7-year Reuters news articles, validate the effectiveness of SARL over existing\nPM approaches, both in terms of accumulated profits and risk-adjusted profits.\nMoreover, extensive simulations are conducted to demonstrate the importance of\nour proposed state augmentation, providing new insights and boosting\nperformance significantly over standard RL-based PM method and other baselines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 08:10:03 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ye", "Yunan", ""], ["Pei", "Hengzhi", ""], ["Wang", "Boxin", ""], ["Chen", "Pin-Yu", ""], ["Zhu", "Yada", ""], ["Xiao", "Jun", ""], ["Li", "Bo", ""]]}, {"id": "2002.05784", "submitter": "Lior Sidi", "authors": "Lior Sidi", "title": "Improving S&P stock prediction with time series stock similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stock market prediction with forecasting algorithms is a popular topic these\ndays where most of the forecasting algorithms train only on data collected on a\nparticular stock. In this paper, we enriched the stock data with related stocks\njust as a professional trader would have done to improve the stock prediction\nmodels. We tested five different similarities functions and found\nco-integration similarity to have the best improvement on the prediction model.\nWe evaluate the models on seven S&P stocks from various industries over five\nyears period. The prediction model we trained on similar stocks had\nsignificantly better results with 0.55 mean accuracy, and 19.782 profit compare\nto the state of the art model with an accuracy of 0.52 and profit of 6.6.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 14:13:45 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sidi", "Lior", ""]]}, {"id": "2002.05786", "submitter": "Murat Ozbayoglu", "authors": "Ahmet Murat Ozbayoglu, Mehmet Ugur Gudelek, Omer Berat Sezer", "title": "Deep Learning for Financial Applications : A Survey", "comments": "13 Figures, 15 Tables, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational intelligence in finance has been a very popular topic for both\nacademia and financial industry in the last few decades. Numerous studies have\nbeen published resulting in various models. Meanwhile, within the Machine\nLearning (ML) field, Deep Learning (DL) started getting a lot of attention\nrecently, mostly due to its outperformance over the classical models. Lots of\ndifferent implementations of DL exist today, and the broad interest is\ncontinuing. Finance is one particular area where DL models started getting\ntraction, however, the playfield is wide open, a lot of research opportunities\nstill exist. In this paper, we tried to provide a state-of-the-art snapshot of\nthe developed DL models for financial applications, as of today. We not only\ncategorized the works according to their intended subfield in finance but also\nanalyzed them based on their DL models. In addition, we also aimed at\nidentifying possible future implementations and highlighted the pathway for the\nongoing research within the field.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 14:34:56 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ozbayoglu", "Ahmet Murat", ""], ["Gudelek", "Mehmet Ugur", ""], ["Sezer", "Omer Berat", ""]]}, {"id": "2002.05789", "submitter": "Felipe Tobar", "authors": "Taco de Wolff, Alejandro Cuevas, Felipe Tobar", "title": "Gaussian process imputation of multiple financial series", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Financial Signal Processing, multiple time series such as financial\nindicators, stock prices and exchange rates are strongly coupled due to their\ndependence on the latent state of the market and therefore they are required to\nbe jointly analysed. We focus on learning the relationships among financial\ntime series by modelling them through a multi-output Gaussian process (MOGP)\nwith expressive covariance functions. Learning these market dependencies among\nfinancial series is crucial for the imputation and prediction of financial\nobservations. The proposed model is validated experimentally on two real-world\nfinancial datasets for which their correlations across channels are analysed.\nWe compare our model against other MOGPs and the independent Gaussian process\non real financial data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:18:18 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["de Wolff", "Taco", ""], ["Cuevas", "Alejandro", ""], ["Tobar", "Felipe", ""]]}, {"id": "2002.05808", "submitter": "Jian Li", "authors": "Shufan Wang, Jian Li, Shiqiang Wang", "title": "Online Algorithms for Multi-shop Ski Rental with Machine Learned Advice", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of augmenting online algorithms with machine learned\n(ML) advice. In particular, we consider the \\emph{multi-shop ski rental} (MSSR)\nproblem, which is a generalization of the classical ski rental problem. In\nMSSR, each shop has different prices for buying and renting a pair of skis, and\na skier has to make decisions on when and where to buy. We obtain both\ndeterministic and randomized online algorithms with provably improved\nperformance when either a single or multiple ML predictions are used to make\ndecisions. These online algorithms have no knowledge about the quality or the\nprediction error type of the ML prediction. The performance of these online\nalgorithms are robust to the poor performance of the predictors, but improve\nwith better predictions. Extensive experiments using both synthetic and real\nworld data traces verify our theoretical observations and show better\nperformance against algorithms that purely rely on online decision making.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:59:36 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 00:49:52 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Wang", "Shufan", ""], ["Li", "Jian", ""], ["Wang", "Shiqiang", ""]]}, {"id": "2002.05809", "submitter": "Konstantinos P. Panousis", "authors": "Konstantinos P. Panousis, Sotirios Chatzis, Sergios Theodoridis", "title": "Variational Conditional-Dependence Hidden Markov Models for Human Action\n  Recognition", "comments": "Under review ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov Models (HMMs) are a powerful generative approach for modeling\nsequential data and time-series in general. However, the commonly employed\nassumption of the dependence of the current time frame to a single or multiple\nimmediately preceding frames is unrealistic; more complicated dynamics\npotentially exist in real world scenarios. Human Action Recognition constitutes\nsuch a scenario, and has attracted increased attention with the advent of\nlow-cost 3D sensors. The naturally arising variations and complex temporal\ndependencies have established this task as a challenging problem in the\ncommunity. This paper revisits conventional sequential modeling approaches,\naiming to address the problem of capturing time-varying temporal dependency\npatterns. To this end, we propose a different formulation of HMMs, whereby the\ndependence on past frames is dynamically inferred from the data. Specifically,\nwe introduce a hierarchical extension by postulating an additional latent\nvariable layer; therein, the (time-varying) temporal dependence patterns are\ntreated as latent variables over which inference is performed. We leverage\nsolid arguments from the Variational Bayes framework and derive a tractable\ninference algorithm based on the forward-backward algorithm. As we\nexperimentally show using benchmark datasets, our approach yields competitive\nrecognition accuracy and can effectively handle data with missing values.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:18:52 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Panousis", "Konstantinos P.", ""], ["Chatzis", "Sotirios", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "2002.05810", "submitter": "Xinshi Chen", "authors": "Xinshi Chen, Yu Li, Ramzan Umarov, Xin Gao, Le Song", "title": "RNA Secondary Structure Prediction By Learning Unrolled Algorithms", "comments": "International Conference on Learning Representations 2020", "journal-ref": "International Conference on Learning Representations 2020,\n  https://openreview.net/forum?id=S1eALyrYDH", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an end-to-end deep learning model, called E2Efold,\nfor RNA secondary structure prediction which can effectively take into account\nthe inherent constraints in the problem. The key idea of E2Efold is to directly\npredict the RNA base-pairing matrix, and use an unrolled algorithm for\nconstrained programming as the template for deep architectures to enforce\nconstraints. With comprehensive experiments on benchmark datasets, we\ndemonstrate the superior performance of E2Efold: it predicts significantly\nbetter structures compared to previous SOTA (especially for pseudoknotted\nstructures), while being as efficient as the fastest algorithms in terms of\ninference time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:21:25 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Xinshi", ""], ["Li", "Yu", ""], ["Umarov", "Ramzan", ""], ["Gao", "Xin", ""], ["Song", "Le", ""]]}, {"id": "2002.05814", "submitter": "Zhuohan Li", "authors": "Siyuan Zhuang, Zhuohan Li, Danyang Zhuo, Stephanie Wang, Eric Liang,\n  Robert Nishihara, Philipp Moritz, Ion Stoica", "title": "Hoplite: Efficient Collective Communication for Task-Based Distributed\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective communication systems such as MPI offer high performance group\ncommunication primitives at the cost of application flexibility. Today, an\nincreasing number of distributed applications (e.g, reinforcement learning)\nrequire flexibility in expressing dynamic and asynchronous communication\npatterns. To accommodate these applications, task-based distributed computing\nframeworks (e.g., Ray, Dask, Hydro) have become popular as they allow\napplications to dynamically specify communication by invoking tasks, or\nfunctions, at runtime. This design makes efficient collective communication\nchallenging because (1) the group of communicating processes is chosen at\nruntime, and (2) processes may not all be ready at the same time.\n  We design and implement Hoplite, a communication layer for task-based\ndistributed systems that achieves high performance collective communication\nwithout compromising application flexibility. The key idea of Hoplite is to use\ndistributed protocols to compute a data transfer schedule on the fly. This\nenables the same optimizations used in traditional collective communication,\nbut for applications that specify the communication incrementally. We show that\nHoplite can achieve similar performance compared with a traditional collective\ncommunication library, MPICH. We port a popular distributed computing\nframework, Ray, on atop of Hoplite. We show that Hoplite can speed up\nasynchronous parameter server and distributed reinforcement learning workloads\nthat are difficult to execute efficiently with traditional collective\ncommunication by up to 8.1x and 3.9x, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 23:48:54 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhuang", "Siyuan", ""], ["Li", "Zhuohan", ""], ["Zhuo", "Danyang", ""], ["Wang", "Stephanie", ""], ["Liang", "Eric", ""], ["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Stoica", "Ion", ""]]}, {"id": "2002.05815", "submitter": "Jonathan Wells", "authors": "Kai Ming Ting, Jonathan R. Wells and Ye Zhu", "title": "Clustering based on Point-Set Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarity between two objects is the core operation in existing\ncluster analyses in grouping similar objects into clusters. Cluster analyses\nhave been applied to a number of applications, including image segmentation,\nsocial network analysis, and computational biology. This paper introduces a new\nsimilarity measure called point-set kernel which computes the similarity\nbetween an object and a sample of objects generated from an unknown\ndistribution. The proposed clustering procedure utilizes this new measure to\ncharacterize both the typical point of every cluster and the cluster grown from\nthe typical point. We show that the new clustering procedure is both effective\nand efficient such that it can deal with large scale datasets. In contrast,\nexisting clustering algorithms are either efficient or effective; and even\nefficient ones have difficulty dealing with large scale datasets without\nspecial hardware. We show that the proposed algorithm is more effective and\nruns orders of magnitude faster than the state-of-the-art density-peak\nclustering and scalable kernel k-means clustering when applying to datasets of\nmillions of data points, on commonly used computing machines.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:00:03 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Ting", "Kai Ming", ""], ["Wells", "Jonathan R.", ""], ["Zhu", "Ye", ""]]}, {"id": "2002.05820", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, David Balduzzi, Wojciech Marian Czarnecki, Marta\n  Garnelo and Yoram Bachrach", "title": "A Limited-Capacity Minimax Theorem for Non-Convex Games or: How I\n  Learned to Stop Worrying about Mixed-Nash and Love Neural Nets", "comments": "Appears in: Proceedings of the 24th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2021). 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training, a special case of multi-objective optimization, is an\nincreasingly prevalent machine learning technique: some of its most notable\napplications include GAN-based generative modeling and self-play techniques in\nreinforcement learning which have been applied to complex games such as Go or\nPoker. In practice, a \\emph{single} pair of networks is typically trained in\norder to find an approximate equilibrium of a highly nonconcave-nonconvex\nadversarial problem. However, while a classic result in game theory states such\nan equilibrium exists in concave-convex games, there is no analogous guarantee\nif the payoff is nonconcave-nonconvex. Our main contribution is to provide an\napproximate minimax theorem for a large class of games where the players pick\nneural networks including WGAN, StarCraft II, and Blotto Game. Our findings\nrely on the fact that despite being nonconcave-nonconvex with respect to the\nneural networks parameters, these games are concave-convex with respect to the\nactual models (e.g., functions or distributions) represented by these neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:17:24 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:25:32 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 21:37:08 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Gidel", "Gauthier", ""], ["Balduzzi", "David", ""], ["Czarnecki", "Wojciech Marian", ""], ["Garnelo", "Marta", ""], ["Bachrach", "Yoram", ""]]}, {"id": "2002.05822", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Jincheng Mei, Amir-massoud Farahmand", "title": "Frequency-based Search-control in Dyna", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning has been empirically demonstrated as a\nsuccessful strategy to improve sample efficiency. In particular, Dyna is an\nelegant model-based architecture integrating learning and planning that\nprovides huge flexibility of using a model. One of the most important\ncomponents in Dyna is called search-control, which refers to the process of\ngenerating state or state-action pairs from which we query the model to acquire\nsimulated experiences. Search-control is critical in improving learning\nefficiency. In this work, we propose a simple and novel search-control strategy\nby searching high frequency regions of the value function. Our main intuition\nis built on Shannon sampling theorem from signal processing, which indicates\nthat a high frequency signal requires more samples to reconstruct. We\nempirically show that a high frequency function is more difficult to\napproximate. This suggests a search-control strategy: we should use states from\nhigh frequency regions of the value function to query the model to acquire more\nsamples. We develop a simple strategy to locally measure the frequency of a\nfunction by gradient and hessian norms, and provide theoretical justification\nfor this approach. We then apply our strategy to search-control in Dyna, and\nconduct experiments to show its property and effectiveness on benchmark\ndomains.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:27:58 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Pan", "Yangchen", ""], ["Mei", "Jincheng", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2002.05825", "submitter": "Silviu Pitis", "authors": "Silviu Pitis, Harris Chan, Kiarash Jamali, Jimmy Ba", "title": "An Inductive Bias for Distances: Neural Nets that Respect the Triangle\n  Inequality", "comments": "11 pages (+18 appendix). Published as a conference paper at ICLR\n  2020. https://openreview.net/forum?id=HJeiDpVFPr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances are pervasive in machine learning. They serve as similarity\nmeasures, loss functions, and learning targets; it is said that a good distance\nmeasure solves a task. When defining distances, the triangle inequality has\nproven to be a useful constraint, both theoretically--to prove convergence and\noptimality guarantees--and empirically--as an inductive bias. Deep metric\nlearning architectures that respect the triangle inequality rely, almost\nexclusively, on Euclidean distance in the latent space. Though effective, this\nfails to model two broad classes of subadditive distances, common in graphs and\nreinforcement learning: asymmetric metrics, and metrics that cannot be embedded\ninto Euclidean space. To address these problems, we introduce novel\narchitectures that are guaranteed to satisfy the triangle inequality. We prove\nour architectures universally approximate norm-induced metrics on\n$\\mathbb{R}^n$, and present a similar result for modified Input Convex Neural\nNetworks. We show that our architectures outperform existing metric approaches\nwhen modeling graph distances and have a better inductive bias than non-metric\napproaches when training data is limited in the multi-goal reinforcement\nlearning setting.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:47:31 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 18:23:59 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 20:06:56 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pitis", "Silviu", ""], ["Chan", "Harris", ""], ["Jamali", "Kiarash", ""], ["Ba", "Jimmy", ""]]}, {"id": "2002.05826", "submitter": "Yuichi Yoshida", "authors": "Tasuku Soma and Yuichi Yoshida", "title": "Statistical Learning with Conditional Value at Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a risk-averse statistical learning framework wherein the\nperformance of a learning algorithm is evaluated by the conditional\nvalue-at-risk (CVaR) of losses rather than the expected loss. We devise\nalgorithms based on stochastic gradient descent for this framework. While\nexisting studies of CVaR optimization require direct access to the underlying\ndistribution, our algorithms make a weaker assumption that only i.i.d.\\ samples\nare given. For convex and Lipschitz loss functions, we show that our algorithm\nhas $O(1/\\sqrt{n})$-convergence to the optimal CVaR, where $n$ is the number of\nsamples. For nonconvex and smooth loss functions, we show a generalization\nbound on CVaR. By conducting numerical experiments on various machine learning\ntasks, we demonstrate that our algorithms effectively minimize CVaR compared\nwith other baseline algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:58:34 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Soma", "Tasuku", ""], ["Yoshida", "Yuichi", ""]]}, {"id": "2002.05842", "submitter": "C.B. Scott", "authors": "C.B. Scott and Eric Mjolsness", "title": "Graph Prolongation Convolutional Networks: Explicitly Multiscale Machine\n  Learning on Graphs with Applications to Modeling of Cytoskeleton", "comments": "Revised version submitted to IOP: Machine Learning, Science, and\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a novel type of ensemble Graph Convolutional Network (GCN) model.\nUsing optimized linear projection operators to map between spatial scales of\ngraph, this ensemble model learns to aggregate information from each scale for\nits final prediction. We calculate these linear projection operators as the\ninfima of an objective function relating the structure matrices used for each\nGCN. Equipped with these projections, our model (a Graph\nProlongation-Convolutional Network) outperforms other GCN ensemble models at\npredicting the potential energy of monomer subunits in a coarse-grained\nmechanochemical simulation of microtubule bending. We demonstrate these\nperformance gains by measuring an estimate of the FLOPs spent to train each\nmodel, as well as wall-clock time. Because our model learns at multiple scales,\nit is possible to train at each scale according to a predetermined schedule of\ncoarse vs. fine training. We examine several such schedules adapted from the\nAlgebraic Multigrid (AMG) literature, and quantify the computational benefit of\neach. We also compare this model to another model which features an optimized\ncoarsening of the input graph. Finally, we derive backpropagation rules for the\ninput of our network model with respect to its output, and discuss how our\nmethod may be extended to very large graphs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 01:56:17 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 23:41:33 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Scott", "C. B.", ""], ["Mjolsness", "Eric", ""]]}, {"id": "2002.05856", "submitter": "Christopher Metzler", "authors": "Christopher A. Metzler and Gordon Wetzstein", "title": "Deep S$^3$PR: Simultaneous Source Separation and Phase Retrieval Using\n  Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and solves the simultaneous source separation and phase\nretrieval (S$^3$PR) problem. S$^3$PR is an important but largely unsolved\nproblem in a number application domains, including microscopy, wireless\ncommunication, and imaging through scattering media, where one has multiple\nindependent coherent sources whose phase is difficult to measure. In general,\nS$^3$PR is highly under-determined, non-convex, and difficult to solve. In this\nwork, we demonstrate that by restricting the solutions to lie in the range of a\ndeep generative model, we can constrain the search space sufficiently to solve\nS$^3$PR.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 03:20:26 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 01:55:29 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Metzler", "Christopher A.", ""], ["Wetzstein", "Gordon", ""]]}, {"id": "2002.05873", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Kohei Yatabe, Marc Delcroix, Yoshiki Masuyama, Daiki\n  Takeuchi", "title": "Speech Enhancement using Self-Adaptation and Multi-Head Self-Attention", "comments": "5 pages, to appear in IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a self-adaptation method for speech enhancement using\nauxiliary speaker-aware features; we extract a speaker representation used for\nadaptation directly from the test utterance. Conventional studies of deep\nneural network (DNN)--based speech enhancement mainly focus on building a\nspeaker independent model. Meanwhile, in speech applications including speech\nrecognition and synthesis, it is known that model adaptation to the target\nspeaker improves the accuracy. Our research question is whether a DNN for\nspeech enhancement can be adopted to unknown speakers without any auxiliary\nguidance signal in test-phase. To achieve this, we adopt multi-task learning of\nspeech enhancement and speaker identification, and use the output of the final\nhidden layer of speaker identification branch as an auxiliary feature. In\naddition, we use multi-head self-attention for capturing long-term dependencies\nin the speech and noise. Experimental results on a public dataset show that our\nstrategy achieves the state-of-the-art performance and also outperform\nconventional methods in terms of subjective quality.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 05:05:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Koizumi", "Yuma", ""], ["Yatabe", "Kohei", ""], ["Delcroix", "Marc", ""], ["Masuyama", "Yoshiki", ""], ["Takeuchi", "Daiki", ""]]}, {"id": "2002.05878", "submitter": "Rongye Shi", "authors": "Zhicheng Gu, Zhihao Li, Xuan Di, Rongye Shi", "title": "An LSTM-Based Autonomous Driving Model Using Waymo Open Dataset", "comments": null, "journal-ref": "Applied Sciences 10(6) 2046, 2020", "doi": "10.3390/app10062046", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Waymo Open Dataset has been released recently, providing a platform to\ncrowdsource some fundamental challenges for automated vehicles (AVs), such as\n3D detection and tracking. While~the dataset provides a large amount of\nhigh-quality and multi-source driving information, people in academia are more\ninterested in the underlying driving policy programmed in Waymo self-driving\ncars, which is inaccessible due to AV manufacturers' proprietary protection.\nAccordingly, academic researchers have to make various assumptions to implement\nAV components in their models or simulations, which may not represent the\nrealistic interactions in real-world traffic. Thus, this paper introduces an\napproach to learn a long short-term memory (LSTM)-based model for imitating the\nbehavior of Waymo's self-driving model. The proposed model has been evaluated\nbased on Mean Absolute Error (MAE). The experimental results show that our\nmodel outperforms several baseline models in driving action prediction. In\naddition, a visualization tool is presented for verifying the performance of\nthe model.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 05:28:15 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 16:25:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Gu", "Zhicheng", ""], ["Li", "Zhihao", ""], ["Di", "Xuan", ""], ["Shi", "Rongye", ""]]}, {"id": "2002.05879", "submitter": "Masaki Kawanaka", "authors": "Masaki Kawanaka, Yuma Koizumi, Ryoichi Miyazaki and Kohei Yatabe", "title": "Stable Training of DNN for Speech Enhancement based on\n  Perceptually-Motivated Black-Box Cost Function", "comments": "accepted to the 45th International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving subjective sound quality of enhanced signals is one of the most\nimportant missions in speech enhancement. For evaluating the subjective\nquality, several methods related to perceptually-motivated objective sound\nquality assessment (OSQA) have been proposed such as PESQ (perceptual\nevaluation of speech quality). However, direct use of such measures for\ntraining deep neural network (DNN) is not allowed in most cases because popular\nOSQAs are non-differentiable with respect to DNN parameters. Therefore, the\nprevious study has proposed to approximate the score of OSQAs by an auxiliary\nDNN so that its gradient can be used for training the primary DNN. One problem\nwith this approach is instability of the training caused by the approximation\nerror of the score. To overcome this problem, we propose to use stabilization\ntechniques borrowed from reinforcement learning. The experiments, aimed to\nincrease the score of PESQ as an example, show that the proposed method (i) can\nstably train a DNN to increase PESQ, (ii) achieved the state-of-the-art PESQ\nscore on a public dataset, and (iii) resulted in better sound quality than\nconventional methods based on subjective evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 05:44:17 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kawanaka", "Masaki", ""], ["Koizumi", "Yuma", ""], ["Miyazaki", "Ryoichi", ""], ["Yatabe", "Kohei", ""]]}, {"id": "2002.05897", "submitter": "Wouter Verbeke", "authors": "Floris Devriendt, Tias Guns and Wouter Verbeke", "title": "Learning to rank for uplift modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling has effectively been used in fields such as marketing and\ncustomer retention, to target those customers that are most likely to respond\ndue to the campaign or treatment. Uplift models produce uplift scores which are\nthen used to essentially create a ranking. We instead investigate to learn to\nrank directly by looking into the potential of learning-to-rank techniques in\nthe context of uplift modeling. We propose a unified formalisation of different\nglobal uplift modeling measures in use today and explore how these can be\nintegrated into the learning-to-rank framework. Additionally, we introduce a\nnew metric for learning-to-rank that focusses on optimizing the area under the\nuplift curve called the promoted cumulative gain (PCG). We employ the\nlearning-to-rank technique LambdaMART to optimize the ranking according to PCG\nand show improved results over standard learning-to-rank metrics and equal to\nimproved results when compared with state-of-the-art uplift modeling. Finally,\nwe show how learning-to-rank models can learn to optimize a certain targeting\ndepth, however, these results do not generalize on the test set.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 07:37:16 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Devriendt", "Floris", ""], ["Guns", "Tias", ""], ["Verbeke", "Wouter", ""]]}, {"id": "2002.05905", "submitter": "Omar Ibrahim Mr", "authors": "Omar Adel Ibrahim, Savio Sciancalepore, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "MAGNETO: Fingerprinting USB Flash Drives via Unintentional Magnetic\n  Emissions", "comments": "Accepted for publication in ACM Transactions on Embedded Computing\n  Systems (TECS) in September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Serial Bus (USB) Flash Drives are nowadays one of the most\nconvenient and diffused means to transfer files, especially when no Internet\nconnection is available. However, USB flash drives are also one of the most\ncommon attack vectors used to gain unauthorized access to host devices. For\ninstance, it is possible to replace a USB drive so that when the USB key is\nconnected, it would install passwords stealing tools, root-kit software, and\nother disrupting malware. In such a way, an attacker can steal sensitive\ninformation via the USB-connected devices, as well as inject any kind of\nmalicious software into the host.\n  To thwart the above-cited raising threats, we propose MAGNETO, an efficient,\nnon-interactive, and privacy-preserving framework to verify the authenticity of\na USB flash drive, rooted in the analysis of its unintentional magnetic\nemissions. We show that the magnetic emissions radiated during boot operations\non a specific host are unique for each device, and sufficient to uniquely\nfingerprint both the brand and the model of the USB flash drive, or the\nspecific USB device, depending on the used equipment. Our investigation on 59\ndifferent USB flash drives---belonging to 17 brands, including the top brands\npurchased on Amazon in mid-2019---, reveals a minimum classification accuracy\nof 98.2% in the identification of both brand and model, accompanied by a\nnegligible time and computational overhead. MAGNETO can also identify the\nspecific USB Flash drive, with a minimum classification accuracy of 91.2%.\nOverall, MAGNETO proves that unintentional magnetic emissions can be considered\nas a viable and reliable means to fingerprint read-only USB flash drives.\nFinally, future research directions in this domain are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:09:54 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 12:33:20 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 02:34:33 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Ibrahim", "Omar Adel", ""], ["Sciancalepore", "Savio", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2002.05909", "submitter": "William Gilpin", "authors": "William Gilpin", "title": "Deep reconstruction of strange attractors from time series", "comments": "9 pages, 6 figures, plus appendices", "journal-ref": "NeurIPS (Neural Information Processing Systems) 2020", "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.data-an q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental measurements of physical systems often have a limited number of\nindependent channels, causing essential dynamical variables to remain\nunobserved. However, many popular methods for unsupervised inference of latent\ndynamics from experimental data implicitly assume that the measurements have\nhigher intrinsic dimensionality than the underlying system---making coordinate\nidentification a dimensionality reduction problem. Here, we study the opposite\nlimit, in which hidden governing coordinates must be inferred from only a\nlow-dimensional time series of measurements. Inspired by classical analysis\ntechniques for partial observations of chaotic attractors, we introduce a\ngeneral embedding technique for univariate and multivariate time series,\nconsisting of an autoencoder trained with a novel latent-space loss function.\nWe show that our technique reconstructs the strange attractors of synthetic and\nreal-world systems better than existing techniques, and that it creates\nconsistent, predictive representations of even stochastic systems. We conclude\nby using our technique to discover dynamical attractors in diverse systems such\nas patient electrocardiograms, household electricity usage, neural spiking, and\neruptions of the Old Faithful geyser---demonstrating diverse applications of\nour technique for exploratory data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:14:52 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 12:18:43 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 12:02:15 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Gilpin", "William", ""]]}, {"id": "2002.05923", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Pascale Fung", "title": "Zero-Resource Cross-Domain Named Entity Recognition", "comments": "RepL4NLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models for cross-domain named entity recognition (NER) rely on\nnumerous unlabeled corpus or labeled NER training data in target domains.\nHowever, collecting data for low-resource target domains is not only expensive\nbut also time-consuming. Hence, we propose a cross-domain NER model that does\nnot use any external resources. We first introduce a Multi-Task Learning (MTL)\nby adding a new objective function to detect whether tokens are named entities\nor not. We then introduce a framework called Mixture of Entity Experts (MoEE)\nto improve the robustness for zero-resource domain adaptation. Finally,\nexperimental results show that our model outperforms strong unsupervised\ncross-domain sequence labeling models, and the performance of our model is\nclose to that of the state-of-the-art model which leverages extensive\nresources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:04:18 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 11:56:07 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "2002.05929", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Dinh Thai Hoang, Dusit Niyato, Derek Leong,\n  Ping Wang, and Zhu Han", "title": "Optimal Pricing of Internet of Things: A Machine Learning Approach", "comments": "17 pages", "journal-ref": "IEEE Journal on Selected Areas in Communications, 2020 dIEEE\n  Journal on Selected Areas in Communications IEEE Journal on Selected Areas in\n  Communications", "doi": "10.1109/JSAC.2020.2971898 10.1109/JSAC.2020.2971898", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of things (IoT) produces massive data from devices embedded with\nsensors. The IoT data allows creating profitable services using machine\nlearning. However, previous research does not address the problem of optimal\npricing and bundling of machine learning-based IoT services. In this paper, we\ndefine the data value and service quality from a machine learning perspective.\nWe present an IoT market model which consists of data vendors selling data to\nservice providers, and service providers offering IoT services to customers.\nThen, we introduce optimal pricing schemes for the standalone and bundled\nselling of IoT services. In standalone service sales, the service provider\noptimizes the size of bought data and service subscription fee to maximize its\nprofit. For service bundles, the subscription fee and data sizes of the grouped\nIoT services are optimized to maximize the total profit of cooperative service\nproviders. We show that bundling IoT services maximizes the profit of service\nproviders compared to the standalone selling. For profit sharing of bundled\nservices, we apply the concepts of core and Shapley solutions from cooperative\ngame theory as efficient and fair allocations of payoffs among the cooperative\nservice providers in the bundling coalition.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:17:40 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""], ["Leong", "Derek", ""], ["Wang", "Ping", ""], ["Han", "Zhu", ""]]}, {"id": "2002.05936", "submitter": "Marcus Scheunemann", "authors": "Marcus M. Scheunemann, Christoph Salge, Daniel Polani, Kerstin\n  Dautenhahn", "title": "Human Perception of Intrinsically Motivated Autonomy in Human-Robot\n  Interaction", "comments": "32 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge in using robots in human-inhabited environments is to design\nbehavior that is engaging, yet robust to the perturbations induced by human\ninteraction. Our idea is to imbue the robot with intrinsic motivation (IM) so\nthat it can handle new situations and appears as a genuine social other to\nhumans and thus be of more interest to a human interaction partner. Human-robot\ninteraction (HRI) experiments mainly focus on scripted or teleoperated robots,\nthat mimic characteristics such as IM to control isolated behavior factors.\nThis article presents a \"robotologist\" study design that allows comparing\nautonomously generated behaviors with each other, and, for the first time,\nevaluates the human perception of IM-based generated behavior in robots. We\nconducted a within-subjects user study (N=24) where participants interacted\nwith a fully autonomous Sphero BB8 robot with different behavioral regimes: one\nrealizing an adaptive, intrinsically motivated behavior and the other being\nreactive, but not adaptive. A quantitative analysis of post-interaction\nquestionnaires showed a significantly higher perception of the dimension\n\"Warmth\" compared to the reactive baseline behavior. Warmth is considered a\nprimary dimension for social attitude formation in human social cognition. A\nhuman perceived as warm (friendly, trustworthy) experiences more positive\nsocial interactions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:49:36 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:40:53 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 17:54:22 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Scheunemann", "Marcus M.", ""], ["Salge", "Christoph", ""], ["Polani", "Daniel", ""], ["Dautenhahn", "Kerstin", ""]]}, {"id": "2002.05954", "submitter": "Sammy Christen", "authors": "Sammy Christen, Lukas Jendele, Emre Aksan, Otmar Hilliges", "title": "Learning Functionally Decomposed Hierarchies for Continuous Control\n  Tasks with Path Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present HiDe, a novel hierarchical reinforcement learning architecture\nthat successfully solves long horizon control tasks and generalizes to unseen\ntest scenarios. Functional decomposition between planning and low-level control\nis achieved by explicitly separating the state-action spaces across the\nhierarchy, which allows the integration of task-relevant knowledge per layer.\nWe propose an RL-based planner to efficiently leverage the information in the\nplanning layer of the hierarchy, while the control layer learns a\ngoal-conditioned control policy. The hierarchy is trained jointly but allows\nfor the composition of different policies such as transferring layers across\nmultiple agents. We experimentally show that our method generalizes across\nunseen test environments and can scale to tasks well beyond 3x horizon length\ncompared to both learning and non-learning based approaches. We evaluate on\ncomplex continuous control tasks with sparse rewards, including navigation and\nrobot manipulation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:19:52 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 12:01:32 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 11:38:36 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Christen", "Sammy", ""], ["Jendele", "Lukas", ""], ["Aksan", "Emre", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2002.05955", "submitter": "Laurent Besacier", "authors": "Marco Dinarelli, Nikita Kapoor, Bassam Jabaian, and Laurent Besacier", "title": "A Data Efficient End-To-End Spoken Language Understanding Architecture", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  End-to-end architectures have been recently proposed for spoken language\nunderstanding (SLU) and semantic parsing. Based on a large amount of data,\nthose models learn jointly acoustic and linguistic-sequential features. Such\narchitectures give very good results in the context of domain, intent and slot\ndetection, their application in a more complex semantic chunking and tagging\ntask is less easy. For that, in many cases, models are combined with an\nexternal language model to enhance their performance.\n  In this paper we introduce a data efficient system which is trained\nend-to-end, with no additional, pre-trained external module. One key feature of\nour approach is an incremental training procedure where acoustic, language and\nsemantic models are trained sequentially one after the other. The proposed\nmodel has a reasonable size and achieves competitive results with respect to\nstate-of-the-art while using a small training dataset. In particular, we reach\n24.02% Concept Error Rate (CER) on MEDIA/test while training on MEDIA/train\nwithout any additional data.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 10:24:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Dinarelli", "Marco", ""], ["Kapoor", "Nikita", ""], ["Jabaian", "Bassam", ""], ["Besacier", "Laurent", ""]]}, {"id": "2002.05967", "submitter": "Silin Gao", "authors": "Silin Gao, Zhijian Ou, Wei Yang and Huifang Xu", "title": "Integrating Discrete and Neural Features via Mixed-feature\n  Trans-dimensional Random Field Language Models", "comments": "Accepted for presentation at ICASSP 2020, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a long recognition that discrete features (n-gram features)\nand neural network based features have complementary strengths for language\nmodels (LMs). Improved performance can be obtained by model interpolation,\nwhich is, however, a suboptimal two-step integration of discrete and neural\nfeatures. The trans-dimensional random field (TRF) framework has the potential\nadvantage of being able to flexibly integrate a richer set of features.\nHowever, either discrete or neural features are used alone in previous TRF LMs.\nThis paper develops a mixed-feature TRF LM and demonstrates its advantage in\nintegrating discrete and neural features. Various LMs are trained over PTB and\nGoogle one-billion-word datasets, and evaluated in N-best list rescoring\nexperiments for speech recognition. Among all single LMs (i.e. without model\ninterpolation), the mixed-feature TRF LMs perform the best, improving over both\ndiscrete TRF LMs and neural TRF LMs alone, and also being significantly better\nthan LSTM LMs. Compared to interpolating two separately trained models with\ndiscrete and neural features respectively, the performance of mixed-feature TRF\nLMs matches the best interpolated model, and with simplified one-step training\nprocess and reduced training time.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:05:11 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 05:23:31 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Gao", "Silin", ""], ["Ou", "Zhijian", ""], ["Yang", "Wei", ""], ["Xu", "Huifang", ""]]}, {"id": "2002.05969", "submitter": "Hongyu Ren", "authors": "Hongyu Ren, Weihua Hu, Jure Leskovec", "title": "Query2box: Reasoning over Knowledge Graphs in Vector Space using Box\n  Embeddings", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering complex logical queries on large-scale incomplete knowledge graphs\n(KGs) is a fundamental yet challenging task. Recently, a promising approach to\nthis problem has been to embed KG entities as well as the query into a vector\nspace such that entities that answer the query are embedded close to the query.\nHowever, prior work models queries as single points in the vector space, which\nis problematic because a complex query represents a potentially large set of\nits answer entities, but it is unclear how such a set can be represented as a\nsingle point. Furthermore, prior work can only handle queries that use\nconjunctions ($\\wedge$) and existential quantifiers ($\\exists$). Handling\nqueries with logical disjunctions ($\\vee$) remains an open problem. Here we\npropose query2box, an embedding-based framework for reasoning over arbitrary\nqueries with $\\wedge$, $\\vee$, and $\\exists$ operators in massive and\nincomplete KGs. Our main insight is that queries can be embedded as boxes\n(i.e., hyper-rectangles), where a set of points inside the box corresponds to a\nset of answer entities of the query. We show that conjunctions can be naturally\nrepresented as intersections of boxes and also prove a negative result that\nhandling disjunctions would require embedding with dimension proportional to\nthe number of KG entities. However, we show that by transforming queries into a\nDisjunctive Normal Form, query2box is capable of handling arbitrary logical\nqueries with $\\wedge$, $\\vee$, $\\exists$ in a scalable manner. We demonstrate\nthe effectiveness of query2box on three large KGs and show that query2box\nachieves up to 25% relative improvement over the state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:20:10 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 03:59:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ren", "Hongyu", ""], ["Hu", "Weihua", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.05988", "submitter": "Ana Sofia Gomes", "authors": "Bernardo Branco, Pedro Abreu, Ana Sofia Gomes, Mariana S. C. Almeida,\n  Jo\\~ao Tiago Ascens\\~ao, Pedro Bizarro", "title": "Interleaved Sequence RNNs for Fraud Detection", "comments": "9 pages, 4 figures, to appear in SIGKDD'20 Industry Track", "journal-ref": null, "doi": "10.1145/3394486.3403361", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Payment card fraud causes multibillion dollar losses for banks and merchants\nworldwide, often fueling complex criminal activities. To address this, many\nreal-time fraud detection systems use tree-based models, demanding complex\nfeature engineering systems to efficiently enrich transactions with historical\ndata while complying with millisecond-level latencies.\n  In this work, we do not require those expensive features by using recurrent\nneural networks and treating payments as an interleaved sequence, where the\nhistory of each card is an unbounded, irregular sub-sequence. We present a\ncomplete RNN framework to detect fraud in real-time, proposing an efficient ML\npipeline from preprocessing to deployment.\n  We show that these feature-free, multi-sequence RNNs outperform\nstate-of-the-art models saving millions of dollars in fraud detection and using\nfewer computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:04:11 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:59:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Branco", "Bernardo", ""], ["Abreu", "Pedro", ""], ["Gomes", "Ana Sofia", ""], ["Almeida", "Mariana S. C.", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.05990", "submitter": "Dongxian Wu", "authors": "Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma", "title": "Skip Connections Matter: On the Transferability of Adversarial Examples\n  Generated with ResNets", "comments": "ICLR 2020 conference paper (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip connections are an essential component of current state-of-the-art deep\nneural networks (DNNs) such as ResNet, WideResNet, DenseNet, and ResNeXt.\nDespite their huge success in building deeper and more powerful DNNs, we\nidentify a surprising security weakness of skip connections in this paper. Use\nof skip connections allows easier generation of highly transferable adversarial\nexamples. Specifically, in ResNet-like (with skip connections) neural networks,\ngradients can backpropagate through either skip connections or residual\nmodules. We find that using more gradients from the skip connections rather\nthan the residual modules according to a decay factor, allows one to craft\nadversarial examples with high transferability. Our method is termed Skip\nGradient Method(SGM). We conduct comprehensive transfer attacks against\nstate-of-the-art DNNs including ResNets, DenseNets, Inceptions,\nInception-ResNet, Squeeze-and-Excitation Network (SENet) and robustly trained\nDNNs. We show that employing SGM on the gradient flow can greatly improve the\ntransferability of crafted attacks in almost all cases. Furthermore, SGM can be\neasily combined with existing black-box attack techniques, and obtain high\nimprovements over state-of-the-art transferability methods. Our findings not\nonly motivate new research into the architectural vulnerability of DNNs, but\nalso open up further challenges for the design of secure DNN architectures.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:09:21 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wu", "Dongxian", ""], ["Wang", "Yisen", ""], ["Xia", "Shu-Tao", ""], ["Bailey", "James", ""], ["Ma", "Xingjun", ""]]}, {"id": "2002.05999", "submitter": "Yinpeng Dong", "authors": "Yinpeng Dong, Zhijie Deng, Tianyu Pang, Hang Su, Jun Zhu", "title": "Adversarial Distributional Training for Robust Deep Learning", "comments": "NeurIPS 2020. The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is among the most effective techniques to improve\nmodel robustness by augmenting training data with adversarial examples.\nHowever, most existing AT methods adopt a specific attack to craft adversarial\nexamples, leading to the unreliable robustness against other unseen attacks.\nBesides, a single attack algorithm could be insufficient to explore the space\nof perturbations. In this paper, we introduce adversarial distributional\ntraining (ADT), a novel framework for learning robust models. ADT is formulated\nas a minimax optimization problem, where the inner maximization aims to learn\nan adversarial distribution to characterize the potential adversarial examples\naround a natural one under an entropic regularizer, and the outer minimization\naims to train robust models by minimizing the expected loss over the worst-case\nadversarial distributions. Through a theoretical analysis, we develop a general\nalgorithm for solving ADT, and present three approaches for parameterizing the\nadversarial distributions, ranging from the typical Gaussian distributions to\nthe flexible implicit ones. Empirical results on several benchmarks validate\nthe effectiveness of ADT compared with the state-of-the-art AT methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:36:59 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:47:50 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Dong", "Yinpeng", ""], ["Deng", "Zhijie", ""], ["Pang", "Tianyu", ""], ["Su", "Hang", ""], ["Zhu", "Jun", ""]]}, {"id": "2002.06000", "submitter": "Borja Gonzalez Leon", "authors": "Borja G. Le\\'on and Francesco Belardinelli", "title": "Extended Markov Games to Learn Multiple Tasks in Multi-Agent\n  Reinforcement Learning", "comments": "Long version of the correspondent ECAI 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of Formal Methods with Reinforcement Learning (RL) has\nrecently attracted interest as a way for single-agent RL to learn multiple-task\nspecifications. In this paper we extend this convergence to multi-agent\nsettings and formally define Extended Markov Games as a general mathematical\nmodel that allows multiple RL agents to concurrently learn various\nnon-Markovian specifications. To introduce this new model we provide formal\ndefinitions and proofs as well as empirical tests of RL algorithms running on\nthis framework. Specifically, we use our model to train two different\nlogic-based multi-agent RL algorithms to solve diverse settings of\nnon-Markovian co-safe LTL specifications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:37:41 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Le\u00f3n", "Borja G.", ""], ["Belardinelli", "Francesco", ""]]}, {"id": "2002.06001", "submitter": "Fabricio Breve", "authors": "Fabricio Breve", "title": "Building Networks for Image Segmentation using Particle Competition and\n  Cooperation", "comments": null, "journal-ref": "BREVE, FA. Building Networks for Image Segmentation Using Particle\n  Competition and Cooperation. Lecture Notes in Computer Science. Cham:\n  Springer International Publishing AG, 2017. v.10404. p.217 - 231", "doi": "10.1007/978-3-319-62392-4_16", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle competition and cooperation (PCC) is a graph-based semi-supervised\nlearning approach. When PCC is applied to interactive image segmentation tasks,\npixels are converted into network nodes, and each node is connected to its\nk-nearest neighbors, according to the distance between a set of features\nextracted from the image. Building a proper network to feed PCC is crucial to\nachieve good segmentation results. However, some features may be more important\nthan others to identify the segments, depending on the characteristics of the\nimage to be segmented. In this paper, an index to evaluate candidate networks\nis proposed. Thus, building the network becomes a problem of optimizing some\nfeature weights based on the proposed index. Computer simulations are performed\non some real-world images from the Microsoft GrabCut database, and the\nsegmentation results related in this paper show the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 12:45:12 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Breve", "Fabricio", ""]]}, {"id": "2002.06015", "submitter": "Kazuki Osawa", "authors": "Kazuki Osawa, Yohei Tsuji, Yuichiro Ueno, Akira Naruse, Chuan-Sheng\n  Foo, and Rio Yokota", "title": "Scalable and Practical Natural Gradient for Large-Scale Deep Learning", "comments": "arXiv admin note: text overlap with arXiv:1811.12019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale distributed training of deep neural networks results in models\nwith worse generalization performance as a result of the increase in the\neffective mini-batch size. Previous approaches attempt to address this problem\nby varying the learning rate and batch size over epochs and layers, or ad hoc\nmodifications of batch normalization. We propose Scalable and Practical Natural\nGradient Descent (SP-NGD), a principled approach for training models that\nallows them to attain similar generalization performance to models trained with\nfirst-order optimization methods, but with accelerated convergence.\nFurthermore, SP-NGD scales to large mini-batch sizes with a negligible\ncomputational overhead as compared to first-order methods. We evaluated SP-NGD\non a benchmark task where highly optimized first-order methods are available as\nreferences: training a ResNet-50 model for image classification on ImageNet. We\ndemonstrate convergence to a top-1 validation accuracy of 75.4% in 5.5 minutes\nusing a mini-batch size of 32,768 with 1,024 GPUs, as well as an accuracy of\n74.9% with an extremely large mini-batch size of 131,072 in 873 steps of\nSP-NGD.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:55:37 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Osawa", "Kazuki", ""], ["Tsuji", "Yohei", ""], ["Ueno", "Yuichiro", ""], ["Naruse", "Akira", ""], ["Foo", "Chuan-Sheng", ""], ["Yokota", "Rio", ""]]}, {"id": "2002.06038", "submitter": "Adri\\`a Puigdom\\`enech Badia", "authors": "Adri\\`a Puigdom\\`enech Badia, Pablo Sprechmann, Alex Vitvitskyi,\n  Daniel Guo, Bilal Piot, Steven Kapturowski, Olivier Tieleman, Mart\\'in\n  Arjovsky, Alexander Pritzel, Andew Bolt, Charles Blundell", "title": "Never Give Up: Learning Directed Exploration Strategies", "comments": "Published as a conference paper in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a reinforcement learning agent to solve hard exploration games by\nlearning a range of directed exploratory policies. We construct an episodic\nmemory-based intrinsic reward using k-nearest neighbors over the agent's recent\nexperience to train the directed exploratory policies, thereby encouraging the\nagent to repeatedly revisit all states in its environment. A self-supervised\ninverse dynamics model is used to train the embeddings of the nearest neighbour\nlookup, biasing the novelty signal towards what the agent can control. We\nemploy the framework of Universal Value Function Approximators (UVFA) to\nsimultaneously learn many directed exploration policies with the same neural\nnetwork, with different trade-offs between exploration and exploitation. By\nusing the same neural network for different degrees of\nexploration/exploitation, transfer is demonstrated from predominantly\nexploratory policies yielding effective exploitative policies. The proposed\nmethod can be incorporated to run with modern distributed RL agents that\ncollect large amounts of experience from many actors running in parallel on\nseparate environment instances. Our method doubles the performance of the base\nagent in all hard exploration in the Atari-57 suite while maintaining a very\nhigh score across the remaining games, obtaining a median human normalised\nscore of 1344.0%. Notably, the proposed method is the first algorithm to\nachieve non-zero rewards (with a mean score of 8,400) in the game of Pitfall!\nwithout using demonstrations or hand-crafted features.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 13:57:22 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Badia", "Adri\u00e0 Puigdom\u00e8nech", ""], ["Sprechmann", "Pablo", ""], ["Vitvitskyi", "Alex", ""], ["Guo", "Daniel", ""], ["Piot", "Bilal", ""], ["Kapturowski", "Steven", ""], ["Tieleman", "Olivier", ""], ["Arjovsky", "Mart\u00edn", ""], ["Pritzel", "Alexander", ""], ["Bolt", "Andew", ""], ["Blundell", "Charles", ""]]}, {"id": "2002.06043", "submitter": "Wouter Kool", "authors": "Wouter Kool, Herke van Hoof, Max Welling", "title": "Estimating Gradients for Discrete Random Variables by Sampling without\n  Replacement", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an unbiased estimator for expectations over discrete random\nvariables based on sampling without replacement, which reduces variance as it\navoids duplicate samples. We show that our estimator can be derived as the\nRao-Blackwellization of three different estimators. Combining our estimator\nwith REINFORCE, we obtain a policy gradient estimator and we reduce its\nvariance using a built-in control variate which is obtained without additional\nmodel evaluations. The resulting estimator is closely related to other gradient\nestimators. Experiments with a toy problem, a categorical Variational\nAuto-Encoder and a structured prediction problem show that our estimator is the\nonly estimator that is consistently among the best estimators in both high and\nlow entropy settings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:15:18 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kool", "Wouter", ""], ["van Hoof", "Herke", ""], ["Welling", "Max", ""]]}, {"id": "2002.06053", "submitter": "Hakime \\\"Ozt\\\"urk", "authors": "Hakime \\\"Ozt\\\"urk, Arzucan \\\"Ozg\\\"ur, Philippe Schwaller, Teodoro\n  Laino, Elif Ozkirimli", "title": "Exploring Chemical Space using Natural Language Processing Methodologies\n  for Drug Discovery", "comments": null, "journal-ref": null, "doi": "10.1016/j.drudis.2020.01.020", "report-no": null, "categories": "q-bio.BM cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based representations of chemicals and proteins can be thought of as\nunstructured languages codified by humans to describe domain-specific\nknowledge. Advances in natural language processing (NLP) methodologies in the\nprocessing of spoken languages accelerated the application of NLP to elucidate\nhidden knowledge in textual representations of these biochemical entities and\nthen use it to construct models to predict molecular properties or to design\nnovel molecules. This review outlines the impact made by these advances on drug\ndiscovery and aims to further the dialogue between medicinal chemists and\ncomputer scientists.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 21:02:05 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["\u00d6zt\u00fcrk", "Hakime", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["Schwaller", "Philippe", ""], ["Laino", "Teodoro", ""], ["Ozkirimli", "Elif", ""]]}, {"id": "2002.06063", "submitter": "Parameswaran Kamalaruban Dr.", "authors": "Parameswaran Kamalaruban, Yu-Ting Huang, Ya-Ping Hsieh, Paul Rolland,\n  Cheng Shi, Volkan Cevher", "title": "Robust Reinforcement Learning via Adversarial training with Langevin\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a sampling perspective to tackle the challenging task of\ntraining robust Reinforcement Learning (RL) agents. Leveraging the powerful\nStochastic Gradient Langevin Dynamics, we present a novel, scalable two-player\nRL algorithm, which is a sampling variant of the two-player policy gradient\nmethod. Our algorithm consistently outperforms existing baselines, in terms of\ngeneralization across different training and testing conditions, on several\nMuJoCo environments. Our experiments also show that, even for objective\nfunctions that entirely ignore potential environmental shifts, our sampling\napproach remains highly robust in comparison to standard RL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:59:14 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2020 19:09:36 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Kamalaruban", "Parameswaran", ""], ["Huang", "Yu-Ting", ""], ["Hsieh", "Ya-Ping", ""], ["Rolland", "Paul", ""], ["Shi", "Cheng", ""], ["Cevher", "Volkan", ""]]}, {"id": "2002.06071", "submitter": "Martin d'Hoffschmidt", "authors": "Martin d'Hoffschmidt, Wacim Belblidia, Tom Brendl\\'e, Quentin\n  Heinrich, Maxime Vidal", "title": "FQuAD: French Question Answering Dataset", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in the field of language modeling have improved\nstate-of-the-art results on many Natural Language Processing tasks. Among them,\nReading Comprehension has made significant progress over the past few years.\nHowever, most results are reported in English since labeled resources available\nin other languages, such as French, remain scarce. In the present work, we\nintroduce the French Question Answering Dataset (FQuAD). FQuAD is a French\nNative Reading Comprehension dataset of questions and answers on a set of\nWikipedia articles that consists of 25,000+ samples for the 1.0 version and\n60,000+ samples for the 1.1 version. We train a baseline model which achieves\nan F1 score of 92.2 and an exact match ratio of 82.1 on the test set. In order\nto track the progress of French Question Answering models we propose a\nleader-board and we have made the 1.0 version of our dataset freely available\nat https://illuin-tech.github.io/FQuAD-explorer/.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:23:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:09:17 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["d'Hoffschmidt", "Martin", ""], ["Belblidia", "Wacim", ""], ["Brendl\u00e9", "Tom", ""], ["Heinrich", "Quentin", ""], ["Vidal", "Maxime", ""]]}, {"id": "2002.06075", "submitter": "David Aparicio", "authors": "David Apar\\'icio, Ricardo Barata, Jo\\~ao Bravo, Jo\\~ao Tiago\n  Ascens\\~ao, Pedro Bizarro", "title": "ARMS: Automated rules management system for fraud detection", "comments": "11 pages, 12 figures, submitted to KDD '20 Applied Data Science Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraud detection is essential in financial services, with the potential of\ngreatly reducing criminal activities and saving considerable resources for\nbusinesses and customers. We address online fraud detection, which consists of\nclassifying incoming transactions as either legitimate or fraudulent in\nreal-time. Modern fraud detection systems consist of a machine learning model\nand rules defined by human experts. Often, the rules performance degrades over\ntime due to concept drift, especially of adversarial nature. Furthermore, they\ncan be costly to maintain, either because they are computationally expensive or\nbecause they send transactions for manual review. We propose ARMS, an automated\nrules management system that evaluates the contribution of individual rules and\noptimizes the set of active rules using heuristic search and a user-defined\nloss-function. It complies with critical domain-specific requirements, such as\nhandling different actions (e.g., accept, alert, and decline), priorities,\nblacklists, and large datasets (i.e., hundreds of rules and millions of\ntransactions). We use ARMS to optimize the rule-based systems of two real-world\nclients. Results show that it can maintain the original systems' performance\n(e.g., recall, or false-positive rate) using only a fraction of the original\nrules (~ 50% in one case, and ~ 20% in the other).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:29:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Apar\u00edcio", "David", ""], ["Barata", "Ricardo", ""], ["Bravo", "Jo\u00e3o", ""], ["Ascens\u00e3o", "Jo\u00e3o Tiago", ""], ["Bizarro", "Pedro", ""]]}, {"id": "2002.06100", "submitter": "Emile Van Krieken", "authors": "Emile van Krieken, Erman Acar, Frank van Harmelen", "title": "Analyzing Differentiable Fuzzy Logic Operators", "comments": "45 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a push to integrate symbolic AI and deep\nlearning, as it is argued that the strengths and weaknesses of these approaches\nare complementary. One such trend in the literature are weakly supervised\nlearning techniques that use operators from fuzzy logics. They employ prior\nbackground knowledge described in logic to benefit the training of a neural\nnetwork from unlabeled and noisy data. By interpreting logical symbols using\nneural networks, this background knowledge can be added to regular loss\nfunctions used in deep learning to integrate reasoning and learning. In this\npaper, we analyze how a large collection of logical operators from the fuzzy\nlogic literature behave in a differentiable setting. We find large differences\nbetween the formal properties of these operators that are of crucial importance\nin a differentiable learning setting. We show that many of these operators,\nincluding some of the best known, are highly unsuitable for use in a\ndifferentiable learning setting. A further finding concerns the treatment of\nimplication in these fuzzy logics, with a strong imbalance between gradients\ndriven by the antecedent and the consequent of the implication. Finally, we\nempirically show that it is possible to use Differentiable Fuzzy Logics for\nsemi-supervised learning. However, to achieve the most significant performance\nimprovement over a supervised baseline, we have to resort to non-standard\ncombinations of logical operators which perform well in learning, but which no\nlonger satisfy the usual logical laws. We end with a discussion on extensions\nto large-scale problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:11:36 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["van Krieken", "Emile", ""], ["Acar", "Erman", ""], ["van Harmelen", "Frank", ""]]}, {"id": "2002.06103", "submitter": "Kashif Rasul", "authors": "Kashif Rasul, Abdul-Saboor Sheikh, Ingmar Schuster, Urs Bergmann,\n  Roland Vollgraf", "title": "Multivariate Probabilistic Time Series Forecasting via Conditioned\n  Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is often fundamental to scientific and engineering\nproblems and enables decision making. With ever increasing data set sizes, a\ntrivial solution to scale up predictions is to assume independence between\ninteracting time series. However, modeling statistical dependencies can improve\naccuracy and enable analysis of interaction effects. Deep learning methods are\nwell suited for this problem, but multivariate models often assume a simple\nparametric distribution and do not scale to high dimensions. In this work we\nmodel the multivariate temporal dynamics of time series via an autoregressive\ndeep learning model, where the data distribution is represented by a\nconditioned normalizing flow. This combination retains the power of\nautoregressive models, such as good performance in extrapolation into the\nfuture, with the flexibility of flows as a general purpose high-dimensional\ndistribution model, while remaining computationally tractable. We show that it\nimproves over the state-of-the-art for standard metrics on many real-world data\nsets with several thousand interacting time-series.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:16:51 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 13:53:39 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 19:15:12 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Rasul", "Kashif", ""], ["Sheikh", "Abdul-Saboor", ""], ["Schuster", "Ingmar", ""], ["Bergmann", "Urs", ""], ["Vollgraf", "Roland", ""]]}, {"id": "2002.06115", "submitter": "William Cohen", "authors": "William W. Cohen, Haitian Sun, R. Alex Hofer, Matthew Siegler", "title": "Scalable Neural Methods for Reasoning With a Symbolic Knowledge Base", "comments": "Also published in ICLR2020\n  https://openreview.net/forum?id=BJlguT4YPr&noteId=BJlguT4YPr", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel way of representing a symbolic knowledge base (KB) called\na sparse-matrix reified KB. This representation enables neural modules that are\nfully differentiable, faithful to the original semantics of the KB, expressive\nenough to model multi-hop inferences, and scalable enough to use with\nrealistically large KBs. The sparse-matrix reified KB can be distributed across\nmultiple GPUs, can scale to tens of millions of entities and facts, and is\norders of magnitude faster than naive sparse-matrix implementations. The\nreified KB enables very simple end-to-end architectures to obtain competitive\nperformance on several benchmarks representing two families of tasks: KB\ncompletion, and learning semantic parsers from denotations.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:32:19 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Cohen", "William W.", ""], ["Sun", "Haitian", ""], ["Hofer", "R. Alex", ""], ["Siegler", "Matthew", ""]]}, {"id": "2002.06137", "submitter": "Nevan Wichers", "authors": "Nevan Wichers", "title": "RL agents Implicitly Learning Human Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, RL agents should be rewarded for fulfilling human\npreferences. We show that RL agents implicitly learn the preferences of humans\nin their environment. Training a classifier to predict if a simulated human's\npreferences are fulfilled based on the activations of a RL agent's neural\nnetwork gets .93 AUC. Training a classifier on the raw environment state gets\nonly .8 AUC. Training the classifier off of the RL agent's activations also\ndoes much better than training off of activations from an autoencoder. The\nhuman preference classifier can be used as the reward function of an RL agent\nto make RL agent more beneficial for humans.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:42:50 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wichers", "Nevan", ""]]}, {"id": "2002.06141", "submitter": "Craig Pelissier", "authors": "Craig Pelissier, Jonathan Frame, Grey Nearing", "title": "Combining Parametric Land Surface Models with Machine Learning", "comments": "4 pages, 3 figures, 1 table, submitted to IGARSS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid machine learning and process-based-modeling (PBM) approach is\nproposed and evaluated at a handful of AmeriFlux sites to simulate the\ntop-layer soil moisture state. The Hybrid-PBM (HPBM) employed here uses the\nNoah land-surface model integrated with Gaussian Processes. It is designed to\ncorrect the model only in climatological situations similar to the training\ndata else it reverts to the PBM. In this way, our approach avoids bad\npredictions in scenarios where similar training data is not available and\nincorporates our physical understanding of the system. Here we assume an\nautoregressive model and obtain out-of-sample results with upwards of a 3-fold\nreduction in the RMSE using a one-year leave-one-out cross-validation at each\nof the selected sites. A path is outlined for using hybrid modeling to build\nglobal land-surface models with the potential to significantly outperform the\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:50:33 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 18:20:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pelissier", "Craig", ""], ["Frame", "Jonathan", ""], ["Nearing", "Grey", ""]]}, {"id": "2002.06144", "submitter": "Rapha\\\"el Barman", "authors": "Rapha\\\"el Barman, Maud Ehrmann, Simon Clematide, Sofia Ares Oliveira,\n  Fr\\'ed\\'eric Kaplan", "title": "Combining Visual and Textual Features for Semantic Segmentation of\n  Historical Newspapers", "comments": null, "journal-ref": "Journal of Data Mining & Digital Humanities, HistoInformatics,\n  HistoInformatics (January 19, 2021) jdmdh:7097", "doi": "10.46298/jdmdh.6107", "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The massive amounts of digitized historical documents acquired over the last\ndecades naturally lend themselves to automatic processing and exploration.\nResearch work seeking to automatically process facsimiles and extract\ninformation thereby are multiplying with, as a first essential step, document\nlayout analysis. If the identification and categorization of segments of\ninterest in document images have seen significant progress over the last years\nthanks to deep learning techniques, many challenges remain with, among others,\nthe use of finer-grained segmentation typologies and the consideration of\ncomplex, heterogeneous documents such as historical newspapers. Besides, most\napproaches consider visual features only, ignoring textual signal. In this\ncontext, we introduce a multimodal approach for the semantic segmentation of\nhistorical newspapers that combines visual and textual features. Based on a\nseries of experiments on diachronic Swiss and Luxembourgish newspapers, we\ninvestigate, among others, the predictive power of visual and textual features\nand their capacity to generalize across time and sources. Results show\nconsistent improvement of multimodal models in comparison to a strong visual\nbaseline, as well as better robustness to high material variance.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:56:18 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 11:59:18 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 07:45:29 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 16:56:29 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Barman", "Rapha\u00ebl", ""], ["Ehrmann", "Maud", ""], ["Clematide", "Simon", ""], ["Oliveira", "Sofia Ares", ""], ["Kaplan", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2002.06157", "submitter": "Vikas Garg", "authors": "Vikas K. Garg, Stefanie Jegelka, and Tommi Jaakkola", "title": "Generalization and Representational Limits of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two fundamental questions about graph neural networks (GNNs).\nFirst, we prove that several important graph properties cannot be computed by\nGNNs that rely entirely on local information. Such GNNs include the standard\nmessage passing models, and more powerful spatial variants that exploit local\ngraph structure (e.g., via relative orientation of messages, or local port\nordering) to distinguish neighbors of each node. Our treatment includes a novel\ngraph-theoretic formalism. Second, we provide the first data dependent\ngeneralization bounds for message passing GNNs. This analysis explicitly\naccounts for the local permutation invariance of GNNs. Our bounds are much\ntighter than existing VC-dimension based guarantees for GNNs, and are\ncomparable to Rademacher bounds for recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:10:14 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Garg", "Vikas K.", ""], ["Jegelka", "Stefanie", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.06160", "submitter": "Nicholas Hoernle", "authors": "Nicholas Hoernle and Gregory Kehne and Ariel D. Procaccia and Kobi Gal", "title": "The Phantom Steering Effect in Q&A Websites", "comments": "To appear in IEEE ICDM2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Badges are commonly used in online platforms as incentives for promoting\ncontributions. It is widely accepted that badges \"steer\" people's behavior\ntoward increasing their rate of contributions before obtaining the badge. This\npaper provides a new probabilistic model of user behavior in the presence of\nbadges. By applying the model to data from thousands of users on the Q&A site\nStack Overflow, we find that steering is not as widely applicable as was\npreviously understood. Rather, the majority of users remain apathetic toward\nbadges, while still providing a substantial number of contributions to the\nsite. An interesting statistical phenomenon, termed \"Phantom Steering,\"\naccounts for the interaction data of these users and this may have contributed\nto some previous conclusions about steering. Our results suggest that a small\npopulation, approximately 20%, of users respond to the badge incentives.\nMoreover, we conduct a qualitative survey of the users on Stack Overflow which\nprovides further evidence that the insights from the model reflect the true\nbehavior of the community. We argue that while badges might contribute toward a\nsuite of effective rewards in an online system, research into other aspects of\nreward systems such as Stack Overflow reputation points should become a focus\nof the community.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:20:37 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 14:00:19 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Hoernle", "Nicholas", ""], ["Kehne", "Gregory", ""], ["Procaccia", "Ariel D.", ""], ["Gal", "Kobi", ""]]}, {"id": "2002.06165", "submitter": "Niko Moritz", "authors": "Leda Sar{\\i}, Niko Moritz, Takaaki Hori, Jonathan Le Roux", "title": "Unsupervised Speaker Adaptation using Attention-based Speaker Memory for\n  End-to-End ASR", "comments": "To appear in Proc. ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised speaker adaptation method inspired by the neural\nTuring machine for end-to-end (E2E) automatic speech recognition (ASR). The\nproposed model contains a memory block that holds speaker i-vectors extracted\nfrom the training data and reads relevant i-vectors from the memory through an\nattention mechanism. The resulting memory vector (M-vector) is concatenated to\nthe acoustic features or to the hidden layer activations of an E2E neural\nnetwork model. The E2E ASR system is based on the joint connectionist temporal\nclassification and attention-based encoder-decoder architecture. M-vector and\ni-vector results are compared for inserting them at different layers of the\nencoder neural network using the WSJ and TED-LIUM2 ASR benchmarks. We show that\nM-vectors, which do not require an auxiliary speaker embedding extraction\nsystem at test time, achieve similar word error rates (WERs) compared to\ni-vectors for single speaker utterances and significantly lower WERs for\nutterances in which there are speaker changes.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:31:31 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sar\u0131", "Leda", ""], ["Moritz", "Niko", ""], ["Hori", "Takaaki", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "2002.06169", "submitter": "Brian Flynn", "authors": "Antonio A. Gentile, Brian Flynn, Sebastian Knauer, Nathan Wiebe,\n  Stefano Paesani, Christopher E. Granade, John G. Rarity, Raffaele Santagati,\n  Anthony Laing", "title": "Learning models of quantum systems from experiments", "comments": "27 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An isolated system of interacting quantum particles is described by a\nHamiltonian operator. Hamiltonian models underpin the study and analysis of\nphysical and chemical processes throughout science and industry, so it is\ncrucial they are faithful to the system they represent. However, formulating\nand testing Hamiltonian models of quantum systems from experimental data is\ndifficult because it is impossible to directly observe which interactions the\nquantum system is subject to. Here, we propose and demonstrate an approach to\nretrieving a Hamiltonian model from experiments, using unsupervised machine\nlearning. We test our methods experimentally on an electron spin in a\nnitrogen-vacancy interacting with its spin bath environment, and numerically,\nfinding success rates up to 86%. By building agents capable of learning\nscience, which recover meaningful representations, we can gain further insight\non the physics of quantum systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:37:50 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Gentile", "Antonio A.", ""], ["Flynn", "Brian", ""], ["Knauer", "Sebastian", ""], ["Wiebe", "Nathan", ""], ["Paesani", "Stefano", ""], ["Granade", "Christopher E.", ""], ["Rarity", "John G.", ""], ["Santagati", "Raffaele", ""], ["Laing", "Anthony", ""]]}, {"id": "2002.06170", "submitter": "Chenguang Wang", "authors": "Chenguang Wang, Zihao Ye, Aston Zhang, Zheng Zhang, Alexander J. Smola", "title": "Transformer on a Diet", "comments": "6 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer has been widely used thanks to its ability to capture sequence\ninformation in an efficient way. However, recent developments, such as BERT and\nGPT-2, deliver only heavy architectures with a focus on effectiveness. In this\npaper, we explore three carefully-designed light Transformer architectures to\nfigure out whether the Transformer with less computations could produce\ncompetitive results. Experimental results on language model benchmark datasets\nhint that such trade-off is promising, and the light Transformer reduces 70%\nparameters at best, while obtains competitive perplexity compared to standard\nTransformer. The source code is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:41:58 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Wang", "Chenguang", ""], ["Ye", "Zihao", ""], ["Zhang", "Aston", ""], ["Zhang", "Zheng", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2002.06177", "submitter": "Gary Marcus", "authors": "Gary Marcus", "title": "The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in artificial intelligence and machine learning has largely\nemphasized general-purpose learning and ever-larger training sets and more and\nmore compute. In contrast, I propose a hybrid, knowledge-driven,\nreasoning-based approach, centered around cognitive models, that could provide\nthe substrate for a richer, more robust AI than is currently possible.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:55:56 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:58:30 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2020 17:48:05 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Marcus", "Gary", ""]]}, {"id": "2002.06189", "submitter": "Lingkai Kong", "authors": "Lingkai Kong and Molei Tao", "title": "Stochasticity of Deterministic Gradient Descent: Large Learning Rate for\n  Multiscale Objective Function", "comments": "NeurIPS 2020. v1->v2: Weakened conditions needed for the theory.\n  Added connections to neural network. Corrected typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.DS math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article suggests that deterministic Gradient Descent, which does not use\nany stochastic gradient approximation, can still exhibit stochastic behaviors.\nIn particular, it shows that if the objective function exhibit multiscale\nbehaviors, then in a large learning rate regime which only resolves the\nmacroscopic but not the microscopic details of the objective, the deterministic\nGD dynamics can become chaotic and convergent not to a local minimizer but to a\nstatistical distribution. A sufficient condition is also established for\napproximating this long-time statistical limit by a rescaled Gibbs\ndistribution. Both theoretical and numerical demonstrations are provided, and\nthe theoretical part relies on the construction of a stochastic map that uses\nbounded noise (as opposed to discretized diffusions).\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 18:59:20 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 16:37:14 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Kong", "Lingkai", ""], ["Tao", "Molei", ""]]}, {"id": "2002.06195", "submitter": "Yangchen Pan", "authors": "Yangchen Pan, Ehsan Imani, Martha White, Amir-massoud Farahmand", "title": "An implicit function learning approach for parametric modal regression", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For multi-valued functions---such as when the conditional distribution on\ntargets given the inputs is multi-modal---standard regression approaches are\nnot always desirable because they provide the conditional mean. Modal\nregression algorithms address this issue by instead finding the conditional\nmode(s). Most, however, are nonparametric approaches and so can be difficult to\nscale. Further, parametric approximators, like neural networks, facilitate\nlearning complex relationships between inputs and targets. In this work, we\npropose a parametric modal regression algorithm. We use the implicit function\ntheorem to develop an objective, for learning a joint function over inputs and\ntargets. We empirically demonstrate on several synthetic problems that our\nmethod (i) can learn multi-valued functions and produce the conditional modes,\n(ii) scales well to high-dimensional inputs, and (iii) can even be more\neffective for certain uni-modal problems, particularly for high-frequency\nfunctions. We demonstrate that our method is competitive in a real-world modal\nregression problem and two regular regression datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 00:37:41 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 17:46:18 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Pan", "Yangchen", ""], ["Imani", "Ehsan", ""], ["White", "Martha", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2002.06200", "submitter": "Daniel Steinberg", "authors": "Daniel Steinberg, Alistair Reid, Simon O'Callaghan, Finnian Lattimore,\n  Lachlan McCalman, Tiberio Caetano", "title": "Fast Fair Regression via Efficient Approximations of Mutual Information", "comments": "arXiv admin note: text overlap with arXiv:2001.06089", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in algorithmic fairness to date has focused on discrete outcomes,\nsuch as deciding whether to grant someone a loan or not. In these\nclassification settings, group fairness criteria such as independence,\nseparation and sufficiency can be measured directly by comparing rates of\noutcomes between subpopulations. Many important problems however require the\nprediction of a real-valued outcome, such as a risk score or insurance premium.\nIn such regression settings, measuring group fairness criteria is\ncomputationally challenging, as it requires estimating information-theoretic\ndivergences between conditional probability density functions. This paper\nintroduces fast approximations of the independence, separation and sufficiency\ngroup fairness criteria for regression models from their (conditional) mutual\ninformation definitions, and uses such approximations as regularisers to\nenforce fairness within a regularised risk minimisation framework. Experiments\nin real-world datasets indicate that in spite of its superior computational\nefficiency our algorithm still displays state-of-the-art accuracy/fairness\ntradeoffs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:50:51 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Steinberg", "Daniel", ""], ["Reid", "Alistair", ""], ["O'Callaghan", "Simon", ""], ["Lattimore", "Finnian", ""], ["McCalman", "Lachlan", ""], ["Caetano", "Tiberio", ""]]}, {"id": "2002.06205", "submitter": "Avi Caciularu", "authors": "Oren Barkan, Avi Caciularu, Ori Katz and Noam Koenigstein", "title": "Attentive Item2Vec: Neural Attentive User Representations", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization methods for recommender systems tend to represent users as a\nsingle latent vector. However, user behavior and interests may change in the\ncontext of the recommendations that are presented to the user. For example, in\nthe case of movie recommendations, it is usually true that earlier user data is\nless informative than more recent data. However, it is possible that a certain\nearly movie may become suddenly more relevant in the presence of a popular\nsequel movie. This is just a single example of a variety of possible\ndynamically altering user interests in the presence of a potential new\nrecommendation. In this work, we present Attentive Item2vec (AI2V) - a novel\nattentive version of Item2vec (I2V). AI2V employs a context-target attention\nmechanism in order to learn and capture different characteristics of user\nhistorical behavior (context) with respect to a potential recommended item\n(target). The attentive context-target mechanism enables a final neural\nattentive user representation. We demonstrate the effectiveness of AI2V on\nseveral datasets, where it is shown to outperform other baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:22:47 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 13:41:55 GMT"}, {"version": "v3", "created": "Sun, 19 Apr 2020 18:25:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Barkan", "Oren", ""], ["Caciularu", "Avi", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2002.06212", "submitter": "Minas Karamanis", "authors": "Minas Karamanis and Florian Beutler", "title": "Ensemble Slice Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML astro-ph.CO astro-ph.IM cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slice Sampling has emerged as a powerful Markov Chain Monte Carlo algorithm\nthat adapts to the characteristics of the target distribution with minimal\nhand-tuning. However, Slice Sampling's performance is highly sensitive to the\nuser-specified initial length scale hyperparameter. Moreover, Slice Sampling\ngenerally struggles with poorly scaled or strongly correlated distributions.\nThis paper introduces Ensemble Slice Sampling, a new class of algorithms that\nbypasses such difficulties by adaptively tuning the length scale. Furthermore,\nEnsemble Slice Sampling's performance is immune to linear correlations by\nexploiting an ensemble of parallel walkers. These algorithms are trivial to\nconstruct, require no hand-tuning, and can easily be implemented in parallel\ncomputing environments. Empirical tests show that Ensemble Slice Sampling can\nimprove efficiency by more than an order of magnitude compared to conventional\nMCMC methods on highly correlated target distributions such as the\nAutoregressive Process of Order 1 and the Correlated Funnel distribution.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:00:12 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Karamanis", "Minas", ""], ["Beutler", "Florian", ""]]}, {"id": "2002.06215", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Jaroslaw Sydir, Meryem Simsek, Hosein Nikopour", "title": "Resource Management in Wireless Networks via Multi-Agent Deep\n  Reinforcement Learning", "comments": "Final version to appear in IEEE Transactions on Wireless\n  Communications", "journal-ref": null, "doi": "10.1109/TWC.2021.3051163", "report-no": null, "categories": "cs.LG cs.IT cs.MA eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a mechanism for distributed resource management and interference\nmitigation in wireless networks using multi-agent deep reinforcement learning\n(RL). We equip each transmitter in the network with a deep RL agent that\nreceives delayed observations from its associated users, while also exchanging\nobservations with its neighboring agents, and decides on which user to serve\nand what transmit power to use at each scheduling interval. Our proposed\nframework enables agents to make decisions simultaneously and in a distributed\nmanner, unaware of the concurrent decisions of other agents. Moreover, our\ndesign of the agents' observation and action spaces is scalable, in the sense\nthat an agent trained on a scenario with a specific number of transmitters and\nusers can be applied to scenarios with different numbers of transmitters and/or\nusers. Simulation results demonstrate the superiority of our proposed approach\ncompared to decentralized baselines in terms of the tradeoff between average\nand $5^{th}$ percentile user rates, while achieving performance close to, and\neven in certain cases outperforming, that of a centralized\ninformation-theoretic baseline. We also show that our trained agents are robust\nand maintain their performance gains when experiencing mismatches between train\nand test deployments.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:01:07 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 06:04:45 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Sydir", "Jaroslaw", ""], ["Simsek", "Meryem", ""], ["Nikopour", "Hosein", ""]]}, {"id": "2002.06219", "submitter": "Rafael Derradi De Souza", "authors": "Paulo Finardi, Israel Campiotti, Gustavo Plensack, Rafael Derradi de\n  Souza, Rodrigo Nogueira, Gustavo Pinheiro, Roberto Lotufo", "title": "Electricity Theft Detection with self-attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel self-attention mechanism model to address\nelectricity theft detection on an imbalanced realistic dataset that presents a\ndaily electricity consumption provided by State Grid Corporation of China. Our\nkey contribution is the introduction of a multi-head self-attention mechanism\nconcatenated with dilated convolutions and unified by a convolution of kernel\nsize $1$. Moreover, we introduce a binary input channel (Binary Mask) to\nidentify the position of the missing values, allowing the network to learn how\nto deal with these values. Our model achieves an AUC of $0.926$ which is an\nimprovement in more than $17\\%$ with respect to previous baseline work. The\ncode is available on GitHub at\nhttps://github.com/neuralmind-ai/electricity-theft-detection-with-self-attention.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:11:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Finardi", "Paulo", ""], ["Campiotti", "Israel", ""], ["Plensack", "Gustavo", ""], ["de Souza", "Rafael Derradi", ""], ["Nogueira", "Rodrigo", ""], ["Pinheiro", "Gustavo", ""], ["Lotufo", "Roberto", ""]]}, {"id": "2002.06224", "submitter": "Zhengli Zhao", "authors": "Samarth Sinha, Zhengli Zhao, Anirudh Goyal, Colin Raffel, Augustus\n  Odena", "title": "Top-k Training of GANs: Improving GAN Performance by Throwing Away Bad\n  Samples", "comments": "NeurIPS 2020. Samarth Sinha and Zhengli Zhao contributed equally as\n  joint first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple (one line of code) modification to the Generative\nAdversarial Network (GAN) training algorithm that materially improves results\nwith no increase in computational cost: When updating the generator parameters,\nwe simply zero out the gradient contributions from the elements of the batch\nthat the critic scores as `least realistic'. Through experiments on many\ndifferent GAN variants, we show that this `top-k update' procedure is a\ngenerally applicable improvement. In order to understand the nature of the\nimprovement, we conduct extensive analysis on a simple mixture-of-Gaussians\ndataset and discover several interesting phenomena. Among these is that, when\ngradient updates are computed using the worst-scoring batch elements, samples\ncan actually be pushed further away from their nearest mode. We also apply our\nmethod to recent GAN variants and improve state-of-the-art FID for conditional\ngeneration from 9.21 to 8.57 on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:27:50 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 00:02:08 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 17:43:22 GMT"}, {"version": "v4", "created": "Thu, 22 Oct 2020 21:42:09 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Sinha", "Samarth", ""], ["Zhao", "Zhengli", ""], ["Goyal", "Anirudh", ""], ["Raffel", "Colin", ""], ["Odena", "Augustus", ""]]}, {"id": "2002.06226", "submitter": "Amir Mosavi Prof", "authors": "Saeed Samadianfard, Sajjad Hashemi, Katayoun Kargar, Mojtaba Izadyar,\n  Ali Mostafaeipour, Amir Mosavi, Narjes Nabipour, Shahaboddin Shamshirband", "title": "Wind speed prediction using a hybrid model of the multi-layer perceptron\n  and whale optimization algorithm", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wind power as a renewable source of energy, has numerous economic,\nenvironmental and social benefits. In order to enhance and control renewable\nwind power, it is vital to utilize models that predict wind speed with high\naccuracy. Due to neglecting of requirement and significance of data\npreprocessing and disregarding the inadequacy of using a single predicting\nmodel, many traditional models have poor performance in wind speed prediction.\nIn the current study, for predicting wind speed at target stations in the north\nof Iran, the combination of a multi-layer perceptron model (MLP) with the Whale\nOptimization Algorithm (WOA) used to build new method (MLP-WOA) with a limited\nset of data (2004-2014). Then, the MLP-WOA model was utilized at each of the\nten target stations, with the nine stations for training and tenth station for\ntesting (namely: Astara, Bandar-E-Anzali, Rasht, Manjil, Jirandeh, Talesh,\nKiyashahr, Lahijan, Masuleh, and Deylaman) to increase the accuracy of the\nsubsequent hybrid model. The capability of the hybrid model in wind speed\nforecasting at each target station was compared with the MLP model without the\nWOA optimizer. To determine definite results, numerous statistical performances\nwere utilized. For all ten target stations, the MLP-WOA model had precise\noutcomes than the standalone MLP model. The hybrid model had acceptable\nperformances with lower amounts of the RMSE, SI and RE parameters and higher\nvalues of NSE, WI, and KGE parameters. It was concluded that the WOA\noptimization algorithm can improve the prediction accuracy of MLP model and may\nbe recommended for accurate wind speed prediction.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:29:33 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Samadianfard", "Saeed", ""], ["Hashemi", "Sajjad", ""], ["Kargar", "Katayoun", ""], ["Izadyar", "Mojtaba", ""], ["Mostafaeipour", "Ali", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Shamshirband", "Shahaboddin", ""]]}, {"id": "2002.06233", "submitter": "Vahid Ranjbar", "authors": "Morteza Rohanian, Mostafa Salehi, Ali Darzi, Vahid Ranjbar", "title": "Convolutional Neural Networks for Sentiment Analysis in Persian Social\n  Media", "comments": "in Farsi, Iranian Journal of Electrical and Computer Engineering\n  (IJECE), February 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the social media engagement on the rise, the resulting data can be used\nas a rich resource for analyzing and understanding different phenomena around\nus. A sentiment analysis system employs these data to find the attitude of\nsocial media users towards certain entities in a given document. In this paper\nwe propose a sentiment analysis method for Persian text using Convolutional\nNeural Network (CNN), a feedforward Artificial Neural Network, that categorize\nsentences into two and five classes (considering their intensity) by applying a\nlayer of convolution over input data through different filters. We evaluated\nthe method on three different datasets of Persian social media texts using Area\nunder Curve metric. The final results show the advantage of using CNN over\nearlier attempts at developing traditional machine learning methods for Persian\ntexts sentiment classification especially for short texts.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 19:52:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rohanian", "Morteza", ""], ["Salehi", "Mostafa", ""], ["Darzi", "Ali", ""], ["Ranjbar", "Vahid", ""]]}, {"id": "2002.06235", "submitter": "John Kelleher", "authors": "Magdalena Kacmajor and John D. Kelleher and Filip Klubicka and Alfredo\n  Maldonado", "title": "Semantic Relatedness and Taxonomic Word Embeddings", "comments": "7 pages 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper connects a series of papers dealing with taxonomic word\nembeddings. It begins by noting that there are different types of semantic\nrelatedness and that different lexical representations encode different forms\nof relatedness. A particularly important distinction within semantic\nrelatedness is that of thematic versus taxonomic relatedness. Next, we present\na number of experiments that analyse taxonomic embeddings that have been\ntrained on a synthetic corpus that has been generated via a random walk over a\ntaxonomy. These experiments demonstrate how the properties of the synthetic\ncorpus, such as the percentage of rare words, are affected by the shape of the\nknowledge graph the corpus is generated from. Finally, we explore the\ninteractions between the relative sizes of natural and synthetic corpora on the\nperformance of embeddings when taxonomic and thematic embeddings are combined.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:02:11 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kacmajor", "Magdalena", ""], ["Kelleher", "John D.", ""], ["Klubicka", "Filip", ""], ["Maldonado", "Alfredo", ""]]}, {"id": "2002.06238", "submitter": "Warren Powell", "authors": "Warren B Powell", "title": "On State Variables, Bandit Problems and POMDPs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State variables are easily the most subtle dimension of sequential decision\nproblems. This is especially true in the context of active learning problems\n(bandit problems\") where decisions affect what we observe and learn. We\ndescribe our canonical framework that models {\\it any} sequential decision\nproblem, and present our definition of state variables that allows us to claim:\nAny properly modeled sequential decision problem is Markovian. We then present\na novel two-agent perspective of partially observable Markov decision problems\n(POMDPs) that allows us to then claim: Any model of a real decision problem is\n(possibly) non-Markovian. We illustrate these perspectives using the context of\nobserving and treating flu in a population, and provide examples of all four\nclasses of policies in this setting. We close with an indication of how to\nextend this thinking to multiagent problems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:09:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Powell", "Warren B", ""]]}, {"id": "2002.06239", "submitter": "Sunwoo Kim", "authors": "Sunwoo Kim, Haici Yang, Minje Kim", "title": "Boosted Locality Sensitive Hashing: Discriminative Binary Codes for\n  Source Separation", "comments": null, "journal-ref": "IEEE International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech enhancement tasks have seen significant improvements with the advance\nof deep learning technology, but with the cost of increased computational\ncomplexity. In this study, we propose an adaptive boosting approach to learning\nlocality sensitive hash codes, which represent audio spectra efficiently. We\nuse the learned hash codes for single-channel speech denoising tasks as an\nalternative to a complex machine learning model, particularly to address the\nresource-constrained environments. Our adaptive boosting algorithm learns\nsimple logistic regressors as the weak learners. Once trained, their binary\nclassification results transform each spectrum of test noisy speech into a bit\nstring. Simple bitwise operations calculate Hamming distance to find the\nK-nearest matching frames in the dictionary of training noisy speech spectra,\nwhose associated ideal binary masks are averaged to estimate the denoising mask\nfor that test mixture. Our proposed learning algorithm differs from AdaBoost in\nthe sense that the projections are trained to minimize the distances between\nthe self-similarity matrix of the hash codes and that of the original spectra,\nrather than the misclassification rate. We evaluate our discriminative hash\ncodes on the TIMIT corpus with various noise types, and show comparative\nperformance to deep learning methods in terms of denoising performance and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:10:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kim", "Sunwoo", ""], ["Yang", "Haici", ""], ["Kim", "Minje", ""]]}, {"id": "2002.06241", "submitter": "Jiachen Li", "authors": "Jiachen Li, Hengbo Ma, Zhihao Zhang, Masayoshi Tomizuka", "title": "Social-WaGDAT: Interaction-aware Trajectory Prediction via Wasserstein\n  Graph Double-Attention Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective understanding of the environment and accurate trajectory prediction\nof surrounding dynamic obstacles are indispensable for intelligent mobile\nsystems (like autonomous vehicles and social robots) to achieve safe and\nhigh-quality planning when they navigate in highly interactive and crowded\nscenarios. Due to the existence of frequent interactions and uncertainty in the\nscene evolution, it is desired for the prediction system to enable relational\nreasoning on different entities and provide a distribution of future\ntrajectories for each agent. In this paper, we propose a generic generative\nneural system (called Social-WaGDAT) for multi-agent trajectory prediction,\nwhich makes a step forward to explicit interaction modeling by incorporating\nrelational inductive biases with a dynamic graph representation and leverages\nboth trajectory and scene context information. We also employ an efficient\nkinematic constraint layer applied to vehicle trajectory prediction which not\nonly ensures physical feasibility but also enhances model performance. The\nproposed system is evaluated on three public benchmark datasets for trajectory\nprediction, where the agents cover pedestrians, cyclists and on-road vehicles.\nThe experimental results demonstrate that our model achieves better performance\nthan various baseline approaches in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 20:11:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Li", "Jiachen", ""], ["Ma", "Hengbo", ""], ["Zhang", "Zhihao", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "2002.06243", "submitter": "Kei Nakagawa", "authors": "Yusuke Uchiyama, Kei Nakagawa", "title": "TPLVM: Portfolio Construction by Student's $t$-process Latent Variable\n  Model", "comments": null, "journal-ref": null, "doi": "10.3390/math8030449", "report-no": null, "categories": "q-fin.PM cs.LG math.ST q-fin.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal asset allocation is a key topic in modern finance theory. To realize\nthe optimal asset allocation on investor's risk aversion, various portfolio\nconstruction methods have been proposed. Recently, the applications of machine\nlearning are rapidly growing in the area of finance. In this article, we\npropose the Student's $t$-process latent variable model (TPLVM) to describe\nnon-Gaussian fluctuations of financial timeseries by lower dimensional latent\nvariables. Subsequently, we apply the TPLVM to minimum-variance portfolio as an\nalternative of existing nonlinear factor models. To test the performance of the\nproposed portfolio, we construct minimum-variance portfolios of global stock\nmarket indices based on the TPLVM or Gaussian process latent variable model. By\ncomparing these portfolios, we confirm the proposed portfolio outperforms that\nof the existing Gaussian process latent variable model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 02:02:02 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Uchiyama", "Yusuke", ""], ["Nakagawa", "Kei", ""]]}, {"id": "2002.06247", "submitter": "Julien Grand-Cl\\'ement", "authors": "Julien Grand-Clement, Carri W. Chan, Vineet Goyal, Gabriel Escobar", "title": "Robust Policies For Proactive ICU Transfers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients whose transfer to the Intensive Care Unit (ICU) is unplanned are\nprone to higher mortality rates than those who were admitted directly to the\nICU. Recent advances in machine learning to predict patient deterioration have\nintroduced the possibility of \\emph{proactive transfer} from the ward to the\nICU. In this work, we study the problem of finding \\emph{robust} patient\ntransfer policies which account for uncertainty in statistical estimates due to\ndata limitations when optimizing to improve overall patient care. We propose a\nMarkov Decision Process model to capture the evolution of patient health, where\nthe states represent a measure of patient severity. Under fairly general\nassumptions, we show that an optimal transfer policy has a threshold structure,\ni.e., that it transfers all patients above a certain severity level to the ICU\n(subject to available capacity). As model parameters are typically determined\nbased on statistical estimations from real-world data, they are inherently\nsubject to misspecification and estimation errors. We account for this\nparameter uncertainty by deriving a robust policy that optimizes the worst-case\nreward across all plausible values of the model parameters. We show that the\nrobust policy also has a threshold structure under fairly general assumptions.\nMoreover, it is more aggressive in transferring patients than the optimal\nnominal policy, which does not take into account parameter uncertainty. We\npresent computational experiments using a dataset of hospitalizations at 21\nKNPC hospitals, and present empirical evidence of the sensitivity of various\nhospital metrics (mortality, length-of-stay, average ICU occupancy) to small\nchanges in the parameters. Our work provides useful insights into the impact of\nparameter uncertainty on deriving simple policies for proactive ICU transfer\nthat have strong empirical performance and theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:07:15 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 21:00:24 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Grand-Clement", "Julien", ""], ["Chan", "Carri W.", ""], ["Goyal", "Vineet", ""], ["Escobar", "Gabriel", ""]]}, {"id": "2002.06250", "submitter": "Md Navid Akbar", "authors": "Md Navid Akbar, Mathew Yarossi, Marc Martinez-Gost, Marc A. Sommer,\n  Moritz Dannhauer, Sumientra Rampersad, Dana Brooks, Eugene Tunik, Deniz\n  Erdo\\u{g}mu\\c{s}", "title": "Mapping Motor Cortex Stimulation to Muscle Responses: A Deep Neural\n  Network Modeling Approach", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network (DNN) that can reliably model muscle responses from\ncorresponding brain stimulation has the potential to increase knowledge of\ncoordinated motor control for numerous basic science and applied use cases.\nSuch cases include the understanding of abnormal movement patterns due to\nneurological injury from stroke, and stimulation based interventions for\nneurological recovery such as paired associative stimulation. In this work,\npotential DNN models are explored and the one with the minimum squared errors\nis recommended for the optimal performance of the M2M-Net, a network that maps\ntranscranial magnetic stimulation of the motor cortex to corresponding muscle\nresponses, using: a finite element simulation, an empirical neural response\nprofile, a convolutional autoencoder, a separate deep network mapper, and\nrecordings of multi-muscle activation. We discuss the rationale behind the\ndifferent modeling approaches and architectures, and contrast their results.\nAdditionally, to obtain a comparative insight of the trade-off between\ncomplexity and performance analysis, we explore different techniques, including\nthe extension of two classical information criteria for M2M-Net. Finally, we\nfind that the model analogous to mapping the motor cortex stimulation to a\ncombination of direct and synergistic connection to the muscles performs the\nbest, when the neural response profile is used at the input.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:24:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Akbar", "Md Navid", ""], ["Yarossi", "Mathew", ""], ["Martinez-Gost", "Marc", ""], ["Sommer", "Marc A.", ""], ["Dannhauer", "Moritz", ""], ["Rampersad", "Sumientra", ""], ["Brooks", "Dana", ""], ["Tunik", "Eugene", ""], ["Erdo\u011fmu\u015f", "Deniz", ""]]}, {"id": "2002.06262", "submitter": "Kaixuan Huang", "authors": "Kaixuan Huang, Yuqing Wang, Molei Tao, Tuo Zhao", "title": "Why Do Deep Residual Networks Generalize Better than Deep Feedforward\n  Networks? -- A Neural Tangent Kernel Perspective", "comments": "Accepted in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks (ResNets) have demonstrated better generalization\nperformance than deep feedforward networks (FFNets). However, the theory behind\nsuch a phenomenon is still largely unknown. This paper studies this fundamental\nproblem in deep learning from a so-called \"neural tangent kernel\" perspective.\nSpecifically, we first show that under proper conditions, as the width goes to\ninfinity, training deep ResNets can be viewed as learning reproducing kernel\nfunctions with some kernel function. We then compare the kernel of deep ResNets\nwith that of deep FFNets and discover that the class of functions induced by\nthe kernel of FFNets is asymptotically not learnable, as the depth goes to\ninfinity. In contrast, the class of functions induced by the kernel of ResNets\ndoes not exhibit such degeneracy. Our discovery partially justifies the\nadvantages of deep ResNets over deep FFNets in generalization abilities.\nNumerical results are provided to support our claim.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 21:53:58 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 08:47:38 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Huang", "Kaixuan", ""], ["Wang", "Yuqing", ""], ["Tao", "Molei", ""], ["Zhao", "Tuo", ""]]}, {"id": "2002.06274", "submitter": "Connor Parde", "authors": "Connor J. Parde, Y. Ivette Col\\'on, Matthew Q. Hill, Carlos D.\n  Castillo, Prithviraj Dhar, Alice J. O'Toole", "title": "Single Unit Status in Deep Convolutional Neural Network Codes for Face\n  Identification: Sparseness Redefined", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (DCNNs) trained for face identification\ndevelop representations that generalize over variable images, while retaining\nsubject (e.g., gender) and image (e.g., viewpoint) information. Identity,\ngender, and viewpoint codes were studied at the \"neural unit\" and ensemble\nlevels of a face-identification network. At the unit level, identification,\ngender classification, and viewpoint estimation were measured by deleting units\nto create variably-sized, randomly-sampled subspaces at the top network layer.\nIdentification of 3,531 identities remained high (area under the ROC\napproximately 1.0) as dimensionality decreased from 512 units to 16 (0.95), 4\n(0.80), and 2 (0.72) units. Individual identities separated statistically on\nevery top-layer unit. Cross-unit responses were minimally correlated,\nindicating that units code non-redundant identity cues. This \"distributed\" code\nrequires only a sparse, random sample of units to identify faces accurately.\nGender classification declined gradually and viewpoint estimation fell steeply\nas dimensionality decreased. Individual units were weakly predictive of gender\nand viewpoint, but ensembles proved effective predictors. Therefore,\ndistributed and sparse codes co-exist in the network units to represent\ndifferent face attributes. At the ensemble level, principal component analysis\nof face representations showed that identity, gender, and viewpoint information\nseparated into high-dimensional subspaces, ordered by explained variance.\nIdentity, gender, and viewpoint information contributed to all individual unit\nresponses, undercutting a neural tuning analogy for face attributes.\nInterpretation of neural-like codes from DCNNs, and by analogy, high-level\nvisual codes, cannot be inferred from single unit responses. Instead, \"meaning\"\nis encoded by directions in the high-dimensional space.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:42:02 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 09:58:01 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Parde", "Connor J.", ""], ["Col\u00f3n", "Y. Ivette", ""], ["Hill", "Matthew Q.", ""], ["Castillo", "Carlos D.", ""], ["Dhar", "Prithviraj", ""], ["O'Toole", "Alice J.", ""]]}, {"id": "2002.06275", "submitter": "Wenhao Lu", "authors": "Wenhao Lu, Jian Jiao, Ruofei Zhang", "title": "TwinBERT: Distilling Knowledge to Twin-Structured BERT Models for\n  Efficient Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models like BERT have achieved great success in a wide\nvariety of NLP tasks, while the superior performance comes with high demand in\ncomputational resources, which hinders the application in low-latency IR\nsystems. We present TwinBERT model for effective and efficient retrieval, which\nhas twin-structured BERT-like encoders to represent query and document\nrespectively and a crossing layer to combine the embeddings and produce a\nsimilarity score. Different from BERT, where the two input sentences are\nconcatenated and encoded together, TwinBERT decouples them during encoding and\nproduces the embeddings for query and document independently, which allows\ndocument embeddings to be pre-computed offline and cached in memory. Thereupon,\nthe computation left for run-time is from the query encoding and query-document\ncrossing only. This single change can save large amount of computation time and\nresources, and therefore significantly improve serving efficiency. Moreover, a\nfew well-designed network layers and training strategies are proposed to\nfurther reduce computational cost while at the same time keep the performance\nas remarkable as BERT model. Lastly, we develop two versions of TwinBERT for\nretrieval and relevance tasks correspondingly, and both of them achieve close\nor on-par performance to BERT-Base model.\n  The model was trained following the teacher-student framework and evaluated\nwith data from one of the major search engines. Experimental results showed\nthat the inference time was significantly reduced and was firstly controlled\naround 20ms on CPUs while at the same time the performance gain from fine-tuned\nBERT-Base model was mostly retained. Integration of the models into production\nsystems also demonstrated remarkable improvements on relevance metrics with\nnegligible influence on latency.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:44:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lu", "Wenhao", ""], ["Jiao", "Jian", ""], ["Zhang", "Ruofei", ""]]}, {"id": "2002.06277", "submitter": "Joan Bruna", "authors": "Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff,\n  Joan Bruna", "title": "A mean-field analysis of two-player zero-sum games", "comments": null, "journal-ref": "Published at NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding Nash equilibria in two-player zero-sum continuous games is a central\nproblem in machine learning, e.g. for training both GANs and robust models. The\nexistence of pure Nash equilibria requires strong conditions which are not\ntypically met in practice. Mixed Nash equilibria exist in greater generality\nand may be found using mirror descent. Yet this approach does not scale to high\ndimensions. To address this limitation, we parametrize mixed strategies as\nmixtures of particles, whose positions and weights are updated using gradient\ndescent-ascent. We study this dynamics as an interacting gradient flow over\nmeasure spaces endowed with the Wasserstein-Fisher-Rao metric. We establish\nglobal convergence to an approximate equilibrium for the related Langevin\ngradient-ascent dynamic. We prove a law of large numbers that relates particle\ndynamics to mean-field dynamics. Our method identifies mixed equilibria in high\ndimensions and is demonstrably effective for training mixtures of GANs.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:46:35 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:17:14 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 14:26:56 GMT"}, {"version": "v4", "created": "Thu, 6 May 2021 14:02:00 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Domingo-Enrich", "Carles", ""], ["Jelassi", "Samy", ""], ["Mensch", "Arthur", ""], ["Rotskoff", "Grant", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.06278", "submitter": "Amir-Hossein Karimi", "authors": "Amir-Hossein Karimi, Bernhard Sch\\\"olkopf, Isabel Valera", "title": "Algorithmic Recourse: from Counterfactual Explanations to Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly used to inform consequential\ndecision-making (e.g., pre-trial bail and loan approval), it becomes important\nto explain how the system arrived at its decision, and also suggest actions to\nachieve a favorable decision. Counterfactual explanations -- \"how the world\nwould have (had) to be different for a desirable outcome to occur\" -- aim to\nsatisfy these criteria. Existing works have primarily focused on designing\nalgorithms to obtain counterfactual explanations for a wide range of settings.\nHowever, one of the main objectives of \"explanations as a means to help a\ndata-subject act rather than merely understand\" has been overlooked. In\nlayman's terms, counterfactual explanations inform an individual where they\nneed to get to, but not how to get there. In this work, we rely on causal\nreasoning to caution against the use of counterfactual explanations as a\nrecommendable set of actions for recourse. Instead, we propose a shift of\nparadigm from recourse via nearest counterfactual explanations to recourse\nthrough minimal interventions, moving the focus from explanations to\nrecommendations. Finally, we provide the reader with an extensive discussion on\nhow to realistically achieve recourse beyond structural interventions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:49:42 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:48:42 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 21:19:02 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 15:15:33 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Karimi", "Amir-Hossein", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Valera", "Isabel", ""]]}, {"id": "2002.06282", "submitter": "Ata Jodeiri", "authors": "Mahya Mirbagheri, Ata Jodeiri, Naser Hakimi, Vahid Zakeri, Seyed\n  Kamaledin Setarehdan", "title": "Accurate Stress Assessment based on functional Near Infrared\n  Spectroscopy using Deep Learning Approach", "comments": "Accepted at ICBME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress is known as one of the major factors threatening human health. A large\nnumber of studies have been performed in order to either assess or relieve\nstress by analyzing the brain and heart-related signals. In this study, signals\nproduced by functional Near-Infrared Spectroscopy (fNIRS) of the brain recorded\nfrom 10 healthy volunteers are employed to assess the stress induced by the\nMontreal Imaging Stress Task by means of a deep learning system. The proposed\ndeep learning system consists of two main parts: First, the one-dimensional\nconvolutional neural network is employed to build informative feature maps.\nThen, a stack of deep fully connected layers is used to predict the stress\nexistence probability. Experiment results showed that the trained fNIRS model\nperforms stress classification by achieving 88.52 -+ 0.77% accuracy. Employment\nof the proposed deep learning system trained on the fNIRS measurements leads to\nhigher stress classification accuracy than the existing methods proposed in\nfNIRS studies in which the same experimental procedure has been employed. The\nproposed method suggests better stability with lower variation in prediction.\nFurthermore, its low computational cost opens up the possibility to be applied\nin real-time stress assessment.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 23:55:08 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Mirbagheri", "Mahya", ""], ["Jodeiri", "Ata", ""], ["Hakimi", "Naser", ""], ["Zakeri", "Vahid", ""], ["Setarehdan", "Seyed Kamaledin", ""]]}, {"id": "2002.06285", "submitter": "Bryan Bischof Dr.", "authors": "Bryan Bischof", "title": "Higher order co-occurrence tensors for hypergraphs via face-splitting", "comments": "8 pages, 1 figure, examples in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular trick for computing a pairwise co-occurrence matrix is the product\nof an incidence matrix and its transpose. We present an analog for higher order\ntuple co-occurrences using the face-splitting product, or alternately known as\nthe transpose Khatri-Rao product. These higher order co-occurrences encode the\ncommonality of tokens in the company of other tokens, and thus generalize the\nmutual information commonly studied. We demonstrate this tensor's use via a\npopular NLP model, and hypergraph models of similarity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:16:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bischof", "Bryan", ""]]}, {"id": "2002.06286", "submitter": "Huaqing Xiong", "authors": "Huaqing Xiong, Tengyu Xu, Yingbin Liang, Wei Zhang", "title": "Non-asymptotic Convergence of Adam-type Reinforcement Learning\n  Algorithms under Markovian Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the wide applications of Adam in reinforcement learning (RL), the\ntheoretical convergence of Adam-type RL algorithms has not been established.\nThis paper provides the first such convergence analysis for two fundamental RL\nalgorithms of policy gradient (PG) and temporal difference (TD) learning that\nincorporate AMSGrad updates (a standard alternative of Adam in theoretical\nanalysis), referred to as PG-AMSGrad and TD-AMSGrad, respectively. Moreover,\nour analysis focuses on Markovian sampling for both algorithms. We show that\nunder general nonlinear function approximation, PG-AMSGrad with a constant\nstepsize converges to a neighborhood of a stationary point at the rate of\n$\\mathcal{O}(1/T)$ (where $T$ denotes the number of iterations), and with a\ndiminishing stepsize converges exactly to a stationary point at the rate of\n$\\mathcal{O}(\\log^2 T/\\sqrt{T})$. Furthermore, under linear function\napproximation, TD-AMSGrad with a constant stepsize converges to a neighborhood\nof the global optimum at the rate of $\\mathcal{O}(1/T)$, and with a diminishing\nstepsize converges exactly to the global optimum at the rate of\n$\\mathcal{O}(\\log T/\\sqrt{T})$. Our study develops new techniques for analyzing\nthe Adam-type RL algorithms under Markovian sampling.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:26:49 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 15:28:43 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Xiong", "Huaqing", ""], ["Xu", "Tengyu", ""], ["Liang", "Yingbin", ""], ["Zhang", "Wei", ""]]}, {"id": "2002.06288", "submitter": "Sriram Gopalakrishnan", "authors": "Sriram Gopalakrishnan, Utkarsh Soni", "title": "Let Me At Least Learn What You Really Like: Dealing With Noisy Humans\n  When Learning Preferences", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the preferences of a human improves the quality of the interaction\nwith the human. The number of queries available to learn preferences maybe\nlimited especially when interacting with a human, and so active learning is a\nmust. One approach to active learning is to use uncertainty sampling to decide\nthe informativeness of a query. In this paper, we propose a modification to\nuncertainty sampling which uses the expected output value to help speed up\nlearning of preferences. We compare our approach with the uncertainty sampling\nbaseline, as well as conduct an ablation study to test the validity of each\ncomponent of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 00:36:23 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gopalakrishnan", "Sriram", ""], ["Soni", "Utkarsh", ""]]}, {"id": "2002.06298", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "Extreme Classification via Adversarial Softmax Approximation", "comments": "Accepted for presentation at the Eighth International Conference on\n  Learning Representations (ICLR 2020),\n  https://openreview.net/forum?id=rJxe3xSYDS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a classifier over a large number of classes, known as 'extreme\nclassification', has become a topic of major interest with applications in\ntechnology, science, and e-commerce. Traditional softmax regression induces a\ngradient cost proportional to the number of classes $C$, which often is\nprohibitively expensive. A popular scalable softmax approximation relies on\nuniform negative sampling, which suffers from slow convergence due a poor\nsignal-to-noise ratio. In this paper, we propose a simple training method for\ndrastically enhancing the gradient signal by drawing negative samples from an\nadversarial model that mimics the data distribution. Our contributions are\nthree-fold: (i) an adversarial sampling mechanism that produces negative\nsamples at a cost only logarithmic in $C$, thus still resulting in cheap\ngradient updates; (ii) a mathematical proof that this adversarial sampling\nminimizes the gradient variance while any bias due to non-uniform sampling can\nbe removed; (iii) experimental results on large scale data sets that show a\nreduction of the training time by an order of magnitude relative to several\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 01:42:52 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "2002.06299", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai, Matthew R. Walter", "title": "Loop Estimator for Discounted Values in Markov Reward Processes", "comments": "accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the working heart of policy iteration algorithms commonly used and studied\nin the discounted setting of reinforcement learning, the policy evaluation step\nestimates the value of states with samples from a Markov reward process induced\nby following a Markov policy in a Markov decision process. We propose a simple\nand efficient estimator called loop estimator that exploits the regenerative\nstructure of Markov reward processes without explicitly estimating a full\nmodel. Our method enjoys a space complexity of $O(1)$ when estimating the value\nof a single positive recurrent state $s$ unlike TD with $O(S)$ or model-based\nmethods with $O\\left(S^2\\right)$. Moreover, the regenerative structure enables\nus to show, without relying on the generative model approach, that the\nestimator has an instance-dependent convergence rate of\n$\\widetilde{O}\\left(\\sqrt{\\tau_s/T}\\right)$ over steps $T$ on a single sample\npath, where $\\tau_s$ is the maximal expected hitting time to state $s$. In\npreliminary numerical experiments, the loop estimator outperforms model-free\nmethods, such as TD(k), and is competitive with the model-based estimator.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 01:42:53 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 17:03:36 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 05:05:36 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "2002.06305", "submitter": "Jesse Dodge", "authors": "Jesse Dodge, Gabriel Ilharco, Roy Schwartz, Ali Farhadi, Hannaneh\n  Hajishirzi, Noah Smith", "title": "Fine-Tuning Pretrained Language Models: Weight Initializations, Data\n  Orders, and Early Stopping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pretrained contextual word embedding models to supervised\ndownstream tasks has become commonplace in natural language processing. This\nprocess, however, is often brittle: even with the same hyperparameter values,\ndistinct random seeds can lead to substantially different results. To better\nunderstand this phenomenon, we experiment with four datasets from the GLUE\nbenchmark, fine-tuning BERT hundreds of times on each while varying only the\nrandom seeds. We find substantial performance increases compared to previously\nreported results, and we quantify how the performance of the best-found model\nvaries as a function of the number of fine-tuning trials. Further, we examine\ntwo factors influenced by the choice of random seed: weight initialization and\ntraining data order. We find that both contribute comparably to the variance of\nout-of-sample performance, and that some weight initializations perform well\nacross all tasks explored. On small datasets, we observe that many fine-tuning\ntrials diverge part of the way through training, and we offer best practices\nfor practitioners to stop training less promising runs early. We publicly\nrelease all of our experimental data, including training and validation scores\nfor 2,100 trials, to encourage further analysis of training dynamics during\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:40:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Dodge", "Jesse", ""], ["Ilharco", "Gabriel", ""], ["Schwartz", "Roy", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""], ["Smith", "Noah", ""]]}, {"id": "2002.06306", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Abulhair Saparov and Tom Mitchell", "title": "Jelly Bean World: A Testbed for Never-Ending Learning", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": "International Conference on Learning Representations 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has shown growing success in recent years. However, current\nmachine learning systems are highly specialized, trained for particular\nproblems or domains, and typically on a single narrow dataset. Human learning,\non the other hand, is highly general and adaptable. Never-ending learning is a\nmachine learning paradigm that aims to bridge this gap, with the goal of\nencouraging researchers to design machine learning systems that can learn to\nperform a wider variety of inter-related tasks in more complex environments. To\ndate, there is no environment or testbed to facilitate the development and\nevaluation of never-ending learning systems. To this end, we propose the Jelly\nBean World testbed. The Jelly Bean World allows experimentation over\ntwo-dimensional grid worlds which are filled with items and in which agents can\nnavigate. This testbed provides environments that are sufficiently complex and\nwhere more generally intelligent algorithms ought to perform better than\ncurrent state-of-the-art reinforcement learning approaches. It does so by\nproducing non-stationary environments and facilitating experimentation with\nmulti-task, multi-agent, multi-modal, and curriculum learning settings. We hope\nthat this new freely-available software will prompt new research and interest\nin the development and evaluation of never-ending learning systems and more\nbroadly, general intelligence systems.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 02:43:16 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Saparov", "Abulhair", ""], ["Mitchell", "Tom", ""]]}, {"id": "2002.06311", "submitter": "Dongge Liu", "authors": "Dongge Liu, Gidon Ernst, Toby Murray, Benjamin I. P. Rubinstein", "title": "Legion: Best-First Concolic Testing", "comments": "12 pages, 2 Algorithms, 3 Figures, 2 Tables, ASE2020", "journal-ref": null, "doi": "10.1145/3324884.3416629", "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concolic execution and fuzzing are two complementary coverage-based testing\ntechniques. How to achieve the best of both remains an open challenge. To\naddress this research problem, we propose and evaluate Legion. Legion\nre-engineers the Monte Carlo tree search (MCTS) framework from the AI\nliterature to treat automated test generation as a problem of sequential\ndecision-making under uncertainty. Its best-first search strategy provides a\nprincipled way to learn the most promising program states to investigate at\neach search iteration, based on observed rewards from previous iterations.\nLegion incorporates a form of directed fuzzing that we call approximate\npath-preserving fuzzing (APPFuzzing) to investigate program states selected by\nMCTS. APPFuzzing serves as the Monte Carlo simulation technique and is\nimplemented by extending prior work on constrained sampling. We evaluate Legion\nagainst competitors on 2531 benchmarks from the coverage category of Test-Comp\n2020, as well as measuring its sensitivity to hyperparameters, demonstrating\nits effectiveness on a wide variety of input programs.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 03:35:11 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 04:14:13 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 02:06:37 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Liu", "Dongge", ""], ["Ernst", "Gidon", ""], ["Murray", "Toby", ""], ["Rubinstein", "Benjamin I. P.", ""]]}, {"id": "2002.06312", "submitter": "Chanwoo Kim", "authors": "Chanwoo Kim, Kwangyoun Kim, and Sathish Reddy Indurthi", "title": "Small energy masking for improved neural network training for end-to-end\n  speech recognition", "comments": "Accepted at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Small Energy Masking (SEM) algorithm, which masks\ninputs having values below a certain threshold. More specifically, a\ntime-frequency bin is masked if the filterbank energy in this bin is less than\na certain energy threshold. A uniform distribution is employed to randomly\ngenerate the ratio of this energy threshold to the peak filterbank energy of\neach utterance in decibels. The unmasked feature elements are scaled so that\nthe total sum of the feature values remain the same through this masking\nprocedure. This very simple algorithm shows relatively 11.2 % and 13.5 % Word\nError Rate (WER) improvements on the standard LibriSpeech test-clean and\ntest-other sets over the baseline end-to-end speech recognition system.\nAdditionally, compared to the input dropout algorithm, SEM algorithm shows\nrelatively 7.7 % and 11.6 % improvements on the same LibriSpeech test-clean and\ntest-other sets. With a modified shallow-fusion technique with a Transformer\nLM, we obtained a 2.62 % WER on the LibriSpeech test-clean set and a 7.87 % WER\non the LibriSpeech test-other set.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 03:36:46 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Chanwoo", ""], ["Kim", "Kwangyoun", ""], ["Indurthi", "Sathish Reddy", ""]]}, {"id": "2002.06328", "submitter": "Shindong Lee", "authors": "Shindong Lee, BongGu Ko, Keonnyeong Lee, In-Chul Yoo, and Dongsuk Yook", "title": "Many-to-Many Voice Conversion using Conditional Cycle-Consistent\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) refers to transforming the speaker characteristics of\nan utterance without altering its linguistic contents. Many works on voice\nconversion require to have parallel training data that is highly expensive to\nacquire. Recently, the cycle-consistent adversarial network (CycleGAN), which\ndoes not require parallel training data, has been applied to voice conversion,\nshowing the state-of-the-art performance. The CycleGAN based voice conversion,\nhowever, can be used only for a pair of speakers, i.e., one-to-one voice\nconversion between two speakers. In this paper, we extend the CycleGAN by\nconditioning the network on speakers. As a result, the proposed method can\nperform many-to-many voice conversion among multiple speakers using a single\ngenerative adversarial network (GAN). Compared to building multiple CycleGANs\nfor each pair of speakers, the proposed method reduces the computational and\nspatial cost significantly without compromising the sound quality of the\nconverted voice. Experimental results using the VCC2018 corpus confirm the\nefficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 06:03:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lee", "Shindong", ""], ["Ko", "BongGu", ""], ["Lee", "Keonnyeong", ""], ["Yoo", "In-Chul", ""], ["Yook", "Dongsuk", ""]]}, {"id": "2002.06336", "submitter": "Avishek Bose", "authors": "Avishek Joey Bose, Ariella Smofsky, Renjie Liao, Prakash Panangaden,\n  and William L. Hamilton", "title": "Latent Variable Modelling with Hyperbolic Normalizing Flows", "comments": "Preprint, work under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of approximate posterior distributions plays a central role in\nstochastic variational inference (SVI). One effective solution is the use of\nnormalizing flows \\cut{defined on Euclidean spaces} to construct flexible\nposterior distributions. However, one key limitation of existing normalizing\nflows is that they are restricted to the Euclidean space and are ill-equipped\nto model data with an underlying hierarchical structure. To address this\nfundamental limitation, we present the first extension of normalizing flows to\nhyperbolic spaces. We first elevate normalizing flows to hyperbolic spaces\nusing coupling transforms defined on the tangent bundle, termed Tangent\nCoupling ($\\mathcal{TC}$). We further introduce Wrapped Hyperboloid Coupling\n($\\mathcal{W}\\mathbb{H}C$), a fully invertible and learnable transformation\nthat explicitly utilizes the geometric structure of hyperbolic spaces, allowing\nfor expressive posteriors while being efficient to sample from. We demonstrate\nthe efficacy of our novel normalizing flow over hyperbolic VAEs and Euclidean\nnormalizing flows. Our approach achieves improved performance on density\nestimation, as well as reconstruction of real-world graph data, which exhibit a\nhierarchical structure. Finally, we show that our approach can be used to power\na generative model over hierarchical data using hyperbolic latent variables.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 07:44:00 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 03:56:12 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 15:51:14 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 05:04:01 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Smofsky", "Ariella", ""], ["Liao", "Renjie", ""], ["Panangaden", "Prakash", ""], ["Hamilton", "William L.", ""]]}, {"id": "2002.06337", "submitter": "Taejoon Byun", "authors": "Taejoon Byun, Abhishek Vijayakumar, Sanjai Rayadurgam, Darren Cofer", "title": "Manifold-based Test Generation for Image Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks used for image classification tasks in critical applications\nmust be tested with sufficient realistic data to assure their correctness. To\neffectively test an image classification neural network, one must obtain\nrealistic test data adequate enough to inspire confidence that differences\nbetween the implicit requirements and the learned model would be exposed. This\nraises two challenges: first, an adequate subset of the data points must be\ncarefully chosen to inspire confidence, and second, the implicit requirements\nmust be meaningfully extrapolated to data points beyond those in the explicit\ntraining set. This paper proposes a novel framework to address these\nchallenges. Our approach is based on the premise that patterns in a large input\ndata space can be effectively captured in a smaller manifold space, from which\nsimilar yet novel test cases---both the input and the label---can be sampled\nand generated. A variant of Conditional Variational Autoencoder (CVAE) is used\nfor capturing this manifold with a generative function, and a search technique\nis applied on this manifold space to efficiently find fault-revealing inputs.\nExperiments show that this approach enables generation of thousands of\nrealistic yet fault-revealing test cases efficiently even for well-trained\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 07:53:34 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Byun", "Taejoon", ""], ["Vijayakumar", "Abhishek", ""], ["Rayadurgam", "Sanjai", ""], ["Cofer", "Darren", ""]]}, {"id": "2002.06349", "submitter": "Apostolos Modas", "authors": "Guillermo Ortiz-Jimenez, Apostolos Modas, Seyed-Mohsen\n  Moosavi-Dezfooli, Pascal Frossard", "title": "Hold me tight! Influence of discriminative features on deep network\n  boundaries", "comments": "Accepted to the 34th Conference on Neural Information Processing\n  Systems (NeurIPS) 2020 (30 pages, 38 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important insights towards the explainability of neural networks reside in\nthe characteristics of their decision boundaries. In this work, we borrow tools\nfrom the field of adversarial robustness, and propose a new perspective that\nrelates dataset features to the distance of samples to the decision boundary.\nThis enables us to carefully tweak the position of the training samples and\nmeasure the induced changes on the boundaries of CNNs trained on large-scale\nvision datasets. We use this framework to reveal some intriguing properties of\nCNNs. Specifically, we rigorously confirm that neural networks exhibit a high\ninvariance to non-discriminative features, and show that the decision\nboundaries of a DNN can only exist as long as the classifier is trained with\nsome features that hold them together. Finally, we show that the construction\nof the decision boundary is extremely sensitive to small perturbations of the\ntraining samples, and that changes in certain directions can lead to sudden\ninvariances in the orthogonal ones. This is precisely the mechanism that\nadversarial training uses to achieve robustness.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 09:29:36 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:42:50 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 12:08:17 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2020 07:16:47 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ortiz-Jimenez", "Guillermo", ""], ["Modas", "Apostolos", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Frossard", "Pascal", ""]]}, {"id": "2002.06352", "submitter": "Mengwei Xu", "authors": "Mengwei Xu, Yuxin Zhao, Kaigui Bian, Gang Huang, Qiaozhu Mei, Xuanzhe\n  Liu", "title": "Federated Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To preserve user privacy while enabling mobile intelligence, techniques have\nbeen proposed to train deep neural networks on decentralized data. However,\ntraining over decentralized data makes the design of neural architecture quite\ndifficult as it already was. Such difficulty is further amplified when\ndesigning and deploying different neural architectures for heterogeneous mobile\nplatforms. In this work, we propose an automatic neural architecture search\ninto the decentralized training, as a new DNN training paradigm called\nFederated Neural Architecture Search, namely federated NAS. To deal with the\nprimary challenge of limited on-client computational and communication\nresources, we present FedNAS, a highly optimized framework for efficient\nfederated NAS. FedNAS fully exploits the key opportunity of insufficient model\ncandidate re-training during the architecture search process, and incorporates\nthree key optimizations: parallel candidates training on partial clients, early\ndropping candidates with inferior performance, and dynamic round numbers.\nTested on large-scale datasets and typical CNN architectures, FedNAS achieves\ncomparable model accuracy as state-of-the-art NAS algorithm that trains models\nwith centralized data, and also reduces the client cost by up to two orders of\nmagnitude compared to a straightforward design of federated NAS.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 10:01:05 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 02:55:53 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 11:31:43 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 03:21:52 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Xu", "Mengwei", ""], ["Zhao", "Yuxin", ""], ["Bian", "Kaigui", ""], ["Huang", "Gang", ""], ["Mei", "Qiaozhu", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "2002.06353", "submitter": "Huaishao Luo", "authors": "Huaishao Luo, Lei Ji, Botian Shi, Haoyang Huang, Nan Duan, Tianrui Li,\n  Jason Li, Taroon Bharti, Ming Zhou", "title": "UniVL: A Unified Video and Language Pre-Training Model for Multimodal\n  Understanding and Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent success of the pre-training technique for NLP and\nimage-linguistic tasks, some video-linguistic pre-training works are gradually\ndeveloped to improve video-text related downstream tasks. However, most of the\nexisting multimodal models are pre-trained for understanding tasks, leading to\na pretrain-finetune discrepancy for generation tasks. This paper proposes\nUniVL: a Unified Video and Language pre-training model for both multimodal\nunderstanding and generation. It comprises four components, including two\nsingle-modal encoders, a cross encoder, and a decoder with the Transformer\nbackbone. Five objectives, including video-text joint, conditioned masked\nlanguage model (CMLM), conditioned masked frame model (CMFM), video-text\nalignment, and language reconstruction, are designed to train each of the\ncomponents. We further develop two pre-training strategies, stage by stage\npre-training (StagedP) and enhanced video representation (EnhancedV), to make\nthe training process of the UniVL more effective. The pre-train is carried out\non a sizeable instructional video dataset HowTo100M. Experimental results\ndemonstrate that the UniVL can learn strong video-text representation and\nachieves state-of-the-art results on five downstream tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 10:03:25 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 14:21:43 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 13:27:13 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Luo", "Huaishao", ""], ["Ji", "Lei", ""], ["Shi", "Botian", ""], ["Huang", "Haoyang", ""], ["Duan", "Nan", ""], ["Li", "Tianrui", ""], ["Li", "Jason", ""], ["Bharti", "Taroon", ""], ["Zhou", "Ming", ""]]}, {"id": "2002.06372", "submitter": "Kirill Akhmetzyanov", "authors": "Kirill Akhmetzyanov, Alexander Yuzhakov", "title": "Multi-Task Multicriteria Hyperparameter Optimization", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for searching optimal hyperparameters among several\ntasks and several criteria. Multi-Task Multi Criteria method (MTMC) provides\nseveral Pareto-optimal solutions, among which one solution is selected with\ngiven criteria significance coefficients. The article begins with a\nmathematical formulation of the problem of choosing optimal hyperparameters.\nThen, the steps of the MTMC method that solves this problem are described. The\nproposed method is evaluated on the image classification problem using a\nconvolutional neural network. The article presents optimal hyperparameters for\nvarious criteria significance coefficients.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 12:47:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Akhmetzyanov", "Kirill", ""], ["Yuzhakov", "Alexander", ""]]}, {"id": "2002.06374", "submitter": "Mohammad Sabouri", "authors": "Daniel. Firouzimagham, Mohammad. Sabouri, and Fatemeh. Adhami", "title": "An IoT-Based System: Big Urban Traffic Data Mining Through Airborne\n  Pollutant Gases Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, in developing countries including Iran, the number of vehicles is\nincreasing due to growing population. This has recently led to waste time\ngetting stuck in traffic, take more time for daily commute, and increase\naccidents. So it is necessary to control traffic congestion by traffic police\nofficers, expand paths efficiently and choose the best way for decreasing the\ntraffic by citizens. Therefore, it is important to have the knowledge of\ninstant traffic in each lane. Todays, many traffic organization services such\nas traffic police officer and urban traffic control system use traffic cameras,\ninductive sensors, satellite images, radar sensors, ultrasonic technology and\nradio-frequency identification (RFID) for urban traffic diagnosis. But this\nmethod has some problems such as inefficiency in heavy traffic influenced by\ncondition of the air and inability to detect parallel traffic. Our method\nsuggested in this article detects traffic congestion based on IOT containing a\nsmart system that gives us traffic congestion by calculating the air pollution\namount in that area. According to conducted experiment, the results were\nsatisfied.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 13:04:37 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Firouzimagham", "Daniel.", ""], ["Sabouri", "Mohammad.", ""], ["Adhami", "Fatemeh.", ""]]}, {"id": "2002.06382", "submitter": "Cefas Rodrigues Freire", "authors": "Cefas Rodrigues Freire, Julio Cesar da Costa Moura, Daniele Montenegro\n  da Silva Barros and Ricardo Alexsandro de Medeiros Valentim", "title": "Automatic lesion segmentation and Pathological Myopia classification in\n  fundus images", "comments": "ISBI 2019 PALM Challenge Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present algorithms to diagnosis Pathological Myopia (PM) and\ndetection of retinal structures and lesions such asOptic Disc (OD), Fovea,\nAtrophy and Detachment. All these tasks were performed in fundus imaging from\nPM patients and they are requirements to participate in the Pathologic Myopia\nChallenge (PALM). The challenge was organized as a half day Challenge, a\nSatellite Event of The IEEE International Symposium on Biomedical Imaging in\nVenice Italy.Our method applies different Deep Learning techniques for each\ntask. Transfer learning is applied in all tasks using Xception as the baseline\nmodel. Also, some key ideas of YOLO architecture are used in the Optic Disc\nsegmentation algorithm pipeline. We have evaluated our model's performance\naccording the challenge rules in terms of AUC-ROC, F1-Score, Mean Dice Score\nand Mean Euclidean Distance. For initial activities our method has shown\nsatisfactory results.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 13:38:30 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Freire", "Cefas Rodrigues", ""], ["Moura", "Julio Cesar da Costa", ""], ["Barros", "Daniele Montenegro da Silva", ""], ["Valentim", "Ricardo Alexsandro de Medeiros", ""]]}, {"id": "2002.06383", "submitter": "Andrew McDole", "authors": "Andrew McDole and Mahmoud Abdelsalam and Maanak Gupta and Sudip Mittal", "title": "Analyzing CNN Based Behavioural Malware Detection Techniques on Cloud\n  IaaS", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-59635-4_5", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Infrastructure as a Service (IaaS) is vulnerable to malware due to its\nexposure to external adversaries, making it a lucrative attack vector for\nmalicious actors. A datacenter infected with malware can cause data loss and/or\nmajor disruptions to service for its users. This paper analyzes and compares\nvarious Convolutional Neural Networks (CNNs) for online detection of malware in\ncloud IaaS. The detection is performed based on behavioural data using process\nlevel performance metrics including cpu usage, memory usage, disk usage etc. We\nhave used the state of the art DenseNets and ResNets in effectively detecting\nmalware in online cloud system. CNN are designed to extract features from data\ngathered from a live malware running on a real cloud environment. Experiments\nare performed on OpenStack (a cloud IaaS software) testbed designed to\nreplicate a typical 3-tier web architecture. Comparative analysis is performed\nfor different metrics for different CNN models used in this research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 14:04:33 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["McDole", "Andrew", ""], ["Abdelsalam", "Mahmoud", ""], ["Gupta", "Maanak", ""], ["Mittal", "Sudip", ""]]}, {"id": "2002.06395", "submitter": "Giuseppe Di Molfetta Prof.", "authors": "Balthazar Casal\\'e, Giuseppe Di Molfetta, Hachem Kadri, Liva Ralaivola", "title": "Quantum Bandits", "comments": "All your comments are very welcome!", "journal-ref": "Quantum Machine Intelligence 2, 1-7 (2020)", "doi": "10.1007/s42484-020-00024-8", "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantum version of the bandit problem known as {\\em best arm\nidentification} (BAI). We first propose a quantum modeling of the BAI problem,\nwhich assumes that both the learning agent and the environment are quantum; we\nthen propose an algorithm based on quantum amplitude amplification to solve\nBAI. We formally analyze the behavior of the algorithm on all instances of the\nproblem and we show, in particular, that it is able to get the optimal solution\nquadratically faster than what is known to hold in the classical case.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:17:11 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 14:13:18 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Casal\u00e9", "Balthazar", ""], ["Di Molfetta", "Giuseppe", ""], ["Kadri", "Hachem", ""], ["Ralaivola", "Liva", ""]]}, {"id": "2002.06406", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber, Ashwath Sampath", "title": "HybridCite: A Hybrid Model for Context-Aware Citation Recommendation", "comments": "to be published in the Proceedings of the ACM/IEEE Joint Conference\n  on Digital Libraries (JCDL '20)", "journal-ref": null, "doi": "10.1145/3383583.3398534", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation recommendation systems aim to recommend citations for either a\ncomplete paper or a small portion of text called a citation context. The\nprocess of recommending citations for citation contexts is called local\ncitation recommendation and is the focus of this paper. Firstly, we develop\ncitation recommendation approaches based on embeddings, topic modeling, and\ninformation retrieval techniques. We combine, for the first time to the best of\nour knowledge, the best-performing algorithms into a semi-genetic hybrid\nrecommender system for citation recommendation. We evaluate the single\napproaches and the hybrid approach offline based on several data sets, such as\nthe Microsoft Academic Graph (MAG) and the MAG in combination with arXiv and\nACL. We further conduct a user study for evaluating our approaches online. Our\nevaluation results show that a hybrid model containing embedding and\ninformation retrieval-based components outperforms its individual components\nand further algorithms by a large margin.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:19:55 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 16:49:44 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Sampath", "Ashwath", ""]]}, {"id": "2002.06410", "submitter": "Song Liu Dr.", "authors": "Song Liu, Yulong Zhang, Mingxuan Yi, Mladen Kolar", "title": "Posterior Ratio Estimation of Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density Ratio Estimation has attracted attention from the machine learning\ncommunity due to its ability to compare the underlying distributions of two\ndatasets. However, in some applications, we want to compare distributions of\nrandom variables that are \\emph{inferred} from observations. In this paper, we\nstudy the problem of estimating the ratio between two posterior probability\ndensity functions of a latent variable. Particularly, we assume the posterior\nratio function can be well-approximated by a parametric model, which is then\nestimated using observed information and prior samples. We prove the\nconsistency of our estimator and the asymptotic normality of the estimated\nparameters as the number of prior samples tending to infinity. Finally, we\nvalidate our theories using numerical experiments and demonstrate the\nusefulness of the proposed method through some real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 16:46:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 17:49:50 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Liu", "Song", ""], ["Zhang", "Yulong", ""], ["Yi", "Mingxuan", ""], ["Kolar", "Mladen", ""]]}, {"id": "2002.06436", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "MRRC: Multiple Role Representation Crossover Interpretation for Image\n  Captioning With R-CNN Feature Distribution Composition (FDC)", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While image captioning through machines requires structured learning and\nbasis for interpretation, improvement requires multiple context understanding\nand processing in a meaningful way. This research will provide a novel concept\nfor context combination and will impact many applications to deal visual\nfeatures as an equivalence of descriptions of objects, activities and events.\nThere are three components of our architecture: Feature Distribution\nComposition (FDC) Layer Attention, Multiple Role Representation Crossover\n(MRRC) Attention Layer and the Language Decoder. FDC Layer Attention helps in\ngenerating the weighted attention from RCNN features, MRRC Attention Layer acts\nas intermediate representation processing and helps in generating the next word\nattention, while Language Decoder helps in estimation of the likelihood for the\nnext probable word in the sentence. We demonstrated effectiveness of FDC, MRRC,\nregional object feature attention and reinforcement learning for effective\nlearning to generate better captions from images. The performance of our model\nenhanced previous performances by 35.3\\% and created a new standard and theory\nfor representation generation based on logic, better interpretability and\ncontexts.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 19:45:22 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2002.06440", "submitter": "Hongyi Wang", "authors": "Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos,\n  Yasaman Khazaeni", "title": "Federated Learning with Matched Averaging", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning allows edge devices to collaboratively learn a shared\nmodel while keeping the training data on device, decoupling the ability to do\nmodel training from the need to store the data in the cloud. We propose\nFederated matched averaging (FedMA) algorithm designed for federated learning\nof modern neural network architectures e.g. convolutional neural networks\n(CNNs) and LSTMs. FedMA constructs the shared global model in a layer-wise\nmanner by matching and averaging hidden elements (i.e. channels for convolution\nlayers; hidden states for LSTM; neurons for fully connected layers) with\nsimilar feature extraction signatures. Our experiments indicate that FedMA not\nonly outperforms popular state-of-the-art federated learning algorithms on deep\nCNN and LSTM architectures trained on real world datasets, but also reduces the\noverall communication burden.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 20:09:24 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Hongyi", ""], ["Yurochkin", "Mikhail", ""], ["Sun", "Yuekai", ""], ["Papailiopoulos", "Dimitris", ""], ["Khazaeni", "Yasaman", ""]]}, {"id": "2002.06442", "submitter": "Chuan Xiao", "authors": "Yaoshu Wang, Chuan Xiao, Jianbin Qin, Xin Cao, Yifang Sun, Wei Wang,\n  and Makoto Onizuka", "title": "Monotonic Cardinality Estimation of Similarity Selection: A Deep\n  Learning Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3318464.3380570", "report-no": null, "categories": "cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the outstanding capability of capturing underlying data distributions,\ndeep learning techniques have been recently utilized for a series of\ntraditional database problems. In this paper, we investigate the possibilities\nof utilizing deep learning for cardinality estimation of similarity selection.\nAnswering this problem accurately and efficiently is essential to many data\nmanagement applications, especially for query optimization. Moreover, in some\napplications the estimated cardinality is supposed to be consistent and\ninterpretable. Hence a monotonic estimation w.r.t. the query threshold is\npreferred. We propose a novel and generic method that can be applied to any\ndata type and distance function. Our method consists of a feature extraction\nmodel and a regression model. The feature extraction model transforms original\ndata and threshold to a Hamming space, in which a deep learning-based\nregression model is utilized to exploit the incremental property of cardinality\nw.r.t. the threshold for both accuracy and monotonicity. We develop a training\nstrategy tailored to our model as well as techniques for fast estimation. We\nalso discuss how to handle updates. We demonstrate the accuracy and the\nefficiency of our method through experiments, and show how it improves the\nperformance of a query optimizer.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 20:22:51 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 15:54:07 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 19:04:19 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Wang", "Yaoshu", ""], ["Xiao", "Chuan", ""], ["Qin", "Jianbin", ""], ["Cao", "Xin", ""], ["Sun", "Yifang", ""], ["Wang", "Wei", ""], ["Onizuka", "Makoto", ""]]}, {"id": "2002.06450", "submitter": "Manni Singh", "authors": "Manni Singh, David Weston, Mark Levene", "title": "Supervised Phrase-boundary Embeddings", "comments": "12 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new word embedding model, called SPhrase, that incorporates\nsupervised phrase information. Our method modifies traditional word embeddings\nby ensuring that all target words in a phrase have exactly the same context. We\ndemonstrate that including this information within a context window produces\nsuperior embeddings for both intrinsic evaluation tasks and downstream\nextrinsic tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 21:05:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Singh", "Manni", ""], ["Weston", "David", ""], ["Levene", "Mark", ""]]}, {"id": "2002.06460", "submitter": "Alfredo Kalaitzis", "authors": "Michel Deudon, Alfredo Kalaitzis, Israel Goytom, Md Rifat Arefin,\n  Zhichao Lin, Kris Sankaran, Vincent Michalski, Samira E. Kahou, Julien\n  Cornebise, Yoshua Bengio", "title": "HighRes-net: Recursive Fusion for Multi-Frame Super-Resolution of\n  Satellite Imagery", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative deep learning has sparked a new wave of Super-Resolution (SR)\nalgorithms that enhance single images with impressive aesthetic results, albeit\nwith imaginary details. Multi-frame Super-Resolution (MFSR) offers a more\ngrounded approach to the ill-posed problem, by conditioning on multiple\nlow-resolution views. This is important for satellite monitoring of human\nimpact on the planet -- from deforestation, to human rights violations -- that\ndepend on reliable imagery. To this end, we present HighRes-net, the first deep\nlearning approach to MFSR that learns its sub-tasks in an end-to-end fashion:\n(i) co-registration, (ii) fusion, (iii) up-sampling, and (iv)\nregistration-at-the-loss. Co-registration of low-resolution views is learned\nimplicitly through a reference-frame channel, with no explicit registration\nmechanism. We learn a global fusion operator that is applied recursively on an\narbitrary number of low-resolution pairs. We introduce a registered loss, by\nlearning to align the SR output to a ground-truth through ShiftNet. We show\nthat by learning deep representations of multiple views, we can super-resolve\nlow-resolution signals and enhance Earth Observation data at scale. Our\napproach recently topped the European Space Agency's MFSR competition on\nreal-world satellite imagery.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:17:47 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Deudon", "Michel", ""], ["Kalaitzis", "Alfredo", ""], ["Goytom", "Israel", ""], ["Arefin", "Md Rifat", ""], ["Lin", "Zhichao", ""], ["Sankaran", "Kris", ""], ["Michalski", "Vincent", ""], ["Kahou", "Samira E.", ""], ["Cornebise", "Julien", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.06469", "submitter": "Murad Tukan", "authors": "Murad Tukan, Cenk Baykal, Dan Feldman, Daniela Rus", "title": "On Coresets for Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient coreset construction algorithm for large-scale\nSupport Vector Machine (SVM) training in Big Data and streaming applications. A\ncoreset is a small, representative subset of the original data points such that\na models trained on the coreset are provably competitive with those trained on\nthe original data set. Since the size of the coreset is generally much smaller\nthan the original set, our preprocess-then-train scheme has potential to lead\nto significant speedups when training SVM models. We prove lower and upper\nbounds on the size of the coreset required to obtain small data summaries for\nthe SVM problem. As a corollary, we show that our algorithm can be used to\nextend the applicability of any off-the-shelf SVM solver to streaming,\ndistributed, and dynamic data settings. We evaluate the performance of our\nalgorithm on real-world and synthetic data sets. Our experimental results\nreaffirm the favorable theoretical properties of our algorithm and demonstrate\nits practical effectiveness in accelerating SVM training.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:25:12 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tukan", "Murad", ""], ["Baykal", "Cenk", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "2002.06470", "submitter": "Arsenii Ashukha", "authors": "Arsenii Ashukha, Alexander Lyzhov, Dmitry Molchanov, Dmitry Vetrov", "title": "Pitfalls of In-Domain Uncertainty Estimation and Ensembling in Deep\n  Learning", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation and ensembling methods go hand-in-hand. Uncertainty\nestimation is one of the main benchmarks for assessment of ensembling\nperformance. At the same time, deep learning ensembles have provided\nstate-of-the-art results in uncertainty estimation. In this work, we focus on\nin-domain uncertainty for image classification. We explore the standards for\nits quantification and point out pitfalls of existing metrics. Avoiding these\npitfalls, we perform a broad study of different ensembling techniques. To\nprovide more insight in this study, we introduce the deep ensemble equivalent\nscore (DEE) and show that many sophisticated ensembling techniques are\nequivalent to an ensemble of only few independently trained networks in terms\nof test performance.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:28:19 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:47:14 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 16:44:09 GMT"}, {"version": "v4", "created": "Sun, 18 Jul 2021 16:17:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ashukha", "Arsenii", ""], ["Lyzhov", "Alexander", ""], ["Molchanov", "Dmitry", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.06473", "submitter": "Yannick Schroecker", "authors": "Yannick Schroecker, Charles Isbell", "title": "Universal Value Density Estimation for Imitation Learning and\n  Goal-Conditioned Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers two distinct settings: imitation learning and\ngoal-conditioned reinforcement learning. In either case, effective solutions\nrequire the agent to reliably reach a specified state (a goal), or set of\nstates (a demonstration). Drawing a connection between probabilistic long-term\ndynamics and the desired value function, this work introduces an approach which\nutilizes recent advances in density estimation to effectively learn to reach a\ngiven state. As our first contribution, we use this approach for\ngoal-conditioned reinforcement learning and show that it is both efficient and\ndoes not suffer from hindsight bias in stochastic domains. As our second\ncontribution, we extend the approach to imitation learning and show that it\nachieves state-of-the art demonstration sample-efficiency on standard benchmark\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:46:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Schroecker", "Yannick", ""], ["Isbell", "Charles", ""]]}, {"id": "2002.06476", "submitter": "Ari Azarafrooz", "authors": "Ari Azarafrooz", "title": "Follow the Neurally-Perturbed Leader for Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game-theoretic models of learning are a powerful set of models that optimize\nmulti-objective architectures. Among these models are zero-sum architectures\nthat have inspired adversarial learning frameworks. An important shortcoming of\nthese zeros-sum architectures is that gradient-based training leads to weak\nconvergence and cyclic dynamics.\n  We propose a novel follow the leader training algorithm for zeros-sum\narchitectures that guarantees convergence to mixed Nash equilibrium without\ncyclic behaviors. It is a special type of follow the perturbed leader algorithm\nwhere perturbations are the result of a neural mediating agent.\n  We validate our theoretical results by applying this training algorithm to\ngames with convex and non-convex loss as well as generative adversarial\narchitectures. Moreover, we customize the implementation of this algorithm for\nadversarial imitation learning applications. At every step of the training, the\nmediator agent perturbs the observations with generated codes. As a result of\nthese mediating codes, the proposed algorithm is also efficient for learning in\nenvironments with various factors of variations. We validate our assertion by\nusing a procedurally generated game environment as well as synthetic data.\nGithub implementation is available.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:09:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 04:54:53 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Azarafrooz", "Ari", ""]]}, {"id": "2002.06478", "submitter": "Tiange Luo", "authors": "Tiange Luo, Kaichun Mo, Zhiao Huang, Jiarui Xu, Siyu Hu, Liwei Wang,\n  Hao Su", "title": "Learning to Group: A Bottom-Up Framework for 3D Part Discovery in Unseen\n  Categories", "comments": "Accepted by ICLR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of discovering 3D parts for objects in unseen\ncategories. Being able to learn the geometry prior of parts and transfer this\nprior to unseen categories pose fundamental challenges on data-driven shape\nsegmentation approaches. Formulated as a contextual bandit problem, we propose\na learning-based agglomerative clustering framework which learns a grouping\npolicy to progressively group small part proposals into bigger ones in a\nbottom-up fashion. At the core of our approach is to restrict the local context\nfor extracting part-level features, which encourages the generalizability to\nunseen categories. On the large-scale fine-grained 3D part dataset, PartNet, we\ndemonstrate that our method can transfer knowledge of parts learned from 3\ntraining categories to 21 unseen testing categories without seeing any\nannotated samples. Quantitative comparisons against four shape segmentation\nbaselines shows that our approach achieve the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:23:43 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 04:49:21 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 22:51:58 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Luo", "Tiange", ""], ["Mo", "Kaichun", ""], ["Huang", "Zhiao", ""], ["Xu", "Jiarui", ""], ["Hu", "Siyu", ""], ["Wang", "Liwei", ""], ["Su", "Hao", ""]]}, {"id": "2002.06482", "submitter": "Jun Shu", "authors": "Jun Shu, Qian Zhao, Keyu Chen, Zongben Xu, Deyu Meng", "title": "Learning Adaptive Loss for Robust Learning with Noisy Labels", "comments": "10pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust loss minimization is an important strategy for handling robust\nlearning issue on noisy labels. Current robust loss functions, however,\ninevitably involve hyperparameter(s) to be tuned, manually or heuristically\nthrough cross validation, which makes them fairly hard to be generally applied\nin practice. Besides, the non-convexity brought by the loss as well as the\ncomplicated network architecture makes it easily trapped into an unexpected\nsolution with poor generalization capability. To address above issues, we\npropose a meta-learning method capable of adaptively learning hyperparameter in\nrobust loss functions. Specifically, through mutual amelioration between robust\nloss hyperparameter and network parameters in our method, both of them can be\nsimultaneously finely learned and coordinated to attain solutions with good\ngeneralization capability. Four kinds of SOTA robust loss functions are\nattempted to be integrated into our algorithm, and comprehensive experiments\nsubstantiate the general availability and effectiveness of the proposed method\nin both its accuracy and generalization performance, as compared with\nconventional hyperparameter tuning strategy, even with carefully tuned\nhyperparameters.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:53:37 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Shu", "Jun", ""], ["Zhao", "Qian", ""], ["Chen", "Keyu", ""], ["Xu", "Zongben", ""], ["Meng", "Deyu", ""]]}, {"id": "2002.06487", "submitter": "Qingfeng Lan", "authors": "Qingfeng Lan, Yangchen Pan, Alona Fyshe, Martha White", "title": "Maxmin Q-learning: Controlling the Estimation Bias of Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Q-learning suffers from overestimation bias, because it approximates the\nmaximum action value using the maximum estimated action value. Algorithms have\nbeen proposed to reduce overestimation bias, but we lack an understanding of\nhow bias interacts with performance, and the extent to which existing\nalgorithms mitigate bias. In this paper, we 1) highlight that the effect of\noverestimation bias on learning efficiency is environment-dependent; 2) propose\na generalization of Q-learning, called \\emph{Maxmin Q-learning}, which provides\na parameter to flexibly control bias; 3) show theoretically that there exists a\nparameter choice for Maxmin Q-learning that leads to unbiased estimation with a\nlower approximation variance than Q-learning; and 4) prove the convergence of\nour algorithm in the tabular case, as well as convergence of several previous\nQ-learning variants, using a novel Generalized Q-learning framework. We\nempirically verify that our algorithm better controls estimation bias in toy\nenvironments, and that it achieves superior performance on several benchmark\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 02:02:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lan", "Qingfeng", ""], ["Pan", "Yangchen", ""], ["Fyshe", "Alona", ""], ["White", "Martha", ""]]}, {"id": "2002.06488", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "Convex Optimization on Functionals of Probability Densities", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information theory, some optimization problems result in convex\noptimization problems on strictly convex functionals of probability densities.\nIn this note, we study these problems and show conditions of minimizers and the\nuniqueness of the minimizer if there exist a minimizer.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 02:10:36 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 05:13:48 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "2002.06495", "submitter": "Milad Nasr", "authors": "Milad Nasr, Alireza Bahramali, Amir Houmansadr", "title": "Blind Adversarial Network Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are commonly used for various traffic analysis\nproblems, such as website fingerprinting and flow correlation, as they\noutperform traditional (e.g., statistical) techniques by large margins.\nHowever, deep neural networks are known to be vulnerable to adversarial\nexamples: adversarial inputs to the model that get labeled incorrectly by the\nmodel due to small adversarial perturbations. In this paper, for the first\ntime, we show that an adversary can defeat DNN-based traffic analysis\ntechniques by applying \\emph{adversarial perturbations} on the patterns of\n\\emph{live} network traffic.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 02:59:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nasr", "Milad", ""], ["Bahramali", "Alireza", ""], ["Houmansadr", "Amir", ""]]}, {"id": "2002.06501", "submitter": "Hikaru Ogura", "authors": "Hikaru Ogura and Akiko Takeda", "title": "Convex Fairness Constrained Model Using Causal Effect Estimators", "comments": "10 pages, 5 figures, Accepted for the 2nd Workshop on Fairness,\n  Accountability, Transparency, Ethics and Society on the Web (FATES on the Web\n  2020), held in conjunction with the WWW'20", "journal-ref": null, "doi": "10.1145/3366424.3383556", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen much research on fairness in machine learning. Here,\nmean difference (MD) or demographic parity is one of the most popular measures\nof fairness. However, MD quantifies not only discrimination but also\nexplanatory bias which is the difference of outcomes justified by explanatory\nfeatures. In this paper, we devise novel models, called FairCEEs, which remove\ndiscrimination while keeping explanatory bias. The models are based on\nestimators of causal effect utilizing propensity score analysis. We prove that\nFairCEEs with the squared loss theoretically outperform a naive MD constraint\nmodel. We provide an efficient algorithm for solving FairCEEs in regression and\nbinary classification tasks. In our experiment on synthetic and real-world data\nin these two tasks, FairCEEs outperformed an existing model that considers\nexplanatory bias in specific cases.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 03:40:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ogura", "Hikaru", ""], ["Takeda", "Akiko", ""]]}, {"id": "2002.06504", "submitter": "Yujia Xie", "authors": "Yujia Xie, Hanjun Dai, Minshuo Chen, Bo Dai, Tuo Zhao, Hongyuan Zha,\n  Wei Wei, Tomas Pfister", "title": "Differentiable Top-k Operator with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The top-k operation, i.e., finding the k largest or smallest elements from a\ncollection of scores, is an important model component, which is widely used in\ninformation retrieval, machine learning, and data mining. However, if the top-k\noperation is implemented in an algorithmic way, e.g., using bubble algorithm,\nthe resulting model cannot be trained in an end-to-end way using prevalent\ngradient descent algorithms. This is because these implementations typically\ninvolve swapping indices, whose gradient cannot be computed. Moreover, the\ncorresponding mapping from the input scores to the indicator vector of whether\nthis element belongs to the top-k set is essentially discontinuous. To address\nthe issue, we propose a smoothed approximation, namely the SOFT (Scalable\nOptimal transport-based diFferenTiable) top-k operator. Specifically, our SOFT\ntop-k operator approximates the output of the top-k operation as the solution\nof an Entropic Optimal Transport (EOT) problem. The gradient of the SOFT\noperator can then be efficiently approximated based on the optimality\nconditions of EOT problem. We apply the proposed operator to the k-nearest\nneighbors and beam search algorithms, and demonstrate improved performance.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:57:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:56:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Xie", "Yujia", ""], ["Dai", "Hanjun", ""], ["Chen", "Minshuo", ""], ["Dai", "Bo", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""], ["Wei", "Wei", ""], ["Pfister", "Tomas", ""]]}, {"id": "2002.06505", "submitter": "Kai Fong Ernest Chong", "authors": "Kai Fong Ernest Chong", "title": "A closer look at the approximation capabilities of neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The universal approximation theorem, in one of its most general versions,\nsays that if we consider only continuous activation functions $\\sigma$, then a\nstandard feedforward neural network with one hidden layer is able to\napproximate any continuous multivariate function $f$ to any given approximation\nthreshold $\\varepsilon$, if and only if $\\sigma$ is non-polynomial. In this\npaper, we give a direct algebraic proof of the theorem. Furthermore we shall\nexplicitly quantify the number of hidden units required for approximation.\nSpecifically, if $X\\subseteq \\mathbb{R}^n$ is compact, then a neural network\nwith $n$ input units, $m$ output units, and a single hidden layer with\n$\\binom{n+d}{d}$ hidden units (independent of $m$ and $\\varepsilon$), can\nuniformly approximate any polynomial function $f:X \\to \\mathbb{R}^m$ whose\ntotal degree is at most $d$ for each of its $m$ coordinate functions. In the\ngeneral case that $f$ is any continuous function, we show there exists some\n$N\\in \\mathcal{O}(\\varepsilon^{-n})$ (independent of $m$), such that $N$ hidden\nunits would suffice to approximate $f$. We also show that this uniform\napproximation property (UAP) still holds even under seemingly strong conditions\nimposed on the weights. We highlight several consequences: (i) For any $\\delta\n> 0$, the UAP still holds if we restrict all non-bias weights $w$ in the last\nlayer to satisfy $|w| < \\delta$. (ii) There exists some $\\lambda>0$ (depending\nonly on $f$ and $\\sigma$), such that the UAP still holds if we restrict all\nnon-bias weights $w$ in the first layer to satisfy $|w|>\\lambda$. (iii) If the\nnon-bias weights in the first layer are \\emph{fixed} and randomly chosen from a\nsuitable range, then the UAP holds with probability $1$.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:58:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chong", "Kai Fong Ernest", ""]]}, {"id": "2002.06506", "submitter": "Yiming Zhang", "authors": "Yiming Zhang, Quan Vuong, Keith W. Ross", "title": "First Order Constrained Optimization in Policy Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, an agent attempts to learn high-performing\nbehaviors through interacting with the environment, such behaviors are often\nquantified in the form of a reward function. However some aspects of\nbehavior-such as ones which are deemed unsafe and to be avoided-are best\ncaptured through constraints. We propose a novel approach called First Order\nConstrained Optimization in Policy Space (FOCOPS) which maximizes an agent's\noverall reward while ensuring the agent satisfies a set of cost constraints.\nUsing data generated from the current policy, FOCOPS first finds the optimal\nupdate policy by solving a constrained optimization problem in the\nnonparameterized policy space. FOCOPS then projects the update policy back into\nthe parametric policy space. Our approach has an approximate upper bound for\nworst-case constraint violation throughout training and is first-order in\nnature therefore simple to implement. We provide empirical evidence that our\nsimple approach achieves better performance on a set of constrained robotics\nlocomotive tasks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:07:17 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 15:35:09 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Zhang", "Yiming", ""], ["Vuong", "Quan", ""], ["Ross", "Keith W.", ""]]}, {"id": "2002.06508", "submitter": "Tongliang Liu", "authors": "Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan\n  Wang, Haifeng Liu, Gang Niu", "title": "Multi-Class Classification from Noisy-Similarity-Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A similarity label indicates whether two instances belong to the same class\nwhile a class label shows the class of the instance. Without class labels, a\nmulti-class classifier could be learned from similarity-labeled pairwise data\nby meta classification learning. However, since the similarity label is less\ninformative than the class label, it is more likely to be noisy. Deep neural\nnetworks can easily remember noisy data, leading to overfitting in\nclassification. In this paper, we propose a method for learning from only\nnoisy-similarity-labeled data. Specifically, to model the noise, we employ a\nnoise transition matrix to bridge the class-posterior probability between clean\nand noisy data. We further estimate the transition matrix from only noisy data\nand build a novel learning system to learn a classifier which can assign\nnoise-free class labels for instances. Moreover, we theoretically justify how\nour proposed method generalizes for learning classifiers. Experimental results\ndemonstrate the superiority of the proposed method over the state-of-the-art\nmethod on benchmark-simulated and real-world noisy-label datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 05:10:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wu", "Songhua", ""], ["Xia", "Xiaobo", ""], ["Liu", "Tongliang", ""], ["Han", "Bo", ""], ["Gong", "Mingming", ""], ["Wang", "Nannan", ""], ["Liu", "Haifeng", ""], ["Niu", "Gang", ""]]}, {"id": "2002.06517", "submitter": "Kyungsu Kim", "authors": "Hyungjun Kim, Kyungsu Kim, Jinseok Kim, Jae-Joon Kim", "title": "BinaryDuo: Reducing Gradient Mismatch in Binary Activation Network by\n  Coupling Binary Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs) have been garnering interest thanks to their\ncompute cost reduction and memory savings. However, BNNs suffer from\nperformance degradation mainly due to the gradient mismatch caused by\nbinarizing activations. Previous works tried to address the gradient mismatch\nproblem by reducing the discrepancy between activation functions used at\nforward pass and its differentiable approximation used at backward pass, which\nis an indirect measure. In this work, we use the gradient of smoothed loss\nfunction to better estimate the gradient mismatch in quantized neural network.\nAnalysis using the gradient mismatch estimator indicates that using higher\nprecision for activation is more effective than modifying the differentiable\napproximation of activation function. Based on the observation, we propose a\nnew training scheme for binary activation networks called BinaryDuo in which\ntwo binary activations are coupled into a ternary activation during training.\nExperimental results show that BinaryDuo outperforms state-of-the-art BNNs on\nvarious benchmarks with the same amount of parameters and computing cost.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 06:18:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Hyungjun", ""], ["Kim", "Kyungsu", ""], ["Kim", "Jinseok", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "2002.06524", "submitter": "Chanwoo Lee", "authors": "Chanwoo Lee, Miaoyan Wang", "title": "Tensor denoising and completion based on ordinal observations", "comments": "35 pages, 6 figures", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning(ICML), 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher-order tensors arise frequently in applications such as neuroimaging,\nrecommendation system, social network analysis, and psychological studies. We\nconsider the problem of low-rank tensor estimation from possibly incomplete,\nordinal-valued observations. Two related problems are studied, one on tensor\ndenoising and the other on tensor completion. We propose a multi-linear\ncumulative link model, develop a rank-constrained M-estimator, and obtain\ntheoretical accuracy guarantees. Our mean squared error bound enjoys a faster\nconvergence rate than previous results, and we show that the proposed estimator\nis minimax optimal under the class of low-rank models. Furthermore, the\nprocedure developed serves as an efficient completion method which guarantees\nconsistent recovery of an order-$K$ $(d,\\ldots,d)$-dimensional low-rank tensor\nusing only $\\tilde{\\mathcal{O}}(Kd)$ noisy, quantized observations. We\ndemonstrate the outperformance of our approach over previous methods on the\ntasks of clustering and collaborative filtering.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:09:56 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 19:01:19 GMT"}, {"version": "v3", "created": "Sun, 13 Dec 2020 00:04:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lee", "Chanwoo", ""], ["Wang", "Miaoyan", ""]]}, {"id": "2002.06525", "submitter": "Kevin Lin", "authors": "Kevin Lin, Ming-Yu Liu, Ming-Ting Sun, Jan Kautz", "title": "Learning to Generate Multiple Style Transfer Outputs for an Input\n  Sentence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text style transfer refers to the task of rephrasing a given text in a\ndifferent style. While various methods have been proposed to advance the state\nof the art, they often assume the transfer output follows a delta distribution,\nand thus their models cannot generate different style transfer results for a\ngiven input text. To address the limitation, we propose a one-to-many text\nstyle transfer framework. In contrast to prior works that learn a one-to-one\nmapping that converts an input sentence to one output sentence, our approach\nlearns a one-to-many mapping that can convert an input sentence to multiple\ndifferent output sentences, while preserving the input content. This is\nachieved by applying adversarial training with a latent decomposition scheme.\nSpecifically, we decompose the latent representation of the input sentence to a\nstyle code that captures the language style variation and a content code that\nencodes the language style-independent content. We then combine the content\ncode with the style code for generating a style transfer output. By combining\nthe same content code with a different style code, we generate a different\nstyle transfer output. Extensive experimental results with comparisons to\nseveral text style transfer approaches on multiple public datasets using a\ndiverse set of performance metrics validate effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:10:45 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lin", "Kevin", ""], ["Liu", "Ming-Yu", ""], ["Sun", "Ming-Ting", ""], ["Kautz", "Jan", ""]]}, {"id": "2002.06532", "submitter": "Disi Ji", "authors": "Disi Ji, Robert L. Logan IV, Padhraic Smyth, Mark Steyvers", "title": "Active Bayesian Assessment for Black-Box Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in machine learning have led to increased deployment of\nblack-box classifiers across a wide variety of applications. In many such\nsituations there is a critical need to both reliably assess the performance of\nthese pre-trained models and to perform this assessment in a label-efficient\nmanner (given that labels may be scarce and costly to collect). In this paper,\nwe introduce an active Bayesian approach for assessment of classifier\nperformance to satisfy the desiderata of both reliability and label-efficiency.\nWe begin by developing inference strategies to quantify uncertainty for common\nassessment metrics such as accuracy, misclassification cost, and calibration\nerror. We then propose a general framework for active Bayesian assessment using\ninferred uncertainty to guide efficient selection of instances for labeling,\nenabling better performance assessment with fewer labels. We demonstrate\nsignificant gains from our proposed active Bayesian approach via a series of\nsystematic empirical experiments assessing the performance of modern neural\nclassifiers (e.g., ResNet and BERT) on several standard image and text\nclassification datasets.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 08:08:42 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 06:36:58 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 16:21:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Ji", "Disi", ""], ["Logan", "Robert L.", "IV"], ["Smyth", "Padhraic", ""], ["Steyvers", "Mark", ""]]}, {"id": "2002.06538", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Distributed Sketching Methods for Privacy Preserving Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study distributed sketching methods for large scale\nregression problems. We leverage multiple randomized sketches for reducing the\nproblem dimensions as well as preserving privacy and improving straggler\nresilience in asynchronous distributed systems. We derive novel approximation\nguarantees for classical sketching methods and analyze the accuracy of\nparameter averaging for distributed sketches. We consider random matrices\nincluding Gaussian, randomized Hadamard, uniform sampling and leverage score\nsampling in the distributed setting. Moreover, we propose a hybrid approach\ncombining sampling and fast random projections for better computational\nefficiency. We illustrate the performance of distributed sketches in a\nserverless computing platform with large scale experiments.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 08:35:48 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 00:36:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.06540", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Distributed Averaging Methods for Randomized Second Order Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed optimization problems where forming the Hessian is\ncomputationally challenging and communication is a significant bottleneck. We\ndevelop unbiased parameter averaging methods for randomized second order\noptimization that employ sampling and sketching of the Hessian. Existing works\ndo not take the bias of the estimators into consideration, which limits their\napplication to massively parallel computation. We provide closed-form formulas\nfor regularization parameters and step sizes that provably minimize the bias\nfor sketched Newton directions. We also extend the framework of second order\naveraging methods to introduce an unbiased distributed optimization framework\nfor heterogeneous computing systems with varying worker resources.\nAdditionally, we demonstrate the implications of our theoretical findings via\nlarge scale experiments performed on a serverless computing platform.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:01:18 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.06541", "submitter": "Liu Ziyin", "authors": "Liu Ziyin, Blair Chen, Ru Wang, Paul Pu Liang, Ruslan Salakhutdinov,\n  Louis-Philippe Morency, Masahito Ueda", "title": "Learning Not to Learn in the Presence of Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the presence of label noise is a challenging yet important task:\nit is crucial to design models that are robust in the presence of mislabeled\ndatasets. In this paper, we discover that a new class of loss functions called\nthe gambler's loss provides strong robustness to label noise across various\nlevels of corruption. We show that training with this loss function encourages\nthe model to \"abstain\" from learning on the data points with noisy labels,\nresulting in a simple and effective method to improve robustness and\ngeneralization. In addition, we propose two practical extensions of the method:\n1) an analytical early stopping criterion to approximately stop training before\nthe memorization of noisy labels, as well as 2) a heuristic for setting\nhyperparameters which do not require knowledge of the noise corruption rate. We\ndemonstrate the effectiveness of our method by achieving strong results across\nthree image and text classification tasks as compared to existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:12:27 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Ziyin", "Liu", ""], ["Chen", "Blair", ""], ["Wang", "Ru", ""], ["Liang", "Paul Pu", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Ueda", "Masahito", ""]]}, {"id": "2002.06544", "submitter": "Hrituraj Singh", "authors": "Hrituraj Singh, Milan Aggrawal, Balaji Krishnamurthy", "title": "Exploring Neural Models for Parsing Natural Language into First-Order\n  Logic", "comments": "11 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic parsing is the task of obtaining machine-interpretable\nrepresentations from natural language text. We consider one such formal\nrepresentation - First-Order Logic (FOL) and explore the capability of neural\nmodels in parsing English sentences to FOL. We model FOL parsing as a sequence\nto sequence mapping task where given a natural language sentence, it is encoded\ninto an intermediate representation using an LSTM followed by a decoder which\nsequentially generates the predicates in the corresponding FOL formula. We\nimprove the standard encoder-decoder model by introducing a variable alignment\nmechanism that enables it to align variables across predicates in the predicted\nFOL. We further show the effectiveness of predicting the category of FOL entity\n- Unary, Binary, Variables and Scoped Entities, at each decoder step as an\nauxiliary task on improving the consistency of generated FOL. We perform\nrigorous evaluations and extensive ablations. We also aim to release our code\nas well as large scale FOL dataset along with models to aid further research in\nlogic-based parsing and inference in NLP.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 09:22:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Singh", "Hrituraj", ""], ["Aggrawal", "Milan", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "2002.06557", "submitter": "Gad Zalcberg", "authors": "Gad Zalcberg and Ami Wiesel", "title": "Fair Principal Component Analysis and Filter Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Fair Principal Component Analysis (FPCA) and search for a low\ndimensional subspace that spans multiple target vectors in a fair manner. FPCA\nis defined as a non-concave maximization of the worst projected target norm\nwithin a given set. The problem arises in filter design in signal processing,\nand when incorporating fairness into dimensionality reduction schemes. The\nstate of the art approach to FPCA is via semidefinite relaxation and involves a\npolynomial yet computationally expensive optimization. To allow scalability, we\npropose to address FPCA using naive sub-gradient descent. We analyze the\nlandscape of the underlying optimization in the case of orthogonal targets. We\nprove that the landscape is benign and that all local minima are globally\noptimal. Interestingly, the SDR approach leads to sub-optimal solutions in this\nsimple case. Finally, we discuss the equivalence between orthogonal FPCA and\nthe design of normalized tight frames.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 11:42:52 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:10:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Zalcberg", "Gad", ""], ["Wiesel", "Ami", ""]]}, {"id": "2002.06561", "submitter": "Li Shen", "authors": "Enneng Yang, Xin Xin, Li Shen and Guibing Guo", "title": "Generalized Embedding Machines for Recommender Systems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization machine (FM) is an effective model for feature-based\nrecommendation which utilizes inner product to capture second-order feature\ninteractions. However, one of the major drawbacks of FM is that it couldn't\ncapture complex high-order interaction signals. A common solution is to change\nthe interaction function, such as stacking deep neural networks on the top of\nFM. In this work, we propose an alternative approach to model high-order\ninteraction signals in the embedding level, namely Generalized Embedding\nMachine (GEM). The embedding used in GEM encodes not only the information from\nthe feature itself but also the information from other correlated features.\nUnder such situation, the embedding becomes high-order. Then we can incorporate\nGEM with FM and even its advanced variants to perform feature interactions.\nMore specifically, in this paper we utilize graph convolution networks (GCN) to\ngenerate high-order embeddings. We integrate GEM with several FM-based models\nand conduct extensive experiments on two real-world datasets. The results\ndemonstrate significant improvement of GEM over corresponding baselines.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 12:03:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Enneng", ""], ["Xin", "Xin", ""], ["Shen", "Li", ""], ["Guo", "Guibing", ""]]}, {"id": "2002.06592", "submitter": "Juba Ziani", "authors": "Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani", "title": "Pipeline Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \\emph{pipeline intervention} problem, defined by a layered\ndirected acyclic graph and a set of stochastic matrices governing transitions\nbetween successive layers. The graph is a stylized model for how people from\ndifferent populations are presented opportunities, eventually leading to some\nreward. In our model, individuals are born into an initial position (i.e. some\nnode in the first layer of the graph) according to a fixed probability\ndistribution, and then stochastically progress through the graph according to\nthe transition matrices, until they reach a node in the final layer of the\ngraph; each node in the final layer has a \\emph{reward} associated with it. The\npipeline intervention problem asks how to best make costly changes to the\ntransition matrices governing people's stochastic transitions through the\ngraph, subject to a budget constraint. We consider two objectives: social\nwelfare maximization, and a fairness-motivated maximin objective that seeks to\nmaximize the value to the population (starting node) with the \\emph{least}\nexpected value. We consider two variants of the maximin objective that turn out\nto be distinct, depending on whether we demand a deterministic solution or\nallow randomization. For each objective, we give an efficient approximation\nalgorithm (an additive FPTAS) for constant width networks. We also tightly\ncharacterize the \"price of fairness\" in our setting: the ratio between the\nhighest achievable social welfare and the highest social welfare consistent\nwith a maximin optimal solution. Finally we show that for polynomial width\nnetworks, even approximating the maximin objective to any constant factor is NP\nhard, even for networks with constant depth. This shows that the restriction on\nthe width in our positive results is essential.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 15:28:29 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 19:49:29 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Arunachaleswaran", "Eshwar Ram", ""], ["Kannan", "Sampath", ""], ["Roth", "Aaron", ""], ["Ziani", "Juba", ""]]}, {"id": "2002.06595", "submitter": "Jayneel Parekh", "authors": "Jayneel Parekh, Preeti Rao, Yi-Hsuan Yang", "title": "Speech-to-Singing Conversion in an Encoder-Decoder Framework", "comments": "Accepted at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper our goal is to convert a set of spoken lines into sung ones.\nUnlike previous signal processing based methods, we take a learning based\napproach to the problem. This allows us to automatically model various aspects\nof this transformation, thus overcoming dependence on specific inputs such as\nhigh quality singing templates or phoneme-score synchronization information.\nSpecifically, we propose an encoder--decoder framework for our task. Given\ntime-frequency representations of speech and a target melody contour, we learn\nencodings that enable us to synthesize singing that preserves the linguistic\ncontent and timbre of the speaker while adhering to the target melody. We also\npropose a multi-task learning based objective to improve lyric intelligibility.\nWe present a quantitative and qualitative analysis of our framework.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 15:33:41 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Parekh", "Jayneel", ""], ["Rao", "Preeti", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2002.06604", "submitter": "Yeongmin Ko", "authors": "Yeongmin Ko, Younkwan Lee, Shoaib Azam, Farzeen Munir, Moongu Jeon,\n  and Witold Pedrycz", "title": "Key Points Estimation and Point Instance Segmentation Approach for Lane\n  Detection", "comments": "Submitted to \"IEEE Transactions on Intelligent Transportation\n  Systems\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perception techniques for autonomous driving should be adaptive to various\nenvironments. In the case of traffic line detection, an essential perception\nmodule, many condition should be considered, such as number of traffic lines\nand computing power of the target system. To address these problems, in this\npaper, we propose a traffic line detection method called Point Instance Network\n(PINet); the method is based on the key points estimation and instance\nsegmentation approach. The PINet includes several stacked hourglass networks\nthat are trained simultaneously. Therefore the size of the trained models can\nbe chosen according to the computing power of the target environment. We cast a\nclustering problem of the predicted key points as an instance segmentation\nproblem; the PINet can be trained regardless of the number of the traffic\nlines. The PINet achieves competitive accuracy and false positive on the\nTuSimple and Culane datasets, popular public datasets for lane detection. Our\ncode is available at https://github.com/koyeongmin/PINet_new\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 15:51:30 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 18:05:40 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 05:56:37 GMT"}, {"version": "v4", "created": "Mon, 14 Sep 2020 03:22:44 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ko", "Yeongmin", ""], ["Lee", "Younkwan", ""], ["Azam", "Shoaib", ""], ["Munir", "Farzeen", ""], ["Jeon", "Moongu", ""], ["Pedrycz", "Witold", ""]]}, {"id": "2002.06610", "submitter": "Jae Myung Kim", "authors": "Jae Myung Kim, Hyungjin Kim, Chanwoo Park, and Jungwoo Lee", "title": "REST: Performance Improvement of a Black Box Model via RL-based Spatial\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks (DNN) have become a highly active area\nof research, and shown remarkable achievements on a variety of computer vision\ntasks. DNNs, however, are known to often make overconfident yet incorrect\npredictions on out-of-distribution samples, which can be a major obstacle to\nreal-world deployments because the training dataset is always limited compared\nto diverse real-world samples. Thus, it is fundamental to provide guarantees of\nrobustness to the distribution shift between training and test time when we\nconstruct DNN models in practice. Moreover, in many cases, the deep learning\nmodels are deployed as black boxes and the performance has been already\noptimized for a training dataset, thus changing the black box itself can lead\nto performance degradation. We here study the robustness to the geometric\ntransformations in a specific condition where the black-box image classifier is\ngiven. We propose an additional learner, \\emph{REinforcement Spatial Transform\nlearner (REST)}, that transforms the warped input data into samples regarded as\nin-distribution by the black-box models. Our work aims to improve the\nrobustness by adding a REST module in front of any black boxes and training\nonly the REST module without retraining the original black box model in an\nend-to-end manner, i.e. we try to convert the real-world data into training\ndistribution which the performance of the black-box model is best suited for.\nWe use a confidence score that is obtained from the black-box model to\ndetermine whether the transformed input is drawn from in-distribution. We\nempirically show that our method has an advantage in generalization to\ngeometric transformations and sample efficiency.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:15:59 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kim", "Jae Myung", ""], ["Kim", "Hyungjin", ""], ["Park", "Chanwoo", ""], ["Lee", "Jungwoo", ""]]}, {"id": "2002.06611", "submitter": "Dhasarathy Parthasarathy", "authors": "Dhasarathy Parthasarathy, Karl B\\\"ackstr\\\"om, Jens Henriksson and\n  S\\'olr\\'un Einarsd\\'ottir", "title": "Controlled time series generation for automotive software-in-the-loop\n  testing using GANs", "comments": "Preprint of paper accepted at The Second IEEE International\n  Conference on Artificial Intelligence Testing, April 13-16, 2020, Oxford, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing automotive mechatronic systems partly uses the software-in-the-loop\napproach, where systematically covering inputs of the system-under-test remains\na major challenge. In current practice, there are two major techniques of input\nstimulation. One approach is to craft input sequences which eases control and\nfeedback of the test process but falls short of exposing the system to\nrealistic scenarios. The other is to replay sequences recorded from field\noperations which accounts for reality but requires collecting a well-labeled\ndataset of sufficient capacity for widespread use, which is expensive. This\nwork applies the well-known unsupervised learning framework of Generative\nAdversarial Networks (GAN) to learn an unlabeled dataset of recorded in-vehicle\nsignals and uses it for generation of synthetic input stimuli. Additionally, a\nmetric-based linear interpolation algorithm is demonstrated, which guarantees\nthat generated stimuli follow a customizable similarity relationship with\nspecified references. This combination of techniques enables controlled\ngeneration of a rich range of meaningful and realistic input patterns,\nimproving virtual test coverage and reducing the need for expensive field\ntests.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:19:29 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 10:52:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Parthasarathy", "Dhasarathy", ""], ["B\u00e4ckstr\u00f6m", "Karl", ""], ["Henriksson", "Jens", ""], ["Einarsd\u00f3ttir", "S\u00f3lr\u00fan", ""]]}, {"id": "2002.06612", "submitter": "Zahra Abbasiantaeb", "authors": "Zahra Abbasiantaeb and Saeedeh Momtazi", "title": "Text-based Question Answering from Information Retrieval and Deep Neural\n  Network Perspectives: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based Question Answering (QA) is a challenging task which aims at\nfinding short concrete answers for users' questions. This line of research has\nbeen widely studied with information retrieval techniques and has received\nincreasing attention in recent years by considering deep neural network\napproaches. Deep learning approaches, which are the main focus of this paper,\nprovide a powerful technique to learn multiple layers of representations and\ninteraction between questions and texts. In this paper, we provide a\ncomprehensive overview of different models proposed for the QA task, including\nboth traditional information retrieval perspective, and more recent deep neural\nnetwork perspective. We also introduce well-known datasets for the task and\npresent available results from the literature to have a comparison between\ndifferent techniques.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:24:39 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:27:09 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Abbasiantaeb", "Zahra", ""], ["Momtazi", "Saeedeh", ""]]}, {"id": "2002.06622", "submitter": "Zhouxing Shi", "authors": "Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh", "title": "Robustness Verification for Transformers", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness verification that aims to formally certify the prediction behavior\nof neural networks has become an important tool for understanding model\nbehavior and obtaining safety guarantees. However, previous methods can usually\nonly handle neural networks with relatively simple architectures. In this\npaper, we consider the robustness verification problem for Transformers.\nTransformers have complex self-attention layers that pose many challenges for\nverification, including cross-nonlinearity and cross-position dependency, which\nhave not been discussed in previous works. We resolve these challenges and\ndevelop the first robustness verification algorithm for Transformers. The\ncertified robustness bounds computed by our method are significantly tighter\nthan those by naive Interval Bound Propagation. These bounds also shed light on\ninterpreting Transformers as they consistently reflect the importance of\ndifferent words in sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 17:16:31 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 12:36:47 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Shi", "Zhouxing", ""], ["Zhang", "Huan", ""], ["Chang", "Kai-Wei", ""], ["Huang", "Minlie", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.06626", "submitter": "Hubert Lin", "authors": "Hubert Lin, Paul Upchurch, Kavita Bala", "title": "Block Annotation: Better Image Annotation for Semantic Segmentation with\n  Sub-Image Decomposition", "comments": "ICCV 2019; http://www.cs.cornell.edu/~hubert/block_annotation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image datasets with high-quality pixel-level annotations are valuable for\nsemantic segmentation: labelling every pixel in an image ensures that rare\nclasses and small objects are annotated. However, full-image annotations are\nexpensive, with experts spending up to 90 minutes per image. We propose block\nsub-image annotation as a replacement for full-image annotation. Despite the\nattention cost of frequent task switching, we find that block annotations can\nbe crowdsourced at higher quality compared to full-image annotation with equal\nmonetary cost using existing annotation tools developed for full-image\nannotation. Surprisingly, we find that 50% pixels annotated with blocks allows\nsemantic segmentation to achieve equivalent performance to 100% pixels\nannotated. Furthermore, as little as 12% of pixels annotated allows performance\nas high as 98% of the performance with dense annotation. In weakly-supervised\nsettings, block annotation outperforms existing methods by 3-4% (absolute)\ngiven equivalent annotation time. To recover the necessary global structure for\napplications such as characterizing spatial context and affordance\nrelationships, we propose an effective method to inpaint block-annotated images\nwith high-quality labels without additional human effort. As such, fewer\nannotations can also be used for these applications compared to full-image\nannotation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 17:42:37 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lin", "Hubert", ""], ["Upchurch", "Paul", ""], ["Bala", "Kavita", ""]]}, {"id": "2002.06650", "submitter": "Alejandro Flores Velazco", "authors": "Alejandro Flores-Velazco, David M. Mount", "title": "Coresets for the Nearest-Neighbor Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a training set $P$ of labeled points, the nearest-neighbor rule\npredicts the class of an unlabeled query point as the label of its closest\npoint in the set. To improve the time and space complexity of classification, a\nnatural question is how to reduce the training set without significantly\naffecting the accuracy of the nearest-neighbor rule. Nearest-neighbor\ncondensation deals with finding a subset $R \\subseteq P$ such that for every\npoint $p \\in P$, $p$'s nearest-neighbor in $R$ has the same label as $p$. This\nrelates to the concept of coresets, which can be broadly defined as subsets of\nthe set, such that an exact result on the coreset corresponds to an approximate\nresult on the original set. However, the guarantees of a coreset hold for any\nquery point, and not only for the points of the training set.\n  This paper introduces the concept of coresets for nearest-neighbor\nclassification. We extend existing criteria used for condensation, and prove\nsufficient conditions to correctly classify any query point when using these\nsubsets. Additionally, we prove that finding such subsets of minimum\ncardinality is NP-hard, and propose quadratic-time approximation algorithms\nwith provable upper-bounds on the size of their selected subsets. Moreover, we\nshow how to improve one of these algorithms to have subquadratic runtime, being\nthe first of this kind for condensation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 19:00:48 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 21:07:11 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 19:14:41 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Flores-Velazco", "Alejandro", ""], ["Mount", "David M.", ""]]}, {"id": "2002.06652", "submitter": "Bin Wang", "authors": "Bin Wang, C.-C. Jay Kuo", "title": "SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentence embedding is an important research topic in natural language\nprocessing (NLP) since it can transfer knowledge to downstream tasks.\nMeanwhile, a contextualized word representation, called BERT, achieves the\nstate-of-the-art performance in quite a few NLP tasks. Yet, it is an open\nproblem to generate a high quality sentence representation from BERT-based word\nmodels. It was shown in previous study that different layers of BERT capture\ndifferent linguistic properties. This allows us to fusion information across\nlayers to find better sentence representation. In this work, we study the\nlayer-wise pattern of the word representation of deep contextualized models.\nThen, we propose a new sentence embedding method by dissecting BERT-based word\nmodels through geometric analysis of the space spanned by the word\nrepresentation. It is called the SBERT-WK method. No further training is\nrequired in SBERT-WK. We evaluate SBERT-WK on semantic textual similarity and\ndownstream supervised tasks. Furthermore, ten sentence-level probing tasks are\npresented for detailed linguistic analysis. Experiments show that SBERT-WK\nachieves the state-of-the-art performance. Our codes are publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 19:02:52 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:39:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Bin", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2002.06659", "submitter": "Yanchao Sun", "authors": "Yanchao Sun, Xiangyu Yin, Furong Huang", "title": "TempLe: Learning Template of Transitions for Sample Efficient Multi-task\n  RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge among various environments is important to efficiently\nlearn multiple tasks online. Most existing methods directly use the previously\nlearned models or previously learned optimal policies to learn new tasks.\nHowever, these methods may be inefficient when the underlying models or optimal\npolicies are substantially different across tasks. In this paper, we propose\nTemplate Learning (TempLe), the first PAC-MDP method for multi-task\nreinforcement learning that could be applied to tasks with varying state/action\nspace. TempLe generates transition dynamics templates, abstractions of the\ntransition dynamics across tasks, to gain sample efficiency by extracting\nsimilarities between tasks even when their underlying models or optimal\npolicies have limited commonalities. We present two algorithms for an \"online\"\nand a \"finite-model\" setting respectively. We prove that our proposed TempLe\nalgorithms achieve much lower sample complexity than single-task learners or\nstate-of-the-art multi-task methods. We show via systematically designed\nexperiments that our TempLe method universally outperforms the state-of-the-art\nmulti-task methods (PAC-MDP or not) in various settings and regimes.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 19:46:49 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 17:14:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Sun", "Yanchao", ""], ["Yin", "Xiangyu", ""], ["Huang", "Furong", ""]]}, {"id": "2002.06665", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Michael Granitzer", "title": "Predicting event attendance exploring social influence", "comments": null, "journal-ref": null, "doi": "10.1145/3297280.3297622", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The problem of predicting people's participation in real-world events has\nreceived considerable attention as it offers valuable insights for human\nbehavior analysis and event-related advertisement. Today social networks (e.g.\nTwitter) widely reflect large popular events where people discuss their\ninterest with friends. Event participants usually stimulate friends to join the\nevent which propagates a social influence in the network. In this paper, we\npropose to model the social influence of friends on event attendance. We\nconsider non-geotagged posts besides structures of social groups to infer\nusers' attendance. To leverage the information on network topology we apply\nsome of recent graph embedding techniques such as node2vec, HARP and Poincar`e.\nWe describe the approach followed to design the feature space and feed it to a\nneural network. The performance evaluation is conducted using two large music\nfestivals datasets, namely the VFestival and Creamfields. The experimental\nresults show that our classifier outperforms the state-of-the-art baseline with\n89% accuracy observed for the VFestival dataset.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:03:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.06668", "submitter": "Yi Zhang", "authors": "Yi Zhang, Orestis Plevrakis, Simon S. Du, Xingguo Li, Zhao Song,\n  Sanjeev Arora", "title": "Over-parameterized Adversarial Training: An Analysis Overcoming the\n  Curse of Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a popular method to give neural nets robustness\nagainst adversarial perturbations. In practice adversarial training leads to\nlow robust training loss. However, a rigorous explanation for why this happens\nunder natural conditions is still missing. Recently a convergence theory for\nstandard (non-adversarial) supervised training was developed by various groups\nfor {\\em very overparametrized} nets. It is unclear how to extend these results\nto adversarial training because of the min-max objective. Recently, a first\nstep towards this direction was made by Gao et al. using tools from online\nlearning, but they require the width of the net to be \\emph{exponential} in\ninput dimension $d$, and with an unnatural activation function. Our work proves\nconvergence to low robust training loss for \\emph{polynomial} width instead of\nexponential, under natural assumptions and with the ReLU activation. Key\nelement of our proof is showing that ReLU networks near initialization can\napproximate the step function, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:13:43 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 03:10:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Yi", ""], ["Plevrakis", "Orestis", ""], ["Du", "Simon S.", ""], ["Li", "Xingguo", ""], ["Song", "Zhao", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2002.06670", "submitter": "Daniel Ranti", "authors": "Daniel Ranti, Katie Hanss, Shan Zhao, Varun Arvind, Joseph Titano,\n  Anthony Costa, Eric Oermann", "title": "The Utility of General Domain Transfer Learning for Medical Language\n  Tasks", "comments": "8 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to analyze the efficacy of transfer learning\ntechniques and transformer-based models as applied to medical natural language\nprocessing (NLP) tasks, specifically radiological text classification. We used\n1,977 labeled head CT reports, from a corpus of 96,303 total reports, to\nevaluate the efficacy of pretraining using general domain corpora and a\ncombined general and medical domain corpus with a bidirectional representations\nfrom transformers (BERT) model for the purpose of radiological text\nclassification. Model performance was benchmarked to a logistic regression\nusing bag-of-words vectorization and a long short-term memory (LSTM)\nmulti-label multi-class classification model, and compared to the published\nliterature in medical text classification. The BERT models using either set of\npretrained checkpoints outperformed the logistic regression model, achieving\nsample-weighted average F1-scores of 0.87 and 0.87 for the general domain model\nand the combined general and biomedical-domain model. General text transfer\nlearning may be a viable technique to generate state-of-the-art results within\nmedical NLP tasks on radiological corpora, outperforming other deep models such\nas LSTMs. The efficacy of pretraining and transformer-based models could serve\nto facilitate the creation of groundbreaking NLP models in the uniquely\nchallenging data environment of medical text.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:20:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ranti", "Daniel", ""], ["Hanss", "Katie", ""], ["Zhao", "Shan", ""], ["Arvind", "Varun", ""], ["Titano", "Joseph", ""], ["Costa", "Anthony", ""], ["Oermann", "Eric", ""]]}, {"id": "2002.06673", "submitter": "Celestine Mendler-D\\\"unner", "authors": "Juan C. Perdomo, Tijana Zrnic, Celestine Mendler-D\\\"unner, Moritz\n  Hardt", "title": "Performative Prediction", "comments": "published at ICML'20; fixed some typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When predictions support decisions they may influence the outcome they aim to\npredict. We call such predictions performative; the prediction influences the\ntarget. Performativity is a well-studied phenomenon in policy-making that has\nso far been neglected in supervised learning. When ignored, performativity\nsurfaces as undesirable distribution shift, routinely addressed with\nretraining.\n  We develop a risk minimization framework for performative prediction bringing\ntogether concepts from statistics, game theory, and causality. A conceptual\nnovelty is an equilibrium notion we call performative stability. Performative\nstability implies that the predictions are calibrated not against past\noutcomes, but against the future outcomes that manifest from acting on the\nprediction. Our main results are necessary and sufficient conditions for the\nconvergence of retraining to a performatively stable point of nearly minimal\nloss.\n  In full generality, performative prediction strictly subsumes the setting\nknown as strategic classification. We thus also give the first sufficient\nconditions for retraining to overcome strategic feedback effects.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 20:29:42 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 02:36:30 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 16:19:45 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 22:07:40 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Perdomo", "Juan C.", ""], ["Zrnic", "Tijana", ""], ["Mendler-D\u00fcnner", "Celestine", ""], ["Hardt", "Moritz", ""]]}, {"id": "2002.06685", "submitter": "Fatemeh Salehi Rizi", "authors": "Fatemeh Salehi Rizi, Michael Granitzer, Konstantin Ziegler", "title": "Global and Local Feature Learning for Ego-Network Analysis", "comments": null, "journal-ref": null, "doi": "10.1109/DEXA.2017.36", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In an ego-network, an individual (ego) organizes its friends (alters) in\ndifferent groups (social circles). This social network can be efficiently\nanalyzed after learning representations of the ego and its alters in a\nlow-dimensional, real vector space. These representations are then easily\nexploited via statistical models for tasks such as social circle detection and\nprediction. Recent advances in language modeling via deep learning have\ninspired new methods for learning network representations. These methods can\ncapture the global structure of networks. In this paper, we evolve these\ntechniques to also encode the local structure of neighborhoods. Therefore, our\nlocal representations capture network features that are hidden in the global\nrepresentation of large networks. We show that the task of social circle\nprediction benefits from a combination of global and local features generated\nby our technique.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 21:35:04 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""], ["Ziegler", "Konstantin", ""]]}, {"id": "2002.06694", "submitter": "Yuqian Zhang", "authors": "Wei Qian, Yuqian Zhang, Yudong Chen", "title": "Structures of Spurious Local Minima in $k$-means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-means clustering is a fundamental problem in unsupervised learning. The\nproblem concerns finding a partition of the data points into $k$ clusters such\nthat the within-cluster variation is minimized. Despite its importance and wide\napplicability, a theoretical understanding of the $k$-means problem has not\nbeen completely satisfactory. Existing algorithms with theoretical performance\nguarantees often rely on sophisticated (sometimes artificial) algorithmic\ntechniques and restricted assumptions on the data. The main challenge lies in\nthe non-convex nature of the problem; in particular, there exist additional\nlocal solutions other than the global optimum. Moreover, the simplest and most\npopular algorithm for $k$-means, namely Lloyd's algorithm, generally converges\nto such spurious local solutions both in theory and in practice.\n  In this paper, we approach the $k$-means problem from a new perspective, by\ninvestigating the structures of these spurious local solutions under a\nprobabilistic generative model with $k$ ground truth clusters. As soon as\n$k=3$, spurious local minima provably exist, even for well-separated and\nbalanced clusters. One such local minimum puts two centers at one true cluster,\nand the third center in the middle of the other two true clusters. For general\n$k$, one local minimum puts multiple centers at a true cluster, and one center\nin the middle of multiple true clusters. Perhaps surprisingly, we prove that\nthis is essentially the only type of spurious local minima under a separation\ncondition. Our results pertain to the $k$-means formulation for mixtures of\nGaussians or bounded distributions. Our theoretical results corroborate\nexisting empirical observations and provide justification for several improved\nalgorithms for $k$-means clustering.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 22:15:03 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 21:19:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Qian", "Wei", ""], ["Zhang", "Yuqian", ""], ["Chen", "Yudong", ""]]}, {"id": "2002.06701", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "Gaussian Smoothen Semantic Features (GSSF) -- Exploring the Linguistic\n  Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we have introduced Gaussian Smoothen Semantic Features (GSSF)\nfor Better Semantic Selection for Indian regional language-based image\ncaptioning and introduced a procedure where we used the existing translation\nand English crowd-sourced sentences for training. We have shown that this\narchitecture is a promising alternative source, where there is a crunch in\nresources. Our main contribution of this work is the development of deep\nlearning architectures for the Bengali language (is the fifth widely spoken\nlanguage in the world) with a completely different grammar and language\nattributes. We have shown that these are working well for complex applications\nlike language generation from image contexts and can diversify the\nrepresentation through introducing constraints, more extensive features, and\nunique feature spaces. We also established that we could achieve absolute\nprecision and diversity when we use smoothened semantic tensor with the\ntraditional LSTM and feature decomposition networks. With better learning\narchitecture, we succeeded in establishing an automated algorithm and\nassessment procedure that can help in the evaluation of competent applications\nwithout the requirement for expertise and human intervention.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:03:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2002.06703", "submitter": "Guy Davidson", "authors": "Guy Davidson, Brenden M. Lake", "title": "Investigating Simple Object Representations in Model-Free Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the benefits of augmenting state-of-the-art model-free deep\nreinforcement algorithms with simple object representations. Following the\nFrostbite challenge posited by Lake et al. (2017), we identify object\nrepresentations as a critical cognitive capacity lacking from current\nreinforcement learning agents. We discover that providing the Rainbow model\n(Hessel et al.,2018) with simple, feature-engineered object representations\nsubstantially boosts its performance on the Frostbite game from Atari 2600. We\nthen analyze the relative contributions of the representations of different\ntypes of objects, identify environment states where these representations are\nmost impactful, and examine how these representations aid in generalizing to\nnovel situations.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:10:41 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 22:00:30 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Davidson", "Guy", ""], ["Lake", "Brenden M.", ""]]}, {"id": "2002.06707", "submitter": "Jonas K\\\"ohler", "authors": "Hao Wu, Jonas K\\\"ohler and Frank No\\'e", "title": "Stochastic Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sampling of probability distributions specified up to a normalization\nconstant is an important problem in both machine learning and statistical\nmechanics. While classical stochastic sampling methods such as Markov Chain\nMonte Carlo (MCMC) or Langevin Dynamics (LD) can suffer from slow mixing times\nthere is a growing interest in using normalizing flows in order to learn the\ntransformation of a simple prior distribution to the given target distribution.\nHere we propose a generalized and combined approach to sample target densities:\nStochastic Normalizing Flows (SNF) -- an arbitrary sequence of deterministic\ninvertible functions and stochastic sampling blocks. We show that stochasticity\novercomes expressivity limitations of normalizing flows resulting from the\ninvertibility constraint, whereas trainable transformations between sampling\nsteps improve efficiency of pure MCMC/LD along the flow. By invoking ideas from\nnon-equilibrium statistical mechanics we derive an efficient training procedure\nby which both the sampler's and the flow's parameters can be optimized\nend-to-end, and by which we can compute exact importance weights without having\nto marginalize out the randomness of the stochastic blocks. We illustrate the\nrepresentational power, sampling efficiency and asymptotic correctness of SNFs\non several benchmarks including applications to sampling molecular systems in\nequilibrium.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 23:29:32 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 15:36:31 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 11:28:47 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Wu", "Hao", ""], ["K\u00f6hler", "Jonas", ""], ["No\u00e9", "Frank", ""]]}, {"id": "2002.06715", "submitter": "Yeming Wen", "authors": "Yeming Wen, Dustin Tran, Jimmy Ba", "title": "BatchEnsemble: An Alternative Approach to Efficient Ensemble and\n  Lifelong Learning", "comments": null, "journal-ref": "Eighth International Conference on Learning Representations (ICLR\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles, where multiple neural networks are trained individually and their\npredictions are averaged, have been shown to be widely successful for improving\nboth the accuracy and predictive uncertainty of single neural networks.\nHowever, an ensemble's cost for both training and testing increases linearly\nwith the number of networks, which quickly becomes untenable.\n  In this paper, we propose BatchEnsemble, an ensemble method whose\ncomputational and memory costs are significantly lower than typical ensembles.\nBatchEnsemble achieves this by defining each weight matrix to be the Hadamard\nproduct of a shared weight among all ensemble members and a rank-one matrix per\nmember. Unlike ensembles, BatchEnsemble is not only parallelizable across\ndevices, where one device trains one member, but also parallelizable within a\ndevice, where multiple ensemble members are updated simultaneously for a given\nmini-batch. Across CIFAR-10, CIFAR-100, WMT14 EN-DE/EN-FR translation, and\nout-of-distribution tasks, BatchEnsemble yields competitive accuracy and\nuncertainties as typical ensembles; the speedup at test time is 3X and memory\nreduction is 3X at an ensemble of size 4. We also apply BatchEnsemble to\nlifelong learning, where on Split-CIFAR-100, BatchEnsemble yields comparable\nperformance to progressive neural networks while having a much lower\ncomputational and memory costs. We further show that BatchEnsemble can easily\nscale up to lifelong learning on Split-ImageNet which involves 100 sequential\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:00:59 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 03:38:44 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wen", "Yeming", ""], ["Tran", "Dustin", ""], ["Ba", "Jimmy", ""]]}, {"id": "2002.06716", "submitter": "Michael Mahoney", "authors": "Charles H. Martin, Tongsu (Serena) Peng, and Michael W. Mahoney", "title": "Predicting trends in the quality of state-of-the-art neural networks\n  without access to training or testing data", "comments": "35 pages, 8 tables, 17 figures. To appear in Nature Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, one works with neural network models trained by someone\nelse. For such pretrained models, one may not have access to training data or\ntest data. Moreover, one may not know details about the model, e.g., the\nspecifics of the training data, the loss function, the hyperparameter values,\netc. Given one or many pretrained models, it is a challenge to say anything\nabout the expected performance or quality of the models. Here, we address this\nchallenge by providing a detailed meta-analysis of hundreds of\npublicly-available pretrained models. We examine norm based capacity control\nmetrics as well as power law based metrics from the recently-developed Theory\nof Heavy-Tailed Self Regularization. We find that norm based metrics correlate\nwell with reported test accuracies for well-trained models, but that they often\ncannot distinguish well-trained versus poorly-trained models. We also find that\npower law based metrics can do much better -- quantitatively better at\ndiscriminating among series of well-trained models with a given architecture;\nand qualitatively better at discriminating well-trained versus poorly-trained\nmodels. These methods can be used to identify when a pretrained neural network\nhas problems that cannot be detected simply by examining training/test\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:01:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 17:21:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Martin", "Charles H.", "", "Serena"], ["Tongsu", "", "", "Serena"], ["Peng", "", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.06723", "submitter": "Zhenyu Shou", "authors": "Zhenyu Shou, Xuan Di", "title": "Reward Design for Driver Repositioning Using Multi-Agent Reinforcement\n  Learning", "comments": "28 pages, 20 figures, published in Transportation Research Part C 119\n  (2020) 102738", "journal-ref": null, "doi": "10.1016/j.trc.2020.102738", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large portion of passenger requests is reportedly unserviced, partially due\nto vacant for-hire drivers' cruising behavior during the passenger seeking\nprocess. This paper aims to model the multi-driver repositioning task through a\nmean field multi-agent reinforcement learning (MARL) approach that captures\ncompetition among multiple agents. Because the direct application of MARL to\nthe multi-driver system under a given reward mechanism will likely yield a\nsuboptimal equilibrium due to the selfishness of drivers, this study proposes a\nreward design scheme with which a more desired equilibrium can be reached. To\neffectively solve the bilevel optimization problem with upper level as the\nreward design and the lower level as a multi-agent system, a Bayesian\noptimization (BO) algorithm is adopted to speed up the learning process. We\nthen apply the bilevel optimization model to two case studies, namely,\ne-hailing driver repositioning under service charge and multiclass taxi driver\nrepositioning under NYC congestion pricing. In the first case study, the model\nis validated by the agreement between the derived optimal control from BO and\nthat from an analytical solution. With a simple piecewise linear service\ncharge, the objective of the e-hailing platform can be increased by 8.4%. In\nthe second case study, an optimal toll charge of $5.1 is solved using BO, which\nimproves the objective of city planners by 7.9%, compared to that without any\ntoll charge. Under this optimal toll charge, the number of taxis in the NYC\ncentral business district is decreased, indicating a better traffic condition,\nwithout substantially increasing the crowdedness of the subway system.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:10:58 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 17:51:40 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2020 16:48:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Shou", "Zhenyu", ""], ["Di", "Xuan", ""]]}, {"id": "2002.06734", "submitter": "Abdelrahman Zayed", "authors": "Abdelrahman Zayed, Guy Cloutier and Hassan Rivaz", "title": "Automatic Frame Selection using CNN in Ultrasound Elastography", "comments": "2020 42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound elastography is used to estimate the mechanical properties of the\ntissue by monitoring its response to an internal or external force. Different\nlevels of deformation are obtained from different tissue types depending on\ntheir mechanical properties, where stiffer tissues deform less. Given two radio\nfrequency (RF) frames collected before and after some deformation, we estimate\ndisplacement and strain images by comparing the RF frames. The quality of the\nstrain image is dependent on the type of motion that occurs during deformation.\nIn-plane axial motion results in high-quality strain images, whereas\nout-of-plane motion results in low-quality strain images. In this paper, we\nintroduce a new method using a convolutional neural network (CNN) to determine\nthe suitability of a pair of RF frames for elastography in only 5.4 ms. Our\nmethod could also be used to automatically choose the best pair of RF frames,\nyielding a high-quality strain image. The CNN was trained on 3,818 pairs of RF\nframes, while testing was done on 986 new unseen pairs, achieving an accuracy\nof more than 91%. The RF frames were collected from both phantom and in vivo\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 01:26:22 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 03:45:37 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Zayed", "Abdelrahman", ""], ["Cloutier", "Guy", ""], ["Rivaz", "Hassan", ""]]}, {"id": "2002.06739", "submitter": "Zhen Wang", "authors": "Lan Bai, Yuan-Hai Shao, Wei-Jie Chen, Zhen Wang, Nai-Yang Deng", "title": "Multiple Flat Projections for Cross-manifold Clustering", "comments": "12 pages, 58 figures", "journal-ref": "IEEE Transactions on Cybernetics, 2021", "doi": "10.1109/TCYB.2021.3050487", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-manifold clustering is a hard topic and many traditional clustering\nmethods fail because of the cross-manifold structures. In this paper, we\npropose a Multiple Flat Projections Clustering (MFPC) to deal with\ncross-manifold clustering problems. In our MFPC, the given samples are\nprojected into multiple subspaces to discover the global structures of the\nimplicit manifolds. Thus, the cross-manifold clusters are distinguished from\nthe various projections. Further, our MFPC is extended to nonlinear manifold\nclustering via kernel tricks to deal with more complex cross-manifold\nclustering. A series of non-convex matrix optimization problems in MFPC are\nsolved by a proposed recursive algorithm. The synthetic tests show that our\nMFPC works on the cross-manifold structures well. Moreover, experimental\nresults on the benchmark datasets show the excellent performance of our MFPC\ncompared with some state-of-the-art clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:16:00 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Bai", "Lan", ""], ["Shao", "Yuan-Hai", ""], ["Chen", "Wei-Jie", ""], ["Wang", "Zhen", ""], ["Deng", "Nai-Yang", ""]]}, {"id": "2002.06742", "submitter": "Ali Vakilian", "authors": "Sepideh Mahabadi and Ali Vakilian", "title": "Individual Fairness for $k$-Clustering", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a local search based algorithm for $k$-median and $k$-means (and more\ngenerally for any $k$-clustering with $\\ell_p$ norm cost function) from the\nperspective of individual fairness. More precisely, for a point $x$ in a point\nset $P$ of size $n$, let $r(x)$ be the minimum radius such that the ball of\nradius $r(x)$ centered at $x$ has at least $n/k$ points from $P$. Intuitively,\nif a set of $k$ random points are chosen from $P$ as centers, every point $x\\in\nP$ expects to have a center within radius $r(x)$. An individually fair\nclustering provides such a guarantee for every point $x\\in P$. This notion of\nfairness was introduced in [Jung et al., 2019] where they showed how to get an\napproximately feasible $k$-clustering with respect to this fairness condition.\n  In this work, we show how to get a bicriteria approximation for fair\n$k$-clustering: The $k$-median ($k$-means) cost of our solution is within a\nconstant factor of the cost of an optimal fair $k$-clustering, and our solution\napproximately satisfies the fairness condition (also within a constant factor).\nFurther, we complement our theoretical bounds with empirical evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:31:13 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 18:31:09 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mahabadi", "Sepideh", ""], ["Vakilian", "Ali", ""]]}, {"id": "2002.06746", "submitter": "Yoichi Chikahara", "authors": "Yoichi Chikahara, Shinsaku Sakaue, Akinori Fujino, Hisashi Kashima", "title": "Learning Individually Fair Classifier with Path-Specific Causal-Effect\n  Constraint", "comments": "23 pages, 9 figures, 3 tables; Accepted by AISTATS2021 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used to make decisions for individuals in various fields,\nwhich require us to achieve good prediction accuracy while ensuring fairness\nwith respect to sensitive features (e.g., race and gender). This problem,\nhowever, remains difficult in complex real-world scenarios. To quantify\nunfairness under such situations, existing methods utilize {\\it path-specific\ncausal effects}. However, none of them can ensure fairness for each individual\nwithout making impractical functional assumptions on the data. In this paper,\nwe propose a far more practical framework for learning an individually fair\nclassifier. To avoid restrictive functional assumptions, we define the {\\it\nprobability of individual unfairness} (PIU) and solve an optimization problem\nwhere PIU's upper bound, which can be estimated from data, is controlled to be\nclose to zero. We elucidate why our method can guarantee fairness for each\nindividual. Experimental results show that our method can learn an individually\nfair classifier at a slight cost of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 02:46:17 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:29:23 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 19:36:28 GMT"}, {"version": "v4", "created": "Fri, 26 Feb 2021 04:50:41 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Chikahara", "Yoichi", ""], ["Sakaue", "Shinsaku", ""], ["Fujino", "Akinori", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2002.06753", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Steven Reich, Liam Fowl, Renkun Ni, Valeriia\n  Cherepanova, Tom Goldstein", "title": "Unraveling Meta-Learning: Understanding Feature Representations for\n  Few-Shot Tasks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms produce feature extractors which achieve\nstate-of-the-art performance on few-shot classification. While the literature\nis rich with meta-learning methods, little is known about why the resulting\nfeature extractors perform so well. We develop a better understanding of the\nunderlying mechanics of meta-learning and the difference between models trained\nusing meta-learning and models which are trained classically. In doing so, we\nintroduce and verify several hypotheses for why meta-learned models perform\nbetter. Furthermore, we develop a regularizer which boosts the performance of\nstandard training routines for few-shot classification. In many cases, our\nroutine outperforms meta-learning while simultaneously running an order of\nmagnitude faster.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:18:45 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 22:50:45 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 13:59:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Goldblum", "Micah", ""], ["Reich", "Steven", ""], ["Fowl", "Liam", ""], ["Ni", "Renkun", ""], ["Cherepanova", "Valeriia", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.06755", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Jure Leskovec", "title": "Unifying Graph Convolutional Neural Networks and Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label Propagation (LPA) and Graph Convolutional Neural Networks (GCN) are\nboth message passing algorithms on graphs. Both solve the task of node\nclassification but LPA propagates node label information across the edges of\nthe graph, while GCN propagates and transforms node feature information.\nHowever, while conceptually similar, theoretical relation between LPA and GCN\nhas not yet been investigated. Here we study the relationship between LPA and\nGCN in terms of two aspects: (1) feature/label smoothing where we analyze how\nthe feature/label of one node is spread over its neighbors; And, (2)\nfeature/label influence of how much the initial feature/label of one node\ninfluences the final feature/label of another node. Based on our theoretical\nanalysis, we propose an end-to-end model that unifies GCN and LPA for node\nclassification. In our unified model, edge weights are learnable, and the LPA\nserves as regularization to assist the GCN in learning proper edge weights that\nlead to improved classification performance. Our model can also be seen as\nlearning attention weights based on node labels, which is more task-oriented\nthan existing feature-based attention models. In a number of experiments on\nreal-world graphs, our model shows superiority over state-of-the-art GCN-based\nmethods in terms of node classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:23:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Wang", "Hongwei", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.06757", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Hongyu Ren, Jure Leskovec", "title": "Relational Message Passing for Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph completion aims to predict missing relations between entities\nin a knowledge graph. In this work, we propose a relational message passing\nmethod for knowledge graph completion. Different from existing embedding-based\nmethods, relational message passing only considers edge features (i.e.,\nrelation types) without entity IDs in the knowledge graph, and passes\nrelational messages among edges iteratively to aggregate neighborhood\ninformation. Specifically, two kinds of neighborhood topology are modeled for a\ngiven entity pair under the relational message passing framework: (1)\nRelational context, which captures the relation types of edges adjacent to the\ngiven entity pair; (2) Relational paths, which characterize the relative\nposition between the given two entities in the knowledge graph. The two message\npassing modules are combined together for relation prediction. Experimental\nresults on knowledge graph benchmarks as well as our newly proposed dataset\nshow that, our method PathCon outperforms state-of-the-art knowledge graph\ncompletion methods by a large margin. PathCon is also shown applicable to\ninductive settings where entities are not seen in training stage, and it is\nable to provide interpretable explanations for the predicted results. The code\nand all datasets are available at https://github.com/hwwang55/PathCon.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 03:33:41 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 21:33:59 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wang", "Hongwei", ""], ["Ren", "Hongyu", ""], ["Leskovec", "Jure", ""]]}, {"id": "2002.06761", "submitter": "Yongming Li", "authors": "Yongming Li, Yan Lei, Pin Wang, Yuchuan Liu", "title": "Hybrid Embedded Deep Stacked Sparse Autoencoder with w_LPPD SVM Ensemble", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a kind of feature learning method with strong nonliear\nfeature transformation and becomes more and more important in many fields of\nartificial intelligence. Deep autoencoder is one representative method of the\ndeep learning methods, and can effectively extract abstract the information of\ndatasets. However, it does not consider the complementarity between the deep\nfeatures and original features during deep feature transformation. Besides, it\nsuffers from small sample problem. In order to solve these problems, a novel\ndeep autoencoder - hybrid feature embedded stacked sparse autoencoder(HESSAE)\nhas been proposed in this paper. HFESAE is capable to learn discriminant deep\nfeatures with the help of embedding original features to filter weak\nhidden-layer outputs during training. For the issue that class representation\nability of abstract information is limited by small sample problem, a feature\nfusion strategy has been designed aiming to combining abstract information\nlearned by HFESAE with original feature and obtain hybrid features for feature\nreduction. The strategy is hybrid feature selection strategy based on L1\nregularization followed by an support vector machine(SVM) ensemble model, in\nwhich weighted local discriminant preservation projection (w_LPPD), is designed\nand employed on each base classifier. At the end of this paper, several\nrepresentative public datasets are used to verify the effectiveness of the\nproposed algorithm. The experimental results demonstrated that, the proposed\nfeature learning method yields superior performance compared to other existing\nand state of art feature learning algorithms including some representative deep\nautoencoder methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:06:05 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Li", "Yongming", ""], ["Lei", "Yan", ""], ["Wang", "Pin", ""], ["Liu", "Yuchuan", ""]]}, {"id": "2002.06765", "submitter": "Teppei Suzuki", "authors": "Teppei Suzuki", "title": "Superpixel Segmentation via Convolutional Neural Networks with\n  Regularized Information Maximization", "comments": "To appear in ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised superpixel segmentation method by optimizing a\nrandomly-initialized convolutional neural network (CNN) in inference time. Our\nmethod generates superpixels via CNN from a single image without any labels by\nminimizing a proposed objective function for superpixel segmentation in\ninference time. There are three advantages to our method compared with many of\nexisting methods: (i) leverages an image prior of CNN for superpixel\nsegmentation, (ii) adaptively changes the number of superpixels according to\nthe given images, and (iii) controls the property of superpixels by adding an\nauxiliary cost to the objective function. We verify the advantages of our\nmethod quantitatively and qualitatively on BSDS500 and SBD datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:32:03 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 02:12:09 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 14:02:13 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Suzuki", "Teppei", ""]]}, {"id": "2002.06768", "submitter": "Ioannis Panageas", "authors": "Qi Lei and Sai Ganesh Nagarajan and Ioannis Panageas and Xiao Wang", "title": "Last iterate convergence in no-regret learning: constrained min-max\n  optimization for convex-concave landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent series of papers it has been established that variants of\nGradient Descent/Ascent and Mirror Descent exhibit last iterate convergence in\nconvex-concave zero-sum games. Specifically, \\cite{DISZ17, LiangS18} show last\niterate convergence of the so called \"Optimistic Gradient Descent/Ascent\" for\nthe case of \\textit{unconstrained} min-max optimization. Moreover, in\n\\cite{Metal} the authors show that Mirror Descent with an extra gradient step\ndisplays last iterate convergence for convex-concave problems (both constrained\nand unconstrained), though their algorithm does not follow the online learning\nframework; it uses extra information rather than \\textit{only} the history to\ncompute the next iteration. In this work, we show that \"Optimistic\nMultiplicative-Weights Update (OMWU)\" which follows the no-regret online\nlearning framework, exhibits last iterate convergence locally for\nconvex-concave games, generalizing the results of \\cite{DP19} where last\niterate convergence of OMWU was shown only for the \\textit{bilinear case}. We\ncomplement our results with experiments that indicate fast convergence of the\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:40:38 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 05:04:45 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Lei", "Qi", ""], ["Nagarajan", "Sai Ganesh", ""], ["Panageas", "Ioannis", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.06772", "submitter": "Branislav Kveton", "authors": "Craig Boutilier, Chih-Wei Hsu, Branislav Kveton, Martin Mladenov,\n  Csaba Szepesvari, and Manzil Zaheer", "title": "Differentiable Bandit Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration policies in Bayesian bandits maximize the average reward over\nproblem instances drawn from some distribution $\\mathcal{P}$. In this work, we\nlearn such policies for an unknown distribution $\\mathcal{P}$ using samples\nfrom $\\mathcal{P}$. Our approach is a form of meta-learning and exploits\nproperties of $\\mathcal{P}$ without making strong assumptions about its form.\nTo do this, we parameterize our policies in a differentiable way and optimize\nthem by policy gradients, an approach that is general and easy to implement. We\nderive effective gradient estimators and introduce novel variance reduction\ntechniques. We also analyze and experiment with various bandit policy classes,\nincluding neural networks and a novel softmax policy. The latter has regret\nguarantees and is a natural starting point for our optimization. Our\nexperiments show the versatility of our approach. We also observe that neural\nnetwork policies can learn implicit biases expressed only through the sampled\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:07:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 07:35:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Boutilier", "Craig", ""], ["Hsu", "Chih-Wei", ""], ["Kveton", "Branislav", ""], ["Mladenov", "Martin", ""], ["Szepesvari", "Csaba", ""], ["Zaheer", "Manzil", ""]]}, {"id": "2002.06774", "submitter": "Janghyeon Lee", "authors": "Janghyeon Lee, Donggyu Joo, Hyeong Gwon Hong, Junmo Kim", "title": "Residual Continual Learning", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel continual learning method called Residual Continual\nLearning (ResCL). Our method can prevent the catastrophic forgetting phenomenon\nin sequential learning of multiple tasks, without any source task information\nexcept the original network. ResCL reparameterizes network parameters by\nlinearly combining each layer of the original network and a fine-tuned network;\ntherefore, the size of the network does not increase at all. To apply the\nproposed method to general convolutional neural networks, the effects of batch\nnormalization layers are also considered. By utilizing residual-learning-like\nreparameterization and a special weight decay loss, the trade-off between\nsource and target performance is effectively controlled. The proposed method\nexhibits state-of-the-art performance in various continual learning scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:24:45 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lee", "Janghyeon", ""], ["Joo", "Donggyu", ""], ["Hong", "Hyeong Gwon", ""], ["Kim", "Junmo", ""]]}, {"id": "2002.06776", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Michael Davinroy, Yi\\u{g}itcan Kaya, Dana\n  Dachman-Soled, Tudor Dumitra\\c{s}", "title": "How to 0wn NAS in Your Spare Time", "comments": "Accepted to ICLR 2020 [Poster]; Our code is available at\n  https://github.com/sanghyun-hong/How-to-0wn-NAS-in-Your-Spare-Time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New data processing pipelines and novel network architectures increasingly\ndrive the success of deep learning. In consequence, the industry considers\ntop-performing architectures as intellectual property and devotes considerable\ncomputational resources to discovering such architectures through neural\narchitecture search (NAS). This provides an incentive for adversaries to steal\nthese novel architectures; when used in the cloud, to provide Machine Learning\nas a Service, the adversaries also have an opportunity to reconstruct the\narchitectures by exploiting a range of hardware side channels. However, it is\nchallenging to reconstruct novel architectures and pipelines without knowing\nthe computational graph (e.g., the layers, branches or skip connections), the\narchitectural parameters (e.g., the number of filters in a convolutional layer)\nor the specific pre-processing steps (e.g. embeddings). In this paper, we\ndesign an algorithm that reconstructs the key components of a novel deep\nlearning system by exploiting a small amount of information leakage from a\ncache side-channel attack, Flush+Reload. We use Flush+Reload to infer the trace\nof computations and the timing for each computation. Our algorithm then\ngenerates candidate computational graphs from the trace and eliminates\nincompatible candidates through a parameter estimation process. We implement\nour algorithm in PyTorch and Tensorflow. We demonstrate experimentally that we\ncan reconstruct MalConv, a novel data pre-processing pipeline for malware\ndetection, and ProxylessNAS- CPU, a novel network architecture for the ImageNet\nclassification optimized to run on CPUs, without knowing the architecture\nfamily. In both cases, we achieve 0% error. These results suggest hardware side\nchannels are a practical attack vector against MLaaS, and more efforts should\nbe devoted to understanding their impact on the security of deep learning\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 05:40:55 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 23:04:04 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Hong", "Sanghyun", ""], ["Davinroy", "Michael", ""], ["Kaya", "Yi\u011fitcan", ""], ["Dachman-Soled", "Dana", ""], ["Dumitra\u015f", "Tudor", ""]]}, {"id": "2002.06789", "submitter": "Minhao Cheng", "authors": "Minhao Cheng, Qi Lei, Pin-Yu Chen, Inderjit Dhillon, Cho-Jui Hsieh", "title": "CAT: Customized Adversarial Training for Improved Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has become one of the most effective methods for\nimproving robustness of neural networks. However, it often suffers from poor\ngeneralization on both clean and perturbed data. In this paper, we propose a\nnew algorithm, named Customized Adversarial Training (CAT), which adaptively\ncustomizes the perturbation level and the corresponding label for each training\nsample in adversarial training. We show that the proposed algorithm achieves\nbetter clean and robust accuracy than previous adversarial training methods\nthrough extensive experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:13:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cheng", "Minhao", ""], ["Lei", "Qi", ""], ["Chen", "Pin-Yu", ""], ["Dhillon", "Inderjit", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.06790", "submitter": "Hongming Huang", "authors": "Hongming Huang, Peng Cheng, Hong Xu, Yongqiang Xiong", "title": "Simulating Performance of ML Systems with Offline Profiling", "comments": "Accepted to The MLOps 2020 workshop, colocated with MLSys 2020. 2\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate that simulation based on offline profiling is a promising\napproach to better understand and improve the complex ML systems. Our approach\nuses operation-level profiling and dataflow based simulation to ensure it\noffers a unified and automated solution for all frameworks and ML models, and\nis also accurate by considering the various parallelization strategies in a\nreal system.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:13:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Huang", "Hongming", ""], ["Cheng", "Peng", ""], ["Xu", "Hong", ""], ["Xiong", "Yongqiang", ""]]}, {"id": "2002.06799", "submitter": "Steven Kommrusch", "authors": "Steve Kommrusch, Th\\'eo Barollet, Louis-No\\\"el Pouchet", "title": "Equivalence of Dataflow Graphs via Rewrite Rules Using a\n  Graph-to-Sequence Neural Model", "comments": "20 pages including references and appendices, 10 figures, updated to\n  include acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we target the problem of provably computing the equivalence\nbetween two programs represented as dataflow graphs. To this end, we formalize\nthe problem of equivalence between two programs as finding a set of\nsemantics-preserving rewrite rules from one into the other, such that after the\nrewrite the two programs are structurally identical, and therefore trivially\nequivalent. We then develop the first graph-to-sequence neural network system\nfor program equivalence, trained to produce such rewrite sequences from a\ncarefully crafted automatic example generation algorithm. We extensively\nevaluate our system on a rich multi-type linear algebra expression language,\nusing arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our\nsystem outputs via inference a correct rewrite sequence for 96% of the 10,000\nprogram pairs isolated for testing, using 30-term programs. And in all cases,\nthe validity of the sequence produced and therefore the provable assertion of\nprogram equivalence is computable, in negligible time.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:43:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 21:40:34 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Kommrusch", "Steve", ""], ["Barollet", "Th\u00e9o", ""], ["Pouchet", "Louis-No\u00ebl", ""]]}, {"id": "2002.06806", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Efe Bozkir, Enkelejda Kasneci", "title": "Reinforcement learning for the privacy preservation and manipulation of\n  eye tracking data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an approach based on reinforcement learning for eye\ntracking data manipulation. It is based on two opposing agents, where one tries\nto classify the data correctly and the second agent looks for patterns in the\ndata, which get manipulated to hide specific information. We show that our\napproach is successfully applicable to preserve the privacy of the subjects.\nFor this purpose, we evaluate our approach iteratively to showcase the behavior\nof the reinforcement learning based approach. In addition, we evaluate the\nimportance of temporal, as well as spatial, information of eye tracking data\nfor specific classification goals. In the last part of our evaluation, we apply\nthe procedure to further public data sets without re-training the autoencoder\nor the data manipulator. The results show that the learned manipulation is\ngeneralized and applicable to unseen data as well.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:02:19 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:41:49 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Bozkir", "Efe", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.06815", "submitter": "Minsung Hyun", "authors": "Minsung Hyun, Jisoo Jeong and Nojun Kwak", "title": "Class-Imbalanced Semi-Supervised Learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-Supervised Learning (SSL) has achieved great success in overcoming the\ndifficulties of labeling and making full use of unlabeled data. However, SSL\nhas a limited assumption that the numbers of samples in different classes are\nbalanced, and many SSL algorithms show lower performance for the datasets with\nthe imbalanced class distribution. In this paper, we introduce a task of\nclass-imbalanced semi-supervised learning (CISSL), which refers to\nsemi-supervised learning with class-imbalanced data. In doing so, we consider\nclass imbalance in both labeled and unlabeled sets. First, we analyze existing\nSSL methods in imbalanced environments and examine how the class imbalance\naffects SSL methods. Then we propose Suppressed Consistency Loss (SCL), a\nregularization method robust to class imbalance. Our method shows better\nperformance than the conventional methods in the CISSL environment. In\nparticular, the more severe the class imbalance and the smaller the size of the\nlabeled data, the better our method performs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:48:47 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hyun", "Minsung", ""], ["Jeong", "Jisoo", ""], ["Kwak", "Nojun", ""]]}, {"id": "2002.06816", "submitter": "Pamela K. Douglas", "authors": "Pamela K. Douglas, Farzad Vasheghani Farahani", "title": "On the Similarity of Deep Learning Representations Across Didactic and\n  Adversarial Examples", "comments": "2 figures", "journal-ref": "Med NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing use of deep neural networks (DNNs) has motivated a parallel\nendeavor: the design of adversaries that profit from successful\nmisclassifications. However, not all adversarial examples are crafted for\nmalicious purposes. For example, real world systems often contain physical,\ntemporal, and sampling variability across instrumentation. Adversarial examples\nin the wild may inadvertently prove deleterious for accurate predictive\nmodeling. Conversely, naturally occurring covariance of image features may\nserve didactic purposes. Here, we studied the stability of deep learning\nrepresentations for neuroimaging classification across didactic and adversarial\nconditions characteristic of MRI acquisition variability. We show that\nrepresentational similarity and performance vary according to the frequency of\nadversarial examples in the input space.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:49:20 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Douglas", "Pamela K.", ""], ["Farahani", "Farzad Vasheghani", ""]]}, {"id": "2002.06817", "submitter": "Kaihsiang Cheng", "authors": "Tsung-Han Hsieh, Kai-Hsiang Cheng, Zhe-Cheng Fan, Yu-Ching Yang,\n  Yi-Hsuan Yang", "title": "Addressing the confounds of accompaniments in singer identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying singers is an important task with many applications. However, the\ntask remains challenging due to many issues. One major issue is related to the\nconfounding factors from the background instrumental music that is mixed with\nthe vocals in music production. A singer identification model may learn to\nextract non-vocal related features from the instrumental part of the songs, if\na singer only sings in certain musical contexts (e.g., genres). The model\ncannot therefore generalize well when the singer sings in unseen contexts. In\nthis paper, we attempt to address this issue. Specifically, we employ\nopen-unmix, an open source tool with state-of-the-art performance in source\nseparation, to separate the vocal and instrumental tracks of music. We then\ninvestigate two means to train a singer identification model: by learning from\nthe separated vocal only, or from an augmented set of data where we\n\"shuffle-and-remix\" the separated vocal tracks and instrumental tracks of\ndifferent songs to artificially make the singers sing in different contexts. We\nalso incorporate melodic features learned from the vocal melody contour for\nbetter performance. Evaluation results on a benchmark dataset called the\nartist20 shows that this data augmentation method greatly improves the accuracy\nof singer identification.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:49:21 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Hsieh", "Tsung-Han", ""], ["Cheng", "Kai-Hsiang", ""], ["Fan", "Zhe-Cheng", ""], ["Yang", "Yu-Ching", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "2002.06836", "submitter": "Alberto Maria Metelli", "authors": "Alberto Maria Metelli, Flavio Mazzolini, Lorenzo Bisi, Luca Sabbioni,\n  Marcello Restelli", "title": "Control Frequency Adaptation via Action Persistence in Batch\n  Reinforcement Learning", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of the control frequency of a system has a relevant impact on the\nability of reinforcement learning algorithms to learn a highly performing\npolicy. In this paper, we introduce the notion of action persistence that\nconsists in the repetition of an action for a fixed number of decision steps,\nhaving the effect of modifying the control frequency. We start analyzing how\naction persistence affects the performance of the optimal policy, and then we\npresent a novel algorithm, Persistent Fitted Q-Iteration (PFQI), that extends\nFQI, with the goal of learning the optimal value function at a given\npersistence. After having provided a theoretical study of PFQI and a heuristic\napproach to identify the optimal persistence, we present an experimental\ncampaign on benchmark domains to show the advantages of action persistence and\nproving the effectiveness of our persistence selection method.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 08:38:51 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 19:18:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Metelli", "Alberto Maria", ""], ["Mazzolini", "Flavio", ""], ["Bisi", "Lorenzo", ""], ["Sabbioni", "Luca", ""], ["Restelli", "Marcello", ""]]}, {"id": "2002.06838", "submitter": "Sheng Hu", "authors": "Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai", "title": "Stratified Rule-Aware Network for Abstract Visual Reasoning", "comments": "AAAI 2021 paper. Code: https://github.com/husheng12345/SRAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract reasoning refers to the ability to analyze information, discover\nrules at an intangible level, and solve problems in innovative ways. Raven's\nProgressive Matrices (RPM) test is typically used to examine the capability of\nabstract reasoning. The subject is asked to identify the correct choice from\nthe answer set to fill the missing panel at the bottom right of RPM (e.g., a\n3$\\times$3 matrix), following the underlying rules inside the matrix. Recent\nstudies, taking advantage of Convolutional Neural Networks (CNNs), have\nachieved encouraging progress to accomplish the RPM test. However, they partly\nignore necessary inductive biases of RPM solver, such as order sensitivity\nwithin each row/column and incremental rule induction. To address this problem,\nin this paper we propose a Stratified Rule-Aware Network (SRAN) to generate the\nrule embeddings for two input sequences. Our SRAN learns multiple granularity\nrule embeddings at different levels, and incrementally integrates the\nstratified embedding flows through a gated fusion module. With the help of\nembeddings, a rule similarity metric is applied to guarantee that SRAN can not\nonly be trained using a tuplet loss but also infer the best answer efficiently.\nWe further point out the severe defects existing in the popular RAVEN dataset\nfor RPM test, which prevent from the fair evaluation of the abstract reasoning\nability. To fix the defects, we propose an answer set generation algorithm\ncalled Attribute Bisection Tree (ABT), forming an improved dataset named\nImpartial-RAVEN (I-RAVEN for short). Extensive experiments are conducted on\nboth PGM and I-RAVEN datasets, showing that our SRAN outperforms the\nstate-of-the-art models by a considerable margin.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 08:44:05 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 08:46:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Hu", "Sheng", ""], ["Ma", "Yuqing", ""], ["Liu", "Xianglong", ""], ["Wei", "Yanlu", ""], ["Bai", "Shihao", ""]]}, {"id": "2002.06856", "submitter": "Shakila Mahjabin Tonni", "authors": "Shakila Mahjabin Tonni, Dinusha Vatsalan, Farhad Farokhi, Dali Kaafar,\n  Zhigang Lu and Gioacchino Tangari", "title": "Data and Model Dependencies of Membership Inference Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models have been shown to be vulnerable to Membership\nInference Attacks (MIA), which infer the membership of a given data point in\nthe target dataset by observing the prediction output of the ML model. While\nthe key factors for the success of MIA have not yet been fully understood,\nexisting defense mechanisms such as using L2 regularization\n\\cite{10shokri2017membership} and dropout layers \\cite{salem2018ml} take only\nthe model's overfitting property into consideration. In this paper, we provide\nan empirical analysis of the impact of both the data and ML model properties on\nthe vulnerability of ML techniques to MIA. Our results reveal the relationship\nbetween MIA accuracy and properties of the dataset and training model in use.\nIn particular, we show that the size of shadow dataset, the class and feature\nbalance and the entropy of the target dataset, the configurations and fairness\nof the training model are the most influential factors. Based on those\nexperimental findings, we conclude that along with model overfitting, multiple\nproperties jointly contribute to MIA success instead of any single property.\nBuilding on our experimental findings, we propose using those data and model\nproperties as regularizers to protect ML models against MIA. Our results show\nthat the proposed defense mechanisms can reduce the MIA accuracy by up to 25\\%\nwithout sacrificing the ML model prediction utility.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:35:00 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 05:15:38 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 13:45:13 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 00:56:33 GMT"}, {"version": "v5", "created": "Sat, 25 Jul 2020 06:25:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tonni", "Shakila Mahjabin", ""], ["Vatsalan", "Dinusha", ""], ["Farokhi", "Farhad", ""], ["Kaafar", "Dali", ""], ["Lu", "Zhigang", ""], ["Tangari", "Gioacchino", ""]]}, {"id": "2002.06862", "submitter": "Taro Langner", "authors": "Taro Langner, Robin Strand, H{\\aa}kan Ahlstr\\\"om, Joel Kullberg", "title": "Large-scale biometry with interpretable neural network regression on UK\n  Biobank body MRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a large-scale medical examination, the UK Biobank study has successfully\nimaged more than 32,000 volunteer participants with magnetic resonance imaging\n(MRI). Each scan is linked to extensive metadata, providing a comprehensive\nmedical survey of imaged anatomy and related health states. Despite its\npotential for research, this vast amount of data presents a challenge to\nestablished methods of evaluation, which often rely on manual input. To date,\nthe range of reference values for cardiovascular and metabolic risk factors is\ntherefore incomplete. In this work, neural networks were trained for\nimage-based regression to infer various biological metrics from the\nneck-to-knee body MRI automatically. The approach requires no manual\nintervention or direct access to reference segmentations for training. The\nexamined fields span 64 variables derived from anthropometric measurements,\ndual-energy X-ray absorptiometry (DXA), atlas-based segmentations, and\ndedicated liver scans. With the ResNet50, the standardized framework achieves a\nclose fit to the target values (median R^2 > 0.97) in cross-validation.\nInterpretation of aggregated saliency maps suggests that the network correctly\ntargets specific body regions and limbs, and learned to emulate different\nmodalities. On several body composition metrics, the quality of the predictions\nis within the range of variability observed between established gold standard\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:47:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 10:23:26 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 08:59:16 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Langner", "Taro", ""], ["Strand", "Robin", ""], ["Ahlstr\u00f6m", "H\u00e5kan", ""], ["Kullberg", "Joel", ""]]}, {"id": "2002.06864", "submitter": "Teodora Baluta", "authors": "Teodora Baluta, Zheng Leong Chua, Kuldeep S. Meel and Prateek Saxena", "title": "Scalable Quantitative Verification For Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the functional success of deep neural networks (DNNs), their\ntrustworthiness remains a crucial open challenge. To address this challenge,\nboth testing and verification techniques have been proposed. But these existing\ntechniques provide either scalability to large networks or formal guarantees,\nnot both. In this paper, we propose a scalable quantitative verification\nframework for deep neural networks, i.e., a test-driven approach that comes\nwith formal guarantees that a desired probabilistic property is satisfied. Our\ntechnique performs enough tests until soundness of a formal probabilistic\nproperty can be proven. It can be used to certify properties of both\ndeterministic and randomized DNNs. We implement our approach in a tool called\nPROVERO and apply it in the context of certifying adversarial robustness of\nDNNs. In this context, we first show a new attack-agnostic measure of\nrobustness which offers an alternative to purely attack-based methodology of\nevaluating robustness being reported today. Second, PROVERO provides\ncertificates of robustness for large DNNs, where existing state-of-the-art\nverification tools fail to produce conclusive results. Our work paves the way\nforward for verifying properties of distributions captured by real-world deep\nneural networks, with provable guarantees, even where testers only have\nblack-box access to the neural network.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:53:50 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 10:25:06 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Baluta", "Teodora", ""], ["Chua", "Zheng Leong", ""], ["Meel", "Kuldeep S.", ""], ["Saxena", "Prateek", ""]]}, {"id": "2002.06873", "submitter": "Swapnil Mishra", "authors": "Swapnil Mishra, Seth Flaxman, Harrison Zhu, Samir Bhatt", "title": "$\\pi$VAE: Encoding stochastic process priors with variational\n  autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic processes provide a mathematically elegant way model complex data.\nIn theory, they provide flexible priors over function classes that can encode a\nwide range of interesting assumptions. In practice, however, efficient\ninference by optimisation or marginalisation is difficult, a problem further\nexacerbated with big data and high dimensional input spaces. We propose a novel\nvariational autoencoder (VAE) called the prior encoding variational autoencoder\n($\\pi$VAE). The $\\pi$VAE is finitely exchangeable and Kolmogorov consistent,\nand thus is a continuous stochastic process. We use $\\pi$VAE to learn low\ndimensional embeddings of function classes. We show that our framework can\naccurately learn expressive function classes such as Gaussian processes, but\nalso properties of functions to enable statistical inference (such as the\nintegral of a log Gaussian process). For popular tasks, such as spatial\ninterpolation, $\\pi$VAE achieves state-of-the-art performance both in terms of\naccuracy and computational efficiency. Perhaps most usefully, we demonstrate\nthat the low dimensional independently distributed latent space representation\nlearnt provides an elegant and scalable means of performing Bayesian inference\nfor stochastic processes within probabilistic programming languages such as\nStan.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 10:23:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:49:28 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 12:22:15 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mishra", "Swapnil", ""], ["Flaxman", "Seth", ""], ["Zhu", "Harrison", ""], ["Bhatt", "Samir", ""]]}, {"id": "2002.06890", "submitter": "Terence Broad", "authors": "Terence Broad, Frederic Fol Leymarie, Mick Grierson", "title": "Amplifying The Uncanny", "comments": null, "journal-ref": "Proceedings of the Eighth Conference on Proceedings of the Eighth\n  Conference on Computation, Communication, Aesthetics & X, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep neural networks have become remarkably good at producing realistic\ndeepfakes, images of people that (to the untrained eye) are indistinguishable\nfrom real images. Deepfakes are produced by algorithms that learn to\ndistinguish between real and fake images and are optimised to generate samples\nthat the system deems realistic. This paper, and the resulting series of\nartworks Being Foiled explore the aesthetic outcome of inverting this process,\ninstead optimising the system to generate images that it predicts as being\nfake. This maximises the unlikelihood of the data and in turn, amplifies the\nuncanny nature of these machine hallucinations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 11:12:39 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 16:49:55 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 13:18:10 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Broad", "Terence", ""], ["Leymarie", "Frederic Fol", ""], ["Grierson", "Mick", ""]]}, {"id": "2002.06910", "submitter": "Angelos Chatzimparmpas", "authors": "Angelos Chatzimparmpas, Rafael M. Martins, Andreas Kerren", "title": "t-viSNE: Interactive Assessment and Interpretation of t-SNE Projections", "comments": "This manuscript is published in the IEEE Transactions on\n  Visualization and Computer Graphics Journal (IEEE TVCG)", "journal-ref": "IEEE TVCG 2020, 26(8), 2696-2714", "doi": "10.1109/TVCG.2020.2986996", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  t-Distributed Stochastic Neighbor Embedding (t-SNE) for the visualization of\nmultidimensional data has proven to be a popular approach, with successful\napplications in a wide range of domains. Despite their usefulness, t-SNE\nprojections can be hard to interpret or even misleading, which hurts the\ntrustworthiness of the results. Understanding the details of t-SNE itself and\nthe reasons behind specific patterns in its output may be a daunting task,\nespecially for non-experts in dimensionality reduction. In this work, we\npresent t-viSNE, an interactive tool for the visual exploration of t-SNE\nprojections that enables analysts to inspect different aspects of their\naccuracy and meaning, such as the effects of hyper-parameters, distance and\nneighborhood preservation, densities and costs of specific neighborhoods, and\nthe correlations between dimensions and visual patterns. We propose a coherent,\naccessible, and well-integrated collection of different views for the\nvisualization of t-SNE projections. The applicability and usability of t-viSNE\nare demonstrated through hypothetical usage scenarios with real data sets.\nFinally, we present the results of a user study where the tool's effectiveness\nwas evaluated. By bringing to light information that would normally be lost\nafter running t-SNE, we hope to support analysts in using t-SNE and making its\nresults better understandable.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:22:34 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 09:37:40 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 05:12:47 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 20:40:37 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Chatzimparmpas", "Angelos", ""], ["Martins", "Rafael M.", ""], ["Kerren", "Andreas", ""]]}, {"id": "2002.06914", "submitter": "Max Berrendorf", "authors": "Max Berrendorf and Evgeniy Faerman and Laurent Vermue and Volker Tresp", "title": "On the Ambiguity of Rank-Based Evaluation of Entity Alignment or Link\n  Prediction Methods", "comments": "fixed a typo on page 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we take a closer look at the evaluation of two families of\nmethods for enriching information from knowledge graphs: Link Prediction and\nEntity Alignment. In the current experimental setting, multiple different\nscores are employed to assess different aspects of model performance. We\nanalyze the informativeness of these evaluation measures and identify several\nshortcomings. In particular, we demonstrate that all existing scores can hardly\nbe used to compare results across different datasets. Moreover, we demonstrate\nthat varying size of the test size automatically has impact on the performance\nof the same model based on commonly used metrics for the Entity Alignment task.\nWe show that this leads to various problems in the interpretation of results,\nwhich may support misleading conclusions. Therefore, we propose adjustments to\nthe evaluation and demonstrate empirically how this supports a fair,\ncomparable, and interpretable assessment of model performance. Our code is\navailable at https://github.com/mberr/rank-based-evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 12:26:14 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 16:42:48 GMT"}, {"version": "v3", "created": "Fri, 16 Apr 2021 16:12:47 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Berrendorf", "Max", ""], ["Faerman", "Evgeniy", ""], ["Vermue", "Laurent", ""], ["Tresp", "Volker", ""]]}, {"id": "2002.06945", "submitter": "Mahdi Boloursaz Mashhadi", "authors": "Mahdi Boloursaz Mashhadi, and Deniz G\\\"und\\\"uz", "title": "Deep Learning for Massive MIMO Channel State Acquisition and Feedback", "comments": "Accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) systems are a main enabler of\nthe excessive throughput requirements in 5G and future generation wireless\nnetworks as they can serve many users simultaneously with high spectral and\nenergy efficiency. To achieve this, massive MIMO systems require accurate and\ntimely channel state information (CSI), which is acquired by a training process\nthat involves pilot transmission, CSI estimation and feedback. This training\nprocess incurs a training overhead, which scales with the number of antennas,\nusers and subcarriers. Reducing this training overhead in massive MIMO systems\nhas been a major topic of research since the emergence of the concept.\nRecently, deep learning (DL)-based approaches for massive MIMO training have\nbeen proposed and showed significant improvements compared to traditional\ntechniques. This paper provides an overview of how neural networks (NNs) can be\nused in the training process of massive MIMO systems to improve the performance\nby reducing the CSI acquisition overhead and to reduce complexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:16:34 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 11:17:59 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 18:30:54 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Mashhadi", "Mahdi Boloursaz", ""], ["G\u00fcnd\u00fcz", "Deniz", ""]]}, {"id": "2002.06946", "submitter": "Saad Mohamad", "authors": "Saad Mohamad and Giovanni Montana", "title": "Adaptive Experience Selection for Policy Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient reinforcement learning (RL) algorithms have achieved\nimpressive performance in challenging learning tasks such as continuous\ncontrol, but suffer from high sample complexity. Experience replay is a\ncommonly used approach to improve sample efficiency, but gradient estimators\nusing past trajectories typically have high variance. Existing sampling\nstrategies for experience replay like uniform sampling or prioritised\nexperience replay do not explicitly try to control the variance of the gradient\nestimates. In this paper, we propose an online learning algorithm, adaptive\nexperience selection (AES), to adaptively learn an experience sampling\ndistribution that explicitly minimises this variance. Using a regret\nminimisation approach, AES iteratively updates the experience sampling\ndistribution to match the performance of a competitor distribution assumed to\nhave optimal variance. Sample non-stationarity is addressed by proposing a\ndynamic (i.e. time changing) competitor distribution for which a closed-form\nsolution is proposed. We demonstrate that AES is a low-regret algorithm with\nreasonable sample complexity. Empirically, AES has been implemented for deep\ndeterministic policy gradient and soft actor critic algorithms, and tested on 8\ncontinuous control tasks from the OpenAI Gym library. Ours results show that\nAES leads to significantly improved performance compared to currently available\nexperience sampling strategies for policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:16:37 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Mohamad", "Saad", ""], ["Montana", "Giovanni", ""]]}, {"id": "2002.06961", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber, Adam Jatowt", "title": "Citation Recommendation: Approaches and Datasets", "comments": "to be published in the International Journal on Digital Libraries", "journal-ref": null, "doi": "10.1007/s00799-020-00288-2", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation recommendation describes the task of recommending citations for a\ngiven text. Due to the overload of published scientific works in recent years\non the one hand, and the need to cite the most appropriate publications when\nwriting scientific texts on the other hand, citation recommendation has emerged\nas an important research topic. In recent years, several approaches and\nevaluation data sets have been presented. However, to the best of our\nknowledge, no literature survey has been conducted explicitly on citation\nrecommendation. In this article, we give a thorough introduction into automatic\ncitation recommendation research. We then present an overview of the approaches\nand data sets for citation recommendation and identify differences and\ncommonalities using various dimensions. Last but not least, we shed light on\nthe evaluation methods, and outline general challenges in the evaluation and\nhow to meet them. We restrict ourselves to citation recommendation for\nscientific publications, as this document type has been studied the most in\nthis area. However, many of the observations and discussions included in this\nsurvey are also applicable to other types of text, such as news articles and\nencyclopedic articles.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:59:50 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 08:01:27 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["F\u00e4rber", "Michael", ""], ["Jatowt", "Adam", ""]]}, {"id": "2002.06963", "submitter": "Dahyun Kim", "authors": "Dahyun Kim, Kunal Pratap Singh, Jonghyun Choi", "title": "Learning Architectures for Binary Networks", "comments": "The manuscript was changed to a one-column format along with minor\n  modifications to the content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Backbone architectures of most binary networks are well-known floating point\narchitectures such as the ResNet family. Questioning that the architectures\ndesigned for floating point networks would not be the best for binary networks,\nwe propose to search architectures for binary networks (BNAS) by defining a new\nsearch space for binary architectures and a novel search objective.\nSpecifically, based on the cell based search method, we define the new search\nspace of binary layer types, design a new cell template, and rediscover the\nutility of and propose to use the Zeroise layer instead of using it as a\nplaceholder. The novel search objective diversifies early search to learn\nbetter performing binary architectures. We show that our proposed method\nsearches architectures with stable training curves despite the quantization\nerror inherent in binary networks. Quantitative analyses demonstrate that our\nsearched architectures outperform the architectures used in state-of-the-art\nbinary networks and outperform or perform on par with state-of-the-art binary\nnetworks that employ various techniques other than architectural changes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:06:45 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 09:08:41 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Kim", "Dahyun", ""], ["Singh", "Kunal Pratap", ""], ["Choi", "Jonghyun", ""]]}, {"id": "2002.06967", "submitter": "Francesco Craighero", "authors": "Francesco Craighero, Fabrizio Angaroni, Alex Graudenzi, Fabio Stella,\n  Marco Antoniotti", "title": "Investigating the Compositional Structure Of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-64583-0_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current understanding of deep neural networks can only partially explain\nhow input structure, network parameters and optimization algorithms jointly\ncontribute to achieve the strong generalization power that is typically\nobserved in many real-world applications. In order to improve the comprehension\nand interpretability of deep neural networks, we here introduce a novel\ntheoretical framework based on the compositional structure of piecewise linear\nactivation functions. By defining a direct acyclic graph representing the\ncomposition of activation patterns through the network layers, it is possible\nto characterize the instances of the input data with respect to both the\npredicted label and the specific (linear) transformation used to perform\npredictions. Preliminary tests on the MNIST dataset show that our method can\ngroup input instances with regard to their similarity in the internal\nrepresentation of the neural network, providing an intuitive measure of input\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:16:17 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Craighero", "Francesco", ""], ["Angaroni", "Fabrizio", ""], ["Graudenzi", "Alex", ""], ["Stella", "Fabio", ""], ["Antoniotti", "Marco", ""]]}, {"id": "2002.06979", "submitter": "Zixin Wen", "authors": "Zixin Wen", "title": "Convergence of End-to-End Training in Deep Unsupervised Contrastive\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised contrastive learning has gained increasing attention in the\nlatest research and has proven to be a powerful method for learning\nrepresentations from unlabeled data. However, little theoretical analysis was\nknown for this framework. In this paper, we study the optimization of deep\nunsupervised contrastive learning. We prove that, by applying end-to-end\ntraining that simultaneously updates two deep over-parameterized neural\nnetworks, one can find an approximate stationary solution for the non-convex\ncontrastive loss. This result is inherently different from the existing\nover-parameterized analysis in the supervised setting because, in contrast to\nlearning a specific target function, unsupervised contrastive learning tries to\nencode the unlabeled data distribution into the neural networks, which\ngenerally has no optimal solution. Our analysis provides theoretical insights\ninto the practical success of these unsupervised pretraining methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:35:21 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 00:32:53 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 17:23:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wen", "Zixin", ""]]}, {"id": "2002.06987", "submitter": "Wei Deng", "authors": "Wei Deng and Junwei Pan and Tian Zhou and Deguang Kong and Aaron\n  Flores and Guang Lin", "title": "DeepLight: Deep Lightweight Feature Interactions for Accelerating CTR\n  Predictions in Ad Serving", "comments": "Accepted by WSDM 2021; Source code:\n  https://github.com/WayneDW/DeepLight_Deep-Lightweight-Feature-Interactions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a crucial task in online display\nadvertising. The embedding-based neural networks have been proposed to learn\nboth explicit feature interactions through a shallow component and deep feature\ninteractions using a deep neural network (DNN) component. These sophisticated\nmodels, however, slow down the prediction inference by at least hundreds of\ntimes. To address the issue of significantly increased serving delay and high\nmemory usage for ad serving in production, this paper presents\n\\emph{DeepLight}: a framework to accelerate the CTR predictions in three\naspects: 1) accelerate the model inference via explicitly searching informative\nfeature interactions in the shallow component; 2) prune redundant layers and\nparameters at intra-layer and inter-layer level in the DNN component; 3)\npromote the sparsity of the embedding layer to preserve the most discriminant\nsignals. By combining the above efforts, the proposed approach accelerates the\nmodel inference by 46X on Criteo dataset and 27X on Avazu dataset without any\nloss on the prediction accuracy. This paves the way for successfully deploying\ncomplicated embedding-based neural networks in production for ad serving.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:51:31 GMT"}, {"version": "v2", "created": "Tue, 18 Aug 2020 01:46:08 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 22:13:51 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Deng", "Wei", ""], ["Pan", "Junwei", ""], ["Zhou", "Tian", ""], ["Kong", "Deguang", ""], ["Flores", "Aaron", ""], ["Lin", "Guang", ""]]}, {"id": "2002.06991", "submitter": "William Clements", "authors": "Robin Quessard, Thomas D. Barrett, William R. Clements", "title": "Learning Group Structure and Disentangled Representations of Dynamical\n  Environments", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentangled representations is a key step towards effectively\ndiscovering and modelling the underlying structure of environments. In the\nnatural sciences, physics has found great success by describing the universe in\nterms of symmetry preserving transformations. Inspired by this formalism, we\npropose a framework, built upon the theory of group representation, for\nlearning representations of a dynamical environment structured around the\ntransformations that generate its evolution. Experimentally, we learn the\nstructure of explicitly symmetric environments without supervision from\nobservational data generated by sequential interactions. We further introduce\nan intuitive disentanglement regularisation to ensure the interpretability of\nthe learnt representations. We show that our method enables accurate\nlong-horizon predictions, and demonstrate a correlation between the quality of\npredictions and disentanglement in the latent space.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:59:31 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 16:23:23 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Quessard", "Robin", ""], ["Barrett", "Thomas D.", ""], ["Clements", "William R.", ""]]}, {"id": "2002.07003", "submitter": "Deyi Liu", "authors": "Deyi Liu, Volkan Cevher, Quoc Tran-Dinh", "title": "A Newton Frank-Wolfe Method for Constrained Self-Concordant Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how to scalably solve a class of constrained self-concordant\nminimization problems using linear minimization oracles (LMO) over the\nconstraint set. We prove that the number of LMO calls of our method is nearly\nthe same as that of the Frank-Wolfe method in the L-smooth case. Specifically,\nour Newton Frank-Wolfe method uses $\\mathcal{O}(\\epsilon^{-\\nu})$ LMO's, where\n$\\epsilon$ is the desired accuracy and $\\nu:= 1 + o(1)$. In addition, we\ndemonstrate how our algorithm can exploit the improved variants of the\nLMO-based schemes, including away-steps, to attain linear convergence rates. We\nalso provide numerical evidence with portfolio design with the competitive\nratio, D-optimal experimental design, and logistic regression with the elastic\nnet where Newton Frank-Wolfe outperforms the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:28:31 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Liu", "Deyi", ""], ["Cevher", "Volkan", ""], ["Tran-Dinh", "Quoc", ""]]}, {"id": "2002.07007", "submitter": "Connor Coley", "authors": "Wenhao Gao, Connor W. Coley", "title": "The Synthesizability of Molecules Proposed by Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of functional molecules is an expensive and time-consuming\nprocess, exemplified by the rising costs of small molecule therapeutic\ndiscovery. One class of techniques of growing interest for early-stage drug\ndiscovery is de novo molecular generation and optimization, catalyzed by the\ndevelopment of new deep learning approaches. These techniques can suggest novel\nmolecular structures intended to maximize a multi-objective function, e.g.,\nsuitability as a therapeutic against a particular target, without relying on\nbrute-force exploration of a chemical space. However, the utility of these\napproaches is stymied by ignorance of synthesizability. To highlight the\nseverity of this issue, we use a data-driven computer-aided synthesis planning\nprogram to quantify how often molecules proposed by state-of-the-art generative\nmodels cannot be readily synthesized. Our analysis demonstrates that there are\nseveral tasks for which these models generate unrealistic molecular structures\ndespite performing well on popular quantitative benchmarks. Synthetic\ncomplexity heuristics can successfully bias generation toward\nsynthetically-tractable chemical space, although doing so necessarily detracts\nfrom the primary objective. This analysis suggests that to improve the utility\nof these models in real discovery workflows, new algorithm development is\nwarranted.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:41:28 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gao", "Wenhao", ""], ["Coley", "Connor W.", ""]]}, {"id": "2002.07016", "submitter": "David Samuel", "authors": "David Samuel, Aditya Ganeshan and Jason Naradowsky", "title": "Meta-learning Extractors for Music Source Separation", "comments": "Camera-ready version for ICASSP 2020; the source files are published\n  at https://github.com/pfnet-research/meta-tasnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchical meta-learning-inspired model for music source\nseparation (Meta-TasNet) in which a generator model is used to predict the\nweights of individual extractor models. This enables efficient\nparameter-sharing, while still allowing for instrument-specific\nparameterization. Meta-TasNet is shown to be more effective than the models\ntrained independently or in a multi-task setting, and achieve performance\ncomparable with state-of-the-art methods. In comparison to the latter, our\nextractors contain fewer parameters and have faster run-time performance. We\ndiscuss important architectural considerations, and explore the costs and\nbenefits of this approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:00:03 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Samuel", "David", ""], ["Ganeshan", "Aditya", ""], ["Naradowsky", "Jason", ""]]}, {"id": "2002.07017", "submitter": "Marco Federici", "authors": "Marco Federici, Anjan Dutta, Patrick Forr\\'e, Nate Kushman, Zeynep\n  Akata", "title": "Learning Robust Representations via Multi-View Information Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information bottleneck principle provides an information-theoretic method\nfor representation learning, by training an encoder to retain all information\nwhich is relevant for predicting the label while minimizing the amount of\nother, excess information in the representation. The original formulation,\nhowever, requires labeled data to identify the superfluous information. In this\nwork, we extend this ability to the multi-view unsupervised setting, where two\nviews of the same underlying entity are provided but the label is unknown. This\nenables us to identify superfluous information as that not shared by both\nviews. A theoretical analysis leads to the definition of a new multi-view model\nthat produces state-of-the-art results on the Sketchy dataset and label-limited\nversions of the MIR-Flickr dataset. We also extend our theory to the\nsingle-view setting by taking advantage of standard data augmentation\ntechniques, empirically showing better generalization capabilities when\ncompared to common unsupervised approaches for representation learning.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:01:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 09:47:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Federici", "Marco", ""], ["Dutta", "Anjan", ""], ["Forr\u00e9", "Patrick", ""], ["Kushman", "Nate", ""], ["Akata", "Zeynep", ""]]}, {"id": "2002.07019", "submitter": "Mingzhe Wang", "authors": "Mingzhe Wang, Jia Deng", "title": "Learning to Prove Theorems by Learning to Generate Theorems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of automated theorem proving, a key AI task. Deep\nlearning has shown promise for training theorem provers, but there are limited\nhuman-written theorems and proofs available for supervised learning. To address\nthis limitation, we propose to learn a neural generator that automatically\nsynthesizes theorems and proofs for the purpose of training a theorem prover.\nExperiments on real-world tasks demonstrate that synthetic data from our\napproach improves the theorem prover and advances the state of the art of\nautomated theorem proving in Metamath. Code is available at\nhttps://github.com/princeton-vl/MetaGen.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:06:02 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 04:33:04 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Mingzhe", ""], ["Deng", "Jia", ""]]}, {"id": "2002.07024", "submitter": "Yahav Bechavod", "authors": "Yahav Bechavod, Katrina Ligett, Zhiwei Steven Wu, Juba Ziani", "title": "Gaming Helps! Learning from Strategic Interactions in Natural Dynamics", "comments": "The Conference version of this paper is to appear in the Proceedings\n  of AISTATS 2021. 27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an online regression setting in which individuals adapt to the\nregression model: arriving individuals are aware of the current model, and\ninvest strategically in modifying their own features so as to improve the\npredicted score that the current model assigns to them. Such feature\nmanipulation has been observed in various scenarios -- from credit assessment\nto school admissions -- posing a challenge for the learner. Surprisingly, we\nfind that such strategic manipulations may in fact help the learner recover the\nmeaningful variables -- that is, the features that, when changed, affect the\ntrue label (as opposed to non-meaningful features that have no effect). We show\nthat even simple behavior on the learner's part allows her to simultaneously i)\naccurately recover the meaningful features, and ii) incentivize agents to\ninvest in these meaningful features, providing incentives for improvement.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:09:37 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 19:04:00 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 15:45:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Bechavod", "Yahav", ""], ["Ligett", "Katrina", ""], ["Wu", "Zhiwei Steven", ""], ["Ziani", "Juba", ""]]}, {"id": "2002.07028", "submitter": "Srinadh Bhojanapalli", "authors": "Srinadh Bhojanapalli, Chulhee Yun, Ankit Singh Rawat, Sashank J.\n  Reddi, Sanjiv Kumar", "title": "Low-Rank Bottleneck in Multi-head Attention Models", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention based Transformer architecture has enabled significant advances in\nthe field of natural language processing. In addition to new pre-training\ntechniques, recent improvements crucially rely on working with a relatively\nlarger embedding dimension for tokens. Unfortunately, this leads to models that\nare prohibitively large to be employed in the downstream tasks. In this paper\nwe identify one of the important factors contributing to the large embedding\nsize requirement. In particular, our analysis highlights that the scaling\nbetween the number of heads and the size of each head in the current\narchitecture gives rise to a low-rank bottleneck in attention heads, causing\nthis limitation. We further validate this in our experiments. As a solution we\npropose to set the head size of an attention unit to input sequence length, and\nindependent of the number of heads, resulting in multi-head attention layers\nwith provably more expressive power. We empirically show that this allows us to\ntrain models with a relatively smaller embedding dimension and with better\nperformance scaling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 16:16:40 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Bhojanapalli", "Srinadh", ""], ["Yun", "Chulhee", ""], ["Rawat", "Ankit Singh", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2002.07031", "submitter": "Qilin Li", "authors": "Qilin Li, Wanquan Liu, Ling Li", "title": "Regularizing Semi-supervised Graph Convolutional Networks with a\n  Manifold Smoothness Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph convolutional networks focus on the neighborhood aggregation\nscheme. When applied to semi-supervised learning, they often suffer from the\noverfitting problem as the networks are trained with the cross-entropy loss on\na small potion of labeled data. In this paper, we propose an unsupervised\nmanifold smoothness loss defined with respect to the graph structure, which can\nbe added to the loss function as a regularization. We draw connections between\nthe proposed loss with an iterative diffusion process, and show that minimizing\nthe loss is equivalent to aggregate neighbor predictions with infinite layers.\nWe conduct experiments on multi-layer perceptron and existing graph networks,\nand demonstrate that adding the proposed loss can improve the performance\nconsistently.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:51:53 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Li", "Qilin", ""], ["Liu", "Wanquan", ""], ["Li", "Ling", ""]]}, {"id": "2002.07032", "submitter": "Andrea Manzoni", "authors": "Luca Rosafalco, Andrea Manzoni, Stefano Mariani, Alberto Corigliano", "title": "Fully convolutional networks for structural health monitoring through\n  multivariate time series classification", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to Structural Health Monitoring (SHM), aiming at\nthe automatic identification of damage-sensitive features from data acquired\nthrough pervasive sensor systems. Damage detection and localization are\nformulated as classification problems, and tackled through Fully Convolutional\nNetworks (FCNs). A supervised training of the proposed network architecture is\nperformed on data extracted from numerical simulations of a physics-based model\n(playing the role of digital twin of the structure to be monitored) accounting\nfor different damage scenarios. By relying on this simplified model of the\nstructure, several load conditions are considered during the training phase of\nthe FCN, whose architecture has been designed to deal with time series of\ndifferent length. The training of the neural network is done before the\nmonitoring system starts operating, thus enabling a real time damage\nclassification. The numerical performances of the proposed strategy are\nassessed on a numerical benchmark case consisting of an eight-story shear\nbuilding subjected to two load types, one of which modeling random vibrations\ndue to low-energy seismicity. Measurement noise has been added to the responses\nof the structure to mimic the outputs of a real monitoring system. Extremely\ngood classification capacities are shown: among the nine possible alternatives\n(represented by the healthy state and by a damage at any floor), damage is\ncorrectly classified in up to 95% of cases, thus showing the strong potential\nof the proposed approach in view of the application to real-life cases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:59:29 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rosafalco", "Luca", ""], ["Manzoni", "Andrea", ""], ["Mariani", "Stefano", ""], ["Corigliano", "Alberto", ""]]}, {"id": "2002.07033", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim,\n  Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo", "title": "Towards an Appropriate Query, Key, and Value Computation for Knowledge\n  Tracing", "comments": "L@S 2020", "journal-ref": null, "doi": "10.1145/3448139.3448188", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing, the act of modeling a student's knowledge through learning\nactivities, is an extensively studied problem in the field of computer-aided\neducation. Although models with attention mechanism have outperformed\ntraditional approaches such as Bayesian knowledge tracing and collaborative\nfiltering, they share two limitations. Firstly, the models rely on shallow\nattention layers and fail to capture complex relations among exercises and\nresponses over time. Secondly, different combinations of queries, keys and\nvalues for the self-attention layer for knowledge tracing were not extensively\nexplored. Usual practice of using exercises and interactions (exercise-response\npairs) as queries and keys/values respectively lacks empirical support. In this\npaper, we propose a novel Transformer based model for knowledge tracing, SAINT:\nSeparated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder\nstructure where exercise and response embedding sequence separately enter the\nencoder and the decoder respectively, which allows to stack attention layers\nmultiple times. To the best of our knowledge, this is the first work to suggest\nan encoder-decoder model for knowledge tracing that applies deep self-attentive\nlayers to exercises and responses separately. The empirical evaluations on a\nlarge-scale knowledge tracing dataset show that SAINT achieves the\nstate-of-the-art performance in knowledge tracing with the improvement of AUC\nby 1.8% compared to the current state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:21:19 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 05:14:09 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:57:13 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 01:02:22 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 02:42:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Cho", "Junghyun", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Cha", "Yeongmin", ""], ["Shin", "Dongmin", ""], ["Bae", "Chan", ""], ["Heo", "Jaewe", ""]]}, {"id": "2002.07036", "submitter": "Hyomin Choi", "authors": "Hyomin Choi and Robert A. Cohen and Ivan V. Bajic", "title": "Back-and-Forth prediction for deep tensor compression", "comments": "Accepted for publication in IEEE ICASSP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent AI applications such as Collaborative Intelligence with neural\nnetworks involve transferring deep feature tensors between various computing\ndevices. This necessitates tensor compression in order to optimize the usage of\nbandwidth-constrained channels between devices. In this paper we present a\nprediction scheme called Back-and-Forth (BaF) prediction, developed for deep\nfeature tensors, which allows us to dramatically reduce tensor size and improve\nits compressibility. Our experiments with a state-of-the-art object detector\ndemonstrate that the proposed method allows us to significantly reduce the\nnumber of bits needed for compressing feature tensors extracted from deep\nwithin the model, with negligible degradation of the detection performance and\nwithout requiring any retraining of the network weights. We achieve a 62% and\n75% reduction in tensor size while keeping the loss in accuracy of the network\nto less than 1% and 2%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 01:32:03 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Choi", "Hyomin", ""], ["Cohen", "Robert A.", ""], ["Bajic", "Ivan V.", ""]]}, {"id": "2002.07046", "submitter": "Yasuharu Nishi", "authors": "Adrian Wildandyawan, Yasuharu Nishi", "title": "Object-based Metamorphic Testing through Image Structuring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing software is often costly due to the need of mass-producing test cases\nand providing a test oracle for it. This is often referred to as the oracle\nproblem. One method that has been proposed in order to alleviate the oracle\nproblem is metamorphic testing. Metamorphic testing produces new test cases by\naltering an existing test case, and uses the metamorphic relation between the\ninputs and the outputs of the System Under Test (SUT) to predict the expected\noutputs of the produced test cases. Metamorphic testing has often been used for\nimage processing software, where changes are applied to the image's attributes\nto create new test cases with annotations that are the same as the original\nimage. We refer to this existing method as the image-based metamorphic testing.\nIn this research, we propose an object-based metamorphic testing and a\ncomposite metamorphic testing which combines different metamorphic testing\napproaches to relatively increase test coverage.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 10:32:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wildandyawan", "Adrian", ""], ["Nishi", "Yasuharu", ""]]}, {"id": "2002.07048", "submitter": "Saeed  Ranjbar Alvar", "authors": "Saeed Ranjbar Alvar and Ivan V. Baji\\'c", "title": "Bit Allocation for Multi-Task Collaborative Intelligence", "comments": "Accepted for publication ICASSP'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that collaborative intelligence (CI) is a promising\nframework for deployment of Artificial Intelligence (AI)-based services on\nmobile devices. In CI, a deep neural network is split between the mobile device\nand the cloud. Deep features obtained at the mobile are compressed and\ntransferred to the cloud to complete the inference. So far, the methods in the\nliterature focused on transferring a single deep feature tensor from the mobile\nto the cloud. Such methods are not applicable to some recent, high-performance\nnetworks with multiple branches and skip connections. In this paper, we propose\nthe first bit allocation method for multi-stream, multi-task CI. We first\nestablish a model for the joint distortion of the multiple tasks as a function\nof the bit rates assigned to different deep feature tensors. Then, using the\nproposed model, we solve the rate-distortion optimization problem under a total\nrate constraint to obtain the best rate allocation among the tensors to be\ntransferred. Experimental results illustrate the efficacy of the proposed\nscheme compared to several alternative bit allocation methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 02:02:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Alvar", "Saeed Ranjbar", ""], ["Baji\u0107", "Ivan V.", ""]]}, {"id": "2002.07051", "submitter": "Marcin Pietron", "authors": "Marcin Pietron and Maciej Wielgosz", "title": "Retrain or not retrain? -- efficient pruning methods of deep CNN\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) play a major role in image processing\ntasks like image classification, object detection, semantic segmentation. Very\noften CNN networks have from several to hundred stacked layers with several\nmegabytes of weights. One of the possible methods to reduce complexity and\nmemory footprint is pruning. Pruning is a process of removing weights which\nconnect neurons from two adjacent layers in the network. The process of finding\nnear optimal solution with specified drop in accuracy can be more sophisticated\nwhen DL model has higher number of convolutional layers. In the paper few\napproaches based on retraining and no retraining are described and compared\ntogether.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 23:24:28 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Pietron", "Marcin", ""], ["Wielgosz", "Maciej", ""]]}, {"id": "2002.07062", "submitter": "Mohit Sinha", "authors": "Phani Kumar Nyshadham, Mohit Sinha, Biswajit Mishra, H S Vijay", "title": "An optimal scheduling architecture for accelerating batch algorithms on\n  Neural Network processor architectures", "comments": "9 pages, page 7 contains the proposed example", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural network topologies, algorithms are running on batches of data\ntensors. The batches of data are typically scheduled onto the computing cores\nwhich execute in parallel. For the algorithms running on batches of data, an\noptimal batch scheduling architecture is very much needed by suitably utilizing\nhardware resources - thereby resulting in significant reduction training and\ninference time. In this paper, we propose to accelerate the batch algorithms\nfor neural networks through a scheduling architecture enabling optimal compute\npower utilization. The proposed optimal scheduling architecture can be built\ninto HW or can be implemented in SW alone which can be leveraged for\naccelerating batch algorithms. The results demonstrate that the proposed\narchitecture speeds up the batch algorithms compared to the previous solutions.\nThe proposed idea applies to any HPC architecture meant for neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:13:13 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Nyshadham", "Phani Kumar", ""], ["Sinha", "Mohit", ""], ["Mishra", "Biswajit", ""], ["Vijay", "H S", ""]]}, {"id": "2002.07064", "submitter": "Michele Gentili", "authors": "Michele Gentili, Leonardo Martini, Manuela Petti, Lorenzo Farina and\n  Luca Becchetti", "title": "Biological Random Walks: integrating heterogeneous data in disease gene\n  prioritization", "comments": null, "journal-ref": "2019 IEEE Conference on Computational Intelligence in\n  Bioinformatics and Computational Biology (CIBCB), 2019, 1-8", "doi": "10.1109/CIBCB.2019.8791472", "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a unified framework to leverage biological information in\nnetwork propagation-based gene prioritization algorithms. Preliminary results\non breast cancer data show significant improvements over state-of-the-art\nbaselines, such as the prioritization of genes that are not identified as\npotential candidates by interactome-based algorithms, but that appear to be\ninvolved in/or potentially related to breast cancer, according to a functional\nanalysis based on recent literature.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:46:35 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gentili", "Michele", ""], ["Martini", "Leonardo", ""], ["Petti", "Manuela", ""], ["Farina", "Lorenzo", ""], ["Becchetti", "Luca", ""]]}, {"id": "2002.07065", "submitter": "Xing Yong Kek", "authors": "Xing Yong Kek, Cheng Siong Chin, Ye Li", "title": "Acoustic Scene Classification Using Bilinear Pooling on Time-liked and\n  Frequency-liked Convolution Neural Network", "comments": "inclusion in conference proceedings 2019 IEEE Symposium Series on\n  Computational Intelligence (IEEE SSCI 2019), Xiamen", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current methodology in tackling Acoustic Scene Classification (ASC) task\ncan be described in two steps, preprocessing of the audio waveform into log-mel\nspectrogram and then using it as the input representation for Convolutional\nNeural Network (CNN). This paradigm shift occurs after DCASE 2016 where this\nframework model achieves the state-of-the-art result in ASC tasks on the\n(ESC-50) dataset and achieved an accuracy of 64.5%, which constitute to 20.5%\nimprovement over the baseline model, and DCASE 2016 dataset with an accuracy of\n90.0% (development) and 86.2% (evaluation), which constitute a 6.4% and 9%\nimprovements with respect to the baseline system. In this paper, we explored\nthe use of harmonic and percussive source separation (HPSS) to split the audio\ninto harmonic audio and percussive audio, which has received popularity in the\nfield of music information retrieval (MIR). Although works have been done in\nusing HPSS as input representation for CNN model in ASC task, this paper\nfurther investigate the possibility on leveraging the separated harmonic\ncomponent and percussive component by curating 2 CNNs which tries to understand\nharmonic audio and percussive audio in their natural form, one specialized in\nextracting deep features in time biased domain and another specialized in\nextracting deep features in frequency biased domain, respectively. The deep\nfeatures extracted from these 2 CNNs will then be combined using bilinear\npooling. Hence, presenting a two-stream time and frequency CNN architecture\napproach in classifying acoustic scene. The model is being evaluated on DCASE\n2019 sub task 1a dataset and scored an average of 65% on development dataset,\nKaggle Leadership Private and Public board.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:06:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Kek", "Xing Yong", ""], ["Chin", "Cheng Siong", ""], ["Li", "Ye", ""]]}, {"id": "2002.07066", "submitter": "Yudong Chen", "authors": "Qiaomin Xie, Yudong Chen, Zhaoran Wang, Zhuoran Yang", "title": "Learning Zero-Sum Simultaneous-Move Markov Games Using Function\n  Approximation and Correlated Equilibrium", "comments": "Accepted for presentation at COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop provably efficient reinforcement learning algorithms for\ntwo-player zero-sum finite-horizon Markov games with simultaneous moves. To\nincorporate function approximation, we consider a family of Markov games where\nthe reward function and transition kernel possess a linear structure. Both the\noffline and online settings of the problems are considered. In the offline\nsetting, we control both players and aim to find the Nash Equilibrium by\nminimizing the duality gap. In the online setting, we control a single player\nplaying against an arbitrary opponent and aim to minimize the regret. For both\nsettings, we propose an optimistic variant of the least-squares minimax value\niteration algorithm. We show that our algorithm is computationally efficient\nand provably achieves an $\\tilde O(\\sqrt{d^3 H^3 T} )$ upper bound on the\nduality gap and regret, where $d$ is the linear dimension, $H$ the horizon and\n$T$ the total number of timesteps. Our results do not require additional\nassumptions on the sampling model.\n  Our setting requires overcoming several new challenges that are absent in\nMarkov decision processes or turn-based Markov games. In particular, to achieve\noptimism with simultaneous moves, we construct both upper and lower confidence\nbounds of the value function, and then compute the optimistic policy by solving\na general-sum matrix game with these bounds as the payoff matrices. As finding\nthe Nash Equilibrium of a general-sum game is computationally hard, our\nalgorithm instead solves for a Coarse Correlated Equilibrium (CCE), which can\nbe obtained efficiently. To our best knowledge, such a CCE-based scheme for\noptimism has not appeared in the literature and might be of interest in its own\nright.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:04:16 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 21:38:20 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 21:09:42 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Xie", "Qiaomin", ""], ["Chen", "Yudong", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""]]}, {"id": "2002.07069", "submitter": "Daniel Griffin", "authors": "Daniel K. Griffin", "title": "The Big Three: A Methodology to Increase Data Science ROI by Answering\n  the Questions Companies Care About", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Companies may be achieving only a third of the value they could be getting\nfrom data science in industry applications. In this paper, we propose a\nmethodology for categorizing and answering 'The Big Three' questions (what is\ngoing on, what is causing it, and what actions can I take that will optimize\nwhat I care about) using data science. The applications of data science seem to\nbe nearly endless in today's modern landscape, with each company jockeying for\nposition in the new data and insights economy. Yet, data scientists seem to be\nsolely focused on using classification, regression, and clustering methods to\nanswer the question 'what is going on'. Answering questions about why things\nare happening or how to take optimal actions to improve metrics are relegated\nto niche fields of research and generally neglected in industry data science\nanalysis. We survey technical methods to answer these other important\nquestions, describe areas in which some of these methods are being applied, and\nprovide a practical example of how to apply our methodology and selected\nmethods to a real business use case.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 21:25:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Griffin", "Daniel K.", ""]]}, {"id": "2002.07076", "submitter": "Florian Adriaens", "authors": "Florian Adriaens, Alexandru Mara, Jefrey Lijffijt, Tijl De Bie", "title": "Block-Approximated Exponential Random Graphs", "comments": "Accepted for DSAA 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge in the field of exponential random graphs (ERGs) is\nthe fitting of non-trivial ERGs on large graphs. By utilizing fast matrix\nblock-approximation techniques, we propose an approximative framework to such\nnon-trivial ERGs that result in dyadic independence (i.e., edge independent)\ndistributions, while being able to meaningfully model both local information of\nthe graph (e.g., degrees) as well as global information (e.g., clustering\ncoefficient, assortativity, etc.) if desired. This allows one to efficiently\ngenerate random networks with similar properties as an observed network, and\nthe models can be used for several downstream tasks such as link prediction.\nOur methods are scalable to sparse graphs consisting of millions of nodes.\nEmpirical evaluation demonstrates competitiveness in terms of both speed and\naccuracy with state-of-the-art methods -- which are typically based on\nembedding the graph into some low-dimensional space -- for link prediction,\nshowcasing the potential of a more direct and interpretable probabalistic model\nfor this task.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:42:16 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 13:42:09 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Adriaens", "Florian", ""], ["Mara", "Alexandru", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.07082", "submitter": "Shiv Ram Dubey", "authors": "Kancharagunta Kishan Babu and Shiv Ram Dubey", "title": "PCSGAN: Perceptual Cyclic-Synthesized Generative Adversarial Networks\n  for Thermal and NIR to Visible Image Transformation", "comments": "Published in Neurocomputing Journal, Elsevier", "journal-ref": "Neurocomputing, 413:41-50, Nov 2020", "doi": "10.1016/j.neucom.2020.06.104", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world scenarios, it is difficult to capture the images in the\nvisible light spectrum (VIS) due to bad lighting conditions. However, the\nimages can be captured in such scenarios using Near-Infrared (NIR) and Thermal\n(THM) cameras. The NIR and THM images contain the limited details. Thus, there\nis a need to transform the images from THM/NIR to VIS for better understanding.\nHowever, it is non-trivial task due to the large domain discrepancies and lack\nof abundant datasets. Nowadays, Generative Adversarial Network (GAN) is able to\ntransform the images from one domain to another domain. Most of the available\nGAN based methods use the combination of the adversarial and the pixel-wise\nlosses (like $L_1$ or $L_2$) as the objective function for training. The\nquality of transformed images in case of THM/NIR to VIS transformation is still\nnot up to the mark using such objective function. Thus, better objective\nfunctions are needed to improve the quality, fine details and realism of the\ntransformed images. A new model for THM/NIR to VIS image transformation called\nPerceptual Cyclic-Synthesized Generative Adversarial Network (PCSGAN) is\nintroduced to address these issues. The PCSGAN uses the combination of the\nperceptual (i.e., feature based) losses along with the pixel-wise and the\nadversarial losses. Both the quantitative and qualitative measures are used to\njudge the performance of the PCSGAN model over the WHU-IIP face and the RGB-NIR\nscene datasets. The proposed PCSGAN outperforms the state-of-the-art image\ntransformation models, including Pix2pix, DualGAN, CycleGAN, PS2GAN, and PAN in\nterms of the SSIM, MSE, PSNR and LPIPS evaluation measures. The code is\navailable at https://github.com/KishanKancharagunta/PCSGAN.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 11:55:03 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 11:50:33 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Babu", "Kancharagunta Kishan", ""], ["Dubey", "Shiv Ram", ""]]}, {"id": "2002.07087", "submitter": "Daniel Flam-Shepherd", "authors": "Daniel Flam-Shepherd, Tony Wu and Alan Aspuru-Guzik", "title": "Graph Deconvolutional Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph generation is an extremely important task, as graphs are found\nthroughout different areas of science and engineering. In this work, we focus\non the modern equivalent of the Erdos-Renyi random graph model: the graph\nvariational autoencoder (GVAE). This model assumes edges and nodes are\nindependent in order to generate entire graphs at a time using a multi-layer\nperceptron decoder. As a result of these assumptions, GVAE has difficulty\nmatching the training distribution and relies on an expensive graph matching\nprocedure. We improve this class of models by building a message passing neural\nnetwork into GVAE's encoder and decoder. We demonstrate our model on the\nspecific task of generating small organic molecules\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 04:37:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Flam-Shepherd", "Daniel", ""], ["Wu", "Tony", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2002.07088", "submitter": "Ryan Feng", "authors": "Ryan Feng, Jiefeng Chen, Earlence Fernandes, Somesh Jha, Atul Prakash", "title": "Robust Physical Hard-Label Attacks on Deep Learning Visual\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing physical adversarial examples for computer vision rely on white-box\naccess. In this work, we investigate physical examples in the black-box\nhard-label case -- where the attacker has only query access to the model and\nonly receives the top-1 class label without confidence information. This threat\nmodel is more realistic for cyber-physical systems -- the main target when\nconsidering physical attacks on computer vision. Key challenges in this setting\ninclude obtaining reliability against environmental variations and creating\narea-limited perturbations without access to model gradients. We base our work\non recent advances in gradient-free optimization and present GRAPHITE, the\nfirst algorithm for black-box hard-label physical attacks on computer vision\nmodels. We evaluate GRAPHITE on a traffic sign classifier and a\npublicly-available Automatic License Plate Recognition (ALPR) tool using only\nquery access. We successfully cause a Stop sign to be misclassified as a Speed\nLimit 30 in 92.9% of physical test images and cause errors in 95% of cases for\nthe ALPR tool.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:24:14 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 21:13:32 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 21:01:43 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Feng", "Ryan", ""], ["Chen", "Jiefeng", ""], ["Fernandes", "Earlence", ""], ["Jha", "Somesh", ""], ["Prakash", "Atul", ""]]}, {"id": "2002.07089", "submitter": "Samaneh Abbasi Sureshjani", "authors": "Samaneh Abbasi-Sureshjani, Sina Amirrajab, Cristian Lorenz, Juergen\n  Weese, Josien Pluim, Marcel Breeuwer", "title": "4D Semantic Cardiac Magnetic Resonance Image Synthesis on XCAT\n  Anatomical Model", "comments": "Accepted to MIDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hybrid controllable image generation method to synthesize\nanatomically meaningful 3D+t labeled Cardiac Magnetic Resonance (CMR) images.\nOur hybrid method takes the mechanistic 4D eXtended CArdiac Torso (XCAT) heart\nmodel as the anatomical ground truth and synthesizes CMR images via a\ndata-driven Generative Adversarial Network (GAN). We employ the\nstate-of-the-art SPatially Adaptive De-normalization (SPADE) technique for\nconditional image synthesis to preserve the semantic spatial information of\nground truth anatomy. Using the parameterized motion model of the XCAT heart,\nwe generate labels for 25 time frames of the heart for one cardiac cycle at 18\nlocations for the short axis view. Subsequently, realistic images are generated\nfrom these labels, with modality-specific features that are learned from real\nCMR image data. We demonstrate that style transfer from another cardiac image\ncan be accomplished by using a style encoder network. Due to the flexibility of\nXCAT in creating new heart models, this approach can result in a realistic\nvirtual population to address different challenges the medical image analysis\nresearch community is facing such as expensive data collection. Our proposed\nmethod has a great potential to synthesize 4D controllable CMR images with\nannotations and adaptable styles to be used in various supervised multi-site,\nmulti-vendor applications in medical image analysis.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:25:07 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 16:55:32 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 14:01:13 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Abbasi-Sureshjani", "Samaneh", ""], ["Amirrajab", "Sina", ""], ["Lorenz", "Cristian", ""], ["Weese", "Juergen", ""], ["Pluim", "Josien", ""], ["Breeuwer", "Marcel", ""]]}, {"id": "2002.07101", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, Laurent Dinh, Aaron Courville", "title": "Augmented Normalizing Flows: Bridging the Gap Between Generative Flows\n  and Latent Variable Models", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new family of generative flows on an augmented\ndata space, with an aim to improve expressivity without drastically increasing\nthe computational cost of sampling and evaluation of a lower bound on the\nlikelihood. Theoretically, we prove the proposed flow can approximate a\nHamiltonian ODE as a universal transport map. Empirically, we demonstrate\nstate-of-the-art performance on standard benchmarks of flow-based generative\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:45:48 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Dinh", "Laurent", ""], ["Courville", "Aaron", ""]]}, {"id": "2002.07106", "submitter": "Ankur Bapna", "authors": "Ankur Bapna, Naveen Arivazhagan, Orhan Firat", "title": "Controlling Computation versus Quality for Neural Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural networks utilize the same amount of compute for every example\nindependent of the inherent complexity of the input. Further, methods that\nadapt the amount of computation to the example focus on finding a fixed\ninference-time computational graph per example, ignoring any external\ncomputational budgets or varying inference time limitations. In this work, we\nutilize conditional computation to make neural sequence models (Transformer)\nmore efficient and computation-aware during inference. We first modify the\nTransformer architecture, making each set of operations conditionally\nexecutable depending on the output of a learned control network. We then train\nthis model in a multi-task setting, where each task corresponds to a particular\ncomputation budget. This allows us to train a single model that can be\ncontrolled to operate on different points of the computation-quality trade-off\ncurve, depending on the available computation budget at inference time. We\nevaluate our approach on two tasks: (i) WMT English-French Translation and (ii)\nUnsupervised representation learning (BERT). Our experiments demonstrate that\nthe proposed Conditional Computation Transformer (CCT) is competitive with\nvanilla Transformers when allowed to utilize its full computational budget,\nwhile improving significantly over computationally equivalent baselines when\noperating on smaller computational budgets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:54:27 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 15:01:45 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bapna", "Ankur", ""], ["Arivazhagan", "Naveen", ""], ["Firat", "Orhan", ""]]}, {"id": "2002.07111", "submitter": "Muhammad Umer", "authors": "Muhammad Umer, Glenn Dawson, Robi Polikar", "title": "Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or \"incremental\") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC's defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary's ability to assume\ncontrol of the model via injection of \"backdoor\" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a \"false memory\" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:13:09 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Umer", "Muhammad", ""], ["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2002.07113", "submitter": "Alaa Abdel-Hakim Ph. D.", "authors": "Alaa E. Abdel-Hakim and Wael Deabes", "title": "Handling Missing Annotations in Supervised Learning Data", "comments": "14 pages, 13 figures, 2 tables", "journal-ref": "Abdel Hakim, Alaa E., and Wael Deabes. \"Can People Really Do\n  Nothing? Handling Annotation Gaps in ADL Sensor Data.\" Algorithms 12, no. 10\n  (2019): 217", "doi": "10.3390/a12100217", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data annotation is an essential stage in supervised learning. However, the\nannotation process is exhaustive and time consuming, specially for large\ndatasets. Activities of Daily Living (ADL) recognition is an example of systems\nthat exploit very large raw sensor data readings. In such systems, sensor\nreadings are collected from activity-monitoring sensors in a 24/7 manner. The\nsize of the generated dataset is so huge that it is almost impossible for a\nhuman annotator to give a certain label to every single instance in the\ndataset. This results in annotation gaps in the input data to the adopting\nsupervised learning system. The performance of the recognition system is\nnegatively affected by these gaps. In this work, we propose and investigate\nthree different paradigms to handle these gaps. In the first paradigm, the gaps\nare taken out by dropping all unlabeled readings. A single \"Unknown\" or\n\"Do-Nothing\" label is given to the unlabeled readings within the operation of\nthe second paradigm. The last paradigm handles these gaps by giving every one\nof them a unique label identifying the encapsulating deterministic labels.\nAlso, we propose a semantic preprocessing method of annotation gaps by\nconstructing a hybrid combination of some of these paradigms for further\nperformance improvement. The performance of the proposed three paradigms and\ntheir hybrid combination is evaluated using an ADL benchmark dataset containing\nmore than $2.5\\times 10^6$ sensor readings that had been collected over more\nthan nine months. The evaluation results emphasize the performance contrast\nunder the operation of each paradigm and support a specific gap handling\napproach for better performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:23:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Abdel-Hakim", "Alaa E.", ""], ["Deabes", "Wael", ""]]}, {"id": "2002.07125", "submitter": "Simon Du", "authors": "Simon S. Du, Jason D. Lee, Gaurav Mahajan, Ruosong Wang", "title": "Agnostic Q-learning with Function Approximation in Deterministic\n  Systems: Tight Bounds on Approximation Error and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current paper studies the problem of agnostic $Q$-learning with function\napproximation in deterministic systems where the optimal $Q$-function is\napproximable by a function in the class $\\mathcal{F}$ with approximation error\n$\\delta \\ge 0$. We propose a novel recursion-based algorithm and show that if\n$\\delta = O\\left(\\rho/\\sqrt{\\dim_E}\\right)$, then one can find the optimal\npolicy using $O\\left(\\dim_E\\right)$ trajectories, where $\\rho$ is the gap\nbetween the optimal $Q$-value of the best actions and that of the second-best\nactions and $\\dim_E$ is the Eluder dimension of $\\mathcal{F}$. Our result has\ntwo implications:\n  1) In conjunction with the lower bound in [Du et al., ICLR 2020], our upper\nbound suggests that the condition $\\delta =\n\\widetilde{\\Theta}\\left(\\rho/\\sqrt{\\mathrm{dim}_E}\\right)$ is necessary and\nsufficient for algorithms with polynomial sample complexity.\n  2) In conjunction with the lower bound in [Wen and Van Roy, NIPS 2013], our\nupper bound suggests that the sample complexity\n$\\widetilde{\\Theta}\\left(\\mathrm{dim}_E\\right)$ is tight even in the agnostic\nsetting.\n  Therefore, we settle the open problem on agnostic $Q$-learning proposed in\n[Wen and Van Roy, NIPS 2013]. We further extend our algorithm to the stochastic\nreward setting and obtain similar results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:41:49 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Du", "Simon S.", ""], ["Lee", "Jason D.", ""], ["Mahajan", "Gaurav", ""], ["Wang", "Ruosong", ""]]}, {"id": "2002.07128", "submitter": "Arijit Sehanobish", "authors": "Neal G. Ravindra, Arijit Sehanobish, Jenna L. Pappalardo, David A.\n  Hafler, David van Dijk", "title": "Disease State Prediction From Single-Cell Data Using Graph Attention\n  Networks", "comments": "Incorporated suggestions from anonymous reviewers, Accepted at ACM\n  CHIL 2020, comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-cell RNA sequencing (scRNA-seq) has revolutionized biological\ndiscovery, providing an unbiased picture of cellular heterogeneity in tissues.\nWhile scRNA-seq has been used extensively to provide insight into both healthy\nsystems and diseases, it has not been used for disease prediction or\ndiagnostics. Graph Attention Networks (GAT) have proven to be versatile for a\nwide range of tasks by learning from both original features and graph\nstructures. Here we present a graph attention model for predicting disease\nstate from single-cell data on a large dataset of Multiple Sclerosis (MS)\npatients. MS is a disease of the central nervous system that can be difficult\nto diagnose. We train our model on single-cell data obtained from blood and\ncerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy\nadults (HA), resulting in 66,667 individual cells. We achieve 92 % accuracy in\npredicting MS, outperforming other state-of-the-art methods such as a graph\nconvolutional network and a random forest classifier. Further, we use the\nlearned graph attention model to get insight into the features (cell types and\ngenes) that are important for this prediction. The graph attention model also\nallow us to infer a new feature space for the cells that emphasizes the\ndifferences between the two conditions. Finally we use the attention weights to\nlearn a new low-dimensional embedding that can be visualized. To the best of\nour knowledge, this is the first effort to use graph attention, and deep\nlearning in general, to predict disease state from single-cell data. We\nenvision applying this method to single-cell data for other diseases.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 16:08:30 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 21:29:15 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Ravindra", "Neal G.", ""], ["Sehanobish", "Arijit", ""], ["Pappalardo", "Jenna L.", ""], ["Hafler", "David A.", ""], ["van Dijk", "David", ""]]}, {"id": "2002.07136", "submitter": "Yichi Zhang", "authors": "Yichi Zhang, Ritchie Zhao, Weizhe Hua, Nayun Xu, G. Edward Suh, Zhiru\n  Zhang", "title": "Precision Gating: Improving Neural Network Efficiency with Dynamic\n  Dual-Precision Activations", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose precision gating (PG), an end-to-end trainable dynamic\ndual-precision quantization technique for deep neural networks. PG computes\nmost features in a low precision and only a small proportion of important\nfeatures in a higher precision to preserve accuracy. The proposed approach is\napplicable to a variety of DNN architectures and significantly reduces the\ncomputational cost of DNN execution with almost no accuracy loss. Our\nexperiments indicate that PG achieves excellent results on CNNs, including\nstatically compressed mobile-friendly networks such as ShuffleNet. Compared to\nthe state-of-the-art prediction-based quantization schemes, PG achieves the\nsame or higher accuracy with 2.4$\\times$ less compute on ImageNet. PG\nfurthermore applies to RNNs. Compared to 8-bit uniform quantization, PG obtains\na 1.2% improvement in perplexity per word with 2.7$\\times$ computational cost\nreduction on LSTM on the Penn Tree Bank dataset. Code is available at:\nhttps://github.com/cornell-zhang/dnn-gating\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:54:37 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 03:10:27 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Zhang", "Yichi", ""], ["Zhao", "Ritchie", ""], ["Hua", "Weizhe", ""], ["Xu", "Nayun", ""], ["Suh", "G. Edward", ""], ["Zhang", "Zhiru", ""]]}, {"id": "2002.07141", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis", "title": "Subset Sampling For Progressive Neural Network Learning", "comments": "accepted in ICIP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progressive Neural Network Learning is a class of algorithms that\nincrementally construct the network's topology and optimize its parameters\nbased on the training data. While this approach exempts the users from the\nmanual task of designing and validating multiple network topologies, it often\nrequires an enormous number of computations. In this paper, we propose to speed\nup this process by exploiting subsets of training data at each incremental\ntraining step. Three different sampling strategies for selecting the training\nsamples according to different criteria are proposed and evaluated. We also\npropose to perform online hyperparameter selection during the network\nprogression, which further reduces the overall training time. Experimental\nresults in object, scene and face recognition problems demonstrate that the\nproposed approach speeds up the optimization procedure considerably while\noperating on par with the baseline approach exploiting the entire training set\nthroughout the training process.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:57:33 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:47:19 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2002.07147", "submitter": "Aaron Roth", "authors": "Christopher Jung and Sampath Kannan and Changhwa Lee and Mallesh M.\n  Pai and Aaron Roth and Rakesh Vohra", "title": "Fair Prediction with Endogenous Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.AI cs.GT cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing regulatory interest in whether machine learning\nalgorithms deployed in consequential domains (e.g. in criminal justice) treat\ndifferent demographic groups \"fairly.\" However, there are several proposed\nnotions of fairness, typically mutually incompatible. Using criminal justice as\nan example, we study a model in which society chooses an incarceration rule.\nAgents of different demographic groups differ in their outside options (e.g.\nopportunity for legal employment) and decide whether to commit crimes. We show\nthat equalizing type I and type II errors across groups is consistent with the\ngoal of minimizing the overall crime rate; other popular notions of fairness\nare not.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:07:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lee", "Changhwa", ""], ["Pai", "Mallesh M.", ""], ["Roth", "Aaron", ""], ["Vohra", "Rakesh", ""]]}, {"id": "2002.07161", "submitter": "Marco Virgolin", "authors": "M. Virgolin, Z. Wang, B.V. Balgobind, I.W.E.M. van Dijk, J. Wiersma,\n  P.S. Kroon, G.O. Janssens, M. van Herk, D.C. Hodgson, L. Zadravec Zaletel,\n  C.R.N. Rasch, A. Bel, P.A.N. Bosman, T. Alderliesten", "title": "Surrogate-free machine learning-based organ dose reconstruction for\n  pediatric abdominal radiotherapy", "comments": "M. Virgolin and Z. Wang share first authorship", "journal-ref": "Physics in Medicine & Biology. 2020 Dec 8;65(24):245021", "doi": "10.1088/1361-6560/ab9fcc", "report-no": null, "categories": "physics.med-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To study radiotherapy-related adverse effects, detailed dose information (3D\ndistribution) is needed for accurate dose-effect modeling. For childhood cancer\nsurvivors who underwent radiotherapy in the pre-CT era, only 2D radiographs\nwere acquired, thus 3D dose distributions must be reconstructed from limited\ninformation. State-of-the-art methods achieve this by using 3D surrogate\nanatomies. These can lack personalization and lead to coarse reconstructions.\nWe present and validate a surrogate-free dose reconstruction method based on\nMachine Learning (ML). Abdominal planning CTs ($n$=142) of recently-treated\nchildhood cancer patients were gathered, their organs at risk were segmented,\nand 300 artificial Wilms' tumor plans were sampled automatically. Each\nartificial plan was automatically emulated on the 142 CTs, resulting in 42,600\n3D dose distributions from which dose-volume metrics were derived. Anatomical\nfeatures were extracted from digitally reconstructed radiographs simulated from\nthe CTs to resemble historical radiographs. Further, patient and radiotherapy\nplan features typically available from historical treatment records were\ncollected. An evolutionary ML algorithm was then used to link features to\ndose-volume metrics. Besides 5-fold cross-validation, a further evaluation was\ndone on an independent dataset of five CTs each associated with two clinical\nplans. Cross-validation resulted in Mean Absolute Errors (MAEs) $\\leq$0.6 Gy\nfor organs completely inside or outside the field. For organs positioned at the\nedge of the field, MAEs $\\leq$1.7 Gy for D$_{mean}$, $\\leq$2.9 Gy for\nD$_{2cc}$, and $\\leq$13% for V$_{5Gy}$ and V$_{10Gy}$, were obtained, without\nsystematic bias. Similar results were found for the independent dataset. Our\nnovel, ML-based organ dose reconstruction method is not only accurate but also\nefficient, as the setup of a surrogate is no longer needed.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 04:19:01 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 17:30:15 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Virgolin", "M.", ""], ["Wang", "Z.", ""], ["Balgobind", "B. V.", ""], ["van Dijk", "I. W. E. M.", ""], ["Wiersma", "J.", ""], ["Kroon", "P. S.", ""], ["Janssens", "G. O.", ""], ["van Herk", "M.", ""], ["Hodgson", "D. C.", ""], ["Zaletel", "L. Zadravec", ""], ["Rasch", "C. R. N.", ""], ["Bel", "A.", ""], ["Bosman", "P. A. N.", ""], ["Alderliesten", "T.", ""]]}, {"id": "2002.07171", "submitter": "Shirli Di-Castro Shashua", "authors": "Shirli Di-Castro Shashua, Shie Mannor", "title": "Kalman meets Bellman: Improving Policy Evaluation through Value Tracking", "comments": "arXiv admin note: substantial text overlap with arXiv:1901.07860", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation is a key process in Reinforcement Learning (RL). It\nassesses a given policy by estimating the corresponding value function. When\nusing parameterized value functions, common approaches minimize the sum of\nsquared Bellman temporal-difference errors and receive a point-estimate for the\nparameters. Kalman-based and Gaussian-processes based frameworks were suggested\nto evaluate the policy by treating the value as a random variable. These\nframeworks can learn uncertainties over the value parameters and exploit them\nfor policy exploration. When adopting these frameworks to solve deep RL tasks,\nseveral limitations are revealed: excessive computations in each optimization\nstep, difficulty with handling batches of samples which slows training and the\neffect of memory in stochastic environments which prevents off-policy learning.\nIn this work, we discuss these limitations and propose to overcome them by an\nalternative general framework, based on the extended Kalman filter. We devise\nan optimization method, called Kalman Optimization for Value Approximation\n(KOVA) that can be incorporated as a policy evaluation component in policy\noptimization algorithms. KOVA minimizes a regularized objective function that\nconcerns both parameter and noisy return uncertainties. We analyze the\nproperties of KOVA and present its performance on deep RL control tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:30:43 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shashua", "Shirli Di-Castro", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.07173", "submitter": "Koosha Zarei", "authors": "Koosha Zarei, Reza Farahbakhsh, Noel Crespi", "title": "How Impersonators Exploit Instagram to Generate Fake Engagement?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Impersonators on Online Social Networks such as Instagram are playing an\nimportant role in the propagation of the content. These entities are the type\nof nefarious fake accounts that intend to disguise a legitimate account by\nmaking similar profiles. In addition to having impersonated profiles, we\nobserved a considerable engagement from these entities to the published posts\nof verified accounts. Toward that end, we concentrate on the engagement of\nimpersonators in terms of active and passive engagements which is studied in\nthree major communities including ``Politician'', ``News agency'', and ``Sports\nstar'' on Instagram. Inside each community, four verified accounts have been\nselected. Based on the implemented approach in our previous studies, we have\ncollected 4.8K comments, and 2.6K likes across 566 posts created from 3.8K\nimpersonators during 7 months. Our study shed light into this interesting\nphenomena and provides a surprising observation that can help us to understand\nbetter how impersonators engaging themselves inside Instagram in terms of\nwriting Comments and leaving Likes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 14:53:01 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zarei", "Koosha", ""], ["Farahbakhsh", "Reza", ""], ["Crespi", "Noel", ""]]}, {"id": "2002.07206", "submitter": "Jiyang Bai", "authors": "Jiyang Bai, Yuxiang Ren, Jiawei Zhang", "title": "Ripple Walk Training: A Subgraph-based training framework for Large and\n  Deep Graph Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have achieved outstanding performance in\nlearning graph-structured data and various tasks. However, many current GNNs\nsuffer from three common problems when facing large-size graphs or using a\ndeeper structure: neighbors explosion, node dependence, and oversmoothing. Such\nproblems attribute to the data structures of the graph itself or the designing\nof the multi-layers GNNs framework, and can lead to low training efficiency and\nhigh space complexity. To deal with these problems, in this paper, we propose a\ngeneral subgraph-based training framework, namely Ripple Walk Training (RWT),\nfor deep and large graph neural networks. RWT samples subgraphs from the full\ngraph to constitute a mini-batch, and the full GNN is updated based on the\nmini-batch gradient. We analyze the high-quality subgraphs to train GNNs in a\ntheoretical way. A novel sampling method Ripple Walk Sampler works for sampling\nthese high-quality subgraphs to constitute the mini-batch, which considers both\nthe randomness and connectivity of the graph-structured data. Extensive\nexperiments on different sizes of graphs demonstrate the effectiveness and\nefficiency of RWT in training various GNNs (GCN & GAT).\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:07:41 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 17:22:50 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 16:22:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "2002.07214", "submitter": "Ziwei Guan", "authors": "Ziwei Guan, Kaiyi Ji, Donald J Bucci Jr, Timothy Y Hu, Joseph Palombo,\n  Michael Liston, Yingbin Liang", "title": "Robust Stochastic Bandit Algorithms under Probabilistic Unbounded\n  Adversarial Attack", "comments": "Published at AAAI'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-armed bandit formalism has been extensively studied under various\nattack models, in which an adversary can modify the reward revealed to the\nplayer. Previous studies focused on scenarios where the attack value either is\nbounded at each round or has a vanishing probability of occurrence. These\nmodels do not capture powerful adversaries that can catastrophically perturb\nthe revealed reward. This paper investigates the attack model where an\nadversary attacks with a certain probability at each round, and its attack\nvalue can be arbitrary and unbounded if it attacks. Furthermore, the attack\nvalue does not necessarily follow a statistical distribution. We propose a\nnovel sample median-based and exploration-aided UCB algorithm (called\nmed-E-UCB) and a median-based $\\epsilon$-greedy algorithm (called\nmed-$\\epsilon$-greedy). Both of these algorithms are provably robust to the\naforementioned attack model. More specifically we show that both algorithms\nachieve $\\mathcal{O}(\\log T)$ pseudo-regret (i.e., the optimal regret without\nattacks). We also provide a high probability guarantee of $\\mathcal{O}(\\log T)$\nregret with respect to random rewards and random occurrence of attacks. These\nbounds are achieved under arbitrary and unbounded reward perturbation as long\nas the attack probability does not exceed a certain constant threshold. We\nprovide multiple synthetic simulations of the proposed algorithms to verify\nthese claims and showcase the inability of existing techniques to achieve\nsublinear regret. We also provide experimental results of the algorithm\noperating in a cognitive radio setting using multiple software-defined radios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:21:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Guan", "Ziwei", ""], ["Ji", "Kaiyi", ""], ["Bucci", "Donald J", "Jr"], ["Hu", "Timothy Y", ""], ["Palombo", "Joseph", ""], ["Liston", "Michael", ""], ["Liang", "Yingbin", ""]]}, {"id": "2002.07215", "submitter": "Ali HeydariGorji", "authors": "Ali HeydariGorji, Mahdi Torabzadehkashi, Siavash Rezaei, Hossein\n  Bobarshad, Vladimir Alves, Pai H. Chou", "title": "STANNIS: Low-Power Acceleration of Deep Neural Network Training Using\n  Computational Storage", "comments": null, "journal-ref": null, "doi": "10.1109/DAC18072.2020.9218687", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a framework for distributed, in-storage training of\nneural networks on clusters of computational storage devices. Such devices not\nonly contain hardware accelerators but also eliminate data movement between the\nhost and storage, resulting in both improved performance and power savings.\nMore importantly, this in-storage processing style of training ensures that\nprivate data never leaves the storage while fully controlling the sharing of\npublic data. Experimental results show up to 2.7x speedup and 69% reduction in\nenergy consumption and no significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:22:35 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 18:56:52 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["HeydariGorji", "Ali", ""], ["Torabzadehkashi", "Mahdi", ""], ["Rezaei", "Siavash", ""], ["Bobarshad", "Hossein", ""], ["Alves", "Vladimir", ""], ["Chou", "Pai H.", ""]]}, {"id": "2002.07217", "submitter": "Romain Lopez", "authors": "Romain Lopez, Pierre Boyeau, Nir Yosef, Michael I. Jordan and Jeffrey\n  Regier", "title": "Decision-Making with Auto-Encoding Variational Bayes", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To make decisions based on a model fit with auto-encoding variational Bayes\n(AEVB), practitioners often let the variational distribution serve as a\nsurrogate for the posterior distribution. This approach yields biased estimates\nof the expected risk, and therefore leads to poor decisions for two reasons.\nFirst, the model fit with AEVB may not equal the underlying data distribution.\nSecond, the variational distribution may not equal the posterior distribution\nunder the fitted model. We explore how fitting the variational distribution\nbased on several objective functions other than the ELBO, while continuing to\nfit the generative model based on the ELBO, affects the quality of downstream\ndecisions. For the probabilistic principal component analysis model, we\ninvestigate how importance sampling error, as well as the bias of the model\nparameter estimates, varies across several approximate posteriors when used as\nproposal distributions. Our theoretical results suggest that a posterior\napproximation distinct from the variational distribution should be used for\nmaking decisions. Motivated by these theoretical results, we propose learning\nseveral approximate proposals for the best model and combining them using\nmultiple importance sampling for decision-making. In addition to toy examples,\nwe present a full-fledged case study of single-cell RNA sequencing. In this\nchallenging instance of multiple hypothesis testing, our proposed approach\nsurpasses the current state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:23:36 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 17:34:20 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 18:01:59 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Lopez", "Romain", ""], ["Boyeau", "Pierre", ""], ["Yosef", "Nir", ""], ["Jordan", "Michael I.", ""], ["Regier", "Jeffrey", ""]]}, {"id": "2002.07221", "submitter": "Wei-Chang Yeh", "authors": "Wei-Chang Yeh", "title": "Convolutional Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector machine (SVM) and deep learning (e.g., convolutional\nneural networks (CNNs)) are the two most famous algorithms in small and big\ndata, respectively. Nonetheless, smaller datasets may be very important,\ncostly, and not easy to obtain in a short time. This paper proposes a novel\nconvolutional SVM (CSVM) that has both advantages of CNN and SVM to improve the\naccuracy and effectiveness of mining smaller datasets. The proposed CSVM adapts\nthe convolution product from CNN to learn new information hidden deeply in the\ndatasets. In addition, it uses a modified simplified swarm optimization (SSO)\nto help train the CSVM to update classifiers, and then the traditional SVM is\nimplemented as the fitness for the SSO to estimate the accuracy. To evaluate\nthe performance of the proposed CSVM, experiments were conducted to test five\nwell-known benchmark databases for the classification problem. Numerical\nexperiments compared favorably with those obtained using SVM, 3-layer\nartificial NN (ANN), and 4-layer ANN. The results of these experiments verify\nthat the proposed CSVM with the proposed SSO can effectively increase\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 11:23:21 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yeh", "Wei-Chang", ""]]}, {"id": "2002.07224", "submitter": "Garrett Bingham", "authors": "Garrett Bingham, William Macke, and Risto Miikkulainen", "title": "Evolutionary Optimization of Deep Learning Activation Functions", "comments": "8 pages; 9 figures/tables; GECCO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of activation function can have a large effect on the performance\nof a neural network. While there have been some attempts to hand-engineer novel\nactivation functions, the Rectified Linear Unit (ReLU) remains the most\ncommonly-used in practice. This paper shows that evolutionary algorithms can\ndiscover novel activation functions that outperform ReLU. A tree-based search\nspace of candidate activation functions is defined and explored with mutation,\ncrossover, and exhaustive search. Experiments on training wide residual\nnetworks on the CIFAR-10 and CIFAR-100 image datasets show that this approach\nis effective. Replacing ReLU with evolved activation functions results in\nstatistically significant increases in network accuracy. Optimal performance is\nachieved when evolution is allowed to customize activation functions to a\nparticular task; however, these novel activation functions are shown to\ngeneralize, achieving high performance across tasks. Evolutionary optimization\nof activation functions is therefore a promising new dimension of metalearning\nin neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 19:54:26 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 15:53:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bingham", "Garrett", ""], ["Macke", "William", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2002.07233", "submitter": "Jason Lee", "authors": "Jason Lee, Dustin Tran, Orhan Firat, Kyunghyun Cho", "title": "On the Discrepancy between Density Estimation and Sequence Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequence-to-sequence generation tasks, including machine translation and\ntext-to-speech, can be posed as estimating the density of the output y given\nthe input x: p(y|x). Given this interpretation, it is natural to evaluate\nsequence-to-sequence models using conditional log-likelihood on a test set.\nHowever, the goal of sequence-to-sequence generation (or structured prediction)\nis to find the best output y^ given an input x, and each task has its own\ndownstream metric R that scores a model output by comparing against a set of\nreferences y*: R(y^, y* | x). While we hope that a model that excels in density\nestimation also performs well on the downstream metric, the exact correlation\nhas not been studied for sequence generation tasks. In this paper, by comparing\nseveral density estimators on five machine translation tasks, we find that the\ncorrelation between rankings of models based on log-likelihood and BLEU varies\nsignificantly depending on the range of the model families being compared.\nFirst, log-likelihood is highly correlated with BLEU when we consider models\nwithin the same family (e.g. autoregressive models, or latent variable models\nwith the same parameterization of the prior). However, we observe no\ncorrelation between rankings of models across different families: (1) among\nnon-autoregressive latent variable models, a flexible prior distribution is\nbetter at density estimation but gives worse generation quality than a simple\nprior, and (2) autoregressive models offer the best translation performance\noverall, while latent variable models with a normalizing flow prior give the\nhighest held-out log-likelihood across all datasets. Therefore, we recommend\nusing a simple prior for the latent variable non-autoregressive model when fast\ngeneration speed is desired.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:13:35 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lee", "Jason", ""], ["Tran", "Dustin", ""], ["Firat", "Orhan", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2002.07236", "submitter": "Kourosh Hakhamaneshi", "authors": "Kourosh Hakhamaneshi, Keertana Settaluri, Pieter Abbeel, Vladimir\n  Stojanovic", "title": "GACEM: Generalized Autoregressive Cross Entropy Method for Multi-Modal\n  Black Box Constraint Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a new method of black-box optimization and constraint\nsatisfaction. Existing algorithms that have attempted to solve this problem are\nunable to consider multiple modes, and are not able to adapt to changes in\nenvironment dynamics. To address these issues, we developed a modified\nCross-Entropy Method (CEM) that uses a masked auto-regressive neural network\nfor modeling uniform distributions over the solution space. We train the model\nusing maximum entropy policy gradient methods from Reinforcement Learning. Our\nalgorithm is able to express complicated solution spaces, thus allowing it to\ntrack a variety of different solution regions. We empirically compare our\nalgorithm with variations of CEM, including one with a Gaussian prior with\nfixed variance, and demonstrate better performance in terms of: number of\ndiverse solutions, better mode discovery in multi-modal problems, and better\nsample efficiency in certain cases.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:21:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Hakhamaneshi", "Kourosh", ""], ["Settaluri", "Keertana", ""], ["Abbeel", "Pieter", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "2002.07246", "submitter": "Huijie Feng", "authors": "Huijie Feng, Chunpeng Wu, Guoyang Chen, Weifeng Zhang, Yang Ning", "title": "Regularized Training and Tight Certification for Randomized Smoothed\n  Classifier with Provable Robustness", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently smoothing deep neural network based classifiers via isotropic\nGaussian perturbation is shown to be an effective and scalable way to provide\nstate-of-the-art probabilistic robustness guarantee against $\\ell_2$ norm\nbounded adversarial perturbations. However, how to train a good base classifier\nthat is accurate and robust when smoothed has not been fully investigated. In\nthis work, we derive a new regularized risk, in which the regularizer can\nadaptively encourage the accuracy and robustness of the smoothed counterpart\nwhen training the base classifier. It is computationally efficient and can be\nimplemented in parallel with other empirical defense methods. We discuss how to\nimplement it under both standard (non-adversarial) and adversarial training\nscheme. At the same time, we also design a new certification algorithm, which\ncan leverage the regularization effect to provide tighter robustness lower\nbound that holds with high probability. Our extensive experimentation\ndemonstrates the effectiveness of the proposed training and certification\napproaches on CIFAR-10 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 20:54:34 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Feng", "Huijie", ""], ["Wu", "Chunpeng", ""], ["Chen", "Guoyang", ""], ["Zhang", "Weifeng", ""], ["Ning", "Yang", ""]]}, {"id": "2002.07252", "submitter": "Fatemeh Salehi Rizi", "authors": "Joerg Schloetterer, Martin Wehking, Fatemeh Salehi Rizi, Michael\n  Granitzer", "title": "Investigating Extensions to Random Walk Based Graph Embedding", "comments": null, "journal-ref": null, "doi": "10.1109/ICCC.2019.00026", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph embedding has recently gained momentum in the research community, in\nparticular after the introduction of random walk and neural network based\napproaches. However, most of the embedding approaches focus on representing the\nlocal neighborhood of nodes and fail to capture the global graph structure,\ni.e. to retain the relations to distant nodes. To counter that problem, we\npropose a novel extension to random walk based graph embedding, which removes a\npercentage of least frequent nodes from the walks at different levels. By this\nremoval, we simulate farther distant nodes to reside in the close neighborhood\nof a node and hence explicitly represent their connection. Besides the common\nevaluation tasks for graph embeddings, such as node classification and link\nprediction, we evaluate and compare our approach against related methods on\nshortest path approximation. The results indicate, that extensions to random\nwalk based methods (including our own) improve the predictive performance only\nslightly - if at all.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:14:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Schloetterer", "Joerg", ""], ["Wehking", "Martin", ""], ["Rizi", "Fatemeh Salehi", ""], ["Granitzer", "Michael", ""]]}, {"id": "2002.07258", "submitter": "Richard Combes", "authors": "Thibaut Cuvelier and Richard Combes and Eric Gourdin", "title": "Statistically Efficient, Polynomial Time Algorithms for Combinatorial\n  Semi Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider combinatorial semi-bandits over a set of arms ${\\cal X} \\subset\n\\{0,1\\}^d$ where rewards are uncorrelated across items. For this problem, the\nalgorithm ESCB yields the smallest known regret bound $R(T) = {\\cal O}\\Big( {d\n(\\ln m)^2 (\\ln T) \\over \\Delta_{\\min} }\\Big)$, but it has computational\ncomplexity ${\\cal O}(|{\\cal X}|)$ which is typically exponential in $d$, and\ncannot be used in large dimensions. We propose the first algorithm which is\nboth computationally and statistically efficient for this problem with regret\n$R(T) = {\\cal O} \\Big({d (\\ln m)^2 (\\ln T)\\over \\Delta_{\\min} }\\Big)$ and\ncomputational complexity ${\\cal O}(T {\\bf poly}(d))$. Our approach involves\ncarefully designing an approximate version of ESCB with the same regret\nguarantees, showing that this approximate algorithm can be implemented in time\n${\\cal O}(T {\\bf poly}(d))$ by repeatedly maximizing a linear function over\n${\\cal X}$ subject to a linear budget constraint, and showing how to solve this\nmaximization problems efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:32:04 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 17:12:58 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Cuvelier", "Thibaut", ""], ["Combes", "Richard", ""], ["Gourdin", "Eric", ""]]}, {"id": "2002.07259", "submitter": "Mostafa ElAraby", "authors": "Mostafa ElAraby, Guy Wolf, Margarida Carvalho", "title": "Identifying Critical Neurons in ANN Architectures using Mixed Integer\n  Programming", "comments": "16 pages, 3 figures, 5 tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a mixed integer program (MIP) for assigning importance scores to\neach neuron in deep neural network architectures which is guided by the impact\nof their simultaneous pruning on the main learning task of the network. By\ncarefully devising the objective function of the MIP, we drive the solver to\nminimize the number of critical neurons (i.e., with high importance score) that\nneed to be kept for maintaining the overall accuracy of the trained neural\nnetwork. Further, the proposed formulation generalizes the recently considered\nlottery ticket optimization by identifying multiple \"lucky\" sub-networks\nresulting in optimized architecture that not only performs well on a single\ndataset, but also generalizes across multiple ones upon retraining of network\nweights. Finally, we present a scalable implementation of our method by\ndecoupling the importance scores across layers using auxiliary networks. We\ndemonstrate the ability of our formulation to prune neural networks with\nmarginal loss in accuracy and generalizability on popular datasets and\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:32:47 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 07:03:36 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 16:09:43 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 16:39:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["ElAraby", "Mostafa", ""], ["Wolf", "Guy", ""], ["Carvalho", "Margarida", ""]]}, {"id": "2002.07264", "submitter": "Philipp Marquetand", "authors": "Julia Westermayr, Michael Gastegger, Philipp Marquetand", "title": "Combining SchNet and SHARC: The SchNarc machine learning approach for\n  excited-state dynamics", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jpclett.0c00527", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has become a part of our everyday life and is\nrevolutionizing quantum chemistry as well. In this work, we show how deep\nlearning can be used to advance the research field of photochemistry by\nlearning all important properties for photodynamics simulations. The properties\nare multiple energies, forces, nonadiabatic couplings and spin-orbit couplings.\nThe nonadiabatic couplings are learned in a phase-free manner as derivatives of\na virtually constructed property by the deep learning model, which guarantees\nrotational covariance. Additionally, an approximation for nonadiabatic\ncouplings is introduced, based on the potentials, their gradients and Hessians.\nAs deep-learning method, we employ SchNet extended for multiple electronic\nstates. In combination with the molecular dynamics program SHARC, our approach\ntermed SchNarc is tested on a model system and two realistic polyatomic\nmolecules and paves the way towards efficient photodynamics simulations of\ncomplex systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 21:38:35 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Westermayr", "Julia", ""], ["Gastegger", "Michael", ""], ["Marquetand", "Philipp", ""]]}, {"id": "2002.07281", "submitter": "Shixiang Zhu", "authors": "Shixiang Zhu, Minghe Zhang, Ruyi Ding, Yao Xie", "title": "Deep Fourier Kernel for Self-Attentive Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel attention-based model for discrete event data to capture\ncomplex non-linear temporal dependence structures. We borrow the idea from the\nattention mechanism and incorporate it into the point processes' conditional\nintensity function. We further introduce a novel score function using Fourier\nkernel embedding, whose spectrum is represented using neural networks, which\ndrastically differs from the traditional dot-product kernel and can capture a\nmore complex similarity structure. We establish our approach's theoretical\nproperties and demonstrate our approach's competitive performance compared to\nthe state-of-the-art for synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:25:40 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 21:42:45 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 00:48:54 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 04:39:07 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 05:33:59 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhu", "Shixiang", ""], ["Zhang", "Minghe", ""], ["Ding", "Ruyi", ""], ["Xie", "Yao", ""]]}, {"id": "2002.07282", "submitter": "Vikranth Dwaracherla", "authors": "Vikranth Dwaracherla, Benjamin Van Roy", "title": "Langevin DQN", "comments": "5 figures, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that tackle deep exploration -- an important challenge in\nreinforcement learning -- have relied on epistemic uncertainty representation\nthrough ensembles or other hypermodels, exploration bonuses, or visitation\ncount distributions. An open question is whether deep exploration can be\nachieved by an incremental reinforcement learning algorithm that tracks a\nsingle point estimate, without additional complexity required to account for\nepistemic uncertainty. We answer this question in the affirmative. In\nparticular, we develop Langevin DQN, a variation of DQN that differs only in\nperturbing parameter updates with Gaussian noise and demonstrate through a\ncomputational study that the presented algorithm achieves deep exploration. We\nalso offer some intuition to how Langevin DQN achieves deep exploration. In\naddition, we present a modification of the Langevin DQN algorithm to improve\nthe computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:29:23 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 06:09:20 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Dwaracherla", "Vikranth", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "2002.07285", "submitter": "Vasilis Syrgkanis", "authors": "Greg Lewis, Vasilis Syrgkanis", "title": "Double/Debiased Machine Learning for Dynamic Treatment Effects via\n  g-Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of treatment effects in settings when multiple\ntreatments are assigned over time and treatments can have a causal effect on\nfuture outcomes or the state of the treated unit. We propose an extension of\nthe double/debiased machine learning framework to estimate the dynamic effects\nof treatments, which can be viewed as a Neyman orthogonal (locally robust)\ncross-fitted version of $g$-estimation in the dynamic treatment regime. Our\nmethod applies to a general class of non-linear dynamic treatment models known\nas Structural Nested Mean Models and allows the use of machine learning methods\nto control for potentially high dimensional state variables, subject to a mean\nsquare error guarantee, while still allowing parametric estimation and\nconstruction of confidence intervals for the structural parameters of interest.\nThese structural parameters can be used for off-policy evaluation of any target\ndynamic policy at parametric rates, subject to semi-parametric restrictions on\nthe data generating process. Our work is based on a recursive peeling process,\ntypical in $g$-estimation, and formulates a strongly convex objective at each\nstage, which allows us to extend the $g$-estimation framework in multiple\ndirections: i) to provide finite sample guarantees, ii) to estimate non-linear\neffect heterogeneity with respect to fixed unit characteristics, within\narbitrary function spaces, enabling a dynamic analogue of the RLearner\nalgorithm for heterogeneous effects, iii) to allow for high-dimensional sparse\nparameterizations of the target structural functions, enabling automated model\nselection via a recursive lasso algorithm. We also provide guarantees for data\nstemming from a single treated unit over a long horizon and under stationarity\nconditions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 22:32:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 11:56:31 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 20:29:01 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 19:46:52 GMT"}, {"version": "v5", "created": "Thu, 17 Jun 2021 01:57:43 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Lewis", "Greg", ""], ["Syrgkanis", "Vasilis", ""]]}, {"id": "2002.07297", "submitter": "Jennifer Brennan", "authors": "Jennifer Brennan, Ramya Korlakai Vinayak and Kevin Jamieson", "title": "Estimating the number and effect sizes of non-null hypotheses", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the distribution of effect sizes (the mean\nof the test statistic under the alternate hypothesis) in a multiple testing\nsetting. Knowing this distribution allows us to calculate the power (type II\nerror) of any experimental design. We show that it is possible to estimate this\ndistribution using an inexpensive pilot experiment, which takes significantly\nfewer samples than would be required by an experiment that identified the\ndiscoveries. Our estimator can be used to guarantee the number of discoveries\nthat will be made using a given experimental design in a future experiment. We\nprove that this simple and computationally efficient estimator enjoys a number\nof favorable theoretical properties, and demonstrate its effectiveness on data\nfrom a gene knockout experiment on influenza inhibition in Drosophila.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 23:20:21 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 18:26:17 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Brennan", "Jennifer", ""], ["Vinayak", "Ramya Korlakai", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2002.07317", "submitter": "Hisaichi Shibata", "authors": "Hisaichi Shibata, Shouhei Hanaoka, Yukihiro Nomura, Naoto Hayashi and\n  Osamu Abe", "title": "On the Matrix-Free Generation of Adversarial Perturbations for Black-Box\n  Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, adversarial perturbations superimposed on inputs are realistic\nthreats for a deep neural network (DNN). In this paper, we propose a practical\ngeneration method of such adversarial perturbation to be applied to black-box\nattacks that demand access to an input-output relationship only. Thus, the\nattackers generate such perturbation without invoking inner functions and/or\naccessing the inner states of a DNN. Unlike the earlier studies, the algorithm\nto generate the perturbation presented in this study requires much fewer query\ntrials. Moreover, to show the effectiveness of the adversarial perturbation\nextracted, we experiment with a DNN for semantic segmentation. The result shows\nthat the network is easily deceived with the perturbation generated than using\nuniformly distributed random noise with the same magnitude.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:50:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shibata", "Hisaichi", ""], ["Hanaoka", "Shouhei", ""], ["Nomura", "Yukihiro", ""], ["Hayashi", "Naoto", ""], ["Abe", "Osamu", ""]]}, {"id": "2002.07323", "submitter": "Yang Liu", "authors": "Yang Liu, Mingxin Chen, Wenxi Zhang, Junbo Zhang, Yu Zheng", "title": "Federated Extra-Trees with Privacy Preserving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly observed that the data are scattered everywhere and difficult\nto be centralized. The data privacy and security also become a sensitive topic.\nThe laws and regulations such as the European Union's General Data Protection\nRegulation (GDPR) are designed to protect the public's data privacy. However,\nmachine learning requires a large amount of data for better performance, and\nthe current circumstances put deploying real-life AI applications in an\nextremely difficult situation. To tackle these challenges, in this paper we\npropose a novel privacy-preserving federated machine learning model, named\nFederated Extra-Trees, which applies local differential privacy in the\nfederated trees model. A secure multi-institutional machine learning system was\ndeveloped to provide superior performance by processing the modeling jointly on\ndifferent clients without exchanging any raw data. We have validated the\naccuracy of our work by conducting extensive experiments on public datasets and\nthe efficiency and robustness were also verified by simulating the real-world\nscenarios. Overall, we presented an extensible, scalable and practical solution\nto handle the data island problem.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 01:15:18 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Mingxin", ""], ["Zhang", "Wenxi", ""], ["Zhang", "Junbo", ""], ["Zheng", "Yu", ""]]}, {"id": "2002.07325", "submitter": "Arash Kalatian", "authors": "Arash Kalatian and Bilal Farooq", "title": "Decoding pedestrian and automated vehicle interactions using immersive\n  virtual reality and interpretable deep learning", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies, 124 (2021)\n  pp. 102962", "doi": "10.1016/j.trc.2020.102962", "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure pedestrian friendly streets in the era of automated vehicles,\nreassessment of current policies, practices, design, rules and regulations of\nurban areas is of importance. This study investigates pedestrian crossing\nbehaviour, as an important element of urban dynamics that is expected to be\naffected by the presence of automated vehicles. For this purpose, an\ninterpretable machine learning framework is proposed to explore factors\naffecting pedestrians' wait time before crossing mid-block crosswalks in the\npresence of automated vehicles. To collect rich behavioural data, we developed\na dynamic and immersive virtual reality experiment, with 180 participants from\na heterogeneous population in 4 different locations in the Greater Toronto Area\n(GTA). Pedestrian wait time behaviour is then analyzed using a data-driven Cox\nProportional Hazards (CPH) model, in which the linear combination of the\ncovariates is replaced by a flexible non-linear deep neural network. The\nproposed model achieved a 5% improvement in goodness of fit, but more\nimportantly, enabled us to incorporate a richer set of covariates. A game\ntheoretic based interpretability method is used to understand the contribution\nof different covariates to the time pedestrians wait before crossing. Results\nshow that the presence of automated vehicles on roads, wider lane widths, high\ndensity on roads, limited sight distance, and lack of walking habits are the\nmain contributing factors to longer wait times. Our study suggested that, to\nmove towards pedestrian-friendly urban areas, national level educational\nprograms for children, enhanced safety measures for seniors, promotion of\nactive modes of transportation, and revised traffic rules and regulations\nshould be considered.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 01:30:29 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 20:51:44 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Kalatian", "Arash", ""], ["Farooq", "Bilal", ""]]}, {"id": "2002.07327", "submitter": "Soha Hassoun", "authors": "Gian Marco Visani, Michael C. Hughes, Soha Hassoun", "title": "Enzyme promiscuity prediction using hierarchy-informed multi-label\n  classification", "comments": "Presented as a poster at the 2019 Machine Learning for Computational\n  Biology Symposium, Vancouver, CA Accepted for publication, Bioinformatics,\n  Jan 22, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As experimental efforts are costly and time consuming, computational\ncharacterization of enzyme capabilities is an attractive alternative. We\npresent and evaluate several machine-learning models to predict which of 983\ndistinct enzymes, as defined via the Enzyme Commission, EC, numbers, are likely\nto interact with a given query molecule. Our data consists of enzyme-substrate\ninteractions from the BRENDA database. Some interactions are attributed to\nnatural selection and involve the enzyme's natural substrates. The majority of\nthe interactions however involve non-natural substrates, thus reflecting\npromiscuous enzymatic activities. We frame this enzyme promiscuity prediction\nproblem as a multi-label classification task. We maximally utilize inhibitor\nand unlabelled data to train prediction models that can take advantage of known\nhierarchical relationships between enzyme classes. We report that a\nhierarchical multi-label neural network, EPP-HMCNF, is the best model for\nsolving this problem, outperforming k-nearest neighbors similarity-based and\nother machine learning models. We show that inhibitor information during\ntraining consistently improves predictive power, particularly for EPP-HMCNF. We\nalso show that all promiscuity prediction models perform worse under a\nrealistic data split when compared to a random data split, and when evaluating\nperformance on non-natural substrates compared to natural substrates. We\nprovide Python code for EPP-HMCNF and other models in a repository termed EPP\n(Enzyme Promiscuity Prediction) at https://github.com/hassounlab/EPP.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 01:39:24 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 03:01:52 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Visani", "Gian Marco", ""], ["Hughes", "Michael C.", ""], ["Hassoun", "Soha", ""]]}, {"id": "2002.07345", "submitter": "Wenbo Ma", "authors": "Wenbo Ma, Miguel A. Lejeune", "title": "A Distributionally Robust Area Under Curve Maximization Model", "comments": null, "journal-ref": "Operations Research Letters, Volume 48, Issue 4, July 2020, Pages\n  460-466", "doi": "10.1016/j.orl.2020.05.012", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Area under ROC curve (AUC) is a widely used performance measure for\nclassification models. We propose two new distributionally robust AUC\nmaximization models (DR-AUC) that rely on the Kantorovich metric and\napproximate the AUC with the hinge loss function. We consider the two cases\nwith respectively fixed and variable support for the worst-case distribution.\nWe use duality theory to reformulate the DR-AUC models and derive tractable\nconvex optimization problems. The numerical experiments show that the proposed\nDR-AUC models -- benchmarked with the standard deterministic AUC and the\nsupport vector machine models - perform better in general and in particular\nimprove the worst-case out-of-sample performance over the majority of the\nconsidered datasets, thereby showing their robustness. The results are\nparticularly encouraging since our numerical experiments are conducted with\ntraining sets of small size which have been known to be conducive to low\nout-of-sample performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:50:45 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 17:19:24 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ma", "Wenbo", ""], ["Lejeune", "Miguel A.", ""]]}, {"id": "2002.07346", "submitter": "Thuong Nguyen Canh", "authors": "Thuong Nguyen Canh and Byeungwoo Jeon", "title": "Restricted Structural Random Matrix for Compressive Sensing", "comments": "25 pages, single column, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) is well-known for its unique functionalities of\nsensing, compressing, and security (i.e. CS measurements are equally\nimportant). However, there is a tradeoff. Improving sensing and compressing\nefficiency with prior signal information tends to favor particular\nmeasurements, thus decrease the security. This work aimed to improve the\nsensing and compressing efficiency without compromise the security with a novel\nsampling matrix, named Restricted Structural Random Matrix (RSRM). RSRM unified\nthe advantages of frame-based and block-based sensing together with the global\nsmoothness prior (i.e. low-resolution signals are highly correlated). RSRM\nacquired compressive measurements with random projection (equally important) of\nmultiple randomly sub-sampled signals, which was restricted to be the\nlow-resolution signals (equal in energy), thereby, its observations are equally\nimportant. RSRM was proven to satisfies the Restricted Isometry Property and\nshows comparable reconstruction performance with recent state-of-the-art\ncompressive sensing and deep learning-based methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 02:52:51 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Canh", "Thuong Nguyen", ""], ["Jeon", "Byeungwoo", ""]]}, {"id": "2002.07348", "submitter": "Ningshan Zhang", "authors": "Corinna Cortes, Giulia DeSalvo, Claudio Gentile, Mehryar Mohri,\n  Ningshan Zhang", "title": "Adaptive Region-Based Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new active learning algorithm that adaptively partitions the\ninput space into a finite number of regions, and subsequently seeks a distinct\npredictor for each region, both phases actively requesting labels. We prove\ntheoretical guarantees for both the generalization error and the label\ncomplexity of our algorithm, and analyze the number of regions defined by the\nalgorithm under some mild assumptions. We also report the results of an\nextensive suite of experiments on several real-world datasets demonstrating\nsubstantial empirical benefits over existing single-region and non-adaptive\nregion-based active learning baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 03:16:36 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Cortes", "Corinna", ""], ["DeSalvo", "Giulia", ""], ["Gentile", "Claudio", ""], ["Mohri", "Mehryar", ""], ["Zhang", "Ningshan", ""]]}, {"id": "2002.07349", "submitter": "Haoyi Fan", "authors": "Haoyi Fan, Fengbin Zhang, Ruidong Wang, Liang Xi, Zuoyong Li", "title": "Correlation-aware Deep Generative Model for Unsupervised Anomaly\n  Detection", "comments": "(Updating code and data) Accepted by PAKDD2020. Copyright (c) 2020\n  Springer. The source code and dataset are available at\n  https://haoyfan.github.io/. Only personal use of these materials is permitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised anomaly detection aims to identify anomalous samples from highly\ncomplex and unstructured data, which is pervasive in both fundamental research\nand industrial applications. However, most existing methods neglect the complex\ncorrelation among data samples, which is important for capturing normal\npatterns from which the abnormal ones deviate. In this paper, we propose a\nmethod of Correlation aware unsupervised Anomaly detection via Deep Gaussian\nMixture Model (CADGMM), which captures the complex correlation among data\npoints for high-quality low-dimensional representation learning. Specifically,\nthe relations among data samples are correlated firstly in forms of a graph\nstructure, in which, the node denotes the sample and the edge denotes the\ncorrelation between two samples from the feature space. Then, a dual-encoder\nthat consists of a graph encoder and a feature encoder, is employed to encode\nboth the feature and correlation information of samples into the\nlow-dimensional latent space jointly, followed by a decoder for data\nreconstruction. Finally, a separate estimation network as a Gaussian Mixture\nModel is utilized to estimate the density of the learned latent vector, and the\nanomalies can be detected by measuring the energy of the samples. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 03:32:06 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 11:30:58 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 04:04:58 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Fan", "Haoyi", ""], ["Zhang", "Fengbin", ""], ["Wang", "Ruidong", ""], ["Xi", "Liang", ""], ["Li", "Zuoyong", ""]]}, {"id": "2002.07363", "submitter": "Yannai A. Gonczarowski", "authors": "Ehsan Emamjomeh-Zadeh, Yannai A. Gonczarowski, David Kempe", "title": "The Complexity of Interactively Learning a Stable Matching by Trial and\n  Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a stable matching setting, we consider a query model that allows for an\ninteractive learning algorithm to make precisely one type of query: proposing a\nmatching, the response to which is either that the proposed matching is stable,\nor a blocking pair (chosen adversarially) indicating that this matching is\nunstable. For one-to-one matching markets, our main result is an essentially\ntight upper bound of $O(n^2\\log n)$ on the deterministic query complexity of\ninteractively learning a stable matching in this coarse query model, along with\nan efficient randomized algorithm that achieves this query complexity with high\nprobability. For many-to-many matching markets in which participants have\nresponsive preferences, we first give an interactive learning algorithm whose\nquery complexity and running time are polynomial in the size of the market if\nthe maximum quota of each agent is bounded; our main result for many-to-many\nmarkets is that the deterministic query complexity can be made polynomial (more\nspecifically, $O(n^3 \\log n)$) in the size of the market even for arbitrary\n(e.g., linear in the market size) quotas.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:29:03 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 00:50:27 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 21:34:58 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Emamjomeh-Zadeh", "Ehsan", ""], ["Gonczarowski", "Yannai A.", ""], ["Kempe", "David", ""]]}, {"id": "2002.07366", "submitter": "Xiao Shen Dr.", "authors": "Xiao Shen, Quanyu Dai, Fu-lai Chung, Wei Lu, Kup-Sze Choi", "title": "Adversarial Deep Network Embedding for Cross-network Node Classification", "comments": null, "journal-ref": "Proceedings of AAAI Conference on Artificial Intelligence (AAAI),\n  pp. 2991-2999 (2020)", "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the task of cross-network node classification, which leverages\nthe abundant labeled nodes from a source network to help classify unlabeled\nnodes in a target network, is studied. The existing domain adaptation\nalgorithms generally fail to model the network structural information, and the\ncurrent network embedding models mainly focus on single-network applications.\nThus, both of them cannot be directly applied to solve the cross-network node\nclassification problem. This motivates us to propose an adversarial\ncross-network deep network embedding (ACDNE) model to integrate adversarial\ndomain adaptation with deep network embedding so as to learn network-invariant\nnode representations that can also well preserve the network structural\ninformation. In ACDNE, the deep network embedding module utilizes two feature\nextractors to jointly preserve attributed affinity and topological proximities\nbetween nodes. In addition, a node classifier is incorporated to make node\nrepresentations label-discriminative. Moreover, an adversarial domain\nadaptation technique is employed to make node representations\nnetwork-invariant. Extensive experimental results demonstrate that the proposed\nACDNE model achieves the state-of-the-art performance in cross-network node\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:30:43 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Shen", "Xiao", ""], ["Dai", "Quanyu", ""], ["Chung", "Fu-lai", ""], ["Lu", "Wei", ""], ["Choi", "Kup-Sze", ""]]}, {"id": "2002.07367", "submitter": "Khai Nguyen", "authors": "Khai Nguyen and Nhat Ho and Tung Pham and Hung Bui", "title": "Distributional Sliced-Wasserstein and Applications to Generative\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sliced-Wasserstein distance (SW) and its variant, Max Sliced-Wasserstein\ndistance (Max-SW), have been used widely in the recent years due to their fast\ncomputation and scalability even when the probability measures lie in a very\nhigh dimensional space. However, SW requires many unnecessary projection\nsamples to approximate its value while Max-SW only uses the most important\nprojection, which ignores the information of other useful directions. In order\nto account for these weaknesses, we propose a novel distance, named\nDistributional Sliced-Wasserstein distance (DSW), that finds an optimal\ndistribution over projections that can balance between exploring distinctive\nprojecting directions and the informativeness of projections themselves. We\nshow that the DSW is a generalization of Max-SW, and it can be computed\nefficiently by searching for the optimal push-forward measure over a set of\nprobability measures over the unit sphere satisfying certain regularizing\nconstraints that favor distinct directions. Finally, we conduct extensive\nexperiments with large-scale datasets to demonstrate the favorable performances\nof the proposed distances over the previous sliced-based distances in\ngenerative modeling applications.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 04:35:16 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 07:21:55 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Nguyen", "Khai", ""], ["Ho", "Nhat", ""], ["Pham", "Tung", ""], ["Bui", "Hung", ""]]}, {"id": "2002.07375", "submitter": "Sankalp Garg", "authors": "Sankalp Garg, Aniket Bajpai, Mausam", "title": "Symbolic Network: Generalized Neural Policies for Relational MDPs", "comments": "In Proceeding of ICML 2020. Code can be found at\n  https://github.com/dair-iitd/symnet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Relational Markov Decision Process (RMDP) is a first-order representation\nto express all instances of a single probabilistic planning domain with\npossibly unbounded number of objects. Early work in RMDPs outputs generalized\n(instance-independent) first-order policies or value functions as a means to\nsolve all instances of a domain at once. Unfortunately, this line of work met\nwith limited success due to inherent limitations of the representation space\nused in such policies or value functions. Can neural models provide the missing\nlink by easily representing more complex generalized policies, thus making them\neffective on all instances of a given domain?\n  We present SymNet, the first neural approach for solving RMDPs that are\nexpressed in the probabilistic planning language of RDDL. SymNet trains a set\nof shared parameters for an RDDL domain using training instances from that\ndomain. For each instance, SymNet first converts it to an instance graph and\nthen uses relational neural models to compute node embeddings. It then scores\neach ground action as a function over the first-order action symbols and node\nembeddings related to the action. Given a new test instance from the same\ndomain, SymNet architecture with pre-trained parameters scores each ground\naction and chooses the best action. This can be accomplished in a single\nforward pass without any retraining on the test instance, thus implicitly\nrepresenting a neural generalized policy for the whole domain. Our experiments\non nine RDDL domains from IPPC demonstrate that SymNet policies are\nsignificantly better than random and sometimes even more effective than\ntraining a state-of-the-art deep reactive policy from scratch.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:03:17 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 17:05:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Garg", "Sankalp", ""], ["Bajpai", "Aniket", ""], ["Mausam", "", ""]]}, {"id": "2002.07376", "submitter": "Chaoqi Wang", "authors": "Chaoqi Wang, Guodong Zhang, Roger Grosse", "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow", "comments": "Fix several typos", "journal-ref": "In Proceedings of the 8th International Conference on Learning\n  Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterization has been shown to benefit both the optimization and\ngeneralization of neural networks, but large networks are resource hungry at\nboth training and test time. Network pruning can reduce test-time resource\nrequirements, but is typically applied to trained networks and therefore cannot\navoid the expensive training process. We aim to prune networks at\ninitialization, thereby saving resources at training time as well.\nSpecifically, we argue that efficient training requires preserving the gradient\nflow through the network. This leads to a simple but effective pruning\ncriterion we term Gradient Signal Preservation (GraSP). We empirically\ninvestigate the effectiveness of the proposed method with extensive experiments\non CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet, using VGGNet and ResNet\narchitectures. Our method can prune 80% of the weights of a VGG-16 network on\nImageNet at initialization, with only a 1.6% drop in top-1 accuracy. Moreover,\nour method achieves significantly better performance than the baseline at\nextreme sparsity levels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:14:47 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 00:02:33 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Wang", "Chaoqi", ""], ["Zhang", "Guodong", ""], ["Grosse", "Roger", ""]]}, {"id": "2002.07379", "submitter": "Lucas Barcelos", "authors": "Lucas Barcelos, Rafael Oliveira, Rafael Possas, Lionel Ott, and Fabio\n  Ramos", "title": "DISCO: Double Likelihood-free Inference Stochastic Control", "comments": "To appear in ICRA 2020. Code available at\n  https://github.com/lubaroli/disco", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate simulation of complex physical systems enables the development,\ntesting, and certification of control strategies before they are deployed into\nthe real systems. As simulators become more advanced, the analytical\ntractability of the differential equations and associated numerical solvers\nincorporated in the simulations diminishes, making them difficult to analyse. A\npotential solution is the use of probabilistic inference to assess the\nuncertainty of the simulation parameters given real observations of the system.\nUnfortunately the likelihood function required for inference is generally\nexpensive to compute or totally intractable. In this paper we propose to\nleverage the power of modern simulators and recent techniques in Bayesian\nstatistics for likelihood-free inference to design a control framework that is\nefficient and robust with respect to the uncertainty over simulation\nparameters. The posterior distribution over simulation parameters is propagated\nthrough a potentially non-analytical model of the system with the unscented\ntransform, and a variant of the information theoretical model predictive\ncontrol. This approach provides a more efficient way to evaluate trajectory\nroll outs than Monte Carlo sampling, reducing the online computation burden.\nExperiments show that the controller proposed attained superior performance and\nrobustness on classical control and robotics tasks when compared to models not\naccounting for the uncertainty over model parameters.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:29:40 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:35:25 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:08:36 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Barcelos", "Lucas", ""], ["Oliveira", "Rafael", ""], ["Possas", "Rafael", ""], ["Ott", "Lionel", ""], ["Ramos", "Fabio", ""]]}, {"id": "2002.07384", "submitter": "Abhimanu Kumar", "authors": "Abhimanu Kumar, Aniket Anand Deshmukh, Urun Dogan, Denis Charles, Eren\n  Manavoglu", "title": "Data Transformation Insights in Self-supervision with Clustering Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervision is key to extending use of deep learning for label scarce\ndomains. For most of self-supervised approaches data transformations play an\nimportant role. However, up until now the impact of transformations have not\nbeen studied. Furthermore, different transformations may have different impact\non the system. We provide novel insights into the use of data transformation in\nself-supervised tasks, specially pertaining to clustering. We show\ntheoretically and empirically that certain set of transformations are helpful\nin convergence of self-supervised clustering. We also show the cases when the\ntransformations are not helpful or in some cases even harmful. We show faster\nconvergence rate with valid transformations for convex as well as certain\nfamily of non-convex objectives along with the proof of convergence to the\noriginal set of optima. We have synthetic as well as real world data\nexperiments. Empirically our results conform with the theoretical insights\nprovided.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:49:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kumar", "Abhimanu", ""], ["Deshmukh", "Aniket Anand", ""], ["Dogan", "Urun", ""], ["Charles", "Denis", ""], ["Manavoglu", "Eren", ""]]}, {"id": "2002.07386", "submitter": "Ashkan Yousefpour", "authors": "Ashkan Yousefpour, Brian Q. Nguyen, Siddartha Devic, Guanhua Wang,\n  Aboudy Kreidieh, Hans Lobel, Alexandre M. Bayen, Jason P. Jue", "title": "ResiliNet: Failure-Resilient Inference in Distributed Neural Networks", "comments": "Accepted in FL-ICML 2020 (International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2020). Added FAQ to the end of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning aims to train distributed deep models without sharing the\nraw data with the centralized server. Similarly, in distributed inference of\nneural networks, by partitioning the network and distributing it across several\nphysical nodes, activations and gradients are exchanged between physical nodes,\nrather than raw data. Nevertheless, when a neural network is partitioned and\ndistributed among physical nodes, failure of physical nodes causes the failure\nof the neural units that are placed on those nodes, which results in a\nsignificant performance drop. Current approaches focus on resiliency of\ntraining in distributed neural networks. However, resiliency of inference in\ndistributed neural networks is less explored. We introduce ResiliNet, a scheme\nfor making inference in distributed neural networks resilient to physical node\nfailures. ResiliNet combines two concepts to provide resiliency: skip\nhyperconnection, a concept for skipping nodes in distributed neural networks\nsimilar to skip connection in resnets, and a novel technique called failout,\nwhich is introduced in this paper. Failout simulates physical node failure\nconditions during training using dropout, and is specifically designed to\nimprove the resiliency of distributed neural networks. The results of the\nexperiments and ablation studies using three datasets confirm the ability of\nResiliNet to provide inference resiliency for distributed neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 05:58:24 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:13:47 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 04:46:05 GMT"}, {"version": "v4", "created": "Sat, 19 Dec 2020 08:08:17 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yousefpour", "Ashkan", ""], ["Nguyen", "Brian Q.", ""], ["Devic", "Siddartha", ""], ["Wang", "Guanhua", ""], ["Kreidieh", "Aboudy", ""], ["Lobel", "Hans", ""], ["Bayen", "Alexandre M.", ""], ["Jue", "Jason P.", ""]]}, {"id": "2002.07399", "submitter": "Yikai Yan", "authors": "Yikai Yan, Chaoyue Niu, Yucheng Ding, Zhenzhe Zheng, Fan Wu, Guihai\n  Chen, Shaojie Tang, Zhihua Wu", "title": "Distributed Non-Convex Optimization with Sublinear Speedup under\n  Intermittent Client Availability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a new distributed machine learning framework, where a\nbunch of heterogeneous clients collaboratively train a model without sharing\ntraining data. In this work, we consider a practical and ubiquitous issue when\ndeploying federated learning in mobile environments: intermittent client\navailability, where the set of eligible clients may change during the training\nprocess. Such intermittent client availability would seriously deteriorate the\nperformance of the classical Federated Averaging algorithm (FedAvg for short).\nThus, we propose a simple distributed non-convex optimization algorithm, called\nFederated Latest Averaging (FedLaAvg for short), which leverages the latest\ngradients of all clients, even when the clients are not available, to jointly\nupdate the global model in each iteration. Our theoretical analysis shows that\nFedLaAvg attains the convergence rate of $O(E^{1/2}/(N^{1/4} T^{1/2}))$,\nachieving a sublinear speedup with respect to the total number of clients. We\nimplement FedLaAvg along with several baselines and evaluate them over the\nbenchmarking MNIST and Sentiment140 datasets. The evaluation results\ndemonstrate that FedLaAvg achieves more stable training than FedAvg in both\nconvex and non-convex settings and indeed reaches a sublinear speedup.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:32:18 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:13:20 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 02:47:23 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Yan", "Yikai", ""], ["Niu", "Chaoyue", ""], ["Ding", "Yucheng", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Tang", "Shaojie", ""], ["Wu", "Zhihua", ""]]}, {"id": "2002.07400", "submitter": "Eran Malach", "authors": "Amit Daniely, Eran Malach", "title": "Learning Parities with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years we see a rapidly growing line of research which shows\nlearnability of various models via common neural network algorithms. Yet,\nbesides a very few outliers, these results show learnability of models that can\nbe learned using linear methods. Namely, such results show that learning\nneural-networks with gradient-descent is competitive with learning a linear\nclassifier on top of a data-independent representation of the examples. This\nleaves much to be desired, as neural networks are far more successful than\nlinear methods. Furthermore, on the more conceptual level, linear models don't\nseem to capture the \"deepness\" of deep networks. In this paper we make a step\ntowards showing leanability of models that are inherently non-linear. We show\nthat under certain distributions, sparse parities are learnable via gradient\ndecent on depth-two network. On the other hand, under the same distributions,\nthese parities cannot be learned efficiently by linear methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:44:17 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 11:38:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Daniely", "Amit", ""], ["Malach", "Eran", ""]]}, {"id": "2002.07405", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Frosst, Colin Raffel, Garrison Cottrell and Geoffrey\n  Hinton", "title": "Deflecting Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an ongoing cycle where stronger defenses against adversarial\nattacks are subsequently broken by a more advanced defense-aware attack. We\npresent a new approach towards ending this cycle where we \"deflect''\nadversarial attacks by causing the attacker to produce an input that\nsemantically resembles the attack's target class. To this end, we first propose\na stronger defense based on Capsule Networks that combines three detection\nmechanisms to achieve state-of-the-art detection performance on both standard\nand defense-aware attacks. We then show that undetected attacks against our\ndefense often perceptually resemble the adversarial target class by performing\na human study where participants are asked to label images produced by the\nattack. These attack images can no longer be called \"adversarial'' because our\nnetwork classifies them the same way as humans do.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 06:59:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Qin", "Yao", ""], ["Frosst", "Nicholas", ""], ["Raffel", "Colin", ""], ["Cottrell", "Garrison", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "2002.07408", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Junwei Lu, Xiaofeng Gao, Haishan Liu, Qiong Chen,\n  Gongshen Liu and Guihai Chen", "title": "MoTiAC: Multi-Objective Actor-Critics for Real-Time Bidding", "comments": "8 Pages, Extensive Experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online real-time bidding (RTB) is known as a complex auction game where ad\nplatforms seek to consider various influential key performance indicators\n(KPIs), like revenue and return on investment (ROI). The trade-off among these\ncompeting goals needs to be balanced on a massive scale. To address the\nproblem, we propose a multi-objective reinforcement learning algorithm, named\nMoTiAC, for the problem of bidding optimization with various goals.\nSpecifically, in MoTiAC, instead of using a fixed and linear combination of\nmultiple objectives, we compute adaptive weights overtime on the basis of how\nwell the current state agrees with the agent's prior. In addition, we provide\ninteresting properties of model updating and further prove that Pareto\noptimality could be guaranteed. We demonstrate the effectiveness of our method\non a real-world commercial dataset. Experiments show that the model outperforms\nall state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 07:16:39 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yang", "Chaoqi", ""], ["Lu", "Junwei", ""], ["Gao", "Xiaofeng", ""], ["Liu", "Haishan", ""], ["Chen", "Qiong", ""], ["Liu", "Gongshen", ""], ["Chen", "Guihai", ""]]}, {"id": "2002.07420", "submitter": "Santiago Ontanon", "authors": "Santiago Onta\\~n\\'on", "title": "An Overview of Distance and Similarity Functions for Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notions of distance and similarity play a key role in many machine\nlearning approaches, and artificial intelligence (AI) in general, since they\ncan serve as an organizing principle by which individuals classify objects,\nform concepts and make generalizations. While distance functions for\npropositional representations have been thoroughly studied, work on distance\nfunctions for structured representations, such as graphs, frames or logical\nclauses, has been carried out in different communities and is much less\nunderstood. Specifically, a significant amount of work that requires the use of\na distance or similarity function for structured representations of data\nusually employs ad-hoc functions for specific applications. Therefore, the goal\nof this paper is to provide an overview of this work to identify connections\nbetween the work carried out in different areas and point out directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 08:00:02 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2002.07422", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Qiuchi Li, Lingyu Hua and Dawei Song", "title": "Assessing the Memory Ability of Recurrent Neural Networks", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that Recurrent Neural Networks (RNNs) can remember, in their\nhidden layers, part of the semantic information expressed by a sequence (e.g.,\na sentence) that is being processed. Different types of recurrent units have\nbeen designed to enable RNNs to remember information over longer time spans.\nHowever, the memory abilities of different recurrent units are still\ntheoretically and empirically unclear, thus limiting the development of more\neffective and explainable RNNs. To tackle the problem, in this paper, we\nidentify and analyze the internal and external factors that affect the memory\nability of RNNs, and propose a Semantic Euclidean Space to represent the\nsemantics expressed by a sequence. Based on the Semantic Euclidean Space, a\nseries of evaluation indicators are defined to measure the memory abilities of\ndifferent recurrent units and analyze their limitations. These evaluation\nindicators also provide a useful guidance to select suitable sequence lengths\nfor different RNNs during training.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 08:07:23 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zhang", "Cheng", ""], ["Li", "Qiuchi", ""], ["Hua", "Lingyu", ""], ["Song", "Dawei", ""]]}, {"id": "2002.07434", "submitter": "Sheng Shi", "authors": "Sheng Shi, Xinfeng Zhang, Wei Fan", "title": "A Modified Perturbed Sampling Method for Local Interpretable\n  Model-agnostic Explanation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is a gateway between Artificial Intelligence and society as\nthe current popular deep learning models are generally weak in explaining the\nreasoning process and prediction results. Local Interpretable Model-agnostic\nExplanation (LIME) is a recent technique that explains the predictions of any\nclassifier faithfully by learning an interpretable model locally around the\nprediction. However, the sampling operation in the standard implementation of\nLIME is defective. Perturbed samples are generated from a uniform distribution,\nignoring the complicated correlation between features. This paper proposes a\nnovel Modified Perturbed Sampling operation for LIME (MPS-LIME), which is\nformalized as the clique set construction problem. In image classification,\nMPS-LIME converts the superpixel image into an undirected graph. Various\nexperiments show that the MPS-LIME explanation of the black-box model achieves\nmuch better performance in terms of understandability, fidelity, and\nefficiency.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:03:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shi", "Sheng", ""], ["Zhang", "Xinfeng", ""], ["Fan", "Wei", ""]]}, {"id": "2002.07454", "submitter": "Yucheng Ding", "authors": "Yucheng Ding, Chaoyue Niu, Yikai Yan, Zhenzhe Zheng, Fan Wu, Guihai\n  Chen, Shaojie Tang, Rongfei Jia", "title": "Distributed Optimization over Block-Cyclic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider practical data characteristics underlying federated learning,\nwhere unbalanced and non-i.i.d. data from clients have a block-cyclic\nstructure: each cycle contains several blocks, and each client's training data\nfollow block-specific and non-i.i.d. distributions. Such a data structure would\nintroduce client and block biases during the collaborative training: the single\nglobal model would be biased towards the client or block specific data. To\novercome the biases, we propose two new distributed optimization algorithms\ncalled multi-model parallel SGD (MM-PSGD) and multi-chain parallel SGD\n(MC-PSGD) with a convergence rate of $O(1/\\sqrt{NT})$, achieving a linear\nspeedup with respect to the total number of clients. In particular, MM-PSGD\nadopts the block-mixed training strategy, while MC-PSGD further adds the\nblock-separate training strategy. Both algorithms create a specific predictor\nfor each block by averaging and comparing the historical global models\ngenerated in this block from different cycles. We extensively evaluate our\nalgorithms over the CIFAR-10 dataset. Evaluation results demonstrate that our\nalgorithms significantly outperform the conventional federated averaging\nalgorithm in terms of test accuracy, and also preserve robustness for the\nvariance of critical parameters.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 09:47:15 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ding", "Yucheng", ""], ["Niu", "Chaoyue", ""], ["Yan", "Yikai", ""], ["Zheng", "Zhenzhe", ""], ["Wu", "Fan", ""], ["Chen", "Guihai", ""], ["Tang", "Shaojie", ""], ["Jia", "Rongfei", ""]]}, {"id": "2002.07463", "submitter": "Geppino Pucci", "authors": "Andrea Pietracaprina, Geppino Pucci, Federico Sold\\`a", "title": "Coreset-based Strategies for Robust Center-type Problems", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset $V$ of points from some metric space, the popular $k$-center\nproblem requires to identify a subset of $k$ points (centers) in $V$ minimizing\nthe maximum distance of any point of $V$ from its closest center. The\n\\emph{robust} formulation of the problem features a further parameter $z$ and\nallows up to $z$ points of $V$ (outliers) to be disregarded when computing the\nmaximum distance from the centers. In this paper, we focus on two important\nconstrained variants of the robust $k$-center problem, namely, the Robust\nMatroid Center (RMC) problem, where the set of returned centers are constrained\nto be an independent set of a matroid of rank $k$ built on $V$, and the Robust\nKnapsack Center (RKC) problem, where each element $i\\in V$ is given a positive\nweight $w_i<1$ and the aggregate weight of the returned centers must be at most\n1. We devise coreset-based strategies for the two problems which yield\nefficient sequential, MapReduce, and Streaming algorithms. More specifically,\nfor any fixed $\\epsilon>0$, the algorithms return solutions featuring a\n$(3+\\epsilon)$-approximation ratio, which is a mere additive term $\\epsilon$\naway from the 3-approximations achievable by the best known polynomial-time\nsequential algorithms for the two problems. Moreover, the algorithms\nobliviously adapt to the intrinsic complexity of the dataset, captured by its\ndoubling dimension $D$. For wide ranges of the parameters $k,z,\\epsilon, D$, we\nobtain a sequential algorithm with running time linear in $|V|$, and\nMapReduce/Streaming algorithms with few rounds/passes and substantially\nsublinear local/working memory.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:04:08 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""], ["Sold\u00e0", "Federico", ""]]}, {"id": "2002.07467", "submitter": "Per Sid\\'en", "authors": "Per Sid\\'en and Fredrik Lindsten", "title": "Deep Gaussian Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Markov random fields (GMRFs) are probabilistic graphical models\nwidely used in spatial statistics and related fields to model dependencies over\nspatial structures. We establish a formal connection between GMRFs and\nconvolutional neural networks (CNNs). Common GMRFs are special cases of a\ngenerative model where the inverse mapping from data to latent variables is\ngiven by a 1-layer linear CNN. This connection allows us to generalize GMRFs to\nmulti-layer CNN architectures, effectively increasing the order of the\ncorresponding GMRF in a way which has favorable computational scaling. We\ndescribe how well-established tools, such as autodiff and variational\ninference, can be used for simple and efficient inference and learning of the\ndeep GMRF. We demonstrate the flexibility of the proposed model and show that\nit outperforms the state-of-the-art on a dataset of satellite temperatures, in\nterms of prediction and predictive uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:06:39 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 15:19:04 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Sid\u00e9n", "Per", ""], ["Lindsten", "Fredrik", ""]]}, {"id": "2002.07469", "submitter": "Paul Baggenstoss", "authors": "Paul M Baggenstoss", "title": "A Neural Network Based on First Principles", "comments": null, "journal-ref": "ICASSP 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a Neural network is derived from first principles, assuming\nonly that each layer begins with a linear dimension-reducing transformation.\nThe approach appeals to the principle of Maximum Entropy (MaxEnt) to find the\nposterior distribution of the input data of each layer, conditioned on the\nlayer output variables. This posterior has a well-defined mean, the conditional\nmean estimator, that is calculated using a type of neural network with\ntheoretically-derived activation functions similar to sigmoid, softplus, and\nrelu. This implicitly provides a theoretical justification for their use. A\ntheorem that finds the conditional distribution and conditional mean estimator\nunder the MaxEnt prior is proposed, unifying results for special cases.\nCombining layers results in an auto-encoder with conventional feed-forward\nanalysis network and a type of linear Bayesian belief network in the\nreconstruction path.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:16:59 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Baggenstoss", "Paul M", ""]]}, {"id": "2002.07493", "submitter": "Michael Steininger", "authors": "Michael Steininger, Konstantin Kobs, Albin Zehe, Florian\n  Lautenschlager, Martin Becker, Andreas Hotho", "title": "MapLUR: Exploring a new Paradigm for Estimating Air Pollution using Deep\n  Learning on Map Images", "comments": "Accepted for publication in ACM TSAS - Special Issue on Deep Learning", "journal-ref": null, "doi": "10.1145/3380973", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land-use regression (LUR) models are important for the assessment of air\npollution concentrations in areas without measurement stations. While many such\nmodels exist, they often use manually constructed features based on restricted,\nlocally available data. Thus, they are typically hard to reproduce and\nchallenging to adapt to areas beyond those they have been developed for. In\nthis paper, we advocate a paradigm shift for LUR models: We propose the\nData-driven, Open, Global (DOG) paradigm that entails models based on purely\ndata-driven approaches using only openly and globally available data. Progress\nwithin this paradigm will alleviate the need for experts to adapt models to the\nlocal characteristics of the available data sources and thus facilitate the\ngeneralizability of air pollution models to new areas on a global scale. In\norder to illustrate the feasibility of the DOG paradigm for LUR, we introduce a\ndeep learning model called MapLUR. It is based on a convolutional neural\nnetwork architecture and is trained exclusively on globally and openly\navailable map data without requiring manual feature engineering. We compare our\nmodel to state-of-the-art baselines like linear regression, random forests and\nmulti-layer perceptrons using a large data set of modeled $\\text{NO}_2$\nconcentrations in Central London. Our results show that MapLUR significantly\noutperforms these approaches even though they are provided with manually\ntailored features. Furthermore, we illustrate that the automatic feature\nextraction inherent to models based on the DOG paradigm can learn features that\nare readily interpretable and closely resemble those commonly used in\ntraditional LUR approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:21:55 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Steininger", "Michael", ""], ["Kobs", "Konstantin", ""], ["Zehe", "Albin", ""], ["Lautenschlager", "Florian", ""], ["Becker", "Martin", ""], ["Hotho", "Andreas", ""]]}, {"id": "2002.07501", "submitter": "Ziyu Wang", "authors": "Ziyu Wang, Shuyu Cheng, Yueru Li, Jun Zhu, Bo Zhang", "title": "A Wasserstein Minimum Velocity Approach to Learning Unnormalized Models", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score matching provides an effective approach to learning flexible\nunnormalized models, but its scalability is limited by the need to evaluate a\nsecond-order derivative. In this paper, we present a scalable approximation to\na general family of learning objectives including score matching, by observing\na new connection between these objectives and Wasserstein gradient flows. We\npresent applications with promise in learning neural density estimators on\nmanifolds, and training implicit variational and Wasserstein auto-encoders with\na manifold-valued prior.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 11:40:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wang", "Ziyu", ""], ["Cheng", "Shuyu", ""], ["Li", "Yueru", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "2002.07514", "submitter": "Andrea Asperti", "authors": "Andrea Asperti, Matteo Trentin", "title": "Balancing reconstruction error and Kullback-Leibler divergence in\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the loss function of Variational Autoencoders there is a well known\ntension between two components: the reconstruction loss, improving the quality\nof the resulting images, and the Kullback-Leibler divergence, acting as a\nregularizer of the latent space. Correctly balancing these two components is a\ndelicate issue, easily resulting in poor generative behaviours. In a recent\nwork, Dai and Wipf obtained a sensible improvement by allowing the network to\nlearn the balancing factor during training, according to a suitable loss\nfunction. In this article, we show that learning can be replaced by a simple\ndeterministic computation, helping to understand the underlying mechanism, and\nresulting in a faster and more accurate behaviour. On typical datasets such as\nCifar and Celeba, our technique sensibly outperforms all previous VAE\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:22:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Asperti", "Andrea", ""], ["Trentin", "Matteo", ""]]}, {"id": "2002.07518", "submitter": "Han Yang", "authors": "Han Yang, Xiao Yan, Xinyan Dai, Yongqiang Chen, James Cheng", "title": "Self-Enhanced GNN: Improving Graph Neural Networks Using Model Outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have received much attention recently because of\ntheir excellent performance on graph-based tasks. However, existing research on\nGNNs focuses on designing more effective models without considering much about\nthe quality of the input data. In this paper, we propose self-enhanced GNN\n(SEG), which improves the quality of the input data using the outputs of\nexisting GNN models for better performance on semi-supervised node\nclassification. As graph data consist of both topology and node labels, we\nimprove input data quality from both perspectives. For topology, we observe\nthat higher classification accuracy can be achieved when the ratio of\ninter-class edges (connecting nodes from different classes) is low and propose\ntopology update to remove inter-class edges and add intra-class edges. For node\nlabels, we propose training node augmentation, which enlarges the training set\nusing the labels predicted by existing GNN models. SEG is a general framework\nthat can be easily combined with existing GNN models. Experimental results\nvalidate that SEG consistently improves the performance of well-known GNN\nmodels such as GCN, GAT and SGC across different datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:27:16 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 06:58:20 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 15:54:55 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yang", "Han", ""], ["Yan", "Xiao", ""], ["Dai", "Xinyan", ""], ["Chen", "Yongqiang", ""], ["Cheng", "James", ""]]}, {"id": "2002.07520", "submitter": "Milad Alizadeh", "authors": "Milad Alizadeh, Arash Behboodi, Mart van Baalen, Christos Louizos,\n  Tijmen Blankevoort, Max Welling", "title": "Gradient $\\ell_1$ Regularization for Quantization Robustness", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyze the effect of quantizing weights and activations of neural\nnetworks on their loss and derive a simple regularization scheme that improves\nrobustness against post-training quantization. By training quantization-ready\nnetworks, our approach enables storing a single set of weights that can be\nquantized on-demand to different bit-widths as energy and memory requirements\nof the application change. Unlike quantization-aware training using the\nstraight-through estimator that only targets a specific bit-width and requires\naccess to training data and pipeline, our regularization-based method paves the\nway for \"on the fly'' post-training quantization to various bit-widths. We show\nthat by modeling quantization as a $\\ell_\\infty$-bounded perturbation, the\nfirst-order term in the loss expansion can be regularized using the\n$\\ell_1$-norm of gradients. We experimentally validate the effectiveness of our\nregularization scheme on different architectures on CIFAR-10 and ImageNet\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:31:34 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Alizadeh", "Milad", ""], ["Behboodi", "Arash", ""], ["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "2002.07528", "submitter": "Piotr Kicki", "authors": "Piotr Kicki, Mete Ozay and Piotr Skrzypczy\\'nski", "title": "A Computationally Efficient Neural Network Invariant to the Action of\n  Symmetry Subgroups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to design a computationally efficient $G$-invariant\nneural network that approximates functions invariant to the action of a given\npermutation subgroup $G \\leq S_n$ of the symmetric group on input data. The key\nelement of the proposed network architecture is a new $G$-invariant\ntransformation module, which produces a $G$-invariant latent representation of\nthe input data. This latent representation is then processed with a multi-layer\nperceptron in the network. We prove the universality of the proposed\narchitecture, discuss its properties and highlight its computational and memory\nefficiency. Theoretical considerations are supported by numerical experiments\ninvolving different network configurations, which demonstrate the effectiveness\nand strong generalization properties of the proposed method in comparison to\nother $G$-invariant neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:50:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Kicki", "Piotr", ""], ["Ozay", "Mete", ""], ["Skrzypczy\u0144ski", "Piotr", ""]]}, {"id": "2002.07530", "submitter": "Louis Faury", "authors": "Louis Faury, Marc Abeille, Cl\\'ement Calauz\\`enes, Olivier Fercoq", "title": "Improved Optimistic Algorithms for Logistic Bandits", "comments": "Accepted at ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalized linear bandit framework has attracted a lot of attention in\nrecent years by extending the well-understood linear setting and allowing to\nmodel richer reward structures. It notably covers the logistic model, widely\nused when rewards are binary. For logistic bandits, the frequentist regret\nguarantees of existing algorithms are $\\tilde{\\mathcal{O}}(\\kappa \\sqrt{T})$,\nwhere $\\kappa$ is a problem-dependent constant. Unfortunately, $\\kappa$ can be\narbitrarily large as it scales exponentially with the size of the decision set.\nThis may lead to significantly loose regret bounds and poor empirical\nperformance. In this work, we study the logistic bandit with a focus on the\nprohibitive dependencies introduced by $\\kappa$. We propose a new optimistic\nalgorithm based on a finer examination of the non-linearities of the reward\nfunction. We show that it enjoys a $\\tilde{\\mathcal{O}}(\\sqrt{T})$ regret with\nno dependency in $\\kappa$, but for a second order term. Our analysis is based\non a new tail-inequality for self-normalized martingales, of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 12:52:32 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 07:36:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Faury", "Louis", ""], ["Abeille", "Marc", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Fercoq", "Olivier", ""]]}, {"id": "2002.07551", "submitter": "QingBiao Li", "authors": "QingBiao Li (Beijing University of Posts and Telecommunications),\n  ChunHua Wu (Beijing University of Posts and Telecommunications), KangFeng\n  Zheng (Beijing University of Posts and Telecommunications) and Zhe Wang\n  (Beijing University of Posts and Telecommunications)", "title": "Hierarchical Transformer Network for Utterance-level Emotion Recognition", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there have been significant advances in de-tecting emotions in text, in\nthe field of utter-ance-level emotion recognition (ULER), there are still many\nproblems to be solved. In this paper, we address some challenges in ULER in\ndialog sys-tems. (1) The same utterance can deliver different emotions when it\nis in different contexts or from different speakers. (2) Long-range contextual\nin-formation is hard to effectively capture. (3) Unlike the traditional text\nclassification problem, this task is supported by a limited number of datasets,\namong which most contain inadequate conversa-tions or speech. To address these\nproblems, we propose a hierarchical transformer framework (apart from the\ndescription of other studies, the \"transformer\" in this paper usually refers to\nthe encoder part of the transformer) with a lower-level transformer to model\nthe word-level input and an upper-level transformer to capture the context of\nutterance-level embeddings. We use a pretrained language model bidirectional\nencoder representa-tions from transformers (BERT) as the lower-level\ntransformer, which is equivalent to introducing external data into the model\nand solve the problem of data shortage to some extent. In addition, we add\nspeaker embeddings to the model for the first time, which enables our model to\ncapture the in-teraction between speakers. Experiments on three dialog emotion\ndatasets, Friends, EmotionPush, and EmoryNLP, demonstrate that our proposed\nhierarchical transformer network models achieve 1.98%, 2.83%, and 3.94%\nimprovement, respec-tively, over the state-of-the-art methods on each dataset\nin terms of macro-F1.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 13:44:49 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Li", "QingBiao", "", "Beijing University of Posts and Telecommunications"], ["Wu", "ChunHua", "", "Beijing University of Posts and Telecommunications"], ["Zheng", "KangFeng", "", "Beijing University of Posts and Telecommunications"], ["Wang", "Zhe", "", "Beijing University of Posts and Telecommunications"]]}, {"id": "2002.07584", "submitter": "Alon Rashelbach", "authors": "Alon Rashelbach, Ori Rottenstreich, Mark Silberstein", "title": "A Computational Approach to Packet Classification", "comments": "To appear in SIGCOMM 2020", "journal-ref": null, "doi": "10.1145/3387514.3405886", "report-no": null, "categories": "cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-field packet classification is a crucial component in modern\nsoftware-defined data center networks. To achieve high throughput and low\nlatency, state-of-the-art algorithms strive to fit the rule lookup data\nstructures into on-die caches; however, they do not scale well with the number\nof rules. We present a novel approach, NuevoMatch, which improves the memory\nscaling of existing methods. A new data structure, Range Query Recursive Model\nIndex (RQ-RMI), is the key component that enables NuevoMatch to replace most of\nthe accesses to main memory with model inference computations. We describe an\nefficient training algorithm that guarantees the correctness of the\nRQ-RMI-based classification. The use of RQ-RMI allows the rules to be\ncompressed into model weights that fit into the hardware cache. Further, it\ntakes advantage of the growing support for fast neural network processing in\nmodern CPUs, such as wide vector instructions, achieving a rate of tens of\nnanoseconds per lookup. Our evaluation using 500K multi-field rules from the\nstandard ClassBench benchmark shows a geometric mean compression factor of\n4.9x, 8x, and 82x, and average performance improvement of 2.4x, 2.6x, and 1.6x\nin throughput compared to CutSplit, NeuroCuts, and TupleMerge, all\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 13:47:02 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 06:18:41 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Rashelbach", "Alon", ""], ["Rottenstreich", "Ori", ""], ["Silberstein", "Mark", ""]]}, {"id": "2002.07591", "submitter": "QingBiao Li", "authors": "QingBiao LI (Beijing University of Posts and Telecommunications),\n  Chunhua Wu (Beijing University of Posts and Telecommunications), Kangfeng\n  Zheng (Beijing University of Posts and Telecommunications)", "title": "Text Classification with Lexicon from PreAttention Mechanism", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive and high-quality lexicon plays a crucial role in traditional\ntext classification approaches. And it improves the utilization of the\nlinguistic knowledge. Although it is helpful for the task, the lexicon has got\nlittle attention in recent neural network models. Firstly, getting a\nhigh-quality lexicon is not easy. We lack an effective automated lexicon\nextraction method, and most lexicons are hand crafted, which is very\ninefficient for big data. What's more, there is no an effective way to use a\nlexicon in a neural network. To address those limitations, we propose a\nPre-Attention mechanism for text classification in this paper, which can learn\nattention of different words according to their effects in the classification\ntasks. The words with different attention can form a domain lexicon.\nExperiments on three benchmark text classification tasks show that our models\nget competitive result comparing with the state-of-the-art methods. We get\n90.5% accuracy on Stanford Large Movie Review dataset, 82.3% on Subjectivity\ndataset, 93.7% on Movie Reviews. And compared with the text classification\nmodel without Pre-Attention mechanism, those with Pre-Attention mechanism\nimprove by 0.9%-2.4% accuracy, which proves the validity of the Pre-Attention\nmechanism. In addition, the Pre-Attention mechanism performs well followed by\ndifferent types of neural networks (e.g., convolutional neural networks and\nLong Short-Term Memory networks). For the same dataset, when we use\nPre-Attention mechanism to get attention value followed by different neural\nnetworks, those words with high attention values have a high degree of\ncoincidence, which proves the versatility and portability of the Pre-Attention\nmechanism. we can get stable lexicons by attention values, which is an\ninspiring method of information extraction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 14:40:20 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["LI", "QingBiao", "", "Beijing University of Posts and Telecommunications"], ["Wu", "Chunhua", "", "Beijing University of Posts and Telecommunications"], ["Zheng", "Kangfeng", "", "Beijing University of Posts and Telecommunications"]]}, {"id": "2002.07596", "submitter": "Thomas Budzinski", "authors": "S\\'ebastien Bubeck and Thomas Budzinski", "title": "Coordination without communication: optimal regret in two players\n  multi-armed bandits", "comments": "28 pages, 5 figures. V2: minor revision", "journal-ref": "COLT 2020", "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider two agents playing simultaneously the same stochastic three-armed\nbandit problem. The two agents are cooperating but they cannot communicate. We\npropose a strategy with no collisions at all between the players (with very\nhigh probability), and with near-optimal regret $O(\\sqrt{T \\log(T)})$. We also\nargue that the extra logarithmic term $\\sqrt{\\log(T)}$ should be necessary by\nproving a lower bound for a full information variant of the problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:35:42 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 19:11:02 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Budzinski", "Thomas", ""]]}, {"id": "2002.07601", "submitter": "Yi Wei", "authors": "Yi Wei, Ming-Min Zhao, Min-Jian Zhao, and Ming Lei", "title": "ADMM-based Decoder for Binary Linear Codes Aided by Deep Learning", "comments": "5 pages, 4 figures, accepted for publication in IEEE communications\n  letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the recent advances in deep learning (DL), this work presents a\ndeep neural network aided decoding algorithm for binary linear codes. Based on\nthe concept of deep unfolding, we design a decoding network by unfolding the\nalternating direction method of multipliers (ADMM)-penalized decoder. In\naddition, we propose two improved versions of the proposed network. The first\none transforms the penalty parameter into a set of iteration-dependent ones,\nand the second one adopts a specially designed penalty function, which is based\non a piecewise linear function with adjustable slopes. Numerical results show\nthat the resulting DL-aided decoders outperform the original ADMM-penalized\ndecoder for various low density parity check (LDPC) codes with similar\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 03:32:14 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wei", "Yi", ""], ["Zhao", "Ming-Min", ""], ["Zhao", "Min-Jian", ""], ["Lei", "Ming", ""]]}, {"id": "2002.07605", "submitter": "Jinyang Jiao", "authors": "Jinyang Jiao, Ming Zhao, Jing Lin, Kaixuan Liang", "title": "A comprehensive review on convolutional neural network in machine fault\n  diagnosis", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.07.088", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of manufacturing industry, machine fault diagnosis\nhas become increasingly significant to ensure safe equipment operation and\nproduction. Consequently, multifarious approaches have been explored and\ndeveloped in the past years, of which intelligent algorithms develop\nparticularly rapidly. Convolutional neural network, as a typical representative\nof intelligent diagnostic models, has been extensively studied and applied in\nrecent five years, and a large amount of literature has been published in\nacademic journals and conference proceedings. However, there has not been a\nsystematic review to cover these studies and make a prospect for the further\nresearch. To fill in this gap, this work attempts to review and summarize the\ndevelopment of the Convolutional Network based Fault Diagnosis (CNFD)\napproaches comprehensively. Generally, a typical CNFD framework is composed of\nthe following steps, namely, data collection, model construction, and feature\nlearning and decision making, thus this paper is organized by following this\nstream. Firstly, data collection process is described, in which several popular\ndatasets are introduced. Then, the fundamental theory from the basic\nconvolutional neural network to its variants is elaborated. After that, the\napplications of CNFD are reviewed in terms of three mainstream directions, i.e.\nclassification, prediction and transfer diagnosis. Finally, conclusions and\nprospects are presented to point out the characteristics of current\ndevelopment, facing challenges and future trends. Last but not least, it is\nexpected that this work would provide convenience and inspire further\nexploration for researchers in this field.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:35:01 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Jiao", "Jinyang", ""], ["Zhao", "Ming", ""], ["Lin", "Jing", ""], ["Liang", "Kaixuan", ""]]}, {"id": "2002.07613", "submitter": "Yiqiu Shen", "authors": "Yiqiu Shen, Nan Wu, Jason Phang, Jungkyu Park, Kangning Liu,\n  Sudarshini Tyagi, Laura Heacock, S. Gene Kim, Linda Moy, Kyunghyun Cho,\n  Krzysztof J. Geras", "title": "An interpretable classifier for high-resolution breast cancer screening\n  images utilizing weakly supervised localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical images differ from natural images in significantly higher resolutions\nand smaller regions of interest. Because of these differences, neural network\narchitectures that work well for natural images might not be applicable to\nmedical image analysis. In this work, we extend the globally-aware multiple\ninstance classifier, a framework we proposed to address these unique properties\nof medical images. This model first uses a low-capacity, yet memory-efficient,\nnetwork on the whole image to identify the most informative regions. It then\napplies another higher-capacity network to collect details from chosen regions.\nFinally, it employs a fusion module that aggregates global and local\ninformation to make a final prediction. While existing methods often require\nlesion segmentation during training, our model is trained with only image-level\nlabels and can generate pixel-level saliency maps indicating possible malignant\nfindings. We apply the model to screening mammography interpretation:\npredicting the presence or absence of benign and malignant lesions. On the NYU\nBreast Cancer Screening Dataset, consisting of more than one million images,\nour model achieves an AUC of 0.93 in classifying breasts with malignant\nfindings, outperforming ResNet-34 and Faster R-CNN. Compared to ResNet-34, our\nmodel is 4.1x faster for inference while using 78.4% less GPU memory.\nFurthermore, we demonstrate, in a reader study, that our model surpasses\nradiologist-level AUC by a margin of 0.11. The proposed model is available\nonline: https://github.com/nyukat/GMIC.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 15:28:42 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Phang", "Jason", ""], ["Park", "Jungkyu", ""], ["Liu", "Kangning", ""], ["Tyagi", "Sudarshini", ""], ["Heacock", "Laura", ""], ["Kim", "S. Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2002.07618", "submitter": "Adriano Fazzone", "authors": "Aris Anagnostopoulos and Carlos Castillo and Adriano Fazzone and\n  Stefano Leonardi and Evimaria Terzi", "title": "Algorithms for Hiring and Outsourcing in the Online Labor Market", "comments": "Published at 24th ACM SIGKDD International Conference on Knowledge\n  Discovery & Data Mining 2018", "journal-ref": null, "doi": "10.1145/3219819.3220056", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although freelancing work has grown substantially in recent years, in part\nfacilitated by a number of online labor marketplaces, (e.g., Guru, Freelancer,\nAmazon Mechanical Turk), traditional forms of \"in-sourcing\" work continue being\nthe dominant form of employment. This means that, at least for the time being,\nfreelancing and salaried employment will continue to co-exist. In this paper,\nwe provide algorithms for outsourcing and hiring workers in a general setting,\nwhere workers form a team and contribute different skills to perform a task. We\ncall this model team formation with outsourcing. In our model, tasks arrive in\nan online fashion: neither the number nor the composition of the tasks is known\na-priori. At any point in time, there is a team of hired workers who receive a\nfixed salary independently of the work they perform. This team is dynamic: new\nmembers can be hired and existing members can be fired, at some cost.\nAdditionally, some parts of the arriving tasks can be outsourced and thus\ncompleted by non-team members, at a premium. Our contribution is an efficient\nonline cost-minimizing algorithm for hiring and firing team members and\noutsourcing tasks. We present theoretical bounds obtained using a primal-dual\nscheme proving that our algorithms have a logarithmic competitive approximation\nratio. We complement these results with experiments using semi-synthetic\ndatasets based on actual task requirements and worker skills from three large\nonline labor marketplaces.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 18:56:26 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Anagnostopoulos", "Aris", ""], ["Castillo", "Carlos", ""], ["Fazzone", "Adriano", ""], ["Leonardi", "Stefano", ""], ["Terzi", "Evimaria", ""]]}, {"id": "2002.07629", "submitter": "Patrick Von Platen", "authors": "Patrick von Platen, Fei Tao, Gokhan Tur", "title": "Multi-Task Siamese Neural Network for Improving Replay Attack Detection", "comments": "Submit to INTERSPEECH2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speaker verification systems are vulnerable to audio replay attacks\nwhich bypass security by replaying recordings of authorized speakers. Replay\nattack detection (RA) detection systems built upon Residual Neural Networks\n(ResNet)s have yielded astonishing results on the public benchmark ASVspoof\n2019 Physical Access challenge. With most teams using fine-tuned feature\nextraction pipelines and model architectures, the generalizability of such\nsystems remains questionable though. In this work, we analyse the effect of\ndiscriminative feature learning in a multi-task learning (MTL) setting can have\non the generalizability and discriminability of RA detection systems. We use a\npopular ResNet architecture optimized by the cross-entropy criterion as our\nbaseline and compare it to the same architecture optimized by MTL using Siamese\nNeural Networks (SNN). It can be shown that SNN outperform the baseline by\nrelative 26.8 % Equal Error Rate (EER). We further enhance the model's\narchitecture and demonstrate that SNN with additional reconstruction loss yield\nanother significant improvement of relative 13.8 % EER.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 00:21:16 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["von Platen", "Patrick", ""], ["Tao", "Fei", ""], ["Tur", "Gokhan", ""]]}, {"id": "2002.07630", "submitter": "Chunjiang Fu", "authors": "Cheng Ju, Yan Qin and Chunjiang Fu", "title": "Extending iLQR method with control delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iterative linear quadradic regulator(iLQR) has become a benchmark method to\ndeal with nonlinear stochastic optimal control problem. However, it does not\napply to delay system. In this paper, we extend the iLQR theory and prove new\ntheorem in case of input signal with fixed delay. Which could be beneficial for\nmachine learning or optimal control application to real time robot or human\nassistive device.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 04:35:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Ju", "Cheng", ""], ["Qin", "Yan", ""], ["Fu", "Chunjiang", ""]]}, {"id": "2002.07631", "submitter": "Navid Naderializadeh", "authors": "Navid Naderializadeh, Mark Eisen, Alejandro Ribeiro", "title": "Wireless Power Control via Counterfactual Optimization of Graph Neural\n  Networks", "comments": "Submitted to the 21st IEEE International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of downlink power control in wireless networks,\nconsisting of multiple transmitter-receiver pairs communicating with each other\nover a single shared wireless medium. To mitigate the interference among\nconcurrent transmissions, we leverage the network topology to create a graph\nneural network architecture, and we then use an unsupervised primal-dual\ncounterfactual optimization approach to learn optimal power allocation\ndecisions. We show how the counterfactual optimization technique allows us to\nguarantee a minimum rate constraint, which adapts to the network size, hence\nachieving the right balance between average and $5^{th}$ percentile user rates\nthroughout a range of network configurations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 07:54:39 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Naderializadeh", "Navid", ""], ["Eisen", "Mark", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2002.07638", "submitter": "Hanwei Wu", "authors": "Hanwei Wu, Ather Gattami, Markus Flierl", "title": "Conditional Mutual information-based Contrastive Loss for Financial Time\n  Series Forecasting", "comments": "Published in ICAIF 2020 : ACM International Conference on AI in\n  Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a representation learning framework for financial time series\nforecasting. One challenge of using deep learning models for finance\nforecasting is the shortage of available training data when using small\ndatasets. Direct trend classification using deep neural networks trained on\nsmall datasets is susceptible to the overfitting problem. In this paper, we\npropose to first learn compact representations from time series data, then use\nthe learned representations to train a simpler model for predicting time series\nmovements. We consider a class-conditioned latent variable model. We train an\nencoder network to maximize the mutual information between the latent variables\nand the trend information conditioned on the encoded observed variables. We\nshow that conditional mutual information maximization can be approximated by a\ncontrastive loss. Then, the problem is transformed into a classification task\nof determining whether two encoded representations are sampled from the same\nclass or not. This is equivalent to performing pairwise comparisons of the\ntraining datapoints, and thus, improves the generalization ability of the\nencoder network. We use deep autoregressive models as our encoder to capture\nlong-term dependencies of the sequence data. Empirical experiments indicate\nthat our proposed method has the potential to advance state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:24:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:39:39 GMT"}, {"version": "v3", "created": "Fri, 7 May 2021 10:37:10 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Wu", "Hanwei", ""], ["Gattami", "Ather", ""], ["Flierl", "Markus", ""]]}, {"id": "2002.07643", "submitter": "Sergey Berezin", "authors": "S. A. Berezin, V.M. Volkova", "title": "Neural arbitrary style transfer for portrait images using the attention\n  mechanism", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arbitrary style transfer is the task of synthesis of an image that has never\nbeen seen before, using two given images: content image and style image. The\ncontent image forms the structure, the basic geometric lines and shapes of the\nresulting image, while the style image sets the color and texture of the\nresult. The word \"arbitrary\" in this context means the absence of any one\npre-learned style. So, for example, convolutional neural networks capable of\ntransferring a new style only after training or retraining on a new amount of\ndata are not con-sidered to solve such a problem, while networks based on the\nattention mech-anism that are capable of performing such a transformation\nwithout retraining - yes. An original image can be, for example, a photograph,\nand a style image can be a painting of a famous artist. The resulting image in\nthis case will be the scene depicted in the original photograph, made in the\nstylie of this picture. Recent arbitrary style transfer algorithms make it\npossible to achieve good re-sults in this task, however, in processing portrait\nimages of people, the result of such algorithms is either unacceptable due to\nexcessive distortion of facial features, or weakly expressed, not bearing the\ncharacteristic features of a style image. In this paper, we consider an\napproach to solving this problem using the combined architecture of deep neural\nnetworks with a attention mechanism that transfers style based on the contents\nof a particular image segment: with a clear predominance of style over the form\nfor the background part of the im-age, and with the prevalence of content over\nthe form in the image part con-taining directly the image of a person.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:59:58 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Berezin", "S. A.", ""], ["Volkova", "V. M.", ""]]}, {"id": "2002.07650", "submitter": "Andrey Malinin Dr.", "authors": "Andrey Malinin, Mark Gales", "title": "Uncertainty Estimation in Autoregressive Structured Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation is important for ensuring safety and robustness of AI\nsystems. While most research in the area has focused on un-structured\nprediction tasks, limited work has investigated general uncertainty estimation\napproaches for structured prediction. Thus, this work aims to investigate\nuncertainty estimation for autoregressive structured prediction tasks within a\nsingle unified and interpretable probabilistic ensemble-based framework. We\nconsider: uncertainty estimation for sequence data at the token-level and\ncomplete sequence-level; interpretations for, and applications of, various\nmeasures of uncertainty; and discuss both the theoretical and practical\nchallenges associated with obtaining them. This work also provides baselines\nfor token-level and sequence-level error detection, and sequence-level\nout-of-domain input detection on the WMT'14 English-French and WMT'17\nEnglish-German translation and LibriSpeech speech recognition datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:40:13 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 12:03:10 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 10:31:28 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 09:01:22 GMT"}, {"version": "v5", "created": "Thu, 11 Feb 2021 09:42:35 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "2002.07651", "submitter": "Abhishek Sharma", "authors": "Abhishek Sharma", "title": "Listwise Learning to Rank with Deep Q-Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Rank is the problem involved with ranking a sequence of documents\nbased on their relevance to a given query. Deep Q-Learning has been shown to be\na useful method for training an agent in sequential decision making. In this\npaper, we show that DeepQRank, our deep q-learning to rank agent, demonstrates\nperformance that can be considered state-of-the-art. Though less\ncomputationally efficient than a supervised learning approach such as linear\nregression, our agent has fewer limitations in terms of which format of data it\ncan use for training and evaluation. We run our algorithm against Microsoft's\nLETOR listwise dataset and achieve an NDCG@1 (ranking accuracy in the range\n[0,1]) of 0.5075, narrowly beating out the leading supervised learning model,\nSVMRank (0.4958).\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 22:45:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Sharma", "Abhishek", ""]]}, {"id": "2002.07656", "submitter": "Stephen Green", "authors": "Stephen R. Green, Christine Simpson, Jonathan Gair", "title": "Gravitational-wave parameter estimation with autoregressive neural\n  network flows", "comments": "14 pages, 7 figures", "journal-ref": "Phys. Rev. D 102, 104057 (2020)", "doi": "10.1103/PhysRevD.102.104057", "report-no": "LIGO-P2000053", "categories": "astro-ph.IM cs.LG gr-qc stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of autoregressive normalizing flows for rapid\nlikelihood-free inference of binary black hole system parameters from\ngravitational-wave data with deep neural networks. A normalizing flow is an\ninvertible mapping on a sample space that can be used to induce a\ntransformation from a simple probability distribution to a more complex one: if\nthe simple distribution can be rapidly sampled and its density evaluated, then\nso can the complex distribution. Our first application to gravitational waves\nuses an autoregressive flow, conditioned on detector strain data, to map a\nmultivariate standard normal distribution into the posterior distribution over\nsystem parameters. We train the model on artificial strain data consisting of\nIMRPhenomPv2 waveforms drawn from a five-parameter $(m_1, m_2, \\phi_0, t_c,\nd_L)$ prior and stationary Gaussian noise realizations with a fixed power\nspectral density. This gives performance comparable to current best\ndeep-learning approaches to gravitational-wave parameter estimation. We then\nbuild a more powerful latent variable model by incorporating autoregressive\nflows within the variational autoencoder framework. This model has performance\ncomparable to Markov chain Monte Carlo and, in particular, successfully models\nthe multimodal $\\phi_0$ posterior. Finally, we train the autoregressive latent\nvariable model on an expanded parameter space, including also aligned spins\n$(\\chi_{1z}, \\chi_{2z})$ and binary inclination $\\theta_{JN}$, and show that\nall parameters and degeneracies are well-recovered. In all cases, sampling is\nextremely fast, requiring less than two seconds to draw $10^4$ posterior\nsamples.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:44:04 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Green", "Stephen R.", ""], ["Simpson", "Christine", ""], ["Gair", "Jonathan", ""]]}, {"id": "2002.07676", "submitter": "Claire Lazar Reich", "authors": "Claire Lazar Reich and Suhas Vijaykumar", "title": "A Possibility in Algorithmic Fairness: Can Calibration and Equal Error\n  Rates Be Reconciled?", "comments": "2nd Symposium on Foundations of Responsible Computing (FORC 2021)\n  https://drops.dagstuhl.de/opus/volltexte/2021/13872/", "journal-ref": null, "doi": "10.4230/LIPIcs.FORC.2021.4", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision makers increasingly rely on algorithmic risk scores to determine\naccess to binary treatments including bail, loans, and medical interventions.\nIn these settings, we reconcile two fairness criteria that were previously\nshown to be in conflict: calibration and error rate equality. In particular, we\nderive necessary and sufficient conditions for the existence of calibrated\nscores that yield classifications achieving equal error rates at any given\ngroup-blind threshold. We then present an algorithm that searches for the most\naccurate score subject to both calibration and minimal error rate disparity.\nApplied to the COMPAS criminal risk assessment tool, we show that our method\ncan eliminate error disparities while maintaining calibration. In a separate\napplication to credit lending, we compare our procedure to the omission of\nsensitive features and show that it raises both profit and the probability that\ncreditworthy individuals receive loans.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:03:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 15:09:40 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 20:41:16 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Reich", "Claire Lazar", ""], ["Vijaykumar", "Suhas", ""]]}, {"id": "2002.07681", "submitter": "Axel Mosig", "authors": "Arne P. Raulf and Joshua Butke and Lukas Menzen and Claus K\\\"upper and\n  Frederik Gro{\\ss}erueschkamp and Klaus Gerwert and Axel Mosig", "title": "Deep Neural Networks for the Correction of Mie Scattering in\n  Fourier-Transformed Infrared Spectra of Biological Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrared spectra obtained from cell or tissue specimen have commonly been\nobserved to involve a significant degree of (resonant) Mie scattering, which\noften overshadows biochemically relevant spectral information by a non-linear,\nnon-additive spectral component in Fourier transformed infrared (FTIR)\nspectroscopic measurements. Correspondingly, many successful machine learning\napproaches for FTIR spectra have relied on preprocessing procedures that\ncomputationally remove the scattering components from an infrared spectrum. We\npropose an approach to approximate this complex preprocessing function using\ndeep neural networks. As we demonstrate, the resulting model is not just\nseveral orders of magnitudes faster, which is important for real-time clinical\napplications, but also generalizes strongly across different tissue types.\nFurthermore, our proposed method overcomes the trade-off between computation\ntime and the corrected spectrum being biased towards an artificial reference\nspectrum.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:07:07 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Raulf", "Arne P.", ""], ["Butke", "Joshua", ""], ["Menzen", "Lukas", ""], ["K\u00fcpper", "Claus", ""], ["Gro\u00dferueschkamp", "Frederik", ""], ["Gerwert", "Klaus", ""], ["Mosig", "Axel", ""]]}, {"id": "2002.07682", "submitter": "Sagar Kale", "authors": "Ashish Chiplunkar, Sagar Kale, Sivaramakrishnan Natarajan Ramamoorthy", "title": "How to Solve Fair $k$-Center in Massive Data Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fueled by massive data, important decision making is being automated with the\nhelp of algorithms, therefore, fairness in algorithms has become an especially\nimportant research topic. In this work, we design new streaming and distributed\nalgorithms for the fair $k$-center problem that models fair data summarization.\nThe streaming and distributed models of computation have an attractive feature\nof being able to handle massive data sets that do not fit into main memory. Our\nmain contributions are: (a) the first distributed algorithm; which has provably\nconstant approximation ratio and is extremely parallelizable, and (b) a\ntwo-pass streaming algorithm with a provable approximation guarantee matching\nthe best known algorithm (which is not a streaming algorithm). Our algorithms\nhave the advantages of being easy to implement in practice, being fast with\nlinear running times, having very small working memory and communication, and\noutperforming existing algorithms on several real and synthetic data sets. To\ncomplement our distributed algorithm, we also give a hardness result for\nnatural distributed algorithms, which holds for even the special case of\n$k$-center.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:11:40 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 16:55:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chiplunkar", "Ashish", ""], ["Kale", "Sagar", ""], ["Ramamoorthy", "Sivaramakrishnan Natarajan", ""]]}, {"id": "2002.07684", "submitter": "Matteo Tiezzi", "authors": "Matteo Tiezzi, Giuseppe Marra, Stefano Melacci, Marco Maggini, and\n  Marco Gori", "title": "A Lagrangian Approach to Information Propagation in Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real world applications, data are characterized by a complex\nstructure, that can be naturally encoded as a graph. In the last years, the\npopularity of deep learning techniques has renewed the interest in neural\nmodels able to process complex patterns. In particular, inspired by the Graph\nNeural Network (GNN) model, different architectures have been proposed to\nextend the original GNN scheme. GNNs exploit a set of state variables, each\nassigned to a graph node, and a diffusion mechanism of the states among\nneighbor nodes, to implement an iterative procedure to compute the fixed point\nof the (learnable) state transition function. In this paper, we propose a novel\napproach to the state computation and the learning algorithm for GNNs, based on\na constraint optimisation task solved in the Lagrangian framework. The state\nconvergence procedure is implicitly expressed by the constraint satisfaction\nmechanism and does not require a separate iterative phase for each epoch of the\nlearning procedure. In fact, the computational structure is based on the search\nfor saddle points of the Lagrangian in the adjoint space composed of weights,\nneural outputs (node states), and Lagrange multipliers. The proposed approach\nis compared experimentally with other popular models for processing graphs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:13:24 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:48:50 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 11:37:42 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tiezzi", "Matteo", ""], ["Marra", "Giuseppe", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "2002.07686", "submitter": "Moran Shkolnik", "authors": "Moran Shkolnik, Brian Chmiel, Ron Banner, Gil Shomron, Yury Nahshan,\n  Alex Bronstein, Uri Weiser", "title": "Robust Quantization: One Model to Rule Them All", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network quantization methods often involve simulating the quantization\nprocess during training, making the trained model highly dependent on the\ntarget bit-width and precise way quantization is performed. Robust quantization\noffers an alternative approach with improved tolerance to different classes of\ndata-types and quantization policies. It opens up new exciting applications\nwhere the quantization process is not static and can vary to meet different\ncircumstances and implementations. To address this issue, we propose a method\nthat provides intrinsic robustness to the model against a broad range of\nquantization processes. Our method is motivated by theoretical arguments and\nenables us to store a single generic model capable of operating at various\nbit-widths and quantization policies. We validate our method's effectiveness on\ndifferent ImageNet models.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:14:36 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:18:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 08:46:01 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shkolnik", "Moran", ""], ["Chmiel", "Brian", ""], ["Banner", "Ron", ""], ["Shomron", "Gil", ""], ["Nahshan", "Yury", ""], ["Bronstein", "Alex", ""], ["Weiser", "Uri", ""]]}, {"id": "2002.07687", "submitter": "Zhichuang Sun", "authors": "Zhichuang Sun, Ruimin Sun, Long Lu, Alan Mislove", "title": "Mind Your Weight(s): A Large-scale Study on Insufficient Machine\n  Learning Model Protection in Mobile Apps", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device machine learning (ML) is quickly gaining popularity among mobile\napps. It allows offline model inference while preserving user privacy. However,\nML models, considered as core intellectual properties of model owners, are now\nstored on billions of untrusted devices and subject to potential thefts. Leaked\nmodels can cause both severe financial loss and security consequences. This\npaper presents the first empirical study of ML model protection on mobile\ndevices. Our study aims to answer three open questions with quantitative\nevidence: How widely is model protection used in apps? How robust are existing\nmodel protection techniques? What impacts can (stolen) models incur? To that\nend, we built a simple app analysis pipeline and analyzed 46,753 popular apps\ncollected from the US and Chinese app markets. We identified 1,468 ML apps\nspanning all popular app categories. We found that, alarmingly, 41% of ML apps\ndo not protect their models at all, which can be trivially stolen from app\npackages. Even for those apps that use model protection or encryption, we were\nable to extract the models from 66% of them via unsophisticated dynamic\nanalysis techniques. The extracted models are mostly commercial products and\nused for face recognition, liveness detection, ID/bank card recognition, and\nmalware detection. We quantitatively estimated the potential financial and\nsecurity impact of a leaked model, which can amount to millions of dollars for\ndifferent stakeholders. Our study reveals that on-device models are currently\nat high risk of being leaked; attackers are highly motivated to steal such\nmodels. Drawn from our large-scale study, we report our insights into this\nemerging security problem and discuss the technical challenges, hoping to\ninspire future research on robust and practical model protection for mobile\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:14:37 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 22:35:34 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Sun", "Zhichuang", ""], ["Sun", "Ruimin", ""], ["Lu", "Long", ""], ["Mislove", "Alan", ""]]}, {"id": "2002.07696", "submitter": "Oren Barkan", "authors": "Oren Barkan, Ori Katz, Noam Koenigstein", "title": "Neural Attentive Multiview Machines", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in multiview representation learning is finding the\noptimal combination of views with respect to the specific task at hand. To this\nend, we introduce NAM: a Neural Attentive Multiview machine that learns\nmultiview item representations and similarity by employing a novel attention\nmechanism. NAM harnesses multiple information sources and automatically\nquantifies their relevancy with respect to a supervised task. Finally, a very\npractical advantage of NAM is its robustness to the case of dataset with\nmissing views. We demonstrate the effectiveness of NAM for the task of movies\nand app recommendations. Our evaluations indicate that NAM outperforms single\nview models as well as alternative multiview methods on item recommendations\ntasks, including cold-start scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:21:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Barkan", "Oren", ""], ["Katz", "Ori", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2002.07699", "submitter": "Bo Peng", "authors": "Bo Peng, Xiaohui Yao, Shannon L. Risacher, Andrew J. Saykin, Li Shen,\n  Xia Ning (for the Alzheimer's Disease Neuroimaging Initiative)", "title": "Cognitive Biomarker Prioritization in Alzheimer's Disease using Brain\n  Morphometric Data", "comments": "This paper has been accepted by BMC MIDM", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background:Cognitive assessments represent the most common clinical routine\nfor the diagnosis of Alzheimer's Disease (AD). Given a large number of\ncognitive assessment tools and time-limited office visits, it is important to\ndetermine a proper set of cognitive tests for different subjects. Most current\nstudies create guidelines of cognitive test selection for a targeted\npopulation, but they are not customized for each individual subject. In this\nmanuscript, we develop a machine learning paradigm enabling personalized\ncognitive assessments prioritization. Method: We adapt a newly developed\nlearning-to-rank approach PLTR to implement our paradigm. This method learns\nthe latent scoring function that pushes the most effective cognitive\nassessments onto the top of the prioritization list. We also extend PLTR to\nbetter separate the most effective cognitive assessments and the less effective\nones. Results: Our empirical study on the ADNI data shows that the proposed\nparadigm outperforms the state-of-the-art baselines on identifying and\nprioritizing individual-specific cognitive biomarkers. We conduct experiments\nin cross validation and level-out validation settings. In the two settings, our\nparadigm significantly outperforms the best baselines with improvement as much\nas 22.1% and 19.7%, respectively, on prioritizing cognitive features.\nConclusions: The proposed paradigm achieves superior performance on\nprioritizing cognitive biomarkers. The cognitive biomarkers prioritized on top\nhave great potentials to facilitate personalized diagnosis, disease subtyping,\nand ultimately precision medicine in AD.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:25:11 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 15:26:49 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 13:26:14 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 15:26:14 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 01:49:34 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Peng", "Bo", "", "for the Alzheimer's Disease Neuroimaging Initiative"], ["Yao", "Xiaohui", "", "for the Alzheimer's Disease Neuroimaging Initiative"], ["Risacher", "Shannon L.", "", "for the Alzheimer's Disease Neuroimaging Initiative"], ["Saykin", "Andrew J.", "", "for the Alzheimer's Disease Neuroimaging Initiative"], ["Shen", "Li", "", "for the Alzheimer's Disease Neuroimaging Initiative"], ["Ning", "Xia", "", "for the Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "2002.07703", "submitter": "Ziyang Wang", "authors": "Ziyang Wang", "title": "Deep Learning in Medical Ultrasound Image Segmentation: a Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning technologies, especially deep learning, into\nmedical image segmentation is being widely studied because of its\nstate-of-the-art performance and results. It can be a key step to provide a\nreliable basis for clinical diagnosis, such as 3D reconstruction of human\ntissues, image-guided interventions, image analyzing and visualization. In this\nreview article, deep-learning-based methods for ultrasound image segmentation\nare categorized into six main groups according to their architectures and\ntraining at first. Secondly, for each group, several current representative\nalgorithms are selected, introduced, analyzed and summarized in detail. In\naddition, common evaluation methods for image segmentation and ultrasound image\nsegmentation datasets are summarized. Further, the performance of the current\nmethods and their evaluations are reviewed. In the end, the challenges and\npotential research directions for medical ultrasound image segmentation are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:33:22 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 18:29:26 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 00:05:17 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wang", "Ziyang", ""]]}, {"id": "2002.07713", "submitter": "Sumit Darak Dr", "authors": "S. V. Sai Santosh and Sumit J. Darak", "title": "Intelligent and Reconfigurable Architecture for KL Divergence Based\n  Online Machine Learning Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online machine learning (OML) algorithms do not need any training phase and\ncan be deployed directly in an unknown environment. OML includes multi-armed\nbandit (MAB) algorithms that can identify the best arm among several arms by\nachieving a balance between exploration of all arms and exploitation of optimal\narm. The Kullback-Leibler divergence based upper confidence bound (KLUCB) is\nthe state-of-the-art MAB algorithm that optimizes exploration-exploitation\ntrade-off but it is complex due to underlining optimization routine. This\nlimits its usefulness for robotics and radio applications which demand\nintegration of KLUCB with the PHY on the system on chip (SoC). In this paper,\nwe efficiently map the KLUCB algorithm on SoC by realizing optimization routine\nvia alternative synthesizable computation without compromising on the\nperformance. The proposed architecture is dynamically reconfigurable such that\nthe number of arms, as well as type of algorithm, can be changed on-the-fly.\nSpecifically, after initial learning, on-the-fly switch to light-weight UCB\noffers around 10-factor improvement in latency and throughput. Since learning\nduration depends on the unknown arm statistics, we offer intelligence embedded\nin architecture to decide the switching instant. We validate the functional\ncorrectness and usefulness of the proposed architecture via a realistic\nwireless application and detailed complexity analysis demonstrates its\nfeasibility in realizing intelligent radios.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:39:57 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Santosh", "S. V. Sai", ""], ["Darak", "Sumit J.", ""]]}, {"id": "2002.07715", "submitter": "Amin Abolghasemi", "authors": "Amin Abolghasemi, Saeedeh Momtazi", "title": "Neural Relation Prediction for Simple Question Answering over Knowledge\n  Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs are widely used as a typical resource to provide answers to\nfactoid questions. In simple question answering over knowledge graphs, relation\nextraction aims to predict the relation of a factoid question from a set of\npredefined relation types. Most recent methods take advantage of neural\nnetworks to match a question with all predefined relations. In this paper, we\npropose an instance-based method to capture the underlying relation of question\nand to this aim, we detect matching paraphrases of a new question which share\nthe same relation, and their corresponding relation is selected as our\nprediction. The idea of our model roots in the fact that a relation can be\nexpressed with various forms of questions while these forms share lexically or\nsemantically similar terms and concepts. Our experiments on the SimpleQuestions\ndataset show that the proposed model achieves better accuracy compared to the\nstate-of-the-art relation extraction models.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:41:24 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 23:21:36 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 14:34:10 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abolghasemi", "Amin", ""], ["Momtazi", "Saeedeh", ""]]}, {"id": "2002.07717", "submitter": "Gregor Simm", "authors": "Gregor N. C. Simm, Robert Pinsler, Jos\\'e Miguel Hern\\'andez-Lobato", "title": "Reinforcement Learning for Molecular Design Guided by Quantum Mechanics", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automating molecular design using deep reinforcement learning (RL) holds the\npromise of accelerating the discovery of new chemical compounds. Existing\napproaches work with molecular graphs and thus ignore the location of atoms in\nspace, which restricts them to 1) generating single organic molecules and 2)\nheuristic reward functions. To address this, we present a novel RL formulation\nfor molecular design in Cartesian coordinates, thereby extending the class of\nmolecules that can be built. Our reward function is directly based on\nfundamental physical properties such as the energy, which we approximate via\nfast quantum-chemical methods. To enable progress towards de-novo molecular\ndesign, we introduce MolGym, an RL environment comprising several challenging\nmolecular design tasks along with baselines. In our experiments, we show that\nour agent can efficiently learn to solve these tasks from scratch by working in\na translation and rotation invariant state-action space.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:43:58 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 14:16:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Simm", "Gregor N. C.", ""], ["Pinsler", "Robert", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "2002.07720", "submitter": "Matteo Tiezzi", "authors": "Giuseppe Marra, Matteo Tiezzi, Stefano Melacci, Alessandro Betti,\n  Marco Maggini, Marco Gori", "title": "Local Propagation in Constraint-based Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a constraint-based representation of neural network\narchitectures. We cast the learning problem in the Lagrangian framework and we\ninvestigate a simple optimization procedure that is well suited to fulfil the\nso-called architectural constraints, learning from the available supervisions.\nThe computational structure of the proposed Local Propagation (LP) algorithm is\nbased on the search for saddle points in the adjoint space composed of weights,\nneural outputs, and Lagrange multipliers. All the updates of the model\nvariables are locally performed, so that LP is fully parallelizable over the\nneural units, circumventing the classic problem of gradient vanishing in deep\nnetworks. The implementation of popular neural models is described in the\ncontext of LP, together with those conditions that trace a natural connection\nwith Backpropagation. We also investigate the setting in which we tolerate\nbounded violations of the architectural constraints, and we provide\nexperimental evidence that LP is a feasible approach to train shallow and deep\nnetworks, opening the road to further investigations on more complex\narchitectures, easily describable by constraints.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:47:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 10:20:48 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Marra", "Giuseppe", ""], ["Tiezzi", "Matteo", ""], ["Melacci", "Stefano", ""], ["Betti", "Alessandro", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "2002.07725", "submitter": "Damian Jimenez", "authors": "Kevin Meng, Damian Jimenez, Fatma Arslan, Jacob Daniel Devasier,\n  Daniel Obembe, Chengkai Li", "title": "Gradient-Based Adversarial Training on Transformer Networks for\n  Detecting Check-Worthy Factual Claims", "comments": "11 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study on the efficacy of adversarial training on transformer\nneural network models, with respect to the task of detecting check-worthy\nclaims. In this work, we introduce the first adversarially-regularized,\ntransformer-based claim spotter model that achieves state-of-the-art results on\nmultiple challenging benchmarks. We obtain a 4.70 point F1-score improvement\nover current state-of-the-art models on the ClaimBuster Dataset and CLEF2019\nDataset, respectively. In the process, we propose a method to apply adversarial\ntraining to transformer models, which has the potential to be generalized to\nmany similar text classification tasks. Along with our results, we are\nreleasing our codebase and manually labeled datasets. We also showcase our\nmodels' real world usage via a live public API.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:51:05 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 12:33:18 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Meng", "Kevin", ""], ["Jimenez", "Damian", ""], ["Arslan", "Fatma", ""], ["Devasier", "Jacob Daniel", ""], ["Obembe", "Daniel", ""], ["Li", "Chengkai", ""]]}, {"id": "2002.07729", "submitter": "Akshay Krishnamurthy", "authors": "Yi Su, Pavithra Srinath, Akshay Krishnamurthy", "title": "Adaptive Estimator Selection for Off-Policy Evaluation", "comments": "Fixed some typos. Published in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a generic data-driven method for estimator selection in off-policy\npolicy evaluation settings. We establish a strong performance guarantee for the\nmethod, showing that it is competitive with the oracle estimator, up to a\nconstant factor. Via in-depth case studies in contextual bandits and\nreinforcement learning, we demonstrate the generality and applicability of the\nmethod. We also perform comprehensive experiments, demonstrating the empirical\nefficacy of our approach and comparing with related approaches. In both case\nstudies, our method compares favorably with existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 16:57:42 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 14:54:22 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Su", "Yi", ""], ["Srinath", "Pavithra", ""], ["Krishnamurthy", "Akshay", ""]]}, {"id": "2002.07738", "submitter": "Samuel Yeom", "authors": "Samuel Yeom, Matt Fredrikson", "title": "Individual Fairness Revisited: Transferring Techniques from Adversarial\n  Robustness", "comments": "Published at IJCAI 2020 (at https://www.ijcai.org/Proceedings/2020/61\n  ); the conference version has a minor error in the proof of Theorem 3, which\n  is fixed here", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We turn the definition of individual fairness on its head---rather than\nascertaining the fairness of a model given a predetermined metric, we find a\nmetric for a given model that satisfies individual fairness. This can\nfacilitate the discussion on the fairness of a model, addressing the issue that\nit may be difficult to specify a priori a suitable metric. Our contributions\nare twofold: First, we introduce the definition of a minimal metric and\ncharacterize the behavior of models in terms of minimal metrics. Second, for\nmore complicated models, we apply the mechanism of randomized smoothing from\nadversarial robustness to make them individually fair under a given weighted\n$L^p$ metric. Our experiments show that adapting the minimal metrics of linear\nmodels to more complicated neural networks can lead to meaningful and\ninterpretable fairness guarantees at little cost to utility.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:14:02 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 22:44:28 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 00:53:43 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 14:03:22 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Yeom", "Samuel", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2002.07752", "submitter": "Prasanth Chatarasi", "authors": "Prasanth Chatarasi, Hyoukjun Kwon, Natesh Raina, Saurabh Malik,\n  Vaisakh Haridas, Angshuman Parashar, Michael Pellauer, Tushar Krishna, Vivek\n  Sarkar", "title": "Marvel: A Data-centric Compiler for DNN Operators on Spatial\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of a spatial DNN accelerator depends heavily on the compiler\nand its cost model ability to generate optimized mappings for various operators\nof DNN models on to the accelerator's compute and memory resources. But,\nexisting cost models lack a formal boundary over the operators for precise and\ntractable analysis, which poses adaptability challenges for new DNN operators.\nTo address this challenge, we leverage the recently introduced Maestro\nData-Centric (MDC) notation. We develop a formal understanding of DNN operators\nwhose mappings can be described in the MDC notation, because any mapping\nadhering to the notation is always analyzable by the MDC's cost model.\nFurthermore, we introduce a transformation for translating mappings into the\nMDC notation for exploring the mapping space.\n  Searching for the optimal mappings is challenging because of the large space\nof mappings, and this challenge gets exacerbated with new operators and diverse\naccelerator configurations.To address this challenge, we propose a decoupled\noff-chip/on-chip approach that decomposes the mapping space into off-chip and\non-chip subspaces, and first optimizes the off-chip subspace followed by the\non-chip subspace. The motivation for this decomposition is to reduce the size\nof the search space dramatically and also to prioritize the optimization of\noff-chip data movement, which is 2-3 orders of magnitude more compared to the\non-chip data movement. We implemented our approach in a tool called {\\em\nMarvel}, and another major benefit of our approach is that it is applicable to\nany DNN operator conformable with the MDC notation.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:39:21 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 19:08:00 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Chatarasi", "Prasanth", ""], ["Kwon", "Hyoukjun", ""], ["Raina", "Natesh", ""], ["Malik", "Saurabh", ""], ["Haridas", "Vaisakh", ""], ["Parashar", "Angshuman", ""], ["Pellauer", "Michael", ""], ["Krishna", "Tushar", ""], ["Sarkar", "Vivek", ""]]}, {"id": "2002.07756", "submitter": "Morteza Haghir Chehreghani", "authors": "Morteza Haghir Chehreghani", "title": "Hierarchical Correlation Clustering and Tree Preserving Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchical correlation clustering method that extends the\nwell-known correlation clustering to produce hierarchical clusters. We then\ninvestigate embedding the respective hierarchy to be used for (tree preserving)\nembedding and feature extraction. We study the connection of such an embedding\nto single linkage embedding and minimax distances, and in particular study\nminimax distances for correlation clustering. Finally, we demonstrate the\nperformance of our methods on several UCI and 20 newsgroup datasets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:44:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chehreghani", "Morteza Haghir", ""]]}, {"id": "2002.07766", "submitter": "Matthew Willetts", "authors": "Alexander Camuto, Matthew Willetts, Brooks Paige, Chris Holmes,\n  Stephen Roberts", "title": "Learning Bijective Feature Maps for Linear ICA", "comments": "8 pages", "journal-ref": "AISTATS 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Separating high-dimensional data like images into independent latent factors,\ni.e independent component analysis (ICA), remains an open research problem. As\nwe show, existing probabilistic deep generative models (DGMs), which are\ntailor-made for image data, underperform on non-linear ICA tasks. To address\nthis, we propose a DGM which combines bijective feature maps with a linear ICA\nmodel to learn interpretable latent structures for high-dimensional data. Given\nthe complexities of jointly training such a hybrid model, we introduce novel\ntheory that constrains linear ICA to lie close to the manifold of orthogonal\nrectangular matrices, the Stiefel manifold. By doing so we create models that\nconverge quickly, are easy to train, and achieve better unsupervised latent\nfactor discovery than flow-based models, linear ICA, and Variational\nAutoencoders on images.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:58:07 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 11:03:28 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 17:10:45 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 17:57:27 GMT"}, {"version": "v5", "created": "Fri, 29 Jan 2021 18:08:28 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Camuto", "Alexander", ""], ["Willetts", "Matthew", ""], ["Paige", "Brooks", ""], ["Holmes", "Chris", ""], ["Roberts", "Stephen", ""]]}, {"id": "2002.07772", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Natalia Ponomareva, Petros Mol, Zhenyu Tan, Rahul\n  Mazumder", "title": "The Tree Ensemble Layer: Differentiability meets Conditional Computation", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and tree ensembles are state-of-the-art learners, each with\nits unique statistical and computational advantages. We aim to combine these\nadvantages by introducing a new layer for neural networks, composed of an\nensemble of differentiable decision trees (a.k.a. soft trees). While\ndifferentiable trees demonstrate promising results in the literature, they are\ntypically slow in training and inference as they do not support conditional\ncomputation. We mitigate this issue by introducing a new sparse activation\nfunction for sample routing, and implement true conditional computation by\ndeveloping specialized forward and backward propagation algorithms that exploit\nsparsity. Our efficient algorithms pave the way for jointly training over deep\nand wide tree ensembles using first-order methods (e.g., SGD). Experiments on\n23 classification datasets indicate over 10x speed-ups compared to the\ndifferentiable trees used in the literature and over 20x reduction in the\nnumber of parameters compared to gradient boosted trees, while maintaining\ncompetitive performance. Moreover, experiments on CIFAR, MNIST, and Fashion\nMNIST indicate that replacing dense layers in CNNs with our tree layer reduces\nthe test loss by 7-53% and the number of parameters by 8x. We provide an\nopen-source TensorFlow implementation with a Keras API.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:05:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 00:40:16 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Ponomareva", "Natalia", ""], ["Mol", "Petros", ""], ["Tan", "Zhenyu", ""], ["Mazumder", "Rahul", ""]]}, {"id": "2002.07775", "submitter": "Jeena Kleenankandy", "authors": "Jeena Kleenankandy, K. A. Abdul Nazeer (Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India)", "title": "An enhanced Tree-LSTM architecture for sentence semantic modeling using\n  typed dependencies", "comments": "Accepted manuscript submitted to Journal of Information Processing\n  and Management ( Elsevier ) on June 11, 2020", "journal-ref": "Information Processing & Management, Elsevier (2020)", "doi": "10.1016/j.ipm.2020.102362", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree-based Long short term memory (LSTM) network has become state-of-the-art\nfor modeling the meaning of language texts as they can effectively exploit the\ngrammatical syntax and thereby non-linear dependencies among words of the\nsentence. However, most of these models cannot recognize the difference in\nmeaning caused by a change in semantic roles of words or phrases because they\ndo not acknowledge the type of grammatical relations, also known as typed\ndependencies, in sentence structure. This paper proposes an enhanced LSTM\narchitecture, called relation gated LSTM, which can model the relationship\nbetween two inputs of a sequence using a control input. We also introduce a\nTree-LSTM model called Typed Dependency Tree-LSTM that uses the sentence\ndependency parse structure as well as the dependency type to embed sentence\nmeaning into a dense vector. The proposed model outperformed its type-unaware\ncounterpart in two typical NLP tasks - Semantic Relatedness Scoring and\nSentiment Analysis, in a lesser number of training epochs. The results were\ncomparable or competitive with other state-of-the-art models. Qualitative\nanalysis showed that changes in the voice of sentences had little effect on the\nmodel's predicted scores, while changes in nominal (noun) words had a more\nsignificant impact. The model recognized subtle semantic relationships in\nsentence pairs. The magnitudes of learned typed dependencies embeddings were\nalso in agreement with human intuitions. The research findings imply the\nsignificance of grammatical relations in sentence modeling. The proposed models\nwould serve as a base for future researches in this direction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:10:03 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 09:45:26 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Kleenankandy", "Jeena", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"], ["Nazeer", "K. A. Abdul", "", "Department of Computer Science\n  and Engineering, National Institute of Technology Calicut, Kerala, India"]]}, {"id": "2002.07784", "submitter": "Julian Portmann", "authors": "Davin Choo, Christoph Grunau, Julian Portmann, V\\'aclav Rozho\\v{n}", "title": "k-means++: few more steps yield constant approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means++ algorithm of Arthur and Vassilvitskii (SODA 2007) is a\nstate-of-the-art algorithm for solving the k-means clustering problem and is\nknown to give an O(log k)-approximation in expectation. Recently, Lattanzi and\nSohler (ICML 2019) proposed augmenting k-means++ with O(k log log k) local\nsearch steps to yield a constant approximation (in expectation) to the k-means\nclustering problem. In this paper, we improve their analysis to show that, for\nany arbitrarily small constant $\\eps > 0$, with only $\\eps k$ additional local\nsearch steps, one can achieve a constant approximation guarantee (with high\nprobability in k), resolving an open problem in their paper.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:28:25 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Choo", "Davin", ""], ["Grunau", "Christoph", ""], ["Portmann", "Julian", ""], ["Rozho\u0148", "V\u00e1clav", ""]]}, {"id": "2002.07788", "submitter": "Ho-Chun Herbert Chang", "authors": "Ho-Chun Herbert Chang", "title": "Multi-Issue Bargaining With Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negotiation is a process where agents aim to work through disputes and\nmaximize their surplus. As the use of deep reinforcement learning in bargaining\ngames is unexplored, this paper evaluates its ability to exploit, adapt, and\ncooperate to produce fair outcomes. Two actor-critic networks were trained for\nthe bidding and acceptance strategy, against time-based agents, behavior-based\nagents, and through self-play. Gameplay against these agents reveals three key\nfindings. 1) Neural agents learn to exploit time-based agents, achieving clear\ntransitions in decision preference values. The Cauchy distribution emerges as\nsuitable for sampling offers, due to its peaky center and heavy tails. The\nkurtosis and variance sensitivity of the probability distributions used for\ncontinuous control produce trade-offs in exploration and exploitation. 2)\nNeural agents demonstrate adaptive behavior against different combinations of\nconcession, discount factors, and behavior-based strategies. 3) Most\nimportantly, neural agents learn to cooperate with other behavior-based agents,\nin certain cases utilizing non-credible threats to force fairer results. This\nbears similarities with reputation-based strategies in the evolutionary\ndynamics, and departs from equilibria in classical game theory.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:33:46 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Chang", "Ho-Chun Herbert", ""]]}, {"id": "2002.07791", "submitter": "Oriol Ramos Terrades", "authors": "O. Ramos Terrades, A. Berenguel, D. Gil", "title": "A flexible outlier detector based on a topology given by graph\n  communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier, or anomaly, detection is essential for optimal performance of\nmachine learning methods and statistical predictive models. It is not just a\ntechnical step in a data cleaning process but a key topic in many fields such\nas fraudulent document detection, in medical applications and assisted\ndiagnosis systems or detecting security threats. In contrast to\npopulation-based methods, neighborhood based local approaches are simple\nflexible methods that have the potential to perform well in small sample size\nunbalanced problems. However, a main concern of local approaches is the impact\nthat the computation of each sample neighborhood has on the method performance.\nMost approaches use a distance in the feature space to define a single\nneighborhood that requires careful selection of several parameters. This work\npresents a local approach based on a local measure of the heterogeneity of\nsample labels in the feature space considered as a topological manifold.\nTopology is computed using the communities of a weighted graph codifying mutual\nnearest neighbors in the feature space. This way, we provide with a set of\nmultiple neighborhoods able to describe the structure of complex spaces without\nparameter fine tuning. The extensive experiments on real-world data sets show\nthat our approach overall outperforms, both, local and global strategies in\nmulti and single view settings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:40:31 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Terrades", "O. Ramos", ""], ["Berenguel", "A.", ""], ["Gil", "D.", ""]]}, {"id": "2002.07793", "submitter": "Zihang Lai", "authors": "Zihang Lai, Erika Lu, Weidi Xie", "title": "MAST: A Memory-Augmented Self-supervised Tracker", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent interest in self-supervised dense tracking has yielded rapid progress,\nbut performance still remains far from supervised methods. We propose a dense\ntracking model trained on videos without any annotations that surpasses\nprevious self-supervised methods on existing benchmarks by a significant margin\n(+15%), and achieves performance comparable to supervised methods. In this\npaper, we first reassess the traditional choices used for self-supervised\ntraining and reconstruction loss by conducting thorough experiments that\nfinally elucidate the optimal choices. Second, we further improve on existing\nmethods by augmenting our architecture with a crucial memory component. Third,\nwe benchmark on large-scale semi-supervised video object segmentation(aka.\ndense tracking), and propose a new metric: generalizability. Our first two\ncontributions yield a self-supervised network that for the first time is\ncompetitive with supervised methods on standard evaluation metrics of dense\ntracking. When measuring generalizability, we show self-supervised approaches\nare actually superior to the majority of supervised methods. We believe this\nnew generalizability metric can better capture the real-world use-cases for\ndense tracking, and will spur new interest in this research direction.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:43:28 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 00:58:21 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Lai", "Zihang", ""], ["Lu", "Erika", ""], ["Xie", "Weidi", ""]]}, {"id": "2002.07803", "submitter": "Tiago Peixoto", "authors": "Tiago P. Peixoto", "title": "Latent Poisson models for networks with heterogeneous density", "comments": "19 pages, 16 figures", "journal-ref": "Phys. Rev. E 102, 012309 (2020)", "doi": "10.1103/PhysRevE.102.012309", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Empirical networks are often globally sparse, with a small average number of\nconnections per node, when compared to the total size of the network. However,\nthis sparsity tends not to be homogeneous, and networks can also be locally\ndense, for example with a few nodes connecting to a large fraction of the rest\nof the network, or with small groups of nodes with a large probability of\nconnections between them. Here we show how latent Poisson models which generate\nhidden multigraphs can be effective at capturing this density heterogeneity,\nwhile being more tractable mathematically than some of the alternatives that\nmodel simple graphs directly. We show how these latent multigraphs can be\nreconstructed from data on simple graphs, and how this allows us to disentangle\ndisassortative degree-degree correlations from the constraints of imposed\ndegree sequences, and to improve the identification of community structure in\nempirically relevant scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:58:13 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 10:57:25 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 14:42:23 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 14:43:43 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Peixoto", "Tiago P.", ""]]}, {"id": "2002.07806", "submitter": "Nir Shlezinger", "authors": "Nariman Farsad, Nir Shlezinger, Andrea J. Goldsmith and Yonina C.\n  Eldar", "title": "Data-Driven Symbol Detection via Model-Based Machine Learning", "comments": "arXiv admin note: text overlap with arXiv:1905.10750", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of symbol detectors in digital communication systems has\ntraditionally relied on statistical channel models that describe the relation\nbetween the transmitted symbols and the observed signal at the receiver. Here\nwe review a data-driven framework to symbol detection design which combines\nmachine learning (ML) and model-based algorithms. In this hybrid approach,\nwell-known channel-model-based algorithms such as the Viterbi method, BCJR\ndetection, and multiple-input multiple-output (MIMO) soft interference\ncancellation (SIC) are augmented with ML-based algorithms to remove their\nchannel-model-dependence, allowing the receiver to learn to implement these\nalgorithms solely from data. The resulting data-driven receivers are most\nsuitable for systems where the underlying channel models are poorly understood,\nhighly complex, or do not well-capture the underlying physics. Our approach is\nunique in that it only replaces the channel-model-based computations with\ndedicated neural networks that can be trained from a small amount of data,\nwhile keeping the general algorithm intact. Our results demonstrate that these\ntechniques can yield near-optimal performance of model-based algorithms without\nknowing the exact channel input-output statistical relationship and in the\npresence of channel state information uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:58:27 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Farsad", "Nariman", ""], ["Shlezinger", "Nir", ""], ["Goldsmith", "Andrea J.", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2002.07833", "submitter": "Dhivya Eswaran", "authors": "Dhivya Eswaran, Srijan Kumar and Christos Faloutsos", "title": "Higher-Order Label Homogeneity and Spreading in Graphs", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Do higher-order network structures aid graph semi-supervised learning? Given\na graph and a few labeled vertices, labeling the remaining vertices is a\nhigh-impact problem with applications in several tasks, such as recommender\nsystems, fraud detection and protein identification. However, traditional\nmethods rely on edges for spreading labels, which is limited as all edges are\nnot equal. Vertices with stronger connections participate in higher-order\nstructures in graphs, which calls for methods that can leverage these\nstructures in the semi-supervised learning tasks.\n  To this end, we propose Higher-Order Label Spreading (HOLS) to spread labels\nusing higher-order structures. HOLS has strong theoretical guarantees and\nreduces to standard label spreading in the base case. Via extensive\nexperiments, we show that higher-order label spreading using triangles in\naddition to edges is up to 4.7% better than label spreading using edges alone.\nCompared to prior traditional and state-of-the-art methods, the proposed method\nleads to statistically significant accuracy gains in all-but-one cases, while\nremaining fast and scalable to large graphs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:09:21 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Eswaran", "Dhivya", ""], ["Kumar", "Srijan", ""], ["Faloutsos", "Christos", ""]]}, {"id": "2002.07836", "submitter": "Kaiyi Ji", "authors": "Kaiyi Ji, Junjie Yang, Yingbin Liang", "title": "Theoretical Convergence of Multi-Step Model-Agnostic Meta-Learning", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a popular meta-learning approach, the model-agnostic meta-learning (MAML)\nalgorithm has been widely used due to its simplicity and effectiveness.\nHowever, the convergence of the general multi-step MAML still remains\nunexplored. In this paper, we develop a new theoretical framework to provide\nsuch convergence guarantee for two types of objective functions that are of\ninterest in practice: (a) resampling case (e.g., reinforcement learning), where\nloss functions take the form in expectation and new data are sampled as the\nalgorithm runs; and (b) finite-sum case (e.g., supervised learning), where loss\nfunctions take the finite-sum form with given samples. For both cases, we\ncharacterize the convergence rate and the computational complexity to attain an\n$\\epsilon$-accurate solution for multi-step MAML in the general nonconvex\nsetting. In particular, our results suggest that an inner-stage stepsize needs\nto be chosen inversely proportional to the number $N$ of inner-stage steps in\norder for $N$-step MAML to have guaranteed convergence. From the technical\nperspective, we develop novel techniques to deal with the nested structure of\nthe meta gradient for multi-step MAML, which can be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:17:54 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:11:20 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 04:03:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Ji", "Kaiyi", ""], ["Yang", "Junjie", ""], ["Liang", "Yingbin", ""]]}, {"id": "2002.07839", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Kumar Kshitij Patel, Sebastian U. Stich, Zhen Dai,\n  Brian Bullins, H. Brendan McMahan, Ohad Shamir, Nathan Srebro", "title": "Is Local SGD Better than Minibatch SGD?", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study local SGD (also known as parallel SGD and federated averaging), a\nnatural and frequently used stochastic distributed optimization method. Its\ntheoretical foundations are currently lacking and we highlight how all existing\nerror guarantees in the convex setting are dominated by a simple baseline,\nminibatch SGD. (1) For quadratic objectives we prove that local SGD strictly\ndominates minibatch SGD and that accelerated local SGD is minimax optimal for\nquadratics; (2) For general convex objectives we provide the first guarantee\nthat at least sometimes improves over minibatch SGD; (3) We show that indeed\nlocal SGD does not dominate minibatch SGD by presenting a lower bound on the\nperformance of local SGD that is worse than the minibatch SGD guarantee.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:22:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:47:48 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Woodworth", "Blake", ""], ["Patel", "Kumar Kshitij", ""], ["Stich", "Sebastian U.", ""], ["Dai", "Zhen", ""], ["Bullins", "Brian", ""], ["McMahan", "H. Brendan", ""], ["Shamir", "Ohad", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.07863", "submitter": "Georg Kohl", "authors": "Georg Kohl, Kiwon Um, Nils Thuerey", "title": "Learning Similarity Metrics for Numerical Simulations", "comments": "Main paper: 9 pages, Appendix: 19 pages. Accepted at ICML 2020.\n  Source code available at https://github.com/tum-pbs/LSIM and further\n  information at https://ge.in.tum.de/publications/2020-lsim-kohl/", "journal-ref": "Proceedings of Machine Learning Research 119 (2020) 5349-5360", "doi": null, "report-no": null, "categories": "cs.LG physics.data-an physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network-based approach that computes a stable and\ngeneralizing metric (LSiM) to compare data from a variety of numerical\nsimulation sources. We focus on scalar time-dependent 2D data that commonly\narises from motion and transport-based partial differential equations (PDEs).\nOur method employs a Siamese network architecture that is motivated by the\nmathematical properties of a metric. We leverage a controllable data generation\nsetup with PDE solvers to create increasingly different outputs from a\nreference simulation in a controlled environment. A central component of our\nlearned metric is a specialized loss function that introduces knowledge about\nthe correlation between single data samples into the training process. To\ndemonstrate that the proposed approach outperforms existing metrics for vector\nspaces and other learned, image-based metrics, we evaluate the different\nmethods on a large range of test data. Additionally, we analyze generalization\nbenefits of an adjustable training data difficulty and demonstrate the\nrobustness of LSiM via an evaluation on three real-world data sets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:11:15 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 18:14:55 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Kohl", "Georg", ""], ["Um", "Kiwon", ""], ["Thuerey", "Nils", ""]]}, {"id": "2002.07867", "submitter": "Quynh Nguyen", "authors": "Quynh Nguyen and Marco Mondelli", "title": "Global Convergence of Deep Networks with One Wide Layer Followed by\n  Pyramidal Topology", "comments": "Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that gradient descent can find a global minimum for\nover-parameterized neural networks where the widths of all the hidden layers\nscale polynomially with $N$ ($N$ being the number of training samples). In this\npaper, we prove that, for deep networks, a single layer of width $N$ following\nthe input layer suffices to ensure a similar guarantee. In particular, all the\nremaining layers are allowed to have constant widths, and form a pyramidal\ntopology. We show an application of our result to the widely used LeCun's\ninitialization and obtain an over-parameterization requirement for the single\nwide layer of order $N^2.$\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:21:27 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 15:23:02 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 19:45:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Nguyen", "Quynh", ""], ["Mondelli", "Marco", ""]]}, {"id": "2002.07870", "submitter": "Mouhyemen Khan", "authors": "Mouhyemen Khan and Abhijit Chatterjee", "title": "Online Parameter Estimation for Safety-Critical Systems with Gaussian\n  Processes", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation is crucial for modeling, tracking, and control of\ncomplex dynamical systems. However, parameter uncertainties can compromise\nsystem performance under a controller relying on nominal parameter values.\nTypically, parameters are estimated using numerical regression approaches\nframed as inverse problems. However, they suffer from non-uniqueness due to\nexistence of multiple local optima, reliance on gradients, numerous\nexperimental data, or stability issues. Addressing these drawbacks, we present\na Bayesian optimization framework based on Gaussian processes (GPs) for online\nparameter estimation. It uses an efficient search strategy over a response\nsurface in the parameter space for finding the global optima with minimal\nfunction evaluations. The response surface is modeled as correlated surrogates\nusing GPs on noisy data. The GP posterior predictive variance is exploited for\nsmart adaptive sampling. This balances the exploration versus exploitation\ntrade-off which is key in reaching the global optima under limited budget. We\ndemonstrate our technique on an actuated planar pendulum and safety-critical\nquadrotor in simulation with changing parameters. We also benchmark our results\nagainst solvers using interior point method and sequential quadratic program.\nBy reconfiguring the controller with new optimized parameters iteratively, we\ndrastically improve trajectory tracking of the system versus the nominal case\nand other solvers.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:38:00 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Khan", "Mouhyemen", ""], ["Chatterjee", "Abhijit", ""]]}, {"id": "2002.07873", "submitter": "Emily T Winn", "authors": "Emily T. Winn, Marilyn Vazquez, Prachi Loliencar, Kaisa Taipale, Xu\n  Wang and Giseon Heo", "title": "A survey of statistical learning techniques as applied to inexpensive\n  pediatric Obstructive Sleep Apnea data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pediatric obstructive sleep apnea affects an estimated 1-5% of\nelementary-school aged children and can lead to other detrimental health\nproblems. Swift diagnosis and treatment are critical to a child's growth and\ndevelopment, but the variability of symptoms and the complexity of the\navailable data make this a challenge. We take a first step in streamlining the\nprocess by focusing on inexpensive data from questionnaires and craniofacial\nmeasurements. We apply correlation networks, the Mapper algorithm from\ntopological data analysis, and singular value decomposition in a process of\nexploratory data analysis. We then apply a variety of supervised and\nunsupervised learning techniques from statistics, machine learning, and\ntopology, ranging from support vector machines to Bayesian classifiers and\nmanifold learning. Finally, we analyze the results of each of these methods and\ndiscuss the implications for a multi-data-sourced algorithm moving forward.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 18:15:32 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 14:35:46 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Winn", "Emily T.", ""], ["Vazquez", "Marilyn", ""], ["Loliencar", "Prachi", ""], ["Taipale", "Kaisa", ""], ["Wang", "Xu", ""], ["Heo", "Giseon", ""]]}, {"id": "2002.07874", "submitter": "Matthew Leming", "authors": "Matthew Leming, Juan Manuel G\\'orriz, John Suckling", "title": "Ensemble Deep Learning on Large, Mixed-Site fMRI Datasets in Autism and\n  Other Tasks", "comments": null, "journal-ref": null, "doi": "10.1142/S0129065720500124", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models for MRI classification face two recurring problems: they\nare typically limited by low sample size, and are abstracted by their own\ncomplexity (the \"black box problem\"). In this paper, we train a convolutional\nneural network (CNN) with the largest multi-source, functional MRI (fMRI)\nconnectomic dataset ever compiled, consisting of 43,858 datapoints. We apply\nthis model to a cross-sectional comparison of autism (ASD) vs typically\ndeveloping (TD) controls that has proved difficult to characterise with\ninferential statistics. To contextualise these findings, we additionally\nperform classifications of gender and task vs rest. Employing class-balancing\nto build a training set, we trained 3$\\times$300 modified CNNs in an ensemble\nmodel to classify fMRI connectivity matrices with overall AUROCs of 0.6774,\n0.7680, and 0.9222 for ASD vs TD, gender, and task vs rest, respectively.\nAdditionally, we aim to address the black box problem in this context using two\nvisualization methods. First, class activation maps show which functional\nconnections of the brain our models focus on when performing classification.\nSecond, by analyzing maximal activations of the hidden layers, we were also\nable to explore how the model organizes a large and mixed-centre dataset,\nfinding that it dedicates specific areas of its hidden layers to processing\ndifferent covariates of data (depending on the independent variable analyzed),\nand other areas to mix data from different sources. Our study finds that deep\nlearning models that distinguish ASD from TD controls focus broadly on temporal\nand cerebellar connections, with a particularly high focus on the right caudate\nnucleus and paracentral sulcus.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 17:28:16 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:31:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Leming", "Matthew", ""], ["G\u00f3rriz", "Juan Manuel", ""], ["Suckling", "John", ""]]}, {"id": "2002.07877", "submitter": "Subhadip Maji", "authors": "Subhadip Maji and Smarajit Bose", "title": "CBIR using features derived by Deep Learning", "comments": "18 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Content Based Image Retrieval (CBIR) System, the task is to retrieve\nsimilar images from a large database given a query image. The usual procedure\nis to extract some useful features from the query image, and retrieve images\nwhich have similar set of features. For this purpose, a suitable similarity\nmeasure is chosen, and images with high similarity scores are retrieved.\nNaturally the choice of these features play a very important role in the\nsuccess of this system, and high level features are required to reduce the\nsemantic gap.\n  In this paper, we propose to use features derived from pre-trained network\nmodels from a deep-learning convolution network trained for a large image\nclassification problem. This approach appears to produce vastly superior\nresults for a variety of databases, and it outperforms many contemporary CBIR\nsystems. We analyse the retrieval time of the method, and also propose a\npre-clustering of the database based on the above-mentioned features which\nyields comparable results in a much shorter time in most of the cases.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 21:26:32 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Maji", "Subhadip", ""], ["Bose", "Smarajit", ""]]}, {"id": "2002.07884", "submitter": "Armen Allahverdyan", "authors": "A.E. Allahverdyan", "title": "Observational nonidentifiability, generalized likelihood and free energy", "comments": "25 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameter estimation problem in mixture models with\nobservational nonidentifiability: the full model (also containing hidden\nvariables) is identifiable, but the marginal (observed) model is not. Hence\nglobal maxima of the marginal likelihood are (infinitely) degenerate and\npredictions of the marginal likelihood are not unique. We show how to\ngeneralize the marginal likelihood by introducing an effective temperature, and\nmaking it similar to the free energy. This generalization resolves the\nobservational nonidentifiability, since its maximization leads to unique\nresults that are better than a random selection of one degenerate maximum of\nthe marginal likelihood or the averaging over many such maxima. The generalized\nlikelihood inherits many features from the usual likelihood, e.g. it holds the\nconditionality principle, and its local maximum can be searched for via\nsuitably modified expectation-maximization method. The maximization of the\ngeneralized likelihood relates to entropy optimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:22:14 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Allahverdyan", "A. E.", ""]]}, {"id": "2002.07891", "submitter": "Pu Zhao", "authors": "Pu Zhao, Pin-Yu Chen, Siyue Wang, Xue Lin", "title": "Towards Query-Efficient Black-Box Adversary with Zeroth-Order Natural\n  Gradient Descent", "comments": "accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great achievements of the modern deep neural networks (DNNs), the\nvulnerability/robustness of state-of-the-art DNNs raises security concerns in\nmany application domains requiring high reliability. Various adversarial\nattacks are proposed to sabotage the learning performance of DNN models. Among\nthose, the black-box adversarial attack methods have received special\nattentions owing to their practicality and simplicity. Black-box attacks\nusually prefer less queries in order to maintain stealthy and low costs.\nHowever, most of the current black-box attack methods adopt the first-order\ngradient descent method, which may come with certain deficiencies such as\nrelatively slow convergence and high sensitivity to hyper-parameter settings.\nIn this paper, we propose a zeroth-order natural gradient descent (ZO-NGD)\nmethod to design the adversarial attacks, which incorporates the zeroth-order\ngradient estimation technique catering to the black-box attack scenario and the\nsecond-order natural gradient descent to achieve higher query efficiency. The\nempirical evaluations on image classification datasets demonstrate that ZO-NGD\ncan obtain significantly lower model query complexities compared with\nstate-of-the-art attack methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:48:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhao", "Pu", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Siyue", ""], ["Lin", "Xue", ""]]}, {"id": "2002.07897", "submitter": "Przemys{\\l}aw Spurek", "authors": "{\\L}ukasz Struski, Szymon Knop, Jacek Tabor, Wiktor Daniec,\n  Przemys{\\l}aw Spurek", "title": "LocoGAN -- Locally Convolutional GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we construct a fully convolutional GAN model: LocoGAN, which\nlatent space is given by noise-like images of possibly different resolutions.\nThe learning is local, i.e. we process not the whole noise-like image, but the\nsub-images of a fixed size. As a consequence LocoGAN can produce images of\narbitrary dimensions e.g. LSUN bedroom data set. Another advantage of our\napproach comes from the fact that we use the position channels, which allows\nthe generation of fully periodic (e.g. cylindrical panoramic images) or almost\nperiodic ,,infinitely long\" images (e.g. wall-papers).\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:03:27 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Struski", "\u0141ukasz", ""], ["Knop", "Szymon", ""], ["Tabor", "Jacek", ""], ["Daniec", "Wiktor", ""], ["Spurek", "Przemys\u0142aw", ""]]}, {"id": "2002.07898", "submitter": "Wen Tang", "authors": "Wen Tang, Emilie Chouzenoux, Jean-Christophe Pesquet, and Hamid Krim", "title": "Deep Transform and Metric Learning Network: Wedding Deep Dictionary\n  Learning and Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On account of its many successes in inference tasks and denoising\napplications, Dictionary Learning (DL) and its related sparse optimization\nproblems have garnered a lot of research interest. While most solutions have\nfocused on single layer dictionaries, the improved recently proposed Deep DL\n(DDL) methods have also fallen short on a number of issues. We propose herein,\na novel DDL approach where each DL layer can be formulated as a combination of\none linear layer and a Recurrent Neural Network (RNN). The RNN is shown to\nflexibly account for the layer-associated and learned metric. Our proposed work\nunveils new insights into Neural Networks and DDL and provides a new, efficient\nand competitive approach to jointly learn a deep transform and a metric for\ninference applications. Extensive experiments are carried out to demonstrate\nthat the proposed method can not only outperform existing DDL but also\nstate-of-the-art generic CNNs.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:04:11 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 01:57:18 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Tang", "Wen", ""], ["Chouzenoux", "Emilie", ""], ["Pesquet", "Jean-Christophe", ""], ["Krim", "Hamid", ""]]}, {"id": "2002.07905", "submitter": "Daniel Vial", "authors": "Daniel Vial, Vijay Subramanian", "title": "Empirical Policy Evaluation with Supergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise and analyze algorithms for the empirical policy evaluation problem\nin reinforcement learning. Our algorithms explore backward from high-cost\nstates to find high-value ones, in contrast to forward approaches that work\nforward from all states. While several papers have demonstrated the utility of\nbackward exploration empirically, we conduct rigorous analyses which show that\nour algorithms can reduce average-case sample complexity from $O(S \\log S)$ to\nas low as $O(\\log S)$.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:17:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Vial", "Daniel", ""], ["Subramanian", "Vijay", ""]]}, {"id": "2002.07906", "submitter": "Wei Zhang", "authors": "Wei Zhang, Thomas Kobber Panum, Somesh Jha, Prasad Chalasani, and\n  David Page", "title": "CAUSE: Learning Granger Causality from Event Sequences using Attribution\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Granger causality between event types from\nasynchronous, interdependent, multi-type event sequences. Existing work suffers\nfrom either limited model flexibility or poor model explainability and thus\nfails to uncover Granger causality across a wide variety of event sequences\nwith diverse event interdependency. To address these weaknesses, we propose\nCAUSE (Causality from AttribUtions on Sequence of Events), a novel framework\nfor the studied task. The key idea of CAUSE is to first implicitly capture the\nunderlying event interdependency by fitting a neural point process, and then\nextract from the process a Granger causality statistic using an axiomatic\nattribution method. Across multiple datasets riddled with diverse event\ninterdependency, we demonstrate that CAUSE achieves superior performance on\ncorrectly inferring the inter-type Granger causality over a range of\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:21:11 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Wei", ""], ["Panum", "Thomas Kobber", ""], ["Jha", "Somesh", ""], ["Chalasani", "Prasad", ""], ["Page", "David", ""]]}, {"id": "2002.07911", "submitter": "Sharath Chandra Raparthy", "authors": "Sharath Chandra Raparthy, Bhairav Mehta, Florian Golemo, Liam Paull", "title": "Generating Automatic Curricula via Self-Supervised Active Domain\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-directed Reinforcement Learning (RL) traditionally considers an agent\ninteracting with an environment, prescribing a real-valued reward to an agent\nproportional to the completion of some goal. Goal-directed RL has seen large\ngains in sample efficiency, due to the ease of reusing or generating new\nexperience by proposing goals. One approach,self-play, allows an agent to\n\"play\" against itself by alternatively setting and accomplishing goals,\ncreating a learned curriculum through which an agent can learn to accomplish\nprogressively more difficult goals. However, self-play has been limited to goal\ncurriculum learning or learning progressively harder goals within a single\nenvironment. Recent work on robotic agents has shown that varying the\nenvironment during training, for example with domain randomization, leads to\nmore robust transfer. As a result, we extend the self-play framework to jointly\nlearn a goal and environment curriculum, leading to an approach that learns the\nmost fruitful domain randomization strategy with self-play. Our method,\nSelf-Supervised Active Domain Randomization(SS-ADR), generates a coupled\ngoal-task curriculum, where agents learn through progressively more difficult\ntasks and environment variations. By encouraging the agent to try tasks that\nare just outside of its current capabilities, SS-ADR builds a domain\nrandomization curriculum that enables state-of-the-art results on\nvarioussim2real transfer tasks. Our results show that a curriculum of\nco-evolving the environment difficulty together with the difficulty of goals\nset in each environment provides practical benefits in the goal-directed tasks\ntested.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:45:29 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 18:24:29 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Raparthy", "Sharath Chandra", ""], ["Mehta", "Bhairav", ""], ["Golemo", "Florian", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07916", "submitter": "Siddhartha Jain", "authors": "Siddhartha Jain, Ge Liu, David Gifford", "title": "Information Condensing Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Information Condensing Active Learning (ICAL), a batch mode\nmodel agnostic Active Learning (AL) method targeted at Deep Bayesian Active\nLearning that focuses on acquiring labels for points which have as much\ninformation as possible about the still unacquired points. ICAL uses the\nHilbert Schmidt Independence Criterion (HSIC) to measure the strength of the\ndependency between a candidate batch of points and the unlabeled set. We\ndevelop key optimizations that allow us to scale our method to large unlabeled\nsets. We show significant improvements in terms of model accuracy and negative\nlog likelihood (NLL) on several image datasets compared to state of the art\nbatch mode AL methods for deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:55:08 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 02:52:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jain", "Siddhartha", ""], ["Liu", "Ge", ""], ["Gifford", "David", ""]]}, {"id": "2002.07917", "submitter": "Nima Noorshams", "authors": "Nima Noorshams, Saurabh Verma, Aude Hofleitner", "title": "TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook", "comments": "Submitted to KDD 2020 applied DS track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 22:56:40 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Noorshams", "Nima", ""], ["Verma", "Saurabh", ""], ["Hofleitner", "Aude", ""]]}, {"id": "2002.07920", "submitter": "Siyue Wang", "authors": "Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, and Peter Chin", "title": "Block Switching: A Stochastic Approach for Deep Learning Security", "comments": "Accepted by AdvML19: Workshop on Adversarial Learning Methods for\n  Machine Learning and Data Mining at KDD, Anchorage, Alaska, USA, August 5th,\n  2019, 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent study of adversarial attacks has revealed the vulnerability of modern\ndeep learning models. That is, subtly crafted perturbations of the input can\nmake a trained network with high accuracy produce arbitrary incorrect\npredictions, while maintain imperceptible to human vision system. In this\npaper, we introduce Block Switching (BS), a defense strategy against\nadversarial attacks based on stochasticity. BS replaces a block of model layers\nwith multiple parallel channels, and the active channel is randomly assigned in\nthe run time hence unpredictable to the adversary. We show empirically that BS\nleads to a more dispersed input gradient distribution and superior defense\neffectiveness compared with other stochastic defenses such as stochastic\nactivation pruning (SAP). Compared to other defenses, BS is also characterized\nby the following features: (i) BS causes less test accuracy drop; (ii) BS is\nattack-independent and (iii) BS is compatible with other defenses and can be\nused jointly with others.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 23:14:25 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Siyue", ""], ["Chen", "Pin-Yu", ""], ["Lin", "Xue", ""], ["Chin", "Peter", ""]]}, {"id": "2002.07922", "submitter": "Mehrdad Farahani", "authors": "Mehrdad Farahani, Marzieh Farahani, Mohammad Manthouri, Okyay Kaynak", "title": "Short-Term Traffic Flow Prediction Using Variational LSTM Networks", "comments": "18 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traffic flow characteristics are one of the most critical decision-making and\ntraffic policing factors in a region. Awareness of the predicted status of the\ntraffic flow has prime importance in traffic management and traffic information\ndivisions. The purpose of this research is to suggest a forecasting model for\ntraffic flow by using deep learning techniques based on historical data in the\nIntelligent Transportation Systems area. The historical data collected from the\nCaltrans Performance Measurement Systems (PeMS) for six months in 2019. The\nproposed prediction model is a Variational Long Short-Term Memory Encoder in\nbrief VLSTM-E try to estimate the flow accurately in contrast to other\nconventional methods. VLSTM-E can provide more reliable short-term traffic flow\nby considering the distribution and missing values.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 23:22:31 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Farahani", "Mehrdad", ""], ["Farahani", "Marzieh", ""], ["Manthouri", "Mohammad", ""], ["Kaynak", "Okyay", ""]]}, {"id": "2002.07933", "submitter": "Hrayr Harutyunyan", "authors": "Hrayr Harutyunyan, Kyle Reing, Greg Ver Steeg, Aram Galstyan", "title": "Improving Generalization by Controlling Label-Noise Information in\n  Neural Network Weights", "comments": "ICML, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of noisy or incorrect labels, neural networks have the\nundesirable tendency to memorize information about the noise. Standard\nregularization techniques such as dropout, weight decay or data augmentation\nsometimes help, but do not prevent this behavior. If one considers neural\nnetwork weights as random variables that depend on the data and stochasticity\nof training, the amount of memorized information can be quantified with the\nShannon mutual information between weights and the vector of all training\nlabels given inputs, $I(w ; \\mathbf{y} \\mid \\mathbf{x})$. We show that for any\ntraining algorithm, low values of this term correspond to reduction in\nmemorization of label-noise and better generalization bounds. To obtain these\nlow values, we propose training algorithms that employ an auxiliary network\nthat predicts gradients in the final layers of a classifier without accessing\nlabels. We illustrate the effectiveness of our approach on versions of MNIST,\nCIFAR-10, and CIFAR-100 corrupted with various noise models, and on a\nlarge-scale dataset Clothing1M that has noisy labels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:08:30 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:41:41 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Harutyunyan", "Hrayr", ""], ["Reing", "Kyle", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "2002.07940", "submitter": "Florian List", "authors": "Florian List and Geraint F. Lewis", "title": "A unified framework for 21cm tomography sample generation and parameter\n  inference with Progressively Growing GANs", "comments": "15 pages, 8+1 figures, accepted by MNRAS", "journal-ref": null, "doi": "10.1093/mnras/staa523", "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a database of 21cm brightness temperature signals from the Epoch of\nReionisation (EoR) for an array of reionisation histories is a complex and\ncomputationally expensive task, given the range of astrophysical processes\ninvolved and the possibly high-dimensional parameter space that is to be\nprobed. We utilise a specific type of neural network, a Progressively Growing\nGenerative Adversarial Network (PGGAN), to produce realistic tomography images\nof the 21cm brightness temperature during the EoR, covering a continuous\nthree-dimensional parameter space that models varying X-ray emissivity, Lyman\nband emissivity, and ratio between hard and soft X-rays. The GPU-trained\nnetwork generates new samples at a resolution of $\\sim 3'$ in a second (on a\nlaptop CPU), and the resulting global 21cm signal, power spectrum, and pixel\ndistribution function agree well with those of the training data, taken from\nthe 21SSD catalogue \\citep{Semelin2017}. Finally, we showcase how a trained\nPGGAN can be leveraged for the converse task of inferring parameters from 21cm\ntomography samples via Approximate Bayesian Computation.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:39:50 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["List", "Florian", ""], ["Lewis", "Geraint F.", ""]]}, {"id": "2002.07942", "submitter": "John Thickstun", "authors": "Vivek Jayaram, John Thickstun", "title": "Source Separation with Deep Generative Priors", "comments": "20 pages; ICML camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial progress in signal source separation, results for richly\nstructured data continue to contain perceptible artifacts. In contrast, recent\ndeep generative models can produce authentic samples in a variety of domains\nthat are indistinguishable from samples of the data distribution. This paper\nintroduces a Bayesian approach to source separation that uses generative models\nas priors over the components of a mixture of sources, and noise-annealed\nLangevin dynamics to sample from the posterior distribution of sources given a\nmixture. This decouples the source separation problem from generative modeling,\nenabling us to directly use cutting-edge generative models as priors. The\nmethod achieves state-of-the-art performance for MNIST digit separation. We\nintroduce new methodology for evaluating separation quality on richer datasets,\nproviding quantitative evaluation of separation results on CIFAR-10. We also\nprovide qualitative results on LSUN.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:48:19 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:19:09 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jayaram", "Vivek", ""], ["Thickstun", "John", ""]]}, {"id": "2002.07948", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar", "title": "Personalized Federated Learning: A Meta-Learning Approach", "comments": "To appear in 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Federated Learning, we aim to train models across multiple computing units\n(users), while users can only communicate with a common central server, without\nexchanging their data samples. This mechanism exploits the computational power\nof all users and allows users to obtain a richer model as their models are\ntrained over a larger set of data points. However, this scheme only develops a\ncommon output for all the users, and, therefore, it does not adapt the model to\neach user. This is an important missing feature, especially given the\nheterogeneity of the underlying data distribution for various users. In this\npaper, we study a personalized variant of the federated learning in which our\ngoal is to find an initial shared model that current or new users can easily\nadapt to their local dataset by performing one or a few steps of gradient\ndescent with respect to their own data. This approach keeps all the benefits of\nthe federated learning architecture, and, by structure, leads to a more\npersonalized model for each user. We show this problem can be studied within\nthe Model-Agnostic Meta-Learning (MAML) framework. Inspired by this connection,\nwe study a personalized variant of the well-known Federated Averaging algorithm\nand evaluate its performance in terms of gradient norm for non-convex loss\nfunctions. Further, we characterize how this performance is affected by the\ncloseness of underlying distributions of user data, measured in terms of\ndistribution distances such as Total Variation and 1-Wasserstein metric.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:08:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 04:16:11 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 02:52:01 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 03:04:01 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Fallah", "Alireza", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.07956", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Tristan Deleu, Sharath Chandra Raparthy, Chris J. Pal,\n  Liam Paull", "title": "Curriculum in Gradient-Based Meta-Reinforcement Learning", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learners such as Model-Agnostic Meta-Learning (MAML) have\nshown strong few-shot performance in supervised and reinforcement learning\nsettings. However, specifically in the case of meta-reinforcement learning\n(meta-RL), we can show that gradient-based meta-learners are sensitive to task\ndistributions. With the wrong curriculum, agents suffer the effects of\nmeta-overfitting, shallow adaptation, and adaptation instability. In this work,\nwe begin by highlighting intriguing failure cases of gradient-based meta-RL and\nshow that task distributions can wildly affect algorithmic outputs, stability,\nand performance. To address this problem, we leverage insights from recent\nliterature on domain randomization and propose meta Active Domain Randomization\n(meta-ADR), which learns a curriculum of tasks for gradient-based meta-RL in a\nsimilar as ADR does for sim2real transfer. We show that this approach induces\nmore stable policies on a variety of simulated locomotion and navigation tasks.\nWe assess in- and out-of-distribution generalization and find that the learned\ntask distributions, even in an unstructured task space, greatly improve the\nadaptation performance of MAML. Finally, we motivate the need for better\nbenchmarking in meta-RL that prioritizes \\textit{generalization} over\nsingle-task adaption performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:40:45 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mehta", "Bhairav", ""], ["Deleu", "Tristan", ""], ["Raparthy", "Sharath Chandra", ""], ["Pal", "Chris J.", ""], ["Paull", "Liam", ""]]}, {"id": "2002.07962", "submitter": "Da Xu", "authors": "Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, Kannan Achan", "title": "Inductive Representation Learning on Temporal Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive representation learning on temporal graphs is an important step\ntoward salable machine learning on real-world dynamic networks. The evolving\nnature of temporal dynamic graphs requires handling new nodes as well as\ncapturing temporal patterns. The node embeddings, which are now functions of\ntime, should represent both the static node features and the evolving\ntopological structures. Moreover, node and topological features can be temporal\nas well, whose patterns the node embeddings should also capture. We propose the\ntemporal graph attention (TGAT) layer to efficiently aggregate\ntemporal-topological neighborhood features as well as to learn the time-feature\ninteractions. For TGAT, we use the self-attention mechanism as building block\nand develop a novel functional time encoding technique based on the classical\nBochner's theorem from harmonic analysis. By stacking TGAT layers, the network\nrecognizes the node embeddings as functions of time and is able to inductively\ninfer embeddings for both new and observed nodes as the graph evolves. The\nproposed approach handles both node classification and link prediction task,\nand can be naturally extended to include the temporal edge features. We\nevaluate our method with transductive and inductive tasks under temporal\nsettings with two benchmark and one industrial dataset. Our TGAT model compares\nfavorably to state-of-the-art baselines as well as the previous temporal graph\nembedding approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:05:37 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Xu", "Da", ""], ["Ruan", "Chuanwei", ""], ["Korpeoglu", "Evren", ""], ["Kumar", "Sushant", ""], ["Achan", "Kannan", ""]]}, {"id": "2002.07964", "submitter": "Yanzhao Li", "authors": "Shaolong Sun, Yanzhao Li, Ju-e Guo, Shouyang Wang", "title": "Tourism Demand Forecasting: An Ensemble Deep Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of tourism-related big data increases the potential to\nimprove the accuracy of tourism demand forecasting, but presents significant\nchallenges for forecasting, including curse of dimensionality and high model\ncomplexity. A novel bagging-based multivariate ensemble deep learning approach\nintegrating stacked autoencoders and kernel-based extreme learning machines\n(B-SAKE) is proposed to address these challenges in this study. By using\nhistorical tourist arrival data, economic variable data and search intensity\nindex (SII) data, we forecast tourist arrivals in Beijing from four countries.\nThe consistent results of multiple schemes suggest that our proposed B-SAKE\napproach outperforms benchmark models in terms of level accuracy, directional\naccuracy and even statistical significance. Both bagging and stacked\nautoencoder can effectively alleviate the challenges brought by tourism big\ndata and improve the forecasting performance of the models. The ensemble deep\nlearning model we propose contributes to tourism forecasting literature and\nbenefits relevant government officials and tourism practitioners.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:23:38 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:30:18 GMT"}, {"version": "v3", "created": "Sat, 16 Jan 2021 08:02:31 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Sun", "Shaolong", ""], ["Li", "Yanzhao", ""], ["Guo", "Ju-e", ""], ["Wang", "Shouyang", ""]]}, {"id": "2002.07965", "submitter": "Taejong Joo", "authors": "Taejong Joo, Uijung Chung, Min-Gwan Seo", "title": "Being Bayesian about Categorical Probability", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks utilize the softmax as a building block in classification\ntasks, which contains an overconfidence problem and lacks an uncertainty\nrepresentation ability. As a Bayesian alternative to the softmax, we consider a\nrandom variable of a categorical probability over class labels. In this\nframework, the prior distribution explicitly models the presumed noise inherent\nin the observed label, which provides consistent gains in generalization\nperformance in multiple challenging tasks. The proposed method inherits\nadvantages of Bayesian approaches that achieve better uncertainty estimation\nand model calibration. Our method can be implemented as a plug-and-play loss\nfunction with negligible computational overhead compared to the softmax with\nthe cross-entropy loss function.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 02:35:32 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 13:00:28 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Joo", "Taejong", ""], ["Chung", "Uijung", ""], ["Seo", "Min-Gwan", ""]]}, {"id": "2002.07971", "submitter": "Sarkhan Badirli", "authors": "Sarkhan Badirli, Xuanqing Liu, Zhengming Xing, Avradeep Bhowmik, Khoa\n  Doan, and Sathiya S. Keerthi", "title": "Gradient Boosting Neural Networks: GrowNet", "comments": "Supplementary material starts after references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel gradient boosting framework is proposed where shallow neural networks\nare employed as ``weak learners''. General loss functions are considered under\nthis unified framework with specific examples presented for classification,\nregression, and learning to rank. A fully corrective step is incorporated to\nremedy the pitfall of greedy function approximation of classic gradient\nboosting decision tree. The proposed model rendered outperforming results\nagainst state-of-the-art boosting methods in all three tasks on multiple\ndatasets. An ablation study is performed to shed light on the effect of each\nmodel components and model hyperparameters.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:02:52 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 22:07:54 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Badirli", "Sarkhan", ""], ["Liu", "Xuanqing", ""], ["Xing", "Zhengming", ""], ["Bhowmik", "Avradeep", ""], ["Doan", "Khoa", ""], ["Keerthi", "Sathiya S.", ""]]}, {"id": "2002.07994", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Best-item Learning in Random Utility Models with Subset Choices", "comments": "Accepted to 23rd International Conference on Artificial Intelligence\n  and Statistics (AISTATS), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of PAC learning the most valuable item from a pool of\n$n$ items using sequential, adaptively chosen plays of subsets of $k$ items,\nwhen, upon playing a subset, the learner receives relative feedback sampled\naccording to a general Random Utility Model (RUM) with independent noise\nperturbations to the latent item utilities. We identify a new property of such\na RUM, termed the minimum advantage, that helps in characterizing the\ncomplexity of separating pairs of items based on their relative win/loss\nempirical counts, and can be bounded as a function of the noise distribution\nalone. We give a learning algorithm for general RUMs, based on pairwise\nrelative counts of items and hierarchical elimination, along with a new PAC\nsample complexity guarantee of $O(\\frac{n}{c^2\\epsilon^2} \\log\n\\frac{k}{\\delta})$ rounds to identify an $\\epsilon$-optimal item with\nconfidence $1-\\delta$, when the worst case pairwise advantage in the RUM has\nsensitivity at least $c$ to the parameter gaps of items. Fundamental lower\nbounds on PAC sample complexity show that this is near-optimal in terms of its\ndependence on $n,k$ and $c$.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 03:57:16 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2002.07997", "submitter": "Xudong Li None", "authors": "Xudong Li, Yang Hu, Jianhua Zheng, Mingtao Li", "title": "Neural Architecture Search For Fault Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have made great progress in fault diagnosis, especially\ndeep learning method. Deep learning is suitable for processing big data, and\nhas a strong feature extraction ability to realize end-to-end fault diagnosis\nsystems. However, designing neural network architecture requires rich\nprofessional knowledge and debugging experience, and a lot of experiments are\nneeded to screen models and hyperparameters, increasing the difficulty of\ndeveloping deep learning models. Frortunately, neural architecture search (NAS)\nis developing rapidly, and is becoming one of the next directions for deep\nlearning. In this paper, we proposed a NAS method for fault diagnosis using\nreinforcement learning. A recurrent neural network is used as an agent to\ngenerate network architecture. The accuracy of the generated network on the\nvalidation dataset is fed back to the agent as a reward, and the parameters of\nthe agent are updated through the strategy gradient algorithm. We use PHM 2009\nData Challenge gearbox dataset to prove the effectiveness of proposed method,\nand obtain state-of-the-art results compared with other artificial designed\nnetwork structures. To author's best knowledge, it's the first time that NAS\nhas been applied in fault diagnosis.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:03:51 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Li", "Xudong", ""], ["Hu", "Yang", ""], ["Zheng", "Jianhua", ""], ["Li", "Mingtao", ""]]}, {"id": "2002.08000", "submitter": "Guanlin Liu", "authors": "Guanlin Liu and Lifeng lai", "title": "Action-Manipulation Attacks Against Stochastic Bandits: Attacks and\n  Defense", "comments": "13 pages, 7 figures, submitted to IEEE Transaction on Signal\n  Processing", "journal-ref": null, "doi": "10.1109/TSP.2020.3021525", "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the broad range of applications of stochastic multi-armed bandit\nmodel, understanding the effects of adversarial attacks and designing bandit\nalgorithms robust to attacks are essential for the safe applications of this\nmodel. In this paper, we introduce a new class of attack named\naction-manipulation attack. In this attack, an adversary can change the action\nsignal selected by the user. We show that without knowledge of mean rewards of\narms, our proposed attack can manipulate Upper Confidence Bound (UCB)\nalgorithm, a widely used bandit algorithm, into pulling a target arm very\nfrequently by spending only logarithmic cost. To defend against this class of\nattacks, we introduce a novel algorithm that is robust to action-manipulation\nattacks when an upper bound for the total attack cost is given. We prove that\nour algorithm has a pseudo-regret upper bounded by $\\mathcal{O}(\\max\\{\\log\nT,A\\})$, where $T$ is the total number of rounds and $A$ is the upper bound of\nthe total attack cost.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 04:09:15 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 22:14:33 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Guanlin", ""], ["lai", "Lifeng", ""]]}, {"id": "2002.08012", "submitter": "Tsubasa Takahashi", "authors": "Tsubasa Takahashi", "title": "Indirect Adversarial Attacks via Poisoning Neighbors for Graph\n  Convolutional Networks", "comments": "Accepted in IEEE BigData 2019", "journal-ref": null, "doi": "10.1109/BigData47090.2019.9006004", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks, which learn aggregations over neighbor\nnodes, have achieved great performance in node classification tasks. However,\nrecent studies reported that such graph convolutional node classifier can be\ndeceived by adversarial perturbations on graphs. Abusing graph convolutions, a\nnode's classification result can be influenced by poisoning its neighbors.\nGiven an attributed graph and a node classifier, how can we evaluate robustness\nagainst such indirect adversarial attacks? Can we generate strong adversarial\nperturbations which are effective on not only one-hop neighbors, but more far\nfrom the target? In this paper, we demonstrate that the node classifier can be\ndeceived with high-confidence by poisoning just a single node even two-hops or\nmore far from the target. Towards achieving the attack, we propose a new\napproach which searches smaller perturbations on just a single node far from\nthe target. In our experiments, our proposed method shows 99% attack success\nrate within two-hops from the target in two datasets. We also demonstrate that\nm-layer graph convolutional neural networks have chance to be deceived by our\nindirect attack within m-hop neighbors. The proposed attack can be used as a\nbenchmark in future defense attempts to develop graph convolutional neural\nnetworks with having adversary robustness.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:44:09 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Takahashi", "Tsubasa", ""]]}, {"id": "2002.08014", "submitter": "Xiang Li", "authors": "Xiang Li, Shusen Wang, Kun Chen, Zhihua Zhang", "title": "Communication-Efficient Distributed SVD via Local Power Iterations", "comments": "9 pages, 7 figures, accepted by 2021 ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed computing of the truncated singular value decomposition\nproblem. We develop an algorithm that we call \\texttt{LocalPower} for improving\ncommunication efficiency. Specifically, we uniformly partition the dataset\namong $m$ nodes and alternate between multiple (precisely $p$) local power\niterations and one global aggregation. In the aggregation, we propose to weight\neach local eigenvector matrix with orthogonal Procrustes transformation (OPT).\nAs a practical surrogate of OPT, sign-fixing, which uses a diagonal matrix with\n$\\pm 1$ entries as weights, has better computation complexity and stability in\nexperiments. We theoretically show that under certain assumptions\n\\texttt{LocalPower} lowers the required number of communications by a factor of\n$p$ to reach a constant accuracy. We also show that the strategy of\nperiodically decaying $p$ helps obtain high-precision solutions. We conduct\nexperiments to demonstrate the effectiveness of \\texttt{LocalPower}.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 05:58:23 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 12:01:29 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 15:17:52 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 08:37:24 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Li", "Xiang", ""], ["Wang", "Shusen", ""], ["Chen", "Kun", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2002.08021", "submitter": "Dan Bi", "authors": "Shaolong Suna, Dan Bi, Ju-e Guo, Shouyang Wang", "title": "Seasonal and Trend Forecasting of Tourist Arrivals: An Adaptive\n  Multiscale Ensemble Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate seasonal and trend forecasting of tourist arrivals is a very\nchallenging task. In the view of the importance of seasonal and trend\nforecasting of tourist arrivals, and limited research work paid attention to\nthese previously. In this study, a new adaptive multiscale ensemble (AME)\nlearning approach incorporating variational mode decomposition (VMD) and least\nsquare support vector regression (LSSVR) is developed for short-, medium-, and\nlong-term seasonal and trend forecasting of tourist arrivals. In the\nformulation of our developed AME learning approach, the original tourist\narrivals series are first decomposed into the trend, seasonal and remainders\nvolatility components. Then, the ARIMA is used to forecast the trend component,\nthe SARIMA is used to forecast seasonal component with a 12-month cycle, while\nthe LSSVR is used to forecast remainder volatility components. Finally, the\nforecasting results of the three components are aggregated to generate an\nensemble forecasting of tourist arrivals by the LSSVR based nonlinear ensemble\napproach. Furthermore, a direct strategy is used to implement multi-step-ahead\nforecasting. Taking two accuracy measures and the Diebold-Mariano test, the\nempirical results demonstrate that our proposed AME learning approach can\nachieve higher level and directional forecasting accuracy compared with other\nbenchmarks used in this study, indicating that our proposed approach is a\npromising model for forecasting tourist arrivals with high seasonality and\nvolatility.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:32:01 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 13:37:10 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Suna", "Shaolong", ""], ["Bi", "Dan", ""], ["Guo", "Ju-e", ""], ["Wang", "Shouyang", ""]]}, {"id": "2002.08024", "submitter": "Hung Le", "authors": "Hung Le, Richard Socher, Steven C.H. Hoi", "title": "Non-Autoregressive Dialog State Tracking", "comments": "Accepted at ICLR 2020. International Conference on Learning\n  Representations (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in Dialogue State Tracking (DST) for task-oriented dialogues\nhave progressed toward open-vocabulary or generation-based approaches where the\nmodels can generate slot value candidates from the dialogue history itself.\nThese approaches have shown good performance gain, especially in complicated\ndialogue domains with dynamic slot values. However, they fall short in two\naspects: (1) they do not allow models to explicitly learn signals across\ndomains and slots to detect potential dependencies among (domain, slot) pairs;\nand (2) existing models follow auto-regressive approaches which incur high time\ncost when the dialogue evolves over multiple domains and multiple turns. In\nthis paper, we propose a novel framework of Non-Autoregressive Dialog State\nTracking (NADST) which can factor in potential dependencies among domains and\nslots to optimize the models towards better prediction of dialogue states as a\ncomplete set rather than separate slots. In particular, the non-autoregressive\nnature of our method not only enables decoding in parallel to significantly\nreduce the latency of DST for real-time dialogue response generation, but also\ndetect dependencies among slots at token level in addition to slot and domain\nlevel. Our empirical results show that our model achieves the state-of-the-art\njoint accuracy across all domains on the MultiWOZ 2.1 corpus, and the latency\nof our model is an order of magnitude lower than the previous state of the art\nas the dialogue history extends over time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:39:26 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Le", "Hung", ""], ["Socher", "Richard", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2002.08025", "submitter": "Minghong Fang", "authors": "Minghong Fang, Neil Zhenqiang Gong, Jia Liu", "title": "Influence Function based Data Poisoning Attacks to Top-N Recommender\n  Systems", "comments": "Accepted by WWW 2020; This is technical report version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system is an essential component of web services to engage users.\nPopular recommender systems model user preferences and item properties using a\nlarge amount of crowdsourced user-item interaction data, e.g., rating scores;\nthen top-$N$ items that match the best with a user's preference are recommended\nto the user. In this work, we show that an attacker can launch a data poisoning\nattack to a recommender system to make recommendations as the attacker desires\nvia injecting fake users with carefully crafted user-item interaction data.\nSpecifically, an attacker can trick a recommender system to recommend a target\nitem to as many normal users as possible. We focus on matrix factorization\nbased recommender systems because they have been widely deployed in industry.\nGiven the number of fake users the attacker can inject, we formulate the\ncrafting of rating scores for the fake users as an optimization problem.\nHowever, this optimization problem is challenging to solve as it is a\nnon-convex integer programming problem. To address the challenge, we develop\nseveral techniques to approximately solve the optimization problem. For\ninstance, we leverage influence function to select a subset of normal users who\nare influential to the recommendations and solve our formulated optimization\nproblem based on these influential users. Our results show that our attacks are\neffective and outperform existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:41:51 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 20:45:44 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 21:24:05 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Fang", "Minghong", ""], ["Gong", "Neil Zhenqiang", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08027", "submitter": "Minghong Fang", "authors": "Minghong Fang, Jia Liu", "title": "Toward Low-Cost and Stable Blockchain Networks", "comments": "Accepted by IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Envisioned to be the future of secured distributed systems, blockchain\nnetworks have received increasing attention from both the industry and academia\nin recent years. However, blockchain mining processes demand high hardware\ncosts and consume a vast amount of energy (studies have shown that the amount\nof energy consumed in Bitcoin mining is almost the same as the electricity used\nin Ireland). To address the high mining cost problem of blockchain networks, in\nthis paper, we propose a blockchain mining resources allocation algorithm to\nreduce the mining cost in PoW-based (proof-of-work-based) blockchain networks.\nWe first propose an analytical queueing model for general blockchain networks.\nIn our queueing model, transactions arrive randomly to the queue and are served\nin a batch manner with unknown service rate probability distribution and\nagnostic to any priority mechanism. Then, we leverage the Lyapunov optimization\ntechniques to propose a dynamic mining resources allocation algorithm (DMRA),\nwhich is parameterized by a tuning parameter $K>0$. We show that our algorithm\nachieves an $[O(1/K), O(K)]$ cost-optimality-gap-vs-delay tradeoff. Our\nsimulation results also demonstrate the effectiveness of DMRA in reducing\nmining costs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 06:42:33 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 20:39:50 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Fang", "Minghong", ""], ["Liu", "Jia", ""]]}, {"id": "2002.08032", "submitter": "Jianhao Ding", "authors": "Jianhao Ding, Lansheng Han", "title": "A Fixed point view: A Model-Based Clustering Framework", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the inflation of the data, clustering analysis, as a branch of\nunsupervised learning, lacks unified understanding and application of its\nmathematical law. Based on the view of fixed point, this paper restates the\nmodel-based clustering and proposes a unified clustering framework. In order to\nfind fixed points as cluster centers, the framework iteratively constructs the\ncontraction map, which strongly reveals the convergence mechanism and\ninterconnections among algorithms. By specifying a contraction map, Gaussian\nmixture model (GMM) can be mapped to the framework as an application. We hope\nthe fixed point framework will help the design of future clustering algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:06:47 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Ding", "Jianhao", ""], ["Han", "Lansheng", ""]]}, {"id": "2002.08037", "submitter": "Tianpei Yang", "authors": "Tianpei Yang, Jianye Hao, Zhaopeng Meng, Zongzhang Zhang, Yujing Hu,\n  Yingfeng Cheng, Changjie Fan, Weixun Wang, Wulong Liu, Zhaodong Wang, and\n  Jiajie Peng", "title": "Efficient Deep Reinforcement Learning via Adaptive Policy Transfer", "comments": "Accepted by IJCAI'2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer Learning (TL) has shown great potential to accelerate Reinforcement\nLearning (RL) by leveraging prior knowledge from past learned policies of\nrelevant tasks. Existing transfer approaches either explicitly computes the\nsimilarity between tasks or select appropriate source policies to provide\nguided explorations for the target task. However, how to directly optimize the\ntarget policy by alternatively utilizing knowledge from appropriate source\npolicies without explicitly measuring the similarity is currently missing. In\nthis paper, we propose a novel Policy Transfer Framework (PTF) to accelerate RL\nby taking advantage of this idea. Our framework learns when and which source\npolicy is the best to reuse for the target policy and when to terminate it by\nmodeling multi-policy transfer as the option learning problem. PTF can be\neasily combined with existing deep RL approaches. Experimental results show it\nsignificantly accelerates the learning process and surpasses state-of-the-art\npolicy transfer methods in terms of learning efficiency and final performance\nin both discrete and continuous action spaces.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:30:57 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 08:41:30 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 10:21:28 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Yang", "Tianpei", ""], ["Hao", "Jianye", ""], ["Meng", "Zhaopeng", ""], ["Zhang", "Zongzhang", ""], ["Hu", "Yujing", ""], ["Cheng", "Yingfeng", ""], ["Fan", "Changjie", ""], ["Wang", "Weixun", ""], ["Liu", "Wulong", ""], ["Wang", "Zhaodong", ""], ["Peng", "Jiajie", ""]]}, {"id": "2002.08041", "submitter": "Hai Tran", "authors": "Hai H. Tran, Sumyeong Ahn, Taeyoung Lee, Yung Yi", "title": "Enlarging Discriminative Power by Adding an Extra Class in Unsupervised\n  Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of unsupervised domain adaptation that\naims at obtaining a prediction model for the target domain using labeled data\nfrom the source domain and unlabeled data from the target domain. There exists\nan array of recent research based on the idea of extracting features that are\nnot only invariant for both domains but also provide high discriminative power\nfor the target domain. In this paper, we propose an idea of empowering the\ndiscriminativeness: Adding a new, artificial class and training the model on\nthe data together with the GAN-generated samples of the new class. The trained\nmodel based on the new class samples is capable of extracting the features that\nare more discriminative by repositioning data of current classes in the target\ndomain and therefore drawing the decision boundaries more effectively. Our idea\nis highly generic so that it is compatible with many existing methods such as\nDANN, VADA, and DIRT-T. We conduct various experiments for the standard data\ncommonly used for the evaluation of unsupervised domain adaptations and\ndemonstrate that our algorithm achieves the SOTA performance for many\nscenarios.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:58:24 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Tran", "Hai H.", ""], ["Ahn", "Sumyeong", ""], ["Lee", "Taeyoung", ""], ["Yi", "Yung", ""]]}, {"id": "2002.08046", "submitter": "Xuan Phi Nguyen", "authors": "Xuan-Phi Nguyen, Shafiq Joty, Steven C.H. Hoi, Richard Socher", "title": "Tree-structured Attention with Hierarchical Accumulation", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating hierarchical structures like constituency trees has been shown\nto be effective for various natural language processing (NLP) tasks. However,\nit is evident that state-of-the-art (SOTA) sequence-based models like the\nTransformer struggle to encode such structures inherently. On the other hand,\ndedicated models like the Tree-LSTM, while explicitly modeling hierarchical\nstructures, do not perform as efficiently as the Transformer. In this paper, we\nattempt to bridge this gap with \"Hierarchical Accumulation\" to encode parse\ntree structures into self-attention at constant time complexity. Our approach\noutperforms SOTA methods in four IWSLT translation tasks and the WMT'14\nEnglish-German translation task. It also yields improvements over Transformer\nand Tree-LSTM on three text classification tasks. We further demonstrate that\nusing hierarchical priors can compensate for data shortage, and that our model\nprefers phrase-level attentions over token-level attentions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:17:00 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Hoi", "Steven C. H.", ""], ["Socher", "Richard", ""]]}, {"id": "2002.08053", "submitter": "Jiaqi Lv", "authors": "Jiaqi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, Masashi Sugiyama", "title": "Progressive Identification of True Labels for Partial-Label Learning", "comments": "In Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial-label learning (PLL) is a typical weakly supervised learning problem,\nwhere each training instance is equipped with a set of candidate labels among\nwhich only one is the true label. Most existing methods elaborately designed\nlearning objectives as constrained optimizations that must be solved in\nspecific manners, making their computational complexity a bottleneck for\nscaling up to big data. The goal of this paper is to propose a novel framework\nof PLL with flexibility on the model and optimization algorithm. More\nspecifically, we propose a novel estimator of the classification risk,\ntheoretically analyze the classifier-consistency, and establish an estimation\nerror bound. Then we propose a progressive identification algorithm for\napproximately minimizing the proposed risk estimator, where the update of the\nmodel and identification of true labels are conducted in a seamless manner. The\nresulting algorithm is model-independent and loss-independent, and compatible\nwith stochastic optimization. Thorough experiments demonstrate it sets the new\nstate of the art.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:35:15 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 14:20:19 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 13:57:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Lv", "Jiaqi", ""], ["Xu", "Miao", ""], ["Feng", "Lei", ""], ["Niu", "Gang", ""], ["Geng", "Xin", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.08056", "submitter": "Lukas Balles", "authors": "Lukas Balles and Fabian Pedregosa and Nicolas Le Roux", "title": "The Geometry of Sign Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign-based optimization methods have become popular in machine learning due\nto their favorable communication cost in distributed optimization and their\nsurprisingly good performance in neural network training. Furthermore, they are\nclosely connected to so-called adaptive gradient methods like Adam. Recent\nworks on signSGD have used a non-standard \"separable smoothness\" assumption,\nwhereas some older works study sign gradient descent as steepest descent with\nrespect to the $\\ell_\\infty$-norm. In this work, we unify these existing\nresults by showing a close connection between separable smoothness and\n$\\ell_\\infty$-smoothness and argue that the latter is the weaker and more\nnatural assumption. We then proceed to study the smoothness constant with\nrespect to the $\\ell_\\infty$-norm and thereby isolate geometric properties of\nthe objective function which affect the performance of sign-based methods. In\nshort, we find sign-based methods to be preferable over gradient descent if (i)\nthe Hessian is to some degree concentrated on its diagonal, and (ii) its\nmaximal eigenvalue is much larger than the average eigenvalue. Both properties\nare common in deep networks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 08:45:54 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Balles", "Lukas", ""], ["Pedregosa", "Fabian", ""], ["Roux", "Nicolas Le", ""]]}, {"id": "2002.08071", "submitter": "Stefano Massaroli", "authors": "Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita,\n  Hajime Asama", "title": "Dissecting Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous deep learning architectures have recently re-emerged as Neural\nOrdinary Differential Equations (Neural ODEs). This infinite-depth approach\ntheoretically bridges the gap between deep learning and dynamical systems,\noffering a novel perspective. However, deciphering the inner working of these\nmodels is still an open challenge, as most applications apply them as generic\nblack-box modules. In this work we \"open the box\", further developing the\ncontinuous-depth formulation with the aim of clarifying the influence of\nseveral design choices on the underlying dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 09:14:46 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 04:22:32 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 06:46:43 GMT"}, {"version": "v4", "created": "Mon, 11 Jan 2021 14:40:32 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Massaroli", "Stefano", ""], ["Poli", "Michael", ""], ["Park", "Jinkyoo", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""]]}, {"id": "2002.08095", "submitter": "Asaf Cassel", "authors": "Asaf Cassel (1), Alon Cohen (2), Tomer Koren (1) ((1) School of\n  Computer Science, Tel Aviv University, (2) Google Research, Tel Aviv)", "title": "Logarithmic Regret for Learning Linear Quadratic Regulators Efficiently", "comments": "Accepted for presentation at International Conference on Machine\n  Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning in Linear Quadratic Control systems whose\ntransition parameters are initially unknown. Recent results in this setting\nhave demonstrated efficient learning algorithms with regret growing with the\nsquare root of the number of decision steps. We present new efficient\nalgorithms that achieve, perhaps surprisingly, regret that scales only\n(poly)logarithmically with the number of steps in two scenarios: when only the\nstate transition matrix $A$ is unknown, and when only the state-action\ntransition matrix $B$ is unknown and the optimal policy satisfies a certain\nnon-degeneracy condition. On the other hand, we give a lower bound that shows\nthat when the latter condition is violated, square root regret is unavoidable.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 10:09:26 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 20:37:42 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Cassel", "Asaf", ""], ["Cohen", "Alon", ""], ["Koren", "Tomer", ""]]}, {"id": "2002.08104", "submitter": "Aleksandra Nowak", "authors": "Romuald A. Janik and Aleksandra Nowak", "title": "Analyzing Neural Networks Based on Random Graphs", "comments": "Added new results and discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a massive evaluation of neural networks with architectures\ncorresponding to random graphs of various types. We investigate various\nstructural and numerical properties of the graphs in relation to neural network\ntest accuracy. We find that none of the classical numerical graph invariants by\nitself allows to single out the best networks. Consequently, we introduce a new\nnumerical graph characteristic that selects a set of quasi-1-dimensional\ngraphs, which are a majority among the best performing networks. We also find\nthat networks with primarily short-range connections perform better than\nnetworks which allow for many long-range connections. Moreover, many resolution\nreducing pathways are beneficial. We provide a dataset of 1020 graphs and the\ntest accuracies of their corresponding neural networks at\nhttps://github.com/rmldj/random-graph-nn-paper\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:04:49 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 17:13:59 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 11:29:36 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Janik", "Romuald A.", ""], ["Nowak", "Aleksandra", ""]]}, {"id": "2002.08111", "submitter": "Sam Ringer", "authors": "Will Williams, Sam Ringer, Tom Ash, John Hughes, David MacLeod, Jamie\n  Dougherty", "title": "Hierarchical Quantized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite progress in training neural networks for lossy image compression,\ncurrent approaches fail to maintain both perceptual quality and abstract\nfeatures at very low bitrates. Encouraged by recent success in learning\ndiscrete representations with Vector Quantized Variational Autoencoders\n(VQ-VAEs), we motivate the use of a hierarchy of VQ-VAEs to attain high factors\nof compression. We show that the combination of stochastic quantization and\nhierarchical latent structure aids likelihood-based image compression. This\nleads us to introduce a novel objective for training hierarchical VQ-VAEs. Our\nresulting scheme produces a Markovian series of latent variables that\nreconstruct images of high-perceptual quality which retain semantically\nmeaningful features. We provide qualitative and quantitative evaluations on the\nCelebA and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:26:34 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 15:39:36 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 11:10:26 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Williams", "Will", ""], ["Ringer", "Sam", ""], ["Ash", "Tom", ""], ["Hughes", "John", ""], ["MacLeod", "David", ""], ["Dougherty", "Jamie", ""]]}, {"id": "2002.08114", "submitter": "Arindam Pal", "authors": "Subhra Mazumdar, Arindam Pal, Francesco Parisi, V.S. Subrahmanian", "title": "BB_Evac: Fast Location-Sensitive Behavior-Based Building Evacuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.AI cs.DS cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Past work on evacuation planning assumes that evacuees will follow\ninstructions -- however, there is ample evidence that this is not the case.\nWhile some people will follow instructions, others will follow their own\ndesires. In this paper, we present a formal definition of a behavior-based\nevacuation problem (BBEP) in which a human behavior model is taken into account\nwhen planning an evacuation. We show that a specific form of constraints can be\nused to express such behaviors. We show that BBEPs can be solved exactly via an\ninteger program called BB_IP, and inexactly by a much faster algorithm that we\ncall BB_Evac. We conducted a detailed experimental evaluation of both\nalgorithms applied to buildings (though in principle the algorithms can be\napplied to any graphs) and show that the latter is an order of magnitude faster\nthan BB_IP while producing results that are almost as good on one real-world\nbuilding graph and as well as on several synthetically generated graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:34:52 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Mazumdar", "Subhra", ""], ["Pal", "Arindam", ""], ["Parisi", "Francesco", ""], ["Subrahmanian", "V. S.", ""]]}, {"id": "2002.08118", "submitter": "Tony Duan", "authors": "Greg Yang, Tony Duan, J. Edward Hu, Hadi Salman, Ilya Razenshteyn,\n  Jerry Li", "title": "Randomized Smoothing of All Shapes and Sizes", "comments": "9 pages main text, 49 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized smoothing is the current state-of-the-art defense with provable\nrobustness against $\\ell_2$ adversarial attacks. Many works have devised new\nrandomized smoothing schemes for other metrics, such as $\\ell_1$ or\n$\\ell_\\infty$; however, substantial effort was needed to derive such new\nguarantees. This begs the question: can we find a general theory for randomized\nsmoothing?\n  We propose a novel framework for devising and analyzing randomized smoothing\nschemes, and validate its effectiveness in practice. Our theoretical\ncontributions are: (1) we show that for an appropriate notion of \"optimal\", the\noptimal smoothing distributions for any \"nice\" norms have level sets given by\nthe norm's *Wulff Crystal*; (2) we propose two novel and complementary methods\nfor deriving provably robust radii for any smoothing distribution; and, (3) we\nshow fundamental limits to current randomized smoothing techniques via the\ntheory of *Banach space cotypes*. By combining (1) and (2), we significantly\nimprove the state-of-the-art certified accuracy in $\\ell_1$ on standard\ndatasets. Meanwhile, we show using (3) that with only label statistics under\nrandom input perturbations, randomized smoothing cannot achieve nontrivial\ncertified accuracy against perturbations of $\\ell_p$-norm $\\Omega(\\min(1,\nd^{\\frac{1}{p} - \\frac{1}{2}}))$, when the input dimension $d$ is large. We\nprovide code in github.com/tonyduan/rs4a.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:41:09 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 19:33:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 06:59:55 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2020 05:27:53 GMT"}, {"version": "v5", "created": "Thu, 23 Jul 2020 21:20:51 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Yang", "Greg", ""], ["Duan", "Tony", ""], ["Hu", "J. Edward", ""], ["Salman", "Hadi", ""], ["Razenshteyn", "Ilya", ""], ["Li", "Jerry", ""]]}, {"id": "2002.08125", "submitter": "Andreas Krug", "authors": "Andreas Krug, Sebastian Stober", "title": "Gradient-Adjusted Neuron Activation Profiles for Comprehensive\n  Introspection of Convolutional Speech Recognition Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning based Automatic Speech Recognition (ASR) models are very\nsuccessful, but hard to interpret. To gain better understanding of how\nArtificial Neural Networks (ANNs) accomplish their tasks, introspection methods\nhave been proposed. Adapting such techniques from computer vision to speech\nrecognition is not straight-forward, because speech data is more complex and\nless interpretable than image data. In this work, we introduce\nGradient-adjusted Neuron Activation Profiles (GradNAPs) as means to interpret\nfeatures and representations in Deep Neural Networks. GradNAPs are\ncharacteristic responses of ANNs to particular groups of inputs, which\nincorporate the relevance of neurons for prediction. We show how to utilize\nGradNAPs to gain insight about how data is processed in ANNs. This includes\ndifferent ways of visualizing features and clustering of GradNAPs to compare\nembeddings of different groups of inputs in any layer of a given network. We\ndemonstrate our proposed techniques using a fully-convolutional ASR model.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:59:36 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Krug", "Andreas", ""], ["Stober", "Sebastian", ""]]}, {"id": "2002.08126", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Jianhua Tao, Ye Bai", "title": "Rnn-transducer with language bias for end-to-end Mandarin-English\n  code-switching speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, language identity information has been utilized to improve the\nperformance of end-to-end code-switching (CS) speech recognition. However,\nprevious works use an additional language identification (LID) model as an\nauxiliary module, which causes the system complex. In this work, we propose an\nimproved recurrent neural network transducer (RNN-T) model with language bias\nto alleviate the problem. We use the language identities to bias the model to\npredict the CS points. This promotes the model to learn the language identity\ninformation directly from transcription, and no additional LID model is needed.\nWe evaluate the approach on a Mandarin-English CS corpus SEAME. Compared to our\nRNN-T baseline, the proposed method can achieve 16.2% and 12.9% relative error\nreduction on two test sets, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:01:33 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Shuai", ""], ["Yi", "Jiangyan", ""], ["Tian", "Zhengkun", ""], ["Tao", "Jianhua", ""], ["Bai", "Ye", ""]]}, {"id": "2002.08129", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse and Michael U. Gutmann", "title": "Bayesian Experimental Design for Implicit Models by Mutual Information\n  Neural Estimation", "comments": "Accepted at the thirty-seventh International Conference on Machine\n  Learning (ICML) 2020. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit stochastic models, where the data-generation distribution is\nintractable but sampling is possible, are ubiquitous in the natural sciences.\nThe models typically have free parameters that need to be inferred from data\ncollected in scientific experiments. A fundamental question is how to design\nthe experiments so that the collected data are most useful. The field of\nBayesian experimental design advocates that, ideally, we should choose designs\nthat maximise the mutual information (MI) between the data and the parameters.\nFor implicit models, however, this approach is severely hampered by the high\ncomputational cost of computing posteriors and maximising MI, in particular\nwhen we have more than a handful of design variables to optimise. In this\npaper, we propose a new approach to Bayesian experimental design for implicit\nmodels that leverages recent advances in neural MI estimation to deal with\nthese issues. We show that training a neural network to maximise a lower bound\non MI allows us to jointly determine the optimal design and the posterior.\nSimulation studies illustrate that this gracefully extends Bayesian\nexperimental design for implicit models to higher design dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:09:42 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 17:28:45 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 15:04:46 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "2002.08131", "submitter": "Jeremy Barnes", "authors": "Jeremy Barnes and Vinit Ravishankar and Lilja {\\O}vrelid and Erik\n  Velldal", "title": "Hierarchical models vs. transfer learning for document-level sentiment\n  classification", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Documents are composed of smaller pieces - paragraphs, sentences, and tokens\n- that have complex relationships between one another. Sentiment classification\nmodels that take into account the structure inherent in these documents have a\ntheoretical advantage over those that do not. At the same time, transfer\nlearning models based on language model pretraining have shown promise for\ndocument classification. However, these two paradigms have not been\nsystematically compared and it is not clear under which circumstances one\napproach is better than the other. In this work we empirically compare\nhierarchical models and transfer learning for document-level sentiment\nclassification. We show that non-trivial hierarchical models outperform\nprevious baselines and transfer learning on document-level sentiment\nclassification in five languages.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 12:22:46 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Barnes", "Jeremy", ""], ["Ravishankar", "Vinit", ""], ["\u00d8vrelid", "Lilja", ""], ["Velldal", "Erik", ""]]}, {"id": "2002.08158", "submitter": "Yibo Yang", "authors": "Yibo Yang, Robert Bamler and Stephan Mandt", "title": "Variational Bayesian Quantization", "comments": "9 pages + detailed supplement with additional full resolution\n  reconstructed images; ICML 2020 final camera-ready version, title changed to\n  \"Variational Bayesian Quantization\" following reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel algorithm for quantizing continuous latent representations\nin trained models. Our approach applies to deep probabilistic models, such as\nvariational autoencoders (VAEs), and enables both data and model compression.\nUnlike current end-to-end neural compression methods that cater the model to a\nfixed quantization scheme, our algorithm separates model design and training\nfrom quantization. Consequently, our algorithm enables \"plug-and-play\"\ncompression with variable rate-distortion trade-off, using a single trained\nmodel. Our algorithm can be seen as a novel extension of arithmetic coding to\nthe continuous domain, and uses adaptive quantization accuracy based on\nestimates of posterior uncertainty. Our experimental results demonstrate the\nimportance of taking into account posterior uncertainties, and show that image\ncompression with the proposed algorithm outperforms JPEG over a wide range of\nbit rates using only a single standard VAE. Further experiments on Bayesian\nneural word embeddings demonstrate the versatility of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:15:37 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 22:25:12 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Yang", "Yibo", ""], ["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "2002.08159", "submitter": "Robin Vogel", "authors": "Robin Vogel, Aur\\'elien Bellet, and Stephan Cl\\'emen\\c{c}on", "title": "Learning Fair Scoring Functions: Bipartite Ranking under ROC-based\n  Fairness Constraints", "comments": "35 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications of AI involve scoring individuals using a learned function\nof their attributes. These predictive risk scores are then used to take\ndecisions based on whether the score exceeds a certain threshold, which may\nvary depending on the context. The level of delegation granted to such systems\nin critical applications like credit lending and medical diagnosis will heavily\ndepend on how questions of fairness can be answered. In this paper, we study\nfairness for the problem of learning scoring functions from binary labeled\ndata, a classic learning task known as bipartite ranking. We argue that the\nfunctional nature of the ROC curve, the gold standard measure of ranking\naccuracy in this context, leads to several ways of formulating fairness\nconstraints. We introduce general families of fairness definitions based on the\nAUC and on ROC curves, and show that our ROC-based constraints can be\ninstantiated such that classifiers obtained by thresholding the scoring\nfunction satisfy classification fairness for a desired range of thresholds. We\nestablish generalization bounds for scoring functions learned under such\nconstraints, design practical learning algorithms and show the relevance our\napproach with numerical experiments on real and synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:17:39 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 13:25:54 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 14:50:12 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 18:54:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Vogel", "Robin", ""], ["Bellet", "Aur\u00e9lien", ""], ["Cl\u00e9men\u00e7on", "Stephan", ""]]}, {"id": "2002.08165", "submitter": "Arslan Chaudhry", "authors": "Arslan Chaudhry, Albert Gordo, Puneet K. Dokania, Philip Torr, David\n  Lopez-Paz", "title": "Using Hindsight to Anchor Past Knowledge in Continual Learning", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In continual learning, the learner faces a stream of data whose distribution\nchanges over time. Modern neural networks are known to suffer under this\nsetting, as they quickly forget previously acquired knowledge. To address such\ncatastrophic forgetting, many continual learning methods implement different\ntypes of experience replay, re-learning on past data stored in a small buffer\nknown as episodic memory. In this work, we complement experience replay with a\nnew objective that we call anchoring, where the learner uses bilevel\noptimization to update its knowledge on the current task, while keeping intact\nthe predictions on some anchor points of past tasks. These anchor points are\nlearned using gradient-based optimization to maximize forgetting, which is\napproximated by fine-tuning the currently trained model on the episodic memory\nof past tasks. Experiments on several supervised learning benchmarks for\ncontinual learning demonstrate that our approach improves the standard\nexperience replay in terms of both accuracy and forgetting metrics and for\nvarious sizes of episodic memories.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 13:21:19 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 08:05:50 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Chaudhry", "Arslan", ""], ["Gordo", "Albert", ""], ["Dokania", "Puneet K.", ""], ["Torr", "Philip", ""], ["Lopez-Paz", "David", ""]]}, {"id": "2002.08196", "submitter": "Tengchan Zeng", "authors": "Tengchan Zeng, Omid Semiari, Mohammad Mozaffari, Mingzhe Chen, Walid\n  Saad, and Mehdi Bennis", "title": "Federated Learning in the Sky: Joint Power Allocation and Scheduling\n  with UAV Swarms", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.RO eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicle (UAV) swarms must exploit machine learning (ML) in\norder to execute various tasks ranging from coordinated trajectory planning to\ncooperative target recognition. However, due to the lack of continuous\nconnections between the UAV swarm and ground base stations (BSs), using\ncentralized ML will be challenging, particularly when dealing with a large\nvolume of data. In this paper, a novel framework is proposed to implement\ndistributed federated learning (FL) algorithms within a UAV swarm that consists\nof a leading UAV and several following UAVs. Each following UAV trains a local\nFL model based on its collected data and then sends this trained local model to\nthe leading UAV who will aggregate the received models, generate a global FL\nmodel, and transmit it to followers over the intra-swarm network. To identify\nhow wireless factors, like fading, transmission delay, and UAV antenna angle\ndeviations resulting from wind and mechanical vibrations, impact the\nperformance of FL, a rigorous convergence analysis for FL is performed. Then, a\njoint power allocation and scheduling design is proposed to optimize the\nconvergence rate of FL while taking into account the energy consumption during\nconvergence and the delay requirement imposed by the swarm's control system.\nSimulation results validate the effectiveness of the FL convergence analysis\nand show that the joint design strategy can reduce the number of communication\nrounds needed for convergence by as much as 35% compared with the baseline\ndesign.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:04:01 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:19:18 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zeng", "Tengchan", ""], ["Semiari", "Omid", ""], ["Mozaffari", "Mohammad", ""], ["Chen", "Mingzhe", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2002.08204", "submitter": "Fabian Timm", "authors": "Lukas Enderich and Fabian Timm and Wolfram Burgard", "title": "SYMOG: learning symmetric mixture of Gaussian modes for improved\n  fixed-point quantization", "comments": "Preprint submitted to Neurocomputing", "journal-ref": "Neurocomputing 2020", "doi": "10.1016/j.neucom.2019.11.114", "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been proven to outperform classical methods\non several machine learning benchmarks. However, they have high computational\ncomplexity and require powerful processing units. Especially when deployed on\nembedded systems, model size and inference time must be significantly reduced.\nWe propose SYMOG (symmetric mixture of Gaussian modes), which significantly\ndecreases the complexity of DNNs through low-bit fixed-point quantization.\nSYMOG is a novel soft quantization method such that the learning task and the\nquantization are solved simultaneously. During training the weight distribution\nchanges from an unimodal Gaussian distribution to a symmetric mixture of\nGaussians, where each mean value belongs to a particular fixed-point mode. We\nevaluate our approach with different architectures (LeNet5, VGG7, VGG11,\nDenseNet) on common benchmark data sets (MNIST, CIFAR-10, CIFAR-100) and we\ncompare with state-of-the-art quantization approaches. We achieve excellent\nresults and outperform 2-bit state-of-the-art performance with an error rate of\nonly 5.71% on CIFAR-10 and 27.65% on CIFAR-100.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 14:17:32 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Enderich", "Lukas", ""], ["Timm", "Fabian", ""], ["Burgard", "Wolfram", ""]]}, {"id": "2002.08224", "submitter": "Christian Krupitzer", "authors": "Christian Krupitzer (1), Tim Wagenhals (2), Marwin Z\\\"ufle (1),\n  Veronika Lesch (1), Dominik Sch\\\"afer (3), Amin Mozaffarin (4), Janick\n  Edinger (2), Christian Becker (2), Samuel Kounev (1) ((1) University of\n  W\\\"urzburg, W\\\"urzburg, Germany, (2) University of Mannheim, Mannheim,\n  Germany, (3) Syntax Systems GmbH, Weinheim, Germany, (4) MOZYS Engineering\n  GmbH, W\\\"urzburg)", "title": "A Survey on Predictive Maintenance for Industry 4.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Production issues at Volkswagen in 2016 lead to dramatic losses in sales of\nup to 400 million Euros per week. This example shows the huge financial impact\nof a working production facility for companies. Especially in the data-driven\ndomains of Industry 4.0 and Industrial IoT with intelligent, connected\nmachines, a conventional, static maintenance schedule seems to be\nold-fashioned. In this paper, we present a survey on the current state of the\nart in predictive maintenance for Industry 4.0. Based on a structured literate\nsurvey, we present a classification of predictive maintenance in the context of\nIndustry 4.0 and discuss recent developments in this area.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 09:33:21 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Krupitzer", "Christian", ""], ["Wagenhals", "Tim", ""], ["Z\u00fcfle", "Marwin", ""], ["Lesch", "Veronika", ""], ["Sch\u00e4fer", "Dominik", ""], ["Mozaffarin", "Amin", ""], ["Edinger", "Janick", ""], ["Becker", "Christian", ""], ["Kounev", "Samuel", ""]]}, {"id": "2002.08232", "submitter": "Dmtri Babaev", "authors": "Dmitrii Babaev, Ivan Kireev, Nikita Ovsov, Mariya Ivanova, Gleb Gusev,\n  Alexander Tuzhilin", "title": "Event sequence metric learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a challenging problem of learning discriminative\nvector representations for event sequences generated by real-world users.\nVector representations map behavioral client raw data to the low-dimensional\nfixed-length vectors in the latent space. We propose a novel method of learning\nthose vector embeddings based on metric learning approach. We propose a\nstrategy of raw data subsequences generation to apply a metric learning\napproach in a fully self-supervised way. We evaluated the method over several\npublic bank transactions datasets and showed that self-supervised embeddings\noutperform other methods when applied to downstream classification tasks.\nMoreover, embeddings are compact and provide additional user privacy\nprotection.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:15:57 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Babaev", "Dmitrii", ""], ["Kireev", "Ivan", ""], ["Ovsov", "Nikita", ""], ["Ivanova", "Mariya", ""], ["Gusev", "Gleb", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2002.08235", "submitter": "Teeratorn Kadeethum", "authors": "Teeratorn Kadeethum, Thomas M Jorgensen, Hamidreza M Nick", "title": "Physics-informed Neural Networks for Solving Nonlinear Diffusivity and\n  Biot's equations", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0232683", "report-no": null, "categories": "cs.CE cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the potential of applying physics-informed neural\nnetworks for solving nonlinear multiphysics problems, which are essential to\nmany fields such as biomedical engineering, earthquake prediction, and\nunderground energy harvesting. Specifically, we investigate how to extend the\nmethodology of physics-informed neural networks to solve both the forward and\ninverse problems in relation to the nonlinear diffusivity and Biot's equations.\nWe explore the accuracy of the physics-informed neural networks with different\ntraining example sizes and choices of hyperparameters. The impacts of the\nstochastic variations between various training realizations are also\ninvestigated. In the inverse case, we also study the effects of noisy\nmeasurements. Furthermore, we address the challenge of selecting the\nhyperparameters of the inverse model and illustrate how this challenge is\nlinked to the hyperparameters selection performed for the forward one.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:22:26 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kadeethum", "Teeratorn", ""], ["Jorgensen", "Thomas M", ""], ["Nick", "Hamidreza M", ""]]}, {"id": "2002.08240", "submitter": "Srinivasan Arunachalam", "authors": "Srinivasan Arunachalam, Alex B. Grilo, Henry Yuen", "title": "Quantum statistical query learning", "comments": "24 Pages. Version 2, minor edits to improve presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a learning model called the quantum statistical learning QSQ\nmodel, which extends the SQ learning model introduced by Kearns to the quantum\nsetting. Our model can be also seen as a restriction of the quantum PAC\nlearning model: here, the learner does not have direct access to quantum\nexamples, but can only obtain estimates of measurement statistics on them.\nTheoretically, this model provides a simple yet expressive setting to explore\nthe power of quantum examples in machine learning. From a practical\nperspective, since simpler operations are required, learning algorithms in the\nQSQ model are more feasible for implementation on near-term quantum devices. We\nprove a number of results about the QSQ learning model. We first show that\nparity functions, (log n)-juntas and polynomial-sized DNF formulas are\nefficiently learnable in the QSQ model, in contrast to the classical setting\nwhere these problems are provably hard. This implies that many of the\nadvantages of quantum PAC learning can be realized even in the more restricted\nquantum SQ learning model. It is well-known that weak statistical query\ndimension, denoted by WSQDIM(C), characterizes the complexity of learning a\nconcept class C in the classical SQ model. We show that log(WSQDIM(C)) is a\nlower bound on the complexity of QSQ learning, and furthermore it is tight for\ncertain concept classes C. Additionally, we show that this quantity provides\nstrong lower bounds for the small-bias quantum communication model under\nproduct distributions. Finally, we introduce the notion of private quantum PAC\nlearning, in which a quantum PAC learner is required to be differentially\nprivate. We show that learnability in the QSQ model implies learnability in the\nquantum private PAC model. Additionally, we show that in the private PAC\nlearning setting, the classical and quantum sample complexities are equal, up\nto constant factors.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:36:57 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 21:26:33 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Arunachalam", "Srinivasan", ""], ["Grilo", "Alex B.", ""], ["Yuen", "Henry", ""]]}, {"id": "2002.08243", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Lior Shani, Aviv Rosenberg and Shie Mannor", "title": "Optimistic Policy Optimization with Bandit Feedback", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization methods are one of the most widely used classes of\nReinforcement Learning (RL) algorithms. Yet, so far, such methods have been\nmostly analyzed from an optimization perspective, without addressing the\nproblem of exploration, or by making strong assumptions on the interaction with\nthe environment. In this paper we consider model-based RL in the tabular\nfinite-horizon MDP setting with unknown transitions and bandit feedback. For\nthis setting, we propose an optimistic trust region policy optimization (TRPO)\nalgorithm for which we establish $\\tilde O(\\sqrt{S^2 A H^4 K})$ regret for\nstochastic rewards. Furthermore, we prove $\\tilde O( \\sqrt{ S^2 A H^4 } K^{2/3}\n) $ regret for adversarial rewards. Interestingly, this result matches previous\nbounds derived for the bandit feedback case, yet with known transitions. To the\nbest of our knowledge, the two results are the first sub-linear regret bounds\nobtained for policy optimization algorithms with unknown transitions and bandit\nfeedback.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:41:18 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:13:53 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Efroni", "Yonathan", ""], ["Shani", "Lior", ""], ["Rosenberg", "Aviv", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.08246", "submitter": "Lam Nguyen", "authors": "Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, Marten\n  van Dijk", "title": "A Unified Convergence Analysis for Shuffling-Type Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a unified convergence analysis for a class of\nshuffling-type gradient methods for solving a well-known finite-sum\nminimization problem commonly used in machine learning. This algorithm covers\nvarious variants such as randomized reshuffling, single shuffling, and\ncyclic/incremental gradient schemes. We consider two different settings:\nstrongly convex and non-convex problems. Our main contribution consists of new\nnon-asymptotic and asymptotic convergence rates for a general class of\nshuffling-type gradient methods to solve both non-convex and strongly convex\nproblems. While our rate in the non-convex problem is new (i.e. not known yet\nunder standard assumptions), the rate on the strongly convex case matches (up\nto a constant) the best-known results. However, unlike existing works in this\ndirection, we only use standard assumptions such as smoothness and strong\nconvexity. Finally, we empirically illustrate the effect of learning rates via\na non-convex logistic regression and neural network examples.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:45:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Nguyen", "Lam M.", ""], ["Tran-Dinh", "Quoc", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Phuong Ha", ""], ["van Dijk", "Marten", ""]]}, {"id": "2002.08247", "submitter": "Amit Dhurandhar", "authors": "Tejaswini Pedapati, Avinash Balakrishnan, Karthikeyan Shanmugam and\n  Amit Dhurandhar", "title": "Learning Global Transparent Models Consistent with Local Contrastive\n  Explanations", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a rich and growing literature on producing local\ncontrastive/counterfactual explanations for black-box models (e.g. neural\nnetworks).\n  In these methods, for an input, an explanation is in the form of a contrast\npoint differing in very few features from the original input and lying in a\ndifferent class. Other works try to build globally interpretable models like\ndecision trees and rule lists based on the data using actual labels or based on\nthe black-box models predictions. Although these interpretable global models\ncan be useful, they may not be consistent with local explanations from a\nspecific black-box of choice. In this work, we explore the question: Can we\nproduce a transparent global model that is simultaneously accurate and\nconsistent with the local (contrastive) explanations of the black-box model? We\nintroduce a natural local consistency metric that quantifies if the local\nexplanations and predictions of the black-box model are also consistent with\nthe proxy global transparent model. Based on a key insight we propose a novel\nmethod where we create custom boolean features from sparse local contrastive\nexplanations of the black-box model and then train a globally transparent model\non just these, and showcase empirically that such models have higher local\nconsistency compared with other known strategies, while still being close in\nperformance to models that are trained with access to the original data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:45:42 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 23:37:44 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 13:01:15 GMT"}, {"version": "v4", "created": "Thu, 29 Oct 2020 00:34:34 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Pedapati", "Tejaswini", ""], ["Balakrishnan", "Avinash", ""], ["Shanmugam", "Karthikeyan", ""], ["Dhurandhar", "Amit", ""]]}, {"id": "2002.08249", "submitter": "Oliver Kirsebom", "authors": "Fabio Frazao, Bruno Padovese, Oliver S. Kirsebom", "title": "Workshop Report: Detection and Classification in Marine Bioacoustics\n  with Deep Learning", "comments": "13 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On 21-22 November 2019, about 30 researchers gathered in Victoria, BC,\nCanada, for the workshop \"Detection and Classification in Marine Bioacoustics\nwith Deep Learning\" organized by MERIDIAN and hosted by Ocean Networks Canada.\nThe workshop was attended by marine biologists, data scientists, and computer\nscientists coming from both Canadian coasts and the US and representing a wide\nspectrum of research organizations including universities, government\n(Fisheries and Oceans Canada, National Oceanic and Atmospheric Administration),\nindustry (JASCO Applied Sciences, Google, Axiom Data Science), and\nnon-for-profits (Orcasound, OrcaLab). Consisting of a mix of oral\npresentations, open discussion sessions, and hands-on tutorials, the workshop\nprogram offered a rare opportunity for specialists from distinctly different\ndomains to engage in conversation about deep learning and its promising\npotential for the development of detection and classification algorithms in\nunderwater acoustics. In this workshop report, we summarize key points from the\npresentations and discussion sessions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:33:06 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Frazao", "Fabio", ""], ["Padovese", "Bruno", ""], ["Kirsebom", "Oliver S.", ""]]}, {"id": "2002.08253", "submitter": "Henry Gouk", "authors": "Henry Gouk, Timothy M. Hospedales, Massimiliano Pontil", "title": "Distance-Based Regularisation of Deep Networks for Fine-Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate approaches to regularisation during fine-tuning of deep neural\nnetworks. First we provide a neural network generalisation bound based on\nRademacher complexity that uses the distance the weights have moved from their\ninitial values. This bound has no direct dependence on the number of weights\nand compares favourably to other bounds when applied to convolutional networks.\nOur bound is highly relevant for fine-tuning, because providing a network with\na good initialisation based on transfer learning means that learning can modify\nthe weights less, and hence achieve tighter generalisation. Inspired by this,\nwe develop a simple yet effective fine-tuning algorithm that constrains the\nhypothesis class to a small sphere centred on the initial pre-trained weights,\nthus obtaining provably better generalisation performance than conventional\ntransfer learning. Empirical evaluation shows that our algorithm works well,\ncorroborating our theoretical results. It outperforms both state of the art\nfine-tuning competitors, and penalty-based alternatives that we show do not\ndirectly constrain the radius of the search space.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:00:47 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 21:48:17 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 16:05:16 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Gouk", "Henry", ""], ["Hospedales", "Timothy M.", ""], ["Pontil", "Massimiliano", ""]]}, {"id": "2002.08258", "submitter": "Yonathan Aflalo Dr", "authors": "Yonathan Aflalo and Asaf Noy and Ming Lin and Itamar Friedman and Lihi\n  Zelnik", "title": "Knapsack Pruning with Inner Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning reduces the computational cost of an\nover-parameterized network to improve its efficiency. Popular methods vary from\n$\\ell_1$-norm sparsification to Neural Architecture Search (NAS). In this work,\nwe propose a novel pruning method that optimizes the final accuracy of the\npruned network and distills knowledge from the over-parameterized parent\nnetwork's inner layers. To enable this approach, we formulate the network\npruning as a Knapsack Problem which optimizes the trade-off between the\nimportance of neurons and their associated computational cost. Then we prune\nthe network channels while maintaining the high-level structure of the network.\nThe pruned network is fine-tuned under the supervision of the parent network\nusing its inner network knowledge, a technique we refer to as the Inner\nKnowledge Distillation. Our method leads to state-of-the-art pruning results on\nImageNet, CIFAR-10 and CIFAR-100 using ResNet backbones. To prune complex\nnetwork structures such as convolutions with skip-links and depth-wise\nconvolutions, we propose a block grouping approach to cope with these\nstructures. Through this we produce compact architectures with the same FLOPs\nas EfficientNet-B0 and MobileNetV3 but with higher accuracy, by $1\\%$ and\n$0.3\\%$ respectively on ImageNet, and faster runtime on GPU.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:04:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 05:36:06 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 10:09:33 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Aflalo", "Yonathan", ""], ["Noy", "Asaf", ""], ["Lin", "Ming", ""], ["Friedman", "Itamar", ""], ["Zelnik", "Lihi", ""]]}, {"id": "2002.08260", "submitter": "Werner Zellinger", "authors": "Werner Zellinger, Bernhard A Moser and Susanne Saminger-Platz", "title": "On generalization in moment-based domain adaptation", "comments": null, "journal-ref": "Annals of Mathematics and Artificial Intelligence 89, 333--369\n  (2021)", "doi": "10.1007/s10472-020-09719-x", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation algorithms are designed to minimize the misclassification\nrisk of a discriminative model for a target domain with little training data by\nadapting a model from a source domain with a large amount of training data.\nStandard approaches measure the adaptation discrepancy based on distance\nmeasures between the empirical probability distributions in the source and\ntarget domain. In this setting, we address the problem of deriving\ngeneralization bounds under practice-oriented general conditions on the\nunderlying probability distributions. As a result, we obtain generalization\nbounds for domain adaptation based on finitely many moments and smoothness\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:05:27 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 12:50:45 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 10:31:28 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zellinger", "Werner", ""], ["Moser", "Bernhard A", ""], ["Saminger-Platz", "Susanne", ""]]}, {"id": "2002.08264", "submitter": "{\\L}ukasz Maziarka", "authors": "{\\L}ukasz Maziarka, Tomasz Danel, S{\\l}awomir Mucha, Krzysztof Rataj,\n  Jacek Tabor, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Molecule Attention Transformer", "comments": null, "journal-ref": "Graph Representation Learning workshop and Machine Learning and\n  the Physical Sciences workshop at NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a single neural network architecture that performs competitively\nacross a range of molecule property prediction tasks remains largely an open\nchallenge, and its solution may unlock a widespread use of deep learning in the\ndrug discovery industry. To move towards this goal, we propose Molecule\nAttention Transformer (MAT). Our key innovation is to augment the attention\nmechanism in Transformer using inter-atomic distances and the molecular graph\nstructure. Experiments show that MAT performs competitively on a diverse set of\nmolecular prediction tasks. Most importantly, with a simple self-supervised\npretraining, MAT requires tuning of only a few hyperparameter values to achieve\nstate-of-the-art performance on downstream tasks. Finally, we show that\nattention weights learned by MAT are interpretable from the chemical point of\nview.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:14:48 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Maziarka", "\u0141ukasz", ""], ["Danel", "Tomasz", ""], ["Mucha", "S\u0142awomir", ""], ["Rataj", "Krzysztof", ""], ["Tabor", "Jacek", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "2002.08267", "submitter": "Aman Shenoy", "authors": "Aman Shenoy and Ashish Sardana", "title": "Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection\n  and Sentiment Analysis in Conversation", "comments": "10 pages, 3 figures, 5 tables; Published in Proceedings of the Second\n  Grand Challenge and Workshop on Multimodal Language (Challenge-HML) in the\n  58th Annual Meeting of the Association for Computational Linguistics (ACL\n  2020)", "journal-ref": "Challenge-HML, ACL 2020, 19-28", "doi": "10.18653/v1/2020.challengehml-1.3", "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sentiment Analysis and Emotion Detection in conversation is key in several\nreal-world applications, with an increase in modalities available aiding a\nbetter understanding of the underlying emotions. Multi-modal Emotion Detection\nand Sentiment Analysis can be particularly useful, as applications will be able\nto use specific subsets of available modalities, as per the available data.\nCurrent systems dealing with Multi-modal functionality fail to leverage and\ncapture - the context of the conversation through all modalities, the\ndependency between the listener(s) and speaker emotional states, and the\nrelevance and relationship between the available modalities. In this paper, we\npropose an end to end RNN architecture that attempts to take into account all\nthe mentioned drawbacks. Our proposed model, at the time of writing,\nout-performs the state of the art on a benchmark dataset on a variety of\naccuracy and regression metrics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:21:00 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 04:43:19 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 20:03:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Shenoy", "Aman", ""], ["Sardana", "Ashish", ""]]}, {"id": "2002.08274", "submitter": "Junteng Jia", "authors": "Junteng Jia and Austin R. Benson", "title": "Residual Correlation in Graph Neural Network Regression", "comments": null, "journal-ref": "KDD 2020", "doi": "10.1145/3394486.3403101", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A graph neural network transforms features in each vertex's neighborhood into\na vector representation of the vertex. Afterward, each vertex's representation\nis used independently for predicting its label. This standard pipeline\nimplicitly assumes that vertex labels are conditionally independent given their\nneighborhood features. However, this is a strong assumption, and we show that\nit is far from true on many real-world graph datasets. Focusing on regression\ntasks, we find that this conditional independence assumption severely limits\npredictive power. This should not be that surprising, given that traditional\ngraph-based semi-supervised learning methods such as label propagation work in\nthe opposite fashion by explicitly modeling the correlation in predicted\noutcomes.\n  Here, we address this problem with an interpretable and efficient framework\nthat can improve any graph neural network architecture simply by exploiting\ncorrelation structure in the regression residuals. In particular, we model the\njoint distribution of residuals on vertices with a parameterized multivariate\nGaussian, and estimate the parameters by maximizing the marginal likelihood of\nthe observed labels. Our framework achieves substantially higher accuracy than\ncompeting baselines, and the learned parameters can be interpreted as the\nstrength of correlation among connected vertices. Furthermore, we develop\nlinear time algorithms for low-variance, unbiased model parameter estimates,\nallowing us to scale to large networks. We also provide a basic version of our\nmethod that makes stronger assumptions on correlation structure but is painless\nto implement, often leading to great practical performance with minimal\noverhead.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:32:54 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 22:18:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jia", "Junteng", ""], ["Benson", "Austin R.", ""]]}, {"id": "2002.08276", "submitter": "Mokhtar Z. Alaya", "authors": "Laetitia Chapel, Mokhtar Z. Alaya, Gilles Gasso", "title": "Partial Optimal Transport with Applications on Positive-Unlabeled\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical optimal transport problem seeks a transportation map that preserves\nthe total mass betwenn two probability distributions, requiring their mass to\nbe the same. This may be too restrictive in certain applications such as color\nor shape matching, since the distributions may have arbitrary masses and/or\nthat only a fraction of the total mass has to be transported. Several\nalgorithms have been devised for computing partial Wasserstein metrics that\nrely on an entropic regularization, but when it comes with exact solutions,\nalmost no partial formulation of neither Wasserstein nor Gromov-Wasserstein are\navailable yet. This precludes from working with distributions that do not lie\nin the same metric space or when invariance to rotation or translation is\nneeded. In this paper, we address the partial Wasserstein and\nGromov-Wasserstein problems and propose exact algorithms to solve them. We\nshowcase the new formulation in a positive-unlabeled (PU) learning application.\nTo the best of our knowledge, this is the first application of optimal\ntransport in this context and we first highlight that partial Wasserstein-based\nmetrics prove effective in usual PU learning settings. We then demonstrate that\npartial Gromov-Wasserstein metrics is efficient in scenario where point clouds\ncome from different domains or have different features.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:36:35 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:48:54 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Chapel", "Laetitia", ""], ["Alaya", "Mokhtar Z.", ""], ["Gasso", "Gilles", ""]]}, {"id": "2002.08277", "submitter": "Yixiao Zhang", "authors": "Yixiao Zhang, Xiaosong Wang, Ziyue Xu, Qihang Yu, Alan Yuille, Daguang\n  Xu", "title": "When Radiology Report Generation Meets Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic radiology report generation has been an attracting research problem\ntowards computer-aided diagnosis to alleviate the workload of doctors in recent\nyears. Deep learning techniques for natural image captioning are successfully\nadapted to generating radiology reports. However, radiology image reporting is\ndifferent from the natural image captioning task in two aspects: 1) the\naccuracy of positive disease keyword mentions is critical in radiology image\nreporting in comparison to the equivalent importance of every single word in a\nnatural image caption; 2) the evaluation of reporting quality should focus more\non matching the disease keywords and their associated attributes instead of\ncounting the occurrence of N-gram. Based on these concerns, we propose to\nutilize a pre-constructed graph embedding module (modeled with a graph\nconvolutional neural network) on multiple disease findings to assist the\ngeneration of reports in this work. The incorporation of knowledge graph allows\nfor dedicated feature learning for each disease finding and the relationship\nmodeling between them. In addition, we proposed a new evaluation metric for\nradiology image reporting with the assistance of the same composed graph.\nExperimental results demonstrate the superior performance of the methods\nintegrated with the proposed graph embedding module on a publicly accessible\ndataset (IU-RR) of chest radiographs compared with previous approaches using\nboth the conventional evaluation metrics commonly adopted for image captioning\nand our proposed ones.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 16:39:42 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Zhang", "Yixiao", ""], ["Wang", "Xiaosong", ""], ["Xu", "Ziyue", ""], ["Yu", "Qihang", ""], ["Yuille", "Alan", ""], ["Xu", "Daguang", ""]]}, {"id": "2002.08289", "submitter": "Chitresh Bhushan", "authors": "Chitresh Bhushan, Zhaoyuan Yang, Nurali Virani, Naresh Iyer", "title": "Variational Encoder-based Reliable Classification", "comments": "Published in ICIP 2020. Typos fixed in revision", "journal-ref": "IEEE International Conference on Image Processing (2020) 1941-1945", "doi": "10.1109/ICIP40778.2020.9190836", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models provide statistically impressive results which might\nbe individually unreliable. To provide reliability, we propose an Epistemic\nClassifier (EC) that can provide justification of its belief using support from\nthe training dataset as well as quality of reconstruction. Our approach is\nbased on modified variational auto-encoders that can identify a semantically\nmeaningful low-dimensional space where perceptually similar instances are close\nin $\\ell_2$-distance too. Our results demonstrate improved reliability of\npredictions and robust identification of samples with adversarial attacks as\ncompared to baseline of softmax-based thresholding.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:05:32 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 13:51:37 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Bhushan", "Chitresh", ""], ["Yang", "Zhaoyuan", ""], ["Virani", "Nurali", ""], ["Iyer", "Naresh", ""]]}, {"id": "2002.08295", "submitter": "Abdul Dakkak", "authors": "Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-mei Hwu", "title": "MLModelScope: A Distributed Platform for Model Evaluation and\n  Benchmarking at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) innovations are being introduced\nat such a rapid pace that researchers are hard-pressed to analyze and study\nthem. The complicated procedures for evaluating innovations, along with the\nlack of standard and efficient ways of specifying and provisioning ML/DL\nevaluation, is a major \"pain point\" for the community. This paper proposes\nMLModelScope, an open-source, framework/hardware agnostic, extensible and\ncustomizable design that enables repeatable, fair, and scalable model\nevaluation and benchmarking. We implement the distributed design with support\nfor all major frameworks and hardware, and equip it with web, command-line, and\nlibrary interfaces. To demonstrate MLModelScope's capabilities we perform\nparallel evaluation and show how subtle changes to model evaluation pipeline\naffects the accuracy and HW/SW stack choices affect performance.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:13:01 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Dakkak", "Abdul", ""], ["Li", "Cheng", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "2002.08301", "submitter": "Wen-Kai Yu", "authors": "Shuo-Fei Wang, Wen-Kai Yu, and Ya-Xin Li", "title": "Multi-wavelet residual dense convolutional neural network for image\n  denoising", "comments": "9 pages, 9 figures", "journal-ref": "IEEE Access (2020)", "doi": "10.1109/ACCESS.2020.3040542", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks with large receptive field (RF) have shown advanced fitting ability\nin recent years. In this work, we utilize the short-term residual learning\nmethod to improve the performance and robustness of networks for image\ndenoising tasks. Here, we choose a multi-wavelet convolutional neural network\n(MWCNN), one of the state-of-art networks with large RF, as the backbone, and\ninsert residual dense blocks (RDBs) in its each layer. We call this scheme\nmulti-wavelet residual dense convolutional neural network (MWRDCNN). Compared\nwith other RDB-based networks, it can extract more features of the object from\nadjacent layers, preserve the large RF, and boost the computing efficiency.\nMeanwhile, this approach also provides a possibility of absorbing advantages of\nmultiple architectures in a single network without conflicts. The performance\nof the proposed method has been demonstrated in extensive experiments with a\ncomparison with existing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:21:37 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wang", "Shuo-Fei", ""], ["Yu", "Wen-Kai", ""], ["Li", "Ya-Xin", ""]]}, {"id": "2002.08313", "submitter": "Akshaj Kumar Veldanda", "authors": "Akshaj Kumar Veldanda, Kang Liu, Benjamin Tan, Prashanth\n  Krishnamurthy, Farshad Khorrami, Ramesh Karri, Brendan Dolan-Gavitt, and\n  Siddharth Garg", "title": "NNoculation: Broad Spectrum and Targeted Treatment of Backdoored DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel two-stage defense (NNoculation) against\nbackdoored neural networks (BadNets) that, unlike existing defenses, makes\nminimal assumptions on the shape, size and location of backdoor triggers and\nBadNet's functioning. In the pre-deployment stage, NNoculation retrains the\nnetwork using \"broad-spectrum\" random perturbations of inputs drawn from a\nclean validation set to partially reduce the adversarial impact of a backdoor.\nIn the post-deployment stage, NNoculation detects and quarantines backdoored\ntest inputs by recording disagreements between the original and pre-deployment\npatched networks. A CycleGAN is then trained to learn transformations between\nclean validation inputs and quarantined inputs; i.e., it learns to add triggers\nto clean validation images. This transformed set of backdoored validation\nimages along with their correct labels is used to further retrain the BadNet,\nyielding our final defense. NNoculation outperforms state-of-the-art defenses\nNeuralCleanse and Artificial Brain Simulation (ABS) that we show are\nineffective when their restrictive assumptions are circumvented by the\nattacker.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:51:21 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Veldanda", "Akshaj Kumar", ""], ["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Krishnamurthy", "Prashanth", ""], ["Khorrami", "Farshad", ""], ["Karri", "Ramesh", ""], ["Dolan-Gavitt", "Brendan", ""], ["Garg", "Siddharth", ""]]}, {"id": "2002.08314", "submitter": "Mokhtar Z. Alaya", "authors": "Mokhtar Z. Alaya, Maxime B\\'erar, Gilles Gasso, Alain Rakotomamonjy", "title": "Theoretical Guarantees for Bridging Metric Measure Embedding and Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for comparing distributions whose supports do not\nnecessarily lie on the same metric space. Unlike Gromov-Wasserstein (GW)\ndistance which compares pairwise distances of elements from each distribution,\nwe consider a method allowing to embed the metric measure spaces in a common\nEuclidean space and compute an optimal transport (OT) on the embedded\ndistributions. This leads to what we call a sub-embedding robust Wasserstein\n(SERW) distance. Under some conditions, SERW is a distance that considers an OT\ndistance of the (low-distorted) embedded distributions using a common metric.\nIn addition to this novel proposal that generalizes several recent OT works,\nour contributions stand on several theoretical analyses: (i) we characterize\nthe embedding spaces to define SERW distance for distribution alignment; (ii)\nwe prove that SERW mimics almost the same properties of GW distance, and we\ngive a cost relation between GW and SERW. The paper also provides some\nnumerical illustrations of how SERW behaves on matching problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:52:01 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:10:38 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 09:57:49 GMT"}, {"version": "v4", "created": "Fri, 25 Dec 2020 15:49:10 GMT"}, {"version": "v5", "created": "Thu, 22 Apr 2021 17:43:40 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Alaya", "Mokhtar Z.", ""], ["B\u00e9rar", "Maxime", ""], ["Gasso", "Gilles", ""], ["Rakotomamonjy", "Alain", ""]]}, {"id": "2002.08320", "submitter": "Diane Staheli", "authors": "Dennis Ross, Arunesh Sinha, Diane Staheli, Bill Streilein", "title": "Proceedings of the Artificial Intelligence for Cyber Security (AICS)\n  Workshop 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workshop will focus on the application of artificial intelligence to\nproblems in cyber security. AICS 2020 emphasis will be on human-machine teaming\nwithin the context of cyber security problems and will specifically explore\ncollaboration between human operators and AI technologies. The workshop will\naddress applicable areas of AI, such as machine learning, game theory, natural\nlanguage processing, knowledge representation, automated and assistive\nreasoning and human machine interactions. Further, cyber security application\nareas with a particular emphasis on the characterization and deployment of\nhuman-machine teaming will be the focus.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 18:12:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 22:03:20 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ross", "Dennis", ""], ["Sinha", "Arunesh", ""], ["Staheli", "Diane", ""], ["Streilein", "Bill", ""]]}, {"id": "2002.08326", "submitter": "Cong Guo", "authors": "Cong Guo, Yangjie Zhou, Jingwen Leng, Yuhao Zhu, Zidong Du, Quan Chen,\n  Chao Li, Bin Yao and Minyi Guo", "title": "Balancing Efficiency and Flexibility for DNN Acceleration via Temporal\n  GPU-Systolic Array Integration", "comments": "6 pages, 9 figures, DAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research interest in specialized hardware accelerators for deep neural\nnetworks (DNN) spikes recently owing to their superior performance and\nefficiency. However, today's DNN accelerators primarily focus on accelerating\nspecific \"kernels\" such as convolution and matrix multiplication, which are\nvital but only part of an end-to-end DNN-enabled application. Meaningful\nspeedups over the entire application often require supporting computations that\nare, while massively parallel, ill-suited to DNN accelerators. Integrating a\ngeneral-purpose processor such as a CPU or a GPU incurs significant data\nmovement overhead and leads to resource under-utilization on the DNN\naccelerators.\n  We propose Simultaneous Multi-mode Architecture (SMA), a novel architecture\ndesign and execution model that offers general-purpose programmability on DNN\naccelerators in order to accelerate end-to-end applications. The key to SMA is\nthe temporal integration of the systolic execution model with the GPU-like SIMD\nexecution model. The SMA exploits the common components shared between the\nsystolic-array accelerator and the GPU, and provides lightweight\nreconfiguration capability to switch between the two modes in-situ. The SMA\nachieves up to 63% performance improvement while consuming 23% less energy than\nthe baseline Volta architecture with TensorCore.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:44:20 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 10:27:55 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Guo", "Cong", ""], ["Zhou", "Yangjie", ""], ["Leng", "Jingwen", ""], ["Zhu", "Yuhao", ""], ["Du", "Zidong", ""], ["Chen", "Quan", ""], ["Li", "Chao", ""], ["Yao", "Bin", ""], ["Guo", "Minyi", ""]]}, {"id": "2002.08327", "submitter": "Shawn Shan", "authors": "Shawn Shan, Emily Wenger, Jiayun Zhang, Huiying Li, Haitao Zheng, Ben\n  Y. Zhao", "title": "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models", "comments": null, "journal-ref": "USENIX Security Symposium 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's proliferation of powerful facial recognition systems poses a real\nthreat to personal privacy. As Clearview.ai demonstrated, anyone can canvas the\nInternet for data and train highly accurate facial recognition models of\nindividuals without their knowledge. We need tools to protect ourselves from\npotential misuses of unauthorized facial recognition systems. Unfortunately, no\npractical or effective solutions exist.\n  In this paper, we propose Fawkes, a system that helps individuals inoculate\ntheir images against unauthorized facial recognition models. Fawkes achieves\nthis by helping users add imperceptible pixel-level changes (we call them\n\"cloaks\") to their own photos before releasing them. When used to train facial\nrecognition models, these \"cloaked\" images produce functional models that\nconsistently cause normal images of the user to be misidentified. We\nexperimentally demonstrate that Fawkes provides 95+% protection against user\nrecognition regardless of how trackers train their models. Even when clean,\nuncloaked images are \"leaked\" to the tracker and used for training, Fawkes can\nstill maintain an 80+% protection success rate. We achieve 100% success in\nexperiments against today's state-of-the-art facial recognition services.\nFinally, we show that Fawkes is robust against a variety of countermeasures\nthat try to detect or disrupt image cloaks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:00:22 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 03:54:20 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Shan", "Shawn", ""], ["Wenger", "Emily", ""], ["Zhang", "Jiayun", ""], ["Li", "Huiying", ""], ["Zheng", "Haitao", ""], ["Zhao", "Ben Y.", ""]]}, {"id": "2002.08329", "submitter": "Arthur Guez", "authors": "Arthur Guez, Fabio Viola, Th\\'eophane Weber, Lars Buesing, Steven\n  Kapturowski, Doina Precup, David Silver, Nicolas Heess", "title": "Value-driven Hindsight Modelling", "comments": "9 pages + reference + appendix. NeurIPS 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value estimation is a critical component of the reinforcement learning (RL)\nparadigm. The question of how to effectively learn value predictors from data\nis one of the major problems studied by the RL community, and different\napproaches exploit structure in the problem domain in different ways. Model\nlearning can make use of the rich transition structure present in sequences of\nobservations, but this approach is usually not sensitive to the reward\nfunction. In contrast, model-free methods directly leverage the quantity of\ninterest from the future, but receive a potentially weak scalar signal (an\nestimate of the return). We develop an approach for representation learning in\nRL that sits in between these two extremes: we propose to learn what to model\nin a way that can directly help value prediction. To this end, we determine\nwhich features of the future trajectory provide useful information to predict\nthe associated return. This provides tractable prediction targets that are\ndirectly relevant for a task, and can thus accelerate learning the value\nfunction. The idea can be understood as reasoning, in hindsight, about which\naspects of the future observations could help past value prediction. We show\nhow this can help dramatically even in simple policy evaluation settings. We\nthen test our approach at scale in challenging domains, including on 57 Atari\n2600 games.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:10:20 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:18:12 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Guez", "Arthur", ""], ["Viola", "Fabio", ""], ["Weber", "Th\u00e9ophane", ""], ["Buesing", "Lars", ""], ["Kapturowski", "Steven", ""], ["Precup", "Doina", ""], ["Silver", "David", ""], ["Heess", "Nicolas", ""]]}, {"id": "2002.08333", "submitter": "Caterina Neef", "authors": "Caterina Neef, Dario Luipers, Jan Bollenbacher, Christian Gebel and\n  Anja Richert", "title": "Towards Intelligent Pick and Place Assembly of Individualized Products\n  Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individualized manufacturing is becoming an important approach as a means to\nfulfill increasingly diverse and specific consumer requirements and\nexpectations. While there are various solutions to the implementation of the\nmanufacturing process, such as additive manufacturing, the subsequent automated\nassembly remains a challenging task. As an approach to this problem, we aim to\nteach a collaborative robot to successfully perform pick and place tasks by\nimplementing reinforcement learning. For the assembly of an individualized\nproduct in a constantly changing manufacturing environment, the simulated\ngeometric and dynamic parameters will be varied. Using reinforcement learning\nalgorithms capable of meta-learning, the tasks will first be trained in\nsimulation. They will then be performed in a real-world environment where new\nfactors are introduced that were not simulated in training to confirm the\nrobustness of the algorithms. The robot will gain its input data from tactile\nsensors, area scan cameras, and 3D cameras used to generate heightmaps of the\nenvironment and the objects. The selection of machine learning algorithms and\nhardware components as well as further research questions to realize the\noutlined production scenario are the results of the presented work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 15:32:28 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Neef", "Caterina", ""], ["Luipers", "Dario", ""], ["Bollenbacher", "Jan", ""], ["Gebel", "Christian", ""], ["Richert", "Anja", ""]]}, {"id": "2002.08335", "submitter": "Gene Yoo", "authors": "Gene Ryan Yoo and Houman Owhadi", "title": "Deep regularization and direct training of the inner layers of Neural\n  Networks with Kernel Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new regularization method for Artificial Neural Networks\n(ANNs) based on Kernel Flows (KFs). KFs were introduced as a method for kernel\nselection in regression/kriging based on the minimization of the loss of\naccuracy incurred by halving the number of interpolation points in random\nbatches of the dataset. Writing $f_\\theta(x) = \\big(f^{(n)}_{\\theta_n}\\circ\nf^{(n-1)}_{\\theta_{n-1}} \\circ \\dots \\circ f^{(1)}_{\\theta_1}\\big)(x)$ for the\nfunctional representation of compositional structure of the ANN, the inner\nlayers outputs $h^{(i)}(x) = \\big(f^{(i)}_{\\theta_i}\\circ\nf^{(i-1)}_{\\theta_{i-1}} \\circ \\dots \\circ f^{(1)}_{\\theta_1}\\big)(x)$ define a\nhierarchy of feature maps and kernels $k^{(i)}(x,x')=\\exp(- \\gamma_i\n\\|h^{(i)}(x)-h^{(i)}(x')\\|_2^2)$. When combined with a batch of the dataset\nthese kernels produce KF losses $e_2^{(i)}$ (the $L^2$ regression error\nincurred by using a random half of the batch to predict the other half)\ndepending on parameters of inner layers $\\theta_1,\\ldots,\\theta_i$ (and\n$\\gamma_i$). The proposed method simply consists in aggregating a subset of\nthese KF losses with a classical output loss. We test the proposed method on\nCNNs and WRNs without alteration of structure nor output classifier and report\nreduced test errors, decreased generalization gaps, and increased robustness to\ndistribution shift without significant increase in computational complexity. We\nsuspect that these results might be explained by the fact that while\nconventional training only employs a linear functional (a generalized moment)\nof the empirical distribution defined by the dataset and can be prone to\ntrapping in the Neural Tangent Kernel regime (under over-parameterizations),\nthe proposed loss function (defined as a nonlinear functional of the empirical\ndistribution) effectively trains the underlying kernel defined by the CNN\nbeyond regressing the data with that kernel.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:20:36 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 03:47:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Yoo", "Gene Ryan", ""], ["Owhadi", "Houman", ""]]}, {"id": "2002.08338", "submitter": "Haw-Minn Lu", "authors": "Haw-minn Lu (1), Giancarlo Perrone (1), Jos\\'e Unpingco (1) ((1) Gary\n  and Mary West Health Institute)", "title": "Multiple Imputation with Denoising Autoencoder using Metamorphic Truth\n  and Imputation Feedback", "comments": "Machine Learning and Data Mining in Pattern Recognition, 16th\n  International Conference on Machine Learning and Data Mining, MLDM 2020,\n  Amsterdam, The Netherlands, July 20-21, 2020, Proceedings, pp. 197-208", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although data may be abundant, complete data is less so, due to missing\ncolumns or rows. This missingness undermines the performance of downstream data\nproducts that either omit incomplete cases or create derived completed data for\nsubsequent processing. Appropriately managing missing data is required in order\nto fully exploit and correctly use data. We propose a Multiple Imputation model\nusing Denoising Autoencoders to learn the internal representation of data.\nFurthermore, we use the novel mechanisms of Metamorphic Truth and Imputation\nFeedback to maintain statistical integrity of attributes and eliminate bias in\nthe learning process. Our approach explores the effects of imputation on\nvarious missingness mechanisms and patterns of missing data, outperforming\nother methods in many standard test cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:26:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 02:20:17 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Lu", "Haw-minn", ""], ["Perrone", "Giancarlo", ""], ["Unpingco", "Jos\u00e9", ""]]}, {"id": "2002.08339", "submitter": "Michel Kinsy", "authors": "Mihailo Isakov and Michel A. Kinsy", "title": "NeuroFabric: Identifying Ideal Topologies for Training A Priori Sparse\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "Report-v05", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long training times of deep neural networks are a bottleneck in machine\nlearning research. The major impediment to fast training is the quadratic\ngrowth of both memory and compute requirements of dense and convolutional\nlayers with respect to their information bandwidth. Recently, training `a\npriori' sparse networks has been proposed as a method for allowing layers to\nretain high information bandwidth, while keeping memory and compute low.\nHowever, the choice of which sparse topology should be used in these networks\nis unclear. In this work, we provide a theoretical foundation for the choice of\nintra-layer topology. First, we derive a new sparse neural network\ninitialization scheme that allows us to explore the space of very deep sparse\nnetworks. Next, we evaluate several topologies and show that seemingly similar\ntopologies can often have a large difference in attainable accuracy. To explain\nthese differences, we develop a data-free heuristic that can evaluate a\ntopology independently from the dataset the network will be trained on. We then\nderive a set of requirements that make a good topology, and arrive at a single\ntopology that satisfies all of them.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:29:18 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Isakov", "Mihailo", ""], ["Kinsy", "Michel A.", ""]]}, {"id": "2002.08345", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and Frank Nielsen", "title": "Schoenberg-Rao distances: Entropy-based and geometry-aware statistical\n  Hilbert distances", "comments": "Most results were already known. The distances described therein do\n  not generalize MMD: it is an MMD with a distance-induced kernel (see\n  [Sejdinovic et al. (2013)]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distances between probability distributions that take into account the\ngeometry of their sample space,like the Wasserstein or the Maximum Mean\nDiscrepancy (MMD) distances have received a lot of attention in machine\nlearning as they can, for instance, be used to compare probability\ndistributions with disjoint supports. In this paper, we study a class of\nstatistical Hilbert distances that we term the Schoenberg-Rao distances, a\ngeneralization of the MMD that allows one to consider a broader class of\nkernels, namely the conditionally negative semi-definite kernels. In\nparticular, we introduce a principled way to construct such kernels and derive\nnovel closed-form distances between mixtures of Gaussian distributions. These\ndistances, derived from the concave Rao's quadratic entropy, enjoy nice\ntheoretical properties and possess interpretable hyperparameters which can be\ntuned for specific applications. Our method constitutes a practical alternative\nto Wasserstein distances and we illustrate its efficiency on a broad range of\nmachine learning tasks such as density estimation, generative modeling and\nmixture simplification.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:48:33 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 13:19:50 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Nielsen", "Frank", ""]]}, {"id": "2002.08347", "submitter": "Florian Tram\\`er", "authors": "Florian Tramer, Nicholas Carlini, Wieland Brendel, Aleksander Madry", "title": "On Adaptive Attacks to Adversarial Example Defenses", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive attacks have (rightfully) become the de facto standard for\nevaluating defenses to adversarial examples. We find, however, that typical\nadaptive evaluations are incomplete. We demonstrate that thirteen defenses\nrecently published at ICLR, ICML and NeurIPS---and chosen for illustrative and\npedagogical purposes---can be circumvented despite attempting to perform\nevaluations using adaptive attacks. While prior evaluation papers focused\nmainly on the end result---showing that a defense was ineffective---this paper\nfocuses on laying out the methodology and the approach necessary to perform an\nadaptive attack. We hope that these analyses will serve as guidance on how to\nproperly perform adaptive attacks against defenses to adversarial examples, and\nthus will allow the community to make further progress in building more robust\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:50:29 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 12:07:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Tramer", "Florian", ""], ["Carlini", "Nicholas", ""], ["Brendel", "Wieland", ""], ["Madry", "Aleksander", ""]]}, {"id": "2002.08356", "submitter": "Takanori Fujiwara", "authors": "Rongchen Guo, Takanori Fujiwara, Yiran Li, Kelly M. Lima, Soman Sen,\n  Nam K. Tran, and Kwan-Liu Ma", "title": "Comparative Visual Analytics for Assessing Medical Records with Sequence\n  Embedding", "comments": "This is the author's version of the article that has been accepted in\n  PacificVis 2020 Visualization Meets AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for data-driven diagnosis has been actively studied in\nmedicine to provide better healthcare. Supporting analysis of a patient cohort\nsimilar to a patient under treatment is a key task for clinicians to make\ndecisions with high confidence. However, such analysis is not straightforward\ndue to the characteristics of medical records: high dimensionality,\nirregularity in time, and sparsity. To address this challenge, we introduce a\nmethod for similarity calculation of medical records. Our method employs event\nand sequence embeddings. While we use an autoencoder for the event embedding,\nwe apply its variant with the self-attention mechanism for the sequence\nembedding. Moreover, in order to better handle the irregularity of data, we\nenhance the self-attention mechanism with consideration of different time\nintervals. We have developed a visual analytics system to support comparative\nstudies of patient records. To make a comparison of sequences with different\nlengths easier, our system incorporates a sequence alignment method. Through\nits interactive interface, the user can quickly identify patients of interest\nand conveniently review both the temporal and multivariate aspects of the\npatient records. We demonstrate the effectiveness of our design and system with\ncase studies using a real-world dataset from the neonatal intensive care unit\nof UC Davis.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:29:30 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:02:15 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Guo", "Rongchen", ""], ["Fujiwara", "Takanori", ""], ["Li", "Yiran", ""], ["Lima", "Kelly M.", ""], ["Sen", "Soman", ""], ["Tran", "Nam K.", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2002.08394", "submitter": "Krishna Murthy Jatavallabhula", "authors": "Kaustubh Mani, Swapnil Daga, Shubhika Garg, N. Sai Shankar, Krishna\n  Murthy Jatavallabhula, K. Madhava Krishna", "title": "MonoLayout: Amodal scene layout from a single image", "comments": "To be presented at WACV 2020 Video:\n  https://www.youtube.com/watch?v=HcroGyo6yRQ Project page:\n  https://hbutsuak95.github.io/monolayout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the novel, highly challenging problem of estimating\nthe layout of a complex urban driving scenario. Given a single color image\ncaptured from a driving platform, we aim to predict the bird's-eye view layout\nof the road and other traffic participants. The estimated layout should reason\nbeyond what is visible in the image, and compensate for the loss of 3D\ninformation due to projection. We dub this problem amodal scene layout\nestimation, which involves \"hallucinating\" scene layout for even parts of the\nworld that are occluded in the image. To this end, we present MonoLayout, a\ndeep neural network for real-time amodal scene layout estimation from a single\nimage. We represent scene layout as a multi-channel semantic occupancy grid,\nand leverage adversarial feature learning to hallucinate plausible completions\nfor occluded image parts. Due to the lack of fair baseline methods, we extend\nseveral state-of-the-art approaches for road-layout estimation and vehicle\noccupancy estimation in bird's-eye view to the amodal setup for rigorous\nevaluation. By leveraging temporal sensor fusion to generate training labels,\nwe significantly outperform current art over a number of datasets. On the KITTI\nand Argoverse datasets, we outperform all baselines by a significant margin. We\nalso make all our annotations, and code publicly available. A video abstract of\nthis paper is available https://www.youtube.com/watch?v=HcroGyo6yRQ .\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:16:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mani", "Kaustubh", ""], ["Daga", "Swapnil", ""], ["Garg", "Shubhika", ""], ["Shankar", "N. Sai", ""], ["Jatavallabhula", "Krishna Murthy", ""], ["Krishna", "K. Madhava", ""]]}, {"id": "2002.08396", "submitter": "Noah Siegel", "authors": "Noah Y. Siegel, Jost Tobias Springenberg, Felix Berkenkamp, Abbas\n  Abdolmaleki, Michael Neunert, Thomas Lampe, Roland Hafner, Nicolas Heess,\n  Martin Riedmiller", "title": "Keep Doing What Worked: Behavioral Modelling Priors for Offline\n  Reinforcement Learning", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning algorithms promise to be applicable in\nsettings where only a fixed data-set (batch) of environment interactions is\navailable and no new experience can be acquired. This property makes these\nalgorithms appealing for real world problems such as robot control. In\npractice, however, standard off-policy algorithms fail in the batch setting for\ncontinuous control. In this paper, we propose a simple solution to this\nproblem. It admits the use of data generated by arbitrary behavior policies and\nuses a learned prior -- the advantage-weighted behavior model (ABM) -- to bias\nthe RL policy towards actions that have previously been executed and are likely\nto be successful on the new task. Our method can be seen as an extension of\nrecent work on batch-RL that enables stable learning from conflicting\ndata-sources. We find improvements on competitive baselines in a variety of RL\ntasks -- including standard continuous control benchmarks and multi-task\nlearning for simulated and real-world robots.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:21:08 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 13:29:13 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 10:12:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Siegel", "Noah Y.", ""], ["Springenberg", "Jost Tobias", ""], ["Berkenkamp", "Felix", ""], ["Abdolmaleki", "Abbas", ""], ["Neunert", "Michael", ""], ["Lampe", "Thomas", ""], ["Hafner", "Roland", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "2002.08404", "submitter": "Arthur Jacot", "authors": "Arthur Jacot, Berfin \\c{S}im\\c{s}ek, Francesco Spadaro, Cl\\'ement\n  Hongler, Franck Gabriel", "title": "Implicit Regularization of Random Feature Models", "comments": null, "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2020, pp. 7397-7406", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Feature (RF) models are used as efficient parametric approximations of\nkernel methods. We investigate, by means of random matrix theory, the\nconnection between Gaussian RF models and Kernel Ridge Regression (KRR). For a\nGaussian RF model with $P$ features, $N$ data points, and a ridge $\\lambda$, we\nshow that the average (i.e. expected) RF predictor is close to a KRR predictor\nwith an effective ridge $\\tilde{\\lambda}$. We show that $\\tilde{\\lambda} >\n\\lambda$ and $\\tilde{\\lambda} \\searrow \\lambda$ monotonically as $P$ grows,\nthus revealing the implicit regularization effect of finite RF sampling. We\nthen compare the risk (i.e. test error) of the $\\tilde{\\lambda}$-KRR predictor\nwith the average risk of the $\\lambda$-RF predictor and obtain a precise and\nexplicit bound on their difference. Finally, we empirically find an extremely\ngood agreement between the test errors of the average $\\lambda$-RF predictor\nand $\\tilde{\\lambda}$-KRR predictor.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:36:23 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 10:29:43 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jacot", "Arthur", ""], ["\u015eim\u015fek", "Berfin", ""], ["Spadaro", "Francesco", ""], ["Hongler", "Cl\u00e9ment", ""], ["Gabriel", "Franck", ""]]}, {"id": "2002.08405", "submitter": "Nihal Sharma", "authors": "Nihal Sharma, Soumya Basu, Karthikeyan Shanmugam and Sanjay Shakkottai", "title": "On Under-exploration in Bandits with Mean Bounds from Confounded Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the multi-armed bandit problem where side information\nin the form of bounds on the mean of each arm is provided. We develop the novel\nnon-optimistic Global Under-Explore (GLUE) algorithm which uses the provided\nmean bounds (across all the arms) to infer pseudo-variances for each arm, which\nin turn decide the rate of exploration for the arms. We analyze the regret of\nGLUE and prove regret upper bounds that are never worse than that of the\nstandard UCB algorithm. Furthermore, we show that GLUE improves upon regret\nguarantees that exists in literature for structured bandit problems (both\ntheoretically and empirically). Finally, we study the practical setting of\nlearning adaptive interventions using prior data that has been confounded by\nunrecorded variables that affect rewards. We show that mean bounds can be\ninferred naturally from such logs and can thus be used to improve the learning\nprocess. We validate our findings through semi-synthetic experiments on data\nderived from real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:36:43 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 17:52:22 GMT"}, {"version": "v3", "created": "Wed, 12 Aug 2020 17:08:31 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 14:55:17 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Sharma", "Nihal", ""], ["Basu", "Soumya", ""], ["Shanmugam", "Karthikeyan", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "2002.08410", "submitter": "Qiong Zhang", "authors": "Qiong Zhang, Jiahua Chen", "title": "A Unified Framework for Gaussian Mixture Reduction with Composite\n  Transportation Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian mixture reduction (GMR) is the problem of approximating a finite\nGaussian mixture by one with fewer components. It is widely used in density\nestimation, nonparametric belief propagation, and Bayesian recursive filtering.\nAlthough optimization and clustering-based algorithms have been proposed for\nGMR, they are either computationally expensive or lacking in theoretical\nsupports. In this work, we propose to perform GMR by minimizing the entropic\nregularized composite transportation distance between two mixtures. We show our\napproach provides a unified framework for GMR that is both interpretable and\ncomputationally efficient. Our work also bridges the gap between optimization\nand clustering-based approaches for GMR. A Majorization-Minimization algorithm\nis developed for our optimization problem and its theoretical convergence is\nalso established in this paper. Empirical experiments are also conducted to\nshow the effectiveness of GMR. The effect of the choice of transportation cost\non the performance of GMR is also investigated.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:52:17 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Zhang", "Qiong", ""], ["Chen", "Jiahua", ""]]}, {"id": "2002.08412", "submitter": "Raed Al Kontar", "authors": "Seokhyun Chung, Raed Al Kontar, Zhenke Wu", "title": "Weakly-supervised Multi-output Regression via Correlated Gaussian\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-output regression seeks to infer multiple latent functions using data\nfrom multiple groups/sources while accounting for potential between-group\nsimilarities. In this paper, we consider multi-output regression under a\nweakly-supervised setting where a subset of data points from multiple groups\nare unlabeled. We use dependent Gaussian processes for multiple outputs\nconstructed by convolutions with shared latent processes. We introduce\nhyperpriors for the multinomial probabilities of the unobserved labels and\noptimize the hyperparameters which we show improves estimation. We derive two\nvariational bounds: (i) a modified variational bound for fast and stable\nconvergence in model inference, (ii) a scalable variational bound that is\namenable to stochastic optimization. We use experiments on synthetic and\nreal-world data to show that the proposed model outperforms state-of-the-art\nmodels with more accurate estimation of multiple latent functions and\nunobserved labels.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 19:54:25 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Chung", "Seokhyun", ""], ["Kontar", "Raed Al", ""], ["Wu", "Zhenke", ""]]}, {"id": "2002.08423", "submitter": "Vaikkunth Mugunthan", "authors": "Vaikkunth Mugunthan, Anton Peraire-Bueno and Lalana Kagal", "title": "PrivacyFL: A simulator for privacy-preserving and secure federated\n  learning", "comments": null, "journal-ref": null, "doi": "10.1145/3340531.3412771", "report-no": null, "categories": "cs.LG cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a technique that enables distributed clients to\ncollaboratively learn a shared machine learning model while keeping their\ntraining data localized. This reduces data privacy risks, however, privacy\nconcerns still exist since it is possible to leak information about the\ntraining dataset from the trained model's weights or parameters. Setting up a\nfederated learning environment, especially with security and privacy\nguarantees, is a time-consuming process with numerous configurations and\nparameters that can be manipulated. In order to help clients ensure that\ncollaboration is feasible and to check that it improves their model accuracy, a\nreal-world simulator for privacy-preserving and secure federated learning is\nrequired. In this paper, we introduce PrivacyFL, which is an extensible, easily\nconfigurable and scalable simulator for federated learning environments. Its\nkey features include latency simulation, robustness to client departure,\nsupport for both centralized and decentralized learning, and configurable\nprivacy and security mechanisms based on differential privacy and secure\nmultiparty computation. In this paper, we motivate our research, describe the\narchitecture of the simulator and associated protocols, and discuss its\nevaluation in numerous scenarios that highlight its wide range of functionality\nand its advantages. Our paper addresses a significant real-world problem:\nchecking the feasibility of participating in a federated learning environment\nunder a variety of circumstances. It also has a strong practical impact because\norganizations such as hospitals, banks, and research institutes, which have\nlarge amounts of sensitive data and would like to collaborate, would greatly\nbenefit from having a system that enables them to do so in a privacy-preserving\nand secure manner.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:16:13 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:30:36 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Mugunthan", "Vaikkunth", ""], ["Peraire-Bueno", "Anton", ""], ["Kagal", "Lalana", ""]]}, {"id": "2002.08436", "submitter": "Guang Cheng", "authors": "Chi-Hua Wang, Yang Yu, Botao Hao, Guang Cheng", "title": "Residual Bootstrap Exploration for Bandit Algorithms", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel perturbation-based exploration method in\nbandit algorithms with bounded or unbounded rewards, called residual bootstrap\nexploration (\\texttt{ReBoot}). The \\texttt{ReBoot} enforces exploration by\ninjecting data-driven randomness through a residual-based perturbation\nmechanism. This novel mechanism captures the underlying distributional\nproperties of fitting errors, and more importantly boosts exploration to escape\nfrom suboptimal solutions (for small sample sizes) by inflating variance level\nin an \\textit{unconventional} way. In theory, with appropriate variance\ninflation level, \\texttt{ReBoot} provably secures instance-dependent\nlogarithmic regret in Gaussian multi-armed bandits. We evaluate the\n\\texttt{ReBoot} in different synthetic multi-armed bandits problems and observe\nthat the \\texttt{ReBoot} performs better for unbounded rewards and more\nrobustly than \\texttt{Giro} \\cite{kveton2018garbage} and \\texttt{PHE}\n\\cite{kveton2019perturbed}, with comparable computational efficiency to the\nThompson sampling method.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:43:27 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Chi-Hua", ""], ["Yu", "Yang", ""], ["Hao", "Botao", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.08438", "submitter": "Mina Amiri", "authors": "Mina Amiri, Rupert Brooks, Hassan Rivaz", "title": "Fine tuning U-Net for ultrasound image segmentation: which layers?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning a network which has been trained on a large dataset is an\nalternative to full training in order to overcome the problem of scarce and\nexpensive data in medical applications. While the shallow layers of the network\nare usually kept unchanged, deeper layers are modified according to the new\ndataset. This approach may not work for ultrasound images due to their\ndrastically different appearance. In this study, we investigated the effect of\nfine-tuning different layers of a U-Net which was trained on segmentation of\nnatural images in breast ultrasound image segmentation. Tuning the contracting\npart and fixing the expanding part resulted in substantially better results\ncompared to fixing the contracting part and tuning the expanding part.\nFurthermore, we showed that starting to fine-tune the U-Net from the shallow\nlayers and gradually including more layers will lead to a better performance\ncompared to fine-tuning the network from the deep layers moving back to shallow\nlayers. We did not observe the same results on segmentation of X-ray images,\nwhich have different salient features compared to ultrasound, it may therefore\nbe more appropriate to fine-tune the shallow layers rather than deep layers.\nShallow layers learn lower level features (including speckle pattern, and\nprobably the noise and artifact properties) which are critical in automatic\nsegmentation in this modality.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:45:40 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Amiri", "Mina", ""], ["Brooks", "Rupert", ""], ["Rivaz", "Hassan", ""]]}, {"id": "2002.08439", "submitter": "Siyue Wang", "authors": "Xiao Wang, Siyue Wang, Pin-Yu Chen, Xue Lin, Peter Chin", "title": "AdvMS: A Multi-source Multi-cost Defense Against Adversarial Attacks", "comments": "Accepted by 45th International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective defense against adversarial attacks is a crucial topic as\ndeep neural networks have been proliferated rapidly in many security-critical\ndomains such as malware detection and self-driving cars. Conventional defense\nmethods, although shown to be promising, are largely limited by their\nsingle-source single-cost nature: The robustness promotion tends to plateau\nwhen the defenses are made increasingly stronger while the cost tends to\namplify. In this paper, we study principles of designing multi-source and\nmulti-cost schemes where defense performance is boosted from multiple defending\ncomponents. Based on this motivation, we propose a multi-source and multi-cost\ndefense scheme, Adversarially Trained Model Switching (AdvMS), that inherits\nadvantages from two leading schemes: adversarial training and random model\nswitching. We show that the multi-source nature of AdvMS mitigates the\nperformance plateauing issue and the multi-cost nature enables improving\nrobustness at a flexible and adjustable combination of costs over different\nfactors which can better suit specific restrictions and needs in practice.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:46:54 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Siyue", ""], ["Chen", "Pin-Yu", ""], ["Lin", "Xue", ""], ["Chin", "Peter", ""]]}, {"id": "2002.08443", "submitter": "Guang Cheng", "authors": "Yang Yu, Shih-Kang Chao, Guang Cheng", "title": "Simultaneous Inference for Massive Data: Distributed Bootstrap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a bootstrap method applied to massive data\nprocessed distributedly in a large number of machines. This new method is\ncomputationally efficient in that we bootstrap on the master machine without\nover-resampling, typically required by existing methods\n\\cite{kleiner2014scalable,sengupta2016subsampled}, while provably achieving\noptimal statistical efficiency with minimal communication. Our method does not\nrequire repeatedly re-fitting the model but only applies multiplier bootstrap\nin the master machine on the gradients received from the worker machines.\nSimulations validate our theory.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 20:53:32 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Yu", "Yang", ""], ["Chao", "Shih-Kang", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.08448", "submitter": "Samik Banerjee", "authors": "Samik Banerjee, Sukhendu Das", "title": "SD-GAN: Structural and Denoising GAN reveals facial parts under\n  occlusion", "comments": "Recommended for revision in Neurocomputing, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain facial parts are salient (unique) in appearance, which substantially\ncontribute to the holistic recognition of a subject. Occlusion of these salient\nparts deteriorates the performance of face recognition algorithms. In this\npaper, we propose a generative model to reconstruct the missing parts of the\nface which are under occlusion. The proposed generative model (SD-GAN)\nreconstructs a face preserving the illumination variation and identity of the\nface. A novel adversarial training algorithm has been designed for a bimodal\nmutually exclusive Generative Adversarial Network (GAN) model, for faster\nconvergence. A novel adversarial \"structural\" loss function is also proposed,\ncomprising of two components: a holistic and a local loss, characterized by\nSSIM and patch-wise MSE. Ablation studies on real and synthetically occluded\nface datasets reveal that our proposed technique outperforms the competing\nmethods by a considerable margin, even for boosting the performance of Face\nRecognition.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 21:12:49 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Banerjee", "Samik", ""], ["Das", "Sukhendu", ""]]}, {"id": "2002.08456", "submitter": "Julien Perolat", "authors": "Julien Perolat, Remi Munos, Jean-Baptiste Lespiau, Shayegan\n  Omidshafiei, Mark Rowland, Pedro Ortega, Neil Burch, Thomas Anthony, David\n  Balduzzi, Bart De Vylder, Georgios Piliouras, Marc Lanctot, Karl Tuyls", "title": "From Poincar\\'e Recurrence to Convergence in Imperfect Information\n  Games: Finding Equilibrium via Regularization", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the Follow the Regularized Leader dynamics in\nsequential imperfect information games (IIG). We generalize existing results of\nPoincar\\'e recurrence from normal-form games to zero-sum two-player imperfect\ninformation games and other sequential game settings. We then investigate how\nadapting the reward (by adding a regularization term) of the game can give\nstrong convergence guarantees in monotone games. We continue by showing how\nthis reward adaptation technique can be leveraged to build algorithms that\nconverge exactly to the Nash equilibrium. Finally, we show how these insights\ncan be directly used to build state-of-the-art model-free algorithms for\nzero-sum two-player Imperfect Information Games (IIG).\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 21:36:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Perolat", "Julien", ""], ["Munos", "Remi", ""], ["Lespiau", "Jean-Baptiste", ""], ["Omidshafiei", "Shayegan", ""], ["Rowland", "Mark", ""], ["Ortega", "Pedro", ""], ["Burch", "Neil", ""], ["Anthony", "Thomas", ""], ["Balduzzi", "David", ""], ["De Vylder", "Bart", ""], ["Piliouras", "Georgios", ""], ["Lanctot", "Marc", ""], ["Tuyls", "Karl", ""]]}, {"id": "2002.08465", "submitter": "Georgios Giasemidis Dr", "authors": "Georgios Giasemidis", "title": "Descriptive and Predictive Analysis of Euroleague Basketball Games and\n  the Wisdom of Basketball Crowds", "comments": "24 pages, several figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we focus on the prediction of basketball games in the\nEuroleague competition using machine learning modelling. The prediction is a\nbinary classification problem, predicting whether a match finishes 1 (home win)\nor 2 (away win). Data is collected from the Euroleague's official website for\nthe seasons 2016-2017, 2017-2018 and 2018-2019, i.e. in the new format era.\nFeatures are extracted from matches' data and off-the-shelf supervised machine\nlearning techniques are applied. We calibrate and validate our models. We find\nthat simple machine learning models give accuracy not greater than 67% on the\ntest set, worse than some sophisticated benchmark models. Additionally, the\nimportance of this study lies in the \"wisdom of the basketball crowd\" and we\ndemonstrate how the predicting power of a collective group of basketball\nenthusiasts can outperform machine learning models discussed in this study. We\nargue why the accuracy level of this group of \"experts\" should be set as the\nbenchmark for future studies in the prediction of (European) basketball games\nusing machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:04:29 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Giasemidis", "Georgios", ""]]}, {"id": "2002.08470", "submitter": "Kevin Scharp", "authors": "Alison Duncan Kerr and Kevin Scharp", "title": "The Information in Emotion Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much information is transmitted when animals use emotions to communicate?\nIt is clear that emotions are used as communication systems in humans and other\nspecies. The quantitative theory of emotion information presented here is based\non Shannon's mathematical theory of information in communication systems. The\ntheory explains myriad aspects of emotion communication and offers dozens of\nnew directions for research. It is superior to the \"contagion\" theory of\nemotion spreading, which is currently dominant. One important application of\nthe information theory of emotion communication is that it permits the\ndevelopment of emotion security systems for social networks to guard against\nthe widespread emotion manipulation we see online today.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 22:42:26 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kerr", "Alison Duncan", ""], ["Scharp", "Kevin", ""]]}, {"id": "2002.08483", "submitter": "Joshua Robinson", "authors": "Joshua Robinson, Stefanie Jegelka, Suvrit Sra", "title": "Strength from Weakness: Fast Learning Using Weak Supervision", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study generalization properties of weakly supervised learning. That is,\nlearning where only a few \"strong\" labels (the actual target of our prediction)\nare present but many more \"weak\" labels are available. In particular, we show\nthat having access to weak labels can significantly accelerate the learning\nrate for the strong task to the fast rate of $\\mathcal{O}(\\nicefrac1n)$, where\n$n$ denotes the number of strongly labeled data points. This acceleration can\nhappen even if by itself the strongly labeled data admits only the slower\n$\\mathcal{O}(\\nicefrac{1}{\\sqrt{n}})$ rate. The actual acceleration depends\ncontinuously on the number of weak labels available, and on the relation\nbetween the two tasks. Our theoretical results are reflected empirically across\na range of tasks and illustrate how weak labels speed up learning on the strong\ntask.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:39:37 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Robinson", "Joshua", ""], ["Jegelka", "Stefanie", ""], ["Sra", "Suvrit", ""]]}, {"id": "2002.08484", "submitter": "Frederick Liu", "authors": "Garima Pruthi, Frederick Liu, Mukund Sundararajan, Satyen Kale", "title": "Estimating Training Data Influence by Tracing Gradient Descent", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method called TracIn that computes the influence of a training\nexample on a prediction made by the model. The idea is to trace how the loss on\nthe test point changes during the training process whenever the training\nexample of interest was utilized. We provide a scalable implementation of\nTracIn via: (a) a first-order gradient approximation to the exact computation,\n(b) saved checkpoints of standard training procedures, and (c) cherry-picking\nlayers of a deep neural network. In contrast with previously proposed methods,\nTracIn is simple to implement; all it needs is the ability to work with\ngradients, checkpoints, and loss functions. The method is general. It applies\nto any machine learning model trained using stochastic gradient descent or a\nvariant of it, agnostic of architecture, domain and task. We expect the method\nto be widely useful within processes that study and improve training data.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:40:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 22:52:31 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2020 18:47:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Pruthi", "Garima", ""], ["Liu", "Frederick", ""], ["Sundararajan", "Mukund", ""], ["Kale", "Satyen", ""]]}, {"id": "2002.08491", "submitter": "Vasileios Charisopoulos", "authors": "Vasileios Charisopoulos, Austin R. Benson, Anil Damle", "title": "Entrywise convergence of iterative methods for eigenproblems", "comments": "21 pages, 8 figures. To appear in the 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several problems in machine learning, statistics, and other fields rely on\ncomputing eigenvectors. For large scale problems, the computation of these\neigenvectors is typically performed via iterative schemes such as subspace\niteration or Krylov methods. While there is classical and comprehensive\nanalysis for subspace convergence guarantees with respect to the spectral norm,\nin many modern applications other notions of subspace distance are more\nappropriate. Recent theoretical work has focused on perturbations of subspaces\nmeasured in the $\\ell_{2 \\to \\infty}$ norm, but does not consider the actual\ncomputation of eigenvectors. Here we address the convergence of subspace\niteration when distances are measured in the $\\ell_{2 \\to \\infty}$ norm and\nprovide deterministic bounds. We complement our analysis with a practical\nstopping criterion and demonstrate its applicability via numerical experiments.\nOur results show that one can get comparable performance on downstream tasks\nwhile requiring fewer iterations, thereby saving substantial computational\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 22:59:56 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 02:06:19 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Charisopoulos", "Vasileios", ""], ["Benson", "Austin R.", ""], ["Damle", "Anil", ""]]}, {"id": "2002.08493", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, and Tuomas Sandholm", "title": "Stochastic Regret Minimization in Extensive-Form Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte-Carlo counterfactual regret minimization (MCCFR) is the\nstate-of-the-art algorithm for solving sequential games that are too large for\nfull tree traversals. It works by using gradient estimates that can be computed\nvia sampling. However, stochastic methods for sequential games have not been\ninvestigated extensively beyond MCCFR. In this paper we develop a new framework\nfor developing stochastic regret minimization methods. This framework allows us\nto use any regret-minimization algorithm, coupled with any gradient estimator.\nThe MCCFR algorithm can be analyzed as a special case of our framework, and\nthis analysis leads to significantly-stronger theoretical on convergence, while\nsimultaneously yielding a simplified proof. Our framework allows us to\ninstantiate several new stochastic methods for solving sequential games. We\nshow extensive experiments on three games, where some variants of our methods\noutperform MCCFR.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 23:05:41 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2002.08506", "submitter": "Yunpu Ma", "authors": "Yunpu Ma and Volker Tresp", "title": "Causal Inference under Networked Interference and Intervention Policy\n  Enhancement", "comments": "Published on AISTATS 2021", "journal-ref": "Proceedings of The 24th International Conference on Artificial\n  Intelligence and Statistics, PMLR 130:3700-3708, 2021", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating individual treatment effects from data of randomized experiments\nis a critical task in causal inference. The Stable Unit Treatment Value\nAssumption (SUTVA) is usually made in causal inference. However, interference\ncan introduce bias when the assigned treatment on one unit affects the\npotential outcomes of the neighboring units. This interference phenomenon is\nknown as spillover effect in economics or peer effect in social science.\nUsually, in randomized experiments or observational studies with interconnected\nunits, one can only observe treatment responses under interference. Hence, how\nto estimate the superimposed causal effect and recover the individual treatment\neffect in the presence of interference becomes a challenging task in causal\ninference. In this work, we study causal effect estimation under general\nnetwork interference using GNNs, which are powerful tools for capturing the\ndependency in the graph. After deriving causal effect estimators, we further\nstudy intervention policy improvement on the graph under capacity constraint.\nWe give policy regret bounds under network interference and treatment capacity\nconstraint. Furthermore, a heuristic graph structure-dependent error bound for\nGNN-based causal estimators is provided.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 00:35:50 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:58:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""]]}, {"id": "2002.08517", "submitter": "Russell Tsuchida B.E.", "authors": "Russell Tsuchida, Tim Pearce, Chris van der Heide, Fred Roosta, Marcus\n  Gallagher", "title": "Avoiding Kernel Fixed Points: Computing with ELU and GELU Infinite\n  Networks", "comments": "AAAI camera ready version. 18 pages, 9 figures, 2 tables. Corrected\n  name particle capitalisation and formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysing and computing with Gaussian processes arising from infinitely wide\nneural networks has recently seen a resurgence in popularity. Despite this,\nmany explicit covariance functions of networks with activation functions used\nin modern networks remain unknown. Furthermore, while the kernels of deep\nnetworks can be computed iteratively, theoretical understanding of deep kernels\nis lacking, particularly with respect to fixed-point dynamics. Firstly, we\nderive the covariance functions of multi-layer perceptrons (MLPs) with\nexponential linear units (ELU) and Gaussian error linear units (GELU) and\nevaluate the performance of the limiting Gaussian processes on some benchmarks.\nSecondly, and more generally, we analyse the fixed-point dynamics of iterated\nkernels corresponding to a broad range of activation functions. We find that\nunlike some previously studied neural network kernels, these new kernels\nexhibit non-trivial fixed-point dynamics which are mirrored in finite-width\nneural networks. The fixed point behaviour present in some networks explains a\nmechanism for implicit regularisation in overparameterised deep models. Our\nresults relate to both the static iid parameter conjugate kernel and the\ndynamic neural tangent kernel constructions. Software at\ngithub.com/RussellTsuchida/ELU_GELU_kernels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:25:39 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 22:47:00 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 00:43:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Tsuchida", "Russell", ""], ["Pearce", "Tim", ""], ["van der Heide", "Chris", ""], ["Roosta", "Fred", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2002.08519", "submitter": "Xiangru Li", "authors": "Haitao Lin, Xiangru Li, Ziying Luo", "title": "Pulsars Detection by Machine Learning with Very Few Features", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": "10.1093/mnras/staa218", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is an active topic to investigate the schemes based on machine learning\n(ML) methods for detecting pulsars as the data volume growing exponentially in\nmodern surveys. To improve the detection performance, input features into an ML\nmodel should be investigated specifically. In the existing pulsar detection\nresearches based on ML methods, there are mainly two kinds of feature designs:\nthe empirical features and statistical features. Due to the combinational\neffects from multiple features, however, there exist some redundancies and even\nirrelevant components in the available features, which can reduce the accuracy\nof a pulsar detection model. Therefore, it is essential to select a subset of\nrelevant features from a set of available candidate features and known as\n{\\itshape feature selection.} In this work, two feature selection algorithms\n----\\textit{Grid Search} (GS) and \\textit{Recursive Feature Elimination}\n(RFE)---- are proposed to improve the detection performance by removing the\nredundant and irrelevant features. The algorithms were evaluated on the\nSouthern High Time Resolution University survey (HTRU-S) with five pulsar\ndetection models. The experimental results verify the effectiveness and\nefficiency of our proposed feature selection algorithms. By the GS, a model\nwith only two features reach a recall rate as high as 99\\% and a false positive\nrate (FPR) as low as 0.65\\%; By the RFE, another model with only three features\nachieves a recall rate 99\\% and an FPR of 0.16\\% in pulsar candidates\nclassification. Furthermore, this work investigated the number of features\nrequired as well as the misclassified pulsars by our models.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:26:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Lin", "Haitao", ""], ["Li", "Xiangru", ""], ["Luo", "Ziying", ""]]}, {"id": "2002.08525", "submitter": "Tom Beucler", "authors": "Tom Beucler, Michael Pritchard, Pierre Gentine, Stephan Rasp", "title": "Towards Physically-consistent, Data-driven Models of Convection", "comments": "Accepted for oral presentation at the 2020 IEEE International\n  Geoscience and Remote Sensing Symposium (IGARSS) 5 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven algorithms, in particular neural networks, can emulate the effect\nof sub-grid scale processes in coarse-resolution climate models if trained on\nhigh-resolution climate simulations. However, they may violate key physical\nconstraints and lack the ability to generalize outside of their training set.\nHere, we show that physical constraints can be enforced in neural networks,\neither approximately by adapting the loss function or to within machine\nprecision by adapting the architecture. As these physical constraints are\ninsufficient to guarantee generalizability, we additionally propose to\nphysically rescale the training and validation data to improve the ability of\nneural networks to generalize to unseen climates.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:48:10 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 00:03:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Beucler", "Tom", ""], ["Pritchard", "Michael", ""], ["Gentine", "Pierre", ""], ["Rasp", "Stephan", ""]]}, {"id": "2002.08526", "submitter": "David Eriksson", "authors": "David Eriksson and Matthias Poloczek", "title": "Scalable Constrained Bayesian Optimization", "comments": "To appear in Proceedings of AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global optimization of a high-dimensional black-box function under\nblack-box constraints is a pervasive task in machine learning, control, and\nengineering. These problems are challenging since the feasible set is typically\nnon-convex and hard to find, in addition to the curses of dimensionality and\nthe heterogeneity of the underlying functions. In particular, these\ncharacteristics dramatically impact the performance of Bayesian optimization\nmethods, that otherwise have become the de facto standard for sample-efficient\noptimization in unconstrained settings, leaving practitioners with evolutionary\nstrategies or heuristics. We propose the scalable constrained Bayesian\noptimization (SCBO) algorithm that overcomes the above challenges and pushes\nthe applicability of Bayesian optimization far beyond the state-of-the-art. A\ncomprehensive experimental evaluation demonstrates that SCBO achieves excellent\nresults on a variety of benchmarks. To this end, we propose two new control\nproblems that we expect to be of independent value for the scientific\ncommunity.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:48:46 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 20:58:24 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 16:05:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Eriksson", "David", ""], ["Poloczek", "Matthias", ""]]}, {"id": "2002.08527", "submitter": "Aritran Piplai", "authors": "Aritran Piplai, Sai Sree Laya Chukkapalli, Anupam Joshi", "title": "NAttack! Adversarial Attacks to bypass a GAN based classifier trained to\n  detect Network intrusion", "comments": "6 pages, 2 figures. 6th IEEE International Conference on Big Data\n  Security on Cloud (BigDataSecurity 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent developments in artificial intelligence and machine learning,\nanomalies in network traffic can be detected using machine learning approaches.\nBefore the rise of machine learning, network anomalies which could imply an\nattack, were detected using well-crafted rules. An attacker who has knowledge\nin the field of cyber-defence could make educated guesses to sometimes\naccurately predict which particular features of network traffic data the\ncyber-defence mechanism is looking at. With this information, the attacker can\ncircumvent a rule-based cyber-defense system. However, after the advancements\nof machine learning for network anomaly, it is not easy for a human to\nunderstand how to bypass a cyber-defence system. Recently, adversarial attacks\nhave become increasingly common to defeat machine learning algorithms. In this\npaper, we show that even if we build a classifier and train it with adversarial\nexamples for network data, we can use adversarial attacks and successfully\nbreak the system. We propose a Generative Adversarial Network(GAN)based\nalgorithm to generate data to train an efficient neural network based\nclassifier, and we subsequently break the system using adversarial attacks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:54:45 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piplai", "Aritran", ""], ["Chukkapalli", "Sai Sree Laya", ""], ["Joshi", "Anupam", ""]]}, {"id": "2002.08528", "submitter": "Ilqar Ramazanli", "authors": "Ilqar Ramazanli, Han Nguyen, Hai Pham, Sashank J. Reddi, Barnabas\n  Poczos", "title": "Adaptive Sampling Distributed Stochastic Variance Reduced Gradient for\n  Heterogeneous Distributed Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed optimization algorithms for minimizing the average of\n\\emph{heterogeneous} functions distributed across several machines with a focus\non communication efficiency. In such settings, naively using the classical\nstochastic gradient descent (SGD) or its variants (e.g., SVRG) with a uniform\nsampling of machines typically yields poor performance. It often leads to the\ndependence of convergence rate on maximum Lipschitz constant of gradients\nacross the devices. In this paper, we propose a novel \\emph{adaptive} sampling\nof machines specially catered to these settings. Our method relies on an\nadaptive estimate of local Lipschitz constants base on the information of past\ngradients. We show that the new way improves the dependence of convergence rate\nfrom maximum Lipschitz constant to \\emph{average} Lipschitz constant across\nmachines, thereby, significantly accelerating the convergence. Our experiments\ndemonstrate that our method indeed speeds up the convergence of the standard\nSVRG algorithm in heterogeneous environments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:55:52 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 20:01:23 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 05:00:16 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ramazanli", "Ilqar", ""], ["Nguyen", "Han", ""], ["Pham", "Hai", ""], ["Reddi", "Sashank J.", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2002.08536", "submitter": "Kohei Yata", "authors": "Yusuke Narita, Shota Yasui, Kohei Yata", "title": "Off-policy Bandit and Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for predicting the performance of reinforcement learning\nand bandit algorithms, given historical data that may have been generated by a\ndifferent algorithm. Our estimator has the property that its prediction\nconverges in probability to the true performance of a counterfactual algorithm\nat the fast $\\sqrt{N}$ rate, as the sample size $N$ increases. We also show a\ncorrect way to estimate the variance of our prediction, thus allowing the\nanalyst to quantify the uncertainty in the prediction. These properties hold\neven when the analyst does not know which among a large number of potentially\nimportant state variables are really important. These theoretical guarantees\nmake our estimator safe to use. We finally apply it to improve advertisement\ndesign by a major advertisement company. We find that our method produces\nsmaller mean squared errors than state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:30:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:44:37 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Narita", "Yusuke", ""], ["Yasui", "Shota", ""], ["Yata", "Kohei", ""]]}, {"id": "2002.08537", "submitter": "Tao Sun", "authors": "Tao Sun, Han Shen, Tianyi Chen, Dongsheng Li", "title": "Adaptive Temporal Difference Learning with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper revisits the celebrated temporal difference (TD) learning\nalgorithm for the policy evaluation in reinforcement learning. Typically, the\nperformance of the plain-vanilla TD algorithm is sensitive to the choice of\nstepsizes. Oftentimes, TD suffers from slow convergence. Motivated by the tight\nconnection between the TD learning algorithm and the stochastic gradient\nmethods, we develop the first adaptive variant of the TD learning algorithm\nwith linear function approximation that we term AdaTD. In contrast to the\noriginal TD, AdaTD is robust or less sensitive to the choice of stepsizes.\nAnalytically, we establish that to reach an $\\epsilon$ accuracy, the number of\niterations needed is\n$\\tilde{O}(\\epsilon^2\\ln^4\\frac{1}{\\epsilon}/\\ln^4\\frac{1}{\\rho})$, where\n$\\rho$ represents the speed of the underlying Markov chain converges to the\nstationary distribution. This implies that the iteration complexity of AdaTD is\nno worse than that of TD in the worst case. Going beyond TD, we further develop\nan adaptive variant of TD($\\lambda$), which is referred to as AdaTD($\\lambda$).\nWe evaluate the empirical performance of AdaTD and AdaTD($\\lambda$) on several\nstandard reinforcement learning tasks in OpenAI Gym on both linear and\nnonlinear function approximation, which demonstrate the effectiveness of our\nnew approaches over existing ones.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:32:40 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Sun", "Tao", ""], ["Shen", "Han", ""], ["Chen", "Tianyi", ""], ["Li", "Dongsheng", ""]]}, {"id": "2002.08538", "submitter": "Yahya Sattar", "authors": "Yahya Sattar and Samet Oymak", "title": "Non-asymptotic and Accurate Learning of Nonlinear Dynamical Systems", "comments": null, "journal-ref": "arXiv preprint:2002.08538, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning stabilizable systems governed by\nnonlinear state equation $h_{t+1}=\\phi(h_t,u_t;\\theta)+w_t$. Here $\\theta$ is\nthe unknown system dynamics, $h_t $ is the state, $u_t$ is the input and $w_t$\nis the additive noise vector. We study gradient based algorithms to learn the\nsystem dynamics $\\theta$ from samples obtained from a single finite trajectory.\nIf the system is run by a stabilizing input policy, we show that\ntemporally-dependent samples can be approximated by i.i.d. samples via a\ntruncation argument by using mixing-time arguments. We then develop new\nguarantees for the uniform convergence of the gradients of empirical loss.\nUnlike existing work, our bounds are noise sensitive which allows for learning\nground-truth dynamics with high accuracy and small sample complexity. Together,\nour results facilitate efficient learning of the general nonlinear system under\nstabilizing policy. We specialize our guarantees to entry-wise nonlinear\nactivations and verify our theory in various numerical experiments\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:36:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sattar", "Yahya", ""], ["Oymak", "Samet", ""]]}, {"id": "2002.08541", "submitter": "Zhiyue Zhang", "authors": "Zhiyue Zhang, Kenneth Lange, Jason Xu", "title": "Simple and Scalable Sparse k-means Clustering via Feature Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering, a fundamental activity in unsupervised learning, is notoriously\ndifficult when the feature space is high-dimensional. Fortunately, in many\nrealistic scenarios, only a handful of features are relevant in distinguishing\nclusters. This has motivated the development of sparse clustering techniques\nthat typically rely on k-means within outer algorithms of high computational\ncomplexity. Current techniques also require careful tuning of shrinkage\nparameters, further limiting their scalability. In this paper, we propose a\nnovel framework for sparse k-means clustering that is intuitive, simple to\nimplement, and competitive with state-of-the-art algorithms. We show that our\nalgorithm enjoys consistency and convergence guarantees. Our core method\nreadily generalizes to several task-specific algorithms such as clustering on\nsubsets of attributes and in partially observed data settings. We showcase\nthese contributions thoroughly via simulated experiments and real data\nbenchmarks, including a case study on protein expression in trisomic mice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 02:41:02 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 11:28:41 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Zhang", "Zhiyue", ""], ["Lange", "Kenneth", ""], ["Xu", "Jason", ""]]}, {"id": "2002.08546", "submitter": "Jian Liang", "authors": "Jian Liang, Dapeng Hu, and Jiashi Feng", "title": "Do We Really Need to Access the Source Data? Source Hypothesis Transfer\n  for Unsupervised Domain Adaptation", "comments": "ICML2020. Fix the typos for Digits. Code is available at\n  https://github.com/tim-learn/SHOT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims to leverage the knowledge learned\nfrom a labeled source dataset to solve similar tasks in a new unlabeled domain.\nPrior UDA methods typically require to access the source data when learning to\nadapt the model, making them risky and inefficient for decentralized private\ndata. This work tackles a practical setting where only a trained source model\nis available and investigates how we can effectively utilize such a model\nwithout source data to solve UDA problems. We propose a simple yet generic\nrepresentation learning framework, named \\emph{Source HypOthesis Transfer}\n(SHOT). SHOT freezes the classifier module (hypothesis) of the source model and\nlearns the target-specific feature extraction module by exploiting both\ninformation maximization and self-supervised pseudo-labeling to implicitly\nalign representations from the target domains to the source hypothesis. To\nverify its versatility, we evaluate SHOT in a variety of adaptation cases\nincluding closed-set, partial-set, and open-set domain adaptation. Experiments\nindicate that SHOT yields state-of-the-art results among multiple domain\nadaptation benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:13:58 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 17:31:59 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 17:03:14 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 09:48:24 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 03:22:32 GMT"}, {"version": "v6", "created": "Tue, 1 Jun 2021 09:06:00 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Liang", "Jian", ""], ["Hu", "Dapeng", ""], ["Feng", "Jiashi", ""]]}, {"id": "2002.08550", "submitter": "Sehoon Ha", "authors": "Sehoon Ha, Peng Xu, Zhenyu Tan, Sergey Levine, Jie Tan", "title": "Learning to Walk in the Real World with Minimal Human Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable and stable locomotion has been one of the most fundamental\nchallenges for legged robots. Deep reinforcement learning (deep RL) has emerged\nas a promising method for developing such control policies autonomously. In\nthis paper, we develop a system for learning legged locomotion policies with\ndeep RL in the real world with minimal human effort. The key difficulties for\non-robot learning systems are automatic data collection and safety. We overcome\nthese two challenges by developing a multi-task learning procedure and a\nsafety-constrained RL framework. We tested our system on the task of learning\nto walk on three different terrains: flat ground, a soft mattress, and a\ndoormat with crevices. Our system can automatically and efficiently learn\nlocomotion skills on a Minitaur robot with little human intervention. The\nsupplemental video can be found at: \\url{https://youtu.be/cwyiq6dCgOc}.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:36:39 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 18:35:02 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 05:46:51 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Ha", "Sehoon", ""], ["Xu", "Peng", ""], ["Tan", "Zhenyu", ""], ["Levine", "Sergey", ""], ["Tan", "Jie", ""]]}, {"id": "2002.08562", "submitter": "Dianbo Liu Dr", "authors": "Dianbo Liu, Tim Miller", "title": "Federated pretraining and fine tuning of BERT using clinical notes from\n  multiple silos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale contextual representation models, such as BERT, have\nsignificantly advanced natural language processing (NLP) in recently years.\nHowever, in certain area like healthcare, accessing diverse large scale text\ndata from multiple institutions is extremely challenging due to privacy and\nregulatory reasons. In this article, we show that it is possible to both\npretrain and fine tune BERT models in a federated manner using clinical texts\nfrom different silos without moving the data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:14:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Liu", "Dianbo", ""], ["Miller", "Tim", ""]]}, {"id": "2002.08563", "submitter": "Elliott Gordon-Rodriguez", "authors": "Elliott Gordon-Rodriguez, Gabriel Loaiza-Ganem, John P. Cunningham", "title": "The continuous categorical: a novel simplex-valued exponential family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simplex-valued data appear throughout statistics and machine learning, for\nexample in the context of transfer learning and compression of deep networks.\nExisting models for this class of data rely on the Dirichlet distribution or\nother related loss functions; here we show these standard choices suffer\nsystematically from a number of limitations, including bias and numerical\nissues that frustrate the use of flexible network models upstream of these\ndistributions. We resolve these limitations by introducing a novel exponential\nfamily of distributions for modeling simplex-valued data - the continuous\ncategorical, which arises as a nontrivial multivariate generalization of the\nrecently discovered continuous Bernoulli. Unlike the Dirichlet and other\ntypical choices, the continuous categorical results in a well-behaved\nprobabilistic loss function that produces unbiased estimators, while preserving\nthe mathematical simplicity of the Dirichlet. As well as exploring its\ntheoretical properties, we introduce sampling methods for this distribution\nthat are amenable to the reparameterization trick, and evaluate their\nperformance. Lastly, we demonstrate that the continuous categorical outperforms\nstandard choices empirically, across a simulation study, an applied example on\nmulti-party elections, and a neural network compression task.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:28:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 17:13:08 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Gordon-Rodriguez", "Elliott", ""], ["Loaiza-Ganem", "Gabriel", ""], ["Cunningham", "John P.", ""]]}, {"id": "2002.08567", "submitter": "Md. Shirajum Munir", "authors": "Md. Shirajum Munir, Nguyen H. Tran, Walid Saad, Choong Seon Hong", "title": "Multi-Agent Meta-Reinforcement Learning for Self-Powered and Sustainable\n  Edge Computing Systems", "comments": "Accepted article by IEEE Transactions on Network and Service\n  Management, DOI: 10.1109/TNSM.2021.3057960. Copyright 2021 IEEE", "journal-ref": null, "doi": "10.1109/TNSM.2021.3057960", "report-no": null, "categories": "cs.LG cs.MA eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The stringent requirements of mobile edge computing (MEC) applications and\nfunctions fathom the high capacity and dense deployment of MEC hosts to the\nupcoming wireless networks. However, operating such high capacity MEC hosts can\nsignificantly increase energy consumption. Thus, a base station (BS) unit can\nact as a self-powered BS. In this paper, an effective energy dispatch mechanism\nfor self-powered wireless networks with edge computing capabilities is studied.\nFirst, a two-stage linear stochastic programming problem is formulated with the\ngoal of minimizing the total energy consumption cost of the system while\nfulfilling the energy demand. Second, a semi-distributed data-driven solution\nis proposed by developing a novel multi-agent meta-reinforcement learning\n(MAMRL) framework to solve the formulated problem. In particular, each BS plays\nthe role of a local agent that explores a Markovian behavior for both energy\nconsumption and generation while each BS transfers time-varying features to a\nmeta-agent. Sequentially, the meta-agent optimizes (i.e., exploits) the energy\ndispatch decision by accepting only the observations from each local agent with\nits own state information. Meanwhile, each BS agent estimates its own energy\ndispatch policy by applying the learned parameters from meta-agent. Finally,\nthe proposed MAMRL framework is benchmarked by analyzing deterministic,\nasymmetric, and stochastic environments in terms of non-renewable energy\nusages, energy cost, and accuracy. Experimental results show that the proposed\nMAMRL model can reduce up to 11% non-renewable energy usage and by 22.4% the\nenergy cost (with 95.8% prediction accuracy), compared to other baseline\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 04:58:07 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 07:10:35 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 02:47:56 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Munir", "Md. Shirajum", ""], ["Tran", "Nguyen H.", ""], ["Saad", "Walid", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2002.08569", "submitter": "Shangwei Guo", "authors": "Shangwei Guo, Tianwei Zhang, Xiaofei Xie, Lei Ma, Tao Xiang, and Yang\n  Liu", "title": "Towards Byzantine-resilient Learning in Decentralized Systems", "comments": "We would like to extensively revise the paper and submit it to a\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of IoT and edge computing, decentralized learning is\nbecoming more promising. When designing a distributed learning system, one\nmajor challenge to consider is Byzantine Fault Tolerance (BFT). Past works have\nresearched Byzantine-resilient solutions for centralized distributed learning.\nHowever, there are currently no satisfactory solutions with strong efficiency\nand security in decentralized systems. In this paper, we propose a novel\nalgorithm, Mozi, to achieve BFT in decentralized learning systems.\nSpecifically, Mozi provides a uniform Byzantine-resilient aggregation rule for\nbenign nodes to select the useful parameter updates and filter out the\nmalicious ones in each training iteration. It guarantees that each benign node\nin a decentralized system can train a correct model under very strong Byzantine\nattacks with an arbitrary number of faulty nodes. We perform the theoretical\nanalysis to prove the uniform convergence of our proposed algorithm.\nExperimental evaluations demonstrate the high security and efficiency of Mozi\ncompared to all existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:11:04 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 03:44:43 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 05:12:04 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Guo", "Shangwei", ""], ["Zhang", "Tianwei", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Xiang", "Tao", ""], ["Liu", "Yang", ""]]}, {"id": "2002.08570", "submitter": "Yilin Kang", "authors": "Yilin Kang, Yong Liu, Ben Niu, Xinyi Tong, Likun Zhang and Weiping\n  Wang", "title": "Input Perturbation: A New Paradigm between Central and Local\n  Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, there are two models on differential privacy: the central\nmodel and the local model. The central model focuses on the machine learning\nmodel and the local model focuses on the training data. In this paper, we study\nthe \\textit{input perturbation} method in differentially private empirical risk\nminimization (DP-ERM), preserving privacy of the central model. By adding noise\nto the original training data and training with the `perturbed data', we\nachieve ($\\epsilon$,$\\delta$)-differential privacy on the final model, along\nwith some kind of privacy on the original data. We observe that there is an\ninteresting connection between the local model and the central model: the\nperturbation on the original data causes the perturbation on the gradient, and\nfinally the model parameters. This observation means that our method builds a\nbridge between local and central model, protecting the data, the gradient and\nthe model simultaneously, which is more superior than previous central methods.\nDetailed theoretical analysis and experiments show that our method achieves\nalmost the same (or even better) performance as some of the best previous\ncentral methods with more protections on privacy, which is an attractive\nresult. Moreover, we extend our method to a more general case: the loss\nfunction satisfies the Polyak-Lojasiewicz condition, which is more general than\nstrong convexity, the constraint on the loss function in most previous work.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:20:02 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kang", "Yilin", ""], ["Liu", "Yong", ""], ["Niu", "Ben", ""], ["Tong", "Xinyi", ""], ["Zhang", "Likun", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.08575", "submitter": "Yuanyuan Jin", "authors": "Yuanyuan Jin, Wei Zhang, Xiangnan He, Xinyu Wang and Xiaoling Wang", "title": "Syndrome-aware Herb Recommendation with Multi-Graph Convolution Network", "comments": "Accepted by ICDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herb recommendation plays a crucial role in the therapeutic process of\nTraditional Chinese Medicine(TCM), which aims to recommend a set of herbs to\ntreat the symptoms of a patient. While several machine learning methods have\nbeen developed for herb recommendation, they are limited in modeling only the\ninteractions between herbs and symptoms, and ignoring the intermediate process\nof syndrome induction. When performing TCM diagnostics, an experienced doctor\ntypically induces syndromes from the patient's symptoms and then suggests herbs\nbased on the induced syndromes. As such, we believe the induction of syndromes,\nan overall description of the symptoms, is important for herb recommendation\nand should be properly handled. However, due to the ambiguity and complexity of\nsyndrome induction, most prescriptions lack the explicit ground truth of\nsyndromes. In this paper, we propose a new method that takes the implicit\nsyndrome induction process into account for herb recommendation. Given a set of\nsymptoms to treat, we aim to generate an overall syndrome representation by\neffectively fusing the embeddings of all the symptoms in the set, to mimic how\na doctor induces the syndromes. Towards symptom embedding learning, we\nadditionally construct a symptom-symptom graph from the input prescriptions for\ncapturing the relations between symptoms; we then build graph convolution\nnetworks(GCNs) on both symptom-symptom and symptom-herb graphs to learn symptom\nembedding. Similarly, we construct a herb-herb graph and build GCNs on both\nherb-herb and symptom-herb graphs to learn herb embedding, which is finally\ninteracted with the syndrome representation to predict the scores of herbs. In\nthis way, more comprehensive representations can be obtained. We conduct\nextensive experiments on a public TCM dataset, showing significant improvements\nover state-of-the-art herb recommendation methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 05:56:53 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jin", "Yuanyuan", ""], ["Zhang", "Wei", ""], ["He", "Xiangnan", ""], ["Wang", "Xinyu", ""], ["Wang", "Xiaoling", ""]]}, {"id": "2002.08578", "submitter": "Yilin Kang", "authors": "Yilin Kang, Yong Liu, Lizhong Ding, Xinwang Liu, Xinyi Tong and\n  Weiping Wang", "title": "Differentially Private ERM Based on Data Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, after observing that different training data instances affect\nthe machine learning model to different extents, we attempt to improve the\nperformance of differentially private empirical risk minimization (DP-ERM) from\na new perspective. Specifically, we measure the contributions of various\ntraining data instances on the final machine learning model, and select some of\nthem to add random noise. Considering that the key of our method is to measure\neach data instance separately, we propose a new `Data perturbation' based (DB)\nparadigm for DP-ERM: adding random noise to the original training data and\nachieving ($\\epsilon,\\delta$)-differential privacy on the final machine\nlearning model, along with the preservation on the original data. By\nintroducing the Influence Function (IF), we quantitatively measure the impact\nof the training data on the final model. Theoretical and experimental results\nshow that our proposed DBDP-ERM paradigm enhances the model performance\nsignificantly.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 06:05:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kang", "Yilin", ""], ["Liu", "Yong", ""], ["Ding", "Lizhong", ""], ["Liu", "Xinwang", ""], ["Tong", "Xinyi", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.08583", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha and Aditya Gopalan", "title": "Regret Minimization in Stochastic Contextual Dueling Bandits", "comments": "Wrong result with incremental contribution, major revision required", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of stochastic $K$-armed dueling bandit in the\ncontextual setting, where at each round the learner is presented with a context\nset of $K$ items, each represented by a $d$-dimensional feature vector, and the\ngoal of the learner is to identify the best arm of each context sets. However,\nunlike the classical contextual bandit setup, our framework only allows the\nlearner to receive item feedback in terms of their (noisy) pariwise\npreferences--famously studied as dueling bandits which is practical interests\nin various online decision making scenarios, e.g. recommender systems,\ninformation retrieval, tournament ranking, where it is easier to elicit the\nrelative strength of the items instead of their absolute scores. However, to\nthe best of our knowledge this work is the first to consider the problem of\nregret minimization of contextual dueling bandits for potentially infinite\ndecision spaces and gives provably optimal algorithms along with a matching\nlower bound analysis. We present two algorithms for the setup with respective\nregret guarantees $\\tilde O(d\\sqrt{T})$ and $\\tilde O(\\sqrt{dT \\log K})$.\nSubsequently we also show that $\\Omega(\\sqrt {dT})$ is actually the fundamental\nperformance limit for this problem, implying the optimality of our second\nalgorithm. However the analysis of our first algorithm is comparatively\nsimpler, and it is often shown to outperform the former empirically. Finally,\nwe corroborate all the theoretical results with suitable experiments.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 06:36:19 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 00:21:15 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gopalan", "Aditya", ""]]}, {"id": "2002.08595", "submitter": "Yingtao Tian", "authors": "Yingtao Tian, Chikahiko Suzuki, Tarin Clanuwat, Mikel Bober-Irizar,\n  Alex Lamb, Asanobu Kitamoto", "title": "KaoKore: A Pre-modern Japanese Art Facial Expression Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From classifying handwritten digits to generating strings of text, the\ndatasets which have received long-time focus from the machine learning\ncommunity vary greatly in their subject matter. This has motivated a renewed\ninterest in building datasets which are socially and culturally relevant, so\nthat algorithmic research may have a more direct and immediate impact on\nsociety. One such area is in history and the humanities, where better and\nrelevant machine learning models can accelerate research across various fields.\nTo this end, newly released benchmarks and models have been proposed for\ntranscribing historical Japanese cursive writing, yet for the field as a whole\nusing machine learning for historical Japanese artworks still remains largely\nuncharted. To bridge this gap, in this work we propose a new dataset KaoKore\nwhich consists of faces extracted from pre-modern Japanese artwork. We\ndemonstrate its value as both a dataset for image classification as well as a\ncreative and artistic dataset, which we explore using generative models.\nDataset available at https://github.com/rois-codh/kaokore\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:22:13 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Tian", "Yingtao", ""], ["Suzuki", "Chikahiko", ""], ["Clanuwat", "Tarin", ""], ["Bober-Irizar", "Mikel", ""], ["Lamb", "Alex", ""], ["Kitamoto", "Asanobu", ""]]}, {"id": "2002.08596", "submitter": "Primoz Kocbek", "authors": "Gregor Stiglic, Primoz Kocbek, Nino Fijacko, Marinka Zitnik, Katrien\n  Verbert, Leona Cilar", "title": "Interpretability of machine learning based prediction models in\n  healthcare", "comments": "12 pages, 2 figures, published in Wiley Interdisciplinary Reviews:\n  Data Mining and Knowledge Discovery", "journal-ref": "WIREs Data Mining Knowl Discov (2020)", "doi": "10.1002/widm.1379", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a need of ensuring machine learning models that are interpretable.\nHigher interpretability of the model means easier comprehension and explanation\nof future predictions for end-users. Further, interpretable machine learning\nmodels allow healthcare experts to make reasonable and data-driven decisions to\nprovide personalized decisions that can ultimately lead to higher quality of\nservice in healthcare. Generally, we can classify interpretability approaches\nin two groups where the first focuses on personalized interpretation (local\ninterpretability) while the second summarizes prediction models on a population\nlevel (global interpretability). Alternatively, we can group interpretability\nmethods into model-specific techniques, which are designed to interpret\npredictions generated by a specific model, such as a neural network, and\nmodel-agnostic approaches, which provide easy-to-understand explanations of\npredictions made by any machine learning model. Here, we give an overview of\ninterpretability approaches and provide examples of practical interpretability\nof machine learning in different areas of healthcare, including prediction of\nhealth-related outcomes, optimizing treatments or improving the efficiency of\nscreening for specific conditions. Further, we outline future directions for\ninterpretable machine learning and highlight the importance of developing\nalgorithmic solutions that can enable machine-learning driven decision making\nin high-stakes healthcare problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:23:22 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 06:36:06 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Stiglic", "Gregor", ""], ["Kocbek", "Primoz", ""], ["Fijacko", "Nino", ""], ["Zitnik", "Marinka", ""], ["Verbert", "Katrien", ""], ["Cilar", "Leona", ""]]}, {"id": "2002.08599", "submitter": "Haggai Maron", "authors": "Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya", "title": "On Learning Sets of Symmetric Elements", "comments": "37th International Conference on Machine Learning, Vienna,2020,\n  Outstanding paper award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from unordered sets is a fundamental learning setup, recently\nattracting increasing attention. Research in this area has focused on the case\nwhere elements of the set are represented by feature vectors, and far less\nemphasis has been given to the common case where set elements themselves adhere\nto their own symmetries. That case is relevant to numerous applications, from\ndeblurring image bursts to multi-view 3D shape recognition and reconstruction.\nIn this paper, we present a principled approach to learning sets of general\nsymmetric elements. We first characterize the space of linear layers that are\nequivariant both to element reordering and to the inherent symmetries of\nelements, like translation in the case of images. We further show that networks\nthat are composed of these layers, called Deep Sets for Symmetric Elements\n(DSS) layers, are universal approximators of both invariant and equivariant\nfunctions, and that these networks are strictly more expressive than Siamese\nnetworks. DSS layers are also straightforward to implement. Finally, we show\nthat they improve over existing set-learning architectures in a series of\nexperiments with images, graphs, and point-clouds.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:29:20 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 06:15:15 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 09:28:48 GMT"}, {"version": "v4", "created": "Sun, 29 Nov 2020 07:34:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Maron", "Haggai", ""], ["Litany", "Or", ""], ["Chechik", "Gal", ""], ["Fetaya", "Ethan", ""]]}, {"id": "2002.08605", "submitter": "Harikrishna Narasimhan", "authors": "Qijia Jiang, Olaoluwa Adigun, Harikrishna Narasimhan, Mahdi Milani\n  Fard, Maya Gupta", "title": "Optimizing Black-box Metrics with Adaptive Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of training models with black-box and hard-to-optimize\nmetrics by expressing the metric as a monotonic function of a small number of\neasy-to-optimize surrogates. We pose the training problem as an optimization\nover a relaxed surrogate space, which we solve by estimating local gradients\nfor the metric and performing inexact convex projections. We analyze gradient\nestimates based on finite differences and local linear interpolations, and show\nconvergence of our approach under smoothness assumptions with respect to the\nsurrogates. Experimental results on classification and ranking problems verify\nthe proposal performs on par with methods that know the mathematical\nformulation, and adds notable value when the form of the metric is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 07:52:08 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Jiang", "Qijia", ""], ["Adigun", "Olaoluwa", ""], ["Narasimhan", "Harikrishna", ""], ["Fard", "Mahdi Milani", ""], ["Gupta", "Maya", ""]]}, {"id": "2002.08614", "submitter": "Atsushi Fujita", "authors": "Raj Dabre, Raphael Rubino, Atsushi Fujita", "title": "Balancing Cost and Benefit with Tied-Multi Transformers", "comments": "Extended version of our previous manuscript available at\n  arXiv:1908.10118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We propose and evaluate a novel procedure for training multiple Transformers\nwith tied parameters which compresses multiple models into one enabling the\ndynamic choice of the number of encoder and decoder layers during decoding. In\nsequence-to-sequence modeling, typically, the output of the last layer of the\nN-layer encoder is fed to the M-layer decoder, and the output of the last\ndecoder layer is used to compute loss. Instead, our method computes a single\nloss consisting of NxM losses, where each loss is computed from the output of\none of the M decoder layers connected to one of the N encoder layers. Such a\nmodel subsumes NxM models with different number of encoder and decoder layers,\nand can be used for decoding with fewer than the maximum number of encoder and\ndecoder layers. We then propose a mechanism to choose a priori the number of\nencoder and decoder layers for faster decoding, and also explore recurrent\nstacking of layers and knowledge distillation for model compression. We present\na cost-benefit analysis of applying the proposed approaches for neural machine\ntranslation and show that they reduce decoding costs while preserving\ntranslation quality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:20:52 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Dabre", "Raj", ""], ["Rubino", "Raphael", ""], ["Fujita", "Atsushi", ""]]}, {"id": "2002.08616", "submitter": "Micha\\\"el Fanuel", "authors": "Micha\\\"el Fanuel and Joachim Schreurs and Johan A.K. Suykens", "title": "Diversity sampling is an implicit regularization for kernel methods", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": "20-21", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods have achieved very good performance on large scale regression\nand classification problems, by using the Nystr\\\"om method and preconditioning\ntechniques. The Nystr\\\"om approximation -- based on a subset of landmarks --\ngives a low rank approximation of the kernel matrix, and is known to provide a\nform of implicit regularization. We further elaborate on the impact of sampling\ndiverse landmarks for constructing the Nystr\\\"om approximation in supervised as\nwell as unsupervised kernel methods. By using Determinantal Point Processes for\nsampling, we obtain additional theoretical results concerning the interplay\nbetween diversity and regularization. Empirically, we demonstrate the\nadvantages of training kernel methods based on subsets made of diverse points.\nIn particular, if the dataset has a dense bulk and a sparser tail, we show that\nNystr\\\"om kernel regression with diverse landmarks increases the accuracy of\nthe regression in sparser regions of the dataset, with respect to a uniform\nlandmark sampling. A greedy heuristic is also proposed to select diverse\nsamples of significant size within large datasets when exact DPP sampling is\nnot practically feasible.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:24:42 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fanuel", "Micha\u00ebl", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2002.08619", "submitter": "Tianyu Pang", "authors": "Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Jun Zhu, Hang Su", "title": "Boosting Adversarial Training with Hypersphere Embedding", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) is one of the most effective defenses against\nadversarial attacks for deep learning models. In this work, we advocate\nincorporating the hypersphere embedding (HE) mechanism into the AT procedure by\nregularizing the features onto compact manifolds, which constitutes a\nlightweight yet effective module to blend in the strength of representation\nlearning. Our extensive analyses reveal that AT and HE are well coupled to\nbenefit the robustness of the adversarially trained models from several\naspects. We validate the effectiveness and adaptability of HE by embedding it\ninto the popular AT frameworks including PGD-AT, ALP, and TRADES, as well as\nthe FreeAT and FastAT strategies. In the experiments, we evaluate our methods\nunder a wide range of adversarial attacks on the CIFAR-10 and ImageNet\ndatasets, which verifies that integrating HE can consistently enhance the model\nrobustness for each AT framework with little extra computation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:42:29 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 13:27:17 GMT"}, {"version": "v3", "created": "Wed, 25 Nov 2020 16:18:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Pang", "Tianyu", ""], ["Yang", "Xiao", ""], ["Dong", "Yinpeng", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""], ["Su", "Hang", ""]]}, {"id": "2002.08621", "submitter": "Shangyuan Tong", "authors": "Shangyuan Tong, Timur Garipov, Tommi Jaakkola", "title": "The Benefits of Pairwise Discriminators for Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training methods typically align distributions by solving\ntwo-player games. However, in most current formulations, even if the generator\naligns perfectly with data, a sub-optimal discriminator can still drive the two\napart. Absent additional regularization, the instability can manifest itself as\na never-ending game. In this paper, we introduce a family of objectives by\nleveraging pairwise discriminators, and show that only the generator needs to\nconverge. The alignment, if achieved, would be preserved with any\ndiscriminator. We provide sufficient conditions for local convergence;\ncharacterize the capacity balance that should guide the discriminator and\ngenerator choices; and construct examples of minimally sufficient\ndiscriminators. Empirically, we illustrate the theory and the effectiveness of\nour approach on synthetic examples. Moreover, we show that practical methods\nderived from our approach can better generate higher-resolution images.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:43:59 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Tong", "Shangyuan", ""], ["Garipov", "Timur", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "2002.08641", "submitter": "Tanya Motwani", "authors": "Tanya Motwani and Manojkumar Parmar", "title": "A Novel Framework for Selection of GANs for an Application", "comments": "11 pages, 1 figure, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a current focal point of research.\nThe body of knowledge is fragmented, leading to a trial-error method while\nselecting an appropriate GAN for a given scenario. We provide a comprehensive\nsummary of the evolution of GANs starting from its inception addressing issues\nlike mode collapse, vanishing gradient, unstable training and non-convergence.\nWe also provide a comparison of various GANs from the application point of\nview, its behaviour and implementation details. We propose a novel framework to\nidentify candidate GANs for a specific use case based on architecture, loss,\nregularization and divergence. We also discuss application of the framework\nusing an example, and we demonstrate a significant reduction in search space.\nThis efficient way to determine potential GANs lowers unit economics of AI\ndevelopment for organizations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:51:48 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 09:48:42 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Motwani", "Tanya", ""], ["Parmar", "Manojkumar", ""]]}, {"id": "2002.08643", "submitter": "Hongyuan Zhang", "authors": "Hongyuan Zhang and Rui Zhang and Xuelong Li", "title": "Embedding Graph Auto-Encoder for Graph Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering, aiming to partition nodes of a graph into various groups\nvia an unsupervised approach, is an attractive topic in recent years. To\nimprove the representative ability, several graph auto-encoder (GAE) models,\nwhich are based on semi-supervised graph convolution networks (GCN), have been\ndeveloped and they achieve good results compared with traditional clustering\nmethods. However, all existing methods either fail to utilize the orthogonal\nproperty of the representations generated by GAE, or separate the clustering\nand the learning of neural networks. We first prove that the relaxed k-means\nwill obtain an optimal partition in the inner-products used space. Driven by\ntheoretical analysis about relaxed k-means, we design a specific GAE-based\nmodel for graph clustering to be consistent with the theory, namely Embedding\nGraph Auto-Encoder (EGAE). Meanwhile, the learned representations are well\nexplainable such that the representations can be also used for other tasks. To\nfurther induce the neural network to produce deep features that are appropriate\nfor the specific clustering model, the relaxed k-means and GAE are learned\nsimultaneously. Therefore, the relaxed k-means can be equivalently regarded as\na decoder that attempts to learn representations that can be linearly\nconstructed by some centroid vectors. Accordingly, EGAE consists of one encoder\nand dual decoders. Extensive experiments are conducted to prove the superiority\nof EGAE and the corresponding theoretical analyses.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:53:28 GMT"}, {"version": "v2", "created": "Sat, 13 Mar 2021 08:07:29 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhang", "Hongyuan", ""], ["Zhang", "Rui", ""], ["Li", "Xuelong", ""]]}, {"id": "2002.08645", "submitter": "Alberto Tonda", "authors": "Pietro Barbiero, Giovanni Squillero, Alberto Tonda", "title": "Uncovering Coresets for Classification With Multi-Objective Evolutionary\n  Algorithms", "comments": "9 pages, 3 figures, conference. Submitted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A coreset is a subset of the training set, using which a machine learning\nalgorithm obtains performances similar to what it would deliver if trained over\nthe whole original data. Coreset discovery is an active and open line of\nresearch as it allows improving training speed for the algorithms and may help\nhuman understanding the results. Building on previous works, a novel approach\nis presented: candidate corsets are iteratively optimized, adding and removing\nsamples. As there is an obvious trade-off between limiting training size and\nquality of the results, a multi-objective evolutionary algorithm is used to\nminimize simultaneously the number of points in the set and the classification\nerror. Experimental results on non-trivial benchmarks show that the proposed\napproach is able to deliver results that allow a classifier to obtain lower\nerror and better ability of generalizing on unseen data than state-of-the-art\ncoreset discovery techniques.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:59:56 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Barbiero", "Pietro", ""], ["Squillero", "Giovanni", ""], ["Tonda", "Alberto", ""]]}, {"id": "2002.08648", "submitter": "Hongyuan Zhang", "authors": "Xuelong Li and Hongyuan Zhang and Rui Zhang", "title": "Adaptive Graph Auto-Encoder for General Data Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based clustering plays an important role in the clustering area. Recent\nstudies about graph convolution neural networks have achieved impressive\nsuccess on graph type data. However, in general clustering tasks, the graph\nstructure of data does not exist such that the strategy to construct a graph is\ncrucial for performance. Therefore, how to extend graph convolution networks\ninto general clustering tasks is an attractive problem. In this paper, we\npropose a graph auto-encoder for general data clustering, which constructs the\ngraph adaptively according to the generative perspective of graphs. The\nadaptive process is designed to induce the model to exploit the high-level\ninformation behind data and utilize the non-Euclidean structure sufficiently.\nWe further design a novel mechanism with rigorous analysis to avoid the\ncollapse caused by the adaptive construction. Via combining the generative\nmodel for network embedding and graph-based clustering, a graph auto-encoder\nwith a novel decoder is developed such that it performs well in weighted graph\nused scenarios. Extensive experiments prove the superiority of our model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:11:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 10:32:50 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 06:25:09 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 04:56:50 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Li", "Xuelong", ""], ["Zhang", "Hongyuan", ""], ["Zhang", "Rui", ""]]}, {"id": "2002.08657", "submitter": "Yuki Koyama", "authors": "Yuki Koyama and Takeo Igarashi", "title": "Computational Design with Crowds", "comments": "This book chapter was originally published in Computational\n  Interaction edited by Antti Oulasvirta, Per Ola Kristensson, Xiaojun Bi, and\n  Andrew Howes", "journal-ref": "Computational Interaction (Antti Oulasvirta, Per Ola Kristensson,\n  Xiaojun Bi, and Andrew Howes (Eds.)), chapter 6, pages 153-184. Oxford\n  University Press, 2018", "doi": "10.1093/oso/9780198799603.001.0001", "report-no": null, "categories": "cs.GR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational design is aimed at supporting or automating design processes\nusing computational techniques. However, some classes of design tasks involve\ncriteria that are difficult to handle only with computers. For example, visual\ndesign tasks seeking to fulfill aesthetic goals are difficult to handle purely\nwith computers. One promising approach is to leverage human computation; that\nis, to incorporate human input into the computation process. Crowdsourcing\nplatforms provide a convenient way to integrate such human computation into a\nworking system.\n  In this chapter, we discuss such computational design with crowds in the\ndomain of parameter tweaking tasks in visual design. Parameter tweaking is\noften performed to maximize the aesthetic quality of designed objects.\nComputational design powered by crowds can solve this maximization problem by\nleveraging human computation. We discuss the opportunities and challenges of\ncomputational design with crowds with two illustrative examples: (1) estimating\nthe objective function (specifically, preference learning from crowds' pairwise\ncomparisons) to facilitate interactive design exploration by a designer and (2)\ndirectly searching for the optimal parameter setting that maximizes the\nobjective function (specifically, crowds-in-the-loop Bayesian optimization).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:40:13 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Koyama", "Yuki", ""], ["Igarashi", "Takeo", ""]]}, {"id": "2002.08663", "submitter": "Jonathan Scarlett", "authors": "Anamay Chaturvedi and Jonathan Scarlett", "title": "Learning Gaussian Graphical Models via Multiplicative Weights", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical model selection in Markov random fields is a fundamental problem in\nstatistics and machine learning. Two particularly prominent models, the Ising\nmodel and Gaussian model, have largely developed in parallel using different\n(though often related) techniques, and several practical algorithms with\nrigorous sample complexity bounds have been established for each. In this\npaper, we adapt a recently proposed algorithm of Klivans and Meka (FOCS, 2017),\nbased on the method of multiplicative weight updates, from the Ising model to\nthe Gaussian model, via non-trivial modifications to both the algorithm and its\nanalysis. The algorithm enjoys a sample complexity bound that is qualitatively\nsimilar to others in the literature, has a low runtime $O(mp^2)$ in the case of\n$m$ samples and $p$ nodes, and can trivially be implemented in an online\nmanner.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:50:58 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 03:07:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chaturvedi", "Anamay", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "2002.08665", "submitter": "Calin Cruceru", "authors": "Calin Cruceru, Gary B\\'ecigneul, Octavian-Eugen Ganea", "title": "Computationally Tractable Riemannian Manifolds for Graph Embeddings", "comments": "Submitted to the Thirty-fourth Conference on Neural Information\n  Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing graphs as sets of node embeddings in certain curved Riemannian\nmanifolds has recently gained momentum in machine learning due to their\ndesirable geometric inductive biases, e.g., hierarchical structures benefit\nfrom hyperbolic geometry. However, going beyond embedding spaces of constant\nsectional curvature, while potentially more representationally powerful, proves\nto be challenging as one can easily lose the appeal of computationally\ntractable tools such as geodesic distances or Riemannian gradients. Here, we\nexplore computationally efficient matrix manifolds, showcasing how to learn and\noptimize graph embeddings in these Riemannian spaces. Empirically, we\ndemonstrate consistent improvements over Euclidean geometry while often\noutperforming hyperbolic and elliptical embeddings based on various metrics\nthat capture different graph properties. Our results serve as new evidence for\nthe benefits of non-Euclidean embeddings in machine learning pipelines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 10:55:47 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 14:04:49 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Cruceru", "Calin", ""], ["B\u00e9cigneul", "Gary", ""], ["Ganea", "Octavian-Eugen", ""]]}, {"id": "2002.08675", "submitter": "You-Wei Luo", "authors": "You-Wei Luo, Chuan-Xian Ren, Pengfei Ge, Ke-Kun Huang, Yu-Feng Yu", "title": "Unsupervised Domain Adaptation via Discriminative Manifold Embedding and\n  Alignment", "comments": "Accepted to AAAI 2020. Code available:\n  \\<https://github.com/LavieLuo/DRMEA>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is effective in leveraging the rich\ninformation from the source domain to the unsupervised target domain. Though\ndeep learning and adversarial strategy make an important breakthrough in the\nadaptability of features, there are two issues to be further explored. First,\nthe hard-assigned pseudo labels on the target domain are risky to the intrinsic\ndata structure. Second, the batch-wise training manner in deep learning limits\nthe description of the global structure. In this paper, a Riemannian manifold\nlearning framework is proposed to achieve transferability and discriminability\nconsistently. As to the first problem, this method establishes a probabilistic\ndiscriminant criterion on the target domain via soft labels. Further, this\ncriterion is extended to a global approximation scheme for the second issue;\nsuch approximation is also memory-saving. The manifold metric alignment is\nexploited to be compatible with the embedding space. A theoretical error bound\nis derived to facilitate the alignment. Extensive experiments have been\nconducted to investigate the proposal and results of the comparison study\nmanifest the superiority of consistent manifold learning framework.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:06:41 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 16:36:53 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Luo", "You-Wei", ""], ["Ren", "Chuan-Xian", ""], ["Ge", "Pengfei", ""], ["Huang", "Ke-Kun", ""], ["Yu", "Yu-Feng", ""]]}, {"id": "2002.08676", "submitter": "Quentin Berthet", "authors": "Quentin Berthet, Mathieu Blondel, Olivier Teboul, Marco Cuturi,\n  Jean-Philippe Vert, Francis Bach", "title": "Learning with Differentiable Perturbed Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning pipelines often rely on optimization procedures to make\ndiscrete decisions (e.g., sorting, picking closest neighbors, or shortest\npaths). Although these discrete decisions are easily computed, they break the\nback-propagation of computational graphs. In order to expand the scope of\nlearning problems that can be solved in an end-to-end fashion, we propose a\nsystematic method to transform optimizers into operations that are\ndifferentiable and never locally constant. Our approach relies on\nstochastically perturbed optimizers, and can be used readily together with\nexisting solvers. Their derivatives can be evaluated efficiently, and\nsmoothness tuned via the chosen noise amplitude. We also show how this\nframework can be connected to a family of losses developed in structured\nprediction, and give theoretical guarantees for their use in learning tasks. We\ndemonstrate experimentally the performance of our approach on various tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:11:32 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 15:09:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Berthet", "Quentin", ""], ["Blondel", "Mathieu", ""], ["Teboul", "Olivier", ""], ["Cuturi", "Marco", ""], ["Vert", "Jean-Philippe", ""], ["Bach", "Francis", ""]]}, {"id": "2002.08681", "submitter": "Yabin Zhang", "authors": "Yabin Zhang, Bin Deng, Hui Tang, Lei Zhang, and Kui Jia", "title": "Unsupervised Multi-Class Domain Adaptation: Theory, Algorithms, and\n  Practice", "comments": "CVPR extension; TPAMI camera ready version:\n  https://ieeexplore.ieee.org/document/9253700; IEEE copyright; Codes are\n  available at: https://github.com/YBZh/MultiClassDA", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (TPAMI),10 November 2020", "doi": "10.1109/TPAMI.2020.3036956", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the formalism of unsupervised multi-class domain\nadaptation (multi-class UDA), which underlies a few recent algorithms whose\nlearning objectives are only motivated empirically. Multi-Class Scoring\nDisagreement (MCSD) divergence is presented by aggregating the absolute margin\nviolations in multi-class classification, and this proposed MCSD is able to\nfully characterize the relations between any pair of multi-class scoring\nhypotheses. By using MCSD as a measure of domain distance, we develop a new\ndomain adaptation bound for multi-class UDA; its data-dependent, probably\napproximately correct bound is also developed that naturally suggests\nadversarial learning objectives to align conditional feature distributions\nacross source and target domains. Consequently, an algorithmic framework of\nMulti-class Domain-adversarial learning Networks (McDalNets) is developed, and\nits different instantiations via surrogate learning objectives either coincide\nwith or resemble a few recently popular methods, thus (partially) underscoring\ntheir practical effectiveness. Based on our identical theory for multi-class\nUDA, we also introduce a new algorithm of Domain-Symmetric Networks (SymmNets),\nwhich is featured by a novel adversarial strategy of domain confusion and\ndiscrimination. SymmNets affords simple extensions that work equally well under\nthe problem settings of either closed set, partial, or open set UDA. We conduct\ncareful empirical studies to compare different algorithms of McDalNets and our\nnewly introduced SymmNets. Experiments verify our theoretical analysis and show\nthe efficacy of our proposed SymmNets. In addition, we have made our\nimplementation code publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:26:45 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 09:36:34 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Yabin", ""], ["Deng", "Bin", ""], ["Tang", "Hui", ""], ["Zhang", "Lei", ""], ["Jia", "Kui", ""]]}, {"id": "2002.08688", "submitter": "Jordi Pons", "authors": "Berkan Kadioglu, Michael Horgan, Xiaoyu Liu, Jordi Pons, Dan Darcy,\n  and Vivek Kumar", "title": "An empirical study of Conv-TasNet", "comments": "In proceedings of ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conv-TasNet is a recently proposed waveform-based deep neural network that\nachieves state-of-the-art performance in speech source separation. Its\narchitecture consists of a learnable encoder/decoder and a separator that\noperates on top of this learned space. Various improvements have been proposed\nto Conv-TasNet. However, they mostly focus on the separator, leaving its\nencoder/decoder as a (shallow) linear operator. In this paper, we conduct an\nempirical study of Conv-TasNet and propose an enhancement to the\nencoder/decoder that is based on a (deep) non-linear variant of it. In\naddition, we experiment with the larger and more diverse LibriTTS dataset and\ninvestigate the generalization capabilities of the studied models when trained\non a much larger dataset. We propose cross-dataset evaluation that includes\nassessing separations from the WSJ0-2mix, LibriTTS and VCTK databases. Our\nresults show that enhancements to the encoder/decoder can improve average\nSI-SNR performance by more than 1 dB. Furthermore, we offer insights into the\ngeneralization capabilities of Conv-TasNet and the potential value of\nimprovements to the encoder/decoder.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 11:51:43 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:00:22 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kadioglu", "Berkan", ""], ["Horgan", "Michael", ""], ["Liu", "Xiaoyu", ""], ["Pons", "Jordi", ""], ["Darcy", "Dan", ""], ["Kumar", "Vivek", ""]]}, {"id": "2002.08695", "submitter": "Quentin Berthet", "authors": "Marin Ballu, Quentin Berthet, Francis Bach", "title": "Stochastic Optimization for Regularized Wasserstein Estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal transport is a foundational problem in optimization, that allows to\ncompare probability distributions while taking into account geometric aspects.\nIts optimal objective value, the Wasserstein distance, provides an important\nloss between distributions that has been used in many applications throughout\nmachine learning and statistics. Recent algorithmic progress on this problem\nand its regularized versions have made these tools increasingly popular.\nHowever, existing techniques require solving an optimization problem to obtain\na single gradient of the loss, thus slowing down first-order methods to\nminimize the sum of losses, that require many such gradient computations. In\nthis work, we introduce an algorithm to solve a regularized version of this\nproblem of Wasserstein estimators, with a time per step which is sublinear in\nthe natural dimensions of the problem. We introduce a dual formulation, and\noptimize it with stochastic gradient steps that can be computed directly from\nsamples, without solving additional optimization problems at each step. Doing\nso, the estimation and computation tasks are performed jointly. We show that\nthis algorithm can be extended to other tasks, including estimation of\nWasserstein barycenters. We provide theoretical guarantees and illustrate the\nperformance of our algorithm with experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:04:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ballu", "Marin", ""], ["Berthet", "Quentin", ""], ["Bach", "Francis", ""]]}, {"id": "2002.08697", "submitter": "Valentin Radu", "authors": "Valentin Radu, Kuba Kaszyk, Yuan Wen, Jack Turner, Jose Cano, Elliot\n  J. Crowley, Bjorn Franke, Amos Storkey, Michael O'Boyle", "title": "Performance Aware Convolutional Neural Network Channel Pruning for\n  Embedded GPUs", "comments": "A copy of this was published in IISWC'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) are becoming a common presence in many\napplications and services, due to their superior recognition accuracy. They are\nincreasingly being used on mobile devices, many times just by porting large\nmodels designed for server space, although several model compression techniques\nhave been considered. One model compression technique intended to reduce\ncomputations is channel pruning. Mobile and embedded systems now have GPUs\nwhich are ideal for the parallel computations of neural networks and for their\nlower energy cost per operation. Specialized libraries perform these neural\nnetwork computations through highly optimized routines. As we find in our\nexperiments, these libraries are optimized for the most common network shapes,\nmaking uninstructed channel pruning inefficient. We evaluate higher level\nlibraries, which analyze the input characteristics of a convolutional layer,\nbased on which they produce optimized OpenCL (Arm Compute Library and TVM) and\nCUDA (cuDNN) code. However, in reality, these characteristics and subsequent\nchoices intended for optimization can have the opposite effect. We show that a\nreduction in the number of convolutional channels, pruning 12% of the initial\nsize, is in some cases detrimental to performance, leading to 2x slowdown. On\nthe other hand, we also find examples where performance-aware pruning achieves\nthe intended results, with performance speedups of 3x with cuDNN and above 10x\nwith Arm Compute Library and TVM. Our findings expose the need for\nhardware-instructed neural network pruning.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:07:44 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Radu", "Valentin", ""], ["Kaszyk", "Kuba", ""], ["Wen", "Yuan", ""], ["Turner", "Jack", ""], ["Cano", "Jose", ""], ["Crowley", "Elliot J.", ""], ["Franke", "Bjorn", ""], ["Storkey", "Amos", ""], ["O'Boyle", "Michael", ""]]}, {"id": "2002.08709", "submitter": "Takashi Ishida", "authors": "Takashi Ishida, Ikko Yamane, Tomoya Sakai, Gang Niu, and Masashi\n  Sugiyama", "title": "Do We Need Zero Training Loss After Achieving Zero Training Error?", "comments": "ICML 2020 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized deep networks have the capacity to memorize training data\nwith zero \\emph{training error}. Even after memorization, the \\emph{training\nloss} continues to approach zero, making the model overconfident and the test\nperformance degraded. Since existing regularizers do not directly aim to avoid\nzero training loss, it is hard to tune their hyperparameters in order to\nmaintain a fixed/preset level of training loss. We propose a direct solution\ncalled \\emph{flooding} that intentionally prevents further reduction of the\ntraining loss when it reaches a reasonably small value, which we call the\n\\emph{flood level}. Our approach makes the loss float around the flood level by\ndoing mini-batched gradient descent as usual but gradient ascent if the\ntraining loss is below the flood level. This can be implemented with one line\nof code and is compatible with any stochastic optimizer and other regularizers.\nWith flooding, the model will continue to \"random walk\" with the same non-zero\ntraining loss, and we expect it to drift into an area with a flat loss\nlandscape that leads to better generalization. We experimentally show that\nflooding improves performance and, as a byproduct, induces a double descent\ncurve of the test loss.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 12:50:49 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 07:22:24 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Ishida", "Takashi", ""], ["Yamane", "Ikko", ""], ["Sakai", "Tomoya", ""], ["Niu", "Gang", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2002.08718", "submitter": "Xiaojie Gao", "authors": "Xiaojie Gao, Yueming Jin, Qi Dou, and Pheng-Ann Heng", "title": "Automatic Gesture Recognition in Robot-assisted Surgery with\n  Reinforcement Learning and Tree Search", "comments": "Accepted as a conference paper in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic surgical gesture recognition is fundamental for improving\nintelligence in robot-assisted surgery, such as conducting complicated tasks of\nsurgery surveillance and skill evaluation. However, current methods treat each\nframe individually and produce the outcomes without effective consideration on\nfuture information. In this paper, we propose a framework based on\nreinforcement learning and tree search for joint surgical gesture segmentation\nand classification. An agent is trained to segment and classify the surgical\nvideo in a human-like manner whose direct decisions are re-considered by tree\nsearch appropriately. Our proposed tree search algorithm unites the outputs\nfrom two designed neural networks, i.e., policy and value network. With the\nintegration of complementary information from distinct models, our framework is\nable to achieve the better performance than baseline methods using either of\nthe neural networks. For an overall evaluation, our developed approach\nconsistently outperforms the existing methods on the suturing task of JIGSAWS\ndataset in terms of accuracy, edit score and F1 score. Our study highlights the\nutilization of tree search to refine actions in reinforcement learning\nframework for surgical robotic applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:12:38 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Gao", "Xiaojie", ""], ["Jin", "Yueming", ""], ["Dou", "Qi", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "2002.08721", "submitter": "Lars Schmarje", "authors": "Lars Schmarje, Monty Santarossa, Simon-Martin Schr\\\"oder, and Reinhard\n  Koch", "title": "A survey on Semi-, Self- and Unsupervised Learning for Image\n  Classification", "comments": "Accepted to IEEE Access 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning strategies achieve outstanding results in computer vision\ntasks, one issue remains: The current strategies rely heavily on a huge amount\nof labeled data. In many real-world problems, it is not feasible to create such\nan amount of labeled training data. Therefore, it is common to incorporate\nunlabeled data into the training process to reach equal results with fewer\nlabels. Due to a lot of concurrent research, it is difficult to keep track of\nrecent developments. In this survey, we provide an overview of often used ideas\nand methods in image classification with fewer labels. We compare 34 methods in\ndetail based on their performance and their commonly used ideas rather than a\nfine-grained taxonomy. In our analysis, we identify three major trends that\nlead to future research opportunities. 1. State-of-the-art methods are\nscaleable to real-world applications in theory but issues like class imbalance,\nrobustness, or fuzzy labels are not considered. 2. The degree of supervision\nwhich is needed to achieve comparable results to the usage of all labels is\ndecreasing and therefore methods need to be extended to settings with a\nvariable number of classes. 3. All methods share some common ideas but we\nidentify clusters of methods that do not share many ideas. We show that\ncombining ideas from different clusters can lead to better performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:29:27 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 13:33:38 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 11:44:02 GMT"}, {"version": "v4", "created": "Thu, 11 Feb 2021 14:16:54 GMT"}, {"version": "v5", "created": "Tue, 25 May 2021 12:29:55 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Schmarje", "Lars", ""], ["Santarossa", "Monty", ""], ["Schr\u00f6der", "Simon-Martin", ""], ["Koch", "Reinhard", ""]]}, {"id": "2002.08729", "submitter": "Ke Quan", "authors": "Ke Quan", "title": "Bimodal Distribution Removal and Genetic Algorithm in Neural Network for\n  Breast Cancer Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis of breast cancer has been well studied in the past. Multiple linear\nprogramming models have been devised to approximate the relationship between\ncell features and tumour malignancy. However, these models are less capable in\nhandling non-linear correlations. Neural networks instead are powerful in\nprocessing complex non-linear correlations. It is thus certainly beneficial to\napproach this cancer diagnosis problem with a model based on neural network.\nParticularly, introducing bias to neural network training process is deemed as\nan important means to increase training efficiency. Out of a number of popular\nproposed methods for introducing artificial bias, Bimodal Distribution Removal\n(BDR) presents ideal efficiency improvement results and fair simplicity in\nimplementation. However, this paper examines the effectiveness of BDR against\nthe target cancer diagnosis classification problem and shows that BDR process\nin fact negatively impacts classification performance. In addition, this paper\nalso explores genetic algorithm as an efficient tool for feature selection and\nproduced significantly better results comparing to baseline model that without\nany feature selection in place\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:51:40 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Quan", "Ke", ""]]}, {"id": "2002.08731", "submitter": "Kristiaan Pelckmans", "authors": "Kristiaan Pelckmans and Liu Yang", "title": "APTER: Aggregated Prognosis Through Exponential Reweighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the task of learning how to make a prognosis of a\npatient based on his/her micro-array expression levels. The method is an\napplication of the aggregation method as recently proposed in the literature on\ntheoretical machine learning, and excels in its computational convenience and\ncapability to deal with high-dimensional data. A formal analysis of the method\nis given, yielding rates of convergence similar to what traditional techniques\nobtain, while it is shown to cope well with an exponentially large set of\nfeatures. Those results are supported by numerical simulations on a range of\npublicly available survival-micro-array datasets. It is empirically found that\nthe proposed technique combined with a recently proposed preprocessing\ntechnique gives excellent performances.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:53:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Pelckmans", "Kristiaan", ""], ["Yang", "Liu", ""]]}, {"id": "2002.08740", "submitter": "Ilia Shumailov", "authors": "Ilia Shumailov, Yiren Zhao, Robert Mullins, Ross Anderson", "title": "Towards Certifiable Adversarial Sample Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are deployed in more and more\nclassification systems, but adversarial samples can be maliciously crafted to\ntrick them, and are becoming a real threat. There have been various proposals\nto improve CNNs' adversarial robustness but these all suffer performance\npenalties or other limitations. In this paper, we provide a new approach in the\nform of a certifiable adversarial detection scheme, the Certifiable Taboo Trap\n(CTT). The system can provide certifiable guarantees of detection of\nadversarial inputs for certain $l_{\\infty}$ sizes on a reasonable assumption,\nnamely that the training data have the same distribution as the test data. We\ndevelop and evaluate several versions of CTT with a range of defense\ncapabilities, training overheads and certifiability on adversarial samples.\nAgainst adversaries with various $l_p$ norms, CTT outperforms existing defense\nmethods that focus purely on improving network robustness. We show that CTT has\nsmall false positive rates on clean test data, minimal compute overheads when\ndeployed, and can support complex security policies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:10:00 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Shumailov", "Ilia", ""], ["Zhao", "Yiren", ""], ["Mullins", "Robert", ""], ["Anderson", "Ross", ""]]}, {"id": "2002.08749", "submitter": "Henghui Ding", "authors": "Jianhan Mei, Henghui Ding, Xudong Jiang", "title": "Object 6D Pose Estimation with Non-local Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the challenging task of estimating 6D object pose\nfrom a single RGB image. Motivated by the deep learning based object detection\nmethods, we propose a concise and efficient network that integrate 6D object\npose parameter estimation into the object detection framework. Furthermore, for\nmore robust estimation to occlusion, a non-local self-attention module is\nintroduced. The experimental results show that the proposed method reaches the\nstate-of-the-art performance on the YCB-video and the Linemod datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:23:32 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mei", "Jianhan", ""], ["Ding", "Henghui", ""], ["Jiang", "Xudong", ""]]}, {"id": "2002.08762", "submitter": "Konstantinos Bougiatiotis", "authors": "K. Bougiatiotis, R. Fasoulis, F. Aisopos, A. Nentidis, G. Paliouras", "title": "Guiding Graph Embeddings using Path-Ranking Methods for Error Detection\n  innoisy Knowledge Graphs", "comments": "9 pages, 2 figures. To appear in GCLR 2021: AAAI 2021 Workshop on\n  Graphs and more Complex structures for Learning and Reasonin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays Knowledge Graphs constitute a mainstream approach for the\nrepresentation of relational information on big heterogeneous data, however,\nthey may contain a big amount of imputed noise when constructed automatically.\nTo address this problem, different error detection methodologies have been\nproposed, mainly focusing on path ranking and representation learning. This\nwork presents various mainstream approaches and proposes a hybrid and modular\nmethodology for the task. We compare different methods on two benchmarks and\none real-world biomedical publications dataset, showcasing the potential of our\napproach and providing insights on graph embeddings when dealing with noisy\nKnowledge Graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:04:11 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 20:43:10 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bougiatiotis", "K.", ""], ["Fasoulis", "R.", ""], ["Aisopos", "F.", ""], ["Nentidis", "A.", ""], ["Paliouras", "G.", ""]]}, {"id": "2002.08772", "submitter": "Yaron Lipman", "authors": "Hadar Serviansky, Nimrod Segol, Jonathan Shlomi, Kyle Cranmer, Eilam\n  Gross, Haggai Maron, Yaron Lipman", "title": "Set2Graph: Learning Graphs From Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in machine learning can be cast as learning functions from sets\nto graphs, or more generally to hypergraphs; in short, Set2Graph functions.\nExamples include clustering, learning vertex and edge features on graphs, and\nlearning features on triplets in a collection. A natural approach for building\nSet2Graph models is to characterize all linear equivariant set-to-hypergraph\nlayers and stack them with non-linear activations. This poses two challenges:\n(i) the expressive power of these networks is not well understood; and (ii)\nthese models would suffer from high, often intractable computational and memory\ncomplexity, as their dimension grows exponentially. This paper advocates a\nfamily of neural network models for learning Set2Graph functions that is both\npractical and of maximal expressive power (universal), that is, can approximate\narbitrary continuous Set2Graph functions over compact sets. Testing these\nmodels on different machine learning tasks, mainly an application to particle\nphysics, we find them favorable to existing baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:53:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:28:05 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 08:17:03 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Serviansky", "Hadar", ""], ["Segol", "Nimrod", ""], ["Shlomi", "Jonathan", ""], ["Cranmer", "Kyle", ""], ["Gross", "Eilam", ""], ["Maron", "Haggai", ""], ["Lipman", "Yaron", ""]]}, {"id": "2002.08774", "submitter": "Victor-Emmanuel Brunel", "authors": "Victor-Emmanuel Brunel and Marco Avella-Medina", "title": "Propose, Test, Release: Differentially private estimation with high\n  probability", "comments": "arXiv admin note: text overlap with arXiv:1906.11923", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive concentration inequalities for differentially private median and\nmean estimators building on the \"Propose, Test, Release\" (PTR) mechanism\nintroduced by Dwork and Lei (2009). We introduce a new general version of the\nPTR mechanism that allows us to derive high probability error bounds for\ndifferentially private estimators. Our algorithms provide the first statistical\nguarantees for differentially private estimation of the median and mean without\nany boundedness assumptions on the data, and without assuming that the target\npopulation parameter lies in some known bounded interval. Our procedures do not\nrely on any truncation of the data and provide the first sub-Gaussian high\nprobability bounds for differentially private median and mean estimation, for\npossibly heavy tailed random variables.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:29:05 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Brunel", "Victor-Emmanuel", ""], ["Avella-Medina", "Marco", ""]]}, {"id": "2002.08777", "submitter": "Jodie Lobana", "authors": "NIklas Kuhl, Jodie Lobana, and Christian Meske", "title": "Do you comply with AI? -- Personalized explanations of learning\n  algorithms and their impact on employees' compliance behavior", "comments": "Fortieth International Conference on Information Systems (ICIS) 2019,\n  Munich, Germany. All Authors contributed equally in shared first authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning algorithms are technological key enablers for artificial\nintelligence (AI). Due to the inherent complexity, these learning algorithms\nrepresent black boxes and are difficult to comprehend, therefore influencing\ncompliance behavior. Hence, compliance with the recommendations of such\nartifacts, which can impact employees' task performance significantly, is still\nsubject to research - and personalization of AI explanations seems to be a\npromising concept in this regard. In our work, we hypothesize that, based on\nvarying backgrounds like training, domain knowledge and demographic\ncharacteristics, individuals have different understandings and hence mental\nmodels about the learning algorithm. Personalization of AI explanations,\nrelated to the individuals' mental models, may thus be an instrument to affect\ncompliance and therefore employee task performance. Our preliminary results\nalready indicate the importance of personalized explanations in industry\nsettings and emphasize the importance of this research endeavor.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:55:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kuhl", "NIklas", ""], ["Lobana", "Jodie", ""], ["Meske", "Christian", ""]]}, {"id": "2002.08782", "submitter": "Elsa Rizk", "authors": "Elsa Rizk, Stefan Vlaski, Ali H. Sayed", "title": "Dynamic Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has emerged as an umbrella term for centralized\ncoordination strategies in multi-agent environments. While many federated\nlearning architectures process data in an online manner, and are hence adaptive\nby nature, most performance analyses assume static optimization problems and\noffer no guarantees in the presence of drifts in the problem solution or data\ncharacteristics. We consider a federated learning model where at every\niteration, a random subset of available agents perform local updates based on\ntheir data. Under a non-stationary random walk model on the true minimizer for\nthe aggregate optimization problem, we establish that the performance of the\narchitecture is determined by three factors, namely, the data variability at\neach agent, the model variability across all agents, and a tracking term that\nis inversely proportional to the learning rate of the algorithm. The results\nclarify the trade-off between convergence and tracking performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:00:54 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 09:26:32 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Rizk", "Elsa", ""], ["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2002.08791", "submitter": "Andrew Wilson", "authors": "Andrew Gordon Wilson, Pavel Izmailov", "title": "Bayesian Deep Learning and a Probabilistic Perspective of Generalization", "comments": "30 pages, 19 figures. Updated to add new results showing Bayesian\n  model averaging mitigates double descent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key distinguishing property of a Bayesian approach is marginalization,\nrather than using a single setting of weights. Bayesian marginalization can\nparticularly improve the accuracy and calibration of modern deep neural\nnetworks, which are typically underspecified by the data, and can represent\nmany compelling but different solutions. We show that deep ensembles provide an\neffective mechanism for approximate Bayesian marginalization, and propose a\nrelated approach that further improves the predictive distribution by\nmarginalizing within basins of attraction, without significant overhead. We\nalso investigate the prior over functions implied by a vague distribution over\nneural network weights, explaining the generalization properties of such models\nfrom a probabilistic perspective. From this perspective, we explain results\nthat have been presented as mysterious and distinct to neural network\ngeneralization, such as the ability to fit images with random labels, and show\nthat these results can be reproduced with Gaussian processes. We also show that\nBayesian model averaging alleviates double descent, resulting in monotonic\nperformance improvements with increased flexibility. Finally, we provide a\nBayesian perspective on tempering for calibrating predictive distributions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:13:27 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 17:46:10 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 14:59:55 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wilson", "Andrew Gordon", ""], ["Izmailov", "Pavel", ""]]}, {"id": "2002.08795", "submitter": "Prithviraj Ammanabrolu", "authors": "Prithviraj Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark O. Riedl", "title": "How To Avoid Being Eaten By a Grue: Exploration Strategies for\n  Text-Adventure Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games -- in which an agent interacts with the world through\ntextual natural language -- present us with the problem of\ncombinatorially-sized action-spaces. Most current reinforcement learning\nalgorithms are not capable of effectively handling such a large number of\npossible actions per turn. Poor sample efficiency, consequently, results in\nagents that are unable to pass bottleneck states, where they are unable to\nproceed because they do not see the right action sequence to pass the\nbottleneck enough times to be sufficiently reinforced. Building on prior work\nusing knowledge graphs in reinforcement learning, we introduce two new game\nstate exploration strategies. We compare our exploration strategies against\nstrong baselines on the classic text-adventure game, Zork1, where prior agent\nhave been unable to get past a bottleneck where the agent is eaten by a Grue.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Ammanabrolu", "Prithviraj", ""], ["Tien", "Ethan", ""], ["Luo", "Zhaochen", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2002.08797", "submitter": "Soufiane Hayou", "authors": "Soufiane Hayou, Jean-Francois Ton, Arnaud Doucet, Yee Whye Teh", "title": "Robust Pruning at Initialization", "comments": "37 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overparameterized Neural Networks (NN) display state-of-the-art performance.\nHowever, there is a growing need for smaller, energy-efficient, neural networks\ntobe able to use machine learning applications on devices with limited\ncomputational resources. A popular approach consists of using pruning\ntechniques. While these techniques have traditionally focused on pruning\npre-trained NN (LeCun et al.,1990; Hassibi et al., 1993), recent work by Lee et\nal. (2018) has shown promising results when pruning at initialization. However,\nfor Deep NNs, such procedures remain unsatisfactory as the resulting pruned\nnetworks can be difficult to train and, for instance, they do not prevent one\nlayer from being fully pruned. In this paper, we provide a comprehensive\ntheoretical analysis of Magnitude and Gradient based pruning at initialization\nand training of sparse architectures. This allows us to propose novel\nprincipled approaches which we validate experimentally on a variety of NN\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:09:50 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 18:26:19 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 11:14:29 GMT"}, {"version": "v4", "created": "Thu, 18 Mar 2021 17:12:50 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 22:43:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hayou", "Soufiane", ""], ["Ton", "Jean-Francois", ""], ["Doucet", "Arnaud", ""], ["Teh", "Yee Whye", ""]]}, {"id": "2002.08799", "submitter": "Carlo Ciliberto", "authors": "Ruohan Wang, Yiannis Demiris, Carlo Ciliberto", "title": "Structured Prediction for Conditional Meta-Learning", "comments": "25 pages, 4 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of optimization-based meta-learning is to find a single\ninitialization shared across a distribution of tasks to speed up the process of\nlearning new tasks. Conditional meta-learning seeks task-specific\ninitialization to better capture complex task distributions and improve\nperformance. However, many existing conditional methods are difficult to\ngeneralize and lack theoretical guarantees. In this work, we propose a new\nperspective on conditional meta-learning via structured prediction. We derive\ntask-adaptive structured meta-learning (TASML), a principled framework that\nyields task-specific objective functions by weighing meta-training data on\ntarget tasks. Our non-parametric approach is model-agnostic and can be combined\nwith existing meta-learning methods to achieve conditioning. Empirically, we\nshow that TASML improves the performance of existing meta-learning models, and\noutperforms the state-of-the-art on benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:24:15 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 17:18:39 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Wang", "Ruohan", ""], ["Demiris", "Yiannis", ""], ["Ciliberto", "Carlo", ""]]}, {"id": "2002.08801", "submitter": "Pierre Colombo", "authors": "Pierre Colombo, Emile Chapuis, Matteo Manica, Emmanuel Vignon,\n  Giovanna Varni, Chloe Clavel", "title": "Guiding attention in Sequence-to-sequence models for Dialogue Act\n  prediction", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of predicting dialog acts (DA) based on conversational dialog is a\nkey component in the development of conversational agents. Accurately\npredicting DAs requires a precise modeling of both the conversation and the\nglobal tag dependencies. We leverage seq2seq approaches widely adopted in\nNeural Machine Translation (NMT) to improve the modelling of tag sequentiality.\nSeq2seq models are known to learn complex global dependencies while currently\nproposed approaches using linear conditional random fields (CRF) only model\nlocal tag dependencies. In this work, we introduce a seq2seq model tailored for\nDA classification using: a hierarchical encoder, a novel guided attention\nmechanism and beam search applied to both training and inference. Compared to\nthe state of the art our model does not require handcrafted features and is\ntrained end-to-end. Furthermore, the proposed approach achieves an unmatched\naccuracy score of 85% on SwDA, and state-of-the-art accuracy score of 91.6% on\nMRDA.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:25:20 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:25:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Colombo", "Pierre", ""], ["Chapuis", "Emile", ""], ["Manica", "Matteo", ""], ["Vignon", "Emmanuel", ""], ["Varni", "Giovanna", ""], ["Clavel", "Chloe", ""]]}, {"id": "2002.08803", "submitter": "Ruohan Wang", "authors": "Ruohan Wang, Carlo Ciliberto, Pierluigi Amadori, Yiannis Demiris", "title": "Support-weighted Adversarial Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Imitation Learning (AIL) is a broad family of imitation learning\nmethods designed to mimic expert behaviors from demonstrations. While AIL has\nshown state-of-the-art performance on imitation learning with only small number\nof demonstrations, it faces several practical challenges such as potential\ntraining instability and implicit reward bias. To address the challenges, we\npropose Support-weighted Adversarial Imitation Learning (SAIL), a general\nframework that extends a given AIL algorithm with information derived from\nsupport estimation of the expert policies. SAIL improves the quality of the\nreinforcement signals by weighing the adversarial reward with a confidence\nscore from support estimation of the expert policy. We also show that SAIL is\nalways at least as efficient as the underlying AIL algorithm that SAIL uses for\nlearning the adversarial reward. Empirically, we show that the proposed method\nachieves better performance and training stability than baseline methods on a\nwide range of benchmark control tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:34:30 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Ruohan", ""], ["Ciliberto", "Carlo", ""], ["Amadori", "Pierluigi", ""], ["Demiris", "Yiannis", ""]]}, {"id": "2002.08805", "submitter": "Jian Li", "authors": "Qilin Fan, Xiuhua Li, Jian Li, Qiang He, Kai Wang, Junhao Wen", "title": "PA-Cache: Evolving Learning-Based Popularity-Aware Content Caching in\n  Edge Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As ubiquitous and personalized services are growing boomingly, an\nincreasingly large amount of traffic is generated over the network by massive\nmobile devices. As a result, content caching is gradually extending to network\nedges to provide low-latency services, improve quality of service, and reduce\nredundant data traffic. Compared to the conventional content delivery networks,\ncaches in edge networks with smaller sizes usually have to accommodate more\nbursty requests. In this paper, we propose an evolving learning-based content\ncaching policy, named PA-Cache in edge networks. It adaptively learns\ntime-varying content popularity and determines which contents should be\nreplaced when the cache is full. Unlike conventional deep neural networks\n(DNNs), which learn a fine-tuned but possibly outdated or biased prediction\nmodel using the entire training dataset with high computational complexity,\nPA-Cache weighs a large set of content features and trains the multi-layer\nrecurrent neural network from shallow to deeper when more requests arrive over\ntime. We extensively evaluate the performance of our proposed PA-Cache on\nreal-world traces from a large online video-on-demand service provider. \\rb{The\nresults show that PA-Cache outperforms existing popular caching algorithms and\napproximates the optimal algorithm with only a 3.8\\% performance gap when the\ncache percentage is 1.0\\%}. PA-Cache also significantly reduces the\ncomputational cost compared to conventional DNN-based approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:38:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 02:54:51 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Fan", "Qilin", ""], ["Li", "Xiuhua", ""], ["Li", "Jian", ""], ["He", "Qiang", ""], ["Wang", "Kai", ""], ["Wen", "Junhao", ""]]}, {"id": "2002.08809", "submitter": "Guan-Horng Liu", "authors": "Guan-Horng Liu, Tianrong Chen and Evangelos A. Theodorou", "title": "DDPNOpt: Differential Dynamic Programming Neural Optimizer", "comments": "Accepted in International Conference on Learning Representations\n  (ICLR) 2021 as Spotlight", "journal-ref": "10th International Conference on Learning Representations (ICLR\n  2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretation of Deep Neural Networks (DNNs) training as an optimal control\nproblem with nonlinear dynamical systems has received considerable attention\nrecently, yet the algorithmic development remains relatively limited. In this\nwork, we make an attempt along this line by reformulating the training\nprocedure from the trajectory optimization perspective. We first show that most\nwidely-used algorithms for training DNNs can be linked to the Differential\nDynamic Programming (DDP), a celebrated second-order method rooted in the\nApproximate Dynamic Programming. In this vein, we propose a new class of\noptimizer, DDP Neural Optimizer (DDPNOpt), for training feedforward and\nconvolution networks. DDPNOpt features layer-wise feedback policies which\nimprove convergence and reduce sensitivity to hyper-parameter over existing\nmethods. It outperforms other optimal-control inspired training methods in both\nconvergence and complexity, and is competitive against state-of-the-art first\nand second order methods. We also observe DDPNOpt has surprising benefit in\npreventing gradient vanishing. Our work opens up new avenues for principled\nalgorithmic design built upon the optimal control theory.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:42:15 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 16:51:50 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 21:47:35 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Guan-Horng", ""], ["Chen", "Tianrong", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2002.08837", "submitter": "Chara Podimata", "authors": "Rupert Freeman, David M. Pennock, Chara Podimata, and Jennifer Wortman\n  Vaughan", "title": "No-Regret and Incentive-Compatible Online Learning", "comments": "Appears in ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study online learning settings in which experts act strategically to\nmaximize their influence on the learning algorithm's predictions by potentially\nmisreporting their beliefs about a sequence of binary events. Our goal is\ntwofold. First, we want the learning algorithm to be no-regret with respect to\nthe best fixed expert in hindsight. Second, we want incentive compatibility, a\nguarantee that each expert's best strategy is to report his true beliefs about\nthe realization of each event. To achieve this goal, we build on the literature\non wagering mechanisms, a type of multi-agent scoring rule. We provide\nalgorithms that achieve no regret and incentive compatibility for myopic\nexperts for both the full and partial information settings. In experiments on\ndatasets from FiveThirtyEight, our algorithms have regret comparable to classic\nno-regret algorithms, which are not incentive-compatible. Finally, we identify\nan incentive-compatible algorithm for forward-looking strategic agents that\nexhibits diminishing regret in practice.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:21:34 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 18:57:41 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Freeman", "Rupert", ""], ["Pennock", "David M.", ""], ["Podimata", "Chara", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "2002.08838", "submitter": "Adel Bibi", "authors": "Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar and Bernard\n  Ghanem", "title": "On the Decision Boundaries of Neural Networks: A Tropical Geometry\n  Perspective", "comments": "First two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work tackles the problem of characterizing and understanding the\ndecision boundaries of neural networks with piecewise linear non-linearity\nactivations. We use tropical geometry, a new development in the area of\nalgebraic geometry, to characterize the decision boundaries of a simple network\nof the form (Affine, ReLU, Affine). Our main finding is that the decision\nboundaries are a subset of a tropical hypersurface, which is intimately related\nto a polytope formed by the convex hull of two zonotopes. The generators of\nthese zonotopes are functions of the network parameters. This geometric\ncharacterization provides new perspectives to three tasks. (i) We propose a new\ntropical perspective to the lottery ticket hypothesis, where we view the effect\nof different initializations on the tropical geometric representation of a\nnetwork's decision boundaries. (ii) Moreover, we propose new tropical based\noptimization reformulations that directly influence the decision boundaries of\nthe network for the task of network pruning. (iii) At last, we discuss the\nreformulation of the generation of adversarial attacks in a tropical sense. We\ndemonstrate that one can construct adversaries in a new tropical setting by\nperturbing a specific set of decision boundaries by perturbing a set of\nparameters in the network.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:22:44 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 17:03:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Alfarra", "Motasem", ""], ["Bibi", "Adel", ""], ["Hammoud", "Hasan", ""], ["Gaafar", "Mohamed", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2002.08841", "submitter": "Joey Huchette", "authors": "Joey Huchette, Haihao Lu, Hossein Esfandiari, Vahab Mirrokni", "title": "Contextual Reserve Price Optimization in Auctions via Mixed-Integer\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a linear model to set the reserve price in\nan auction, given contextual information, in order to maximize expected revenue\nfrom the seller side. First, we show that it is not possible to solve this\nproblem in polynomial time unless the \\emph{Exponential Time Hypothesis} fails.\nSecond, we present a strong mixed-integer programming (MIP) formulation for\nthis problem, which is capable of exactly modeling the nonconvex and\ndiscontinuous expected reward function. Moreover, we show that this MIP\nformulation is ideal (i.e. the strongest possible formulation) for the revenue\nfunction of a single impression. Since it can be computationally expensive to\nexactly solve the MIP formulation in practice, we also study the performance of\nits linear programming (LP) relaxation. Though it may work well in practice, we\nshow that, unfortunately, in the worst case the optimal objective of the LP\nrelaxation can be O(number of samples) times larger than the optimal objective\nof the true problem. Finally, we present computational results, showcasing that\nthe MIP formulation, along with its LP relaxation, are able to achieve superior\nin- and out-of-sample performance, as compared to state-of-the-art algorithms\non both real and synthetic datasets. More broadly, we believe this work offers\nan indication of the strength of optimization methodologies like MIP to exactly\nmodel intrinsic discontinuities in machine learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:28:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 22:04:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huchette", "Joey", ""], ["Lu", "Haihao", ""], ["Esfandiari", "Hossein", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "2002.08853", "submitter": "Yiming Xu", "authors": "Ruijian Han, Yiming Xu and Kani Chen", "title": "A General Pairwise Comparison Model for Extremely Sparse Networks", "comments": "25 pages, 4 figures, included more numerical simulations, changed\n  some phrasing in the statements and updated citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference using pairwise comparison data has been an effective\napproach to analyzing complex and sparse networks. In this paper we propose a\ngeneral framework for modeling the mutual interaction in a network, which\nenjoys ample flexibility in terms of parametrization. Within this setup, we\nestablish that the maximum likelihood estimator (MLE) for the latent scores of\nthe subjects is uniformly consistent under a near-minimal condition on network\nsparsity. This condition is sharp in terms of the leading order asymptotics\ndescribing the sparsity. The proof utilizes a novel chaining technique based on\nthe error-induced metric as well as careful counting of comparison graph\nstructures. Our results guarantee that the MLE is a valid estimator for\ninference in large-scale comparison networks where data is asymptotically\ndeficient. Numerical simulations are provided to complement the theoretical\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:39:55 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 17:29:24 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Han", "Ruijian", ""], ["Xu", "Yiming", ""], ["Chen", "Kani", ""]]}, {"id": "2002.08856", "submitter": "Thomas Flynn", "authors": "Thomas Flynn, Kwang Min Yu, Abid Malik, Nicolas D'Imperio, Shinjae Yoo", "title": "Bounding the expected run-time of nonconvex optimization with early\n  stopping", "comments": "Camera ready version for UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines the convergence of stochastic gradient-based optimization\nalgorithms that use early stopping based on a validation function. The form of\nearly stopping we consider is that optimization terminates when the norm of the\ngradient of a validation function falls below a threshold. We derive conditions\nthat guarantee this stopping rule is well-defined, and provide bounds on the\nexpected number of iterations and gradient evaluations needed to meet this\ncriterion. The guarantee accounts for the distance between the training and\nvalidation sets, measured with the Wasserstein distance. We develop the\napproach in the general setting of a first-order optimization algorithm, with\npossibly biased update directions subject to a geometric drift condition. We\nthen derive bounds on the expected running time for early stopping variants of\nseveral algorithms, including stochastic gradient descent (SGD), decentralized\nSGD (DSGD), and the stochastic variance reduced gradient (SVRG) algorithm.\nFinally, we consider the generalization properties of the iterate returned by\nearly stopping.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:43:37 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 20:50:55 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 15:27:06 GMT"}, {"version": "v4", "created": "Wed, 22 Jul 2020 17:56:23 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Flynn", "Thomas", ""], ["Yu", "Kwang Min", ""], ["Malik", "Abid", ""], ["D'Imperio", "Nicolas", ""], ["Yoo", "Shinjae", ""]]}, {"id": "2002.08859", "submitter": "Eitan Richardson", "authors": "Eitan Richardson and Yair Weiss", "title": "A Bayes-Optimal View on Adversarial Examples", "comments": "Minor revision per journal review, 28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since the discovery of adversarial examples - the ability to fool modern CNN\nclassifiers with tiny perturbations of the input, there has been much\ndiscussion whether they are a \"bug\" that is specific to current neural\narchitectures and training methods or an inevitable \"feature\" of high\ndimensional geometry. In this paper, we argue for examining adversarial\nexamples from the perspective of Bayes-Optimal classification. We construct\nrealistic image datasets for which the Bayes-Optimal classifier can be\nefficiently computed and derive analytic conditions on the distributions under\nwhich these classifiers are provably robust against any adversarial attack even\nin high dimensions. Our results show that even when these \"gold standard\"\noptimal classifiers are robust, CNNs trained on the same datasets consistently\nlearn a vulnerable classifier, indicating that adversarial examples are often\nan avoidable \"bug\". We further show that RBF SVMs trained on the same data\nconsistently learn a robust classifier. The same trend is observed in\nexperiments with real images in different datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:43:47 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 09:47:10 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Richardson", "Eitan", ""], ["Weiss", "Yair", ""]]}, {"id": "2002.08860", "submitter": "Biswadip Dey", "authors": "Yaofeng Desmond Zhong, Biswadip Dey, Amit Chakraborty", "title": "Dissipative SymODEN: Encoding Hamiltonian Dynamics with Dissipation and\n  Control into Deep Learning", "comments": "Published at ICLR 2020 Workshop on Integration of Deep Neural Models\n  and Differential Equations (DeepDiffEq)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce Dissipative SymODEN, a deep learning architecture\nwhich can infer the dynamics of a physical system with dissipation from\nobserved state trajectories. To improve prediction accuracy while reducing\nnetwork size, Dissipative SymODEN encodes the port-Hamiltonian dynamics with\nenergy dissipation and external input into the design of its computation graph\nand learns the dynamics in a structured way. The learned model, by revealing\nkey aspects of the system, such as the inertia, dissipation, and potential\nenergy, paves the way for energy-based controllers.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:44:10 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 03:59:58 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 02:53:24 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhong", "Yaofeng Desmond", ""], ["Dey", "Biswadip", ""], ["Chakraborty", "Amit", ""]]}, {"id": "2002.08866", "submitter": "Jamie Kiros", "authors": "Jamie Kiros", "title": "Contextual Lensing of Universal Sentence Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a universal sentence encoder universal? The notion of a generic\nencoder of text appears to be at odds with the inherent contextualization and\nnon-permanence of language use in a dynamic world. However, mapping sentences\ninto generic fixed-length vectors for downstream similarity and retrieval tasks\nhas been fruitful, particularly for multilingual applications. How do we manage\nthis dilemma? In this work we propose Contextual Lensing, a methodology for\ninducing context-oriented universal sentence vectors. We break the construction\nof universal sentence vectors into a core, variable length, sentence matrix\nrepresentation equipped with an adaptable `lens' from which fixed-length\nvectors can be induced as a function of the lens context. We show that it is\npossible to focus notions of language similarity into a small number of lens\nparameters given a core universal matrix representation. For example, we\ndemonstrate the ability to encode translation similarity of sentences across\nseveral languages into a single weight matrix, even when the core encoder has\nnot seen parallel data.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:06:27 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kiros", "Jamie", ""]]}, {"id": "2002.08871", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Olivier Teboul, Quentin Berthet, Josip Djolonga", "title": "Fast Differentiable Sorting and Ranking", "comments": "In proceedings of ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sorting operation is one of the most commonly used building blocks in\ncomputer programming. In machine learning, it is often used for robust\nstatistics. However, seen as a function, it is piecewise linear and as a result\nincludes many kinks where it is non-differentiable. More problematic is the\nrelated ranking operator, often used for order statistics and ranking metrics.\nIt is a piecewise constant function, meaning that its derivatives are null or\nundefined. While numerous works have proposed differentiable proxies to sorting\nand ranking, they do not achieve the $O(n \\log n)$ time complexity one would\nexpect from sorting and ranking operations. In this paper, we propose the first\ndifferentiable sorting and ranking operators with $O(n \\log n)$ time and $O(n)$\nspace complexity. Our proposal in addition enjoys exact computation and\ndifferentiation. We achieve this feat by constructing differentiable operators\nas projections onto the permutahedron, the convex hull of permutations, and\nusing a reduction to isotonic optimization. Empirically, we confirm that our\napproach is an order of magnitude faster than existing approaches and showcase\ntwo novel applications: differentiable Spearman's rank correlation coefficient\nand least trimmed squares.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:11:09 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:11:03 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Blondel", "Mathieu", ""], ["Teboul", "Olivier", ""], ["Berthet", "Quentin", ""], ["Djolonga", "Josip", ""]]}, {"id": "2002.08872", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas", "title": "Halpern Iteration for Near-Optimal and Parameter-Free Monotone Inclusion\n  and Strong Solutions to Variational Inequalities", "comments": "23 pages; v1->v2: added acknowledgements and some more related work;\n  v2 -> v3: fixed a small typo in the proof of Lemma 2.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We leverage the connections between nonexpansive maps, monotone Lipschitz\noperators, and proximal mappings to obtain near-optimal (i.e., optimal up to\npoly-log factors in terms of iteration complexity) and parameter-free methods\nfor solving monotone inclusion problems. These results immediately translate\ninto near-optimal guarantees for approximating strong solutions to variational\ninequality problems, approximating convex-concave min-max optimization\nproblems, and minimizing the norm of the gradient in min-max optimization\nproblems. Our analysis is based on a novel and simple potential-based proof of\nconvergence of Halpern iteration, a classical iteration for finding fixed\npoints of nonexpansive maps. Additionally, we provide a series of algorithmic\nreductions that highlight connections between different problem classes and\nlead to lower bounds that certify near-optimality of the studied methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:12:49 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 17:28:39 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 15:48:39 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Diakonikolas", "Jelena", ""]]}, {"id": "2002.08878", "submitter": "Clement Moulin-Frier", "authors": "Cl\\'ement Moulin-Frier and Pierre-Yves Oudeyer", "title": "Multi-Agent Reinforcement Learning as a Computational Tool for Language\n  Evolution Research: Historical Context and Future Challenges", "comments": null, "journal-ref": "Challenges and Opportunities for Multi-Agent Reinforcement\n  Learning (COMARL AAAI 2020-2021), AAAI Spring Symposium Series, Stanford\n  University, Palo Alto, California, USA", "doi": null, "report-no": null, "categories": "cs.MA cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models of emergent communication in agent populations are\ncurrently gaining interest in the machine learning community due to recent\nadvances in Multi-Agent Reinforcement Learning (MARL). Current contributions\nare however still relatively disconnected from the earlier theoretical and\ncomputational literature aiming at understanding how language might have\nemerged from a prelinguistic substance. The goal of this paper is to position\nrecent MARL contributions within the historical context of language evolution\nresearch, as well as to extract from this theoretical and computational\nbackground a few challenges for future research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:26:46 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 13:54:46 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Moulin-Frier", "Cl\u00e9ment", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2002.08882", "submitter": "Thomas Lange", "authors": "Thomas Lange, Aneesh Balakrishnan, Maximilien Glorieux, Dan\n  Alexandrescu, Luca Sterpone", "title": "Machine Learning to Tackle the Challenges of Transient and Soft Errors\n  in Complex Circuits", "comments": null, "journal-ref": null, "doi": "10.1109/IOLTS.2019.8854423", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Functional Failure Rate analysis of today's complex circuits is a\ndifficult task and requires a significant investment in terms of human efforts,\nprocessing resources and tool licenses. Thereby, de-rating or vulnerability\nfactors are a major instrument of failure analysis efforts. Usually\ncomputationally intensive fault-injection simulation campaigns are required to\nobtain a fine-grained reliability metrics for the functional level. Therefore,\nthe use of machine learning algorithms to assist this procedure and thus,\noptimising and enhancing fault injection efforts, is investigated in this\npaper. Specifically, machine learning models are used to predict accurate\nper-instance Functional De-Rating data for the full list of circuit instances,\nan objective that is difficult to reach using classical methods. The described\nmethodology uses a set of per-instance features, extracted through an analysis\napproach, combining static elements (cell properties, circuit structure,\nsynthesis attributes) and dynamic elements (signal activity). Reference data is\nobtained through first-principles fault simulation approaches. One part of this\nreference dataset is used to train the machine learning model and the remaining\nis used to validate and benchmark the accuracy of the trained tool. The\npresented methodology is applied on a practical example and various machine\nlearning models are evaluated and compared.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:38:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Lange", "Thomas", ""], ["Balakrishnan", "Aneesh", ""], ["Glorieux", "Maximilien", ""], ["Alexandrescu", "Dan", ""], ["Sterpone", "Luca", ""]]}, {"id": "2002.08892", "submitter": "Ankit Singh Rawat", "authors": "Venkata Gandikota, Arya Mazumdar, Ankit Singh Rawat", "title": "Reliable Distributed Clustering with Redundant Data Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present distributed generalized clustering algorithms that\ncan handle large scale data across multiple machines in spite of straggling or\nunreliable machines. We propose a novel data assignment scheme that enables us\nto obtain global information about the entire data even when some machines fail\nto respond with the results of the assigned local computations. The assignment\nscheme leads to distributed algorithms with good approximation guarantees for a\nvariety of clustering and dimensionality reduction problems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:44:37 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Gandikota", "Venkata", ""], ["Mazumdar", "Arya", ""], ["Rawat", "Ankit Singh", ""]]}, {"id": "2002.08898", "submitter": "Adarsh Kumar", "authors": "Adarsh Kumar, Peter Ku, Anuj Kumar Goyal, Angeliki Metallinou, Dilek\n  Hakkani-Tur", "title": "MA-DST: Multi-Attention Based Scalable Dialog State Tracking", "comments": "Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task oriented dialog agents provide a natural language interface for users to\ncomplete their goal. Dialog State Tracking (DST), which is often a core\ncomponent of these systems, tracks the system's understanding of the user's\ngoal throughout the conversation. To enable accurate multi-domain DST, the\nmodel needs to encode dependencies between past utterances and slot semantics\nand understand the dialog context, including long-range cross-domain\nreferences. We introduce a novel architecture for this task to encode the\nconversation history and slot semantics more robustly by using attention\nmechanisms at multiple granularities. In particular, we use cross-attention to\nmodel relationships between the context and slots at different semantic levels\nand self-attention to resolve cross-domain coreferences. In addition, our\nproposed architecture does not rely on knowing the domain ontologies beforehand\nand can also be used in a zero-shot setting for new domains or unseen slot\nvalues. Our model improves the joint goal accuracy by 5% (absolute) in the\nfull-data setting and by up to 2% (absolute) in the zero-shot setting over the\npresent state-of-the-art on the MultiWoZ 2.1 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 05:34:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Adarsh", ""], ["Ku", "Peter", ""], ["Goyal", "Anuj Kumar", ""], ["Metallinou", "Angeliki", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2002.08900", "submitter": "M Sadegh Riazi", "authors": "M. Sadegh Riazi and Seyed M. Chavoshian and Farinaz Koushanfar", "title": "SynFi: Automatic Synthetic Fingerprint Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authentication and identification methods based on human fingerprints are\nubiquitous in several systems ranging from government organizations to consumer\nproducts. The performance and reliability of such systems directly rely on the\nvolume of data on which they have been verified. Unfortunately, a large volume\nof fingerprint databases is not publicly available due to many privacy and\nsecurity concerns.\n  In this paper, we introduce a new approach to automatically generate\nhigh-fidelity synthetic fingerprints at scale. Our approach relies on (i)\nGenerative Adversarial Networks to estimate the probability distribution of\nhuman fingerprints and (ii) Super-Resolution methods to synthesize fine-grained\ntextures. We rigorously test our system and show that our methodology is the\nfirst to generate fingerprints that are computationally indistinguishable from\nreal ones, a task that prior art could not accomplish.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 07:45:29 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Riazi", "M. Sadegh", ""], ["Chavoshian", "Seyed M.", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2002.08901", "submitter": "Zeljko Kraljevic", "authors": "Rebecca Bendayan, Honghan Wu, Zeljko Kraljevic, Robert Stewart, Tom\n  Searle, Jaya Chaturvedi, Jayati Das-Munshi, Zina Ibrahim, Aurelie Mascio,\n  Angus Roberts, Daniel Bean, Richard Dobson", "title": "Identifying physical health comorbidities in a cohort of individuals\n  with severe mental illness: An application of SemEHR", "comments": "4 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimorbidity research in mental health services requires data from physical\nhealth conditions which is traditionally limited in mental health care\nelectronic health records. In this study, we aimed to extract data from\nphysical health conditions from clinical notes using SemEHR. Data was extracted\nfrom Clinical Record Interactive Search (CRIS) system at South London and\nMaudsley Biomedical Research Centre (SLaM BRC) and the cohort consisted of all\nindividuals who had received a primary or secondary diagnosis of severe mental\nillness between 2007 and 2018. Three pairs of annotators annotated 2403\ndocuments with an average Cohen's Kappa of 0.757. Results show that the NLP\nperformance varies across different diseases areas (F1 0.601 - 0.954)\nsuggesting that the language patterns or terminologies of different condition\ngroups entail different technical challenges to the same NLP task.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 13:14:58 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Bendayan", "Rebecca", ""], ["Wu", "Honghan", ""], ["Kraljevic", "Zeljko", ""], ["Stewart", "Robert", ""], ["Searle", "Tom", ""], ["Chaturvedi", "Jaya", ""], ["Das-Munshi", "Jayati", ""], ["Ibrahim", "Zina", ""], ["Mascio", "Aurelie", ""], ["Roberts", "Angus", ""], ["Bean", "Daniel", ""], ["Dobson", "Richard", ""]]}, {"id": "2002.08902", "submitter": "Yu Wang", "authors": "Yu Wang, Yining Sun, Zuchang Ma, Lisheng Gao, Yang Xu, Ting Sun", "title": "Application of Pre-training Models in Named Entity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) is a fundamental Natural Language Processing\n(NLP) task to extract entities from unstructured data. The previous methods for\nNER were based on machine learning or deep learning. Recently, pre-training\nmodels have significantly improved performance on multiple NLP tasks. In this\npaper, firstly, we introduce the architecture and pre-training tasks of four\ncommon pre-training models: BERT, ERNIE, ERNIE2.0-tiny, and RoBERTa. Then, we\napply these pre-training models to a NER task by fine-tuning, and compare the\neffects of the different model architecture and pre-training tasks on the NER\ntask. The experiment results showed that RoBERTa achieved state-of-the-art\nresults on the MSRA-2006 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 08:18:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Wang", "Yu", ""], ["Sun", "Yining", ""], ["Ma", "Zuchang", ""], ["Gao", "Lisheng", ""], ["Xu", "Yang", ""], ["Sun", "Ting", ""]]}, {"id": "2002.08907", "submitter": "Alejandro Carderera", "authors": "Alejandro Carderera and Sebastian Pokutta", "title": "Second-order Conditional Gradient Sliding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained second-order convex optimization algorithms are the method of\nchoice when a high accuracy solution to a problem is needed, due to their local\nquadratic convergence. These algorithms require the solution of a constrained\nquadratic subproblem at every iteration. We present the \\emph{Second-Order\nConditional Gradient Sliding} (SOCGS) algorithm, which uses a projection-free\nalgorithm to solve the constrained quadratic subproblems inexactly. When the\nfeasible region is a polytope the algorithm converges quadratically in primal\ngap after a finite number of linearly convergent iterations. Once in the\nquadratic regime the SOCGS algorithm requires $\\mathcal{O}(\\log(\\log\n1/\\varepsilon))$ first-order and Hessian oracle calls and $\\mathcal{O}(\\log\n(1/\\varepsilon) \\log(\\log1/\\varepsilon))$ linear minimization oracle calls to\nachieve an $\\varepsilon$-optimal solution. This algorithm is useful when the\nfeasible region can only be accessed efficiently through a linear optimization\noracle, and computing first-order information of the function, although\npossible, is costly.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:52:18 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:57:53 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Carderera", "Alejandro", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2002.08909", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang", "title": "REALM: Retrieval-Augmented Language Model Pre-Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language model pre-training has been shown to capture a surprising amount of\nworld knowledge, crucial for NLP tasks such as question answering. However,\nthis knowledge is stored implicitly in the parameters of a neural network,\nrequiring ever-larger networks to cover more facts.\n  To capture knowledge in a more modular and interpretable way, we augment\nlanguage model pre-training with a latent knowledge retriever, which allows the\nmodel to retrieve and attend over documents from a large corpus such as\nWikipedia, used during pre-training, fine-tuning and inference. For the first\ntime, we show how to pre-train such a knowledge retriever in an unsupervised\nmanner, using masked language modeling as the learning signal and\nbackpropagating through a retrieval step that considers millions of documents.\n  We demonstrate the effectiveness of Retrieval-Augmented Language Model\npre-training (REALM) by fine-tuning on the challenging task of Open-domain\nQuestion Answering (Open-QA). We compare against state-of-the-art models for\nboth explicit and implicit knowledge storage on three popular Open-QA\nbenchmarks, and find that we outperform all previous methods by a significant\nmargin (4-16% absolute accuracy), while also providing qualitative benefits\nsuch as interpretability and modularity.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:40:59 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Guu", "Kelvin", ""], ["Lee", "Kenton", ""], ["Tung", "Zora", ""], ["Pasupat", "Panupong", ""], ["Chang", "Ming-Wei", ""]]}, {"id": "2002.08910", "submitter": "Colin Raffel", "authors": "Adam Roberts, Colin Raffel, and Noam Shazeer", "title": "How Much Knowledge Can You Pack Into the Parameters of a Language Model?", "comments": "Camera-ready version for EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been observed that neural language models trained on\nunstructured text can implicitly store and retrieve knowledge using natural\nlanguage queries. In this short paper, we measure the practical utility of this\napproach by fine-tuning pre-trained models to answer questions without access\nto any external context or knowledge. We show that this approach scales with\nmodel size and performs competitively with open-domain systems that explicitly\nretrieve answers from an external knowledge source when answering questions. To\nfacilitate reproducibility and future work, we release our code and trained\nmodels at https://goo.gle/t5-cbqa.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:55:58 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 04:54:34 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:04:06 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 21:26:45 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Roberts", "Adam", ""], ["Raffel", "Colin", ""], ["Shazeer", "Noam", ""]]}, {"id": "2002.08926", "submitter": "William Chan", "authors": "William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi,\n  Navdeep Jaitly", "title": "Imputer: Sequence Modelling via Imputation and Dynamic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Imputer, a neural sequence model that generates\noutput sequences iteratively via imputations. The Imputer is an iterative\ngenerative model, requiring only a constant number of generation steps\nindependent of the number of input or output tokens. The Imputer can be trained\nto approximately marginalize over all possible alignments between the input and\noutput sequences, and all possible generation orders. We present a tractable\ndynamic programming training algorithm, which yields a lower bound on the log\nmarginal likelihood. When applied to end-to-end speech recognition, the Imputer\noutperforms prior non-autoregressive models and achieves competitive results to\nautoregressive models. On LibriSpeech test-other, the Imputer achieves 11.1\nWER, outperforming CTC at 13.0 WER and seq2seq at 12.5 WER.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:21:30 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 17:32:18 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Chan", "William", ""], ["Saharia", "Chitwan", ""], ["Hinton", "Geoffrey", ""], ["Norouzi", "Mohammad", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "2002.08927", "submitter": "Abhishek Kumar", "authors": "Abhishek Kumar, Ben Poole, Kevin Murphy", "title": "Regularized Autoencoders via Relaxed Injective Probability Flow", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertible flow-based generative models are an effective method for learning\nto generate samples, while allowing for tractable likelihood computation and\ninference. However, the invertibility requirement restricts models to have the\nsame latent dimensionality as the inputs. This imposes significant\narchitectural, memory, and computational costs, making them more challenging to\nscale than other classes of generative models such as Variational Autoencoders\n(VAEs). We propose a generative model based on probability flows that does away\nwith the bijectivity requirement on the model and only assumes injectivity.\nThis also provides another perspective on regularized autoencoders (RAEs), with\nour final objectives resembling RAEs with specific regularizers that are\nderived by lower bounding the probability flow objective. We empirically\ndemonstrate the promise of the proposed model, improving over VAEs and AEs in\nterms of sample quality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:22:46 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kumar", "Abhishek", ""], ["Poole", "Ben", ""], ["Murphy", "Kevin", ""]]}, {"id": "2002.08930", "submitter": "Jihoon Moon", "authors": "J. H. Moon, Debasmit Das and C. S. George Lee", "title": "Multi-step Online Unsupervised Domain Adaptation", "comments": "To appear in ICASSP 2020. Copyright 2020 IEEE", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9052976", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the Online Unsupervised Domain Adaptation (OUDA)\nproblem, where the target data are unlabelled and arriving sequentially. The\ntraditional methods on the OUDA problem mainly focus on transforming each\narriving target data to the source domain, and they do not sufficiently\nconsider the temporal coherency and accumulative statistics among the arriving\ntarget data. We propose a multi-step framework for the OUDA problem, which\ninstitutes a novel method to compute the mean-target subspace inspired by the\ngeometrical interpretation on the Euclidean space. This mean-target subspace\ncontains accumulative temporal information among the arrived target data.\nMoreover, the transformation matrix computed from the mean-target subspace is\napplied to the next target data as a preprocessing step, aligning the target\ndata closer to the source domain. Experiments on four datasets demonstrated the\ncontribution of each step in our proposed multi-step OUDA framework and its\nperformance over previous approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:26:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Moon", "J. H.", ""], ["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "2002.08933", "submitter": "Neil Zeghidour", "authors": "Neil Zeghidour and David Grangier", "title": "Wavesplit: End-to-End Speech Separation by Speaker Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Wavesplit, an end-to-end source separation system. From a single\nmixture, the model infers a representation for each source and then estimates\neach source signal given the inferred representations. The model is trained to\njointly perform both tasks from the raw waveform. Wavesplit infers a set of\nsource representations via clustering, which addresses the fundamental\npermutation problem of separation. For speech separation, our sequence-wide\nspeaker representations provide a more robust separation of long, challenging\nrecordings compared to prior work. Wavesplit redefines the state-of-the-art on\nclean mixtures of 2 or 3 speakers (WSJ0-2/3mix), as well as in noisy and\nreverberated settings (WHAM/WHAMR). We also set a new benchmark on the recent\nLibriMix dataset. Finally, we show that Wavesplit is also applicable to other\ndomains, by separating fetal and maternal heart rates from a single abdominal\nelectrocardiogram.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:30:36 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 13:57:33 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zeghidour", "Neil", ""], ["Grangier", "David", ""]]}, {"id": "2002.08934", "submitter": "Jicong Fan", "authors": "Jicong Fan and Madeleine Udell", "title": "Online high rank matrix completion", "comments": "The paper was published by the proceedings of IEEE CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in matrix completion enable data imputation in full-rank\nmatrices by exploiting low dimensional (nonlinear) latent structure. In this\npaper, we develop a new model for high rank matrix completion (HRMC), together\nwith batch and online methods to fit the model and out-of-sample extension to\ncomplete new data. The method works by (implicitly) mapping the data into a\nhigh dimensional polynomial feature space using the kernel trick; importantly,\nthe data occupies a low dimensional subspace in this feature space, even when\nthe original data matrix is of full-rank. We introduce an explicit\nparametrization of this low dimensional subspace, and an online fitting\nprocedure, to reduce computational complexity compared to the state of the art.\nThe online method can also handle streaming or sequential data and adapt to\nnon-stationary latent structure. We provide guidance on the sampling rate\nrequired these methods to succeed. Experimental results on synthetic data and\nmotion capture data validate the performance of the proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:31:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fan", "Jicong", ""], ["Udell", "Madeleine", ""]]}, {"id": "2002.08936", "submitter": "Weihao Kong", "authors": "Weihao Kong, Raghav Somani, Zhao Song, Sham Kakade, Sewoong Oh", "title": "Meta-learning for mixed linear regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern supervised learning, there are a large number of tasks, but many of\nthem are associated with only a small amount of labeled data. These include\ndata from medical image processing and robotic interaction. Even though each\nindividual task cannot be meaningfully trained in isolation, one seeks to\nmeta-learn across the tasks from past experiences by exploiting some\nsimilarities. We study a fundamental question of interest: When can abundant\ntasks with small data compensate for lack of tasks with big data? We focus on a\ncanonical scenario where each task is drawn from a mixture of $k$ linear\nregressions, and identify sufficient conditions for such a graceful exchange to\nhold; The total number of examples necessary with only small data tasks scales\nsimilarly as when big data tasks are available. To this end, we introduce a\nnovel spectral approach and show that we can efficiently utilize small data\ntasks with the help of $\\tilde\\Omega(k^{3/2})$ medium data tasks each with\n$\\tilde\\Omega(k^{1/2})$ examples.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:34:28 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kong", "Weihao", ""], ["Somani", "Raghav", ""], ["Song", "Zhao", ""], ["Kakade", "Sham", ""], ["Oh", "Sewoong", ""]]}, {"id": "2002.08937", "submitter": "Weida Li", "authors": "Weida Li, Mingxia Liu, Daoqiang Zhang", "title": "Nystr\\\"om Subspace Learning for Large-scale SVMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an implementation of the Nystr\\\"{o}m method, Nystr\\\"{o}m computational\nregularization (NCR) imposed on kernel classification and kernel ridge\nregression has proven capable of achieving optimal bounds in the large-scale\nstatistical learning setting, while enjoying much better time complexity. In\nthis study, we propose a Nystr\\\"{o}m subspace learning (NSL) framework to\nreveal that all you need for employing the Nystr\\\"{o}m method, including NCR,\nupon any kernel SVM is to use the efficient off-the-shelf linear SVM solvers as\na black box. Based on our analysis, the bounds developed for the Nystr\\\"{o}m\nmethod are linked to NSL, and the analytical difference between two distinct\nimplementations of the Nystr\\\"{o}m method is clearly presented. Besides, NSL\nalso leads to sharper theoretical results for the clustered Nystr\\\"{o}m method.\nFinally, both regression and classification tasks are performed to compare two\nimplementations of the Nystr\\\"{o}m method.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:36:16 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Li", "Weida", ""], ["Liu", "Mingxia", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2002.08943", "submitter": "Quentin Bertrand", "authors": "Quentin Bertrand and Quentin Klopfenstein and Mathieu Blondel and\n  Samuel Vaiter and Alexandre Gramfort and Joseph Salmon", "title": "Implicit differentiation of Lasso-type models for hyperparameter\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Setting regularization parameters for Lasso-type estimators is notoriously\ndifficult, though crucial in practice. The most popular hyperparameter\noptimization approach is grid-search using held-out validation data.\nGrid-search however requires to choose a predefined grid for each parameter,\nwhich scales exponentially in the number of parameters. Another approach is to\ncast hyperparameter optimization as a bi-level optimization problem, one can\nsolve by gradient descent. The key challenge for these methods is the\nestimation of the gradient with respect to the hyperparameters. Computing this\ngradient via forward or backward automatic differentiation is possible yet\nusually suffers from high memory consumption. Alternatively implicit\ndifferentiation typically involves solving a linear system which can be\nprohibitive and numerically unstable in high dimension. In addition, implicit\ndifferentiation usually assumes smooth loss functions, which is not the case\nfor Lasso-type problems. This work introduces an efficient implicit\ndifferentiation algorithm, without matrix inversion, tailored for Lasso-type\nproblems. Our approach scales to high-dimensional data by leveraging the\nsparsity of the solutions. Experiments demonstrate that the proposed method\noutperforms a large number of standard methods to optimize the error on\nheld-out data, or the Stein Unbiased Risk Estimator (SURE).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:43:42 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 21:26:41 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:53:44 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Bertrand", "Quentin", ""], ["Klopfenstein", "Quentin", ""], ["Blondel", "Mathieu", ""], ["Vaiter", "Samuel", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "2002.08948", "submitter": "Adarsh Subbaswamy", "authors": "Adarsh Subbaswamy, Suchi Saria", "title": "I-SPEC: An End-to-End Framework for Learning Transportable, Shift-Stable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shifts in environment between development and deployment cause classical\nsupervised learning to produce models that fail to generalize well to new\ntarget distributions. Recently, many solutions which find invariant predictive\ndistributions have been developed. Among these, graph-based approaches do not\nrequire data from the target environment and can capture more stable\ninformation than alternative methods which find stable feature sets. However,\nthese approaches assume that the data generating process is known in the form\nof a full causal graph, which is generally not the case. In this paper, we\npropose I-SPEC, an end-to-end framework that addresses this shortcoming by\nusing data to learn a partial ancestral graph (PAG). Using the PAG we develop\nan algorithm that determines an interventional distribution that is stable to\nthe declared shifts; this subsumes existing approaches which find stable\nfeature sets that are less accurate. We apply I-SPEC to a mortality prediction\nproblem to show it can learn a model that is robust to shifts without needing\nupfront knowledge of the full causal DAG.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:56:04 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Subbaswamy", "Adarsh", ""], ["Saria", "Suchi", ""]]}, {"id": "2002.08949", "submitter": "Ruilin Li", "authors": "Ruilin Li, Xin Wang, Hongyuan Zha and Molei Tao", "title": "Improving Sampling Accuracy of Stochastic Gradient MCMC Methods via\n  Non-uniform Subsampling of Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic Gradient (SG-)MCMC methods for sampling statistical distributions\napproximate gradients by stochastic ones, commonly via uniformly subsampled\ndata points. We propose a non-uniform subsampling scheme to improve the\nsampling accuracy. The proposed exponentially weighted stochastic gradient\n(EWSG) is designed so that a non-uniform-SG-MCMC method mimics the statistical\nbehavior of a batch-gradient-MCMC method, and hence the inaccuracy due to SG\napproximation is reduced. EWSG differs from Variance Reduction (VR) techniques\nas it focuses on the entire distribution instead of just the variance;\nnevertheless, its reduced local variance is also proved. EWSG can also be\nviewed as an extension of the importance sampling idea, successful for SG-based\noptimizations, to sampling tasks. In our practical implementation of EWSG, the\nnon-uniform subsampling is performed efficiently via a Metropolis-Hasting chain\non the data index, which is coupled to the MCMC algorithm. Numerical\nexperiments are provided, not only to demonstrate EWSG's effectiveness, but\nalso to guide hyperparameter choices, and validate our \\emph{non-asymptotic\nglobal error bound} despite of approximations in the implementation. Notably,\nwhile statistical accuracy is improved, convergence speed can be comparable to\nthe uniform version, which renders EWSG a practical alternative to VR (but EWSG\nand VR can be combined too).\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 18:56:18 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:12:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Li", "Ruilin", ""], ["Wang", "Xin", ""], ["Zha", "Hongyuan", ""], ["Tao", "Molei", ""]]}, {"id": "2002.08953", "submitter": "Hsin-Yuan Huang", "authors": "Hsin-Yuan Huang, Richard Kueng, and John Preskill", "title": "Predicting Many Properties of a Quantum System from Very Few\n  Measurements", "comments": "10 pages, 9 figures + 30 page appendix; supersedes arXiv:1908.08909;\n  open source code available at\n  https://github.com/momohuang/predicting-quantum-properties", "journal-ref": "Nature Physics 16, 1050--1057 (2020)", "doi": "10.1038/s41567-020-0932-7", "report-no": null, "categories": "quant-ph cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting properties of complex, large-scale quantum systems is essential\nfor developing quantum technologies. We present an efficient method for\nconstructing an approximate classical description of a quantum state using very\nfew measurements of the state. This description, called a classical shadow, can\nbe used to predict many different properties: order $\\log M$ measurements\nsuffice to accurately predict $M$ different functions of the state with high\nsuccess probability. The number of measurements is independent of the system\nsize, and saturates information-theoretic lower bounds. Moreover, target\nproperties to predict can be selected after the measurements are completed. We\nsupport our theoretical findings with extensive numerical experiments. We apply\nclassical shadows to predict quantum fidelities, entanglement entropies,\ntwo-point correlation functions, expectation values of local observables, and\nthe energy variance of many-body local Hamiltonians. The numerical results\nhighlight the advantages of classical shadows relative to previously known\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:00:02 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 00:59:07 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Hsin-Yuan", ""], ["Kueng", "Richard", ""], ["Preskill", "John", ""]]}, {"id": "2002.08958", "submitter": "Mher Safaryan", "authors": "Mher Safaryan and Egor Shulgin and Peter Richt\\'arik", "title": "Uncertainty Principle for Communication Compression in Distributed and\n  Federated Learning and the Search for an Optimal Compressor", "comments": "23 pages, 6 figures, 2 tables", "journal-ref": "Information and Inference: A Journal of the IMA, 2021", "doi": "10.1093/imaiai/iaab006", "report-no": null, "categories": "cs.LG cs.DC cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to mitigate the high communication cost in distributed and federated\nlearning, various vector compression schemes, such as quantization,\nsparsification and dithering, have become very popular. In designing a\ncompression method, one aims to communicate as few bits as possible, which\nminimizes the cost per communication round, while at the same time attempting\nto impart as little distortion (variance) to the communicated messages as\npossible, which minimizes the adverse effect of the compression on the overall\nnumber of communication rounds. However, intuitively, these two goals are\nfundamentally in conflict: the more compression we allow, the more distorted\nthe messages become. We formalize this intuition and prove an {\\em uncertainty\nprinciple} for randomized compression operators, thus quantifying this\nlimitation mathematically, and {\\em effectively providing asymptotically tight\nlower bounds on what might be achievable with communication compression}.\nMotivated by these developments, we call for the search for the optimal\ncompression operator. In an attempt to take a first step in this direction, we\nconsider an unbiased compression method inspired by the Kashin representation\nof vectors, which we call {\\em Kashin compression (KC)}. In contrast to all\npreviously proposed compression mechanisms, KC enjoys a {\\em dimension\nindependent} variance bound for which we derive an explicit formula even in the\nregime when only a few bits need to be communicate per each vector entry.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:20:51 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 09:40:43 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 11:13:35 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Safaryan", "Mher", ""], ["Shulgin", "Egor", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.08972", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Efe Bozkir and Onur G\\\"unl\\\"u, Wolfgang Fuhl, Rafael F. Schaefer, and\n  Enkelejda Kasneci", "title": "Differential Privacy for Eye Tracking with Temporal Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New generation head-mounted displays, such as VR and AR glasses, are coming\ninto the market with already integrated eye tracking and are expected to enable\nnovel ways of human-computer interaction in many applications. However, since\neye movement properties contain biometric information, privacy concerns have to\nbe handled properly. Privacy-preservation techniques such as differential\nprivacy mechanisms have recently been applied to the eye movement data obtained\nfrom such displays. Standard differential privacy mechanisms; however, are\nvulnerable to temporal correlations in the eye movement features. In this work,\nwe propose a novel transform-coding based differential privacy mechanism to\nfurther adapt it to the statistics of eye movement feature data by comparing\nvarious low-complexity methods. We extent Fourier Perturbation Algorithm, which\nis a differential privacy mechanism, and correct a scaling mistake in its\nproof. Furthermore, we illustrate significant reductions in sample correlations\nin addition to query sensitivities, which provide the best utility-privacy\ntrade-off in the eye tracking literature. Our results show significantly high\nprivacy without loss in classification accuracies as well.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:01:34 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:04:54 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Bozkir", "Efe", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Fuhl", "Wolfgang", ""], ["Schaefer", "Rafael F.", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.08973", "submitter": "Raphael Gontijo-Lopes", "authors": "Raphael Gontijo-Lopes, Sylvia J. Smullin, Ekin D. Cubuk, Ethan Dyer", "title": "Affinity and Diversity: Quantifying Mechanisms of Data Augmentation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though data augmentation has become a standard component of deep neural\nnetwork training, the underlying mechanism behind the effectiveness of these\ntechniques remains poorly understood. In practice, augmentation policies are\noften chosen using heuristics of either distribution shift or augmentation\ndiversity. Inspired by these, we seek to quantify how data augmentation\nimproves model generalization. To this end, we introduce interpretable and\neasy-to-compute measures: Affinity and Diversity. We find that augmentation\nperformance is predicted not by either of these alone but by jointly optimizing\nthe two.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:02:02 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 19:04:48 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Gontijo-Lopes", "Raphael", ""], ["Smullin", "Sylvia J.", ""], ["Cubuk", "Ekin D.", ""], ["Dyer", "Ethan", ""]]}, {"id": "2002.08981", "submitter": "Stathi Fotiadis", "authors": "Stathi Fotiadis, Eduardo Pignatelli, Mario Lino Valencia, Chris\n  Cantwell, Amos Storkey, Anil A. Bharath", "title": "Comparing recurrent and convolutional neural networks for predicting\n  wave propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems can be modelled by partial differential equations and\nnumerical computations are used everywhere in science and engineering. In this\nwork, we investigate the performance of recurrent and convolutional deep neural\nnetwork architectures to predict the surface waves. The system is governed by\nthe Saint-Venant equations. We improve on the long-term prediction over\nprevious methods while keeping the inference time at a fraction of numerical\nsimulations. We also show that convolutional networks perform at least as well\nas recurrent networks in this task. Finally, we assess the generalisation\ncapability of each network by extrapolating in longer time-frames and in\ndifferent physical settings.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:15:04 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 18:05:20 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 14:28:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fotiadis", "Stathi", ""], ["Pignatelli", "Eduardo", ""], ["Valencia", "Mario Lino", ""], ["Cantwell", "Chris", ""], ["Storkey", "Amos", ""], ["Bharath", "Anil A.", ""]]}, {"id": "2002.08987", "submitter": "Muhammad Shahbaz", "authors": "Tushar Swamy, Alexander Rucker, Muhammad Shahbaz, and Kunle Olukotun", "title": "Taurus: An Intelligent Data Plane", "comments": "12 pages, 13 figures, and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging applications -- cloud computing, the internet of things, and\naugmented/virtual reality -- need responsive, available, secure, ubiquitous,\nand scalable datacenter networks. Network management currently uses simple,\nper-packet, data-plane heuristics (e.g., ECMP and sketches) under an\nintelligent, millisecond-latency control plane that runs data-driven\nperformance and security policies. However, to meet users' quality-of-service\nexpectations in a modern data center, networks must operate intelligently at\nline rate. In this paper, we present Taurus, an intelligent data plane capable\nof machine-learning inference at line rate. Taurus adds custom hardware based\non a map-reduce abstraction to programmable network devices, such as switches\nand NICs; this new hardware uses pipelined and SIMD parallelism for fast\ninference. Our evaluation of a Taurus-enabled switch ASIC -- supporting several\nreal-world benchmarks -- shows that Taurus operates three orders of magnitude\nfaster than a server-based control plane, while increasing area by 24% and\nlatency, on average, by 178 ns. On the long road to self-driving networks,\nTaurus is the equivalent of adaptive cruise control: deterministic rules steer\nflows, while machine learning tunes performance and heightens security.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:18:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Swamy", "Tushar", ""], ["Rucker", "Alexander", ""], ["Shahbaz", "Muhammad", ""], ["Olukotun", "Kunle", ""]]}, {"id": "2002.08991", "submitter": "Keno Bressem", "authors": "Keno K. Bressem, Lisa Adams, Christoph Erxleben, Bernd Hamm, Stefan\n  Niehues, Janis Vahldiek", "title": "Comparing Different Deep Learning Architectures for Classification of\n  Chest Radiographs", "comments": "15 pages, 6 figures, 3 tables", "journal-ref": null, "doi": "10.1038/s41598-020-70479-z", "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chest radiographs are among the most frequently acquired images in radiology\nand are often the subject of computer vision research. However, most of the\nmodels used to classify chest radiographs are derived from openly available\ndeep neural networks, trained on large image-datasets. These datasets routinely\ndiffer from chest radiographs in that they are mostly color images and contain\nseveral possible image classes, while radiographs are greyscale images and\noften only contain fewer image classes. Therefore, very deep neural networks,\nwhich can represent more complex relationships in image-features, might not be\nrequired for the comparatively simpler task of classifying grayscale chest\nradiographs. We compared fifteen different architectures of artificial neural\nnetworks regarding training-time and performance on the openly available\nCheXpert dataset to identify the most suitable models for deep learning tasks\non chest radiographs. We could show, that smaller networks such as ResNet-34,\nAlexNet or VGG-16 have the potential to classify chest radiographs as precisely\nas deeper neural networks such as DenseNet-201 or ResNet-151, while being less\ncomputationally demanding.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:47:16 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bressem", "Keno K.", ""], ["Adams", "Lisa", ""], ["Erxleben", "Christoph", ""], ["Hamm", "Bernd", ""], ["Niehues", "Stefan", ""], ["Vahldiek", "Janis", ""]]}, {"id": "2002.08994", "submitter": "Christopher Liaw", "authors": "Nicholas J. A. Harvey, Christopher Liaw, Edwin Perkins, Sikander\n  Randhawa", "title": "Optimal anytime regret with two experts", "comments": "41 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiplicative weights method is an algorithm for the problem of\nprediction with expert advice. It achieves the minimax regret asymptotically if\nthe number of experts is large, and the time horizon is known in advance.\nOptimal algorithms are also known if there are exactly two or three experts,\nand the time horizon is known in advance.\n  In the anytime setting, where the time horizon is not known in advance,\nalgorithms can be obtained by the doubling trick, but they are not optimal, let\nalone practical. No minimax optimal algorithm was previously known in the\nanytime setting, regardless of the number of experts.\n  We design the first minimax optimal algorithm for minimizing regret in the\nanytime setting. We consider the case of two experts, and prove that the\noptimal regret is $\\gamma \\sqrt{t} / 2$ at all time steps $t$, where $\\gamma$\nis a natural constant that arose 35 years ago in studying fundamental\nproperties of Brownian motion. The algorithm is designed by considering a\ncontinuous analogue, which is solved using ideas from stochastic calculus.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:04:32 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Harvey", "Nicholas J. A.", ""], ["Liaw", "Christopher", ""], ["Perkins", "Edwin", ""], ["Randhawa", "Sikander", ""]]}, {"id": "2002.09000", "submitter": "Kevin Amaral", "authors": "Kevin M. Amaral, Zihan Li, Wei Ding, Scott Crouter, Ping Chen", "title": "SummerTime: Variable-length Time SeriesSummarization with Applications\n  to PhysicalActivity Analysis", "comments": "11 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{SummerTime} seeks to summarize globally time series signals and\nprovides a fixed-length, robust summarization of the variable-length time\nseries. Many classical machine learning methods for classification and\nregression depend on data instances with a fixed number of features. As a\nresult, those methods cannot be directly applied to variable-length time series\ndata. One common approach is to perform classification over a sliding window on\nthe data and aggregate the decisions made at local sections of the time series\nin some way, through majority voting for classification or averaging for\nregression. The downside to this approach is that minority local information is\nlost in the voting process and averaging assumes that each time series\nmeasurement is equal in significance. Also, since time series can be of varying\nlength, the quality of votes and averages could vary greatly in cases where\nthere is a close voting tie or bimodal distribution of regression domain.\nSummarization conducted by the \\textit{SummerTime} method will be a\nfixed-length feature vector which can be used in-place of the time series\ndataset for use with classical machine learning methods. We use Gaussian\nMixture models (GMM) over small same-length disjoint windows in the time series\nto group local data into clusters. The time series' rate of membership for each\ncluster will be a feature in the summarization. The model is naturally capable\nof converging to an appropriate cluster count. We compare our results to\nstate-of-the-art studies in physical activity classification and show\nhigh-quality improvement by classifying with only the summarization. Finally,\nwe show that regression using the summarization can augment energy expenditure\nestimation, producing more robust and precise results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:20:06 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Amaral", "Kevin M.", ""], ["Li", "Zihan", ""], ["Ding", "Wei", ""], ["Crouter", "Scott", ""], ["Chen", "Ping", ""]]}, {"id": "2002.09018", "submitter": "Rohan Anil", "authors": "Rohan Anil, Vineet Gupta, Tomer Koren, Kevin Regan and Yoram Singer", "title": "Scalable Second Order Optimization for Deep Learning", "comments": "24 pages, Code available here: https://bit.ly/3uXXtKy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization in machine learning, both theoretical and applied, is presently\ndominated by first-order gradient methods such as stochastic gradient descent.\nSecond-order optimization methods, that involve second derivatives and/or\nsecond order statistics of the data, are far less prevalent despite strong\ntheoretical properties, due to their prohibitive computation, memory and\ncommunication costs. In an attempt to bridge this gap between theoretical and\npractical optimization, we present a scalable implementation of a second-order\npreconditioned method (concretely, a variant of full-matrix Adagrad), that\nalong with several critical algorithmic and numerical improvements, provides\nsignificant convergence and wall-clock time improvements compared to\nconventional first-order methods on state-of-the-art deep models. Our novel\ndesign effectively utilizes the prevalent heterogeneous hardware architecture\nfor training deep models, consisting of a multicore CPU coupled with multiple\naccelerator units. We demonstrate superior performance compared to\nstate-of-the-art on very large learning tasks such as machine translation with\nTransformers, language modeling with BERT, click-through rate prediction on\nCriteo, and image classification on ImageNet with ResNet-50.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 20:51:33 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 06:29:48 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Anil", "Rohan", ""], ["Gupta", "Vineet", ""], ["Koren", "Tomer", ""], ["Regan", "Kevin", ""], ["Singer", "Yoram", ""]]}, {"id": "2002.09021", "submitter": "Jianyu Fan", "authors": "Jianyu Fan, Yi-Hsuan Yang, Kui Dong, and Philippe Pasquier", "title": "A Comparative Study of Western and Chinese Classical Music based on\n  Soundscape Models", "comments": "Paper accepted for 45th International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether literally or suggestively, the concept of soundscape is alluded in\nboth modern and ancient music. In this study, we examine whether we can analyze\nand compare Western and Chinese classical music based on soundscape models. We\naddressed this question through a comparative study. Specifically, corpora of\nWestern classical music excerpts (WCMED) and Chinese classical music excerpts\n(CCMED) were curated and annotated with emotional valence and arousal through a\ncrowdsourcing experiment. We used a sound event detection (SED) and soundscape\nemotion recognition (SER) models with transfer learning to predict the\nperceived emotion of WCMED and CCMED. The results show that both SER and SED\nmodels could be used to analyze Chinese and Western classical music. The fact\nthat SER and SED work better on Chinese classical music emotion recognition\nprovides evidence that certain similarities exist between Chinese classical\nmusic and soundscape recordings, which permits transferability between machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:16:27 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Fan", "Jianyu", ""], ["Yang", "Yi-Hsuan", ""], ["Dong", "Kui", ""], ["Pasquier", "Philippe", ""]]}, {"id": "2002.09024", "submitter": "Chengyue Gong", "authors": "Chengyue Gong, Tongzheng Ren, Mao Ye, Qiang Liu", "title": "MaxUp: A Simple Way to Improve Generalization of Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose \\emph{MaxUp}, an embarrassingly simple, highly effective technique\nfor improving the generalization performance of machine learning models,\nespecially deep neural networks. The idea is to generate a set of augmented\ndata with some random perturbations or transforms and minimize the maximum, or\nworst case loss over the augmented data. By doing so, we implicitly introduce a\nsmoothness or robustness regularization against the random perturbations, and\nhence improve the generation performance. For example, in the case of Gaussian\nperturbation,\n  \\emph{MaxUp} is asymptotically equivalent to using the gradient norm of the\nloss as a penalty to encourage smoothness. We test \\emph{MaxUp} on a range of\ntasks, including image classification, language modeling, and adversarial\ncertification, on which \\emph{MaxUp} consistently outperforms the existing best\nbaseline methods, without introducing substantial computational overhead. In\nparticular, we improve ImageNet classification from the state-of-the-art top-1\naccuracy $85.5\\%$ without extra data to $85.8\\%$. Code will be released soon.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:20:28 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Gong", "Chengyue", ""], ["Ren", "Tongzheng", ""], ["Ye", "Mao", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09026", "submitter": "Jianyu Fan", "authors": "Jianyu Fan, Eric Nichols, Daniel Tompkins, Ana Elisa Mendez Mendez,\n  Benjamin Elizalde, and Philippe Pasquier", "title": "Multi-label Sound Event Retrieval Using a Deep Learning-based Siamese\n  Structure with a Pairwise Presence Matrix", "comments": "Paper accepted for 45th International Conference on Acoustics,\n  Speech, and Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Realistic recordings of soundscapes often have multiple sound events\nco-occurring, such as car horns, engine and human voices. Sound event retrieval\nis a type of content-based search aiming at finding audio samples, similar to\nan audio query based on their acoustic or semantic content. State of the art\nsound event retrieval models have focused on single-label audio recordings,\nwith only one sound event occurring, rather than on multi-label audio\nrecordings (i.e., multiple sound events occur in one recording). To address\nthis latter problem, we propose different Deep Learning architectures with a\nSiamese-structure and a Pairwise Presence Matrix. The networks are trained and\nevaluated using the SONYC-UST dataset containing both single- and multi-label\nsoundscape recordings. The performance results show the effectiveness of our\nproposed model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:33:07 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Fan", "Jianyu", ""], ["Nichols", "Eric", ""], ["Tompkins", "Daniel", ""], ["Mendez", "Ana Elisa Mendez", ""], ["Elizalde", "Benjamin", ""], ["Pasquier", "Philippe", ""]]}, {"id": "2002.09027", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Yi Ouyang, I-Te Danny Hung,\n  Chin-Hui Lee, Xiaoli Ma", "title": "Enhanced Adversarial Strategically-Timed Attacks against Deep\n  Reinforcement Learning", "comments": "Accepted to IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent deep neural networks based techniques, especially those equipped with\nthe ability of self-adaptation in the system level such as deep reinforcement\nlearning (DRL), are shown to possess many advantages of optimizing robot\nlearning systems (e.g., autonomous navigation and continuous robot arm\ncontrol.) However, the learning-based systems and the associated models may be\nthreatened by the risks of intentionally adaptive (e.g., noisy sensor\nconfusion) and adversarial perturbations from real-world scenarios. In this\npaper, we introduce timing-based adversarial strategies against a DRL-based\nnavigation system by jamming in physical noise patterns on the selected time\nframes. To study the vulnerability of learning-based navigation systems, we\npropose two adversarial agent models: one refers to online learning; another\none is based on evolutionary learning. Besides, three open-source robot\nlearning and navigation control environments are employed to study the\nvulnerability under adversarial timing attacks. Our experimental results show\nthat the adversarial timing attacks can lead to a significant performance drop,\nand also suggest the necessity of enhancing the robustness of robot learning\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 21:39:25 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ouyang", "Yi", ""], ["Hung", "I-Te Danny", ""], ["Lee", "Chin-Hui", ""], ["Ma", "Xiaoli", ""]]}, {"id": "2002.09030", "submitter": "Augustus Odena", "authors": "Augustus Odena, Charles Sutton", "title": "Learning to Represent Programs with Property Signatures", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of property signatures, a representation for programs\nand program specifications meant for consumption by machine learning\nalgorithms. Given a function with input type $\\tau_{in}$ and output type\n$\\tau_{out}$, a property is a function of type: $(\\tau_{in}, \\tau_{out})\n\\rightarrow \\texttt{Bool}$ that (informally) describes some simple property of\nthe function under consideration. For instance, if $\\tau_{in}$ and $\\tau_{out}$\nare both lists of the same type, one property might ask `is the input list the\nsame length as the output list?'. If we have a list of such properties, we can\nevaluate them all for our function to get a list of outputs that we will call\nthe property signature. Crucially, we can `guess' the property signature for a\nfunction given only a set of input/output pairs meant to specify that function.\nWe discuss several potential applications of property signatures and show\nexperimentally that they can be used to improve over a baseline synthesizer so\nthat it emits twice as many programs in less than one-tenth of the time.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 01:50:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Odena", "Augustus", ""], ["Sutton", "Charles", ""]]}, {"id": "2002.09038", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Ilija Bogunovic, Stefanie Jegelka, Andreas Krause", "title": "Distributionally Robust Bayesian Optimization", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness to distributional shift is one of the key challenges of\ncontemporary machine learning. Attaining such robustness is the goal of\ndistributionally robust optimization, which seeks a solution to an optimization\nproblem that is worst-case robust under a specified distributional shift of an\nuncontrolled covariate. In this paper, we study such a problem when the\ndistributional shift is measured via the maximum mean discrepancy (MMD). For\nthe setting of zeroth-order, noisy optimization, we present a novel\ndistributionally robust Bayesian optimization algorithm (DRBO). Our algorithm\nprovably obtains sub-linear robust regret in various settings that differ in\nhow the uncertain covariate is observed. We demonstrate the robust performance\nof our method on both synthetic and real-world benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:04:30 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 08:23:36 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 10:40:30 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Kirschner", "Johannes", ""], ["Bogunovic", "Ilija", ""], ["Jegelka", "Stefanie", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.09043", "submitter": "David Venuto", "authors": "David Venuto, Jhelum Chakravorty, Leonard Boussioux, Junhao Wang,\n  Gavin McCracken, Doina Precup", "title": "oIRL: Robust Adversarial Inverse Reinforcement Learning with Temporally\n  Extended Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Explicit engineering of reward functions for given environments has been a\nmajor hindrance to reinforcement learning methods. While Inverse Reinforcement\nLearning (IRL) is a solution to recover reward functions from demonstrations\nonly, these learned rewards are generally heavily \\textit{entangled} with the\ndynamics of the environment and therefore not portable or \\emph{robust} to\nchanging environments. Modern adversarial methods have yielded some success in\nreducing reward entanglement in the IRL setting. In this work, we leverage one\nsuch method, Adversarial Inverse Reinforcement Learning (AIRL), to propose an\nalgorithm that learns hierarchical disentangled rewards with a policy over\noptions. We show that this method has the ability to learn \\emph{generalizable}\npolicies and reward functions in complex transfer learning tasks, while\nyielding results in continuous control benchmarks that are comparable to those\nof the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:21:41 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Venuto", "David", ""], ["Chakravorty", "Jhelum", ""], ["Boussioux", "Leonard", ""], ["Wang", "Junhao", ""], ["McCracken", "Gavin", ""], ["Precup", "Doina", ""]]}, {"id": "2002.09044", "submitter": "Philip Paquette", "authors": "Philip Paquette", "title": "A Road Map to Strong Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I wrote this paper because technology can really improve people's lives. With\nit, we can live longer in a healthy body, save time through increased\nefficiency and automation, and make better decisions. To get to the next level,\nwe need to start looking at intelligence from a much broader perspective, and\npromote international interdisciplinary collaborations. Section 1 of this paper\ndelves into sociology and social psychology to explain that the mechanisms\nunderlying intelligence are inherently social. Section 2 proposes a method to\nclassify intelligence, and describes the differences between weak and strong\nintelligence. Section 3 examines the Chinese Room argument from a different\nperspective. It demonstrates that a Turing-complete machine cannot have strong\nintelligence, and considers the modifications necessary for a computer to be\nintelligent and have understanding. Section 4 argues that the existential risk\ncaused by the technological explosion of a single agent should not be of\nserious concern. Section 5 looks at the AI control problem and argues that it\nis impossible to build a super-intelligent machine that will do what it\ncreators want. By using insights from biology, it also proposes a solution to\nthe control problem. Section 6 discusses some of the implications of strong\nintelligence. Section 7 lists the main challenges with deep learning, and\nasserts that radical changes will be required to reach strong intelligence.\nSection 8 examines a neuroscience framework that could help explain how a\ncortical column works. Section 9 lays out the broad strokes of a road map\ntowards strong intelligence. Finally, section 10 analyzes the impacts and the\nchallenges of greater intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:22:50 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Paquette", "Philip", ""]]}, {"id": "2002.09046", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Huan Wang, Caiming Xiong, Richard Socher, Yoshua Bengio", "title": "Neural Bayes: A Generic Parameterization Method for Unsupervised\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a parameterization method called Neural Bayes which allows\ncomputing statistical quantities that are in general difficult to compute and\nopens avenues for formulating new objectives for unsupervised representation\nlearning. Specifically, given an observed random variable $\\mathbf{x}$ and a\nlatent discrete variable $z$, we can express $p(\\mathbf{x}|z)$,\n$p(z|\\mathbf{x})$ and $p(z)$ in closed form in terms of a sufficiently\nexpressive function (Eg. neural network) using our parameterization without\nrestricting the class of these distributions. To demonstrate its usefulness, we\ndevelop two independent use cases for this parameterization:\n  1. Mutual Information Maximization (MIM): MIM has become a popular means for\nself-supervised representation learning. Neural Bayes allows us to compute\nmutual information between observed random variables $\\mathbf{x}$ and latent\ndiscrete random variables $z$ in closed form. We use this for learning image\nrepresentations and show its usefulness on downstream classification tasks.\n  2. Disjoint Manifold Labeling: Neural Bayes allows us to formulate an\nobjective which can optimally label samples from disjoint manifolds present in\nthe support of a continuous distribution. This can be seen as a specific form\nof clustering where each disjoint manifold in the support is a separate\ncluster. We design clustering tasks that obey this formulation and empirically\nshow that the model optimally labels the disjoint manifolds. Our code is\navailable at \\url{https://github.com/salesforce/NeuralBayes}\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:28:53 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Arpit", "Devansh", ""], ["Wang", "Huan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2002.09047", "submitter": "Xiao Xu", "authors": "Xiao Xu, Qing Zhao", "title": "Distributed No-Regret Learning in Multi-Agent Systems", "comments": "Accepted for publication in IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial article, we give an overview of new challenges and\nrepresentative results on distributed no-regret learning in multi-agent systems\nmodeled as repeated unknown games. Four emerging game\ncharacteristics---dynamicity, incomplete and imperfect feedback, bounded\nrationality, and heterogeneity---that challenge canonical game models are\nexplored. For each of the four characteristics, we illuminate its implications\nand ramifications in game modeling, notions of regret, feasible game outcomes,\nand the design and analysis of distributed learning algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:30:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Xu", "Xiao", ""], ["Zhao", "Qing", ""]]}, {"id": "2002.09049", "submitter": "Xingchao Liu", "authors": "Xingchao Liu, Mao Ye, Dengyong Zhou, Qiang Liu", "title": "Post-training Quantization with Multiple Points: Mixed Precision without\n  Mixed Precision", "comments": "Accepted by AAAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the post-training quantization problem, which discretizes the\nweights of pre-trained deep neural networks without re-training the model. We\npropose multipoint quantization, a quantization method that approximates a\nfull-precision weight vector using a linear combination of multiple vectors of\nlow-bit numbers; this is in contrast to typical quantization methods that\napproximate each weight using a single low precision number. Computationally,\nwe construct the multipoint quantization with an efficient greedy selection\nprocedure, and adaptively decides the number of low precision points on each\nquantized weight vector based on the error of its output. This allows us to\nachieve higher precision levels for important weights that greatly influence\nthe outputs, yielding an 'effect of mixed precision' but without physical mixed\nprecision implementations (which requires specialized hardware accelerators).\nEmpirically, our method can be implemented by common operands, bringing almost\nno memory and computation overhead. We show that our method outperforms a range\nof state-of-the-art methods on ImageNet classification and it can be\ngeneralized to more challenging tasks like PASCAL VOC object detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:37:45 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 07:20:56 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 15:25:38 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Liu", "Xingchao", ""], ["Ye", "Mao", ""], ["Zhou", "Dengyong", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09051", "submitter": "Vincent Roulet", "authors": "Vincent Roulet and Zaid Harchaoui", "title": "An Elementary Approach to Convergence Guarantees of Optimization\n  Algorithms for Deep Networks", "comments": "The changes from v1 to v2 include i) slightly more general results;\n  ii) slightly more concise proofs; iii) highway and residual networks; iv)\n  implicitly defined network layers; v) additional algorithm boxes and\n  illustration figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to obtain convergence guarantees of optimization\nalgorithms for deep networks based on elementary arguments and computations.\nThe convergence analysis revolves around the analytical and computational\nstructures of optimization oracles central to the implementation of deep\nnetworks in machine learning software. We provide a systematic way to compute\nestimates of the smoothness constants that govern the convergence behavior of\nfirst-order optimization algorithms used to train deep networks. A diverse set\nof example components and architectures arising in modern deep networks\nintersperse the exposition to illustrate the approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:40:52 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 02:47:52 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Roulet", "Vincent", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.09054", "submitter": "Lionel Robert", "authors": "Lionel P. Robert, Casey Pierce, Liz Morris, Sangmi Kim, Rasha Alahmad", "title": "Designing Fair AI for Managing Employees in Organizations: A Review,\n  Critique, and Design Agenda", "comments": "66 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations are rapidly deploying artificial intelligence (AI) systems to\nmanage their workers. However, AI has been found at times to be unfair to\nworkers. Unfairness toward workers has been associated with decreased worker\neffort and increased worker turnover. To avoid such problems, AI systems must\nbe designed to support fairness and redress instances of unfairness. Despite\nthe attention related to AI unfairness, there has not been a theoretical and\nsystematic approach to developing a design agenda. This paper addresses the\nissue in three ways. First, we introduce the organizational justice theory,\nthree different fairness types (distributive, procedural, interactional), and\nthe frameworks for redressing instances of unfairness (retributive justice,\nrestorative justice). Second, we review the design literature that specifically\nfocuses on issues of AI fairness in organizations. Third, we propose a design\nagenda for AI fairness in organizations that applies each of the fairness types\nto organizational scenarios. Then, the paper concludes with implications for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:52:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Robert", "Lionel P.", ""], ["Pierce", "Casey", ""], ["Morris", "Liz", ""], ["Kim", "Sangmi", ""], ["Alahmad", "Rasha", ""]]}, {"id": "2002.09062", "submitter": "Weiqi Ji", "authors": "Weiqi Ji and Sili Deng", "title": "Autonomous Discovery of Unknown Reaction Pathways from Data by Chemical\n  Reaction Neural Network", "comments": null, "journal-ref": "The Journal of Physical Chemistry A, 2021", "doi": "10.1021/acs.jpca.0c09316", "report-no": null, "categories": "q-bio.MN cs.LG physics.chem-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Chemical reactions occur in energy, environmental, biological, and many other\nnatural systems, and the inference of the reaction networks is essential to\nunderstand and design the chemical processes in engineering and life sciences.\nYet, revealing the reaction pathways for complex systems and processes is still\nchallenging due to the lack of knowledge of the involved species and reactions.\nHere, we present a neural network approach that autonomously discovers reaction\npathways from the time-resolved species concentration data. The proposed\nChemical Reaction Neural Network (CRNN), by design, satisfies the fundamental\nphysics laws, including the Law of Mass Action and the Arrhenius Law.\nConsequently, the CRNN is physically interpretable such that the reaction\npathways can be interpreted, and the kinetic parameters can be quantified\nsimultaneously from the weights of the neural network. The inference of the\nchemical pathways is accomplished by training the CRNN with species\nconcentration data via stochastic gradient descent. We demonstrate the\nsuccessful implementations and the robustness of the approach in elucidating\nthe chemical reaction pathways of several chemical engineering and biochemical\nsystems. The autonomous inference by the CRNN approach precludes the need for\nexpert knowledge in proposing candidate networks and addresses the curse of\ndimensionality in complex systems. The physical interpretability also makes the\nCRNN capable of not only fitting the data for a given system but also\ndeveloping knowledge of unknown pathways that could be generalized to similar\nchemical systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 23:36:46 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 22:18:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Ji", "Weiqi", ""], ["Deng", "Sili", ""]]}, {"id": "2002.09067", "submitter": "Kensen Shi", "authors": "Kensen Shi, David Bieber, Charles Sutton", "title": "Incremental Sampling Without Replacement for Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is a fundamental technique, and sampling without replacement is\noften desirable when duplicate samples are not beneficial. Within machine\nlearning, sampling is useful for generating diverse outputs from a trained\nmodel. We present an elegant procedure for sampling without replacement from a\nbroad class of randomized programs, including generative neural models that\nconstruct outputs sequentially. Our procedure is efficient even for\nexponentially-large output spaces. Unlike prior work, our approach is\nincremental, i.e., samples can be drawn one at a time, allowing for increased\nflexibility. We also present a new estimator for computing expectations from\nsamples drawn without replacement. We show that incremental sampling without\nreplacement is applicable to many domains, e.g., program synthesis and\ncombinatorial optimization.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:12:01 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 00:09:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Shi", "Kensen", ""], ["Bieber", "David", ""], ["Sutton", "Charles", ""]]}, {"id": "2002.09070", "submitter": "Mao Ye", "authors": "Mao Ye, Tongzheng Ren, Qiang Liu", "title": "Stein Self-Repulsive Dynamics: Benefits From Past Samples", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Stein self-repulsive dynamics for obtaining diversified\nsamples from intractable un-normalized distributions. Our idea is to introduce\nStein variational gradient as a repulsive force to push the samples of Langevin\ndynamics away from the past trajectories. This simple idea allows us to\nsignificantly decrease the auto-correlation in Langevin dynamics and hence\nincrease the effective sample size. Importantly, as we establish in our\ntheoretical analysis, the asymptotic stationary distribution remains correct\neven with the addition of the repulsive force, thanks to the special properties\nof the Stein variational gradient. We perform extensive empirical studies of\nour new algorithm, showing that our method yields much higher sample efficiency\nand better uncertainty estimation than vanilla Langevin dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:26:38 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 05:36:41 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Ye", "Mao", ""], ["Ren", "Tongzheng", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09072", "submitter": "Ruiyi Zhang", "authors": "Ruiyi Zhang, Bo Dai, Lihong Li, Dale Schuurmans", "title": "GenDICE: Generalized Offline Estimation of Stationary Values", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem that arises in reinforcement learning and Monte Carlo\nmethods is estimating quantities defined by the stationary distribution of a\nMarkov chain. In many real-world applications, access to the underlying\ntransition operator is limited to a fixed set of data that has already been\ncollected, without additional interaction with the environment being available.\nWe show that consistent estimation remains possible in this challenging\nscenario, and that effective estimation can still be achieved in important\napplications. Our approach is based on estimating a ratio that corrects for the\ndiscrepancy between the stationary and empirical distributions, derived from\nfundamental properties of the stationary distribution, and exploiting\nconstraint reformulations based on variational divergence minimization. The\nresulting algorithm, GenDICE, is straightforward and effective. We prove its\nconsistency under general conditions, provide an error analysis, and\ndemonstrate strong empirical performance on benchmark problems, including\noff-line PageRank and off-policy policy evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:27:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Ruiyi", ""], ["Dai", "Bo", ""], ["Li", "Lihong", ""], ["Schuurmans", "Dale", ""]]}, {"id": "2002.09073", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Rajiv Khanna and Michael W. Mahoney", "title": "Improved guarantees and a multiple-descent curve for Column Subset\n  Selection and the Nystr\\\"om method", "comments": "Minor typo corrections and clarifications; slight change in the\n  title; moved part of the related work and background discussion to the\n  appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Column Subset Selection Problem (CSSP) and the Nystr\\\"om method are among\nthe leading tools for constructing small low-rank approximations of large\ndatasets in machine learning and scientific computing. A fundamental question\nin this area is: how well can a data subset of size k compete with the best\nrank k approximation? We develop techniques which exploit spectral properties\nof the data matrix to obtain improved approximation guarantees which go beyond\nthe standard worst-case analysis. Our approach leads to significantly better\nbounds for datasets with known rates of singular value decay, e.g., polynomial\nor exponential decay. Our analysis also reveals an intriguing phenomenon: the\napproximation factor as a function of k may exhibit multiple peaks and valleys,\nwhich we call a multiple-descent curve. A lower bound we establish shows that\nthis behavior is not an artifact of our analysis, but rather it is an inherent\nproperty of the CSSP and Nystr\\\"om tasks. Finally, using the example of a\nradial basis function (RBF) kernel, we show that both our improved bounds and\nthe multiple-descent curve can be observed on real datasets simply by varying\nthe RBF parameter.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 00:43:06 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 01:22:04 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 21:19:09 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Khanna", "Rajiv", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.09077", "submitter": "Guannan Zhang", "authors": "Jiaxing Zhang, Hoang Tran, Guannan Zhang", "title": "Accelerating Reinforcement Learning with a\n  Directional-Gaussian-Smoothing Evolution Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution strategy (ES) has been shown great promise in many challenging\nreinforcement learning (RL) tasks, rivaling other state-of-the-art deep RL\nmethods. Yet, there are two limitations in the current ES practice that may\nhinder its otherwise further capabilities. First, most current methods rely on\nMonte Carlo type gradient estimators to suggest search direction, where the\npolicy parameter is, in general, randomly sampled. Due to the low accuracy of\nsuch estimators, the RL training may suffer from slow convergence and require\nmore iterations to reach optimal solution. Secondly, the landscape of reward\nfunctions can be deceptive and contains many local maxima, causing ES\nalgorithms to prematurely converge and be unable to explore other parts of the\nparameter space with potentially greater rewards. In this work, we employ a\nDirectional Gaussian Smoothing Evolutionary Strategy (DGS-ES) to accelerate RL\ntraining, which is well-suited to address these two challenges with its ability\nto i) provide gradient estimates with high accuracy, and ii) find nonlocal\nsearch direction which lays stress on large-scale variation of the reward\nfunction and disregards local fluctuation. Through several benchmark RL tasks\ndemonstrated herein, we show that DGS-ES is highly scalable, possesses superior\nwall-clock time, and achieves competitive reward scores to other popular policy\ngradient and ES approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:05:57 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Jiaxing", ""], ["Tran", "Hoang", ""], ["Zhang", "Guannan", ""]]}, {"id": "2002.09080", "submitter": "Essam Rashed", "authors": "Essam A. Rashed and Jose Gomez-Tames and Akimasa Hirata", "title": "Development of accurate human head models for personalized\n  electromagnetic dosimetry using deep learning", "comments": null, "journal-ref": "NeuroImage 202, pp. 116132, 2019", "doi": "10.1016/j.neuroimage.2019.116132", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of personalized human head models from medical images has\nbecome an important topic in the electromagnetic dosimetry field, including the\noptimization of electrostimulation, safety assessments, etc. Human head models\nare commonly generated via the segmentation of magnetic resonance images into\ndifferent anatomical tissues. This process is time consuming and requires\nspecial experience for segmenting a relatively large number of tissues. Thus,\nit is challenging to accurately compute the electric field in different\nspecific brain regions. Recently, deep learning has been applied for the\nsegmentation of the human brain. However, most studies have focused on the\nsegmentation of brain tissue only and little attention has been paid to other\ntissues, which are considerably important for electromagnetic dosimetry.\n  In this study, we propose a new architecture for a convolutional neural\nnetwork, named ForkNet, to perform the segmentation of whole human head\nstructures, which is essential for evaluating the electrical field distribution\nin the brain. The proposed network can be used to generate personalized head\nmodels and applied for the evaluation of the electric field in the brain during\ntranscranial magnetic stimulation. Our computational results indicate that the\nhead models generated using the proposed network exhibit strong matching with\nthose created via manual segmentation in an intra-scanner segmentation task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 01:21:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Rashed", "Essam A.", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2002.09089", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Russell Coleman, Ravi Srinivasan, Scott Niekum", "title": "Safe Imitation Learning via Fast Bayesian Reward Inference from\n  Preferences", "comments": "In proceedings ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian reward learning from demonstrations enables rigorous safety and\nuncertainty analysis when performing imitation learning. However, Bayesian\nreward learning methods are typically computationally intractable for complex\ncontrol problems. We propose Bayesian Reward Extrapolation (Bayesian REX), a\nhighly efficient Bayesian reward learning algorithm that scales to\nhigh-dimensional imitation learning problems by pre-training a low-dimensional\nfeature encoding via self-supervised tasks and then leveraging preferences over\ndemonstrations to perform fast Bayesian inference. Bayesian REX can learn to\nplay Atari games from demonstrations, without access to the game score and can\ngenerate 100,000 samples from the posterior over reward functions in only 5\nminutes on a personal laptop. Bayesian REX also results in imitation learning\nperformance that is competitive with or better than state-of-the-art methods\nthat only learn point estimates of the reward function. Finally, Bayesian REX\nenables efficient high-confidence policy evaluation without having access to\nsamples of the reward function. These high-confidence performance bounds can be\nused to rank the performance and risk of a variety of evaluation policies and\nprovide a way to detect reward hacking behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:04:54 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 04:42:38 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 17:55:39 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 21:48:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Brown", "Daniel S.", ""], ["Coleman", "Russell", ""], ["Srinivasan", "Ravi", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.09094", "submitter": "Kazuo Aoyama", "authors": "Kazuo Aoyama, Kazumi Saito, and Tetsuo Ikeda", "title": "Inverted-File k-Means Clustering: Performance Analysis", "comments": "15 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an inverted-file k-means clustering algorithm (IVF)\nsuitable for a large-scale sparse data set with potentially numerous classes.\nGiven such a data set, IVF efficiently works at high-speed and with low memory\nconsumption, which keeps the same solution as a standard Lloyd's algorithm. The\nhigh performance arises from two distinct data representations. One is a sparse\nexpression for both the object and mean feature vectors. The other is an\ninverted-file data structure for a set of the mean feature vectors. To confirm\nthe effect of these representations, we design three algorithms using distinct\ndata structures and expressions for comparison. We experimentally demonstrate\nthat IVF achieves better performance than the designed algorithms when they are\napplied to large-scale real document data sets in a modern computer system\nequipped with superscalar out-of-order processors and a deep hierarchical\nmemory system. We also introduce a simple yet practical clock-cycle per\ninstruction (CPI) model for speed-performance analysis. Analytical results\nreveal that IVF suppresses three performance degradation factors: the numbers\nof cache misses, branch mispredictions, and the completed instructions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:20:33 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Aoyama", "Kazuo", ""], ["Saito", "Kazumi", ""], ["Ikeda", "Tetsuo", ""]]}, {"id": "2002.09096", "submitter": "Olivia Choudhury", "authors": "Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa\n  Sylla, Yoonyoung Park, Grace Hsu, Amar Das", "title": "Anonymizing Data for Privacy-Preserving Federated Learning", "comments": "24th European Conference on Artificial Intelligence (ECAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables training a global machine learning model from data\ndistributed across multiple sites, without having to move the data. This is\nparticularly relevant in healthcare applications, where data is rife with\npersonal, highly-sensitive information, and data analysis methods must provably\ncomply with regulatory guidelines. Although federated learning prevents sharing\nraw data, it is still possible to launch privacy attacks on the model\nparameters that are exposed during the training process, or on the generated\nmachine learning model. In this paper, we propose the first syntactic approach\nfor offering privacy in the context of federated learning. Unlike the\nstate-of-the-art differential privacy-based frameworks, our approach aims to\nmaximize utility or model performance, while supporting a defensible level of\nprivacy, as demanded by GDPR and HIPAA. We perform a comprehensive empirical\nevaluation on two important problems in the healthcare domain, using real-world\nelectronic health data of 1 million patients. The results demonstrate the\neffectiveness of our approach in achieving high model performance, while\noffering the desired level of privacy. Through comparative studies, we also\nshow that, for varying datasets, experimental setups, and privacy budgets, our\napproach offers higher model performance than differential privacy-based\ntechniques in federated learning.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:30:16 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Choudhury", "Olivia", ""], ["Gkoulalas-Divanis", "Aris", ""], ["Salonidis", "Theodoros", ""], ["Sylla", "Issa", ""], ["Park", "Yoonyoung", ""], ["Hsu", "Grace", ""], ["Das", "Amar", ""]]}, {"id": "2002.09100", "submitter": "Jiangjiang Zhang", "authors": "Jiangjiang Zhang, Qiang Zheng, Laosheng Wu, Lingzao Zeng", "title": "Using Deep Learning to Improve Ensemble Smoother: Applications to\n  Subsurface Characterization", "comments": null, "journal-ref": null, "doi": "10.1029/2020WR027399", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble smoother (ES) has been widely used in various research fields to\nreduce the uncertainty of the system-of-interest. However, the commonly-adopted\nES method that employs the Kalman formula, that is, ES$_\\text{(K)}$, does not\nperform well when the probability distributions involved are non-Gaussian. To\naddress this issue, we suggest to use deep learning (DL) to derive an\nalternative update scheme for ES in complex data assimilation applications.\nHere we show that the DL-based ES method, that is, ES$_\\text{(DL)}$, is more\ngeneral and flexible. In this new update scheme, a high volume of training data\nare generated from a relatively small-sized ensemble of model parameters and\nsimulation outputs, and possible non-Gaussian features can be preserved in the\ntraining data and captured by an adequate DL model. This new variant of ES is\ntested in two subsurface characterization problems with or without Gaussian\nassumptions. Results indicate that ES$_\\text{(DL)}$ can produce similar (in the\nGaussian case) or even better (in the non-Gaussian case) results compared to\nthose from ES$_\\text{(K)}$. The success of ES$_\\text{(DL)}$ comes from the\npower of DL in extracting complex (including non-Gaussian) features and\nlearning nonlinear relationships from massive amounts of training data.\nAlthough in this work we only apply the ES$_\\text{(DL)}$ method in parameter\nestimation problems, the proposed idea can be conveniently extended to analysis\nof model structural uncertainty and state estimation in real-time forecasting\nstudies.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:46:53 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:15:59 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Zhang", "Jiangjiang", ""], ["Zheng", "Qiang", ""], ["Wu", "Laosheng", ""], ["Zeng", "Lingzao", ""]]}, {"id": "2002.09103", "submitter": "Arsenii Ashukha", "authors": "Dmitry Molchanov, Alexander Lyzhov, Yuliya Molchanova, Arsenii\n  Ashukha, Dmitry Vetrov", "title": "Greedy Policy Search: A Simple Baseline for Learnable Test-Time\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test-time data augmentation$-$averaging the predictions of a machine learning\nmodel across multiple augmented samples of data$-$is a widely used technique\nthat improves the predictive performance. While many advanced learnable data\naugmentation techniques have emerged in recent years, they are focused on the\ntraining phase. Such techniques are not necessarily optimal for test-time\naugmentation and can be outperformed by a policy consisting of simple crops and\nflips. The primary goal of this paper is to demonstrate that test-time\naugmentation policies can be successfully learned too. We introduce greedy\npolicy search (GPS), a simple but high-performing method for learning a policy\nof test-time augmentation. We demonstrate that augmentation policies learned\nwith GPS achieve superior predictive performance on image classification\nproblems, provide better in-domain uncertainty estimation, and improve the\nrobustness to domain shift.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:57:13 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 13:10:23 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Molchanov", "Dmitry", ""], ["Lyzhov", "Alexander", ""], ["Molchanova", "Yuliya", ""], ["Ashukha", "Arsenii", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.09106", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Meysam Majidi Nezhad, Ehsan Abbasnejad, Lina Bertling\n  Tjernberg, Davide Astiaso Garcia, Bradley Alexander, Markus Wagner", "title": "An Evolutionary Deep Learning Method for Short-term Wind Speed\n  Prediction: A Case Study of the Lillgrund Offshore Wind Farm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate short-term wind speed forecasting is essential for large-scale\nintegration of wind power generation. However, the seasonal and stochastic\ncharacteristics of wind speed make forecasting a challenging task. This study\nuses a new hybrid evolutionary approach that uses a popular evolutionary search\nalgorithm, CMA-ES, to tune the hyper-parameters of two Long short-term\nmemory(LSTM) ANN models for wind prediction. The proposed hybrid approach is\ntrained on data gathered from an offshore wind turbine installed in a Swedish\nwind farm located in the Baltic Sea. Two forecasting horizons including\nten-minutes ahead (absolute short term) and one-hour ahead (short term) are\nconsidered in our experiments. Our experimental results indicate that the new\napproach is superior to five other applied machine learning models, i.e.,\npolynomial neural network (PNN), feed-forward neural network (FNN), nonlinear\nautoregressive neural network (NAR) and adaptive neuro-fuzzy inference system\n(ANFIS), as measured by five performance criteria.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:28:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Neshat", "Mehdi", ""], ["Nezhad", "Meysam Majidi", ""], ["Abbasnejad", "Ehsan", ""], ["Tjernberg", "Lina Bertling", ""], ["Garcia", "Davide Astiaso", ""], ["Alexander", "Bradley", ""], ["Wagner", "Markus", ""]]}, {"id": "2002.09107", "submitter": "Iretiayo Akinola", "authors": "Iretiayo Akinola, Jacob Varley and Dmitry Kalashnikov", "title": "Learning Precise 3D Manipulation from Multiple Uncalibrated Cameras", "comments": "Accepted at International Conference on Robotics and Automation (ICRA\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an effective multi-view approach to closed-loop\nend-to-end learning of precise manipulation tasks that are 3D in nature. Our\nmethod learns to accomplish these tasks using multiple statically placed but\nuncalibrated RGB camera views without building an explicit 3D representation\nsuch as a pointcloud or voxel grid. This multi-camera approach achieves\nsuperior task performance on difficult stacking and insertion tasks compared to\nsingle-view baselines. Single view robotic agents struggle from occlusion and\nchallenges in estimating relative poses between points of interest. While full\n3D scene representations (voxels or pointclouds) are obtainable from registered\noutput of multiple depth sensors, several challenges complicate operating off\nsuch explicit 3D representations. These challenges include imperfect camera\ncalibration, poor depth maps due to object properties such as reflective\nsurfaces, and slower inference speeds over 3D representations compared to 2D\nimages. Our use of static but uncalibrated cameras does not require\ncamera-robot or camera-camera calibration making the proposed approach easy to\nsetup and our use of \\textit{sensor dropout} during training makes it resilient\nto the loss of camera-views after deployment.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:28:42 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 18:48:24 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Akinola", "Iretiayo", ""], ["Varley", "Jacob", ""], ["Kalashnikov", "Dmitry", ""]]}, {"id": "2002.09112", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak, Geoff Pleiss, Jacob R. Gardner", "title": "Deep Sigma Point Processes", "comments": "15 pages, 13 figures; as appeared in UAI 2020", "journal-ref": "Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI), PMLR 124:789-798, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Deep Sigma Point Processes, a class of parametric models\ninspired by the compositional structure of Deep Gaussian Processes (DGPs). Deep\nSigma Point Processes (DSPPs) retain many of the attractive features of\n(variational) DGPs, including mini-batch training and predictive uncertainty\nthat is controlled by kernel basis functions. Importantly, since DSPPs admit a\nsimple maximum likelihood inference procedure, the resulting predictive\ndistributions are not degraded by any posterior approximations. In an extensive\nempirical comparison on univariate and multivariate regression tasks we find\nthat the resulting predictive distributions are significantly better calibrated\nthan those obtained with other probabilistic methods for scalable regression,\nincluding variational DGPs--often by as much as a nat per datapoint.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:40:35 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 17:27:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jankowiak", "Martin", ""], ["Pleiss", "Geoff", ""], ["Gardner", "Jacob R.", ""]]}, {"id": "2002.09116", "submitter": "Danica J. Sutherland", "authors": "Feng Liu, Wenkai Xu, Jie Lu, Guangquan Zhang, Arthur Gretton, Danica\n  J. Sutherland", "title": "Learning Deep Kernels for Non-Parametric Two-Sample Tests", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML 2020), PMLR 119:6316-6326", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a class of kernel-based two-sample tests, which aim to determine\nwhether two sets of samples are drawn from the same distribution. Our tests are\nconstructed from kernels parameterized by deep neural nets, trained to maximize\ntest power. These tests adapt to variations in distribution smoothness and\nshape over space, and are especially suited to high dimensions and complex\ndata. By contrast, the simpler kernels used in prior kernel testing work are\nspatially homogeneous, and adaptive only in lengthscale. We explain how this\nscheme includes popular classifier-based two-sample tests as a special case,\nbut improves on them in general. We provide the first proof of consistency for\nthe proposed adaptation method, which applies both to kernels on deep features\nand to simpler radial basis kernels or multiple kernel learning. In\nexperiments, we establish the superior performance of our deep kernels in\nhypothesis testing on benchmark and real-world data. The code of our\ndeep-kernel-based two sample tests is available at\nhttps://github.com/fengliu90/DK-for-TST.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 03:54:23 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 18:23:31 GMT"}, {"version": "v3", "created": "Thu, 14 Jan 2021 05:29:18 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Liu", "Feng", ""], ["Xu", "Wenkai", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""], ["Gretton", "Arthur", ""], ["Sutherland", "Danica J.", ""]]}, {"id": "2002.09124", "submitter": "Farzan Farnia", "authors": "Farzan Farnia, Asuman Ozdaglar", "title": "GANs May Have No Nash Equilibria", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) represent a zero-sum game between two\nmachine players, a generator and a discriminator, designed to learn the\ndistribution of data. While GANs have achieved state-of-the-art performance in\nseveral benchmark learning tasks, GAN minimax optimization still poses great\ntheoretical and empirical challenges. GANs trained using first-order\noptimization methods commonly fail to converge to a stable solution where the\nplayers cannot improve their objective, i.e., the Nash equilibrium of the\nunderlying game. Such issues raise the question of the existence of Nash\nequilibrium solutions in the GAN zero-sum game. In this work, we show through\nseveral theoretical and numerical results that indeed GAN zero-sum games may\nnot have any local Nash equilibria. To characterize an equilibrium notion\napplicable to GANs, we consider the equilibrium of a new zero-sum game with an\nobjective function given by a proximal operator applied to the original\nobjective, a solution we call the proximal equilibrium. Unlike the Nash\nequilibrium, the proximal equilibrium captures the sequential nature of GANs,\nin which the generator moves first followed by the discriminator. We prove that\nthe optimal generative model in Wasserstein GAN problems provides a proximal\nequilibrium. Inspired by these results, we propose a new approach, which we\ncall proximal training, for solving GAN problems. We discuss several numerical\nexperiments demonstrating the existence of proximal equilibrium solutions in\nGAN minimax problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:30:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Farnia", "Farzan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "2002.09127", "submitter": "Eric Yuan", "authors": "Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre C\\^ot\\'e, Mikul\\'a\\v{s}\n  Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang,\n  Adam Trischler, William L. Hamilton", "title": "Learning Dynamic Belief Graphs to Generalize on Text-Based Games", "comments": "Bug fixed in Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playing text-based games requires skills in processing natural language and\nsequential decision making. Achieving human-level performance on text-based\ngames remains an open challenge, and prior research has largely relied on\nhand-crafted structured representations and heuristics. In this work, we\ninvestigate how an agent can plan and generalize in text-based games using\ngraph-structured representations learned end-to-end from raw text. We propose a\nnovel graph-aided transformer agent (GATA) that infers and updates latent\nbelief graphs during planning to enable effective action selection by capturing\nthe underlying game dynamics. GATA is trained using a combination of\nreinforcement and self-supervised learning. Our work demonstrates that the\nlearned graph-based representations help agents converge to better policies\nthan their text-only counterparts and facilitate effective generalization\nacross game configurations. Experiments on 500+ unique games from the TextWorld\nsuite show that our best agent outperforms text-based baselines by an average\nof 24.2%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:38:37 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:22:16 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 20:01:55 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 14:02:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Adhikari", "Ashutosh", ""], ["Yuan", "Xingdi", ""], ["C\u00f4t\u00e9", "Marc-Alexandre", ""], ["Zelinka", "Mikul\u00e1\u0161", ""], ["Rondeau", "Marc-Antoine", ""], ["Laroche", "Romain", ""], ["Poupart", "Pascal", ""], ["Tang", "Jian", ""], ["Trischler", "Adam", ""], ["Hamilton", "William L.", ""]]}, {"id": "2002.09128", "submitter": "Sirui Xie", "authors": "Shoukang Hu, Sirui Xie, Hehui Zheng, Chunxiao Liu, Jianping Shi,\n  Xunying Liu, Dahua Lin", "title": "DSNAS: Direct Neural Architecture Search without Parameter Retraining", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  If NAS methods are solutions, what is the problem? Most existing NAS methods\nrequire two-stage parameter optimization. However, performance of the same\narchitecture in the two stages correlates poorly. In this work, we propose a\nnew problem definition for NAS, task-specific end-to-end, based on this\nobservation. We argue that given a computer vision task for which a NAS method\nis expected, this definition can reduce the vaguely-defined NAS evaluation to\ni) accuracy of this task and ii) the total computation consumed to finally\nobtain a model with satisfying accuracy. Seeing that most existing methods do\nnot solve this problem directly, we propose DSNAS, an efficient differentiable\nNAS framework that simultaneously optimizes architecture and parameters with a\nlow-biased Monte Carlo estimate. Child networks derived from DSNAS can be\ndeployed directly without parameter retraining. Comparing with two-stage\nmethods, DSNAS successfully discovers networks with comparable accuracy (74.4%)\non ImageNet in 420 GPU hours, reducing the total time by more than 34%. Our\nimplementation is available at https://github.com/SNAS-Series/SNAS-Series.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:41:47 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 00:31:37 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Hu", "Shoukang", ""], ["Xie", "Sirui", ""], ["Zheng", "Hehui", ""], ["Liu", "Chunxiao", ""], ["Shi", "Jianping", ""], ["Liu", "Xunying", ""], ["Lin", "Dahua", ""]]}, {"id": "2002.09131", "submitter": "Wonmin Byeon", "authors": "Jiahao Su, Wonmin Byeon, Jean Kossaifi, Furong Huang, Jan Kautz,\n  Animashree Anandkumar", "title": "Convolutional Tensor-Train LSTM for Spatio-temporal Learning", "comments": "Jiahao Su and Wonmin Byeon contributed equally to this work. 22\n  pages, 14 figures, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from spatio-temporal data has numerous applications such as\nhuman-behavior analysis, object tracking, video compression, and physics\nsimulation.However, existing methods still perform poorly on challenging video\ntasks such as long-term forecasting. This is because these kinds of challenging\ntasks require learning long-term spatio-temporal correlations in the video\nsequence. In this paper, we propose a higher-order convolutional LSTM model\nthat can efficiently learn these correlations, along with a succinct\nrepresentations of the history. This is accomplished through a novel tensor\ntrain module that performs prediction by combining convolutional features\nacross time. To make this feasible in terms of computation and memory\nrequirements, we propose a novel convolutional tensor-train decomposition of\nthe higher-order model. This decomposition reduces the model complexity by\njointly approximating a sequence of convolutional kernels asa low-rank\ntensor-train factorization. As a result, our model outperforms existing\napproaches, but uses only a fraction of parameters, including the baseline\nmodels.Our results achieve state-of-the-art performance in a wide range of\napplications and datasets, including the multi-steps video prediction on the\nMoving-MNIST-2and KTH action datasets as well as early activity recognition on\nthe Something-Something V2 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:00:01 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:31:38 GMT"}, {"version": "v3", "created": "Sun, 22 Mar 2020 19:27:44 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 18:30:12 GMT"}, {"version": "v5", "created": "Sun, 4 Oct 2020 23:14:31 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Su", "Jiahao", ""], ["Byeon", "Wonmin", ""], ["Kossaifi", "Jean", ""], ["Huang", "Furong", ""], ["Kautz", "Jan", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "2002.09132", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Hiroki Toda, Ryota Sugiyama, Ichiro Takeuchi", "title": "Computing Valid p-value for Optimal Changepoint by Selective Inference\n  using Dynamic Programming", "comments": "Spotlight Presentation at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a vast body of literature related to methods for detecting\nchangepoints (CP). However, less attention has been paid to assessing the\nstatistical reliability of the detected CPs. In this paper, we introduce a\nnovel method to perform statistical inference on the significance of the CPs,\nestimated by a Dynamic Programming (DP)-based optimal CP detection algorithm.\nBased on the selective inference (SI) framework, we propose an exact\n(non-asymptotic) approach to compute valid p-values for testing the\nsignificance of the CPs. Although it is well-known that SI has low statistical\npower because of over-conditioning, we address this disadvantage by introducing\nparametric programming techniques. Then, we propose an efficient method to\nconduct SI with the minimum amount of conditioning, leading to high statistical\npower. We conduct experiments on both synthetic and real-world datasets,\nthrough which we offer evidence that our proposed method is more powerful than\nexisting methods, has decent performance in terms of computational efficiency,\nand provides good results in many practical applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:07:22 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 13:06:56 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Toda", "Hiroki", ""], ["Sugiyama", "Ryota", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2002.09133", "submitter": "R. Jyothi", "authors": "R. Jyothi and P. Babu", "title": "PIANO: A Fast Parallel Iterative Algorithm for Multinomial and Sparse\n  Multinomial Logistic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial Logistic Regression is a well-studied tool for classification and\nhas been widely used in fields like image processing, computer vision and,\nbioinformatics, to name a few. Under a supervised classification scenario, a\nMultinomial Logistic Regression model learns a weight vector to differentiate\nbetween any two classes by optimizing over the likelihood objective. With the\nadvent of big data, the inundation of data has resulted in large dimensional\nweight vector and has also given rise to a huge number of classes, which makes\nthe classical methods applicable for model estimation not computationally\nviable. To handle this issue, we here propose a parallel iterative algorithm:\nParallel Iterative Algorithm for MultiNomial LOgistic Regression (PIANO) which\nis based on the Majorization Minimization procedure, and can parallely update\neach element of the weight vectors. Further, we also show that PIANO can be\neasily extended to solve the Sparse Multinomial Logistic Regression problem -\nan extensively studied problem because of its attractive feature selection\nproperty. In particular, we work out the extension of PIANO to solve the Sparse\nMultinomial Logistic Regression problem with l1 and l0 regularizations. We also\nprove that PIANO converges to a stationary point of the Multinomial and the\nSparse Multinomial Logistic Regression problems. Simulations were conducted to\ncompare PIANO with the existing methods, and it was found that the proposed\nalgorithm performs better than the existing methods in terms of speed of\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:15:48 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jyothi", "R.", ""], ["Babu", "P.", ""]]}, {"id": "2002.09136", "submitter": "Yuanyi Zhong", "authors": "Yuanyi Zhong, Alexander Schwing, Jian Peng", "title": "Disentangling Controllable Object through Video Prediction Improves\n  Visual Reinforcement Learning", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many vision-based reinforcement learning (RL) problems, the agent controls\na movable object in its visual field, e.g., the player's avatar in video games\nand the robotic arm in visual grasping and manipulation. Leveraging\naction-conditioned video prediction, we propose an end-to-end learning\nframework to disentangle the controllable object from the observation signal.\nThe disentangled representation is shown to be useful for RL as additional\nobservation channels to the agent. Experiments on a set of Atari games with the\npopular Double DQN algorithm demonstrate improved sample efficiency and game\nperformance (from 222.8% to 261.4% measured in normalized game scores, with\nprediction bonus reward).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:43:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhong", "Yuanyi", ""], ["Schwing", "Alexander", ""], ["Peng", "Jian", ""]]}, {"id": "2002.09142", "submitter": "Sina Aghaei", "authors": "Sina Aghaei, Andres Gomez, Phebe Vayanos", "title": "Learning Optimal Classification Trees: Strong Max-Flow Formulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning optimal binary classification trees.\nLiterature on the topic has burgeoned in recent years, motivated both by the\nempirical suboptimality of heuristic approaches and the tremendous improvements\nin mixed-integer programming (MIP) technology. Yet, existing approaches from\nthe literature do not leverage the power of MIP to its full extent. Indeed,\nthey rely on weak formulations, resulting in slow convergence and large\noptimality gaps. To fill this gap in the literature, we propose a flow-based\nMIP formulation for optimal binary classification trees that has a stronger\nlinear programming relaxation. Our formulation presents an attractive\ndecomposable structure. We exploit this structure and max-flow/min-cut duality\nto derive a Benders' decomposition method, which scales to larger instances. We\nconduct extensive computational experiments on standard benchmark datasets on\nwhich we show that our proposed approaches are 50 times faster than\nstate-of-the art MIP-based techniques and improve out of sample performance up\nto 13.8%.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 05:58:17 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 02:24:34 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Aghaei", "Sina", ""], ["Gomez", "Andres", ""], ["Vayanos", "Phebe", ""]]}, {"id": "2002.09143", "submitter": "Bowen Shi", "authors": "Bowen Shi, Ming Sun, Krishna C. Puvvada, Chieh-Chi Kao, Spyros\n  Matsoukas, Chao Wang", "title": "Few-shot acoustic event detection via meta-learning", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study few-shot acoustic event detection (AED) in this paper. Few-shot\nlearning enables detection of new events with very limited labeled data.\nCompared to other research areas like computer vision, few-shot learning for\naudio recognition has been under-studied. We formulate few-shot AED problem and\nexplore different ways of utilizing traditional supervised methods for this\nsetting as well as a variety of meta-learning approaches, which are\nconventionally used to solve few-shot classification problem. Compared to\nsupervised baselines, meta-learning models achieve superior performance, thus\nshowing its effectiveness on generalization to new audio events. Our analysis\nincluding impact of initialization and domain discrepancy further validate the\nadvantage of meta-learning approaches in few-shot AED.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:02:11 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shi", "Bowen", ""], ["Sun", "Ming", ""], ["Puvvada", "Krishna C.", ""], ["Kao", "Chieh-Chi", ""], ["Matsoukas", "Spyros", ""], ["Wang", "Chao", ""]]}, {"id": "2002.09145", "submitter": "Yuan Jin", "authors": "Yuan Jin, He Zhao, Ming Liu, Ye Zhu, Lan Du, Longxiang Gao, Wray\n  Buntine", "title": "Leveraging Cross Feedback of User and Item Embeddings with Attention for\n  Variational Autoencoder based Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Matrix factorization (MF) has been widely applied to collaborative filtering\nin recommendation systems. Its Bayesian variants can derive posterior\ndistributions of user and item embeddings, and are more robust to sparse\nratings. However, the Bayesian methods are restricted by their update rules for\nthe posterior parameters due to the conjugacy of the priors and the likelihood.\nVariational autoencoders (VAE) can address this issue by capturing complex\nmappings between the posterior parameters and the data. However, current\nresearch on VAEs for collaborative filtering only considers the mappings based\non the explicit data information while the implicit embedding information is\noverlooked. In this paper, we first derive evidence lower bounds (ELBO) for\nBayesian MF models from two viewpoints: user-oriented and item-oriented. Based\non the ELBOs, we propose a VAE-based Bayesian MF framework. It leverages not\nonly the data but also the embedding information to approximate the user-item\njoint distribution. As suggested by the ELBOs, the approximation is iterative\nwith cross feedback of user and item embeddings into each other's encoders.\nMore specifically, user embeddings sampled at the previous iteration are fed to\nthe item-side encoders to estimate the posterior parameters for the item\nembeddings at the current iteration, and vice versa. The estimation also\nattends to the cross-fed embeddings to further exploit useful information. The\ndecoder then reconstructs the data via the matrix factorization over the\ncurrently re-sampled user and item embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 06:05:06 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 21:32:43 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Jin", "Yuan", ""], ["Zhao", "He", ""], ["Liu", "Ming", ""], ["Zhu", "Ye", ""], ["Du", "Lan", ""], ["Gao", "Longxiang", ""], ["Buntine", "Wray", ""]]}, {"id": "2002.09161", "submitter": "Xinwei Shen", "authors": "Xinwei Shen, Tong Zhang, Kani Chen", "title": "Bidirectional Generative Modeling Using Adversarial Gradient Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the general $f$-divergence formulation of bidirectional\ngenerative modeling, which includes VAE and BiGAN as special cases. We present\na new optimization method for this formulation, where the gradient is computed\nusing an adversarially learned discriminator. In our framework, we show that\ndifferent divergences induce similar algorithms in terms of gradient\nevaluation, except with different scaling. Therefore this paper gives a general\nrecipe for a class of principled $f$-divergence based generative modeling\nmethods. Theoretical justifications and extensive empirical studies are\nprovided to demonstrate the advantage of our approach over existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:28:56 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 10:43:09 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 03:59:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Shen", "Xinwei", ""], ["Zhang", "Tong", ""], ["Chen", "Kani", ""]]}, {"id": "2002.09162", "submitter": "Daniel Andrade", "authors": "Daniel Andrade and Yuzuru Okajima", "title": "Adaptive Covariate Acquisition for Minimizing Total Cost of\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some applications, acquiring covariates comes at a cost which is not\nnegligible. For example in the medical domain, in order to classify whether a\npatient has diabetes or not, measuring glucose tolerance can be expensive.\nAssuming that the cost of each covariate, and the cost of misclassification can\nbe specified by the user, our goal is to minimize the (expected) total cost of\nclassification, i.e. the cost of misclassification plus the cost of the\nacquired covariates. We formalize this optimization goal using the\n(conditional) Bayes risk and describe the optimal solution using a recursive\nprocedure. Since the procedure is computationally infeasible, we consequently\nintroduce two assumptions: (1) the optimal classifier can be represented by a\ngeneralized additive model, (2) the optimal sets of covariates are limited to a\nsequence of sets of increasing size. We show that under these two assumptions,\na computationally efficient solution exists. Furthermore, on several medical\ndatasets, we show that the proposed method achieves in most situations the\nlowest total costs when compared to various previous methods. Finally, we\nweaken the requirement on the user to specify all misclassification costs by\nallowing the user to specify the minimally acceptable recall (target recall).\nOur experiments confirm that the proposed method achieves the target recall\nwhile minimizing the false discovery rate and the covariate acquisition costs\nbetter than previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:30:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Andrade", "Daniel", ""], ["Okajima", "Yuzuru", ""]]}, {"id": "2002.09168", "submitter": "Yujun Shen", "authors": "Mengya Gao, Yujun Shen, Quanquan Li, Chen Change Loy", "title": "Residual Knowledge Distillation", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is one of the most potent ways for model\ncompression. The key idea is to transfer the knowledge from a deep teacher\nmodel (T) to a shallower student (S). However, existing methods suffer from\nperformance degradation due to the substantial gap between the learning\ncapacities of S and T. To remedy this problem, this work proposes Residual\nKnowledge Distillation (RKD), which further distills the knowledge by\nintroducing an assistant (A). Specifically, S is trained to mimic the feature\nmaps of T, and A aids this process by learning the residual error between them.\nIn this way, S and A complement with each other to get better knowledge from T.\nFurthermore, we devise an effective method to derive S and A from a given model\nwithout increasing the total computational cost. Extensive experiments show\nthat our approach achieves appealing results on popular classification\ndatasets, CIFAR-100 and ImageNet, surpassing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:49:26 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Gao", "Mengya", ""], ["Shen", "Yujun", ""], ["Li", "Quanquan", ""], ["Loy", "Chen Change", ""]]}, {"id": "2002.09169", "submitter": "Dinghuai Zhang", "authors": "Dinghuai Zhang, Mao Ye, Chengyue Gong, Zhanxing Zhu, Qiang Liu", "title": "Black-Box Certification with Randomized Smoothing: A Functional\n  Optimization Based Framework", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized classifiers have been shown to provide a promising approach for\nachieving certified robustness against adversarial attacks in deep learning.\nHowever, most existing methods only leverage Gaussian smoothing noise and only\nwork for $\\ell_2$ perturbation. We propose a general framework of adversarial\ncertification with non-Gaussian noise and for more general types of attacks,\nfrom a unified functional optimization perspective. Our new framework allows us\nto identify a key trade-off between accuracy and robustness via designing\nsmoothing distributions, helping to design new families of non-Gaussian\nsmoothing distributions that work more efficiently for different $\\ell_p$\nsettings, including $\\ell_1$, $\\ell_2$ and $\\ell_\\infty$ attacks. Our proposed\nmethods achieve better certification results than previous works and provide a\nnew perspective on randomized smoothing certification.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 07:52:47 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:27:06 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Zhang", "Dinghuai", ""], ["Ye", "Mao", ""], ["Gong", "Chengyue", ""], ["Zhu", "Zhanxing", ""], ["Liu", "Qiang", ""]]}, {"id": "2002.09174", "submitter": "Quanquan Gu", "authors": "Tianyuan Jin and Pan Xu and Xiaokui Xiao and Quanquan Gu", "title": "Double Explore-then-Commit: Asymptotic Optimality and Beyond", "comments": "46 pages. This version improves the presentation, and adds new\n  algorithms and theoretical results: an anytime algorithm with asymptotic\n  optimality guarantee, and an extension to K-armed bandits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-armed bandit problem with subgaussian rewards. The\nexplore-then-commit (ETC) strategy, which consists of an exploration phase\nfollowed by an exploitation phase, is one of the most widely used algorithms in\na variety of online decision applications. Nevertheless, it has been shown in\nGarivier et al. (2016) that ETC is suboptimal in the asymptotic sense as the\nhorizon grows, and thus, is worse than fully sequential strategies such as\nUpper Confidence Bound (UCB). In this paper, we show that a variant of ETC\nalgorithm can actually achieve the asymptotic optimality for multi-armed bandit\nproblems as UCB-type algorithms do and extend it to the batched bandit setting.\nSpecifically, we propose a double explore-then-commit (DETC) algorithm that has\ntwo exploration and exploitation phases and prove that DETC achieves the\nasymptotically optimal regret bound. To our knowledge, DETC is the first\nnon-fully-sequential algorithm that achieves such asymptotic optimality. In\naddition, we extend DETC to batched bandit problems, where (i) the exploration\nprocess is split into a small number of batches and (ii) the round complexity\nis of central interest. We prove that a batched version of DETC can achieve the\nasymptotic optimality with only a constant round complexity. This is the first\nbatched bandit algorithm that can attain the optimal asymptotic regret bound\nand optimal round complexity simultaneously.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:07:56 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 07:40:47 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Jin", "Tianyuan", ""], ["Xu", "Pan", ""], ["Xiao", "Xiaokui", ""], ["Gu", "Quanquan", ""]]}, {"id": "2002.09188", "submitter": "Shuichi Kawano", "authors": "Shuichi Kawano", "title": "Sparse principal component regression via singular value decomposition\n  approach", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component regression (PCR) is a two-stage procedure: the first\nstage performs principal component analysis (PCA) and the second stage\nconstructs a regression model whose explanatory variables are replaced by\nprincipal components obtained by the first stage. Since PCA is performed by\nusing only explanatory variables, the principal components have no information\nabout the response variable. To address the problem, we propose a one-stage\nprocedure for PCR in terms of singular value decomposition approach. Our\napproach is based upon two loss functions, a regression loss and a PCA loss,\nwith sparse regularization. The proposed method enables us to obtain principal\ncomponent loadings that possess information about both explanatory variables\nand a response variable. An estimation algorithm is developed by using\nalternating direction method of multipliers. We conduct numerical studies to\nshow the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:03:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Kawano", "Shuichi", ""]]}, {"id": "2002.09191", "submitter": "Cristina Molero-R\\'io", "authors": "Rafael Blanquero, Emilio Carrizosa, Cristina Molero-R\\'io, Dolores\n  Romero Morales", "title": "Sparsity in Optimal Randomized Classification Trees", "comments": "This research has been financed in part by research projects EC H2020\n  Marie Sk{\\l}odowska-Curie Actions, Research and Innovation Staff Exchange\n  Network of European Data Scientists, NeEDS, Grant agreement ID 822214,\n  COSECLA - Fundaci\\'on BBVA, MTM2015-65915R, Spain, P11-FQM-7603 and FQM-329,\n  Junta de Andaluc\\'{\\i}a. This support is gratefully acknowledged. Available\n  online 16 December 2019", "journal-ref": "European Journal of Operational Research, 2019", "doi": "10.1016/j.ejor.2019.12.002", "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision trees are popular Classification and Regression tools and, when\nsmall-sized, easy to interpret. Traditionally, a greedy approach has been used\nto build the trees, yielding a very fast training process; however, controlling\nsparsity (a proxy for interpretability) is challenging. In recent studies,\noptimal decision trees, where all decisions are optimized simultaneously, have\nshown a better learning performance, especially when oblique cuts are\nimplemented. In this paper, we propose a continuous optimization approach to\nbuild sparse optimal classification trees, based on oblique cuts, with the aim\nof using fewer predictor variables in the cuts as well as along the whole tree.\nBoth types of sparsity, namely local and global, are modeled by means of\nregularizations with polyhedral norms. The computational experience reported\nsupports the usefulness of our methodology. In all our data sets, local and\nglobal sparsity can be improved without harming classification accuracy. Unlike\ngreedy approaches, our ability to easily trade in some of our classification\naccuracy for a gain in global sparsity is shown.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:09:59 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Blanquero", "Rafael", ""], ["Carrizosa", "Emilio", ""], ["Molero-R\u00edo", "Cristina", ""], ["Morales", "Dolores Romero", ""]]}, {"id": "2002.09192", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Renuka Sindhgatta and Chun Ouyang and Peter Bruza\n  and Andreas Wichert", "title": "An Investigation of Interpretability Techniques for Deep Learning in\n  Predictive Process Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores interpretability techniques for two of the most\nsuccessful learning algorithms in medical decision-making literature: deep\nneural networks and random forests. We applied these algorithms in a real-world\nmedical dataset containing information about patients with cancer, where we\nlearn models that try to predict the type of cancer of the patient, given their\nset of medical activity records.\n  We explored different algorithms based on neural network architectures using\nlong short term deep neural networks, and random forests. Since there is a\ngrowing need to provide decision-makers understandings about the logic of\npredictions of black boxes, we also explored different techniques that provide\ninterpretations for these classifiers. In one of the techniques, we intercepted\nsome hidden layers of these neural networks and used autoencoders in order to\nlearn what is the representation of the input in the hidden layers. In another,\nwe investigated an interpretable model locally around the random forest's\nprediction.\n  Results show learning an interpretable model locally around the model's\nprediction leads to a higher understanding of why the algorithm is making some\ndecision. Use of local and linear model helps identify the features used in\nprediction of a specific instance or data point. We see certain distinct\nfeatures used for predictions that provide useful insights about the type of\ncancer, along with features that do not generalize well. In addition, the\nstructured deep learning approach using autoencoders provided meaningful\nprediction insights, which resulted in the identification of nonlinear clusters\ncorrespondent to the patients' different types of cancer.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:14:34 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Moreira", "Catarina", ""], ["Sindhgatta", "Renuka", ""], ["Ouyang", "Chun", ""], ["Bruza", "Peter", ""], ["Wichert", "Andreas", ""]]}, {"id": "2002.09213", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska and Marta R. Costa-juss\\`a", "title": "Refinement of Unsupervised Cross-Lingual Word Embeddings", "comments": "Accepted at the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)", "journal-ref": null, "doi": "10.3233/FAIA200317", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cross-lingual word embeddings aim to bridge the gap between high-resource and\nlow-resource languages by allowing to learn multilingual word representations\neven without using any direct bilingual signal. The lion's share of the methods\nare projection-based approaches that map pre-trained embeddings into a shared\nlatent space. These methods are mostly based on the orthogonal transformation,\nwhich assumes language vector spaces to be isomorphic. However, this criterion\ndoes not necessarily hold, especially for morphologically-rich languages. In\nthis paper, we propose a self-supervised method to refine the alignment of\nunsupervised bilingual word embeddings. The proposed model moves vectors of\nwords and their corresponding translations closer to each other as well as\nenforces length- and center-invariance, thus allowing to better align\ncross-lingual embeddings. The experimental results demonstrate the\neffectiveness of our approach, as in most cases it outperforms state-of-the-art\nmethods in a bilingual lexicon induction task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:39:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2002.09219", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (MLIA), Edouard Delasalles (MLIA), Micka\\\"el Chen\n  (MLIA), Sylvain Lamprier (MLIA), Patrick Gallinari (MLIA)", "title": "Stochastic Latent Residual Video Prediction", "comments": null, "journal-ref": "Thirty-seventh International Conference on Machine Learning,\n  International Machine Learning Society, Jul 2020, Vienne, Austria. pp.89--102", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing video prediction models that account for the inherent uncertainty\nof the future is challenging. Most works in the literature are based on\nstochastic image-autoregressive recurrent networks, which raises several\nperformance and applicability issues. An alternative is to use fully latent\ntemporal models which untie frame synthesis and temporal dynamics. However, no\nsuch model for stochastic video prediction has been proposed in the literature\nyet, due to design and training difficulties. In this paper, we overcome these\ndifficulties by introducing a novel stochastic temporal model whose dynamics\nare governed in a latent space by a residual update rule. This first-order\nscheme is motivated by discretization schemes of differential equations. It\nnaturally models video dynamics as it allows our simpler, more interpretable,\nlatent model to outperform prior state-of-the-art methods on challenging\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:44:01 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 15:50:43 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 14:34:16 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 14:37:21 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Franceschi", "Jean-Yves", "", "MLIA"], ["Delasalles", "Edouard", "", "MLIA"], ["Chen", "Micka\u00ebl", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2002.09225", "submitter": "Krikamol Muandet", "authors": "Krikamol Muandet, Wittawat Jitkrittum, Jonas K\\\"ubler", "title": "Kernel Conditional Moment Test via Maximum Moment Restriction", "comments": "In Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of specification tests called kernel conditional\nmoment (KCM) tests. Our tests are built on a novel representation of\nconditional moment restrictions in a reproducing kernel Hilbert space (RKHS)\ncalled conditional moment embedding (CMME). After transforming the conditional\nmoment restrictions into a continuum of unconditional counterparts, the test\nstatistic is defined as the maximum moment restriction (MMR) within the unit\nball of the RKHS. We show that the MMR not only fully characterizes the\noriginal conditional moment restrictions, leading to consistency in both\nhypothesis testing and parameter estimation, but also has an analytic\nexpression that is easy to compute as well as closed-form asymptotic\ndistributions. Our empirical studies show that the KCM test has a promising\nfinite-sample performance compared to existing tests.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 10:58:57 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2020 14:05:18 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 18:08:23 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Muandet", "Krikamol", ""], ["Jitkrittum", "Wittawat", ""], ["K\u00fcbler", "Jonas", ""]]}, {"id": "2002.09237", "submitter": "S\\\"oren Klemm", "authors": "Karim Huesmann, Soeren Klemm, Lars Linsen and Benjamin Risse", "title": "Exploiting the Full Capacity of Deep Neural Networks while Avoiding\n  Overfitting by Targeted Sparsity Regularization", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Overfitting is one of the most common problems when training deep neural\nnetworks on comparatively small datasets. Here, we demonstrate that neural\nnetwork activation sparsity is a reliable indicator for overfitting which we\nutilize to propose novel targeted sparsity visualization and regularization\nstrategies. Based on these strategies we are able to understand and counteract\noverfitting caused by activation sparsity and filter correlation in a targeted\nlayer-by-layer manner. Our results demonstrate that targeted sparsity\nregularization can efficiently be used to regularize well-known datasets and\narchitectures with a significant increase in image classification performance\nwhile outperforming both dropout and batch normalization. Ultimately, our study\nreveals novel insights into the contradicting concepts of activation sparsity\nand network capacity by demonstrating that targeted sparsity regularization\nenables salient and discriminative feature learning while exploiting the full\ncapacity of deep models without suffering from overfitting, even when trained\nexcessively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:38:17 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Huesmann", "Karim", ""], ["Klemm", "Soeren", ""], ["Linsen", "Lars", ""], ["Risse", "Benjamin", ""]]}, {"id": "2002.09247", "submitter": "Russa Biswas", "authors": "Russa Biswas, Mehwish Alam, and Harald Sack", "title": "Is Aligning Embedding Spaces a Challenging Task? A Study on\n  Heterogeneous Embedding Alignment Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Representation Learning of words and Knowledge Graphs (KG) into low\ndimensional vector spaces along with its applications to many real-world\nscenarios have recently gained momentum. In order to make use of multiple KG\nembeddings for knowledge-driven applications such as question answering, named\nentity disambiguation, knowledge graph completion, etc., alignment of different\nKG embedding spaces is necessary. In addition to multilinguality and\ndomain-specific information, different KGs pose the problem of structural\ndifferences making the alignment of the KG embeddings more challenging. This\npaper provides a theoretical analysis and comparison of the state-of-the-art\nalignment methods between two embedding spaces representing entity-entity and\nentity-word. This paper also aims at assessing the capability and short-comings\nof the existing alignment methods on the pretext of different applications.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:37:12 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 15:49:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Biswas", "Russa", ""], ["Alam", "Mehwish", ""], ["Sack", "Harald", ""]]}, {"id": "2002.09249", "submitter": "Marcell Beregi-Kov\\'acs", "authors": "Marcell Beregi-Kov\\'acs, \\'Agnes Baran and Andr\\'as Hajdu", "title": "Efficient Learning of Model Weights via Changing Features During\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a machine learning model, which dynamically changes\nthe features during training. Our main motivation is to update the model in a\nsmall content during the training process with replacing less descriptive\nfeatures to new ones from a large pool. The main benefit is coming from the\nfact that opposite to the common practice we do not start training a new model\nfrom the scratch, but can keep the already learned weights. This procedure\nallows the scan of a large feature pool which together with keeping the\ncomplexity of the model leads to an increase of the model accuracy within the\nsame training time. The efficiency of our approach is demonstrated in several\nclassic machine learning scenarios including linear regression and neural\nnetwork-based training. As a specific analysis towards signal processing, we\nhave successfully tested our approach on the database MNIST for digit\nclassification considering single pixel and pixel-pairs intensities as possible\nfeatures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:38:14 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Beregi-Kov\u00e1cs", "Marcell", ""], ["Baran", "\u00c1gnes", ""], ["Hajdu", "Andr\u00e1s", ""]]}, {"id": "2002.09253", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Tristan Karch, Nicolas Lair, Jean-Michel Dussoux,\n  Cl\\'ement Moulin-Frier, Peter Ford Dominey, Pierre-Yves Oudeyer", "title": "Language as a Cognitive Tool to Imagine Goals in Curiosity-Driven\n  Exploration", "comments": "Contains main article and supplementaries", "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental machine learning studies how artificial agents can model the\nway children learn open-ended repertoires of skills. Such agents need to create\nand represent goals, select which ones to pursue and learn to achieve them.\nRecent approaches have considered goal spaces that were either fixed and\nhand-defined or learned using generative models of states. This limited agents\nto sample goals within the distribution of known effects. We argue that the\nability to imagine out-of-distribution goals is key to enable creative\ndiscoveries and open-ended learning. Children do so by leveraging the\ncompositionality of language as a tool to imagine descriptions of outcomes they\nnever experienced before, targeting them as goals during play. We introduce\nIMAGINE, an intrinsically motivated deep reinforcement learning architecture\nthat models this ability. Such imaginative agents, like children, benefit from\nthe guidance of a social peer who provides language descriptions. To take\nadvantage of goal imagination, agents must be able to leverage these\ndescriptions to interpret their imagined out-of-distribution goals. This\ngeneralization is made possible by modularity: a decomposition between learned\ngoal-achievement reward function and policy relying on deep sets, gated\nattention and object-centered representations. We introduce the Playground\nenvironment and study how this form of goal imagination improves generalization\nand exploration over agents lacking this capacity. In addition, we identify the\nproperties of goal imagination that enable these results and study the impacts\nof modularity and social interactions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 12:59:57 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:38:50 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 09:23:40 GMT"}, {"version": "v4", "created": "Wed, 21 Oct 2020 16:48:51 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Karch", "Tristan", ""], ["Lair", "Nicolas", ""], ["Dussoux", "Jean-Michel", ""], ["Moulin-Frier", "Cl\u00e9ment", ""], ["Dominey", "Peter Ford", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2002.09259", "submitter": "Theo Ladune", "authors": "Th\\'eo Ladune (IETR), Pierrick Philippe, Wassim Hamidouche (IETR), Lu\n  Zhang (IETR), Olivier Deforges (IETR)", "title": "Binary Probability Model for Learning Based Image Compression", "comments": null, "journal-ref": "International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2020, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to enhance learned image compression systems with a\nricher probability model for the latent variables. Previous works model the\nlatents with a Gaussian or a Laplace distribution. Inspired by binary\narithmetic coding , we propose to signal the latents with three binary values\nand one integer, with different probability models. A relaxation method is\ndesigned to perform gradient-based training. The richer probability model\nresults in a better entropy coding leading to lower rate. Experiments under the\nChallenge on Learned Image Compression (CLIC) test conditions demonstrate that\nthis method achieves 18% rate saving compared to Gaussian or Laplace models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:09:58 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ladune", "Th\u00e9o", "", "IETR"], ["Philippe", "Pierrick", "", "IETR"], ["Hamidouche", "Wassim", "", "IETR"], ["Zhang", "Lu", "", "IETR"], ["Deforges", "Olivier", "", "IETR"]]}, {"id": "2002.09268", "submitter": "Peter Davies", "authors": "Peter Davies, Vijaykrishna Gurunathan, Niusha Moshrefi, Saleh\n  Ashkboos, Dan Alistarh", "title": "New Bounds For Distributed Mean Estimation and Variance Reduction", "comments": "42 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed mean estimation (DME), in which $n$\nmachines are each given a local $d$-dimensional vector $x_v \\in \\mathbb{R}^d$,\nand must cooperate to estimate the mean of their inputs $\\mu = \\frac 1n\\sum_{v\n= 1}^n x_v$, while minimizing total communication cost.\n  DME is a fundamental construct in distributed machine learning, and there has\nbeen considerable work on variants of this problem, especially in the context\nof distributed variance reduction for stochastic gradients in parallel SGD.\nPrevious work typically assumes an upper bound on the norm of the input\nvectors, and achieves an error bound in terms of this norm. However, in many\nreal applications, the input vectors are concentrated around the correct output\n$\\mu$, but $\\mu$ itself has large norm. In such cases, previous output error\nbounds perform poorly.\n  In this paper, we show that output error bounds need not depend on input\nnorm. We provide a method of quantization which allows distributed mean\nestimation to be performed with solution quality dependent only on the distance\nbetween inputs, not on input norm, and show an analogous result for distributed\nvariance reduction. The technique is based on a new connection with lattice\ntheory. We also provide lower bounds showing that the communication to error\ntrade-off of our algorithms is asymptotically optimal.\n  As the lattices achieving optimal bounds under $\\ell_2$-norm can be\ncomputationally impractical, we also present an extension which leverages\neasy-to-use cubic lattices, and is loose only up to a logarithmic factor in\n$d$. We show experimentally that our method yields practical improvements for\ncommon applications, relative to prior approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:27:13 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 14:33:28 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 14:03:21 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 15:50:18 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Davies", "Peter", ""], ["Gurunathan", "Vijaykrishna", ""], ["Moshrefi", "Niusha", ""], ["Ashkboos", "Saleh", ""], ["Alistarh", "Dan", ""]]}, {"id": "2002.09277", "submitter": "Blake Woodworth", "authors": "Blake Woodworth, Suriya Gunasekar, Jason D. Lee, Edward Moroshko,\n  Pedro Savarese, Itay Golan, Daniel Soudry, Nathan Srebro", "title": "Kernel and Rich Regimes in Overparametrized Models", "comments": "This updates and significantly extends a previous article\n  (arXiv:1906.05827), Sections 6 and 7 are the most major additions. 31 pages.\n  arXiv admin note: text overlap with arXiv:1906.05827", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of work studies overparametrized neural networks in the \"kernel\nregime,\" i.e. when the network behaves during training as a kernelized linear\npredictor, and thus training with gradient descent has the effect of finding\nthe minimum RKHS norm solution. This stands in contrast to other studies which\ndemonstrate how gradient descent on overparametrized multilayer networks can\ninduce rich implicit biases that are not RKHS norms. Building on an observation\nby Chizat and Bach, we show how the scale of the initialization controls the\ntransition between the \"kernel\" (aka lazy) and \"rich\" (aka active) regimes and\naffects generalization properties in multilayer homogeneous models. We also\nhighlight an interesting role for the width of a model in the case that the\npredictor is not identically zero at initialization. We provide a complete and\ndetailed analysis for a family of simple depth-$D$ models that already exhibit\nan interesting and meaningful transition between the kernel and rich regimes,\nand we also demonstrate this transition empirically for more complex matrix\nfactorization models and multilayer non-linear networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:43:02 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:41:49 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 15:04:41 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Woodworth", "Blake", ""], ["Gunasekar", "Suriya", ""], ["Lee", "Jason D.", ""], ["Moroshko", "Edward", ""], ["Savarese", "Pedro", ""], ["Golan", "Itay", ""], ["Soudry", "Daniel", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.09283", "submitter": "Bin Hu", "authors": "Hanshu Cai, Yiwen Gao, Shuting Sun, Na Li, Fuze Tian, Han Xiao,\n  Jianxiu Li, Zhengwu Yang, Xiaowei Li, Qinglin Zhao, Zhenyu Liu, Zhijun Yao,\n  Minqiang Yang, Hong Peng, Jing Zhu, Xiaowei Zhang, Guoping Gao, Fang Zheng,\n  Rui Li, Zhihua Guo, Rong Ma, Jing Yang, Lan Zhang, Xiping Hu, Yumin Li, Bin\n  Hu", "title": "MODMA dataset: a Multi-modal Open Dataset for Mental-disorder Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the World Health Organization, the number of mental disorder\npatients, especially depression patients, has grown rapidly and become a\nleading contributor to the global burden of disease. However, the present\ncommon practice of depression diagnosis is based on interviews and clinical\nscales carried out by doctors, which is not only labor-consuming but also\ntime-consuming. One important reason is due to the lack of physiological\nindicators for mental disorders. With the rising of tools such as data mining\nand artificial intelligence, using physiological data to explore new possible\nphysiological indicators of mental disorder and creating new applications for\nmental disorder diagnosis has become a new research hot topic. However, good\nquality physiological data for mental disorder patients are hard to acquire. We\npresent a multi-modal open dataset for mental-disorder analysis. The dataset\nincludes EEG and audio data from clinically depressed patients and matching\nnormal controls. All our patients were carefully diagnosed and selected by\nprofessional psychiatrists in hospitals. The EEG dataset includes not only data\ncollected using traditional 128-electrodes mounted elastic cap, but also a\nnovel wearable 3-electrode EEG collector for pervasive applications. The\n128-electrodes EEG signals of 53 subjects were recorded as both in resting\nstate and under stimulation; the 3-electrode EEG signals of 55 subjects were\nrecorded in resting state; the audio data of 52 subjects were recorded during\ninterviewing, reading, and picture description. We encourage other researchers\nin the field to use it for testing their methods of mental-disorder analysis.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 09:40:39 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 02:27:08 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 03:43:31 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cai", "Hanshu", ""], ["Gao", "Yiwen", ""], ["Sun", "Shuting", ""], ["Li", "Na", ""], ["Tian", "Fuze", ""], ["Xiao", "Han", ""], ["Li", "Jianxiu", ""], ["Yang", "Zhengwu", ""], ["Li", "Xiaowei", ""], ["Zhao", "Qinglin", ""], ["Liu", "Zhenyu", ""], ["Yao", "Zhijun", ""], ["Yang", "Minqiang", ""], ["Peng", "Hong", ""], ["Zhu", "Jing", ""], ["Zhang", "Xiaowei", ""], ["Gao", "Guoping", ""], ["Zheng", "Fang", ""], ["Li", "Rui", ""], ["Guo", "Zhihua", ""], ["Ma", "Rong", ""], ["Yang", "Jing", ""], ["Zhang", "Lan", ""], ["Hu", "Xiping", ""], ["Li", "Yumin", ""], ["Hu", "Bin", ""]]}, {"id": "2002.09284", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche and Auguste Hirth", "title": "On The Reasons Behind Decisions", "comments": "To appear in the proceedings of European Conference on Artificial\n  Intelligence (ECAI), Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that some common machine learning classifiers can be\ncompiled into Boolean circuits that have the same input-output behavior. We\npresent a theory for unveiling the reasons behind the decisions made by Boolean\nclassifiers and study some of its theoretical and practical implications. We\ndefine notions such as sufficient, necessary and complete reasons behind\ndecisions, in addition to classifier and decision bias. We show how these\nnotions can be used to evaluate counterfactual statements such as \"a decision\nwill stick even if ... because ... .\" We present efficient algorithms for\ncomputing these notions, which are based on new advances on tractable Boolean\ncircuits, and illustrate them using a case study.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:37:29 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""], ["Hirth", "Auguste", ""]]}, {"id": "2002.09285", "submitter": "Maxime Martineau", "authors": "Maxime Martineau, Romain Raveaux, Donatello Conte, Gilles Venturini", "title": "A Convolutional Neural Network into graph space", "comments": "arXiv admin note: text overlap with arXiv:1611.08402 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs), in a few decades, have outperformed the\nexisting state of the art methods in classification context. However, in the\nway they were formalised, CNNs are bound to operate on euclidean spaces.\nIndeed, convolution is a signal operation that are defined on euclidean spaces.\nThis has restricted deep learning main use to euclidean-defined data such as\nsound or image. And yet, numerous computer application fields (among which\nnetwork analysis, computational social science, chemo-informatics or computer\ngraphics) induce non-euclideanly defined data such as graphs, networks or\nmanifolds. In this paper we propose a new convolution neural network\narchitecture, defined directly into graph space. Convolution and pooling\noperators are defined in graph domain. We show its usability in a\nback-propagation context. Experimental results show that our model performance\nis at state of the art level on simple tasks. It shows robustness with respect\nto graph domain changes and improvement with respect to other euclidean and\nnon-euclidean convolutional architectures.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:14:21 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 12:59:14 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Martineau", "Maxime", ""], ["Raveaux", "Romain", ""], ["Conte", "Donatello", ""], ["Venturini", "Gilles", ""]]}, {"id": "2002.09286", "submitter": "M. Umut Isik", "authors": "Jonah Casebeer, Umut Isik, Shrikant Venkataramani, Arvindh\n  Krishnaswamy", "title": "Efficient Trainable Front-Ends for Neural Speech Enhancement", "comments": "5 pages, 5 figures, ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural speech enhancement and source separation systems operate in the\ntime-frequency domain. Such models often benefit from making their Short-Time\nFourier Transform (STFT) front-ends trainable. In current literature, these are\nimplemented as large Discrete Fourier Transform matrices; which are\nprohibitively inefficient for low-compute systems. We present an efficient,\ntrainable front-end based on the butterfly mechanism to compute the Fast\nFourier Transform, and show its accuracy and efficiency benefits for\nlow-compute neural speech enhancement models. We also explore the effects of\nmaking the STFT window trainable.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 01:51:15 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Casebeer", "Jonah", ""], ["Isik", "Umut", ""], ["Venkataramani", "Shrikant", ""], ["Krishnaswamy", "Arvindh", ""]]}, {"id": "2002.09291", "submitter": "Simiao Zuo", "authors": "Simiao Zuo, Haoming Jiang, Zichong Li, Tuo Zhao, Hongyuan Zha", "title": "Transformer Hawkes Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data acquisition routinely produce massive amounts of event sequence\ndata in various domains, such as social media, healthcare, and financial\nmarkets. These data often exhibit complicated short-term and long-term temporal\ndependencies. However, most of the existing recurrent neural network based\npoint process models fail to capture such dependencies, and yield unreliable\nprediction performance. To address this issue, we propose a Transformer Hawkes\nProcess (THP) model, which leverages the self-attention mechanism to capture\nlong-term dependencies and meanwhile enjoys computational efficiency. Numerical\nexperiments on various datasets show that THP outperforms existing models in\nterms of both likelihood and event prediction accuracy by a notable margin.\nMoreover, THP is quite general and can incorporate additional structural\nknowledge. We provide a concrete example, where THP achieves improved\nprediction performance for learning multiple point processes when incorporating\ntheir relational information.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 13:48:13 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 20:43:41 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 21:57:17 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 15:44:31 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 01:59:26 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zuo", "Simiao", ""], ["Jiang", "Haoming", ""], ["Li", "Zichong", ""], ["Zhao", "Tuo", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2002.09298", "submitter": "Hanan Salam", "authors": "Ahmed Rachid Hazourli and Amine Djeghri and Hanan Salam and Alice\n  Othmani", "title": "Deep Multi-Facial Patches Aggregation Network For Facial Expression\n  Recognition", "comments": "This article arXiv:2002.09298 is an updated version of\n  arXiv:1909.10305", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an approach for Facial Expressions Recognition\n(FER) based on a deep multi-facial patches aggregation network. Deep features\nare learned from facial patches using deep sub-networks and aggregated within\none deep architecture for expression classification . Several problems may\naffect the performance of deep-learning based FER approaches, in particular,\nthe small size of existing FER datasets which might not be sufficient to train\nlarge deep learning networks. Moreover, it is extremely time-consuming to\ncollect and annotate a large number of facial images. To account for this, we\npropose two data augmentation techniques for facial expression generation to\nexpand FER labeled training datasets. We evaluate the proposed framework on\nthree FER datasets. Results show that the proposed approach achieves\nstate-of-art FER deep learning approaches performance when the model is trained\nand tested on images from the same dataset. Moreover, the proposed data\naugmentation techniques improve the expression recognition rate, and thus can\nbe a solution for training deep learning FER models using small datasets. The\naccuracy degrades significantly when testing for dataset bias.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 17:57:06 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Hazourli", "Ahmed Rachid", ""], ["Djeghri", "Amine", ""], ["Salam", "Hanan", ""], ["Othmani", "Alice", ""]]}, {"id": "2002.09301", "submitter": "Hans Kersting", "authors": "Hans Kersting, Nicholas Kr\\\"amer, Martin Schiegg, Christian Daniel,\n  Michael Tiemann, Philipp Hennig", "title": "Differentiable Likelihoods for Fast Inversion of 'Likelihood-Free'\n  Dynamical Systems", "comments": "11 pages (+ 5 pages appendix), 6 figures", "journal-ref": null, "doi": null, "report-no": "Published at ICML 2020", "categories": "stat.ML cs.LG cs.NA math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Likelihood-free (a.k.a. simulation-based) inference problems are inverse\nproblems with expensive, or intractable, forward models. ODE inverse problems\nare commonly treated as likelihood-free, as their forward map has to be\nnumerically approximated by an ODE solver. This, however, is not a fundamental\nconstraint but just a lack of functionality in classic ODE solvers, which do\nnot return a likelihood but a point estimate. To address this shortcoming, we\nemploy Gaussian ODE filtering (a probabilistic numerical method for ODEs) to\nconstruct a local Gaussian approximation to the likelihood. This approximation\nyields tractable estimators for the gradient and Hessian of the\n(log-)likelihood. Insertion of these estimators into existing gradient-based\noptimization and sampling methods engenders new solvers for ODE inverse\nproblems. We demonstrate that these methods outperform standard likelihood-free\napproaches on three benchmark-systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:00:15 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 18:06:37 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kersting", "Hans", ""], ["Kr\u00e4mer", "Nicholas", ""], ["Schiegg", "Martin", ""], ["Daniel", "Christian", ""], ["Tiemann", "Michael", ""], ["Hennig", "Philipp", ""]]}, {"id": "2002.09303", "submitter": "Thomas Deselaers", "authors": "Philippe Gervais and Thomas Deselaers and Emre Aksan and Otmar\n  Hilliges", "title": "The DIDI dataset: Digital Ink Diagram data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We are releasing a dataset of diagram drawings with dynamic drawing\ninformation. The dataset aims to foster research in interactive graphical\nsymbolic understanding. The dataset was obtained using a prompted data\ncollection effort.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 16:16:28 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 11:56:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gervais", "Philippe", ""], ["Deselaers", "Thomas", ""], ["Aksan", "Emre", ""], ["Hilliges", "Otmar", ""]]}, {"id": "2002.09304", "submitter": "Gabriel Turinici", "authors": "Imen Ayadi (CEREMADE), Gabriel Turinici (CEREMADE)", "title": "Stochastic Runge-Kutta methods and adaptive SGD-G2 stochastic gradient\n  descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of the loss function is of paramount importance in deep\nneural networks. On the other hand, many popular optimization algorithms have\nbeen shown to correspond to some evolution equation of gradient flow type.\nInspired by the numerical schemes used for general evolution equations we\nintroduce a second order stochastic Runge Kutta method and show that it yields\na consistent procedure for the minimization of the loss function. In addition\nit can be coupled, in an adaptive framework, with a Stochastic Gradient Descent\n(SGD) to adjust automatically the learning rate of the SGD, without the need of\nany additional information on the Hessian of the loss functional. The adaptive\nSGD, called SGD-G2, is successfully tested on standard datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:45:53 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Ayadi", "Imen", "", "CEREMADE"], ["Turinici", "Gabriel", "", "CEREMADE"]]}, {"id": "2002.09309", "submitter": "Alexander Terenin", "authors": "James T. Wilson and Viacheslav Borovitskiy and Alexander Terenin and\n  Peter Mostowsky and Marc Peter Deisenroth", "title": "Efficiently Sampling Functions from Gaussian Process Posteriors", "comments": null, "journal-ref": "International Conference on Machine Learning, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are the gold standard for many real-world modeling\nproblems, especially in cases where a model's success hinges upon its ability\nto faithfully represent predictive uncertainty. These problems typically exist\nas parts of larger frameworks, wherein quantities of interest are ultimately\ndefined by integrating over posterior distributions. These quantities are\nfrequently intractable, motivating the use of Monte Carlo methods. Despite\nsubstantial progress in scaling up Gaussian processes to large training sets,\nmethods for accurately generating draws from their posterior distributions\nstill scale cubically in the number of test locations. We identify a\ndecomposition of Gaussian processes that naturally lends itself to scalable\nsampling by separating out the prior from the data. Building off of this\nfactorization, we propose an easy-to-use and general-purpose approach for fast\nposterior sampling, which seamlessly pairs with sparse approximations to afford\nscalability both during training and at test time. In a series of experiments\ndesigned to test competing sampling schemes' statistical properties and\npractical ramifications, we demonstrate how decoupled sample paths accurately\nrepresent Gaussian process posteriors at a fraction of the usual cost.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:03:16 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 16:22:27 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:13:39 GMT"}, {"version": "v4", "created": "Sun, 16 Aug 2020 13:37:40 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wilson", "James T.", ""], ["Borovitskiy", "Viacheslav", ""], ["Terenin", "Alexander", ""], ["Mostowsky", "Peter", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "2002.09320", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "An Advance on Variable Elimination with Applications to Tensor-Based\n  Computation", "comments": "To Appear in Proceedings of the European Conference on Artificial\n  Intelligence (ECAI), Spain, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new results on the classical algorithm of variable elimination,\nwhich underlies many algorithms including for probabilistic inference. The\nresults relate to exploiting functional dependencies, allowing one to perform\ninference and learning efficiently on models that have very large treewidth.\nThe highlight of the advance is that it works with standard (dense) factors,\nwithout the need for sparse factors or techniques based on knowledge\ncompilation that are commonly utilized. This is significant as it permits a\ndirect implementation of the improved variable elimination algorithm using\ntensors and their operations, leading to extremely efficient implementations\nespecially when learning model parameters. Moreover, the proposed technique\ndoes not require knowledge of the specific functional dependencies, only that\nthey exist, so can be used when learning these dependencies. We illustrate the\nefficacy of our proposed algorithm by compiling Bayesian network queries into\ntensor graphs and then learning their parameters from labeled data using a\nstandard tool for tensor computation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:17:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "2002.09334", "submitter": "Xukun Li", "authors": "Xiaowei Xu, Xiangao Jiang, Chunlian Ma, Peng Du, Xukun Li, Shuangzhi\n  Lv, Liang Yu, Yanfei Chen, Junwei Su, Guanjing Lang, Yongtao Li, Hong Zhao,\n  Kaijin Xu, Lingxiang Ruan, Wei Wu", "title": "Deep Learning System to Screen Coronavirus Disease 2019 Pneumonia", "comments": null, "journal-ref": "Engineering, Volume 6, Issue 10, October 2020, Pages 1122-1129", "doi": "10.1016/j.eng.2020.04.010", "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We found that the real time reverse transcription-polymerase chain reaction\n(RT-PCR) detection of viral RNA from sputum or nasopharyngeal swab has a\nrelatively low positive rate in the early stage to determine COVID-19 (named by\nthe World Health Organization). The manifestations of computed tomography (CT)\nimaging of COVID-19 had their own characteristics, which are different from\nother types of viral pneumonia, such as Influenza-A viral pneumonia. Therefore,\nclinical doctors call for another early diagnostic criteria for this new type\nof pneumonia as soon as possible.This study aimed to establish an early\nscreening model to distinguish COVID-19 pneumonia from Influenza-A viral\npneumonia and healthy cases with pulmonary CT images using deep learning\ntechniques. The candidate infection regions were first segmented out using a\n3-dimensional deep learning model from pulmonary CT image set. These separated\nimages were then categorized into COVID-19, Influenza-A viral pneumonia and\nirrelevant to infection groups, together with the corresponding confidence\nscores using a location-attention classification model. Finally the infection\ntype and total confidence score of this CT case were calculated with Noisy-or\nBayesian function.The experiments result of benchmark dataset showed that the\noverall accuracy was 86.7 % from the perspective of CT cases as a whole.The\ndeep learning models established in this study were effective for the early\nscreening of COVID-19 patients and demonstrated to be a promising supplementary\ndiagnostic method for frontline clinical doctors.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:44:21 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Xu", "Xiaowei", ""], ["Jiang", "Xiangao", ""], ["Ma", "Chunlian", ""], ["Du", "Peng", ""], ["Li", "Xukun", ""], ["Lv", "Shuangzhi", ""], ["Yu", "Liang", ""], ["Chen", "Yanfei", ""], ["Su", "Junwei", ""], ["Lang", "Guanjing", ""], ["Li", "Yongtao", ""], ["Zhao", "Hong", ""], ["Xu", "Kaijin", ""], ["Ruan", "Lingxiang", ""], ["Wu", "Wei", ""]]}, {"id": "2002.09339", "submitter": "Bruno Loureiro", "authors": "Federica Gerace, Bruno Loureiro, Florent Krzakala, Marc M\\'ezard and\n  Lenka Zdeborov\\'a", "title": "Generalisation error in learning with random features and the hidden\n  manifold model", "comments": "v2: ICML 2020 camera-ready", "journal-ref": "International Conference on Machine Learning, ICML 2020", "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study generalised linear regression and classification for a synthetically\ngenerated dataset encompassing different problems of interest, such as learning\nwith random features, neural networks in the lazy training regime, and the\nhidden manifold model. We consider the high-dimensional regime and using the\nreplica method from statistical physics, we provide a closed-form expression\nfor the asymptotic generalisation performance in these problems, valid in both\nthe under- and over-parametrised regimes and for a broad choice of generalised\nlinear model loss functions. In particular, we show how to obtain analytically\nthe so-called double descent behaviour for logistic regression with a peak at\nthe interpolation threshold, we illustrate the superiority of orthogonal\nagainst random Gaussian projections in learning with random features, and\ndiscuss the role played by correlations in the data generated by the hidden\nmanifold model. Beyond the interest in these particular problems, the\ntheoretical formalism introduced in this manuscript provides a path to further\nextensions to more complex tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:49:41 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 08:32:53 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Gerace", "Federica", ""], ["Loureiro", "Bruno", ""], ["Krzakala", "Florent", ""], ["M\u00e9zard", "Marc", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2002.09343", "submitter": "Wenshuo Guo", "authors": "Serena Wang, Wenshuo Guo, Harikrishna Narasimhan, Andrew Cotter, Maya\n  Gupta, Michael I. Jordan", "title": "Robust Optimization for Fairness with Noisy Protected Groups", "comments": "To appear at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020); first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing fairness criteria for machine learning involve equalizing some\nmetric across protected groups such as race or gender. However, practitioners\ntrying to audit or enforce such group-based criteria can easily face the\nproblem of noisy or biased protected group information. First, we study the\nconsequences of naively relying on noisy protected group labels: we provide an\nupper bound on the fairness violations on the true groups G when the fairness\ncriteria are satisfied on noisy groups $\\hat{G}$. Second, we introduce two new\napproaches using robust optimization that, unlike the naive approach of only\nrelying on $\\hat{G}$, are guaranteed to satisfy fairness criteria on the true\nprotected groups G while minimizing a training objective. We provide\ntheoretical guarantees that one such approach converges to an optimal feasible\nsolution. Using two case studies, we show empirically that the robust\napproaches achieve better true group fairness guarantees than the naive\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 14:58:37 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:21:20 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 05:37:29 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Wang", "Serena", ""], ["Guo", "Wenshuo", ""], ["Narasimhan", "Harikrishna", ""], ["Cotter", "Andrew", ""], ["Gupta", "Maya", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.09364", "submitter": "Arnaud Van Looveren", "authors": "Giovanni Vacanti and Arnaud Van Looveren", "title": "Adversarial Detection and Correction by Matching Prediction\n  Distributions", "comments": "13 pages, 16 figures. For an open source implementation of the\n  algorithm, see https://github.com/SeldonIO/alibi-detect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel adversarial detection and correction method for machine\nlearning classifiers.The detector consists of an autoencoder trained with a\ncustom loss function based on the Kullback-Leibler divergence between the\nclassifier predictions on the original and reconstructed instances.The method\nis unsupervised, easy to train and does not require any knowledge about the\nunderlying attack. The detector almost completely neutralises powerful attacks\nlike Carlini-Wagner or SLIDE on MNIST and Fashion-MNIST, and remains very\neffective on CIFAR-10 when the attack is granted full access to the\nclassification model but not the defence. We show that our method is still able\nto detect the adversarial examples in the case of a white-box attack where the\nattacker has full knowledge of both the model and the defence and investigate\nthe robustness of the attack. The method is very flexible and can also be used\nto detect common data corruptions and perturbations which negatively impact the\nmodel performance. We illustrate this capability on the CIFAR-10-C dataset.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 15:45:42 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Vacanti", "Giovanni", ""], ["Van Looveren", "Arnaud", ""]]}, {"id": "2002.09380", "submitter": "Y. A. Joarder", "authors": "Y. A. Joarder (1) and Mosabbir Ahmed (2) ((1,2) Department of Computer\n  Science and Engineering, World University of Bangladesh (WUB), Dhaka,\n  Bangladesh)", "title": "A Hybrid Algorithm Based Robust Big Data Clustering for Solving\n  Unhealthy Initialization, Dynamic Centroid Selection and Empty clustering\n  Problems with Analysis", "comments": "18 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data is a massive volume of both structured and unstructured data that is\ntoo large and it also difficult to process using traditional techniques.\nClustering algorithms have developed as a powerful learning tool that can\nexactly analyze the volume of data that produced by modern applications.\nClustering in data mining is the grouping of a particular set of objects based\non their characteristics. The main aim of clustering is to classified data into\nclusters such that objects are grouped in the same clusters when they are\ncorresponding according to similarities and features mainly. Till now, K-MEANS\nis the best utilized calculation connected in a wide scope of zones to\nrecognize gatherings where cluster separations are a lot than between gathering\nseparations. Our developed algorithm works with K-MEANS for high quality\nclustering during clustering from big data. Our proposed algorithm EG K-MEANS :\nExtended Generation K-MEANS solves mainly three issues of K-MEANS: unhealthy\ninitialization, dynamic centroid selection and empty clustering. It ensures the\nbest way of preventing unhealthy initialization, dynamic centroid selection and\nempty clustering problems for getting high quality clustering.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:09:19 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Joarder", "Y. A.", ""], ["Ahmed", "Mosabbir", ""]]}, {"id": "2002.09398", "submitter": "Moshe Gabel", "authors": "Gal Yehuda, Moshe Gabel, Assaf Schuster", "title": "It's Not What Machines Can Learn, It's What We Cannot Teach", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can deep neural networks learn to solve any task, and in particular problems\nof high complexity? This question attracts a lot of interest, with recent works\ntackling computationally hard tasks such as the traveling salesman problem and\nsatisfiability. In this work we offer a different perspective on this question.\nGiven the common assumption that $\\textit{NP} \\neq \\textit{coNP}$ we prove that\nany polynomial-time sample generator for an $\\textit{NP}$-hard problem samples,\nin fact, from an easier sub-problem. We empirically explore a case study,\nConjunctive Query Containment, and show how common data generation techniques\ngenerate biased datasets that lead practitioners to over-estimate model\naccuracy. Our results suggest that machine learning approaches that require\ntraining on a dense uniform sampling from the target distribution cannot be\nused to solve computationally hard problems, the reason being the difficulty of\ngenerating sufficiently large and unbiased training sets.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:26:55 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 16:43:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yehuda", "Gal", ""], ["Gabel", "Moshe", ""], ["Schuster", "Assaf", ""]]}, {"id": "2002.09402", "submitter": "Sainbayar Sukhbaatar", "authors": "Angela Fan, Thibaut Lavril, Edouard Grave, Armand Joulin, Sainbayar\n  Sukhbaatar", "title": "Addressing Some Limitations of Transformers with Feedback Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have been successfully applied to sequential, auto-regressive\ntasks despite being feedforward networks. Unlike recurrent neural networks,\nTransformers use attention to capture temporal relations while processing input\ntokens in parallel. While this parallelization makes them computationally\nefficient, it restricts the model from fully exploiting the sequential nature\nof the input. The representation at a given layer can only access\nrepresentations from lower layers, rather than the higher level representations\nalready available. In this work, we propose the Feedback Transformer\narchitecture that exposes all previous representations to all future\nrepresentations, meaning the lowest representation of the current timestep is\nformed from the highest-level abstract representation of the past. We\ndemonstrate on a variety of benchmarks in language modeling, machine\ntranslation, and reinforcement learning that the increased representation\ncapacity can create small, shallow models with much stronger performance than\ncomparable Transformers.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:37:57 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 09:21:14 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 13:12:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Fan", "Angela", ""], ["Lavril", "Thibaut", ""], ["Grave", "Edouard", ""], ["Joulin", "Armand", ""], ["Sukhbaatar", "Sainbayar", ""]]}, {"id": "2002.09405", "submitter": "Alvaro Sanchez-Gonzalez", "authors": "Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure\n  Leskovec, Peter W. Battaglia", "title": "Learning to Simulate Complex Physics with Graph Networks", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present a machine learning framework and model implementation that\ncan learn to simulate a wide variety of challenging physical domains, involving\nfluids, rigid solids, and deformable materials interacting with one another.\nOur framework---which we term \"Graph Network-based Simulators\"\n(GNS)---represents the state of a physical system with particles, expressed as\nnodes in a graph, and computes dynamics via learned message-passing. Our\nresults show that our model can generalize from single-timestep predictions\nwith thousands of particles during training, to different initial conditions,\nthousands of timesteps, and at least an order of magnitude more particles at\ntest time. Our model was robust to hyperparameter choices across various\nevaluation metrics: the main determinants of long-term performance were the\nnumber of message-passing steps, and mitigating the accumulation of error by\ncorrupting the training data with noise. Our GNS framework advances the\nstate-of-the-art in learned physical simulation, and holds promise for solving\na wide range of complex forward and inverse problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:44:28 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 16:52:10 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sanchez-Gonzalez", "Alvaro", ""], ["Godwin", "Jonathan", ""], ["Pfaff", "Tobias", ""], ["Ying", "Rex", ""], ["Leskovec", "Jure", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "2002.09420", "submitter": "Robin Vogel", "authors": "Stephan Cl\\'emen\\c{c}on, Robin Vogel", "title": "A Multiclass Classification Approach to Label Ranking", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiclass classification, the goal is to learn how to predict a random\nlabel $Y$, valued in $\\mathcal{Y}=\\{1,\\; \\ldots,\\; K \\}$ with $K\\geq 3$, based\nupon observing a r.v. $X$, taking its values in $\\mathbb{R}^q$ with $q\\geq 1$\nsay, by means of a classification rule $g:\\mathbb{R}^q\\to \\mathcal{Y}$ with\nminimum probability of error $\\mathbb{P}\\{Y\\neq g(X) \\}$. However, in a wide\nvariety of situations, the task targeted may be more ambitious, consisting in\nsorting all the possible label values $y$ that may be assigned to $X$ by\ndecreasing order of the posterior probability $\\eta_y(X)=\\mathbb{P}\\{Y=y \\mid X\n\\}$. This article is devoted to the analysis of this statistical learning\nproblem, halfway between multiclass classification and posterior probability\nestimation (regression) and referred to as label ranking here. We highlight the\nfact that it can be viewed as a specific variant of ranking median regression\n(RMR), where, rather than observing a random permutation $\\Sigma$ assigned to\nthe input vector $X$ and drawn from a Bradley-Terry-Luce-Plackett model with\nconditional preference vector $(\\eta_1(X),\\; \\ldots,\\; \\eta_K(X))$, the sole\ninformation available for training a label ranking rule is the label $Y$ ranked\non top, namely $\\Sigma^{-1}(1)$. Inspired by recent results in RMR, we prove\nthat under appropriate noise conditions, the One-Versus-One (OVO) approach to\nmulticlassification yields, as a by-product, an optimal ranking of the labels\nwith overwhelming probability. Beyond theoretical guarantees, the relevance of\nthe approach to label ranking promoted in this article is supported by\nexperimental results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:12:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Cl\u00e9men\u00e7on", "Stephan", ""], ["Vogel", "Robin", ""]]}, {"id": "2002.09422", "submitter": "Sharon Qian", "authors": "Sharon Qian, Dimitris Kalimeris, Gal Kaplun, Yaron Singer", "title": "Robustness from Simple Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the vast success of Deep Neural Networks in numerous application\ndomains, it has been shown that such models are not robust i.e., they are\nvulnerable to small adversarial perturbations of the input. While extensive\nwork has been done on why such perturbations occur or how to successfully\ndefend against them, we still do not have a complete understanding of\nrobustness. In this work, we investigate the connection between robustness and\nsimplicity. We find that simpler classifiers, formed by reducing the number of\noutput classes, are less susceptible to adversarial perturbations.\nConsequently, we demonstrate that decomposing a complex multiclass model into\nan aggregation of binary models enhances robustness. This behavior is\nconsistent across different datasets and model architectures and can be\ncombined with known defense techniques such as adversarial training. Moreover,\nwe provide further evidence of a disconnect between standard and robust\nlearning regimes. In particular, we show that elaborate label information can\nhelp standard accuracy but harm robustness.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:13:37 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Qian", "Sharon", ""], ["Kalimeris", "Dimitris", ""], ["Kaplun", "Gal", ""], ["Singer", "Yaron", ""]]}, {"id": "2002.09423", "submitter": "David Torpey", "authors": "David Torpey and Turgay Celik", "title": "Human Action Recognition using Local Two-Stream Convolution Neural\n  Network Features and Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple yet effective method for human action\nrecognition in video. The proposed method separately extracts local appearance\nand motion features using state-of-the-art three-dimensional convolutional\nneural networks from sampled snippets of a video. These local features are then\nconcatenated to form global representations which are then used to train a\nlinear SVM to perform the action classification using full context of the\nvideo, as partial context as used in previous works. The videos undergo two\nsimple proposed preprocessing techniques, optical flow scaling and crop\nfilling. We perform an extensive evaluation on three common benchmark dataset\nto empirically show the benefit of the SVM, and the two preprocessing steps.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 17:26:32 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Torpey", "David", ""], ["Celik", "Turgay", ""]]}, {"id": "2002.09424", "submitter": "David Torpey", "authors": "Ziyad Jappie and David Torpey and Turgay Celik", "title": "SummaryNet: A Multi-Stage Deep Learning Model for Automatic Video\n  Summarisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video summarisation can be posed as the task of extracting important parts of\na video in order to create an informative summary of what occurred in the\nvideo. In this paper we introduce SummaryNet as a supervised learning framework\nfor automated video summarisation. SummaryNet employs a two-stream\nconvolutional network to learn spatial (appearance) and temporal (motion)\nrepresentations. It utilizes an encoder-decoder model to extract the most\nsalient features from the learned video representations. Lastly, it uses a\nsigmoid regression network with bidirectional long short-term memory cells to\npredict the probability of a frame being a summary frame. Experimental results\non benchmark datasets show that the proposed method achieves comparable or\nsignificantly better results than the state-of-the-art video summarisation\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:24:35 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Jappie", "Ziyad", ""], ["Torpey", "David", ""], ["Celik", "Turgay", ""]]}, {"id": "2002.09434", "submitter": "Qi Lei", "authors": "Simon S. Du, Wei Hu, Sham M. Kakade, Jason D. Lee, Qi Lei", "title": "Few-Shot Learning via Learning the Representation, Provably", "comments": "ICLR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies few-shot learning via representation learning, where one\nuses $T$ source tasks with $n_1$ data per task to learn a representation in\norder to reduce the sample complexity of a target task for which there is only\n$n_2 (\\ll n_1)$ data. Specifically, we focus on the setting where there exists\na good \\emph{common representation} between source and target, and our goal is\nto understand how much of a sample size reduction is possible. First, we study\nthe setting where this common representation is low-dimensional and provide a\nfast rate of $O\\left(\\frac{\\mathcal{C}\\left(\\Phi\\right)}{n_1T} +\n\\frac{k}{n_2}\\right)$; here, $\\Phi$ is the representation function class,\n$\\mathcal{C}\\left(\\Phi\\right)$ is its complexity measure, and $k$ is the\ndimension of the representation. When specialized to linear representation\nfunctions, this rate becomes $O\\left(\\frac{dk}{n_1T} + \\frac{k}{n_2}\\right)$\nwhere $d (\\gg k)$ is the ambient input dimension, which is a substantial\nimprovement over the rate without using representation learning, i.e. over the\nrate of $O\\left(\\frac{d}{n_2}\\right)$. This result bypasses the\n$\\Omega(\\frac{1}{T})$ barrier under the i.i.d. task assumption, and can capture\nthe desired property that all $n_1T$ samples from source tasks can be\n\\emph{pooled} together for representation learning. Next, we consider the\nsetting where the common representation may be high-dimensional but is\ncapacity-constrained (say in norm); here, we again demonstrate the advantage of\nrepresentation learning in both high-dimensional linear regression and neural\nnetwork learning. Our results demonstrate representation learning can fully\nutilize all $n_1T$ samples from source tasks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:30:00 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 04:06:04 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Lei", "Qi", ""]]}, {"id": "2002.09436", "submitter": "Sebastian Pina-Otey", "authors": "Sebastian Pina-Otey, Federico S\\'anchez, Vicens Gaitan and Thorsten\n  Lux", "title": "Likelihood-free inference of experimental Neutrino Oscillations using\n  Neural Spline Flows", "comments": "10 pages, 3 figures", "journal-ref": "Phys. Rev. D 101, 113001 (2020)", "doi": "10.1103/PhysRevD.101.113001", "report-no": null, "categories": "hep-ph cs.LG hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, likelihood-free inference refers to the task of\nperforming an analysis driven by data instead of an analytical expression. We\ndiscuss the application of Neural Spline Flows, a neural density estimation\nalgorithm, to the likelihood-free inference problem of the measurement of\nneutrino oscillation parameters in Long Baseline neutrino experiments. A method\nadapted to physics parameter inference is developed and applied to the case of\nthe disappearance muon neutrino analysis at the T2K experiment.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:35:08 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 19:00:26 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 06:18:32 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Pina-Otey", "Sebastian", ""], ["S\u00e1nchez", "Federico", ""], ["Gaitan", "Vicens", ""], ["Lux", "Thorsten", ""]]}, {"id": "2002.09437", "submitter": "Viveka Kulharia", "authors": "Jishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz,\n  Philip H.S. Torr, Puneet K. Dokania", "title": "Calibrating Deep Neural Networks using Focal Loss", "comments": "This paper was accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Miscalibration - a mismatch between a model's confidence and its correctness\n- of Deep Neural Networks (DNNs) makes their predictions hard to rely on.\nIdeally, we want networks to be accurate, calibrated and confident. We show\nthat, as opposed to the standard cross-entropy loss, focal loss [Lin et. al.,\n2017] allows us to learn models that are already very well calibrated. When\ncombined with temperature scaling, whilst preserving accuracy, it yields\nstate-of-the-art calibrated models. We provide a thorough analysis of the\nfactors causing miscalibration, and use the insights we glean from this to\njustify the empirically excellent performance of focal loss. To facilitate the\nuse of focal loss in practice, we also provide a principled approach to\nautomatically select the hyperparameter involved in the loss function. We\nperform extensive experiments on a variety of computer vision and NLP datasets,\nand with a wide variety of network architectures, and show that our approach\nachieves state-of-the-art calibration without compromising on accuracy in\nalmost all cases. Code is available at\nhttps://github.com/torrvision/focal_calibration.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:35:50 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 14:22:17 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mukhoti", "Jishnu", ""], ["Kulharia", "Viveka", ""], ["Sanyal", "Amartya", ""], ["Golodetz", "Stuart", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "2002.09438", "submitter": "Guang Cheng", "authors": "Chi-Hua Wang, Guang Cheng", "title": "Online Batch Decision-Making with High-Dimensional Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a class of new algorithms for sequential decision\nmaking that interacts with \\textit{a batch of users} simultaneously instead of\n\\textit{a user} at each decision epoch. This type of batch models is motivated\nby interactive marketing and clinical trial, where a group of people are\ntreated simultaneously and the outcomes of the whole group are collected before\nthe next stage of decision. In such a scenario, our goal is to allocate a batch\nof treatments to maximize treatment efficacy based on observed high-dimensional\nuser covariates. We deliver a solution, named \\textit{Teamwork LASSO Bandit\nalgorithm}, that resolves a batch version of explore-exploit dilemma via\nswitching between teamwork stage and selfish stage during the whole decision\nprocess. This is made possible based on statistical properties of LASSO\nestimate of treatment efficacy that adapts to a sequence of batch observations.\nIn general, a rate of optimal allocation condition is proposed to delineate the\nexploration and exploitation trade-off on the data collection scheme, which is\nsufficient for LASSO to identify the optimal treatment for observed user\ncovariates. An upper bound on expected cumulative regret of the proposed\nalgorithm is provided.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:36:15 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 20:43:39 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Wang", "Chi-Hua", ""], ["Cheng", "Guang", ""]]}, {"id": "2002.09441", "submitter": "Nate Veldt", "authors": "Nate Veldt and Austin R. Benson and Jon Kleinberg", "title": "Minimizing Localized Ratio Cut Objectives in Hypergraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraphs are a useful abstraction for modeling multiway relationships in\ndata, and hypergraph clustering is the task of detecting groups of closely\nrelated nodes in such data. Graph clustering has been studied extensively, and\nthere are numerous methods for detecting small, localized clusters without\nhaving to explore an entire input graph. However, there are only a few\nspecialized approaches for localized clustering in hypergraphs. Here we present\na framework for local hypergraph clustering based on minimizing localized ratio\ncut objectives. Our framework takes an input set of reference nodes in a\nhypergraph and solves a sequence of hypergraph minimum $s$-$t$ cut problems in\norder to identify a nearby well-connected cluster of nodes that overlaps\nsubstantially with the input set.\n  Our methods extend graph-based techniques but are significantly more general\nand have new output quality guarantees. First, our methods can minimize new\ngeneralized notions of hypergraph cuts, which depend on specific configurations\nof nodes within each hyperedge, rather than just on the number of cut\nhyperedges. Second, our framework has several attractive theoretical properties\nin terms of output cluster quality. Most importantly, our algorithm is\nstrongly-local, meaning that its runtime depends only on the size of the input\nset, and does not need to explore the entire hypergraph to find good local\nclusters. We use our methodology to effectively identify clusters in\nhypergraphs of real-world data with millions of nodes, millions of hyperedges,\nand large average hyperedge size with runtimes ranging between a few seconds\nand a few minutes.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:42:22 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 02:48:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Veldt", "Nate", ""], ["Benson", "Austin R.", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2002.09460", "submitter": "Nate Veldt", "authors": "Nate Veldt and Anthony Wirth and David F. Gleich", "title": "Parameterized Correlation Clustering in Hypergraphs and Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications in community detection and dense subgraph\ndiscovery, we consider new clustering objectives in hypergraphs and bipartite\ngraphs. These objectives are parameterized by one or more resolution parameters\nin order to enable diverse knowledge discovery in complex data.\n  For both hypergraph and bipartite objectives, we identify parameter regimes\nthat are equivalent to existing objectives and share their (polynomial-time)\napproximation algorithms. We first show that our parameterized hypergraph\ncorrelation clustering objective is related to higher-order notions of\nnormalized cut and modularity in hypergraphs. It is further amenable to\napproximation algorithms via hyperedge expansion techniques.\n  Our parameterized bipartite correlation clustering objective generalizes\nstandard unweighted bipartite correlation clustering, as well as bicluster\ndeletion. For a certain choice of parameters it is also related to our\nhypergraph objective. Although in general it is NP-hard, we highlight a\nparameter regime for the bipartite objective where the problem reduces to the\nbipartite matching problem and thus can be solved in polynomial time. For other\nparameter settings, we present approximation algorithms using linear program\nrounding techniques. These results allow us to introduce the first\nconstant-factor approximation for bicluster deletion, the task of removing a\nminimum number of edges to partition a bipartite graph into disjoint\nbi-cliques.\n  In several experimental results, we highlight the flexibility of our\nframework and the diversity of results that can be obtained in different\nparameter settings. This includes clustering bipartite graphs across a range of\nparameters, detecting motif-rich clusters in an email network and a food web,\nand forming clusters of retail products in a product review hypergraph, that\nare highly correlated with known product categories.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:26:53 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 15:10:01 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Veldt", "Nate", ""], ["Wirth", "Anthony", ""], ["Gleich", "David F.", ""]]}, {"id": "2002.09463", "submitter": "Huanyu Zhang", "authors": "Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, Zhiwei Steven Wu", "title": "Privately Learning Markov Random Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning Markov Random Fields (including the\nprototypical example, the Ising model) under the constraint of differential\nprivacy. Our learning goals include both structure learning, where we try to\nestimate the underlying graph structure of the model, as well as the harder\ngoal of parameter learning, in which we additionally estimate the parameter on\neach edge. We provide algorithms and lower bounds for both problems under a\nvariety of privacy constraints -- namely pure, concentrated, and approximate\ndifferential privacy. While non-privately, both learning goals enjoy roughly\nthe same complexity, we show that this is not the case under differential\nprivacy. In particular, only structure learning under approximate differential\nprivacy maintains the non-private logarithmic dependence on the dimensionality\nof the data, while a change in either the learning goal or the privacy notion\nwould necessitate a polynomial dependence. As a result, we show that the\nprivacy constraint imposes a strong separation between these two learning\nproblems in the high-dimensional data regime.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:24:58 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Zhang", "Huanyu", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2002.09464", "submitter": "Vikrant Singhal", "authors": "Gautam Kamath, Vikrant Singhal, Jonathan Ullman", "title": "Private Mean Estimation of Heavy-Tailed Distributions", "comments": "Appeared in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give new upper and lower bounds on the minimax sample complexity of\ndifferentially private mean estimation of distributions with bounded $k$-th\nmoments. Roughly speaking, in the univariate case, we show that $n =\n\\Theta\\left(\\frac{1}{\\alpha^2} +\n\\frac{1}{\\alpha^{\\frac{k}{k-1}}\\varepsilon}\\right)$ samples are necessary and\nsufficient to estimate the mean to $\\alpha$-accuracy under\n$\\varepsilon$-differential privacy, or any of its common relaxations. This\nresult demonstrates a qualitatively different behavior compared to estimation\nabsent privacy constraints, for which the sample complexity is identical for\nall $k \\geq 2$. We also give algorithms for the multivariate setting whose\nsample complexity is a factor of $O(d)$ larger than the univariate case.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 22:24:31 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:06:17 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kamath", "Gautam", ""], ["Singhal", "Vikrant", ""], ["Ullman", "Jonathan", ""]]}, {"id": "2002.09465", "submitter": "Gautam Kamath", "authors": "Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov,\n  Zhiwei Steven Wu, Huanyu Zhang", "title": "Locally Private Hypothesis Selection", "comments": "To appear in COLT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of hypothesis selection under local differential\nprivacy. Given samples from an unknown probability distribution $p$ and a set\nof $k$ probability distributions $\\mathcal{Q}$, we aim to output, under the\nconstraints of $\\varepsilon$-local differential privacy, a distribution from\n$\\mathcal{Q}$ whose total variation distance to $p$ is comparable to the best\nsuch distribution. This is a generalization of the classic problem of $k$-wise\nsimple hypothesis testing, which corresponds to when $p \\in \\mathcal{Q}$, and\nwe wish to identify $p$. Absent privacy constraints, this problem requires\n$O(\\log k)$ samples from $p$, and it was recently shown that the same\ncomplexity is achievable under (central) differential privacy. However, the\nnaive approach to this problem under local differential privacy would require\n$\\tilde O(k^2)$ samples.\n  We first show that the constraint of local differential privacy incurs an\nexponential increase in cost: any algorithm for this problem requires at least\n$\\Omega(k)$ samples. Second, for the special case of $k$-wise simple hypothesis\ntesting, we provide a non-interactive algorithm which nearly matches this\nbound, requiring $\\tilde O(k)$ samples. Finally, we provide sequentially\ninteractive algorithms for the general case, requiring $\\tilde O(k)$ samples\nand only $O(\\log \\log k)$ rounds of interactivity. Our algorithms are achieved\nthrough a reduction to maximum selection with adversarial comparators, a\nproblem of independent interest for which we initiate study in the parallel\nsetting. For this problem, we provide a family of algorithms for each number of\nallowed rounds of interaction $t$, as well as lower bounds showing that they\nare near-optimal for every $t$. Notably, our algorithms result in exponential\nimprovements on the round complexity of previous methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:30:48 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 02:58:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Kamath", "Gautam", ""], ["Kulkarni", "Janardhan", ""], ["Nikolov", "Aleksandar", ""], ["Wu", "Zhiwei Steven", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2002.09469", "submitter": "Joao Monteiro", "authors": "Joao Monteiro, Isabela Albuquerque, Jahangir Alam, R Devon Hjelm,\n  Tiago Falk", "title": "An end-to-end approach for the verification problem: learning the right\n  distance", "comments": "ICML 2020 final camera ready. Code is available at:\n  https://github.com/joaomonteirof/e2e_verification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we augment the metric learning setting by introducing a\nparametric pseudo-distance, trained jointly with the encoder. Several\ninterpretations are thus drawn for the learned distance-like model's output. We\nfirst show it approximates a likelihood ratio which can be used for hypothesis\ntests, and that it further induces a large divergence across the joint\ndistributions of pairs of examples from the same and from different classes.\nEvaluation is performed under the verification setting consisting of\ndetermining whether sets of examples belong to the same class, even if such\nclasses are novel and were never presented to the model during training.\nEmpirical evaluation shows such method defines an end-to-end approach for the\nverification problem, able to attain better performance than simple scorers\nsuch as those based on cosine similarity and further outperforming widely used\ndownstream classifiers. We further observe training is much simplified under\nthe proposed approach compared to metric learning with actual distances,\nrequiring no complex scheme to harvest pairs of examples.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:46:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 00:09:11 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 21:46:22 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 16:20:28 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Monteiro", "Joao", ""], ["Albuquerque", "Isabela", ""], ["Alam", "Jahangir", ""], ["Hjelm", "R Devon", ""], ["Falk", "Tiago", ""]]}, {"id": "2002.09471", "submitter": "Yue Zhang", "authors": "Yue Zhang, Arti Ramesh", "title": "Learning Fairness-aware Relational Structures", "comments": "Accepted for publication in ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of fair machine learning models that effectively avert bias\nand discrimination is an important problem that has garnered attention in\nrecent years. The necessity of encoding complex relational dependencies among\nthe features and variables for competent predictions require the development of\nfair, yet expressive relational models. In this work, we introduce Fair-A3SL, a\nfairness-aware structure learning algorithm for learning relational structures,\nwhich incorporates fairness measures while learning relational graphical model\nstructures. Our approach is versatile in being able to encode a wide range of\nfairness metrics such as statistical parity difference, overestimation,\nequalized odds, and equal opportunity, including recently proposed relational\nfairness measures. While existing approaches employ the fairness measures on\npre-determined model structures post prediction, Fair-A3SL directly learns the\nstructure while optimizing for the fairness measures and hence is able to\nremove any structural bias in the model. We demonstrate the effectiveness of\nour learned model structures when compared with the state-of-the-art fairness\nmodels quantitatively and qualitatively on datasets representing three\ndifferent modeling scenarios: i) a relational dataset, ii) a recidivism\nprediction dataset widely used in studying discrimination, and iii) a\nrecommender systems dataset. Our results show that Fair-A3SL can learn fair,\nyet interpretable and expressive structures capable of making accurate\npredictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:53:52 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhang", "Yue", ""], ["Ramesh", "Arti", ""]]}, {"id": "2002.09473", "submitter": "Hegler Tissot", "authors": "Jianyu Liu and Hegler Tissot", "title": "Clustering as an Evaluation Protocol for Knowledge Embedding\n  Representation of Categorised Multi-relational Data in the Clinical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge representation is an increasingly important technology\napplicable in many domain-specific machine learning problems. We discuss the\neffectiveness of traditional Link Prediction or Knowledge Graph Completion\nevaluation protocol when embedding knowledge representation for categorised\nmulti-relational data in the clinical domain. Link prediction uses to split the\ndata into training and evaluation subsets, leading to loss of information along\ntraining and harming the knowledge representation model accuracy. We propose a\nClustering Evaluation Protocol as a replacement alternative to the\ntraditionally used evaluation tasks. We used embedding models trained by a\nknowledge embedding approach which has been evaluated with clinical datasets.\nExperimental results with Pearson and Spearman correlations show strong\nevidence that the novel proposed evaluation protocol is pottentially able to\nreplace link prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 16:04:22 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Liu", "Jianyu", ""], ["Tissot", "Hegler", ""]]}, {"id": "2002.09478", "submitter": "Ran Wang", "authors": "Ran Wang, Karthikeya S. Parunandi, Aayushman Sharma, Raman Goyal,\n  Suman Chakravorty", "title": "On the Search for Feedback in Reinforcement Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.08361", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Reinforcement Learning (RL) in an unknown nonlinear dynamical\nsystem is equivalent to the search for an optimal feedback law utilizing the\nsimulations/ rollouts of the unknown dynamical system. Most RL techniques\nsearch over a complex global nonlinear feedback parametrization making them\nsuffer from high training times as well as variance. Instead, we advocate\nsearching over a local feedback representation consisting of an open-loop\nsequence, and an associated optimal linear feedback law completely determined\nby the open-loop. We show that this alternate approach results in highly\nefficient training, the answers obtained are repeatable and hence reliable, and\nthe resulting closed performance is superior to global state-of-the-art RL\ntechniques. Finally, if we replan, whenever required, which is feasible due to\nthe fast and reliable local solution, allows us to recover global optimality of\nthe resulting feedback law.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 02:44:56 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:01:49 GMT"}, {"version": "v3", "created": "Wed, 4 Nov 2020 17:15:23 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2021 03:33:41 GMT"}, {"version": "v5", "created": "Fri, 16 Jul 2021 22:48:19 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wang", "Ran", ""], ["Parunandi", "Karthikeya S.", ""], ["Sharma", "Aayushman", ""], ["Goyal", "Raman", ""], ["Chakravorty", "Suman", ""]]}, {"id": "2002.09481", "submitter": "Vojtech Mrazek", "authors": "Filip Vaverka, Vojtech Mrazek, Zdenek Vasicek, Lukas Sekanina", "title": "TFApprox: Towards a Fast Emulation of DNN Approximate Hardware\n  Accelerators on GPU", "comments": "To appear at the 23rd Design, Automation and Test in Europe (DATE\n  2020). Grenoble, France", "journal-ref": null, "doi": "10.23919/DATE48585.2020.9116299", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency of hardware accelerators of deep neural networks (DNN) can\nbe improved by introducing approximate arithmetic circuits. In order to\nquantify the error introduced by using these circuits and avoid the expensive\nhardware prototyping, a software emulator of the DNN accelerator is usually\nexecuted on CPU or GPU. However, this emulation is typically two or three\norders of magnitude slower than a software DNN implementation running on CPU or\nGPU and operating with standard floating point arithmetic instructions and\ncommon DNN libraries. The reason is that there is no hardware support for\napproximate arithmetic operations on common CPUs and GPUs and these operations\nhave to be expensively emulated. In order to address this issue, we propose an\nefficient emulation method for approximate circuits utilized in a given DNN\naccelerator which is emulated on GPU. All relevant approximate circuits are\nimplemented as look-up tables and accessed through a texture memory mechanism\nof CUDA capable GPUs. We exploit the fact that the texture memory is optimized\nfor irregular read-only access and in some GPU architectures is even\nimplemented as a dedicated cache. This technique allowed us to reduce the\ninference time of the emulated DNN accelerator approximately 200 times with\nrespect to an optimized CPU version on complex DNNs such as ResNet. The\nproposed approach extends the TensorFlow library and is available online at\nhttps://github.com/ehw-fit/tf-approximate.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 08:22:56 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Vaverka", "Filip", ""], ["Mrazek", "Vojtech", ""], ["Vasicek", "Zdenek", ""], ["Sekanina", "Lukas", ""]]}, {"id": "2002.09485", "submitter": "\\'Angel Panizo-LLedot", "authors": "David Camacho, \\`Angel Panizo-LLedot, Gema Bello-Orgaz, Antonio\n  Gonzalez-Pardo, Erik Cambria", "title": "The Four Dimensions of Social Network Analysis: An Overview of Research\n  Methods, Applications, and Software Tools", "comments": "This paper is currently under evaluation in Information Fusion\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network based applications have experienced exponential growth in\nrecent years. One of the reasons for this rise is that this application domain\noffers a particularly fertile place to test and develop the most advanced\ncomputational techniques to extract valuable information from the Web. The main\ncontribution of this work is three-fold: (1) we provide an up-to-date\nliterature review of the state of the art on social network analysis (SNA);(2)\nwe propose a set of new metrics based on four essential features (or\ndimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of\npopular SNA tools and frameworks. We have also performed a scientometric study\nto detect the most active research areas and application domains in this area.\nThis work proposes the definition of four different dimensions, namely Pattern\n& Knowledge discovery, Information Fusion & Integration, Scalability, and\nVisualization, which are used to define a set of new metrics (termed degrees)\nin order to evaluate the different software tools and frameworks of SNA (a set\nof 20 SNA-software tools are analyzed and ranked following previous metrics).\nThese dimensions, together with the defined degrees, allow evaluating and\nmeasure the maturity of social network technologies, looking for both a\nquantitative assessment of them, as to shed light to the challenges and future\ntrends in this active area.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:11:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Camacho", "David", ""], ["Panizo-LLedot", "\u00c0ngel", ""], ["Bello-Orgaz", "Gema", ""], ["Gonzalez-Pardo", "Antonio", ""], ["Cambria", "Erik", ""]]}, {"id": "2002.09488", "submitter": "Jonathan Lacotte", "authors": "Jonathan Lacotte, Mert Pilanci", "title": "Optimal Randomized First-Order Methods for Least-Squares Problems", "comments": "arXiv admin note: text overlap with arXiv:2002.00864", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an exact analysis of a class of randomized algorithms for solving\noverdetermined least-squares problems. We consider first-order methods, where\nthe gradients are pre-conditioned by an approximation of the Hessian, based on\na subspace embedding of the data matrix. This class of algorithms encompasses\nseveral randomized methods among the fastest solvers for least-squares\nproblems. We focus on two classical embeddings, namely, Gaussian projections\nand subsampled randomized Hadamard transforms (SRHT). Our key technical\ninnovation is the derivation of the limiting spectral density of SRHT\nembeddings. Leveraging this novel result, we derive the family of normalized\northogonal polynomials of the SRHT density and we find the optimal\npre-conditioned first-order method along with its rate of convergence. Our\nanalysis of Gaussian embeddings proceeds similarly, and leverages classical\nrandom matrix theory results. In particular, we show that for a given sketch\nsize, SRHT embeddings exhibits a faster rate of convergence than Gaussian\nembeddings. Then, we propose a new algorithm by optimizing the computational\ncomplexity over the choice of the sketching dimension. To our knowledge, our\nresulting algorithm yields the best known complexity for solving least-squares\nproblems with no condition number dependence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 17:45:32 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 00:34:08 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Lacotte", "Jonathan", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.09505", "submitter": "Ashley Edwards", "authors": "Ashley D. Edwards, Himanshu Sahni, Rosanne Liu, Jane Hung, Ankit Jain,\n  Rui Wang, Adrien Ecoffet, Thomas Miconi, Charles Isbell, Jason Yosinski", "title": "Estimating Q(s,s') with Deep Deterministic Dynamics Gradients", "comments": "Accepted into ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel form of value function, $Q(s, s')$, that\nexpresses the utility of transitioning from a state $s$ to a neighboring state\n$s'$ and then acting optimally thereafter. In order to derive an optimal\npolicy, we develop a forward dynamics model that learns to make next-state\npredictions that maximize this value. This formulation decouples actions from\nvalues while still learning off-policy. We highlight the benefits of this\napproach in terms of value function transfer, learning within redundant action\nspaces, and learning off-policy from state observations generated by\nsub-optimal or completely random policies. Code and videos are available at\nhttp://sites.google.com/view/qss-paper.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:05:24 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 18:13:00 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Edwards", "Ashley D.", ""], ["Sahni", "Himanshu", ""], ["Liu", "Rosanne", ""], ["Hung", "Jane", ""], ["Jain", "Ankit", ""], ["Wang", "Rui", ""], ["Ecoffet", "Adrien", ""], ["Miconi", "Thomas", ""], ["Isbell", "Charles", ""], ["Yosinski", "Jason", ""]]}, {"id": "2002.09516", "submitter": "Yaqi Duan", "authors": "Yaqi Duan, Mengdi Wang", "title": "Minimax-Optimal Off-Policy Evaluation with Linear Function Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the statistical theory of batch data reinforcement\nlearning with function approximation. Consider the off-policy evaluation\nproblem, which is to estimate the cumulative value of a new target policy from\nlogged history generated by unknown behavioral policies. We study a\nregression-based fitted Q iteration method, and show that it is equivalent to a\nmodel-based method that estimates a conditional mean embedding of the\ntransition operator. We prove that this method is information-theoretically\noptimal and has nearly minimal estimation error. In particular, by leveraging\ncontraction property of Markov processes and martingale concentration, we\nestablish a finite-sample instance-dependent error upper bound and a\nnearly-matching minimax lower bound. The policy evaluation error depends\nsharply on a restricted $\\chi^2$-divergence over the function class between the\nlong-term distribution of the target policy and the distribution of past data.\nThis restricted $\\chi^2$-divergence is both instance-dependent and\nfunction-class-dependent. It characterizes the statistical limit of off-policy\nevaluation. Further, we provide an easily computable confidence bound for the\npolicy evaluator, which may be useful for optimistic planning and safe policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:20:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Duan", "Yaqi", ""], ["Wang", "Mengdi", ""]]}, {"id": "2002.09518", "submitter": "Kaveh Hassani", "authors": "Amir Hosein Khasahmadi, Kaveh Hassani, Parsa Moradi, Leo Lee, Quaid\n  Morris", "title": "Memory-Based Graph Networks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are a class of deep models that operate on data\nwith arbitrary topology represented as graphs. We introduce an efficient memory\nlayer for GNNs that can jointly learn node representations and coarsen the\ngraph. We also introduce two new networks based on this layer: memory-based GNN\n(MemGNN) and graph memory network (GMN) that can learn hierarchical graph\nrepresentations. The experimental results shows that the proposed models\nachieve state-of-the-art results in eight out of nine graph classification and\nregression benchmarks. We also show that the learned representations could\ncorrespond to chemical features in the molecule data. Code and reference\nimplementations are released at: https://github.com/amirkhas/GraphMemoryNet\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:26:31 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 04:50:41 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Khasahmadi", "Amir Hosein", ""], ["Hassani", "Kaveh", ""], ["Moradi", "Parsa", ""], ["Lee", "Leo", ""], ["Morris", "Quaid", ""]]}, {"id": "2002.09523", "submitter": "Yue Zhang", "authors": "Yue Zhang, Arti Ramesh", "title": "Struct-MMSB: Mixed Membership Stochastic Blockmodels with Interpretable\n  Structured Priors", "comments": "ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixed membership stochastic blockmodel (MMSB) is a popular framework for\ncommunity detection and network generation. It learns a low-rank mixed\nmembership representation for each node across communities by exploiting the\nunderlying graph structure. MMSB assumes that the membership distributions of\nthe nodes are independently drawn from a Dirichlet distribution, which limits\nits capability to model highly correlated graph structures that exist in\nreal-world networks. In this paper, we present a flexible richly structured\nMMSB model, \\textit{Struct-MMSB}, that uses a recently developed statistical\nrelational learning model, hinge-loss Markov random fields (HL-MRFs), as a\nstructured prior to model complex dependencies among node attributes,\nmulti-relational links, and their relationship with mixed-membership\ndistributions. Our model is specified using a probabilistic programming\ntemplating language that uses weighted first-order logic rules, which enhances\nthe model's interpretability. Further, our model is capable of learning latent\ncharacteristics in real-world networks via meaningful latent variables encoded\nas a complex combination of observed features and membership distributions. We\npresent an expectation-maximization based inference algorithm that learns\nlatent variables and parameters iteratively, a scalable stochastic variation of\nthe inference algorithm, and a method to learn the weights of HL-MRF structured\npriors. We evaluate our model on six datasets across three different types of\nnetworks and corresponding modeling scenarios and demonstrate that our models\nare able to achieve an improvement of 15\\% on average in test log-likelihood\nand faster convergence when compared to state-of-the-art network models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:32:32 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Yue", ""], ["Ramesh", "Arti", ""]]}, {"id": "2002.09526", "submitter": "Filip Hanzely", "authors": "Filip Hanzely, Nikita Doikov, Peter Richt\\'arik, Yurii Nesterov", "title": "Stochastic Subspace Cubic Newton Method", "comments": "29 pages, 5 figures, 1 table, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new randomized second-order optimization\nalgorithm---Stochastic Subspace Cubic Newton (SSCN)---for minimizing a high\ndimensional convex function $f$. Our method can be seen both as a {\\em\nstochastic} extension of the cubically-regularized Newton method of Nesterov\nand Polyak (2006), and a {\\em second-order} enhancement of stochastic subspace\ndescent of Kozak et al. (2019). We prove that as we vary the minibatch size,\nthe global convergence rate of SSCN interpolates between the rate of stochastic\ncoordinate descent (CD) and the rate of cubic regularized Newton, thus giving\nnew insights into the connection between first and second-order methods.\nRemarkably, the local convergence rate of SSCN matches the rate of stochastic\nsubspace descent applied to the problem of minimizing the quadratic function\n$\\frac12 (x-x^*)^\\top \\nabla^2f(x^*)(x-x^*)$, where $x^*$ is the minimizer of\n$f$, and hence depends on the properties of $f$ at the optimum only. Our\nnumerical experiments show that SSCN outperforms non-accelerated first-order CD\nalgorithms while being competitive to their accelerated variants.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 19:42:18 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hanzely", "Filip", ""], ["Doikov", "Nikita", ""], ["Richt\u00e1rik", "Peter", ""], ["Nesterov", "Yurii", ""]]}, {"id": "2002.09535", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Kai He, Liang Sun, Yingying Zhang, Min Ke, Huan Xu", "title": "RobustPeriod: Time-Frequency Mining for Robust Multiple Periodicity\n  Detection", "comments": "Accepted by SIGMOD 2021; 10 pages, 6 figures, 8 tables, and 70\n  referred papers", "journal-ref": null, "doi": "10.1145/3448016.3452779", "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Periodicity detection is a crucial step in time series tasks, including\nmonitoring and forecasting of metrics in many areas, such as IoT applications\nand self-driving database management system. In many of these applications,\nmultiple periodic components exist and are often interlaced with each other.\nSuch dynamic and complicated periodic patterns make the accurate periodicity\ndetection difficult. In addition, other components in the time series, such as\ntrend, outliers and noises, also pose additional challenges for accurate\nperiodicity detection. In this paper, we propose a robust and general framework\nfor multiple periodicity detection. Our algorithm applies maximal overlap\ndiscrete wavelet transform to transform the time series into multiple\ntemporal-frequency scales such that different periodic components can be\nisolated. We rank them by wavelet variance, and then at each scale detect\nsingle periodicity by our proposed Huber-periodogram and Huber-ACF robustly. We\nrigorously prove the theoretical properties of Huber-periodogram and justify\nthe use of Fisher's test on Huber-periodogram for periodicity detection. To\nfurther refine the detected periods, we compute unbiased autocorrelation\nfunction based on Wiener-Khinchin theorem from Huber-periodogram for improved\nrobustness and efficiency. Experiments on synthetic and real-world datasets\nshow that our algorithm outperforms other popular ones for both single and\nmultiple periodicity detection.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:10:36 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 00:59:11 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Wen", "Qingsong", ""], ["He", "Kai", ""], ["Sun", "Liang", ""], ["Zhang", "Yingying", ""], ["Ke", "Min", ""], ["Xu", "Huan", ""]]}, {"id": "2002.09538", "submitter": "Nathaniel Garton", "authors": "Nathaniel Garton, Jarad Niemi, Alicia Carriquiry", "title": "Knot Selection in Sparse Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knot-based, sparse Gaussian processes have enjoyed considerable success as\nscalable approximations to full Gaussian processes. Problems can occur,\nhowever, when knot selection is done by optimizing the marginal likelihood. For\nexample, the marginal likelihood surface is highly multimodal, which can cause\nsuboptimal knot placement where some knots serve practically no function. This\nis especially a problem when many more knots are used than are necessary,\nresulting in extra computational cost for little to no gains in accuracy.\n  We propose a one-at-a-time knot selection algorithm to select both the number\nand placement of knots. Our algorithm uses Bayesian optimization to efficiently\npropose knots that are likely to be good and largely avoids the pathologies\nencountered when using the marginal likelihood as the objective function. We\nprovide empirical results showing improved accuracy and speed over the current\nstandard approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:32:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Garton", "Nathaniel", ""], ["Niemi", "Jarad", ""], ["Carriquiry", "Alicia", ""]]}, {"id": "2002.09539", "submitter": "Jianyu Wang", "authors": "Jianyu Wang, Hao Liang, Gauri Joshi", "title": "Overlap Local-SGD: An Algorithmic Approach to Hide Communication Delays\n  in Distributed SGD", "comments": "Accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stochastic gradient descent (SGD) is essential for scaling the\nmachine learning algorithms to a large number of computing nodes. However, the\ninfrastructures variability such as high communication delay or random node\nslowdown greatly impedes the performance of distributed SGD algorithm,\nespecially in a wireless system or sensor networks. In this paper, we propose\nan algorithmic approach named Overlap-Local-SGD (and its momentum variant) to\noverlap the communication and computation so as to speedup the distributed\ntraining procedure. The approach can help to mitigate the straggler effects as\nwell. We achieve this by adding an anchor model on each node. After multiple\nlocal updates, locally trained models will be pulled back towards the\nsynchronized anchor model rather than communicating with others. Experimental\nresults of training a deep neural network on CIFAR-10 dataset demonstrate the\neffectiveness of Overlap-Local-SGD. We also provide a convergence guarantee for\nthe proposed algorithm under non-convex objective functions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:33:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Jianyu", ""], ["Liang", "Hao", ""], ["Joshi", "Gauri", ""]]}, {"id": "2002.09545", "submitter": "Qingsong Wen", "authors": "Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, Huan\n  Xu", "title": "RobustTAD: Robust Time Series Anomaly Detection via Decomposition and\n  Convolutional Neural Networks", "comments": "9 pages, 5 figures, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The monitoring and management of numerous and diverse time series data at\nAlibaba Group calls for an effective and scalable time series anomaly detection\nservice. In this paper, we propose RobustTAD, a Robust Time series Anomaly\nDetection framework by integrating robust seasonal-trend decomposition and\nconvolutional neural network for time series data. The seasonal-trend\ndecomposition can effectively handle complicated patterns in time series, and\nmeanwhile significantly simplifies the architecture of the neural network,\nwhich is an encoder-decoder architecture with skip connections. This\narchitecture can effectively capture the multi-scale information from time\nseries, which is very useful in anomaly detection. Due to the limited labeled\ndata in time series anomaly detection, we systematically investigate data\naugmentation methods in both time and frequency domains. We also introduce\nlabel-based weight and value-based weight in the loss function by utilizing the\nunbalanced nature of the time series anomaly detection problem. Compared with\nthe widely used forecasting-based anomaly detection algorithms,\ndecomposition-based algorithms, traditional statistical algorithms, as well as\nrecent neural network based algorithms, RobustTAD performs significantly better\non public benchmark datasets. It is deployed as a public online service and\nwidely adopted in different business scenarios at Alibaba Group.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:43:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gao", "Jingkun", ""], ["Song", "Xiaomin", ""], ["Wen", "Qingsong", ""], ["Wang", "Pichao", ""], ["Sun", "Liang", ""], ["Xu", "Huan", ""]]}, {"id": "2002.09547", "submitter": "Liam Hodgkinson", "authors": "Liam Hodgkinson, Chris van der Heide, Fred Roosta, Michael W. Mahoney", "title": "Stochastic Normalizing Flows", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce stochastic normalizing flows, an extension of continuous\nnormalizing flows for maximum likelihood estimation and variational inference\n(VI) using stochastic differential equations (SDEs). Using the theory of rough\npaths, the underlying Brownian motion is treated as a latent variable and\napproximated, enabling efficient training of neural SDEs as random neural\nordinary differential equations. These SDEs can be used for constructing\nefficient Markov chains to sample from the underlying distribution of a given\ndataset. Furthermore, by considering families of targeted SDEs with prescribed\nstationary distribution, we can apply VI to the optimization of hyperparameters\nin stochastic MCMC.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:47:55 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:17:18 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hodgkinson", "Liam", ""], ["van der Heide", "Chris", ""], ["Roosta", "Fred", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.09558", "submitter": "Jonathan Ventura", "authors": "Wesley Khademi, Sonia Rao, Clare Minnerath, Guy Hagen, and Jonathan\n  Ventura", "title": "Self-Supervised Poisson-Gaussian Denoising", "comments": "to appear in IEEE WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the blindspot model for self-supervised denoising to handle\nPoisson-Gaussian noise and introduce an improved training scheme that avoids\nhyperparameters and adapts the denoiser to the test data. Self-supervised\nmodels for denoising learn to denoise from only noisy data and do not require\ncorresponding clean images, which are difficult or impossible to acquire in\nsome application areas of interest such as low-light microscopy. We introduce a\nnew training strategy to handle Poisson-Gaussian noise which is the standard\nnoise model for microscope images. Our new strategy eliminates hyperparameters\nfrom the loss function, which is important in a self-supervised regime where no\nground truth data is available to guide hyperparameter tuning. We show how our\ndenoiser can be adapted to the test data to improve performance. Our\nevaluations on microscope image denoising benchmarks validate our approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 21:34:33 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 01:13:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Khademi", "Wesley", ""], ["Rao", "Sonia", ""], ["Minnerath", "Clare", ""], ["Hagen", "Guy", ""], ["Ventura", "Jonathan", ""]]}, {"id": "2002.09564", "submitter": "Shadab Khan", "authors": "Prateek Munjal, Nasir Hayat, Munawar Hayat, Jamshid Sourati, Shadab\n  Khan", "title": "Towards Robust and Reproducible Active Learning Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) is a promising ML paradigm that has the potential to\nparse through large unlabeled data and help reduce annotation cost in domains\nwhere labeling entire data can be prohibitive. Recently proposed neural network\nbased AL methods use different heuristics to accomplish this goal. In this\nstudy, we show that recent AL methods offer a gain over random baseline under a\nbrittle combination of experimental conditions. We demonstrate that such\nmarginal gains vanish when experimental factors are changed, leading to\nreproducibility issues and suggesting that AL methods lack robustness. We also\nobserve that with a properly tuned model, which employs recently proposed\nregularization techniques, the performance significantly improves for all AL\nmethods including the random sampling baseline, and performance differences\namong the AL methods become negligible. Based on these observations, we suggest\na set of experiments that are critical to assess the true effectiveness of an\nAL method. To facilitate these experiments we also present an open source\ntoolkit. We believe our findings and recommendations will help advance\nreproducible research in robust AL using neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:01:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Munjal", "Prateek", ""], ["Hayat", "Nasir", ""], ["Hayat", "Munawar", ""], ["Sourati", "Jamshid", ""], ["Khan", "Shadab", ""]]}, {"id": "2002.09565", "submitter": "Micah Goldblum", "authors": "Micah Goldblum, Avi Schwarzschild, Ankit B. Patel, Tom Goldstein", "title": "Adversarial Attacks on Machine Learning Systems for High-Frequency\n  Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic trading systems are often completely automated, and deep learning\nis increasingly receiving attention in this domain. Nonetheless, little is\nknown about the robustness properties of these models. We study valuation\nmodels for algorithmic trading from the perspective of adversarial machine\nlearning. We introduce new attacks specific to this domain with size\nconstraints that minimize attack costs. We further discuss how these attacks\ncan be used as an analysis tool to study and evaluate the robustness properties\nof financial models. Finally, we investigate the feasibility of realistic\nadversarial attacks in which an adversarial trader fools automated trading\nsystems into making inaccurate predictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:04:35 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 18:20:18 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 01:55:01 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Goldblum", "Micah", ""], ["Schwarzschild", "Avi", ""], ["Patel", "Ankit B.", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.09571", "submitter": "Nicholas Cheney", "authors": "Shawn Beaulieu, Lapo Frati, Thomas Miconi, Joel Lehman, Kenneth O.\n  Stanley, Jeff Clune, Nick Cheney", "title": "Learning to Continually Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual lifelong learning requires an agent or model to learn many\nsequentially ordered tasks, building on previous knowledge without\ncatastrophically forgetting it. Much work has gone towards preventing the\ndefault tendency of machine learning models to catastrophically forget, yet\nvirtually all such work involves manually-designed solutions to the problem. We\ninstead advocate meta-learning a solution to catastrophic forgetting, allowing\nAI to learn to continually learn. Inspired by neuromodulatory processes in the\nbrain, we propose A Neuromodulated Meta-Learning Algorithm (ANML). It\ndifferentiates through a sequential learning process to meta-learn an\nactivation-gating function that enables context-dependent selective activation\nwithin a deep neural network. Specifically, a neuromodulatory (NM) neural\nnetwork gates the forward pass of another (otherwise normal) neural network\ncalled the prediction learning network (PLN). The NM network also thus\nindirectly controls selective plasticity (i.e. the backward pass of) the PLN.\nANML enables continual learning without catastrophic forgetting at scale: it\nproduces state-of-the-art continual learning performance, sequentially learning\nas many as 600 classes (over 9,000 SGD updates).\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:52:00 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:22:48 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Beaulieu", "Shawn", ""], ["Frati", "Lapo", ""], ["Miconi", "Thomas", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""], ["Cheney", "Nick", ""]]}, {"id": "2002.09572", "submitter": "Stanis{\\l}aw Jastrz\\k{e}bski", "authors": "Stanislaw Jastrzebski, Maciej Szymczak, Stanislav Fort, Devansh Arpit,\n  Jacek Tabor, Kyunghyun Cho, Krzysztof Geras", "title": "The Break-Even Point on Optimization Trajectories of Deep Neural\n  Networks", "comments": "Accepted as a spotlight at ICLR 2020. The last two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The early phase of training of deep neural networks is critical for their\nfinal performance. In this work, we study how the hyperparameters of stochastic\ngradient descent (SGD) used in the early phase of training affect the rest of\nthe optimization trajectory. We argue for the existence of the \"break-even\"\npoint on this trajectory, beyond which the curvature of the loss surface and\nnoise in the gradient are implicitly regularized by SGD. In particular, we\ndemonstrate on multiple classification tasks that using a large learning rate\nin the initial phase of training reduces the variance of the gradient, and\nimproves the conditioning of the covariance of gradients. These effects are\nbeneficial from the optimization perspective and become visible after the\nbreak-even point. Complementing prior work, we also show that using a low\nlearning rate results in bad conditioning of the loss surface even for a neural\nnetwork with batch normalization layers. In short, our work shows that key\nproperties of the loss surface are strongly influenced by SGD in the early\nphase of training. We argue that studying the impact of the identified effects\non generalization is a promising future direction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 22:55:51 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jastrzebski", "Stanislaw", ""], ["Szymczak", "Maciej", ""], ["Fort", "Stanislav", ""], ["Arpit", "Devansh", ""], ["Tabor", "Jacek", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof", ""]]}, {"id": "2002.09573", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Martin E Jakobsen, Phillip B Mogensen, Lasse\n  Petersen, Nikolaj Thams, Gherardo Varando", "title": "Causal structure learning from time series: Large regression\n  coefficients may predict causal links better in practice than small p-values", "comments": null, "journal-ref": "Proceedings of the NeurIPS 2019 Competition and Demonstration\n  Track, Proceedings of Machine Learning Research, 123:27-36, 2020 (\n  http://proceedings.mlr.press/v123/weichwald20a.html )", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we describe the algorithms for causal structure learning\nfrom time series data that won the Causality 4 Climate competition at the\nConference on Neural Information Processing Systems 2019 (NeurIPS). We examine\nhow our combination of established ideas achieves competitive performance on\nsemi-realistic and realistic time series data exhibiting common challenges in\nreal-world Earth sciences data. In particular, we discuss a) a rationale for\nleveraging linear methods to identify causal links in non-linear systems, b) a\nsimulation-backed explanation as to why large regression coefficients may\npredict causal links better in practice than small p-values and thus why\nnormalising the data may sometimes hinder causal structure learning.\n  For benchmark usage, we detail the algorithms here and provide\nimplementations at https://github.com/sweichwald/tidybench . We propose the\npresented competition-proven methods for baseline benchmark comparisons to\nguide the development of novel algorithms for structure learning from time\nseries.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:02:00 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 09:24:53 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Jakobsen", "Martin E", ""], ["Mogensen", "Phillip B", ""], ["Petersen", "Lasse", ""], ["Thams", "Nikolaj", ""], ["Varando", "Gherardo", ""]]}, {"id": "2002.09574", "submitter": "Saurav Prakash", "authors": "Sagar Dhakal, Saurav Prakash, Yair Yona, Shilpa Talwar, Nageen Himayat", "title": "Coded Federated Learning", "comments": "Presented at the Wireless Edge Intelligence Workshop, IEEE GLOBECOM\n  2019", "journal-ref": null, "doi": "10.1109/GCWkshps45667.2019.9024521", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a method of training a global model from decentralized\ndata distributed across client devices. Here, model parameters are computed\nlocally by each client device and exchanged with a central server, which\naggregates the local models for a global view, without requiring sharing of\ntraining data. The convergence performance of federated learning is severely\nimpacted in heterogeneous computing platforms such as those at the wireless\nedge, where straggling computations and communication links can significantly\nlimit timely model parameter updates. This paper develops a novel coded\ncomputing technique for federated learning to mitigate the impact of\nstragglers. In the proposed Coded Federated Learning (CFL) scheme, each client\ndevice privately generates parity training data and shares it with the central\nserver only once at the start of the training phase. The central server can\nthen preemptively perform redundant gradient computations on the composite\nparity data to compensate for the erased or delayed parameter updates. Our\nresults show that CFL allows the global model to converge nearly four times\nfaster when compared to an uncoded approach\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:06:20 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 14:24:43 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Dhakal", "Sagar", ""], ["Prakash", "Saurav", ""], ["Yona", "Yair", ""], ["Talwar", "Shilpa", ""], ["Himayat", "Nageen", ""]]}, {"id": "2002.09575", "submitter": "Tian Gao", "authors": "Tian Gao, Dharmashankar Subramanian, Karthikeyan Shanmugam, Debarun\n  Bhattacharjya, Nicholas Mattei", "title": "A Multi-Channel Neural Graphical Event Model with Negative Evidence", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Event datasets are sequences of events of various types occurring irregularly\nover the time-line, and they are increasingly prevalent in numerous domains.\nExisting work for modeling events using conditional intensities rely on either\nusing some underlying parametric form to capture historical dependencies, or on\nnon-parametric models that focus primarily on tasks such as prediction. We\npropose a non-parametric deep neural network approach in order to estimate the\nunderlying intensity functions. We use a novel multi-channel RNN that optimally\nreinforces the negative evidence of no observable events with the introduction\nof fake event epochs within each consecutive inter-event interval. We evaluate\nour method against state-of-the-art baselines on model fitting tasks as gauged\nby log-likelihood. Through experiments on both synthetic and real-world\ndatasets, we find that our proposed approach outperforms existing baselines on\nmost of the datasets studied.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:10:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gao", "Tian", ""], ["Subramanian", "Dharmashankar", ""], ["Shanmugam", "Karthikeyan", ""], ["Bhattacharjya", "Debarun", ""], ["Mattei", "Nicholas", ""]]}, {"id": "2002.09576", "submitter": "Scott Freitas", "authors": "Scott Freitas, Shang-Tse Chen, Zijie J. Wang, Duen Horng Chau", "title": "UnMask: Adversarial Detection and Defense Through Robust Feature\n  Alignment", "comments": "Accepted into IEEE Big Data 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are being integrated into a wide range of high-impact,\nsecurity-critical systems, from self-driving cars to medical diagnosis.\nHowever, recent research has demonstrated that many of these deep learning\narchitectures are vulnerable to adversarial attacks--highlighting the vital\nneed for defensive techniques to detect and mitigate these attacks before they\noccur. To combat these adversarial attacks, we developed UnMask, an adversarial\ndetection and defense framework based on robust feature alignment. The core\nidea behind UnMask is to protect these models by verifying that an image's\npredicted class (\"bird\") contains the expected robust features (e.g., beak,\nwings, eyes). For example, if an image is classified as \"bird\", but the\nextracted features are wheel, saddle and frame, the model may be under attack.\nUnMask detects such attacks and defends the model by rectifying the\nmisclassification, re-classifying the image based on its robust features. Our\nextensive evaluation shows that UnMask (1) detects up to 96.75% of attacks, and\n(2) defends the model by correctly classifying up to 93% of adversarial images\nproduced by the current strongest attack, Projected Gradient Descent, in the\ngray-box setting. UnMask provides significantly better protection than\nadversarial training across 8 attack vectors, averaging 31.18% higher accuracy.\nWe open source the code repository and data with this paper:\nhttps://github.com/safreita1/unmask.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 23:20:23 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 20:21:11 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Freitas", "Scott", ""], ["Chen", "Shang-Tse", ""], ["Wang", "Zijie J.", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2002.09579", "submitter": "Yuhao Zhang", "authors": "Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni", "title": "Robustness to Programmable String Transformations via Augmented Abstract\n  Training", "comments": "12 pages, ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks for natural language processing tasks are vulnerable to\nadversarial input perturbations. In this paper, we present a versatile language\nfor programmatically specifying string transformations -- e.g., insertions,\ndeletions, substitutions, swaps, etc. -- that are relevant to the task at hand.\nWe then present an approach to adversarially training models that are robust to\nsuch user-defined string transformations. Our approach combines the advantages\nof search-based techniques for adversarial training with abstraction-based\ntechniques. Specifically, we show how to decompose a set of user-defined string\ntransformations into two component specifications, one that benefits from\nsearch and another from abstraction. We use our technique to train models on\nthe AG and SST2 datasets and show that the resulting models are robust to\ncombinations of user-defined transformations mimicking spelling mistakes and\nother meaning-preserving transformations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:06:09 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:53:49 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 23:03:53 GMT"}, {"version": "v4", "created": "Wed, 2 Sep 2020 14:41:25 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Zhang", "Yuhao", ""], ["Albarghouthi", "Aws", ""], ["D'Antoni", "Loris", ""]]}, {"id": "2002.09580", "submitter": "Can Bakiskan", "authors": "Can Bakiskan, Soorya Gopalakrishnan, Metehan Cekic, Upamanyu Madhow,\n  Ramtin Pedarsani", "title": "Polarizing Front Ends for Robust CNNs", "comments": "Published in 45th International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vulnerability of deep neural networks to small, adversarially designed\nperturbations can be attributed to their \"excessive linearity.\" In this paper,\nwe propose a bottom-up strategy for attenuating adversarial perturbations using\na nonlinear front end which polarizes and quantizes the data. We observe that\nideal polarization can be utilized to completely eliminate perturbations,\ndevelop algorithms to learn approximately polarizing bases for data, and\ninvestigate the effectiveness of the proposed strategy on the MNIST and Fashion\nMNIST datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:28:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Bakiskan", "Can", ""], ["Gopalakrishnan", "Soorya", ""], ["Cekic", "Metehan", ""], ["Madhow", "Upamanyu", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2002.09587", "submitter": "Zhanyu Wang", "authors": "Zhanyu Wang and Jean Honorio", "title": "The Sample Complexity of Meta Sparse Regression", "comments": null, "journal-ref": "Artificial Intelligence and Statistics (AISTATS), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the meta-learning problem in sparse linear regression\nwith infinite tasks. We assume that the learner can access several similar\ntasks. The goal of the learner is to transfer knowledge from the prior tasks to\na similar but novel task. For p parameters, size of the support set k , and l\nsamples per task, we show that T \\in O (( k log(p) ) /l ) tasks are sufficient\nin order to recover the common support of all tasks. With the recovered\nsupport, we can greatly reduce the sample complexity for estimating the\nparameter of the novel task, i.e., l \\in O (1) with respect to T and p . We\nalso prove that our rates are minimax optimal. A key difference between\nmeta-learning and the classical multi-task learning, is that meta-learning\nfocuses only on the recovery of the parameters of the novel task, while\nmulti-task learning estimates the parameter of all tasks, which requires l to\ngrow with T . Instead, our efficient meta-learning estimator allows for l to be\nconstant with respect to T (i.e., few-shot learning).\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 00:59:53 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2020 18:35:21 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Wang", "Zhanyu", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.09589", "submitter": "Vaishakh Ravindrakumar", "authors": "Yi Hao, Ayush Jain, Alon Orlitsky, Vaishakh Ravindrakumar", "title": "SURF: A Simple, Universal, Robust, Fast Distribution Learning Algorithm", "comments": "27 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample- and computationally-efficient distribution estimation is a\nfundamental tenet in statistics and machine learning. We present SURF, an\nalgorithm for approximating distributions by piecewise polynomials. SURF is:\nsimple, replacing prior complex optimization techniques by straight-forward\n{empirical probability} approximation of each potential polynomial piece\n{through simple empirical-probability interpolation}, and using plain\ndivide-and-conquer to merge the pieces; universal, as well-known\npolynomial-approximation results imply that it accurately approximates a large\nclass of common distributions; robust to distribution mis-specification as for\nany degree $d \\le 8$, it estimates any distribution to an $\\ell_1$ distance $<\n3$ times that of the nearest degree-$d$ piecewise polynomial, improving known\nfactor upper bounds of 3 for single polynomials and 15 for polynomials with\narbitrarily many pieces; fast, using optimal sample complexity, running in near\nsample-linear time, and if given sorted samples it may be parallelized to run\nin sub-linear time. In experiments, SURF outperforms state-of-the art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:03:33 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 19:10:43 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hao", "Yi", ""], ["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""], ["Ravindrakumar", "Vaishakh", ""]]}, {"id": "2002.09594", "submitter": "Xuhong Wang", "authors": "Xuhong Wang, Baihong Jin, Ying Du, Ping Cui and Yupu Yang", "title": "One-Class Graph Neural Networks for Anomaly Detection in Attributed\n  Networks", "comments": "16 pages, 4 figures. Neural Comput & Applic (2021)", "journal-ref": null, "doi": "10.1007/s00521-021-05924-9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, graph-structured data are increasingly used to model complex\nsystems. Meanwhile, detecting anomalies from graph has become a vital research\nproblem of pressing societal concerns. Anomaly detection is an unsupervised\nlearning task of identifying rare data that differ from the majority. As one of\nthe dominant anomaly detection algorithms, One Class Support Vector Machine has\nbeen widely used to detect outliers. However, those traditional anomaly\ndetection methods lost their effectiveness in graph data. Since traditional\nanomaly detection methods are stable, robust and easy to use, it is vitally\nimportant to generalize them to graph data. In this work, we propose One Class\nGraph Neural Network (OCGNN), a one-class classification framework for graph\nanomaly detection. OCGNN is designed to combine the powerful representation\nability of Graph Neural Networks along with the classical one-class objective.\nCompared with other baselines, OCGNN achieves significant improvements in\nextensive experiments.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:25:49 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 11:28:03 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Wang", "Xuhong", ""], ["Jin", "Baihong", ""], ["Du", "Ying", ""], ["Cui", "Ping", ""], ["Yang", "Yupu", ""]]}, {"id": "2002.09595", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "The Pragmatic Turn in Explainable Artificial Intelligence (XAI)", "comments": null, "journal-ref": "Minds and Machines, 29(3), 441-459, 2019", "doi": "10.1007/s11023-019-09502-w", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I argue that the search for explainable models and\ninterpretable decisions in AI must be reformulated in terms of the broader\nproject of offering a pragmatic and naturalistic account of understanding in\nAI. Intuitively, the purpose of providing an explanation of a model or a\ndecision is to make it understandable to its stakeholders. But without a\nprevious grasp of what it means to say that an agent understands a model or a\ndecision, the explanatory strategies will lack a well-defined goal. Aside from\nproviding a clearer objective for XAI, focusing on understanding also allows us\nto relax the factivity condition on explanation, which is impossible to fulfill\nin many machine learning models, and to focus instead on the pragmatic\nconditions that determine the best fit between a model and the methods and\ndevices deployed to understand it. After an examination of the different types\nof understanding discussed in the philosophical and psychological literature, I\nconclude that interpretative or approximation models not only provide the best\nway to achieve the objectual understanding of a machine learning model, but are\nalso a necessary condition to achieve post-hoc interpretability. This\nconclusion is partly based on the shortcomings of the purely functionalist\napproach to post-hoc interpretability that seems to be predominant in most\nrecent literature.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:40:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2002.09609", "submitter": "Raman Arora", "authors": "Raman Arora, Teodor V. Marinov, Enayat Ullah", "title": "Private Stochastic Convex Optimization: Efficient Algorithms for\n  Non-smooth Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit the problem of private stochastic convex\noptimization. We propose an algorithm based on noisy mirror descent, which\nachieves optimal rates both in terms of statistical complexity and number of\nqueries to a first-order stochastic oracle in the regime when the privacy\nparameter is inversely proportional to the number of samples.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 03:03:43 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 18:59:44 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 05:30:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Arora", "Raman", ""], ["Marinov", "Teodor V.", ""], ["Ullah", "Enayat", ""]]}, {"id": "2002.09615", "submitter": "Amanda Bower", "authors": "Amanda Bower and Laura Balzano", "title": "Preference Modeling with Context-Dependent Salient Features", "comments": "This is the ICML camera ready version. The main difference is that\n  the statements of the theorems now hold with arbitrary probability \\delta\n  instead of with probability 1-2/d", "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a ranking on a set of items from noisy\npairwise comparisons given item features. We address the fact that pairwise\ncomparison data often reflects irrational choice, e.g. intransitivity. Our key\nobservation is that two items compared in isolation from other items may be\ncompared based on only a salient subset of features. Formalizing this\nframework, we propose the salient feature preference model and prove a finite\nsample complexity result for learning the parameters of our model and the\nunderlying ranking with maximum likelihood estimation. We also provide\nempirical results that support our theoretical bounds and illustrate how our\nmodel explains systematic intransitivity. Finally we demonstrate strong\nperformance of maximum likelihood estimation of our model on both synthetic\ndata and two real data sets: the UT Zappos50K data set and comparison data\nabout the compactness of legislative districts in the US.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:05:16 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 01:45:10 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bower", "Amanda", ""], ["Balzano", "Laura", ""]]}, {"id": "2002.09621", "submitter": "Junchi Yang", "authors": "Junchi Yang, Negar Kiyavash, Niao He", "title": "Global Convergence and Variance-Reduced Optimization for a Class of\n  Nonconvex-Nonconcave Minimax Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex minimax problems appear frequently in emerging machine learning\napplications, such as generative adversarial networks and adversarial learning.\nSimple algorithms such as the gradient descent ascent (GDA) are the common\npractice for solving these nonconvex games and receive lots of empirical\nsuccess. Yet, it is known that these vanilla GDA algorithms with constant step\nsize can potentially diverge even in the convex setting. In this work, we show\nthat for a subclass of nonconvex-nonconcave objectives satisfying a so-called\ntwo-sided Polyak-{\\L}ojasiewicz inequality, the alternating gradient descent\nascent (AGDA) algorithm converges globally at a linear rate and the stochastic\nAGDA achieves a sublinear rate. We further develop a variance reduced algorithm\nthat attains a provably faster rate than AGDA when the problem has the\nfinite-sum structure.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:20:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yang", "Junchi", ""], ["Kiyavash", "Negar", ""], ["He", "Niao", ""]]}, {"id": "2002.09623", "submitter": "Tao Cao", "authors": "Yuan Zhou, Tao Cao, and Wei Xiang", "title": "Anypath Routing Protocol Design via Q-Learning for Underwater Sensor\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising technology in the Internet of Underwater Things, underwater\nsensor networks have drawn a widespread attention from both academia and\nindustry. However, designing a routing protocol for underwater sensor networks\nis a great challenge due to high energy consumption and large latency in the\nunderwater environment. This paper proposes a Q-learning-based\nlocalization-free anypath routing (QLFR) protocol to prolong the lifetime as\nwell as reduce the end-to-end delay for underwater sensor networks. Aiming at\noptimal routing policies, the Q-value is calculated by jointly considering the\nresidual energy and depth information of sensor nodes throughout the routing\nprocess. More specifically, we define two reward functions (i.e., depth-related\nand energy-related rewards) for Q-learning with the objective of reducing\nlatency and extending network lifetime. In addition, a new holding time\nmechanism for packet forwarding is designed according to the priority of\nforwarding candidate nodes. Furthermore, a mathematical analysis is presented\nto analyze the performance of the proposed routing protocol. Extensive\nsimulation results demonstrate the superiority performance of the proposed\nrouting protocol in terms of the end-to-end delay and the network lifetime.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:28:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhou", "Yuan", ""], ["Cao", "Tao", ""], ["Xiang", "Wei", ""]]}, {"id": "2002.09632", "submitter": "Guanxiong Liu", "authors": "Guanxiong Liu, Issa Khalil, Abdallah Khreishah", "title": "Using Single-Step Adversarial Training to Defend Iterative Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples have become one of the largest challenges that machine\nlearning models, especially neural network classifiers, face. These adversarial\nexamples break the assumption of attack-free scenario and fool state-of-the-art\n(SOTA) classifiers with insignificant perturbations to human. So far,\nresearchers achieved great progress in utilizing adversarial training as a\ndefense. However, the overwhelming computational cost degrades its\napplicability and little has been done to overcome this issue. Single-Step\nadversarial training methods have been proposed as computationally viable\nsolutions, however they still fail to defend against iterative adversarial\nexamples. In this work, we first experimentally analyze several different SOTA\ndefense methods against adversarial examples. Then, based on observations from\nexperiments, we propose a novel single-step adversarial training method which\ncan defend against both single-step and iterative adversarial examples. Lastly,\nthrough extensive evaluations, we demonstrate that our proposed method\noutperforms the SOTA single-step and iterative adversarial training defense.\nCompared with ATDA (single-step method) on CIFAR10 dataset, our proposed method\nachieves 35.67% enhancement in test accuracy and 19.14% reduction in training\ntime. When compared with methods that use BIM or Madry examples (iterative\nmethods) on CIFAR10 dataset, it saves up to 76.03% in training time with less\nthan 3.78% degeneration in test accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:36:35 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 17:24:24 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Guanxiong", ""], ["Khalil", "Issa", ""], ["Khreishah", "Abdallah", ""]]}, {"id": "2002.09635", "submitter": "Michael Girard", "authors": "Sripad Krishna Devalla, Tan Hung Pham, Satish Kumar Panda, Liang\n  Zhang, Giridhar Subramanian, Anirudh Swaminathan, Chin Zhi Yun, Mohan Rajan,\n  Sujatha Mohan, Ramaswami Krishnadas, Vijayalakshmi Senthil, John Mark S. de\n  Leon, Tin A. Tun, Ching-Yu Cheng, Leopold Schmetterer, Shamira Perera, Tin\n  Aung, Alexandre H. Thiery, Micha\u007fel J. A. Girard", "title": "Towards Label-Free 3D Segmentation of Optical Coherence Tomography\n  Images of the Optic Nerve Head Using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the introduction of optical coherence tomography (OCT), it has been\npossible to study the complex 3D morphological changes of the optic nerve head\n(ONH) tissues that occur along with the progression of glaucoma. Although\nseveral deep learning (DL) techniques have been recently proposed for the\nautomated extraction (segmentation) and quantification of these morphological\nchanges, the device specific nature and the difficulty in preparing manual\nsegmentations (training data) limit their clinical adoption. With several new\nmanufacturers and next-generation OCT devices entering the market, the\ncomplexity in deploying DL algorithms clinically is only increasing. To address\nthis, we propose a DL based 3D segmentation framework that is easily\ntranslatable across OCT devices in a label-free manner (i.e. without the need\nto manually re-segment data for each device). Specifically, we developed 2 sets\nof DL networks. The first (referred to as the enhancer) was able to enhance OCT\nimage quality from 3 OCT devices, and harmonized image-characteristics across\nthese devices. The second performed 3D segmentation of 6 important ONH tissue\nlayers. We found that the use of the enhancer was critical for our segmentation\nnetwork to achieve device independency. In other words, our 3D segmentation\nnetwork trained on any of 3 devices successfully segmented ONH tissue layers\nfrom the other two devices with high performance (Dice coefficients > 0.92).\nWith such an approach, we could automatically segment images from new OCT\ndevices without ever needing manual segmentation data from such devices.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 05:41:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Devalla", "Sripad Krishna", ""], ["Pham", "Tan Hung", ""], ["Panda", "Satish Kumar", ""], ["Zhang", "Liang", ""], ["Subramanian", "Giridhar", ""], ["Swaminathan", "Anirudh", ""], ["Yun", "Chin Zhi", ""], ["Rajan", "Mohan", ""], ["Mohan", "Sujatha", ""], ["Krishnadas", "Ramaswami", ""], ["Senthil", "Vijayalakshmi", ""], ["de Leon", "John Mark S.", ""], ["Tun", "Tin A.", ""], ["Cheng", "Ching-Yu", ""], ["Schmetterer", "Leopold", ""], ["Perera", "Shamira", ""], ["Aung", "Tin", ""], ["Thiery", "Alexandre H.", ""], ["Girard", "Micha\u007fel J. A.", ""]]}, {"id": "2002.09650", "submitter": "Xiaojing Ye", "authors": "Shaojun Ma, Haodong Sun, Xiaojing Ye, Hongyuan Zha, Haomin Zhou", "title": "Learning Cost Functions for Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse optimal transport (OT) refers to the problem of learning the cost\nfunction for OT from observed transport plan or its samples. In this paper, we\nderive an unconstrained convex optimization formulation of the inverse OT\nproblem, which can be further augmented by any customizable regularization. We\nprovide a comprehensive characterization of the properties of inverse OT,\nincluding uniqueness of solutions. We also develop two numerical algorithms,\none is a fast matrix scaling method based on the Sinkhorn-Knopp algorithm for\ndiscrete OT, and the other one is a learning based algorithm that parameterizes\nthe cost function as a deep neural network for continuous OT. The novel\nframework proposed in the work avoids repeatedly solving a forward OT in each\niteration which has been a thorny computational bottleneck for the bi-level\noptimization in existing inverse OT approaches. Numerical results demonstrate\npromising efficiency and accuracy advantages of the proposed algorithms over\nexisting state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 07:27:17 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 15:36:53 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Ma", "Shaojun", ""], ["Sun", "Haodong", ""], ["Ye", "Xiaojing", ""], ["Zha", "Hongyuan", ""], ["Zhou", "Haomin", ""]]}, {"id": "2002.09656", "submitter": "Yifan Yang", "authors": "Yang Yifan, Guo Ju'e, Sun Shaolong, and Li Yixin", "title": "A new hybrid approach for crude oil price forecasting: Evidence from\n  multi-scale data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faced with the growing research towards crude oil price fluctuations\ninfluential factors following the accelerated development of Internet\ntechnology, accessible data such as Google search volume index are increasingly\nquantified and incorporated into forecasting approaches. In this paper, we\napply multi-scale data that including both GSVI data and traditional economic\ndata related to crude oil price as independent variables and propose a new\nhybrid approach for monthly crude oil price forecasting. This hybrid approach,\nbased on divide and conquer strategy, consists of K-means method, kernel\nprincipal component analysis and kernel extreme learning machine , where\nK-means method is adopted to divide input data into certain clusters, KPCA is\napplied to reduce dimension, and KELM is employed for final crude oil price\nforecasting. The empirical result can be analyzed from data and method levels.\nAt the data level, GSVI data perform better than economic data in level\nforecasting accuracy but with opposite performance in directional forecasting\naccuracy because of Herd Behavior, while hybrid data combined their advantages\nand obtain best forecasting performance in both level and directional accuracy.\nAt the method level, the approaches with K-means perform better than those\nwithout K-means, which demonstrates that divide and conquer strategy can\neffectively improve the forecasting performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 07:56:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Yifan", "Yang", ""], ["Ju'e", "Guo", ""], ["Shaolong", "Sun", ""], ["Yixin", "Li", ""]]}, {"id": "2002.09668", "submitter": "Kai Yang", "authors": "Yuanming Shi, Kai Yang, Tao Jiang, Jun Zhang, and Khaled B. Letaief", "title": "Communication-Efficient Edge AI: Algorithms and Systems", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) has achieved remarkable breakthroughs in a wide\nrange of fields, ranging from speech processing, image classification to drug\ndiscovery. This is driven by the explosive growth of data, advances in machine\nlearning (especially deep learning), and easy access to vastly powerful\ncomputing resources. Particularly, the wide scale deployment of edge devices\n(e.g., IoT devices) generates an unprecedented scale of data, which provides\nthe opportunity to derive accurate models and develop various intelligent\napplications at the network edge. However, such enormous data cannot all be\nsent from end devices to the cloud for processing, due to the varying channel\nquality, traffic congestion and/or privacy concerns. By pushing inference and\ntraining processes of AI models to edge nodes, edge AI has emerged as a\npromising alternative. AI at the edge requires close cooperation among edge\ndevices, such as smart phones and smart vehicles, and edge servers at the\nwireless access points and base stations, which however result in heavy\ncommunication overheads. In this paper, we present a comprehensive survey of\nthe recent developments in various techniques for overcoming these\ncommunication challenges. Specifically, we first identify key communication\nchallenges in edge AI systems. We then introduce communication-efficient\ntechniques, from both algorithmic and system perspectives for training and\ninference tasks at the network edge. Potential future research directions are\nalso highlighted.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:27:55 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shi", "Yuanming", ""], ["Yang", "Kai", ""], ["Jiang", "Tao", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "2002.09670", "submitter": "Kian Hsiang Low", "authors": "Dmitrii Kharkovskii, Chun Kai Ling, Kian Hsiang Low", "title": "Nonmyopic Gaussian Process Optimization with Macro-Actions", "comments": "23rd International Conference on Artificial Intelligence and\n  Statistics (AISTATS 2020), Extended version with proofs, 32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-staged approach to nonmyopic adaptive Gaussian\nprocess optimization (GPO) for Bayesian optimization (BO) of unknown, highly\ncomplex objective functions that, in contrast to existing nonmyopic adaptive BO\nalgorithms, exploits the notion of macro-actions for scaling up to a further\nlookahead to match up to a larger available budget. To achieve this, we\ngeneralize GP upper confidence bound to a new acquisition function defined\nw.r.t. a nonmyopic adaptive macro-action policy, which is intractable to be\noptimized exactly due to an uncountable set of candidate outputs. The\ncontribution of our work here is thus to derive a nonmyopic adaptive\nepsilon-Bayes-optimal macro-action GPO (epsilon-Macro-GPO) policy. To perform\nnonmyopic adaptive BO in real time, we then propose an asymptotically optimal\nanytime variant of our epsilon-Macro-GPO policy with a performance guarantee.\nWe empirically evaluate the performance of our epsilon-Macro-GPO policy and its\nanytime variant in BO with synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:56:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kharkovskii", "Dmitrii", ""], ["Ling", "Chun Kai", ""], ["Low", "Kian Hsiang", ""]]}, {"id": "2002.09671", "submitter": "Yan Lin", "authors": "Jun Li, Zhichao Xing, Weibin Zhang, Yan Lin, and Feng Shu", "title": "Vehicle Tracking in Wireless Sensor Networks via Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle tracking has become one of the key applications of wireless sensor\nnetworks (WSNs) in the fields of rescue, surveillance, traffic monitoring, etc.\nHowever, the increased tracking accuracy requires more energy consumption. In\nthis letter, a decentralized vehicle tracking strategy is conceived for\nimproving both tracking accuracy and energy saving, which is based on adjusting\nthe intersection area between the fixed sensing area and the dynamic activation\narea. Then, two deep reinforcement learning (DRL) aided solutions are proposed\nrelying on the dynamic selection of the activation area radius. Finally,\nsimulation results show the superiority of our DRL aided design.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:01:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Li", "Jun", ""], ["Xing", "Zhichao", ""], ["Zhang", "Weibin", ""], ["Lin", "Yan", ""], ["Shu", "Feng", ""]]}, {"id": "2002.09676", "submitter": "Siddhant Gangapurwala", "authors": "Siddhant Gangapurwala, Alexander Mitchell and Ioannis Havoutis", "title": "Guided Constrained Policy Optimization for Dynamic Quadrupedal Robot\n  Locomotion", "comments": "8 pages, 8 figures, 5 tables, 1 algorithm, accepted to IEEE Robotics\n  and Automation Letters (RA-L), January 2020 with presentation at\n  International Conference on Robotics and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep reinforcement learning (RL) uses model-free techniques to optimize\ntask-specific control policies. Despite having emerged as a promising approach\nfor complex problems, RL is still hard to use reliably for real-world\napplications. Apart from challenges such as precise reward function tuning,\ninaccurate sensing and actuation, and non-deterministic response, existing RL\nmethods do not guarantee behavior within required safety constraints that are\ncrucial for real robot scenarios. In this regard, we introduce guided\nconstrained policy optimization (GCPO), an RL framework based upon our\nimplementation of constrained proximal policy optimization (CPPO) for tracking\nbase velocity commands while following the defined constraints. We also\nintroduce schemes which encourage state recovery into constrained regions in\ncase of constraint violations. We present experimental results of our training\nmethod and test it on the real ANYmal quadruped robot. We compare our approach\nagainst the unconstrained RL method and show that guided constrained RL offers\nfaster convergence close to the desired optimum resulting in an optimal, yet\nphysically feasible, robotic control behavior without the need for precise\nreward function tuning.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:15:53 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gangapurwala", "Siddhant", ""], ["Mitchell", "Alexander", ""], ["Havoutis", "Ioannis", ""]]}, {"id": "2002.09677", "submitter": "Ayoub Belhadji", "authors": "Ayoub Belhadji, R\\'emi Bardenet, Pierre Chainais", "title": "Kernel interpolation with continuous volume sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in kernel methods is to pick nodes and weights, so as to\napproximate a given function from an RKHS by the weighted sum of kernel\ntranslates located at the nodes. This is the crux of kernel density estimation,\nkernel quadrature, or interpolation from discrete samples. Furthermore, RKHSs\noffer a convenient mathematical and computational framework. We introduce and\nanalyse continuous volume sampling (VS), the continuous counterpart -- for\nchoosing node locations -- of a discrete distribution introduced in (Deshpande\n& Vempala, 2006). Our contribution is theoretical: we prove almost optimal\nbounds for interpolation and quadrature under VS. While similar bounds already\nexist for some specific RKHSs using ad-hoc node constructions, VS offers bounds\nthat apply to any Mercer kernel and depend on the spectrum of the associated\nintegration operator. We emphasize that, unlike previous randomized approaches\nthat rely on regularized leverage scores or determinantal point processes,\nevaluating the pdf of VS only requires pointwise evaluations of the kernel. VS\nis thus naturally amenable to MCMC samplers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:34:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Belhadji", "Ayoub", ""], ["Bardenet", "R\u00e9mi", ""], ["Chainais", "Pierre", ""]]}, {"id": "2002.09692", "submitter": "Zhenheng Tang", "authors": "Zhenheng Tang, Shaohuai Shi, Xiaowen Chu", "title": "Communication-Efficient Decentralized Learning with Sparsification and\n  Adaptive Peer Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning techniques such as federated learning have enabled\nmultiple workers to train machine learning models together to reduce the\noverall training time. However, current distributed training algorithms\n(centralized or decentralized) suffer from the communication bottleneck on\nmultiple low-bandwidth workers (also on the server under the centralized\narchitecture). Although decentralized algorithms generally have lower\ncommunication complexity than the centralized counterpart, they still suffer\nfrom the communication bottleneck for workers with low network bandwidth. To\ndeal with the communication problem while being able to preserve the\nconvergence performance, we introduce a novel decentralized training algorithm\nwith the following key features: 1) It does not require a parameter server to\nmaintain the model during training, which avoids the communication pressure on\nany single peer. 2) Each worker only needs to communicate with a single peer at\neach communication round with a highly compressed model, which can\nsignificantly reduce the communication traffic on the worker. We theoretically\nprove that our sparsification algorithm still preserves convergence properties.\n3) Each worker dynamically selects its peer at different communication rounds\nto better utilize the bandwidth resources. We conduct experiments with\nconvolutional neural networks on 32 workers to verify the effectiveness of our\nproposed algorithm compared to seven existing methods. Experimental results\nshow that our algorithm significantly reduces the communication traffic and\ngenerally select relatively high bandwidth peers.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 12:31:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tang", "Zhenheng", ""], ["Shi", "Shaohuai", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.09693", "submitter": "Haoxing Lin", "authors": "Haoxing Lin and Weijia Jia and Yongjian You and Yiping Sun", "title": "Interpretable Crowd Flow Prediction with Spatial-Temporal Self-Attention", "comments": "7pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd flow prediction has been increasingly investigated in intelligent urban\ncomputing field as a fundamental component of urban management system. The most\nchallenging part of predicting crowd flow is to measure the complicated\nspatial-temporal dependencies. A prevalent solution employed in current methods\nis to divide and conquer the spatial and temporal information by various\narchitectures (e.g., CNN/GCN, LSTM). However, this strategy has two\ndisadvantages: (1) the sophisticated dependencies are also divided and\ntherefore partially isolated; (2) the spatial-temporal features are transformed\ninto latent representations when passing through different architectures,\nmaking it hard to interpret the predicted crowd flow. To address these issues,\nwe propose a Spatial-Temporal Self-Attention Network (STSAN) with an ST\nencoding gate that calculates the entire spatial-temporal representation with\npositional and time encodings and therefore avoids dividing the dependencies.\nFurthermore, we develop a Multi-aspect attention mechanism that applies scaled\ndot-product attention over spatial-temporal information and measures the\nattention weights that explicitly indicate the dependencies. Experimental\nresults on traffic and mobile data demonstrate that the proposed method reduces\ninflow and outflow RMSE by 16% and 8% on the Taxi-NYC dataset compared to the\nSOTA baselines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 12:43:11 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lin", "Haoxing", ""], ["Jia", "Weijia", ""], ["You", "Yongjian", ""], ["Sun", "Yiping", ""]]}, {"id": "2002.09695", "submitter": "Yifan Yang", "authors": "Guowei Zhang, Tao Ren, and Yifan Yang", "title": "A New Unified Deep Learning Approach with\n  Decomposition-Reconstruction-Ensemble Framework for Time Series Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new variational mode decomposition (VMD) based deep learning approach is\nproposed in this paper for time series forecasting problem. Firstly, VMD is\nadopted to decompose the original time series into several sub-signals. Then, a\nconvolutional neural network (CNN) is applied to learn the reconstruction\npatterns on the decomposed sub-signals to obtain several reconstructed\nsub-signals. Finally, a long short term memory (LSTM) network is employed to\nforecast the time series with the decomposed sub-signals and the reconstructed\nsub-signals as inputs. The proposed VMD-CNN-LSTM approach is originated from\nthe decomposition-reconstruction-ensemble framework, and innovated by embedding\nthe reconstruction, single forecasting, and ensemble steps in a unified deep\nlearning approach. To verify the forecasting performance of the proposed\napproach, four typical time series datasets are introduced for empirical\nanalysis. The empirical results demonstrate that the proposed approach\noutperforms consistently the benchmark approaches in terms of forecasting\naccuracy, and also indicate that the reconstructed sub-signals obtained by CNN\nis of importance for further improving the forecasting performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 12:57:50 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Guowei", ""], ["Ren", "Tao", ""], ["Yang", "Yifan", ""]]}, {"id": "2002.09699", "submitter": "Rongfei Zeng", "authors": "Rongfei Zeng, Shixun Zhang, Jiaqi Wang and Xiaowen Chu", "title": "FMore: An Incentive Scheme of Multi-dimensional Auction for Federated\n  Learning in MEC", "comments": null, "journal-ref": null, "doi": "10.1109/ICDCS47774.2020.00094", "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Promising federated learning coupled with Mobile Edge Computing (MEC) is\nconsidered as one of the most promising solutions to the AI-driven service\nprovision. Plenty of studies focus on federated learning from the performance\nand security aspects, but they neglect the incentive mechanism. In MEC, edge\nnodes would not like to voluntarily participate in learning, and they differ in\nthe provision of multi-dimensional resources, both of which might deteriorate\nthe performance of federated learning. Also, lightweight schemes appeal to edge\nnodes in MEC. These features require the incentive mechanism to be well\ndesigned for MEC. In this paper, we present an incentive mechanism FMore with\nmulti-dimensional procurement auction of K winners. Our proposal FMore not only\nis lightweight and incentive compatible, but also encourages more high-quality\nedge nodes with low cost to participate in learning and eventually improve the\nperformance of federated learning. We also present theoretical results of Nash\nequilibrium strategy to edge nodes and employ the expected utility theory to\nprovide guidance to the aggregator. Both extensive simulations and real-world\nexperiments demonstrate that the proposed scheme can effectively reduce the\ntraining rounds and drastically improve the model accuracy for challenging AI\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 13:43:36 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zeng", "Rongfei", ""], ["Zhang", "Shixun", ""], ["Wang", "Jiaqi", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.09718", "submitter": "Yifan Sun", "authors": "Yifan Sun and Francis Bach", "title": "Safe Screening for the Generalized Conditional Gradient Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional gradient method (CGM) has been widely used for fast sparse\napproximation, having a low per iteration computational cost for structured\nsparse regularizers. We explore the sparsity acquiring properties of a\ngeneralized CGM (gCGM), where the constraint is replaced by a penalty function\nbased on a gauge penalty; this can be done without significantly increasing the\nper-iteration computation, and applies to general notions of sparsity. Without\nassuming bounded iterates, we show $O(1/t)$ convergence of the function values\nand gap of gCGM. We couple this with a safe screening rule, and show that at a\nrate $O(1/(t\\delta^2))$, the screened support matches the support at the\nsolution, where $\\delta \\geq 0$ measures how close the problem is to being\ndegenerate. In our experiments, we show that the gCGM for these modified\npenalties have similar feature selection properties as common penalties, but\nwith potentially more stability over the choice of hyperparameter.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 15:07:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sun", "Yifan", ""], ["Bach", "Francis", ""]]}, {"id": "2002.09723", "submitter": "Cristian Rusu", "authors": "Cristian Rusu and Lorenzo Rosasco", "title": "Constructing fast approximate eigenspaces with application to the fast\n  graph Fourier transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.SP math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate numerically efficient approximations of eigenspaces associated\nto symmetric and general matrices. The eigenspaces are factored into a fixed\nnumber of fundamental components that can be efficiently manipulated (we\nconsider extended orthogonal Givens or scaling and shear transformations). The\nnumber of these components controls the trade-off between approximation\naccuracy and the computational complexity of projecting on the eigenspaces. We\nwrite minimization problems for the single fundamental components and provide\nclosed-form solutions. Then we propose algorithms that iterative update all\nthese components until convergence. We show results on random matrices and an\napplication on the approximation of graph Fourier transforms for directed and\nundirected graphs.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 15:55:50 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:32:39 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 20:32:41 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Rusu", "Cristian", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2002.09726", "submitter": "Boris Kramer", "authors": "Peter Benner and Pawan Goyal and Boris Kramer and Benjamin\n  Peherstorfer and Karen Willcox", "title": "Operator inference for non-intrusive model reduction of systems with\n  non-polynomial nonlinear terms", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113433", "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a non-intrusive model reduction method to learn\nlow-dimensional models of dynamical systems with non-polynomial nonlinear terms\nthat are spatially local and that are given in analytic form. In contrast to\nstate-of-the-art model reduction methods that are intrusive and thus require\nfull knowledge of the governing equations and the operators of a full model of\nthe discretized dynamical system, the proposed approach requires only the\nnon-polynomial terms in analytic form and learns the rest of the dynamics from\nsnapshots computed with a potentially black-box full-model solver. The proposed\nmethod learns operators for the linear and polynomially nonlinear dynamics via\na least-squares problem, where the given non-polynomial terms are incorporated\nin the right-hand side. The least-squares problem is linear and thus can be\nsolved efficiently in practice. The proposed method is demonstrated on three\nproblems governed by partial differential equations, namely the\ndiffusion-reaction Chafee-Infante model, a tubular reactor model for reactive\nflows, and a batch-chromatography model that describes a chemical separation\nprocess. The numerical results provide evidence that the proposed approach\nlearns reduced models that achieve comparable accuracy as models constructed\nwith state-of-the-art intrusive model reduction methods that require full\nknowledge of the governing equations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 16:27:05 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 22:11:28 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Benner", "Peter", ""], ["Goyal", "Pawan", ""], ["Kramer", "Boris", ""], ["Peherstorfer", "Benjamin", ""], ["Willcox", "Karen", ""]]}, {"id": "2002.09735", "submitter": "Will Wei Sun", "authors": "Jie Zhou and Will Wei Sun and Jingfei Zhang and Lexin Li", "title": "Partially Observed Dynamic Tensor Response Regression", "comments": "Improved lower bound on observation probability (Assumptions 2,6);\n  Improved sample complexity conditions (Assumptions 5,10); Improved final\n  statistical error rate in Theorems 1-2; add a new initialization section;\n  extend to sub-Gaussian error tensor", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data science, dynamic tensor data is prevailing in numerous\napplications. An important task is to characterize the relationship between\nsuch dynamic tensor and external covariates. However, the tensor data is often\nonly partially observed, rendering many existing methods inapplicable. In this\narticle, we develop a regression model with partially observed dynamic tensor\nas the response and external covariates as the predictor. We introduce the\nlow-rank, sparsity and fusion structures on the regression coefficient tensor,\nand consider a loss function projected over the observed entries. We develop an\nefficient non-convex alternating updating algorithm, and derive the\nfinite-sample error bound of the actual estimator from each step of our\noptimization algorithm. Unobserved entries in tensor response have imposed\nserious challenges. As a result, our proposal differs considerably in terms of\nestimation algorithm, regularity conditions, as well as theoretical properties,\ncompared to the existing tensor completion or tensor response regression\nsolutions. We illustrate the efficacy of our proposed method using simulations,\nand two real applications, a neuroimaging dementia study and a digital\nadvertising study.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:14:10 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 22:09:53 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 23:30:56 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhou", "Jie", ""], ["Sun", "Will Wei", ""], ["Zhang", "Jingfei", ""], ["Li", "Lexin", ""]]}, {"id": "2002.09737", "submitter": "Li Wenliang", "authors": "Li K. Wenliang, Theodore Moskovitz, Heishiro Kanagawa, Maneesh Sahani", "title": "Amortised Learning by Wake-Sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Models that employ latent variables to capture structure in observed data lie\nat the heart of many current unsupervised learning algorithms, but exact\nmaximum-likelihood learning for powerful and flexible latent-variable models is\nalmost always intractable. Thus, state-of-the-art approaches either abandon the\nmaximum-likelihood framework entirely, or else rely on a variety of variational\napproximations to the posterior distribution over the latents. Here, we propose\nan alternative approach that we call amortised learning. Rather than computing\nan approximation to the posterior over latents, we use a wake-sleep Monte-Carlo\nstrategy to learn a function that directly estimates the maximum-likelihood\nparameter updates. Amortised learning is possible whenever samples of latents\nand observations can be simulated from the generative model, treating the model\nas a \"black box\". We demonstrate its effectiveness on a wide range of complex\nmodels, including those with latents that are discrete or supported on\nnon-Euclidean spaces.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 17:24:28 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 22:37:41 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wenliang", "Li K.", ""], ["Moskovitz", "Theodore", ""], ["Kanagawa", "Heishiro", ""], ["Sahani", "Maneesh", ""]]}, {"id": "2002.09741", "submitter": "Cheng Lu", "authors": "Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, Tian Tian", "title": "VFlow: More Expressive Generative Flows with Variational Data\n  Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative flows are promising tractable models for density modeling that\ndefine probabilistic distributions with invertible transformations. However,\ntractability imposes architectural constraints on generative flows, making them\nless expressive than other types of generative models. In this work, we study a\npreviously overlooked constraint that all the intermediate representations must\nhave the same dimensionality with the original data due to invertibility,\nlimiting the width of the network. We tackle this constraint by augmenting the\ndata with some extra dimensions and jointly learning a generative flow for\naugmented data as well as the distribution of augmented dimensions under a\nvariational inference framework. Our approach, VFlow, is a generalization of\ngenerative flows and therefore always performs better. Combining with existing\ngenerative flows, VFlow achieves a new state-of-the-art 2.98 bits per dimension\non the CIFAR-10 dataset and is more compact than previous models to reach\nsimilar modeling quality.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:03:44 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 15:27:12 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Chen", "Jianfei", ""], ["Lu", "Cheng", ""], ["Chenli", "Biqi", ""], ["Zhu", "Jun", ""], ["Tian", "Tian", ""]]}, {"id": "2002.09745", "submitter": "Judy Hanwen Shen", "authors": "Sivakanth Gopi, Pankaj Gulhane, Janardhan Kulkarni, Judy Hanwen Shen,\n  Milad Shokouhi and Sergey Yekhanin", "title": "Differentially Private Set Union", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the basic operation of set union in the global model of differential\nprivacy. In this problem, we are given a universe $U$ of items, possibly of\ninfinite size, and a database $D$ of users. Each user $i$ contributes a subset\n$W_i \\subseteq U$ of items. We want an ($\\epsilon$,$\\delta$)-differentially\nprivate algorithm which outputs a subset $S \\subset \\cup_i W_i$ such that the\nsize of $S$ is as large as possible. The problem arises in countless real world\napplications; it is particularly ubiquitous in natural language processing\n(NLP) applications as vocabulary extraction. For example, discovering words,\nsentences, $n$-grams etc., from private text data belonging to users is an\ninstance of the set union problem.\n  Known algorithms for this problem proceed by collecting a subset of items\nfrom each user, taking the union of such subsets, and disclosing the items\nwhose noisy counts fall above a certain threshold. Crucially, in the above\nprocess, the contribution of each individual user is always independent of the\nitems held by other users, resulting in a wasteful aggregation process, where\nsome item counts happen to be way above the threshold. We deviate from the\nabove paradigm by allowing users to contribute their items in a\n$\\textit{dependent fashion}$, guided by a $\\textit{policy}$. In this new\nsetting ensuring privacy is significantly delicate. We prove that any policy\nwhich has certain $\\textit{contractive}$ properties would result in a\ndifferentially private algorithm. We design two new algorithms, one using\nLaplace noise and other Gaussian noise, as specific instances of policies\nsatisfying the contractive properties. Our experiments show that the new\nalgorithms significantly outperform previously known mechanisms for the\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 18:33:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gopi", "Sivakanth", ""], ["Gulhane", "Pankaj", ""], ["Kulkarni", "Janardhan", ""], ["Shen", "Judy Hanwen", ""], ["Shokouhi", "Milad", ""], ["Yekhanin", "Sergey", ""]]}, {"id": "2002.09754", "submitter": "Parmita Mehta", "authors": "Parmita Mehta, Stephen Portillo, Magdalena Balazinska, Andrew Connolly", "title": "Sampling for Deep Learning Model Diagnosis (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) models have achieved paradigm-changing performance in many\nfields with high dimensional data, such as images, audio, and text. However,\nthe black-box nature of deep neural networks is a barrier not just to adoption\nin applications such as medical diagnosis, where interpretability is essential,\nbut also impedes diagnosis of under performing models. The task of diagnosing\nor explaining DL models requires the computation of additional artifacts, such\nas activation values and gradients. These artifacts are large in volume, and\ntheir computation, storage, and querying raise significant data management\nchallenges.\n  In this paper, we articulate DL diagnosis as a data management problem, and\nwe propose a general, yet representative, set of queries to evaluate systems\nthat strive to support this new workload. We further develop a novel data\nsampling technique that produce approximate but accurate results for these\nmodel debugging queries. Our sampling technique utilizes the lower dimension\nrepresentation learned by the DL model and focuses on model decision boundaries\nfor the data in this lower dimensional space. We evaluate our techniques on one\nstandard computer vision and one scientific data set and demonstrate that our\nsampling technique outperforms a variety of state-of-the-art alternatives in\nterms of query accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:24:16 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mehta", "Parmita", ""], ["Portillo", "Stephen", ""], ["Balazinska", "Magdalena", ""], ["Connolly", "Andrew", ""]]}, {"id": "2002.09758", "submitter": "Ethan Perez", "authors": "Ethan Perez, Patrick Lewis, Wen-tau Yih, Kyunghyun Cho, Douwe Kiela", "title": "Unsupervised Question Decomposition for Question Answering", "comments": "EMNLP 2020 Camera-Ready. Code available at\n  https://github.com/facebookresearch/UnsupervisedDecomposition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to improve question answering (QA) by decomposing hard questions into\nsimpler sub-questions that existing QA systems are capable of answering. Since\nlabeling questions with decompositions is cumbersome, we take an unsupervised\napproach to produce sub-questions, also enabling us to leverage millions of\nquestions from the internet. Specifically, we propose an algorithm for One-to-N\nUnsupervised Sequence transduction (ONUS) that learns to map one hard,\nmulti-hop question to many simpler, single-hop sub-questions. We answer\nsub-questions with an off-the-shelf QA model and give the resulting answers to\na recomposition model that combines them into a final answer. We show large QA\nimprovements on HotpotQA over a strong baseline on the original, out-of-domain,\nand multi-hop dev sets. ONUS automatically learns to decompose different kinds\nof questions, while matching the utility of supervised and heuristic\ndecomposition methods for QA and exceeding those methods in fluency.\nQualitatively, we find that using sub-questions is promising for shedding light\non why a QA system makes a prediction.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:40:35 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 18:49:59 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 18:47:48 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Perez", "Ethan", ""], ["Lewis", "Patrick", ""], ["Yih", "Wen-tau", ""], ["Cho", "Kyunghyun", ""], ["Kiela", "Douwe", ""]]}, {"id": "2002.09763", "submitter": "Hong-Li Zeng", "authors": "Kristiaan Pelckmans and Hong-Li Zeng", "title": "Longitudinal Support Vector Machines for High Dimensional Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a classifier from observed functional\ndata. Here, each data-point takes the form of a single time-series and contains\nnumerous features. Assuming that each such series comes with a binary label,\nthe problem of learning to predict the label of a new coming time-series is\nconsidered. Hereto, the notion of {\\em margin} underlying the classical support\nvector machine is extended to the continuous version for such data. The\nlongitudinal support vector machine is also a convex optimization problem and\nits dual form is derived as well. Empirical results for specified cases with\nsignificance tests indicate the efficacy of this innovative algorithm for\nanalyzing such long-term multivariate data.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:01:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Pelckmans", "Kristiaan", ""], ["Zeng", "Hong-Li", ""]]}, {"id": "2002.09766", "submitter": "Chen Zhu", "authors": "Chen Zhu, Renkun Ni, Ping-yeh Chiang, Hengduo Li, Furong Huang, Tom\n  Goldstein", "title": "Improving the Tightness of Convex Relaxation Bounds for Training\n  Certifiably Robust Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex relaxations are effective for training and certifying neural networks\nagainst norm-bounded adversarial attacks, but they leave a large gap between\ncertifiable and empirical robustness. In principle, convex relaxation can\nprovide tight bounds if the solution to the relaxed problem is feasible for the\noriginal non-convex problem. We propose two regularizers that can be used to\ntrain neural networks that yield tighter convex relaxation bounds for\nrobustness. In all of our experiments, the proposed regularizers result in\nhigher certified accuracy than non-regularized baselines.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:19:53 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhu", "Chen", ""], ["Ni", "Renkun", ""], ["Chiang", "Ping-yeh", ""], ["Li", "Hengduo", ""], ["Huang", "Furong", ""], ["Goldstein", "Tom", ""]]}, {"id": "2002.09769", "submitter": "Henry WJ Reeve", "authors": "Henry WJ Reeve, Ata Kaban", "title": "Optimistic bounds for multi-output prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the challenge of multi-output learning, where the goal is to\nlearn a vector-valued function based on a supervised data set. This includes a\nrange of important problems in Machine Learning including multi-target\nregression, multi-class classification and multi-label classification. We begin\nour analysis by introducing the self-bounding Lipschitz condition for\nmulti-output loss functions, which interpolates continuously between a\nclassical Lipschitz condition and a multi-dimensional analogue of a smoothness\ncondition. We then show that the self-bounding Lipschitz condition gives rise\nto optimistic bounds for multi-output learning, which are minimax optimal up to\nlogarithmic factors. The proof exploits local Rademacher complexity combined\nwith a powerful minoration inequality due to Srebro, Sridharan and Tewari. As\nan application we derive a state-of-the-art generalization bound for\nmulti-class gradient boosting.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 20:54:17 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Reeve", "Henry WJ", ""], ["Kaban", "Ata", ""]]}, {"id": "2002.09772", "submitter": "Aly El Gamal", "authors": "Kirthi Shankar Sivamani, Rajeev Sahay, Aly El Gamal", "title": "Non-Intrusive Detection of Adversarial Deep Learning Attacks via\n  Observer Networks", "comments": "5 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep learning models are vulnerable to\nspecifically crafted adversarial inputs that are quasi-imperceptible to humans.\nIn this letter, we propose a novel method to detect adversarial inputs, by\naugmenting the main classification network with multiple binary detectors\n(observer networks) which take inputs from the hidden layers of the original\nnetwork (convolutional kernel outputs) and classify the input as clean or\nadversarial. During inference, the detectors are treated as a part of an\nensemble network and the input is deemed adversarial if at least half of the\ndetectors classify it as so. The proposed method addresses the trade-off\nbetween accuracy of classification on clean and adversarial samples, as the\noriginal classification network is not modified during the detection process.\nThe use of multiple observer networks makes attacking the detection mechanism\nnon-trivial even when the attacker is aware of the victim classifier. We\nachieve a 99.5% detection accuracy on the MNIST dataset and 97.5% on the\nCIFAR-10 dataset using the Fast Gradient Sign Attack in a semi-white box setup.\nThe number of false positive detections is a mere 0.12% in the worst case\nscenario.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 21:13:00 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sivamani", "Kirthi Shankar", ""], ["Sahay", "Rajeev", ""], ["Gamal", "Aly El", ""]]}, {"id": "2002.09773", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Mert Pilanci", "title": "Revealing the Structure of Deep Neural Networks via Convex Duality", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study regularized deep neural networks (DNNs) and introduce a convex\nanalytic framework to characterize the structure of the hidden layers. We show\nthat a set of optimal hidden layer weights for a norm regularized DNN training\nproblem can be explicitly found as the extreme points of a convex set. For the\nspecial case of deep linear networks, we prove that each optimal weight matrix\naligns with the previous layers via duality. More importantly, we apply the\nsame characterization to deep ReLU networks with whitened data and prove the\nsame weight alignment holds. As a corollary, we also prove that norm\nregularized deep ReLU networks yield spline interpolation for one-dimensional\ndatasets which was previously known only for two-layer networks. Furthermore,\nwe provide closed-form solutions for the optimal layer weights when data is\nrank-one or whitened. The same analysis also applies to architectures with\nbatch normalization even for arbitrary data. Therefore, we obtain a complete\nexplanation for a recent empirical observation termed Neural Collapse where\nclass means collapse to the vertices of a simplex equiangular tight frame.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 21:13:44 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:27:45 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 02:36:15 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 17:21:01 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ergen", "Tolga", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.09779", "submitter": "Alexandra Volokhova", "authors": "Viktor Oganesyan, Alexandra Volokhova, Dmitry Vetrov", "title": "Stochasticity in Neural ODEs: An Empirical Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic regularization of neural networks (e.g. dropout) is a wide-spread\ntechnique in deep learning that allows for better generalization. Despite its\nsuccess, continuous-time models, such as neural ordinary differential equation\n(ODE), usually rely on a completely deterministic feed-forward operation. This\nwork provides an empirical study of stochastically regularized neural ODE on\nseveral image-classification tasks (CIFAR-10, CIFAR-100, TinyImageNet).\nBuilding upon the formalism of stochastic differential equations (SDEs), we\ndemonstrate that neural SDE is able to outperform its deterministic\ncounterpart. Further, we show that data augmentation during the training\nimproves the performance of both deterministic and stochastic versions of the\nsame model. However, the improvements obtained by the data augmentation\ncompletely eliminate the empirical gains of the stochastic regularization,\nmaking the difference in the performance of neural ODE and neural SDE\nnegligible.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:12:56 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 17:02:20 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Oganesyan", "Viktor", ""], ["Volokhova", "Alexandra", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "2002.09781", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amir Globerson", "title": "An Optimization and Generalization Analysis for Max-Pooling Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-Pooling operations are a core component of deep learning architectures.\nIn particular, they are part of most convolutional architectures used in\nmachine vision, since pooling is a natural approach to pattern detection\nproblems. However, these architectures are not well understood from a\ntheoretical perspective. For example, we do not understand when they can be\nglobally optimized, and what is the effect of over-parameterization on\ngeneralization. Here we perform a theoretical analysis of a convolutional\nmax-pooling architecture, proving that it can be globally optimized, and can\ngeneralize well even for highly over-parameterized models. Our analysis focuses\non a data generating distribution inspired by pattern detection problem, where\na \"discriminative\" pattern needs to be detected among \"spurious\" patterns. We\nempirically validate that CNNs significantly outperform fully connected\nnetworks in our setting, as predicted by our theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:26:26 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 20:13:27 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 09:10:23 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 11:45:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Brutzkus", "Alon", ""], ["Globerson", "Amir", ""]]}, {"id": "2002.09786", "submitter": "Abdulrahman Mahmoud", "authors": "Abdulrahman Mahmoud, Siva Kumar Sastry Hari, Christopher W. Fletcher,\n  Sarita V. Adve, Charbel Sakr, Naresh Shanbhag, Pavlo Molchanov, Michael B.\n  Sullivan, Timothy Tsai, Stephen W. Keckler", "title": "HarDNN: Feature Map Vulnerability Evaluation in CNNs", "comments": "14 pages, 5 figures, a short version accepted for publication in\n  First Workshop on Secure and Resilient Autonomy (SARA) co-located with\n  MLSys2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Convolutional Neural Networks (CNNs) are increasingly being employed in\nsafety-critical applications, it is important that they behave reliably in the\nface of hardware errors. Transient hardware errors may percolate undesirable\nstate during execution, resulting in software-manifested errors which can\nadversely affect high-level decision making. This paper presents HarDNN, a\nsoftware-directed approach to identify vulnerable computations during a CNN\ninference and selectively protect them based on their propensity towards\ncorrupting the inference output in the presence of a hardware error. We show\nthat HarDNN can accurately estimate relative vulnerability of a feature map\n(fmap) in CNNs using a statistical error injection campaign, and explore\nheuristics for fast vulnerability assessment. Based on these results, we\nanalyze the tradeoff between error coverage and computational overhead that the\nsystem designers can use to employ selective protection. Results show that the\nimprovement in resilience for the added computation is superlinear with HarDNN.\nFor example, HarDNN improves SqueezeNet's resilience by 10x with just 30%\nadditional computations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 23:05:03 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 11:07:36 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mahmoud", "Abdulrahman", ""], ["Hari", "Siva Kumar Sastry", ""], ["Fletcher", "Christopher W.", ""], ["Adve", "Sarita V.", ""], ["Sakr", "Charbel", ""], ["Shanbhag", "Naresh", ""], ["Molchanov", "Pavlo", ""], ["Sullivan", "Michael B.", ""], ["Tsai", "Timothy", ""], ["Keckler", "Stephen W.", ""]]}, {"id": "2002.09794", "submitter": "Sivakumar Chidambaram", "authors": "Sivakumar Chidambaram, J.M. Pierre Langlois, Jean Pierre David", "title": "PoET-BiN: Power Efficient Tiny Binary Neurons", "comments": "Accepted in MLSys 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks in image classification has inspired various\nhardware implementations on embedded platforms such as Field Programmable Gate\nArrays, embedded processors and Graphical Processing Units. These embedded\nplatforms are constrained in terms of power, which is mainly consumed by the\nMultiply Accumulate operations and the memory accesses for weight fetching.\nQuantization and pruning have been proposed to address this issue. Though\neffective, these techniques do not take into account the underlying\narchitecture of the embedded hardware. In this work, we propose PoET-BiN, a\nLook-Up Table based power efficient implementation on resource constrained\nembedded devices. A modified Decision Tree approach forms the backbone of the\nproposed implementation in the binary domain. A LUT access consumes far less\npower than the equivalent Multiply Accumulate operation it replaces, and the\nmodified Decision Tree algorithm eliminates the need for memory accesses. We\napplied the PoET-BiN architecture to implement the classification layers of\nnetworks trained on MNIST, SVHN and CIFAR-10 datasets, with near state-of-the\nart results. The energy reduction for the classifier portion reaches up to six\norders of magnitude compared to a floating point implementations and up to\nthree orders of magnitude when compared to recent binary quantized neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:32:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Chidambaram", "Sivakumar", ""], ["Langlois", "J. M. Pierre", ""], ["David", "Jean Pierre", ""]]}, {"id": "2002.09795", "submitter": "Donghwan Lee", "authors": "Donghwan Lee and Niao He", "title": "Periodic Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of target networks is a common practice in deep reinforcement\nlearning for stabilizing the training; however, theoretical understanding of\nthis technique is still limited. In this paper, we study the so-called periodic\nQ-learning algorithm (PQ-learning for short), which resembles the technique\nused in deep Q-learning for solving infinite-horizon discounted Markov decision\nprocesses (DMDP) in the tabular setting. PQ-learning maintains two separate\nQ-value estimates - the online estimate and target estimate. The online\nestimate follows the standard Q-learning update, while the target estimate is\nupdated periodically. In contrast to the standard Q-learning, PQ-learning\nenjoys a simple finite time analysis and achieves better sample complexity for\nfinding an epsilon-optimal policy. Our result provides a preliminary\njustification of the effectiveness of utilizing target estimates or networks in\nQ-learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:33:13 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lee", "Donghwan", ""], ["He", "Niao", ""]]}, {"id": "2002.09797", "submitter": "Seong Joon Oh", "authors": "Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi,\n  Jaejun Yoo", "title": "Reliable Fidelity and Diversity Metrics for Generative Models", "comments": "First two authors have contributed equally; ICML 2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Devising indicative evaluation metrics for the image generation task remains\nan open problem. The most widely used metric for measuring the similarity\nbetween real and generated images has been the Fr\\'echet Inception Distance\n(FID) score. Because it does not differentiate the fidelity and diversity\naspects of the generated images, recent papers have introduced variants of\nprecision and recall metrics to diagnose those properties separately. In this\npaper, we show that even the latest version of the precision and recall metrics\nare not reliable yet. For example, they fail to detect the match between two\nidentical distributions, they are not robust against outliers, and the\nevaluation hyperparameters are selected arbitrarily. We propose density and\ncoverage metrics that solve the above issues. We analytically and\nexperimentally show that density and coverage provide more interpretable and\nreliable signals for practitioners than the existing metrics. Code:\nhttps://github.com/clovaai/generative-evaluation-prdc.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 00:50:01 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 20:37:50 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Naeem", "Muhammad Ferjad", ""], ["Oh", "Seong Joon", ""], ["Uh", "Youngjung", ""], ["Choi", "Yunjey", ""], ["Yoo", "Jaejun", ""]]}, {"id": "2002.09812", "submitter": "Xin Yang", "authors": "Yingyu Liang, Zhao Song, Mengdi Wang, Lin F. Yang, Xin Yang", "title": "Sketching Transformed Matrices with Applications to Natural Language\n  Processing", "comments": "AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we are given a large matrix $A=(a_{i,j})$ that cannot be stored in\nmemory but is in a disk or is presented in a data stream. However, we need to\ncompute a matrix decomposition of the entry-wisely transformed matrix,\n$f(A):=(f(a_{i,j}))$ for some function $f$. Is it possible to do it in a space\nefficient way? Many machine learning applications indeed need to deal with such\nlarge transformed matrices, for example word embedding method in NLP needs to\nwork with the pointwise mutual information (PMI) matrix, while the entrywise\ntransformation makes it difficult to apply known linear algebraic tools.\nExisting approaches for this problem either need to store the whole matrix and\nperform the entry-wise transformation afterwards, which is space consuming or\ninfeasible, or need to redesign the learning method, which is application\nspecific and requires substantial remodeling.\n  In this paper, we first propose a space-efficient sketching algorithm for\ncomputing the product of a given small matrix with the transformed matrix. It\nworks for a general family of transformations with provable small error bounds\nand thus can be used as a primitive in downstream learning tasks. We then apply\nthis primitive to a concrete application: low-rank approximation. We show that\nour approach obtains small error and is efficient in both space and time. We\ncomplement our theoretical results with experiments on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:07:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Liang", "Yingyu", ""], ["Song", "Zhao", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""], ["Yang", "Xin", ""]]}, {"id": "2002.09814", "submitter": "Sanath Kumar Krishnamurthy", "authors": "Sanath Kumar Krishnamurthy, Susan Athey", "title": "Survey Bandits with Regret Guarantees", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a variant of the contextual bandit problem. In standard\ncontextual bandits, when a user arrives we get the user's complete feature\nvector and then assign a treatment (arm) to that user. In a number of\napplications (like healthcare), collecting features from users can be costly.\nTo address this issue, we propose algorithms that avoid needless feature\ncollection while maintaining strong regret guarantees.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:24:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Krishnamurthy", "Sanath Kumar", ""], ["Athey", "Susan", ""]]}, {"id": "2002.09815", "submitter": "Amirata Ghorbani", "authors": "Amirata Ghorbani and James Zou", "title": "Neuron Shapley: Discovering the Responsible Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop Neuron Shapley as a new framework to quantify the contribution of\nindividual neurons to the prediction and performance of a deep network. By\naccounting for interactions across neurons, Neuron Shapley is more effective in\nidentifying important filters compared to common approaches based on activation\npatterns. Interestingly, removing just 30 filters with the highest Shapley\nscores effectively destroys the prediction accuracy of Inception-v3 on\nImageNet. Visualization of these few critical filters provides insights into\nhow the network functions. Neuron Shapley is a flexible framework and can be\napplied to identify responsible neurons in many tasks. We illustrate additional\napplications of identifying filters that are responsible for biased prediction\nin facial recognition and filters that are vulnerable to adversarial attacks.\nRemoving these filters is a quick way to repair models. Enabling all these\napplications is a new multi-arm bandit algorithm that we developed to\nefficiently estimate Neuron Shapley values.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:29:58 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 06:57:29 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 22:06:48 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Zou", "James", ""]]}, {"id": "2002.09818", "submitter": "Burkay Donderici", "authors": "Burkay Donderici, Caleb New, Chenliang Xu", "title": "Assembling Semantically-Disentangled Representations for\n  Predictive-Generative Models via Adaptation from Synthetic Domain", "comments": "8 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can form high-level hierarchical representations of\ninput data. Various researchers have demonstrated that these representations\ncan be used to enable a variety of useful applications. However, such\nrepresentations are typically based on the statistics within the data, and may\nnot conform with the semantic representation that may be necessitated by the\napplication. Conditional models are typically used to overcome this challenge,\nbut they require large annotated datasets which are difficult to come by and\ncostly to create. In this paper, we show that semantically-aligned\nrepresentations can be generated instead with the help of a physics based\nengine. This is accomplished by creating a synthetic dataset with decoupled\nattributes, learning an encoder for the synthetic dataset, and augmenting\nprescribed attributes from the synthetic domain with attributes from the real\ndomain. It is shown that the proposed (SYNTH-VAE-GAN) method can construct a\nconditional predictive-generative model of human face attributes without\nrelying on real data labels.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:35:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Donderici", "Burkay", ""], ["New", "Caleb", ""], ["Xu", "Chenliang", ""]]}, {"id": "2002.09820", "submitter": "Gabriel Fernandez", "authors": "Gabriel I. Fernandez, Colin Togashi, Dennis W. Hong, Lin F. Yang", "title": "Deep Reinforcement Learning with Linear Quadratic Regulator Regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners often rely on compute-intensive domain randomization to ensure\nreinforcement learning policies trained in simulation can robustly transfer to\nthe real world. Due to unmodeled nonlinearities in the real system, however,\neven such simulated policies can still fail to perform stably enough to acquire\nexperience in real environments. In this paper we propose a novel method that\nguarantees a stable region of attraction for the output of a policy trained in\nsimulation, even for highly nonlinear systems. Our core technique is to use\n\"bias-shifted\" neural networks for constructing the controller and training the\nnetwork in the simulator. The modified neural networks not only capture the\nnonlinearities of the system but also provably preserve linearity in a certain\nregion of the state space and thus can be tuned to resemble a linear quadratic\nregulator that is known to be stable for the real system. We have tested our\nnew method by transferring simulated policies for a swing-up inverted pendulum\nto real systems and demonstrated its efficacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:50:49 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 03:46:10 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fernandez", "Gabriel I.", ""], ["Togashi", "Colin", ""], ["Hong", "Dennis W.", ""], ["Yang", "Lin F.", ""]]}, {"id": "2002.09821", "submitter": "Weitao Xu", "authors": "Weitao Xu, Xiang Zhang, Lina Yao, Wanli Xue, Bo Wei", "title": "A Multi-view CNN-based Acoustic Classification System for Automatic\n  Animal Species Identification", "comments": null, "journal-ref": "Ad Hoc Networks 2020", "doi": "10.1016/j.adhoc.2020.102115", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic identification of animal species by their vocalization is an\nimportant and challenging task. Although many kinds of audio monitoring system\nhave been proposed in the literature, they suffer from several disadvantages\nsuch as non-trivial feature selection, accuracy degradation because of\nenvironmental noise or intensive local computation. In this paper, we propose a\ndeep learning based acoustic classification framework for Wireless Acoustic\nSensor Network (WASN). The proposed framework is based on cloud architecture\nwhich relaxes the computational burden on the wireless sensor node. To improve\nthe recognition accuracy, we design a multi-view Convolution Neural Network\n(CNN) to extract the short-, middle-, and long-term dependencies in parallel.\nThe evaluation on two real datasets shows that the proposed architecture can\nachieve high accuracy and outperforms traditional classification systems\nsignificantly when the environmental noise dominate the audio signal (low SNR).\nMoreover, we implement and deploy the proposed system on a testbed and analyse\nthe system performance in real-world environments. Both simulation and\nreal-world evaluation demonstrate the accuracy and robustness of the proposed\nacoustic classification system in distinguishing species of animals.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 03:51:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Xu", "Weitao", ""], ["Zhang", "Xiang", ""], ["Yao", "Lina", ""], ["Xue", "Wanli", ""], ["Wei", "Bo", ""]]}, {"id": "2002.09831", "submitter": "Samet Oymak", "authors": "Yuan Zhao, Jiasi Chen, Samet Oymak", "title": "On the Role of Dataset Quality and Heterogeneity in Model Confidence", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety-critical applications require machine learning models that output\naccurate and calibrated probabilities. While uncalibrated deep networks are\nknown to make over-confident predictions, it is unclear how model confidence is\nimpacted by the variations in the data, such as label noise or class size. In\nthis paper, we investigate the role of the dataset quality by studying the\nimpact of dataset size and the label noise on the model confidence. We\ntheoretically explain and experimentally demonstrate that, surprisingly, label\nnoise in the training data leads to under-confident networks, while reduced\ndataset size leads to over-confident models. We then study the impact of\ndataset heterogeneity, where data quality varies across classes, on model\nconfidence. We demonstrate that this leads to heterogenous confidence/accuracy\nbehavior in the test data and is poorly handled by the standard calibration\nalgorithms. To overcome this, we propose an intuitive heterogenous calibration\ntechnique and show that the proposed approach leads to improved calibration\nmetrics (both average and worst-case errors) on the CIFAR datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:13:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhao", "Yuan", ""], ["Chen", "Jiasi", ""], ["Oymak", "Samet", ""]]}, {"id": "2002.09832", "submitter": "Lior Rokach", "authors": "Sigal Shaked, Amos Zamir, Roman Vainshtein, Moshe Unger, Lior Rokach,\n  Rami Puzis, Bracha Shapira", "title": "Sequence Preserving Network Traffic Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Network Traffic Generator (NTG), a framework for perturbing\nrecorded network traffic with the purpose of generating diverse but realistic\nbackground traffic for network simulation and what-if analysis in enterprise\nenvironments. The framework preserves many characteristics of the original\ntraffic recorded in an enterprise, as well as sequences of network activities.\nUsing the proposed framework, the original traffic flows are profiled using 200\ncross-protocol features. The traffic is aggregated into flows of packets\nbetween IP pairs and clustered into groups of similar network activities.\nSequences of network activities are then extracted. We examined two methods for\nextracting sequences of activities: a Markov model and a neural language model.\nFinally, new traffic is generated using the extracted model. We developed a\nprototype of the framework and conducted extensive experiments based on two\nreal network traffic collections. Hypothesis testing was used to examine the\ndifference between the distribution of original and generated features, showing\nthat 30-100\\% of the extracted features were preserved. Small differences\nbetween n-gram perplexities in sequences of network activities in the original\nand generated traffic, indicate that sequences of network activities were well\npreserved.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:17:37 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shaked", "Sigal", ""], ["Zamir", "Amos", ""], ["Vainshtein", "Roman", ""], ["Unger", "Moshe", ""], ["Rokach", "Lior", ""], ["Puzis", "Rami", ""], ["Shapira", "Bracha", ""]]}, {"id": "2002.09834", "submitter": "Lior Rokach", "authors": "Sigal Shaked, Lior Rokach", "title": "PrivGen: Preserving Privacy of Sequences Through Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data is everywhere, and it can serve as a basis for research that\nwill lead to improved processes. For example, road infrastructure can be\nimproved by identifying bottlenecks in GPS data, or early diagnosis can be\nimproved by analyzing patterns of disease progression in medical data. The main\nobstacle is that access and use of such data is usually limited or not\npermitted at all due to concerns about violating user privacy, and rightly so.\nAnonymizing sequence data is not a simple task, since a user creates an almost\nunique signature over time. Existing anonymization methods reduce the quality\nof information in order to maintain the level of anonymity required. Damage to\nquality may disrupt patterns that appear in the original data and impair the\npreservation of various characteristics. Since in many cases the researcher\ndoes not need the data as is and instead is only interested in the patterns\nthat exist in the data, we propose PrivGen, an innovative method for generating\ndata that maintains patterns and characteristics of the source data. We\ndemonstrate that the data generation mechanism significantly limits the risk of\nprivacy infringement. Evaluating our method with real-world datasets shows that\nits generated data preserves many characteristics of the data, including the\nsequential model, as trained based on the source data. This suggests that the\ndata generated by our method could be used in place of actual data for various\ntypes of analysis, maintaining user privacy and the data's integrity at the\nsame time.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:43:15 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shaked", "Sigal", ""], ["Rokach", "Lior", ""]]}, {"id": "2002.09841", "submitter": "Chao Wang", "authors": "Chao Wang, Hengshu Zhu, Chen Zhu, Chuan Qin, Hui Xiong", "title": "SetRank: A Setwise Bayesian Approach for Collaborative Ranking from\n  Implicit Feedback", "comments": "This paper has been accepted in AAAI'20", "journal-ref": "The Thirty-Fourth AAAI Conference on Artificial Intelligenc\n  (AAAI'20), New York, New York, USA, 2020", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent development of online recommender systems has a focus on\ncollaborative ranking from implicit feedback, such as user clicks and\npurchases. Different from explicit ratings, which reflect graded user\npreferences, the implicit feedback only generates positive and unobserved\nlabels. While considerable efforts have been made in this direction, the\nwell-known pairwise and listwise approaches have still been limited by various\nchallenges. Specifically, for the pairwise approaches, the assumption of\nindependent pairwise preference is not always held in practice. Also, the\nlistwise approaches cannot efficiently accommodate \"ties\" due to the\nprecondition of the entire list permutation. To this end, in this paper, we\npropose a novel setwise Bayesian approach for collaborative ranking, namely\nSetRank, to inherently accommodate the characteristics of implicit feedback in\nrecommender system. Specifically, SetRank aims at maximizing the posterior\nprobability of novel setwise preference comparisons and can be implemented with\nmatrix factorization and neural networks. Meanwhile, we also present the\ntheoretical analysis of SetRank to show that the bound of excess risk can be\nproportional to $\\sqrt{M/N}$, where $M$ and $N$ are the numbers of items and\nusers, respectively. Finally, extensive experiments on four real-world datasets\nclearly validate the superiority of SetRank compared with various\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:40:48 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Chao", ""], ["Zhu", "Hengshu", ""], ["Zhu", "Chen", ""], ["Qin", "Chuan", ""], ["Xiong", "Hui", ""]]}, {"id": "2002.09843", "submitter": "Yan Feng", "authors": "Xue Yang, Yan Feng, Weijun Fang, Jun Shao, Xiaohu Tang, Shu-Tao Xia,\n  Rongxing Lu", "title": "Computation-efficient Deep Model Training for Ciphertext-based\n  Cross-silo Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cross-silo federated learning improves privacy of training data by\nexchanging model updates rather than raw data, sharing updates (e.g., local\ngradients or parameters) may still involve risks. To ensure no updates are\nrevealed to the server, industrial FL schemes allow clients (e.g., financial or\nmedical) to mask local gradients by homomorphic encryption (HE). In this case,\nthe server cannot obtain the updates, but the curious clients can obtain this\ninformation to infer other clients' private data. To alleviate this situation,\nthe most direct idea is to let clients train deep models on encrypted domain.\nUnfortunately, the resulting solution is of poor accuracy and high cost, since\nthe existing advanced HE is incompatible with non-linear activation functions\nand inefficient in terms of computational cost. In this paper, we propose a\n\\emph{computational-efficient deep model training scheme for ciphertext-based\ncross-silo federated learning} to comprehensively guarantee privacy. First, we\ncustomize \\emph{a novel one-time-pad-style model encryption method} to directly\nsupports non-linear activation functions and decimal arithmetic operations on\nthe encrypted domain. Then, we design a hybrid privacy-preserving scheme by\ncombining our model encryption method with secret sharing techniques to keep\nupdates secret from the clients and prevent the server from obtaining local\ngradients of each client. Extensive experiments demonstrate that for both\nregression and classification tasks, our scheme achieves the same accuracy as\nnon-private approaches and outperforms the state-of-the-art HE-based scheme.\nBesides, training time of our scheme is almost the same as non-private\napproaches and much more efficient than HE-based schemes. Our scheme trains a\n$9$-layer neural network on the MNIST dataset in less than one hour.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 06:50:20 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 02:24:04 GMT"}, {"version": "v3", "created": "Thu, 6 Aug 2020 15:10:37 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 08:35:48 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Yang", "Xue", ""], ["Feng", "Yan", ""], ["Fang", "Weijun", ""], ["Shao", "Jun", ""], ["Tang", "Xiaohu", ""], ["Xia", "Shu-Tao", ""], ["Lu", "Rongxing", ""]]}, {"id": "2002.09846", "submitter": "Wei Ye", "authors": "Wei Ye, Zhen Wang, Rachel Redberg, Ambuj Singh", "title": "Tree++: Truncated Tree Based Graph Kernels", "comments": null, "journal-ref": null, "doi": "10.1109/TKDE.2019.2946149", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph-structured data arise ubiquitously in many application domains. A\nfundamental problem is to quantify their similarities. Graph kernels are often\nused for this purpose, which decompose graphs into substructures and compare\nthese substructures. However, most of the existing graph kernels do not have\nthe property of scale-adaptivity, i.e., they cannot compare graphs at multiple\nlevels of granularities. Many real-world graphs such as molecules exhibit\nstructure at varying levels of granularities. To tackle this problem, we\npropose a new graph kernel called Tree++ in this paper. At the heart of Tree++\nis a graph kernel called the path-pattern graph kernel. The path-pattern graph\nkernel first builds a truncated BFS tree rooted at each vertex and then uses\npaths from the root to every vertex in the truncated BFS tree as features to\nrepresent graphs. The path-pattern graph kernel can only capture graph\nsimilarity at fine granularities. In order to capture graph similarity at\ncoarse granularities, we incorporate a new concept called super path into it.\nThe super path contains truncated BFS trees rooted at the vertices in a path.\nOur evaluation on a variety of real-world graphs demonstrates that Tree++\nachieves the best classification accuracy compared with previous graph kernels.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:07:10 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Ye", "Wei", ""], ["Wang", "Zhen", ""], ["Redberg", "Rachel", ""], ["Singh", "Ambuj", ""]]}, {"id": "2002.09847", "submitter": "Jong Chul Ye", "authors": "Joonyoung Song, Jae-Heon Jeong, Dae-Soon Park, Hyun-Ho Kim, Doo-Chun\n  Seo, Jong Chul Ye", "title": "Unsupervised Denoising for Satellite Imagery using Wavelet Subband\n  CycleGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-spectral satellite imaging sensors acquire various spectral band images\nsuch as red (R), green (G), blue (B), near-infrared (N), etc. Thanks to the\nunique spectroscopic property of each spectral band with respective to the\nobjects on the ground, multi-spectral satellite imagery can be used for various\ngeological survey applications. Unfortunately, image artifacts from imaging\nsensor noises often affect the quality of scenes and have negative impacts on\nthe applications of satellite imagery. Recently, deep learning approaches have\nbeen extensively explored for the removal of noises in satellite imagery. Most\ndeep learning denoising methods, however, follow a supervised learning scheme,\nwhich requires matched noisy image and clean image pairs that are difficult to\ncollect in real situations. In this paper, we propose a novel unsupervised\nmultispectral denoising method for satellite imagery using wavelet subband\ncycle-consistent adversarial network (WavCycleGAN). The proposed method is\nbased on unsupervised learning scheme using adversarial loss and\ncycle-consistency loss to overcome the lack of paired data. Moreover, in\ncontrast to the standard image domain cycleGAN, we introduce a wavelet subband\ndomain learning scheme for effective denoising without sacrificing high\nfrequency components such as edges and detail information. Experimental results\nfor the removal of vertical stripe and wave noises in satellite imaging sensors\ndemonstrate that the proposed method effectively removes noises and preserves\nimportant high frequency features of satellite images.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:11:05 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Song", "Joonyoung", ""], ["Jeong", "Jae-Heon", ""], ["Park", "Dae-Soon", ""], ["Kim", "Hyun-Ho", ""], ["Seo", "Doo-Chun", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2002.09853", "submitter": "Azhar Hussain", "authors": "Azhar Hussain, Tong Wang and Cao Jiahua", "title": "Optimizing Traffic Lights with Multi-agent Deep Reinforcement Learning\n  and V2X communication", "comments": "7 Figure, Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a system to optimize duration of traffic signals using\nmulti-agent deep reinforcement learning and Vehicle-to-Everything (V2X)\ncommunication. This system aims at analyzing independent and shared rewards for\nmulti-agents to control duration of traffic lights. A learning agent traffic\nlight gets information along its lanes within a circular V2X coverage. The\nduration cycles of traffic light are modeled as Markov decision Processes. We\ninvestigate four variations of reward functions. The first two are\nunshared-rewards: based on waiting number, and waiting time of vehicles between\ntwo cycles of traffic light. The third and fourth functions are: shared-rewards\nbased on waiting cars, and waiting time for all agents. Each agent has a memory\nfor optimization through target network and prioritized experience replay. We\nevaluate multi-agents through the Simulation of Urban MObility (SUMO)\nsimulator. The results prove effectiveness of the proposed system to optimize\ntraffic signals and reduce average waiting cars to 41.5 % as compared to the\ntraditional periodic traffic control system.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 07:43:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hussain", "Azhar", ""], ["Wang", "Tong", ""], ["Jiahua", "Cao", ""]]}, {"id": "2002.09860", "submitter": "Andrea Asperti", "authors": "Andrea Asperti", "title": "Variance Loss in Variational Autoencoders", "comments": "Article accepted at the Sixth International Conference on Machine\n  Learning, Optimization, and Data Science. July 19-23, 2020 - Certosa di\n  Pontignano, Siena, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we highlight what appears to be major issue of Variational\nAutoencoders, evinced from an extensive experimentation with different network\narchitectures and datasets: the variance of generated data is significantly\nlower than that of training data. Since generative models are usually evaluated\nwith metrics such as the Frechet Inception Distance (FID) that compare the\ndistributions of (features of) real versus generated images, the variance loss\ntypically results in degraded scores. This problem is particularly relevant in\na two stage setting, where we use a second VAE to sample in the latent space of\nthe first VAE. The minor variance creates a mismatch between the actual\ndistribution of latent variables and those generated by the second VAE, that\nhinders the beneficial effects of the second stage. Renormalizing the output of\nthe second VAE towards the expected normal spherical distribution, we obtain a\nsudden burst in the quality of generated samples, as also testified in terms of\nFID.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 08:23:51 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:55:37 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Asperti", "Andrea", ""]]}, {"id": "2002.09864", "submitter": "Daniel Teitelman Mr", "authors": "Daniel Teitelman, Itay Naeh and Shie Mannor", "title": "Stealing Black-Box Functionality Using The Deep Neural Tree Architecture", "comments": "8 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper makes a substantial step towards cloning the functionality of\nblack-box models by introducing a Machine learning (ML) architecture named Deep\nNeural Trees (DNTs). This new architecture can learn to separate different\ntasks of the black-box model, and clone its task-specific behavior. We propose\nto train the DNT using an active learning algorithm to obtain faster and more\nsample-efficient training. In contrast to prior work, we study a complex\n\"victim\" black-box model based solely on input-output interactions, while at\nthe same time the attacker and the victim model may have completely different\ninternal architectures. The attacker is a ML based algorithm whereas the victim\nis a generally unknown module, such as a multi-purpose digital chip, complex\nanalog circuit, mechanical system, software logic or a hybrid of these. The\ntrained DNT module not only can function as the attacked module, but also\nprovides some level of explainability to the cloned model due to the tree-like\nnature of the proposed architecture.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:04:30 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Teitelman", "Daniel", ""], ["Naeh", "Itay", ""], ["Mannor", "Shie", ""]]}, {"id": "2002.09866", "submitter": "Yossi Adi", "authors": "Yossi Adi, Yaniv Nemcovsky, Alex Schwing, Tamir Hazan", "title": "On the generalization of bayesian deep nets for multi-class\n  classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization bounds which assess the difference between the true risk and\nthe empirical risk have been studied extensively. However, to obtain bounds,\ncurrent techniques use strict assumptions such as a uniformly bounded or a\nLipschitz loss function. To avoid these assumptions, in this paper, we propose\na new generalization bound for Bayesian deep nets by exploiting the\ncontractivity of the Log-Sobolev inequalities. Using these inequalities adds an\nadditional loss-gradient norm term to the generalization bound, which is\nintuitively a surrogate of the model complexity. Empirically, we analyze the\naffect of this loss-gradient norm term using different deep nets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:05:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Adi", "Yossi", ""], ["Nemcovsky", "Yaniv", ""], ["Schwing", "Alex", ""], ["Hazan", "Tamir", ""]]}, {"id": "2002.09869", "submitter": "Alon Cohen", "authors": "Alon Cohen, Haim Kaplan, Yishay Mansour and Aviv Rosenberg", "title": "Near-optimal Regret Bounds for Stochastic Shortest Path", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic shortest path (SSP) is a well-known problem in planning and\ncontrol, in which an agent has to reach a goal state in minimum total expected\ncost. In the learning formulation of the problem, the agent is unaware of the\nenvironment dynamics (i.e., the transition function) and has to repeatedly play\nfor a given number of episodes while reasoning about the problem's optimal\nsolution. Unlike other well-studied models in reinforcement learning (RL), the\nlength of an episode is not predetermined (or bounded) and is influenced by the\nagent's actions. Recently, Tarbouriech et al. (2019) studied this problem in\nthe context of regret minimization and provided an algorithm whose regret bound\nis inversely proportional to the square root of the minimum instantaneous cost.\nIn this work we remove this dependence on the minimum cost---we give an\nalgorithm that guarantees a regret bound of $\\widetilde{O}(B_\\star |S|\n\\sqrt{|A| K})$, where $B_\\star$ is an upper bound on the expected cost of the\noptimal policy, $S$ is the set of states, $A$ is the set of actions and $K$ is\nthe number of episodes. We additionally show that any learning algorithm must\nhave at least $\\Omega(B_\\star \\sqrt{|S| |A| K})$ regret in the worst case.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 09:10:14 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cohen", "Alon", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Rosenberg", "Aviv", ""]]}, {"id": "2002.09884", "submitter": "Xiao Ma", "authors": "Xiao Ma, Peter Karkus, David Hsu, Wee Sun Lee, Nan Ye", "title": "Discriminative Particle Filter Reinforcement Learning for Complex\n  Partial Observations", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is successful in decision making for\nsophisticated games, such as Atari, Go, etc. However, real-world decision\nmaking often requires reasoning with partial information extracted from complex\nvisual observations. This paper presents Discriminative Particle Filter\nReinforcement Learning (DPFRL), a new reinforcement learning framework for\ncomplex partial observations. DPFRL encodes a differentiable particle filter in\nthe neural network policy for explicit reasoning with partial observations over\ntime. The particle filter maintains a belief using learned discriminative\nupdate, which is trained end-to-end for decision making. We show that using the\ndiscriminative update instead of standard generative models results in\nsignificantly improved performance, especially for tasks with complex visual\nobservations, because they circumvent the difficulty of modeling complex\nobservations that are irrelevant to decision making. In addition, to extract\nfeatures from the particle belief, we propose a new type of belief feature\nbased on the moment generating function. DPFRL outperforms state-of-the-art\nPOMDP RL models in Flickering Atari Games, an existing POMDP RL benchmark, and\nin Natural Flickering Atari Games, a new, more challenging POMDP RL benchmark\nintroduced in this paper. Further, DPFRL performs well for visual navigation\nwith real-world data in the Habitat environment.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 11:22:43 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiao", ""], ["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""], ["Ye", "Nan", ""]]}, {"id": "2002.09889", "submitter": "Daniel Wilke", "authors": "D. Kafka and Daniel. N. Wilke", "title": "Investigating the interaction between gradient-only line searches and\n  different activation functions", "comments": "37 pages, 9 figures, submitted for journal review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-only line searches (GOLS) adaptively determine step sizes along\nsearch directions for discontinuous loss functions resulting from dynamic\nmini-batch sub-sampling in neural network training. Step sizes in GOLS are\ndetermined by localizing Stochastic Non-Negative Associated Gradient Projection\nPoints (SNN-GPPs) along descent directions. These are identified by a sign\nchange in the directional derivative from negative to positive along a descent\ndirection. Activation functions are a significant component of neural network\narchitectures as they introduce non-linearities essential for complex function\napproximations. The smoothness and continuity characteristics of the activation\nfunctions directly affect the gradient characteristics of the loss function to\nbe optimized. Therefore, it is of interest to investigate the relationship\nbetween activation functions and different neural network architectures in the\ncontext of GOLS. We find that GOLS are robust for a range of activation\nfunctions, but sensitive to the Rectified Linear Unit (ReLU) activation\nfunction in standard feedforward architectures. The zero-derivative in ReLU's\nnegative input domain can lead to the gradient-vector becoming sparse, which\nseverely affects training. We show that implementing architectural features\nsuch as batch normalization and skip connections can alleviate these\ndifficulties and benefit training with GOLS for all activation functions\nconsidered.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 12:28:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kafka", "D.", ""], ["Wilke", "Daniel. N.", ""]]}, {"id": "2002.09891", "submitter": "Enmei Tu", "authors": "Zihao Wang, Enmei Tu, Zhou Meng", "title": "End-To-End Graph-based Deep Semi-Supervised Learning", "comments": "5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of a graph is determined jointly by three key factors of the\ngraph: nodes, edges and similarity measure (or edge weights), and is very\ncrucial to the success of graph-based semi-supervised learning (SSL)\napproaches. Recently, dynamic graph, which means part/all its factors are\ndynamically updated during the training process, has demonstrated to be\npromising for graph-based semi-supervised learning. However, existing\napproaches only update part of the three factors and keep the rest manually\nspecified during the learning stage. In this paper, we propose a novel\ngraph-based semi-supervised learning approach to optimize all three factors\nsimultaneously in an end-to-end learning fashion. To this end, we concatenate\ntwo neural networks (feature network and similarity network) together to learn\nthe categorical label and semantic similarity, respectively, and train the\nnetworks to minimize a unified SSL objective function. We also introduce an\nextended graph Laplacian regularization term to increase training efficiency.\nExtensive experiments on several benchmark datasets demonstrate the\neffectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 12:32:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Zihao", ""], ["Tu", "Enmei", ""], ["Meng", "Zhou", ""]]}, {"id": "2002.09914", "submitter": "Martijn Oldenhof", "authors": "Martijn Oldenhof, Adam Arany, Yves Moreau and Jaak Simm", "title": "ChemGrapher: Optical Graph Recognition of Chemical Compounds by Deep\n  Learning", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": "10.1021/acs.jcim.0c00459", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In drug discovery, knowledge of the graph structure of chemical compounds is\nessential. Many thousands of scientific articles in chemistry and\npharmaceutical sciences have investigated chemical compounds, but in cases the\ndetails of the structure of these chemical compounds is published only as an\nimages. A tool to analyze these images automatically and convert them into a\nchemical graph structure would be useful for many applications, such drug\ndiscovery. A few such tools are available and they are mostly derived from\noptical character recognition. However, our evaluation of the performance of\nthose tools reveals that they make often mistakes in detecting the correct bond\nmultiplicity and stereochemical information. In addition, errors sometimes even\nlead to missing atoms in the resulting graph. In our work, we address these\nissues by developing a compound recognition method based on machine learning.\nMore specifically, we develop a deep neural network model for optical compound\nrecognition. The deep learning solution presented here consists of a\nsegmentation model, followed by three classification models that predict atom\nlocations, bonds and charges. Furthermore, this model not only predicts the\ngraph structure of the molecule but also produces all information necessary to\nrelate each component of the resulting graph to the source image. This solution\nis scalable and could rapidly process thousands of images. Finally, we compare\nempirically the proposed method to a well-established tool and observe\nsignificant error reductions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 14:30:55 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Oldenhof", "Martijn", ""], ["Arany", "Adam", ""], ["Moreau", "Yves", ""], ["Simm", "Jaak", ""]]}, {"id": "2002.09917", "submitter": "Xiangrui Li", "authors": "Xiangrui Li, Deng Pan, Xin Li, Dongxiao Zhu", "title": "Improve SGD Training via Aligning Mini-batches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) for supervised learning can be viewed as a\npipeline of a feature extractor (i.e. last hidden layer) and a linear\nclassifier (i.e. output layer) that is trained jointly with stochastic gradient\ndescent (SGD). In each iteration of SGD, a mini-batch from the training data is\nsampled and the true gradient of the loss function is estimated as the noisy\ngradient calculated on this mini-batch. From the feature learning perspective,\nthe feature extractor should be updated to learn meaningful features with\nrespect to the entire data, and reduce the accommodation to noise in the\nmini-batch. With this motivation, we propose In-Training Distribution Matching\n(ITDM) to improve DNN training and reduce overfitting. Specifically, along with\nthe loss function, ITDM regularizes the feature extractor by matching the\nmoments of distributions of different mini-batches in each iteration of SGD,\nwhich is fulfilled by minimizing the maximum mean discrepancy. As such, ITDM\ndoes not assume any explicit parametric form of data distribution in the latent\nfeature space. Extensive experiments are conducted to demonstrate the\neffectiveness of our proposed strategy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:10:59 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:59:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Xiangrui", ""], ["Pan", "Deng", ""], ["Li", "Xin", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "2002.09927", "submitter": "Setareh Ariafar", "authors": "Setareh Ariafar, Zelda Mariet, Ehsan Elhamifar, Dana Brooks, Jennifer\n  Dy and Jasper Snoek", "title": "Weighting Is Worth the Wait: Bayesian Optimization with Importance\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many contemporary machine learning models require extensive tuning of\nhyperparameters to perform well. A variety of methods, such as Bayesian\noptimization, have been developed to automate and expedite this process.\nHowever, tuning remains extremely costly as it typically requires repeatedly\nfully training models. We propose to accelerate the Bayesian optimization\napproach to hyperparameter tuning for neural networks by taking into account\nthe relative amount of information contributed by each training example. To do\nso, we leverage importance sampling (IS); this significantly increases the\nquality of the black-box function evaluations, but also their runtime, and so\nmust be done carefully. Casting hyperparameter search as a multi-task Bayesian\noptimization problem over both hyperparameters and importance sampling design\nachieves the best of both worlds: by learning a parameterization of IS that\ntrades-off evaluation complexity and quality, we improve upon Bayesian\noptimization state-of-the-art runtime and final validation error across a\nvariety of datasets and complex neural architectures.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:52:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ariafar", "Setareh", ""], ["Mariet", "Zelda", ""], ["Elhamifar", "Ehsan", ""], ["Brooks", "Dana", ""], ["Dy", "Jennifer", ""], ["Snoek", "Jasper", ""]]}, {"id": "2002.09928", "submitter": "Auke Wiggers", "authors": "Auke Wiggers, Emiel Hoogeboom", "title": "Predictive Sampling with Forecasting Autoregressive Models", "comments": "Accepted at the 37th International Conference on Machine Learning\n  (ICML 2020). 14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autoregressive models (ARMs) currently hold state-of-the-art performance in\nlikelihood-based modeling of image and audio data. Generally, neural network\nbased ARMs are designed to allow fast inference, but sampling from these models\nis impractically slow. In this paper, we introduce the predictive sampling\nalgorithm: a procedure that exploits the fast inference property of ARMs in\norder to speed up sampling, while keeping the model intact. We propose two\nvariations of predictive sampling, namely sampling with ARM fixed-point\niteration and learned forecasting modules. Their effectiveness is demonstrated\nin two settings: i) explicit likelihood modeling on binary MNIST, SVHN and\nCIFAR10, and ii) discrete latent modeling in an autoencoder trained on SVHN,\nCIFAR10 and Imagenet32. Empirically, we show considerable improvements over\nbaselines in number of ARM inference calls and sampling speed.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:58:47 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 10:02:57 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wiggers", "Auke", ""], ["Hoogeboom", "Emiel", ""]]}, {"id": "2002.09931", "submitter": "Carlos Sarraute PhD", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Carlos Sarraute, Jan\n  Vanthienen, Bart Baesens", "title": "The Value of Big Data for Credit Scoring: Enhancing Financial Inclusion\n  using Mobile Phone Data and Social Network Analytics", "comments": null, "journal-ref": "Applied Soft Computing, Volume 74, January 2019, Pages 26-39", "doi": "10.1016/j.asoc.2018.10.004", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Credit scoring is without a doubt one of the oldest applications of\nanalytics. In recent years, a multitude of sophisticated classification\ntechniques have been developed to improve the statistical performance of credit\nscoring models. Instead of focusing on the techniques themselves, this paper\nleverages alternative data sources to enhance both statistical and economic\nmodel performance. The study demonstrates how including call networks, in the\ncontext of positive credit information, as a new Big Data source has added\nvalue in terms of profit by applying a profit measure and profit-based feature\nselection. A unique combination of datasets, including call-detail records,\ncredit and debit account information of customers is used to create scorecards\nfor credit card applicants. Call-detail records are used to build call networks\nand advanced social network analytics techniques are applied to propagate\ninfluence from prior defaulters throughout the network to produce influence\nscores. The results show that combining call-detail records with traditional\ndata in credit scoring models significantly increases their performance when\nmeasured in AUC. In terms of profit, the best model is the one built with only\ncalling behavior features. In addition, the calling behavior features are the\nmost predictive in other models, both in terms of statistical and economic\nperformance. The results have an impact in terms of ethical use of call-detail\nrecords, regulatory implications, financial inclusion, as well as data sharing\nand privacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 16:13:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Bravo", "Cristi\u00e1n", ""], ["Sarraute", "Carlos", ""], ["Vanthienen", "Jan", ""], ["Baesens", "Bart", ""]]}, {"id": "2002.09943", "submitter": "Cong Ye", "authors": "Cong Ye, Konstantinos Slavakis, Pratik V. Patil, Johan Nakuci, Sarah\n  F. Muldoon, John Medaglia", "title": "Network Clustering Via Kernel-ARMA Modeling and the Grassmannian The\n  Brain-Network Case", "comments": "arXiv admin note: substantial text overlap with arXiv:1906.02292", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a clustering framework for networks with nodes\nannotated with time-series data. The framework addresses all types of\nnetwork-clustering problems: State clustering, node clustering within states\n(a.k.a. topology identification or community detection), and even\nsubnetwork-state-sequence identification/tracking. Via a bottom-up approach,\nfeatures are first extracted from the raw nodal time-series data by kernel\nautoregressive-moving-average modeling to reveal non-linear dependencies and\nlow-rank representations, and then mapped onto the Grassmann manifold\n(Grassmannian). All clustering tasks are performed by leveraging the underlying\nRiemannian geometry of the Grassmannian in a novel way. To validate the\nproposed framework, brain-network clustering is considered, where extensive\nnumerical tests on synthetic and real functional magnetic resonance imaging\n(fMRI) data demonstrate that the advocated learning framework compares\nfavorably versus several state-of-the-art clustering schemes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 19:48:38 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ye", "Cong", ""], ["Slavakis", "Konstantinos", ""], ["Patil", "Pratik V.", ""], ["Nakuci", "Johan", ""], ["Muldoon", "Sarah F.", ""], ["Medaglia", "John", ""]]}, {"id": "2002.09945", "submitter": "Thomas Lange", "authors": "Thomas Lange, Aneesh Balakrishnan, Maximilien Glorieux, Dan\n  Alexandrescu, Luca Sterpone", "title": "On the Estimation of Complex Circuits Functional Failure Rate by Machine\n  Learning Techniques", "comments": "arXiv admin note: text overlap with arXiv:2002.08882", "journal-ref": null, "doi": "10.1109/DSN-S.2019.00021", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De-Rating or Vulnerability Factors are a major feature of failure analysis\nefforts mandated by today's Functional Safety requirements. Determining the\nFunctional De-Rating of sequential logic cells typically requires\ncomputationally intensive fault-injection simulation campaigns. In this paper a\nnew approach is proposed which uses Machine Learning to estimate the Functional\nDe-Rating of individual flip-flops and thus, optimising and enhancing fault\ninjection efforts. Therefore, first, a set of per-instance features is\ndescribed and extracted through an analysis approach combining static elements\n(cell properties, circuit structure, synthesis attributes) and dynamic elements\n(signal activity). Second, reference data is obtained through first-principles\nfault simulation approaches. Finally, one part of the reference dataset is used\nto train the Machine Learning algorithm and the remaining is used to validate\nand benchmark the accuracy of the trained tool. The intended goal is to obtain\na trained model able to provide accurate per-instance Functional De-Rating data\nfor the full list of circuit instances, an objective that is difficult to reach\nusing classical methods. The presented methodology is accompanied by a\npractical example to determine the performance of various Machine Learning\nmodels for different training sizes.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 15:18:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lange", "Thomas", ""], ["Balakrishnan", "Aneesh", ""], ["Glorieux", "Maximilien", ""], ["Alexandrescu", "Dan", ""], ["Sterpone", "Luca", ""]]}, {"id": "2002.09954", "submitter": "Luigi Carratino", "authors": "Daniele Calandriello, Luigi Carratino, Alessandro Lazaric, Michal\n  Valko, Lorenzo Rosasco", "title": "Near-linear Time Gaussian Process Optimization with Adaptive Batching\n  and Resparsification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GP) are one of the most successful frameworks to model\nuncertainty. However, GP optimization (e.g., GP-UCB) suffers from major\nscalability issues. Experimental time grows linearly with the number of\nevaluations, unless candidates are selected in batches (e.g., using GP-BUCB)\nand evaluated in parallel. Furthermore, computational cost is often prohibitive\nsince algorithms such as GP-BUCB require a time at least quadratic in the\nnumber of dimensions and iterations to select each batch. In this paper, we\nintroduce BBKB (Batch Budgeted Kernel Bandits), the first no-regret GP\noptimization algorithm that provably runs in near-linear time and selects\ncandidates in batches. This is obtained with a new guarantee for the tracking\nof the posterior variances that allows BBKB to choose increasingly larger\nbatches, improving over GP-BUCB. Moreover, we show that the same bound can be\nused to adaptively delay costly updates to the sparse GP approximation used by\nBBKB, achieving a near-constant per-step amortized cost. These findings are\nthen confirmed in several experiments, where BBKB is much faster than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:43:29 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:45:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Calandriello", "Daniele", ""], ["Carratino", "Luigi", ""], ["Lazaric", "Alessandro", ""], ["Valko", "Michal", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "2002.09956", "submitter": "Yingxue Zhou", "authors": "Arindam Banerjee, Tiancong Chen and Yingxue Zhou", "title": "De-randomized PAC-Bayes Margin Bounds: Applications to Non-convex and\n  Non-smooth Predictors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of several notable efforts, explaining the generalization of\ndeterministic non-smooth deep nets, e.g., ReLU-nets, has remained challenging.\nExisting approaches for deterministic non-smooth deep nets typically need to\nbound the Lipschitz constant of such deep nets but such bounds are quite large,\nmay even increase with the training set size yielding vacuous generalization\nbounds. In this paper, we present a new family of de-randomized PAC-Bayes\nmargin bounds for deterministic non-convex and non-smooth predictors, e.g.,\nReLU-nets. Unlike PAC-Bayes, which applies to Bayesian predictors, the\nde-randomized bounds apply to deterministic predictors like ReLU-nets. A\nspecific instantiation of the bound depends on a trade-off between the\n(weighted) distance of the trained weights from the initialization and the\neffective curvature (`flatness') of the trained predictor.\n  To get to these bounds, we first develop a de-randomization argument for\nnon-convex but smooth predictors, e.g., linear deep networks (LDNs), which\nconnects the performance of the deterministic predictor with a Bayesian\npredictor. We then consider non-smooth predictors which for any given input\nrealized as a smooth predictor, e.g., ReLU-nets become some LDNs for any given\ninput, but the realized smooth predictors can be different for different\ninputs. For such non-smooth predictors, we introduce a new PAC-Bayes analysis\nwhich takes advantage of the smoothness of the realized predictors, e.g., LDN,\nfor a given input, and avoids dependency on the Lipschitz constant of the\nnon-smooth predictor. After careful de-randomization, we get a bound for the\ndeterministic non-smooth predictor. We also establish non-uniform sample\ncomplexity results based on such bounds. Finally, we present extensive\nempirical results of our bounds over changing training set size and randomness\nin labels.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:54:07 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 06:56:39 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 01:29:31 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Banerjee", "Arindam", ""], ["Chen", "Tiancong", ""], ["Zhou", "Yingxue", ""]]}, {"id": "2002.09958", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi, Sourjya Roy, Anand Raghunathan, Kaushik Roy", "title": "Gradual Channel Pruning while Training using Feature Relevance Scores\n  for Convolutional Neural Networks", "comments": "15 pages, 2 figures, 4 tables", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3024992", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The enormous inference cost of deep neural networks can be scaled down by\nnetwork compression. Pruning is one of the predominant approaches used for deep\nnetwork compression. However, existing pruning techniques have one or more of\nthe following limitations: 1) Additional energy cost on top of the compute\nheavy training stage due to pruning and fine-tuning stages, 2) Layer-wise\npruning based on the statistics of a particular, ignoring the effect of error\npropagation in the network, 3) Lack of an efficient estimate for determining\nthe important channels globally, 4) Unstructured pruning requires specialized\nhardware for effective use. To address all the above issues, we present a\nsimple-yet-effective gradual channel pruning while training methodology using a\nnovel data-driven metric referred to as feature relevance score. The proposed\ntechnique gets rid of the additional retraining cycles by pruning the least\nimportant channels in a structured fashion at fixed intervals during the actual\ntraining phase. Feature relevance scores help in efficiently evaluating the\ncontribution of each channel towards the discriminative power of the network.\nWe demonstrate the effectiveness of the proposed methodology on architectures\nsuch as VGG and ResNet using datasets such as CIFAR-10, CIFAR-100 and ImageNet,\nand successfully achieve significant model compression while trading off less\nthan $1\\%$ accuracy. Notably on CIFAR-10 dataset trained on ResNet-110, our\napproach achieves $2.4\\times$ compression and a $56\\%$ reduction in FLOPs with\nan accuracy drop of $0.01\\%$ compared to the unpruned network.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:56:18 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:01:47 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Roy", "Sourjya", ""], ["Raghunathan", "Anand", ""], ["Roy", "Kaushik", ""]]}, {"id": "2002.09963", "submitter": "Matthew Almeida", "authors": "Matthew Almeida, Wei Ding, Scott Crouter, Ping Chen", "title": "Mitigating Class Boundary Label Uncertainty to Reduce Both Model Bias\n  and Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study of model bias and variance with respect to decision boundaries is\ncritically important in supervised classification. There is generally a\ntradeoff between the two, as fine-tuning of the decision boundary of a\nclassification model to accommodate more boundary training samples (i.e.,\nhigher model complexity) may improve training accuracy (i.e., lower bias) but\nhurt generalization against unseen data (i.e., higher variance). By focusing on\njust classification boundary fine-tuning and model complexity, it is difficult\nto reduce both bias and variance. To overcome this dilemma, we take a different\nperspective and investigate a new approach to handle inaccuracy and uncertainty\nin the training data labels, which are inevitable in many applications where\nlabels are conceptual and labeling is performed by human annotators. The\nprocess of classification can be undermined by uncertainty in the labels of the\ntraining data; extending a boundary to accommodate an inaccurately labeled\npoint will increase both bias and variance. Our novel method can reduce both\nbias and variance by estimating the pointwise label uncertainty of the training\nset and accordingly adjusting the training sample weights such that those\nsamples with high uncertainty are weighted down and those with low uncertainty\nare weighted up. In this way, uncertain samples have a smaller contribution to\nthe objective function of the model's learning algorithm and exert less pull on\nthe decision boundary. In a real-world physical activity recognition case\nstudy, the data presents many labeling challenges, and we show that this new\napproach improves model performance and reduces model variance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:24:04 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Almeida", "Matthew", ""], ["Ding", "Wei", ""], ["Crouter", "Scott", ""], ["Chen", "Ping", ""]]}, {"id": "2002.09964", "submitter": "Hossein Taheri", "authors": "Hossein Taheri, Aryan Mokhtari, Hamed Hassani, Ramtin Pedarsani", "title": "Quantized Decentralized Stochastic Learning over Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MA cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized stochastic learning problem where data points are\ndistributed among computing nodes communicating over a directed graph. As the\nmodel size gets large, decentralized learning faces a major bottleneck that is\nthe heavy communication load due to each node transmitting large messages\n(model updates) to its neighbors. To tackle this bottleneck, we propose the\nquantized decentralized stochastic learning algorithm over directed graphs that\nis based on the push-sum algorithm in decentralized consensus optimization.\nMore importantly, we prove that our algorithm achieves the same convergence\nrates of the decentralized stochastic learning algorithm with\nexact-communication for both convex and non-convex losses. Numerical\nevaluations corroborate our main theoretical results and illustrate significant\nspeed-up compared to the exact-communication methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:25:39 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 09:12:25 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 07:41:26 GMT"}, {"version": "v4", "created": "Tue, 21 Jul 2020 17:06:54 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 10:02:25 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Taheri", "Hossein", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "2002.09970", "submitter": "Mario Krenn", "authors": "Mario Krenn, Manuel Erhard, Anton Zeilinger", "title": "Computer-inspired Quantum Experiments", "comments": "Comments and suggestions for additional references are welcome!", "journal-ref": "Nature Reviews Physics 2, 649-661 (2020)", "doi": "10.1038/s42254-020-0230-4", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of new devices and experiments in science and engineering has\nhistorically relied on the intuitions of human experts. This credo, however,\nhas changed. In many disciplines, computer-inspired design processes, also\nknown as inverse-design, have augmented the capability of scientists. Here we\nvisit different fields of physics in which computer-inspired designs are\napplied. We will meet vastly diverse computational approaches based on\ntopological optimization, evolutionary strategies, deep learning, reinforcement\nlearning or automated reasoning. Then we draw our attention specifically on\nquantum physics. In the quest for designing new quantum experiments, we face\ntwo challenges: First, quantum phenomena are unintuitive. Second, the number of\npossible configurations of quantum experiments explodes combinatorially. To\novercome these challenges, physicists began to use algorithms for\ncomputer-designed quantum experiments. We focus on the most mature and\n\\textit{practical} approaches that scientists used to find new complex quantum\nexperiments, which experimentalists subsequently have realized in the\nlaboratories. The underlying idea is a highly-efficient topological search,\nwhich allows for scientific interpretability. In that way, some of the\ncomputer-designs have led to the discovery of new scientific concepts and ideas\n-- demonstrating how computer algorithm can genuinely contribute to science by\nproviding unexpected inspirations. We discuss several extensions and\nalternatives based on optimization and machine learning techniques, with the\npotential of accelerating the discovery of practical computer-inspired\nexperiments or concepts in the future. Finally, we discuss what we can learn\nfrom the different approaches in the fields of physics, and raise several\nfascinating possibilities for future research.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:59:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Krenn", "Mario", ""], ["Erhard", "Manuel", ""], ["Zeilinger", "Anton", ""]]}, {"id": "2002.09971", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Peng Liao, Predrag Klasnja, Serena Yeung, Susan Murphy", "title": "Rapidly Personalizing Mobile Health Treatment Policies with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile health (mHealth), reinforcement learning algorithms that adapt to\none's context without learning personalized policies might fail to distinguish\nbetween the needs of individuals. Yet the high amount of noise due to the in\nsitu delivery of mHealth interventions can cripple the ability of an algorithm\nto learn when given access to only a single user's data, making personalization\nchallenging. We present IntelligentPooling, which learns personalized policies\nvia an adaptive, principled use of other users' data. We show that\nIntelligentPooling achieves an average of 26% lower regret than\nstate-of-the-art across all generative models. Additionally, we inspect the\nbehavior of this approach in a live clinical trial, demonstrating its ability\nto learn from even a small group of users.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:59:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tomkins", "Sabina", ""], ["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Yeung", "Serena", ""], ["Murphy", "Susan", ""]]}, {"id": "2002.09996", "submitter": "Janis Klaise", "authors": "Michael Pearce, Janis Klaise, Matthew Groves", "title": "Practical Bayesian Optimization of Objectives with Conditioning\n  Variables", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization is a class of data efficient model based algorithms\ntypically focused on global optimization. We consider the more general case\nwhere a user is faced with multiple problems that each need to be optimized\nconditional on a state variable, for example given a range of cities with\ndifferent patient distributions, we optimize the ambulance locations\nconditioned on patient distribution. Given partitions of CIFAR-10, we optimize\nCNN hyperparameters for each partition. Similarity across objectives boosts\noptimization of each objective in two ways: in modelling by data sharing across\nobjectives, and also in acquisition by quantifying how a single point on one\nobjective can provide benefit to all objectives. For this we propose a\nframework for conditional optimization: ConBO. This can be built on top of a\nrange of acquisition functions and we propose a new Hybrid Knowledge Gradient\nacquisition function. The resulting method is intuitive and theoretically\ngrounded, performs either similar to or significantly better than recently\npublished works on a range of problems, and is easily parallelized to collect a\nbatch of points.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:06:26 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 21:21:40 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Pearce", "Michael", ""], ["Klaise", "Janis", ""], ["Groves", "Matthew", ""]]}, {"id": "2002.09998", "submitter": "Ayman Boustati", "authors": "Ayman Boustati, \\\"Omer Deniz Akyildiz, Theodoros Damoulas, Adam M.\n  Johansen", "title": "Generalized Bayesian Filtering via Sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a framework for inference in general state-space hidden Markov\nmodels (HMMs) under likelihood misspecification. In particular, we leverage the\nloss-theoretic perspective of Generalized Bayesian Inference (GBI) to define\ngeneralised filtering recursions in HMMs, that can tackle the problem of\ninference under model misspecification. In doing so, we arrive at principled\nprocedures for robust inference against observation contamination by utilising\nthe $\\beta$-divergence. Operationalising the proposed framework is made\npossible via sequential Monte Carlo methods (SMC), where most standard particle\nmethods, and their associated convergence results, are readily adapted to the\nnew setting. We apply our approach to object tracking and Gaussian process\nregression problems, and observe improved performance over both standard\nfiltering algorithms and other robust filters.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:15:52 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:05:58 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Boustati", "Ayman", ""], ["Akyildiz", "\u00d6mer Deniz", ""], ["Damoulas", "Theodoros", ""], ["Johansen", "Adam M.", ""]]}, {"id": "2002.10002", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar, Aldo Pacchiano, Yi-an Ma, Peter L. Bartlett, Michael I.\n  Jordan", "title": "On Thompson Sampling with Langevin Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson sampling for multi-armed bandit problems is known to enjoy favorable\nperformance in both theory and practice. However, it suffers from a significant\nlimitation computationally, arising from the need for samples from posterior\ndistributions at every iteration. We propose two Markov Chain Monte Carlo\n(MCMC) methods tailored to Thompson sampling to address this issue. We\nconstruct quickly converging Langevin algorithms to generate approximate\nsamples that have accuracy guarantees, and we leverage novel posterior\nconcentration rates to analyze the regret of the resulting approximate Thompson\nsampling algorithm. Further, we specify the necessary hyperparameters for the\nMCMC procedure to guarantee optimal instance-dependent frequentist regret while\nhaving low computational complexity. In particular, our algorithms take\nadvantage of both posterior concentration and a sample reuse mechanism to\nensure that only a constant number of iterations and a constant amount of data\nis needed in each round. The resulting approximate Thompson sampling algorithm\nhas logarithmic regret and its computational complexity does not scale with the\ntime horizon of the algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:35:29 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 02:02:30 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Mazumdar", "Eric", ""], ["Pacchiano", "Aldo", ""], ["Ma", "Yi-an", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.10003", "submitter": "Maximilian Seitzer", "authors": "Maximilian Seitzer", "title": "NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through\n  Aggregated Convolutional Feature Maps", "comments": "Disentanglement Challenge - 33rd Conference on Neural Information\n  Processing Systems (NeurIPS) - NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report to our stage 1 submission to the NeurIPS 2019 disentanglement\nchallenge presents a simple image preprocessing method for training VAEs\nleading to improved disentanglement compared to directly using the images. In\nparticular, we propose to use regionally aggregated feature maps extracted from\nCNNs pretrained on ImageNet. Our method achieved the 2nd place in stage 1 of\nthe challenge. Code is available at\nhttps://github.com/mseitzer/neurips2019-disentanglement-challenge.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:35:59 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Seitzer", "Maximilian", ""]]}, {"id": "2002.10006", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Lior Wolf", "title": "On the Modularity of Hypernetworks", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of learning to map an input $I$ to a function\n$h_I:\\mathcal{X}\\to \\mathbb{R}$, two alternative methods are compared: (i) an\nembedding-based method, which learns a fixed function in which $I$ is encoded\nas a conditioning signal $e(I)$ and the learned function takes the form $h_I(x)\n= q(x,e(I))$, and (ii) hypernetworks, in which the weights $\\theta_I$ of the\nfunction $h_I(x) = g(x;\\theta_I)$ are given by a hypernetwork $f$ as\n$\\theta_I=f(I)$. In this paper, we define the property of modularity as the\nability to effectively learn a different function for each input instance $I$.\nFor this purpose, we adopt an expressivity perspective of this property and\nextend the theory of Devore et al. 1996 and provide a lower bound on the\ncomplexity (number of trainable parameters) of neural networks as function\napproximators, by eliminating the requirements for the approximation method to\nbe robust. Our results are then used to compare the complexities of $q$ and\n$g$, showing that under certain conditions and when letting the functions $e$\nand $f$ be as large as we wish, $g$ can be smaller than $q$ by orders of\nmagnitude. This sheds light on the modularity of hypernetworks in comparison\nwith the embedding-based method. Besides, we show that for a structured target\nfunction, the overall number of trainable parameters in a hypernetwork is\nsmaller by orders of magnitude than the number of trainable parameters of a\nstandard neural network and an embedding method.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:51:52 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 12:22:00 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Galanti", "Tomer", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.10007", "submitter": "Tomer Galanti", "authors": "Tomer Galanti, Ofir Nabati, Lior Wolf", "title": "A Critical View of the Structural Causal Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the univariate case, we show that by comparing the individual complexities\nof univariate cause and effect, one can identify the cause and the effect,\nwithout considering their interaction at all. In our framework, complexities\nare captured by the reconstruction error of an autoencoder that operates on the\nquantiles of the distribution. Comparing the reconstruction errors of the two\nautoencoders, one for each variable, is shown to perform surprisingly well on\nthe accepted causality directionality benchmarks. Hence, the decision as to\nwhich of the two is the cause and which is the effect may not be based on\ncausality but on complexity.\n  In the multivariate case, where one can ensure that the complexities of the\ncause and effect are balanced, we propose a new adversarial training method\nthat mimics the disentangled structure of the causal model. We prove that in\nthe multidimensional case, such modeling is likely to fit the data only in the\ndirection of causality. Furthermore, a uniqueness result shows that the learned\nmodel is able to identify the underlying causal and residual (noise)\ncomponents. Our multidimensional method outperforms the literature methods on\nboth synthetic and real world datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:52:28 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Galanti", "Tomer", ""], ["Nabati", "Ofir", ""], ["Wolf", "Lior", ""]]}, {"id": "2002.10016", "submitter": "Hadi Abdi Khojasteh", "authors": "Hadi Abdi Khojasteh (1), Ebrahim Ansari (1 and 2), Parvin Razzaghi (1\n  and 3), Akbar Karimi (4) ((1) Institute for Advanced Studies in Basic\n  Sciences (IASBS), Zanjan, Iran, (2) Faculty of Mathematics and Physics,\n  Institute of Formal and Applied Linguistics, Charles University, Czechia, (3)\n  Institute for Research in Fundamental Sciences (IPM), Tehran, Iran, (4) IMP\n  Lab, Department of Engineering and Architecture, University of Parma, Parma,\n  Italy)", "title": "Deep Multimodal Image-Text Embeddings for Automatic Cross-Media\n  Retrieval", "comments": "6 pages and 2 figures, Learn more about this project at\n  https://iasbs.ac.ir/~ansari/deeptwitter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the task of matching images and sentences by learning a\nvisual-textual embedding space for cross-modal retrieval. Finding such a space\nis a challenging task since the features and representations of text and image\nare not comparable. In this work, we introduce an end-to-end deep multimodal\nconvolutional-recurrent network for learning both vision and language\nrepresentations simultaneously to infer image-text similarity. The model learns\nwhich pairs are a match (positive) and which ones are a mismatch (negative)\nusing a hinge-based triplet ranking. To learn about the joint representations,\nwe leverage our newly extracted collection of tweets from Twitter. The main\ncharacteristic of our dataset is that the images and tweets are not\nstandardized the same as the benchmarks. Furthermore, there can be a higher\nsemantic correlation between the pictures and tweets contrary to benchmarks in\nwhich the descriptions are well-organized. Experimental results on MS-COCO\nbenchmark dataset show that our model outperforms certain methods presented\npreviously and has competitive performance compared to the state-of-the-art.\nThe code and dataset have been made available publicly.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 23:58:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Khojasteh", "Hadi Abdi", "", "1 and 2"], ["Ansari", "Ebrahim", "", "1 and 2"], ["Razzaghi", "Parvin", "", "1\n  and 3"], ["Karimi", "Akbar", ""]]}, {"id": "2002.10021", "submitter": "Jacob Tyo", "authors": "Jacob Tyo and Zachary Lipton", "title": "How Transferable are the Representations Learned by Deep Q Agents?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we consider the source of Deep Reinforcement Learning (DRL)'s\nsample complexity, asking how much derives from the requirement of learning\nuseful representations of environment states and how much is due to the sample\ncomplexity of learning a policy. While for DRL agents, the distinction between\nrepresentation and policy may not be clear, we seek new insight through a set\nof transfer learning experiments. In each experiment, we retain some fraction\nof layers trained on either the same game or a related game, comparing the\nbenefits of transfer learning to learning a policy from scratch. Interestingly,\nwe find that benefits due to transfer are highly variable in general and\nnon-symmetric across pairs of tasks. Our experiments suggest that perhaps\ntransfer from simpler environments can boost performance on more complex\ndownstream tasks and that the requirements of learning a useful representation\ncan range from negligible to the majority of the sample complexity, based on\nthe environment. Furthermore, we find that fine-tuning generally outperforms\ntraining with the transferred layers frozen, confirming an insight first noted\nin the classification setting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 00:23:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tyo", "Jacob", ""], ["Lipton", "Zachary", ""]]}, {"id": "2002.10022", "submitter": "Amir Mosavi Prof", "authors": "Shahab Shamshirband, Amir Mosavi, Narjes Nabipour, Kwok-wing Chau", "title": "Application of ERA5 and MENA simulations to predict offshore wind energy\n  potential", "comments": "21 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study explores wind energy resources in different locations through the\nGulf of Oman and also their future variability due climate change impacts. In\nthis regard, EC-EARTH near surface wind outputs obtained from CORDEX-MENA\nsimulations are used for historical and future projection of the energy. The\nERA5 wind data are employed to assess suitability of the climate model.\nMoreover, the ERA5 wave data over the study area are applied to compute sea\nsurface roughness as an important variable for converting near surface wind\nspeeds to those of wind speed at turbine hub-height. Considering the power\ndistribution, bathymetry and distance from the coats, some spots as tentative\nenergy hotspots to provide detailed assessment of directional and temporal\nvariability and also to investigate climate change impact studies. RCP8.5 as a\ncommon climatic scenario is used to project and extract future variation of the\nenergy in the selected sites. The results of this study demonstrate that the\nselected locations have a suitable potential for wind power turbine plan and\nconstructions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 00:25:29 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Shamshirband", "Shahab", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Chau", "Kwok-wing", ""]]}, {"id": "2002.10025", "submitter": "Ting-Kueu Hu", "authors": "Ting-Kuei Hu, Tianlong Chen, Haotao Wang, Zhangyang Wang", "title": "Triple Wins: Boosting Accuracy, Robustness and Efficiency Together by\n  Enabling Input-Adaptive Inference", "comments": "Published on ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks were recently suggested to face the odds between accuracy (on\nclean natural images) and robustness (on adversarially perturbed images)\n(Tsipras et al., 2019). Such a dilemma is shown to be rooted in the inherently\nhigher sample complexity (Schmidt et al., 2018) and/or model capacity\n(Nakkiran, 2019), for learning a high-accuracy and robust classifier. In view\nof that, give a classification task, growing the model capacity appears to help\ndraw a win-win between accuracy and robustness, yet at the expense of model\nsize and latency, therefore posing challenges for resource-constrained\napplications. Is it possible to co-design model accuracy, robustness and\nefficiency to achieve their triple wins? This paper studies multi-exit networks\nassociated with input-adaptive efficient inference, showing their strong\npromise in achieving a \"sweet point\" in cooptimizing model accuracy, robustness\nand efficiency. Our proposed solution, dubbed Robust Dynamic Inference Networks\n(RDI-Nets), allows for each input (either clean or adversarial) to adaptively\nchoose one of the multiple output layers (early branches or the final one) to\noutput its prediction. That multi-loss adaptivity adds new variations and\nflexibility to adversarial attacks and defenses, on which we present a\nsystematical investigation. We show experimentally that by equipping existing\nbackbones with such robust adaptive inference, the resulting RDI-Nets can\nachieve better accuracy and robustness, yet with over 30% computational\nsavings, compared to the defended original models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 00:40:22 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 03:27:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hu", "Ting-Kuei", ""], ["Chen", "Tianlong", ""], ["Wang", "Haotao", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2002.10032", "submitter": "Mohammad Akbari", "authors": "Mohammad Akbari and Jie Liang and Jingning Han and Chengjie Tu", "title": "Generalized Octave Convolutions for Learned Multi-Frequency Image\n  Compression", "comments": "13 pages, 10 figures, 5 tables; Extended version of the paper\n  accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learned image compression has recently shown the potential to outperform the\nstandard codecs. State-of-the-art rate-distortion (R-D) performance has been\nachieved by context-adaptive entropy coding approaches in which hyperprior and\nautoregressive models are jointly utilized to effectively capture the spatial\ndependencies in the latent representations. However, the latents are feature\nmaps of the same spatial resolution in previous works, which contain some\nredundancies that affect the R-D performance. In this paper, we propose the\nfirst learned multi-frequency image compression and entropy coding approach\nthat is based on the recently developed octave convolutions to factorize the\nlatents into high and low frequency (resolution) components, where the low\nfrequency is represented by a lower resolution. Therefore, its spatial\nredundancy is reduced, which improves the R-D performance. Novel generalized\noctave convolution and octave transposed-convolution architectures with\ninternal activation layers are also proposed to preserve more spatial structure\nof the information. Experimental results show that the proposed scheme not only\noutperforms all existing learned methods as well as standard codecs such as the\nnext-generation video coding standard VVC (4:2:0) on the Kodak dataset in both\nPSNR and MS-SSIM. We also show that the proposed generalized octave convolution\ncan improve the performance of other auto-encoder-based computer vision tasks\nsuch as semantic segmentation and image denoising.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 01:35:29 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 18:22:26 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 06:34:00 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Akbari", "Mohammad", ""], ["Liang", "Jie", ""], ["Han", "Jingning", ""], ["Tu", "Chengjie", ""]]}, {"id": "2002.10034", "submitter": "Sema Candemir", "authors": "Sema Candemir, Xuan V. Nguyen, Luciano M. Prevedello, Matthew T.\n  Bigelow, Richard D.White, Barbaros S. Erdal (for the Alzheimer's Disease\n  Neuroimaging Initiative)", "title": "Predicting Rate of Cognitive Decline at Baseline Using a Deep Neural\n  Network with Multidata Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: This study investigates whether a machine-learning-based system can\npredict the rate of cognitive decline in mildly cognitively impaired patients\nby processing only the clinical and imaging data collected at the initial\nvisit.\n  Approach: We built a predictive model based on a supervised hybrid neural\nnetwork utilizing a 3-Dimensional Convolutional Neural Network to perform\nvolume analysis of Magnetic Resonance Imaging and integration of non-imaging\nclinical data at the fully connected layer of the architecture. The experiments\nare conducted on the Alzheimers Disease Neuroimaging Initiative dataset.\n  Results: Experimental results confirm that there is a correlation between\ncognitive decline and the data obtained at the first visit. The system achieved\nan area under the receiver operator curve (AUC) of 0.70 for cognitive decline\nclass prediction.\n  Conclusion: To our knowledge, this is the first study that predicts slowly\ndeteriorating/stable or rapidly deteriorating classes by processing routinely\ncollected baseline clinical and demographic data (Baseline MRI, Baseline MMSE,\nScalar Volumetric data, Age, Gender, Education, Ethnicity, and Race). The\ntraining data is built based on MMSE-rate values. Unlike the studies in the\nliterature that focus on predicting Mild Cognitive Impairment-to-Alzheimer`s\ndisease conversion and disease classification, we approach the problem as an\nearly prediction of cognitive decline rate in MCI patients.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 01:39:17 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 05:40:42 GMT"}, {"version": "v3", "created": "Mon, 5 Oct 2020 23:14:23 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Candemir", "Sema", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Nguyen", "Xuan V.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Prevedello", "Luciano M.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Bigelow", "Matthew T.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["White", "Richard D.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Erdal", "Barbaros S.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"]]}, {"id": "2002.10043", "submitter": "Yifei Shen", "authors": "Yifei Shen, Ye Xue, Jun Zhang, Khaled B. Letaief, and Vincent Lau", "title": "Complete Dictionary Learning via $\\ell_p$-norm Maximization", "comments": "accepted by UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is a classic representation learning method that has been\nwidely applied in signal processing and data analytics. In this paper, we\ninvestigate a family of $\\ell_p$-norm ($p>2,p \\in \\mathbb{N}$) maximization\napproaches for the complete dictionary learning problem from theoretical and\nalgorithmic aspects. Specifically, we prove that the global maximizers of these\nformulations are very close to the true dictionary with high probability, even\nwhen Gaussian noise is present. Based on the generalized power method (GPM), an\nefficient algorithm is then developed for the $\\ell_p$-based formulations. We\nfurther show the efficacy of the developed algorithm: for the population GPM\nalgorithm over the sphere constraint, it first quickly enters the neighborhood\nof a global maximizer, and then converges linearly in this region. Extensive\nexperiments will demonstrate that the $\\ell_p$-based approaches enjoy a higher\ncomputational efficiency and better robustness than conventional approaches and\n$p=3$ performs the best.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 02:33:01 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 13:07:36 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 11:58:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shen", "Yifei", ""], ["Xue", "Ye", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""], ["Lau", "Vincent", ""]]}, {"id": "2002.10060", "submitter": "Wu Lin", "authors": "Wu Lin, Mark Schmidt, Mohammad Emtiyaz Khan", "title": "Handling the Positive-Definite Constraint in the Bayesian Learning Rule", "comments": "Fixed typos and updated the abstract (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bayesian learning rule is a natural-gradient variational inference\nmethod, which not only contains many existing learning algorithms as special\ncases but also enables the design of new algorithms. Unfortunately, when\nvariational parameters lie in an open constraint set, the rule may not satisfy\nthe constraint and requires line-searches which could slow down the algorithm.\nIn this work, we address this issue for positive-definite constraints by\nproposing an improved rule that naturally handles the constraints. Our\nmodification is obtained by using Riemannian gradient methods, and is valid\nwhen the approximation attains a \\emph{block-coordinate natural\nparameterization} (e.g., Gaussian distributions and their mixtures). We propose\na principled way to derive Riemannian gradients and retractions from scratch.\nOur method outperforms existing methods without any significant increase in\ncomputation. Our work makes it easier to apply the rule in the presence of\npositive-definite constraints in parameter spaces.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:29:39 GMT"}, {"version": "v10", "created": "Thu, 23 Jul 2020 16:19:52 GMT"}, {"version": "v11", "created": "Mon, 17 Aug 2020 15:52:27 GMT"}, {"version": "v12", "created": "Fri, 4 Sep 2020 05:37:10 GMT"}, {"version": "v13", "created": "Sun, 25 Oct 2020 04:28:55 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 09:13:54 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 10:19:13 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 19:44:16 GMT"}, {"version": "v5", "created": "Mon, 11 May 2020 15:43:05 GMT"}, {"version": "v6", "created": "Mon, 8 Jun 2020 04:35:11 GMT"}, {"version": "v7", "created": "Tue, 30 Jun 2020 06:59:14 GMT"}, {"version": "v8", "created": "Thu, 2 Jul 2020 11:16:36 GMT"}, {"version": "v9", "created": "Tue, 21 Jul 2020 16:01:35 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lin", "Wu", ""], ["Schmidt", "Mark", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2002.10061", "submitter": "Wensi Tang", "authors": "Wensi Tang, Guodong Long, Lu Liu, Tianyi Zhou, Jing Jiang, Michael\n  Blumenstein", "title": "Rethinking 1D-CNN for Time Series Classification: A Stronger Baseline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For time series classification task using 1D-CNN, the selection of kernel\nsize is critically important to ensure the model can capture the right scale\nsalient signal from a long time-series. Most of the existing work on 1D-CNN\ntreats the kernel size as a hyper-parameter and tries to find the proper kernel\nsize through a grid search which is time-consuming and is inefficient. This\npaper theoretically analyses how kernel size impacts the performance of 1D-CNN.\nConsidering the importance of kernel size, we propose a novel Omni-Scale 1D-CNN\n(OS-CNN) architecture to capture the proper kernel size during the model\nlearning period. A specific design for kernel size configuration is developed\nwhich enables us to assemble very few kernel-size options to represent more\nreceptive fields. The proposed OS-CNN method is evaluated using the UCR archive\nwith 85 datasets. The experiment results demonstrate that our method is a\nstronger baseline in multiple performance indicators, including the critical\ndifference diagram, counts of wins, and average accuracy. We also published the\nexperimental source codes at GitHub (https://github.com/Wensi-Tang/OS-CNN/).\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:33:58 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 00:28:30 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Tang", "Wensi", ""], ["Long", "Guodong", ""], ["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Jiang", "Jing", ""], ["Blumenstein", "Michael", ""]]}, {"id": "2002.10064", "submitter": "Abhronil Sengupta", "authors": "Sen Lu, Abhronil Sengupta", "title": "Exploring the Connection Between Binary and Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2020.00535", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-chip edge intelligence has necessitated the exploration of algorithmic\ntechniques to reduce the compute requirements of current machine learning\nframeworks. This work aims to bridge the recent algorithmic progress in\ntraining Binary Neural Networks and Spiking Neural Networks - both of which are\ndriven by the same motivation and yet synergies between the two have not been\nfully explored. We show that training Spiking Neural Networks in the extreme\nquantization regime results in near full precision accuracies on large-scale\ndatasets like CIFAR-$100$ and ImageNet. An important implication of this work\nis that Binary Spiking Neural Networks can be enabled by \"In-Memory\" hardware\naccelerators catered for Binary Neural Networks without suffering any accuracy\ndegradation due to binarization. We utilize standard training techniques for\nnon-spiking networks to generate our spiking networks by conversion process and\nalso perform an extensive empirical analysis and explore simple design-time and\nrun-time optimization techniques for reducing inference latency of spiking\nnetworks (both for binary and full-precision models) by an order of magnitude\nover prior work.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:46:51 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 19:49:59 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 21:53:42 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Lu", "Sen", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "2002.10066", "submitter": "Yonadav Shavit", "authors": "Yonadav Shavit, Benjamin Edelman, Brian Axelrod", "title": "Causal Strategic Linear Regression", "comments": "18 pages; to appear in the proceedings of ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many predictive decision-making scenarios, such as credit scoring and\nacademic testing, a decision-maker must construct a model that accounts for\nagents' propensity to \"game\" the decision rule by changing their features so as\nto receive better decisions. Whereas the strategic classification literature\nhas previously assumed that agents' outcomes are not causally affected by their\nfeatures (and thus that strategic agents' goal is deceiving the\ndecision-maker), we join concurrent work in modeling agents' outcomes as a\nfunction of their changeable attributes. As our main contribution, we provide\nefficient algorithms for learning decision rules that optimize three distinct\ndecision-maker objectives in a realizable linear setting: accurately predicting\nagents' post-gaming outcomes (prediction risk minimization), incentivizing\nagents to improve these outcomes (agent outcome maximization), and estimating\nthe coefficients of the true underlying model (parameter estimation). Our\nalgorithms circumvent a hardness result of Miller et al. (2020) by allowing the\ndecision maker to test a sequence of decision rules and observe agents'\nresponses, in effect performing causal interventions through the decision\nrules.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 03:57:22 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 22:24:19 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Shavit", "Yonadav", ""], ["Edelman", "Benjamin", ""], ["Axelrod", "Brian", ""]]}, {"id": "2002.10069", "submitter": "Benjamin Gravell", "authors": "Benjamin Gravell and Tyler Summers", "title": "Robust Learning-Based Control via Bootstrapped Multiplicative Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite decades of research and recent progress in adaptive control and\nreinforcement learning, there remains a fundamental lack of understanding in\ndesigning controllers that provide robustness to inherent non-asymptotic\nuncertainties arising from models estimated with finite, noisy data. We propose\na robust adaptive control algorithm that explicitly incorporates such\nnon-asymptotic uncertainties into the control design. The algorithm has three\ncomponents: (1) a least-squares nominal model estimator; (2) a bootstrap\nresampling method that quantifies non-asymptotic variance of the nominal model\nestimate; and (3) a non-conventional robust control design method using an\noptimal linear quadratic regulator (LQR) with multiplicative noise. A key\nadvantage of the proposed approach is that the system identification and robust\ncontrol design procedures both use stochastic uncertainty representations, so\nthat the actual inherent statistical estimation uncertainty directly aligns\nwith the uncertainty the robust controller is being designed against. We show\nthrough numerical experiments that the proposed robust adaptive controller can\nsignificantly outperform the certainty equivalent controller on both expected\nregret and measures of regret risk.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 04:12:52 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 19:26:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Gravell", "Benjamin", ""], ["Summers", "Tyler", ""]]}, {"id": "2002.10072", "submitter": "Chongwen Huang", "authors": "Chongwen Huang, Member, IEEE, Ronghong Mo and Chau Yuen, Senior Member", "title": "Reconfigurable Intelligent Surface Assisted Multiuser MISO Systems\n  Exploiting Deep Reinforcement Learning", "comments": "12 pages. Accepted by IEEE JSAC special issue on Multiple Antenna\n  Technologies for Beyond 5G", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the reconfigurable intelligent surface (RIS), benefited from the\nbreakthrough on the fabrication of programmable meta-material, has been\nspeculated as one of the key enabling technologies for the future six\ngeneration (6G) wireless communication systems scaled up beyond massive\nmultiple input multiple output (Massive-MIMO) technology to achieve smart radio\nenvironments. Employed as reflecting arrays, RIS is able to assist MIMO\ntransmissions without the need of radio frequency chains resulting in\nconsiderable reduction in power consumption. In this paper, we investigate the\njoint design of transmit beamforming matrix at the base station and the phase\nshift matrix at the RIS, by leveraging recent advances in deep reinforcement\nlearning (DRL). We first develop a DRL based algorithm, in which the joint\ndesign is obtained through trial-and-error interactions with the environment by\nobserving predefined rewards, in the context of continuous state and action.\nUnlike the most reported works utilizing the alternating optimization\ntechniques to alternatively obtain the transmit beamforming and phase shifts,\nthe proposed DRL based algorithm obtains the joint design simultaneously as the\noutput of the DRL neural network. Simulation results show that the proposed\nalgorithm is not only able to learn from the environment and gradually improve\nits behavior, but also obtains the comparable performance compared with two\nstate-of-the-art benchmarks. It is also observed that, appropriate neural\nnetwork parameter settings will improve significantly the performance and\nconvergence rate of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 04:28:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Huang", "Chongwen", ""], ["Member", "", ""], ["IEEE", "", ""], ["Mo", "Ronghong", ""], ["Yuen", "Chau", ""], ["Member", "Senior", ""]]}, {"id": "2002.10077", "submitter": "Zachary Izzo", "authors": "Zachary Izzo, Mary Anne Smart, Kamalika Chaudhuri, James Zou", "title": "Approximate Data Deletion from Machine Learning Models", "comments": "20 pages, 1 figure, accepted for publication at AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deleting data from a trained machine learning (ML) model is a critical task\nin many applications. For example, we may want to remove the influence of\ntraining points that might be out of date or outliers. Regulations such as EU's\nGeneral Data Protection Regulation also stipulate that individuals can request\nto have their data deleted. The naive approach to data deletion is to retrain\nthe ML model on the remaining data, but this is too time consuming. In this\nwork, we propose a new approximate deletion method for linear and logistic\nmodels whose computational cost is linear in the the feature dimension $d$ and\nindependent of the number of training data $n$. This is a significant gain over\nall existing methods, which all have superlinear time dependence on the\ndimension. We also develop a new feature-injection test to evaluate the\nthoroughness of data deletion from ML models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:12:03 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 18:56:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Izzo", "Zachary", ""], ["Smart", "Mary Anne", ""], ["Chaudhuri", "Kamalika", ""], ["Zou", "James", ""]]}, {"id": "2002.10078", "submitter": "Chuan Guo", "authors": "Chuan Guo, Ruihan Wu, Kilian Q. Weinberger", "title": "On Hiding Neural Networks Inside Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern neural networks often contain significantly more parameters than the\nsize of their training data. We show that this excess capacity provides an\nopportunity for embedding secret machine learning models within a trained\nneural network. Our novel framework hides the existence of a secret neural\nnetwork with arbitrary desired functionality within a carrier network. We prove\ntheoretically that the secret network's detection is computationally infeasible\nand demonstrate empirically that the carrier network does not compromise the\nsecret network's disguise. Our paper introduces a previously unknown\nsteganographic technique that can be exploited by adversaries if left\nunchecked.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:18:29 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:27:10 GMT"}, {"version": "v3", "created": "Sat, 22 May 2021 00:27:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Guo", "Chuan", ""], ["Wu", "Ruihan", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.10080", "submitter": "Xiangyu Yang", "authors": "Xiangyu Yang, Sheng Hua, Yuanming Shi, Hao Wang, Jun Zhang, Khaled B.\n  Letaief", "title": "Sparse Optimization for Green Edge AI Inference", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid upsurge of deep learning tasks at the network edge, effective\nedge artificial intelligence (AI) inference becomes critical to provide\nlow-latency intelligent services for mobile users via leveraging the edge\ncomputing capability. In such scenarios, energy efficiency becomes a primary\nconcern. In this paper, we present a joint inference task selection and\ndownlink beamforming strategy to achieve energy-efficient edge AI inference\nthrough minimizing the overall power consumption consisting of both computation\nand transmission power consumption, yielding a mixed combinatorial optimization\nproblem. By exploiting the inherent connections between the set of task\nselection and group sparsity structural transmit beamforming vector, we\nreformulate the optimization as a group sparse beamforming problem. To solve\nthis challenging problem, we propose a log-sum function based three-stage\napproach. By adopting the log-sum function to enhance the group sparsity, a\nproximal iteratively reweighted algorithm is developed. Furthermore, we\nestablish the global convergence analysis and provide the ergodic worst-case\nconvergence rate for this algorithm. Simulation results will demonstrate the\neffectiveness of the proposed approach for improving energy efficiency in edge\nAI inference systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:21:58 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 13:11:12 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yang", "Xiangyu", ""], ["Hua", "Sheng", ""], ["Shi", "Yuanming", ""], ["Wang", "Hao", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled B.", ""]]}, {"id": "2002.10084", "submitter": "Matthew Roos", "authors": "Matthew J. Roos", "title": "Utilizing a null class to restrict decision spaces and defend against\n  neural network adversarial attacks", "comments": "15 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress, deep neural networks generally continue to be\nvulnerable to so-called adversarial examples--input images with small\nperturbations that can result in changes in the output classifications, despite\nno such change in the semantic meaning to human viewers. This is true even for\nseemingly simple challenges such as the MNIST digit classification task. In\npart, this suggests that these networks are not relying on the same set of\nobject features as humans use to make these classifications. In this paper we\nexamine an additional, and largely unexplored, cause behind this\nphenomenon--namely, the use of the conventional training paradigm in which the\nentire input space is parcellated among the training classes. Owing to this\nparadigm, learned decision spaces for individual classes span excessively large\nregions of the input space and include images that have no semantic similarity\nto images in the training set. In this study, we train models that include a\nnull class. That is, models may \"opt-out\" of classifying an input image as one\nof the digit classes. During training, null images are created through a\nvariety of methods, in an attempt to create tighter and more semantically\nmeaningful decision spaces for the digit classes. The best performing models\nclassify nearly all adversarial examples as nulls, rather than mistaking them\nas a member of an incorrect digit class, while simultaneously maintaining high\naccuracy on the unperturbed test set. The use of a null class and the training\nparadigm presented herein may provide an effective defense against adversarial\nattacks for some applications. Code for replicating this study will be made\navailable at https://github.com/mattroos/null_class_adversarial_defense .\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:47:08 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Roos", "Matthew J.", ""]]}, {"id": "2002.10085", "submitter": "Wenrui Zhang", "authors": "Wenrui Zhang, Peng Li", "title": "Temporal Spike Sequence Learning via Backpropagation for Deep Spiking\n  Neural Networks", "comments": "Accepted for spotlight presentation of NeurIPS (Neural Information\n  Processing System) 2020:\n  https://proceedings.neurips.cc/paper/2020/hash/8bdb5058376143fa358981954e7626b8-Abstract.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are well suited for spatio-temporal learning\nand implementations on energy-efficient event-driven neuromorphic processors.\nHowever, existing SNN error backpropagation (BP) methods lack proper handling\nof spiking discontinuities and suffer from low performance compared with the BP\nmethods for traditional artificial neural networks. In addition, a large number\nof time steps are typically required to achieve decent performance, leading to\nhigh latency and rendering spike-based computation unscalable to deep\narchitectures. We present a novel Temporal Spike Sequence Learning\nBackpropagation (TSSL-BP) method for training deep SNNs, which breaks down\nerror backpropagation across two types of inter-neuron and intra-neuron\ndependencies and leads to improved temporal learning precision. It captures\ninter-neuron dependencies through presynaptic firing times by considering the\nall-or-none characteristics of firing activities and captures intra-neuron\ndependencies by handling the internal evolution of each neuronal state in time.\nTSSL-BP efficiently trains deep SNNs within a much shortened temporal window of\na few steps while improving the accuracy for various image classification\ndatasets including CIFAR10.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 05:49:37 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 07:41:13 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 21:42:18 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 06:24:25 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "2002.10097", "submitter": "Leo Schwinn", "authors": "Leo Schwinn, Ren\\'e Raab, Bj\\\"orn Eskofier", "title": "Towards Rapid and Robust Adversarial Training with One-Step Attacks", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is the most successful empirical method for increasing\nthe robustness of neural networks against adversarial attacks. However, the\nmost effective approaches, like training with Projected Gradient Descent (PGD)\nare accompanied by high computational complexity. In this paper, we present two\nideas that, in combination, enable adversarial training with the\ncomputationally less expensive Fast Gradient Sign Method (FGSM). First, we add\nuniform noise to the initial data point of the FGSM attack, which creates a\nwider variety of adversaries, thus prohibiting overfitting to one particular\nperturbation bound. Further, we add a learnable regularization step prior to\nthe neural network, which we call Pixelwise Noise Injection Layer (PNIL).\nInputs propagated trough the PNIL are resampled from a learned Gaussian\ndistribution. The regularization induced by the PNIL prevents the model form\nlearning to obfuscate its gradients, a factor that hindered prior approaches\nfrom successfully applying one-step methods for adversarial training. We show\nthat noise injection in conjunction with FGSM-based adversarial training\nachieves comparable results to adversarial training with PGD while being\nconsiderably faster. Moreover, we outperform PGD-based adversarial training by\ncombining noise injection and PNIL.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:28:43 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 14:32:31 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 06:41:20 GMT"}, {"version": "v4", "created": "Tue, 17 Mar 2020 07:52:57 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Schwinn", "Leo", ""], ["Raab", "Ren\u00e9", ""], ["Eskofier", "Bj\u00f6rn", ""]]}, {"id": "2002.10099", "submitter": "Amos Gropp", "authors": "Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, Yaron Lipman", "title": "Implicit Geometric Regularization for Learning Shapes", "comments": "37th International Conference on Machine Learning, Vienna, Austria,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing shapes as level sets of neural networks has been recently proved\nto be useful for different shape analysis and reconstruction tasks. So far,\nsuch representations were computed using either: (i) pre-computed implicit\nshape representations; or (ii) loss functions explicitly defined over the\nneural level sets. In this paper we offer a new paradigm for computing high\nfidelity implicit neural representations directly from raw data (i.e., point\nclouds, with or without normal information). We observe that a rather simple\nloss function, encouraging the neural network to vanish on the input point\ncloud and to have a unit norm gradient, possesses an implicit geometric\nregularization property that favors smooth and natural zero level set surfaces,\navoiding bad zero-loss solutions. We provide a theoretical analysis of this\nproperty for the linear case, and show that, in practice, our method leads to\nstate of the art implicit neural representations with higher level-of-details\nand fidelity compared to previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:36:32 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 12:32:45 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gropp", "Amos", ""], ["Yariv", "Lior", ""], ["Haim", "Niv", ""], ["Atzmon", "Matan", ""], ["Lipman", "Yaron", ""]]}, {"id": "2002.10105", "submitter": "Qiang Wang", "authors": "Qiang Wang, Shaohuai Shi, Canhui Wang, Xiaowen Chu", "title": "Communication Contention Aware Scheduling of Multiple Deep Learning\n  Training Jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Deep Learning (DDL) has rapidly grown its popularity since it\nhelps boost the training performance on high-performance GPU clusters.\nEfficient job scheduling is indispensable to maximize the overall performance\nof the cluster when training multiple jobs simultaneously. However, existing\nschedulers do not consider the communication contention of multiple\ncommunication tasks from different distributed training jobs, which could\ndeteriorate the system performance and prolong the job completion time. In this\npaper, we first establish a new DDL job scheduling framework which organizes\nDDL jobs as Directed Acyclic Graphs (DAGs) and considers communication\ncontention between nodes. We then propose an efficient algorithm, LWF-$\\kappa$,\nto balance the GPU utilization and consolidate the allocated GPUs for each job.\nWhen scheduling those communication tasks, we observe that neither avoiding all\nthe contention nor blindly accepting them is optimal to minimize the job\ncompletion time. We thus propose a provable algorithm, AdaDUAL, to efficiently\nschedule those communication tasks. Based on AdaDUAL, we finally propose\nAda-SRSF for the DDL job scheduling problem. Simulations on a 64-GPU cluster\nconnected with 10 Gbps Ethernet show that LWF-$\\kappa$ achieves up to\n$1.59\\times$ improvement over the classical first-fit algorithms. More\nimportantly, Ada-SRSF reduces the average job completion time by $20.1\\%$ and\n$36.7\\%$, as compared to the SRSF(1) scheme (avoiding all the contention) and\nthe SRSF(2) scheme (blindly accepting all of two-way communication contention)\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:50:56 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Wang", "Qiang", ""], ["Shi", "Shaohuai", ""], ["Wang", "Canhui", ""], ["Chu", "Xiaowen", ""]]}, {"id": "2002.10107", "submitter": "Issa Annamoradnejad", "authors": "Issa Annamoradnejad, Mohammadamin Fazli, Jafar Habibi", "title": "Predicting Subjective Features of Questions of QA Websites using BERT", "comments": "5 pages, 4 figures, 2 tables", "journal-ref": "2020 6th International Conference on Web Research (ICWR), Tehran,\n  Iran, 2020, pp. 240-244", "doi": "10.1109/ICWR49608.2020.9122318", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question-Answering websites, such as StackOverflow and Quora,\nexpect users to follow specific guidelines in order to maintain content\nquality. These systems mainly rely on community reports for assessing contents,\nwhich has serious problems such as the slow handling of violations, the loss of\nnormal and experienced users' time, the low quality of some reports, and\ndiscouraging feedback to new users. Therefore, with the overall goal of\nproviding solutions for automating moderation actions in Q&A websites, we aim\nto provide a model to predict 20 quality or subjective aspects of questions in\nQA websites. To this end, we used data gathered by the CrowdSource team at\nGoogle Research in 2019 and a fine-tuned pre-trained BERT model on our problem.\nBased on the evaluation by Mean-Squared-Error (MSE), the model achieved a value\nof 0.046 after 2 epochs of training, which did not improve substantially in the\nnext ones. Results confirm that by simple fine-tuning, we can achieve accurate\nmodels in little time and on less amount of data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:56:02 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 08:10:16 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 13:22:04 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 14:37:39 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Annamoradnejad", "Issa", ""], ["Fazli", "Mohammadamin", ""], ["Habibi", "Jafar", ""]]}, {"id": "2002.10110", "submitter": "Huan Li", "authors": "Huan Li and Zhouchen Lin", "title": "Revisiting EXTRA for Smooth Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EXTRA is a popular method for dencentralized distributed optimization and has\nbroad applications. This paper revisits EXTRA. First, we give a sharp\ncomplexity analysis for EXTRA with the improved\n$O\\left(\\left(\\frac{L}{\\mu}+\\frac{1}{1-\\sigma_2(W)}\\right)\\log\\frac{1}{\\epsilon(1-\\sigma_2(W))}\\right)$\ncommunication and computation complexities for $\\mu$-strongly convex and\n$L$-smooth problems, where $\\sigma_2(W)$ is the second largest singular value\nof the weight matrix $W$. When the strong convexity is absent, we prove the\n$O\\left(\\left(\\frac{L}{\\epsilon}+\\frac{1}{1-\\sigma_2(W)}\\right)\\log\\frac{1}{1-\\sigma_2(W)}\\right)$\ncomplexities. Then, we use the Catalyst framework to accelerate EXTRA and\nobtain the $O\\left(\\sqrt{\\frac{L}{\\mu(1-\\sigma_2(W))}}\\log\\frac{\nL}{\\mu(1-\\sigma_2(W))}\\log\\frac{1}{\\epsilon}\\right)$ communication and\ncomputation complexities for strongly convex and smooth problems and the\n$O\\left(\\sqrt{\\frac{L}{\\epsilon(1-\\sigma_2(W))}}\\log\\frac{1}{\\epsilon(1-\\sigma_2(W))}\\right)$\ncomplexities for non-strongly convex ones. Our communication complexities of\nthe accelerated EXTRA are only worse by the factors of\n$\\left(\\log\\frac{L}{\\mu(1-\\sigma_2(W))}\\right)$ and\n$\\left(\\log\\frac{1}{\\epsilon(1-\\sigma_2(W))}\\right)$ from the lower complexity\nbounds for strongly convex and non-strongly convex problems, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:07:08 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 04:38:13 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Li", "Huan", ""], ["Lin", "Zhouchen", ""]]}, {"id": "2002.10113", "submitter": "Alex Tong Lin", "authors": "Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, Stanley J.\n  Osher", "title": "Alternating the Population and Control Neural Networks to Solve\n  High-Dimensional Stochastic Mean-Field Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present APAC-Net, an alternating population and agent control neural\nnetwork for solving stochastic mean field games (MFGs). Our algorithm is geared\ntoward high-dimensional instances of MFGs that are beyond reach with existing\nsolution methods. We achieve this in two steps. First, we take advantage of the\nunderlying variational primal-dual structure that MFGs exhibit and phrase it as\na convex-concave saddle point problem. Second, we parameterize the value and\ndensity functions by two neural networks, respectively. By phrasing the problem\nin this manner, solving the MFG can be interpreted as a special case of\ntraining a generative adversarial network (GAN). We show the potential of our\nmethod on up to 100-dimensional MFG problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:24:52 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:23:39 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 23:36:31 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lin", "Alex Tong", ""], ["Fung", "Samy Wu", ""], ["Li", "Wuchen", ""], ["Nurbekyan", "Levon", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2002.10116", "submitter": "\\c{S}aziye Bet\\\"ul \\\"Ozate\\c{s}", "authors": "\\c{S}aziye Bet\\\"ul \\\"Ozate\\c{s} (1), Arzucan \\\"Ozg\\\"ur (1), Tunga\n  G\\\"ung\\\"or (1), Balk{\\i}z \\\"Ozt\\\"urk (2) ((1) Department of Computer\n  Engineering, Bo\\u{g}azi\\c{c}i University, (2) Department of Linguistics,\n  Bo\\u{g}azi\\c{c}i University)", "title": "A Hybrid Approach to Dependency Parsing: Combining Rules and Morphology\n  with Deep Learning", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully data-driven, deep learning-based models are usually designed as\nlanguage-independent and have been shown to be successful for many natural\nlanguage processing tasks. However, when the studied language is low-resourced\nand the amount of training data is insufficient, these models can benefit from\nthe integration of natural language grammar-based information. We propose two\napproaches to dependency parsing especially for languages with restricted\namount of training data. Our first approach combines a state-of-the-art deep\nlearning-based parser with a rule-based approach and the second one\nincorporates morphological information into the parser. In the rule-based\napproach, the parsing decisions made by the rules are encoded and concatenated\nwith the vector representations of the input words as additional information to\nthe deep network. The morphology-based approach proposes different methods to\ninclude the morphological structure of words into the parser network.\nExperiments are conducted on the IMST-UD Treebank and the results suggest that\nintegration of explicit knowledge about the target language to a neural parser\nthrough a rule-based parsing system and morphological analysis leads to more\naccurate annotations and hence, increases the parsing performance in terms of\nattachment scores. The proposed methods are developed for Turkish, but can be\nadapted to other languages as well.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:34:33 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["\u00d6zate\u015f", "\u015eaziye Bet\u00fcl", ""], ["\u00d6zg\u00fcr", "Arzucan", ""], ["G\u00fcng\u00f6r", "Tunga", ""], ["\u00d6zt\u00fcrk", "Balk\u0131z", ""]]}, {"id": "2002.10118", "submitter": "Agustinus Kristiadi", "authors": "Agustinus Kristiadi, Matthias Hein, Philipp Hennig", "title": "Being Bayesian, Even Just a Bit, Fixes Overconfidence in ReLU Networks", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The point estimates of ReLU classification networks---arguably the most\nwidely used neural network architecture---have been shown to yield arbitrarily\nhigh confidence far away from the training data. This architecture, in\nconjunction with a maximum a posteriori estimation scheme, is thus not\ncalibrated nor robust. Approximate Bayesian inference has been empirically\ndemonstrated to improve predictive uncertainty in neural networks, although the\ntheoretical analysis of such Bayesian approximations is limited. We\ntheoretically analyze approximate Gaussian distributions on the weights of ReLU\nnetworks and show that they fix the overconfidence problem. Furthermore, we\nshow that even a simplistic, thus cheap, Bayesian approximation, also fixes\nthese issues. This indicates that a sufficient condition for a calibrated\nuncertainty on a ReLU network is \"to be a bit Bayesian\". These theoretical\nresults validate the usage of last-layer Bayesian approximation and motivate a\nrange of a fidelity-cost trade-off. We further validate these findings\nempirically via various standard experiments using common deep ReLU networks\nand Laplace approximations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:52:06 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 15:04:19 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kristiadi", "Agustinus", ""], ["Hein", "Matthias", ""], ["Hennig", "Philipp", ""]]}, {"id": "2002.10121", "submitter": "Khashayar Khosravi", "authors": "Mohsen Bayati, Nima Hamidi, Ramesh Johari, Khashayar Khosravi", "title": "The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed\n  Bandit with Many Arms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structure of regret-minimizing policies in the many-armed\nBayesian multi-armed bandit problem: in particular, with k the number of arms\nand T the time horizon, we consider the case where k > \\sqrt{T}. We first show\nthat subsampling is a critical step for designing optimal policies. In\nparticular, the standard UCB algorithm leads to sub-optimal regret bounds in\nthis regime. However, a subsampled UCB (SS-UCB), which samples \\sqrt{T} arms\nand executes UCB only on that subset, is rate-optimal. Despite theoretically\noptimal regret, even SS-UCB performs poorly due to excessive exploration of\nsuboptimal arms. In fact, in numerical experiments SS-UCB performs worse than a\nsimple greedy algorithm (and its subsampled version) that pulls the current\nempirical best arm at every time period. We show that these insights hold even\nin a contextual setting, using real-world data. These empirical results suggest\na novel form of free exploration in the many-armed regime that benefits greedy\nalgorithms. We theoretically study this new source of free exploration and find\nthat it is deeply connected to the distribution of a certain tail event for the\nprior distribution of arm rewards. This is a fundamentally distinct phenomenon\nfrom free exploration as discussed in the recent literature on contextual\nbandits, where free exploration arises due to variation in contexts. We prove\nthat the subsampled greedy algorithm is rate-optimal for Bernoulli bandits when\nk > \\sqrt{T}, and achieves sublinear regret with more general distributions.\nThis is a case where theoretical rate optimality does not tell the whole story:\nwhen complemented by the empirical observations of our paper, the power of\ngreedy algorithms becomes quite evident. Taken together, from a practical\nstandpoint, our results suggest that in applications it may be preferable to\nuse a variant of the greedy algorithm in the many-armed regime.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 08:59:34 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:56:39 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Bayati", "Mohsen", ""], ["Hamidi", "Nima", ""], ["Johari", "Ramesh", ""], ["Khosravi", "Khashayar", ""]]}, {"id": "2002.10123", "submitter": "Ahmet Karak\\\"u\\c{c}\\\"uk", "authors": "Ahmet G\\\"okhan Poyraz, Ahmet Emir Dirik, Ahmet Karak\\\"u\\c{c}\\\"uk,\n  Nasir Memon", "title": "Fusion of Camera Model and Source Device Specific Forensic Methods for\n  Improved Tamper Detection", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PRNU based camera recognition method is widely studied in the image forensic\nliterature. In recent years, CNN based camera model recognition methods have\nbeen developed. These two methods also provide solutions to tamper localization\nproblem. In this paper, we propose their combination via a Neural Network to\nachieve better small-scale tamper detection performance. According to the\nresults, the fusion method performs better than underlying methods even under\nhigh JPEG compression. For forgeries as small as 100$\\times$100 pixel size, the\nproposed method outperforms the state-of-the-art, which validates the\nusefulness of fusion for localization of small-size image forgeries. We believe\nthe proposed approach is feasible for any tamper-detection pipeline using the\nPRNU based methodology.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:02:12 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 14:41:47 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Poyraz", "Ahmet G\u00f6khan", ""], ["Dirik", "Ahmet Emir", ""], ["Karak\u00fc\u00e7\u00fck", "Ahmet", ""], ["Memon", "Nasir", ""]]}, {"id": "2002.10127", "submitter": "Ahmad Mel", "authors": "Ahmad Mel, Bo Kang, Jefrey Lijffijt, Tijl De Bie", "title": "FONDUE: A Framework for Node Disambiguation Using Network Embeddings", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data often presents itself in the form of a network. Examples\ninclude social networks, citation networks, biological networks, and knowledge\ngraphs. In their simplest form, networks represent real-life entities (e.g.\npeople, papers, proteins, concepts) as nodes, and describe them in terms of\ntheir relations with other entities by means of edges between these nodes. This\ncan be valuable for a range of purposes from the study of information diffusion\nto bibliographic analysis, bioinformatics research, and question-answering.\n  The quality of networks is often problematic though, affecting downstream\ntasks. This paper focuses on the common problem where a node in the network in\nfact corresponds to multiple real-life entities. In particular, we introduce\nFONDUE, an algorithm based on network embedding for node disambiguation. Given\na network, FONDUE identifies nodes that correspond to multiple entities, for\nsubsequent splitting. Extensive experiments on twelve benchmark datasets\ndemonstrate that FONDUE is substantially and uniformly more accurate for\nambiguous node identification compared to the existing state-of-the-art, at a\ncomparable computational cost, while less optimal for determining the best way\nto split ambiguous nodes.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:34:18 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mel", "Ahmad", ""], ["Kang", "Bo", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.10148", "submitter": "Markus Sch\\\"oberl", "authors": "Markus Sch\\\"oberl, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis", "title": "Embedded-physics machine learning for coarse-graining and collective\n  variable discovery without data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel learning framework that consistently embeds underlying\nphysics while bypassing a significant drawback of most modern, data-driven\ncoarse-grained approaches in the context of molecular dynamics (MD), i.e., the\navailability of big data. The generation of a sufficiently large training\ndataset poses a computationally demanding task, while complete coverage of the\natomistic configuration space is not guaranteed. As a result, the explorative\ncapabilities of data-driven coarse-grained models are limited and may yield\nbiased \"predictive\" tools. We propose a novel objective based on reverse\nKullback-Leibler divergence that fully incorporates the available physics in\nthe form of the atomistic force field. Rather than separating model learning\nfrom the data-generation procedure - the latter relies on simulating atomistic\nmotions governed by force fields - we query the atomistic force field at sample\nconfigurations proposed by the predictive coarse-grained model. Thus, learning\nrelies on the evaluation of the force field but does not require any MD\nsimulation. The resulting generative coarse-grained model serves as an\nefficient surrogate model for predicting atomistic configurations and\nestimating relevant observables. Beyond obtaining a predictive coarse-grained\nmodel, we demonstrate that in the discovered lower-dimensional representation,\nthe collective variables (CVs) are related to physicochemical properties, which\nare essential for gaining understanding of unexplored complex systems. We\ndemonstrate the algorithmic advances in terms of predictive ability and the\nphysical meaning of the revealed CVs for a bimodal potential energy function\nand the alanine dipeptide.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 10:28:41 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Sch\u00f6berl", "Markus", ""], ["Zabaras", "Nicholas", ""], ["Koutsourelakis", "Phaedon-Stelios", ""]]}, {"id": "2002.10174", "submitter": "Runmin Wu", "authors": "Runmin Wu, Kunyao Zhang, Lijun Wang, Yue Wang, Pingping Zhang, Huchuan\n  Lu, Yizhou Yu", "title": "When Relation Networks meet GANs: Relation GANs with Triplet Loss", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Though recent research has achieved remarkable progress in generating\nrealistic images with generative adversarial networks (GANs), the lack of\ntraining stability is still a lingering concern of most GANs, especially on\nhigh-resolution inputs and complex datasets. Since the randomly generated\ndistribution can hardly overlap with the real distribution, training GANs often\nsuffers from the gradient vanishing problem. A number of approaches have been\nproposed to address this issue by constraining the discriminator's capabilities\nusing empirical techniques, like weight clipping, gradient penalty, spectral\nnormalization etc. In this paper, we provide a more principled approach as an\nalternative solution to this issue. Instead of training the discriminator to\ndistinguish real and fake input samples, we investigate the relationship\nbetween paired samples by training the discriminator to separate paired samples\nfrom the same distribution and those from different distributions. To this end,\nwe explore a relation network architecture for the discriminator and design a\ntriplet loss which performs better generalization and stability. Extensive\nexperiments on benchmark datasets show that the proposed relation discriminator\nand new loss can provide significant improvement on variable vision tasks\nincluding unconditional and conditional image generation and image translation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 11:35:28 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 07:35:13 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 03:28:57 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Wu", "Runmin", ""], ["Zhang", "Kunyao", ""], ["Wang", "Lijun", ""], ["Wang", "Yue", ""], ["Zhang", "Pingping", ""], ["Lu", "Huchuan", ""], ["Yu", "Yizhou", ""]]}, {"id": "2002.10177", "submitter": "Ioan Marius Bilasco PhD", "authors": "Pierre Falez and Pierre Tirilly and Ioan Marius Bilasco", "title": "Improving STDP-based Visual Feature Learning with Whitening", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207373", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, spiking neural networks (SNNs) emerge as an alternative to\ndeep neural networks (DNNs). SNNs present a higher computational efficiency\nusing low-power neuromorphic hardware and require less labeled data for\ntraining using local and unsupervised learning rules such as spike\ntiming-dependent plasticity (STDP). SNN have proven their effectiveness in\nimage classification on simple datasets such as MNIST. However, to process\nnatural images, a pre-processing step is required. Difference-of-Gaussians\n(DoG) filtering is typically used together with on-center/off-center coding,\nbut it results in a loss of information that is detrimental to the\nclassification performance. In this paper, we propose to use whitening as a\npre-processing step before learning features with STDP. Experiments on CIFAR-10\nshow that whitening allows STDP to learn visual features that are closer to the\nones learned with standard neural networks, with a significantly increased\nclassification performance as compared to DoG filtering. We also propose an\napproximation of whitening as convolution kernels that is computationally\ncheaper to learn and more suited to be implemented on neuromorphic hardware.\nExperiments on CIFAR-10 show that it performs similarly to regular whitening.\nCross-dataset experiments on CIFAR-10 and STL-10 also show that it is fairly\nstable across datasets, making it possible to learn a single whitening\ntransformation to process different datasets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 11:48:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Falez", "Pierre", ""], ["Tirilly", "Pierre", ""], ["Bilasco", "Ioan Marius", ""]]}, {"id": "2002.10199", "submitter": "Tuomo Alasalmi", "authors": "Tuomo Alasalmi, Jaakko Suutala, Heli Koskim\\\"aki, and Juha R\\\"oning", "title": "Better Classifier Calibration for Small Data Sets", "comments": null, "journal-ref": "ACM Transactions on Knowledge Discovery from Data, 14(3), Article\n  34 (May 2020)", "doi": "10.1145/3385656", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier calibration does not always go hand in hand with the classifier's\nability to separate the classes. There are applications where good classifier\ncalibration, i.e. the ability to produce accurate probability estimates, is\nmore important than class separation. When the amount of data for training is\nlimited, the traditional approach to improve calibration starts to crumble. In\nthis article we show how generating more data for calibration is able to\nimprove calibration algorithm performance in many cases where a classifier is\nnot naturally producing well-calibrated outputs and the traditional approach\nfails. The proposed approach adds computational cost but considering that the\nmain use case is with small data sets this extra computational cost stays\ninsignificant and is comparable to other methods in prediction time. From the\ntested classifiers the largest improvement was detected with the random forest\nand naive Bayes classifiers. Therefore, the proposed approach can be\nrecommended at least for those classifiers when the amount of data available\nfor training is limited and good calibration is essential.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:27:21 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:15:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Alasalmi", "Tuomo", ""], ["Suutala", "Jaakko", ""], ["Koskim\u00e4ki", "Heli", ""], ["R\u00f6ning", "Juha", ""]]}, {"id": "2002.10214", "submitter": "Andrea Borghesi", "authors": "Andrea Borghesi, Federico Baldo, Michele Lombardi, Michela Milano", "title": "Injective Domain Knowledge in Neural Networks for Transprecision\n  Computing", "comments": null, "journal-ref": "Nicosia G. et al. (eds) Machine Learning, Optimization, and Data\n  Science. LOD 2020. Lecture Notes in Computer Science, vol 12565. Springer,\n  Cham", "doi": "10.1007/978-3-030-64583-0_52", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) models are very effective in many learning tasks, due\nto the capability to extract meaningful information from large data sets.\nNevertheless, there are learning problems that cannot be easily solved relying\non pure data, e.g. scarce data or very complex functions to be approximated.\nFortunately, in many contexts domain knowledge is explicitly available and can\nbe used to train better ML models. This paper studies the improvements that can\nbe obtained by integrating prior knowledge when dealing with a non-trivial\nlearning task, namely precision tuning of transprecision computing\napplications. The domain information is injected in the ML models in different\nways: I) additional features, II) ad-hoc graph-based network topology, III)\nregularization schemes. The results clearly show that ML models exploiting\nproblem-specific information outperform the purely data-driven ones, with an\naverage accuracy improvement around 38%.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 12:58:56 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Borghesi", "Andrea", ""], ["Baldo", "Federico", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10218", "submitter": "Tianxiang Mao", "authors": "Tian-Xiang Mao, Jie Wang, Baojiu Li, Yan-Chuan Cai, Bridget Falck,\n  Mark Neyrinck and Alex Szalay", "title": "Baryon acoustic oscillations reconstruction using convolutional neural\n  networks", "comments": "Accepted for publication in MNRAS", "journal-ref": "MNRAS, 501, 1499-1510 (2021)", "doi": "10.1093/mnras/staa3741", "report-no": null, "categories": "astro-ph.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new scheme to reconstruct the baryon acoustic oscillations (BAO)\nsignal, which contains key cosmological information, based on deep\nconvolutional neural networks (CNN). Trained with almost no fine-tuning, the\nnetwork can recover large-scale modes accurately in the test set: the\ncorrelation coefficient between the true and reconstructed initial conditions\nreaches $90\\%$ at $k\\leq 0.2 h\\mathrm{Mpc}^{-1}$, which can lead to significant\nimprovements of the BAO signal-to-noise ratio down to\n$k\\simeq0.4h\\mathrm{Mpc}^{-1}$. Since this new scheme is based on the\nconfiguration-space density field in sub-boxes, it is local and less affected\nby survey boundaries than the standard reconstruction method, as our tests\nconfirm. We find that the network trained in one cosmology is able to\nreconstruct BAO peaks in the others, i.e. recovering information lost to\nnon-linearity independent of cosmology. The accuracy of recovered BAO peak\npositions is far less than that caused by the difference in the cosmology\nmodels for training and testing, suggesting that different models can be\ndistinguished efficiently in our scheme. It is very promising that Our scheme\nprovides a different new way to extract the cosmological information from the\nongoing and future large galaxy surveys.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:18:31 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 08:12:25 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 08:41:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mao", "Tian-Xiang", ""], ["Wang", "Jie", ""], ["Li", "Baojiu", ""], ["Cai", "Yan-Chuan", ""], ["Falck", "Bridget", ""], ["Neyrinck", "Mark", ""], ["Szalay", "Alex", ""]]}, {"id": "2002.10221", "submitter": "Samuel Alexander", "authors": "Samuel Allen Alexander", "title": "The Archimedean trap: Why traditional reinforcement learning will\n  probably not yield AGI", "comments": "16 pages", "journal-ref": "Journal of Artificial General Intelligence 11(1): 70--85 (2020)", "doi": "10.2478/jagi-2020-0004", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After generalizing the Archimedean property of real numbers in such a way as\nto make it adaptable to non-numeric structures, we demonstrate that the real\nnumbers cannot be used to accurately measure non-Archimedean structures. We\nargue that, since an agent with Artificial General Intelligence (AGI) should\nhave no problem engaging in tasks that inherently involve non-Archimedean\nrewards, and since traditional reinforcement learning rewards are real numbers,\ntherefore traditional reinforcement learning probably will not lead to AGI. We\nindicate two possible ways traditional reinforcement learning could be altered\nto remove this roadblock.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 22:01:56 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 03:39:28 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Alexander", "Samuel Allen", ""]]}, {"id": "2002.10228", "submitter": "Srikanth Chandar", "authors": "Srikanth Chandar and Harsha Sunder", "title": "Dynamic Systems Simulation and Control Using Consecutive Recurrent\n  Neural Networks", "comments": "14 pages, granted for publication in Communications in Computer and\n  Information Science (CCIS) proceedings by Springer Nature, presented in the\n  International Conference on Modelling, Machine Learning and Astronomy (MMLA\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel architecture to connecting adaptive\nlearning and neural networks into an arbitrary machine's control system\nparadigm. Two consecutive Recurrent Neural Networks (RNNs) are used together to\naccurately model the dynamic characteristics of electromechanical systems that\ninclude controllers, actuators and motors. The age-old method of achieving\ncontrol with the use of the- Proportional, Integral and Derivative constants is\nwell understood as a simplified method that does not capture the complexities\nof the inherent nonlinearities of complex control systems. In the context of\ncontrolling and simulating electromechanical systems, we propose an alternative\nto PID controllers, employing a sequence of two Recurrent Neural Networks. The\nfirst RNN emulates the behavior of the controller, and the second the\nactuator/motor. The second RNN when used in isolation, potentially serves as an\nadvantageous alternative to extant testing methods of electromechanical\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:08:44 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 01:57:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chandar", "Srikanth", ""], ["Sunder", "Harsha", ""]]}, {"id": "2002.10233", "submitter": "Yanan Sun", "authors": "Yanan Sun, Ziyao Ren, Gary G. Yen, Bing Xue, Mengjie Zhang and\n  Jiancheng Lv", "title": "ArcText: A Unified Text Approach to Describing Convolutional Neural\n  Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superiority of Convolutional Neural Networks (CNNs) largely relies on\ntheir architectures that are often manually crafted with extensive human\nexpertise. Unfortunately, such kind of domain knowledge is not necessarily\nowned by each of the users interested. Data mining on existing CNN can discover\nuseful patterns and fundamental sub-comments from their architectures,\nproviding researchers with strong prior knowledge to design proper CNN\narchitectures when they have no expertise in CNNs. There have been various\nstate-of-the-art data mining algorithms at hand, while there is only rare work\nthat has been done for the mining. One of the main reasons is the gap between\nCNN architectures and data mining algorithms. Specifically, the current CNN\narchitecture descriptions cannot be exactly vectorized to the input of data\nmining algorithms. In this paper, we propose a unified approach, named ArcText,\nto describing CNN architectures based on text. Particularly, four different\nunits and an ordering method have been elaborately designed in ArcText, to\nuniquely describe the same architecture with sufficient information. Also, the\nresulted description can be exactly converted back to the corresponding CNN\narchitecture. ArcText bridges the gap between CNN architectures and data mining\nresearchers, and has the potentiality to be utilized to wider scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 17:17:16 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 14:59:39 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 08:17:06 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 08:43:12 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Sun", "Yanan", ""], ["Ren", "Ziyao", ""], ["Yen", "Gary G.", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""], ["Lv", "Jiancheng", ""]]}, {"id": "2002.10234", "submitter": "Yuji Roh", "authors": "Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh", "title": "FR-Train: A Mutual Information-Based Approach to Fair and Robust\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustworthy AI is a critical issue in machine learning where, in addition to\ntraining a model that is accurate, one must consider both fair and robust\ntraining in the presence of data bias and poisoning. However, the existing\nmodel fairness techniques mistakenly view poisoned data as an additional bias\nto be fixed, resulting in severe performance degradation. To address this\nproblem, we propose FR-Train, which holistically performs fair and robust model\ntraining. We provide a mutual information-based interpretation of an existing\nadversarial training-based fairness-only method, and apply this idea to\narchitect an additional discriminator that can identify poisoned data using a\nclean validation set and reduce its influence. In our experiments, FR-Train\nshows almost no decrease in fairness and accuracy in the presence of data\npoisoning by both mitigating the bias and defending against poisoning. We also\ndemonstrate how to construct clean validation sets using crowdsourcing, and\nrelease new benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:37:29 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 07:46:37 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Roh", "Yuji", ""], ["Lee", "Kangwook", ""], ["Whang", "Steven Euijong", ""], ["Suh", "Changho", ""]]}, {"id": "2002.10235", "submitter": "Xuhui Fan", "authors": "Yaqiong Li, Xuhui Fan, Ling Chen, Bin Li, Zheng Yu, Scott A. Sisson", "title": "Recurrent Dirichlet Belief Networks for Interpretable Dynamic Relational\n  Data Modelling", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dirichlet Belief Network~(DirBN) has been recently proposed as a\npromising approach in learning interpretable deep latent representations for\nobjects. In this work, we leverage its interpretable modelling architecture and\npropose a deep dynamic probabilistic framework -- the Recurrent Dirichlet\nBelief Network~(Recurrent-DBN) -- to study interpretable hidden structures from\ndynamic relational data. The proposed Recurrent-DBN has the following merits:\n(1) it infers interpretable and organised hierarchical latent structures for\nobjects within and across time steps; (2) it enables recurrent long-term\ntemporal dependence modelling, which outperforms the one-order Markov\ndescriptions in most of the dynamic probabilistic frameworks. In addition, we\ndevelop a new inference strategy, which first upward-and-backward propagates\nlatent counts and then downward-and-forward samples variables, to enable\nefficient Gibbs sampling for the Recurrent-DBN. We apply the Recurrent-DBN to\ndynamic relational data problems. The extensive experiment results on\nreal-world data validate the advantages of the Recurrent-DBN over the\nstate-of-the-art models in interpretable latent structure discovery and\nimproved link prediction performance.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:40:24 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 10:54:50 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Li", "Yaqiong", ""], ["Fan", "Xuhui", ""], ["Chen", "Ling", ""], ["Li", "Bin", ""], ["Yu", "Zheng", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.10241", "submitter": "Sujoy Chatterjee", "authors": "Sujoy Chatterjee, Nicolas Pasquier, Simon Nanty, Maria A. Zuluaga", "title": "Multi-objective Consensus Clustering Framework for Flight Search\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the travel industry, online customers book their travel itinerary\naccording to several features, like cost and duration of the travel or the\nquality of amenities. To provide personalized recommendations for travel\nsearches, an appropriate segmentation of customers is required. Clustering\nensemble approaches were developed to overcome well-known problems of classical\nclustering approaches, that each rely on a different theoretical model and can\nthus identify in the data space only clusters corresponding to this model.\nClustering ensemble approaches combine multiple clustering results, each from a\ndifferent algorithmic configuration, for generating more robust consensus\nclusters corresponding to agreements between initial clusters. We present a new\nclustering ensemble multi-objective optimization-based framework developed for\nanalyzing Amadeus customer search data and improve personalized\nrecommendations. This framework optimizes diversity in the clustering ensemble\nsearch space and automatically determines an appropriate number of clusters\nwithout requiring user's input. Experimental results compare the efficiency of\nthis approach with other existing approaches on Amadeus customer search data in\nterms of internal (Adjusted Rand Index) and external (Amadeus business metric)\nvalidations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 03:56:02 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:41:59 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chatterjee", "Sujoy", ""], ["Pasquier", "Nicolas", ""], ["Nanty", "Simon", ""], ["Zuluaga", "Maria A.", ""]]}, {"id": "2002.10243", "submitter": "Tianyu Cui", "authors": "Tianyu Cui, Aki Havulinna, Pekka Marttinen, Samuel Kaski", "title": "Informative Bayesian Neural Network Priors for Weak Signals", "comments": "25 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding domain knowledge into the prior over the high-dimensional weight\nspace of a neural network is challenging but essential in applications with\nlimited data and weak signals. Two types of domain knowledge are commonly\navailable in scientific applications: 1. feature sparsity (fraction of features\ndeemed relevant); 2. signal-to-noise ratio, quantified, for instance, as the\nproportion of variance explained (PVE). We show how to encode both types of\ndomain knowledge into the widely used Gaussian scale mixture priors with\nAutomatic Relevance Determination. Specifically, we propose a new joint prior\nover the local (i.e., feature-specific) scale parameters that encodes knowledge\nabout feature sparsity, and a Stein gradient optimization to tune the\nhyperparameters in such a way that the distribution induced on the model's PVE\nmatches the prior distribution. We show empirically that the new prior improves\nprediction accuracy, compared to existing neural network priors, on several\npublicly available datasets and in a genetics application where signals are\nweak and sparse, often outperforming even computationally intensive\ncross-validation for hyperparameter tuning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:43:44 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 14:55:29 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Cui", "Tianyu", ""], ["Havulinna", "Aki", ""], ["Marttinen", "Pekka", ""], ["Kaski", "Samuel", ""]]}, {"id": "2002.10247", "submitter": "Manav Kaushik", "authors": "Manav Kaushik and A K Giri", "title": "Forecasting Foreign Exchange Rate: A Multivariate Comparative Analysis\n  between Traditional Econometric, Contemporary Machine Learning & Deep\n  Learning Techniques", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In todays global economy, accuracy in predicting macro-economic parameters\nsuch as the foreign the exchange rate or at least estimating the trend\ncorrectly is of key importance for any future investment. In recent times, the\nuse of computational intelligence-based techniques for forecasting\nmacroeconomic variables has been proven highly successful. This paper tries to\ncome up with a multivariate time series approach to forecast the exchange rate\n(USD/INR) while parallelly comparing the performance of three multivariate\nprediction modelling techniques: Vector Auto Regression (a Traditional\nEconometric Technique), Support Vector Machine (a Contemporary Machine Learning\nTechnique), and Recurrent Neural Networks (a Contemporary Deep Learning\nTechnique). We have used monthly historical data for several macroeconomic\nvariables from April 1994 to December 2018 for USA and India to predict USD-INR\nForeign Exchange Rate. The results clearly depict that contemporary techniques\nof SVM and RNN (Long Short-Term Memory) outperform the widely used traditional\nmethod of Auto Regression. The RNN model with Long Short-Term Memory (LSTM)\nprovides the maximum accuracy (97.83%) followed by SVM Model (97.17%) and VAR\nModel (96.31%). At last, we present a brief analysis of the correlation and\ninterdependencies of the variables used for forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:11:57 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Kaushik", "Manav", ""], ["Giri", "A K", ""]]}, {"id": "2002.10248", "submitter": "Serena Booth", "authors": "Serena Booth, Yilun Zhou, Ankit Shah, Julie Shah", "title": "Bayes-TrEx: a Bayesian Sampling Approach to Model Transparency by\n  Example", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanation methods are gaining popularity for interpreting,\nunderstanding, and debugging neural networks. Most analyses using such methods\nexplain decisions in response to inputs drawn from the test set. However, the\ntest set may have few examples that trigger some model behaviors, such as\nhigh-confidence failures or ambiguous classifications. To address these\nchallenges, we introduce a flexible model inspection framework: Bayes-TrEx.\nGiven a data distribution, Bayes-TrEx finds in-distribution examples with a\nspecified prediction confidence. We demonstrate several use cases of\nBayes-TrEx, including revealing highly confident (mis)classifications,\nvisualizing class boundaries via ambiguous examples, understanding novel-class\nextrapolation behavior, and exposing neural network overconfidence. We use\nBayes-TrEx to study classifiers trained on CLEVR, MNIST, and Fashion-MNIST, and\nwe show that this framework enables more flexible holistic model analysis than\njust inspecting the test set. Code is available at\nhttps://github.com/serenabooth/Bayes-TrEx.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 15:49:00 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 14:11:24 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 16:24:24 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 16:44:55 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Booth", "Serena", ""], ["Zhou", "Yilun", ""], ["Shah", "Ankit", ""], ["Shah", "Julie", ""]]}, {"id": "2002.10252", "submitter": "Negin Entezari", "authors": "Negin Entezari, Evangelos E. Papalexakis", "title": "TensorShield: Tensor-based Defense Against Adversarial Attacks on Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that machine learning approaches like deep\nneural networks (DNNs) are easily fooled by adversarial attacks. Subtle and\nimperceptible perturbations of the data are able to change the result of deep\nneural networks. Leveraging vulnerable machine learning methods raises many\nconcerns especially in domains where security is an important factor.\nTherefore, it is crucial to design defense mechanisms against adversarial\nattacks. For the task of image classification, unnoticeable perturbations\nmostly occur in the high-frequency spectrum of the image. In this paper, we\nutilize tensor decomposition techniques as a preprocessing step to find a\nlow-rank approximation of images which can significantly discard high-frequency\nperturbations. Recently a defense framework called Shield could \"vaccinate\"\nConvolutional Neural Networks (CNN) against adversarial examples by performing\nrandom-quality JPEG compressions on local patches of images on the ImageNet\ndataset. Our tensor-based defense mechanism outperforms the SLQ method from\nShield by 14% against FastGradient Descent (FGSM) adversarial attacks, while\nmaintaining comparable speed.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 00:39:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Entezari", "Negin", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2002.10254", "submitter": "Ripon Patgiri", "authors": "Ripon Patgiri, Sajid Hussain, Aditya Nongmeikapam", "title": "Empirical Study on Airline Delay Analysis and Prediction", "comments": "Figure 13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Big Data analytics are a logical analysis of very large scale datasets.\nThe data analysis enhances an organization and improve the decision making\nprocess. In this article, we present Airline Delay Analysis and Prediction to\nanalyze airline datasets with the combination of weather dataset. In this\nresearch work, we consider various attributes to analyze flight delay, for\nexample, day-wise, airline-wise, cloud cover, temperature, etc. Moreover, we\npresent rigorous experiments on various machine learning model to predict\ncorrectly the delay of a flight, namely, logistic regression with L2\nregularization, Gaussian Naive Bayes, K-Nearest Neighbors, Decision Tree\nclassifier and Random forest model. The accuracy of the Random Forest model is\n82% with a delay threshold of 15 minutes of flight delay. The analysis is\ncarried out using dataset from 1987 to 2008, the training is conducted with\ndataset from 2000 to 2007 and validated prediction result using 2008 data.\nMoreover, we have got recall 99% in the Random Forest model.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 15:32:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Patgiri", "Ripon", ""], ["Hussain", "Sajid", ""], ["Nongmeikapam", "Aditya", ""]]}, {"id": "2002.10257", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh", "title": "Using Wavelets to Analyze Similarities in Image-Classification Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning image classifiers usually rely on huge training sets and their\ntraining process can be described as learning the similarities and differences\namong training images. But, images in large training sets are not usually\nstudied from this perspective and fine-level similarities and differences among\nimages is usually overlooked. This is due to lack of fast and efficient\ncomputational methods to analyze the contents of these datasets. Some studies\naim to identify the influential and redundant training images, but such methods\nrequire a model that is already trained on the entire training set. Here, using\nimage processing and numerical analysis tools we develop a practical and fast\nmethod to analyze the similarities in image classification datasets. We show\nthat such analysis can provide valuable insights about the datasets and the\nclassification task at hand, prior to training a model. Our method uses wavelet\ndecomposition of images and other numerical analysis tools, with no need for a\npre-trained model. Interestingly, the results we obtain corroborate the\nprevious results in the literature that analyzed the similarities using\npre-trained CNNs. We show that similar images in standard datasets (such as\nCIFAR) can be identified in a few seconds, a significant speed-up compared to\nalternative methods in the literature. By removing the computational speed\nobstacle, it becomes practical to gain new insights about the contents of\ndatasets and the models trained on them. We show that similarities between\ntraining and testing images may provide insights about the generalization of\nmodels. Finally, we investigate the similarities between images in relation to\ndecision boundaries of a trained model.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:46:28 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 01:42:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""]]}, {"id": "2002.10259", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka", "title": "Complex Markov Logic Networks: Expressivity and Liftability", "comments": "Fixed typos in Lemma 1 and Section 7. Paper accepted to UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study expressivity of Markov logic networks (MLNs). We introduce complex\nMLNs, which use complex-valued weights, and we show that, unlike standard MLNs\nwith real-valued weights, complex MLNs are fully expressive. We then observe\nthat discrete Fourier transform can be computed using weighted first order\nmodel counting (WFOMC) with complex weights and use this observation to design\nan algorithm for computing relational marginal polytopes which needs\nsubstantially less calls to a WFOMC oracle than a recent algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:50:59 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 13:04:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kuzelka", "Ondrej", ""]]}, {"id": "2002.10261", "submitter": "Zayd Hammoudeh", "authors": "Zayd Hammoudeh and Daniel Lowd", "title": "Learning from Positive and Unlabeled Data with Arbitrary Positive Shift", "comments": "Accepted at NeurIPS'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive-unlabeled (PU) learning trains a binary classifier using only\npositive and unlabeled data. A common simplifying assumption is that the\npositive data is representative of the target positive class. This assumption\nrarely holds in practice due to temporal drift, domain shift, and/or\nadversarial manipulation. This paper shows that PU learning is possible even\nwith arbitrarily non-representative positive data given unlabeled data from the\nsource and target distributions. Our key insight is that only the negative\nclass's distribution need be fixed. We integrate this into two statistically\nconsistent methods to address arbitrary positive bias - one approach combines\nnegative-unlabeled learning with unlabeled-unlabeled learning while the other\nuses a novel, recursive risk estimator. Experimental results demonstrate our\nmethods' effectiveness across numerous real-world datasets and forms of\npositive bias, including disjoint positive class-conditional supports.\nAdditionally, we propose a general, simplified approach to address PU risk\nestimation overfitting.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:53:22 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 00:48:59 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 02:00:34 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 12:20:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hammoudeh", "Zayd", ""], ["Lowd", "Daniel", ""]]}, {"id": "2002.10266", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Stephanie Van Laere, Tim Verbelen, Bart Dhoedt", "title": "Rhythm, Chord and Melody Generation for Lead Sheets using Recurrent\n  Neural Networks", "comments": "8 pages, 2 figures, 3 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music that is generated by recurrent neural networks often lacks a sense of\ndirection and coherence. We therefore propose a two-stage LSTM-based model for\nlead sheet generation, in which the harmonic and rhythmic templates of the song\nare produced first, after which, in a second stage, a sequence of melody notes\nis generated conditioned on these templates. A subjective listening test shows\nthat our approach outperforms the baselines and increases perceived musical\ncoherence.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:36:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["De Boom", "Cedric", ""], ["Van Laere", "Stephanie", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "2002.10268", "submitter": "Martin Lellep", "authors": "Martin Lellep, Jonathan Prexl, Moritz Linkmann, and Bruno Eckhardt", "title": "Using Machine Learning to predict extreme events in the H\\'enon map", "comments": "9 pages, 12 figures", "journal-ref": "Chaos: An Interdisciplinary Journal of Nonlinear Science 30.1\n  (2020): 013113", "doi": "10.1063/1.5121844", "report-no": null, "categories": "cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) inspired algorithms provide a flexible set of tools for\nanalyzing and forecasting chaotic dynamical systems. We here analyze the\nperformance of one algorithm for the prediction of extreme events in the\ntwo-dimensional H\\'enon map at the classical parameters. The task is to\ndetermine whether a trajectory will exceed a threshold after a set number of\ntime steps into the future. This task has a geometric interpretation within the\ndynamics of the H\\'enon map, which we use to gauge the performance of the\nneural networks that are used in this work. We analyze the dependence of the\nsuccess rate of the ML models on the prediction time $T$ , the number of\ntraining samples $N_T$ and the size of the network $N_p$. We observe that in\norder to maintain a certain accuracy, $N_T \\propto exp(2 h T)$ and $N_p \\propto\nexp(hT)$, where $h$ is the topological entropy. Similar relations between the\nintrinsic chaotic properties of the dynamics and ML parameters might be\nobservable in other systems as well.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 15:56:20 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Lellep", "Martin", ""], ["Prexl", "Jonathan", ""], ["Linkmann", "Moritz", ""], ["Eckhardt", "Bruno", ""]]}, {"id": "2002.10269", "submitter": "Mojgan Mohajer Dr.", "authors": "Mojgan Mohajer", "title": "A Graph-Based Platform for Customer Behavior Analysis using\n  Applications' Clickstream Data", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickstream analysis is getting more attention since the increase of usage in\ne-commerce and applications. Beside customers' purchase behavior analysis,\nthere is also attempt to analyze the customer behavior in relation to the\nquality of web or application design. In general, clickstream data can be\nconsidered as a sequence of log events collected at different levels of web/app\nusage. The analysis of clickstream data can be performed directly as sequence\nanalysis or by extracting features from sequences. In this work, we show how\nrepresenting and saving the sequences with their underlying graph structures\ncan induce a platform for customer behavior analysis. Our main idea is that\nclickstream data containing sequences of actions of an application, are walks\nof the corresponding finite state automaton (FSA) of that application. Our\nhypothesis is that the customers of an application normally do not use all\npossible walks through that FSA and the number of actual walks is much smaller\nthan total number of possible walks through the FSA. Sequences of such a walk\nnormally consist of a finite number of cycles on FSA graphs. Identifying and\nmatching these cycles in the classical sequence analysis is not straight\nforward. We show that representing the sequences through their underlying graph\nstructures not only groups the sequences automatically but also provides a\ncompressed data representation of the original sequences.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 13:57:29 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Mohajer", "Mojgan", ""]]}, {"id": "2002.10271", "submitter": "Wittawat Jitkrittum", "authors": "Wittawat Jitkrittum, Heishiro Kanagawa, Bernhard Sch\\\"olkopf", "title": "Testing Goodness of Fit of Conditional Density Models with Kernels", "comments": "In UAI 2020. http://auai.org/uai2020/accepted.php", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonparametric statistical tests of goodness of fit for\nconditional distributions: given a conditional probability density function\n$p(y|x)$ and a joint sample, decide whether the sample is drawn from\n$p(y|x)r_x(x)$ for some density $r_x$. Our tests, formulated with a Stein\noperator, can be applied to any differentiable conditional density model, and\nrequire no knowledge of the normalizing constant. We show that 1) our tests are\nconsistent against any fixed alternative conditional model; 2) the statistics\ncan be estimated easily, requiring no density estimation as an intermediate\nstep; and 3) our second test offers an interpretable test result providing\ninsight on where the conditional model does not fit well in the domain of the\ncovariate. We demonstrate the interpretability of our test on a task of\nmodeling the distribution of New York City's taxi drop-off location given a\npick-up point. To our knowledge, our work is the first to propose such\nconditional goodness-of-fit tests that simultaneously have all these desirable\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:04:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:27:09 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jitkrittum", "Wittawat", ""], ["Kanagawa", "Heishiro", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2002.10286", "submitter": "Idan Amir", "authors": "Idan Amir, Idan Attias, Tomer Koren, Roi Livni, Yishay Mansour", "title": "Prediction with Corrupted Expert Advice", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": "Conference on Neural Information Processing Systems 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the fundamental problem of prediction with expert advice, in a\nsetting where the environment is benign and generates losses stochastically,\nbut the feedback observed by the learner is subject to a moderate adversarial\ncorruption. We prove that a variant of the classical Multiplicative Weights\nalgorithm with decreasing step sizes achieves constant regret in this setting\nand performs optimally in a wide range of environments, regardless of the\nmagnitude of the injected corruption. Our results reveal a surprising disparity\nbetween the often comparable Follow the Regularized Leader (FTRL) and Online\nMirror Descent (OMD) frameworks: we show that for experts in the corrupted\nstochastic regime, the regret performance of OMD is in fact strictly inferior\nto that of FTRL.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:39:55 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 20:17:11 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Amir", "Idan", ""], ["Attias", "Idan", ""], ["Koren", "Tomer", ""], ["Livni", "Roi", ""], ["Mansour", "Yishay", ""]]}, {"id": "2002.10290", "submitter": "Alessandro Pastore", "authors": "Marco Carnini and Alessandro Pastore", "title": "Trees and Forests in Nuclear Physics", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6471/ab92e3", "report-no": null, "categories": "nucl-th cs.LG nucl-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple introduction to the decision tree algorithm using some\nexamples from nuclear physics. We show how to improve the accuracy of the\nclassical liquid drop nuclear mass model by performing Feature Engineering with\na decision tree. Finally, we apply the method to the Duflo-Zuker model showing\nthat, despite their simplicity, decision trees are capable of improving the\ndescription of nuclear masses using a limited number of free parameters.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:47:33 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 12:55:26 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Carnini", "Marco", ""], ["Pastore", "Alessandro", ""]]}, {"id": "2002.10295", "submitter": "David P\\\"atzel", "authors": "Michael Heider and David P\\\"atzel and J\\\"org H\\\"ahner", "title": "SupRB: A Supervised Rule-based Learning System for Continuous Problems", "comments": "Submitted to the Genetic and Evolutionary Computation Conference 2020\n  (GECCO 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the SupRB learning system, a new Pittsburgh-style learning\nclassifier system (LCS) for supervised learning on multi-dimensional continuous\ndecision problems. SupRB learns an approximation of a quality function from\nexamples (consisting of situations, choices and associated qualities) and is\nthen able to make an optimal choice as well as predict the quality of a choice\nin a given situation. One area of application for SupRB is parametrization of\nindustrial machinery. In this field, acceptance of the recommendations of\nmachine learning systems is highly reliant on operators' trust. While an\nessential and much-researched ingredient for that trust is prediction quality,\nit seems that this alone is not enough. At least as important is a\nhuman-understandable explanation of the reasoning behind a recommendation.\nWhile many state-of-the-art methods such as artificial neural networks fall\nshort of this, LCSs such as SupRB provide human-readable rules that can be\nunderstood very easily. The prevalent LCSs are not directly applicable to this\nproblem as they lack support for continuous choices. This paper lays the\nfoundations for SupRB and shows its general applicability on a simplified model\nof an additive manufacturing problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 14:54:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Heider", "Michael", ""], ["P\u00e4tzel", "David", ""], ["H\u00e4hner", "J\u00f6rg", ""]]}, {"id": "2002.10301", "submitter": "Adithya M Devraj", "authors": "Adithya M. Devraj and Sean P. Meyn", "title": "Q-learning with Uniformly Bounded Variance: Large Discounting is Not a\n  Barrier to Fast Learning", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample complexity bounds are a common performance metric in the Reinforcement\nLearning literature. In the discounted cost, infinite horizon setting, all of\nthe known bounds have a factor that is a polynomial in $1/(1-\\gamma)$, where\n$\\gamma < 1$ is the discount factor. For a large discount factor, these bounds\nseem to imply that a very large number of samples is required to achieve an\n$\\varepsilon$-optimal policy. The objective of the present work is to introduce\na new class of algorithms that have sample complexity uniformly bounded for all\n$\\gamma < 1$. One may argue that this is impossible, due to a recent min-max\nlower bound. The explanation is that this previous lower bound is for a\nspecific problem, which we modify, without compromising the ultimate objective\nof obtaining an $\\varepsilon$-optimal policy. Specifically, we show that the\nasymptotic covariance of the Q-learning algorithm with an optimized step-size\nsequence is a quadratic function of $1/(1-\\gamma)$; an expected, and\nessentially known result. The new relative Q-learning algorithm proposed here\nis shown to have asymptotic covariance that is a quadratic in $1/(1- \\rho^*\n\\gamma)$, where $1 - \\rho^* > 0$ is an upper bound on the spectral gap of an\noptimal transition matrix.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:12:41 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 21:58:23 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Devraj", "Adithya M.", ""], ["Meyn", "Sean P.", ""]]}, {"id": "2002.10306", "submitter": "Indro Spinelli", "authors": "Indro Spinelli, Simone Scardapane, Aurelio Uncini", "title": "Adaptive Propagation Graph Convolutional Network", "comments": "Published in IEEE Transaction on Neural Networks and Learning Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.3025110", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) are a family of neural network models\nthat perform inference on graph data by interleaving vertex-wise operations and\nmessage-passing exchanges across nodes. Concerning the latter, two key\nquestions arise: (i) how to design a differentiable exchange protocol (e.g., a\n1-hop Laplacian smoothing in the original GCN), and (ii) how to characterize\nthe trade-off in complexity with respect to the local updates. In this paper,\nwe show that state-of-the-art results can be achieved by adapting the number of\ncommunication steps independently at every node. In particular, we endow each\nnode with a halting unit (inspired by Graves' adaptive computation time) that\nafter every exchange decides whether to continue communicating or not. We show\nthat the proposed adaptive propagation GCN (AP-GCN) achieves superior or\nsimilar results to the best proposed models so far on a number of benchmarks,\nwhile requiring a small overhead in terms of additional parameters. We also\ninvestigate a regularization term to enforce an explicit trade-off between\ncommunication and accuracy. The code for the AP-GCN experiments is released as\nan open-source library.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:31:16 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 18:28:25 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 09:28:34 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Spinelli", "Indro", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2002.10309", "submitter": "Badri Narayana Patro", "authors": "Badri N. Patro, Mayank Lunayach and Vinay P. Namboodiri", "title": "Uncertainty based Class Activation Maps for Visual Question Answering", "comments": "This work is an extension of our ICCV-2019 work. arXiv admin note:\n  text overlap with arXiv:1908.06306", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding and explaining deep learning models is an imperative task.\nTowards this, we propose a method that obtains gradient-based certainty\nestimates that also provide visual attention maps. Particularly, we solve for\nvisual question answering task. We incorporate modern probabilistic deep\nlearning methods that we further improve by using the gradients for these\nestimates. These have two-fold benefits: a) improvement in obtaining the\ncertainty estimates that correlate better with misclassified samples and b)\nimproved attention maps that provide state-of-the-art results in terms of\ncorrelation with human attention regions. The improved attention maps result in\nconsistent improvement for various methods for visual question answering.\nTherefore, the proposed technique can be thought of as a recipe for obtaining\nimproved certainty estimates and explanations for deep learning models. We\nprovide detailed empirical analysis for the visual question answering task on\nall standard benchmarks and comparison with state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:54:19 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Patro", "Badri N.", ""], ["Lunayach", "Mayank", ""], ["Namboodiri", "Vinay P.", ""]]}, {"id": "2002.10312", "submitter": "Anian Ruoss", "authors": "Anian Ruoss, Mislav Balunovi\\'c, Marc Fischer, and Martin Vechev", "title": "Learning Certified Individually Fair Representations", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair representation learning provides an effective way of enforcing fairness\nconstraints without compromising utility for downstream users. A desirable\nfamily of such fairness constraints, each requiring similar treatment for\nsimilar individuals, is known as individual fairness. In this work, we\nintroduce the first method that enables data consumers to obtain certificates\nof individual fairness for existing and new data points. The key idea is to map\nsimilar individuals to close latent representations and leverage this latent\nproximity to certify individual fairness. That is, our method enables the data\nproducer to learn and certify a representation where for a data point all\nsimilar individuals are at $\\ell_\\infty$-distance at most $\\epsilon$, thus\nallowing data consumers to certify individual fairness by proving\n$\\epsilon$-robustness of their classifier. Our experimental evaluation on five\nreal-world datasets and several fairness constraints demonstrates the\nexpressivity and scalability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:41:34 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:17:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Ruoss", "Anian", ""], ["Balunovi\u0107", "Mislav", ""], ["Fischer", "Marc", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.10316", "submitter": "Wei Tang", "authors": "Wei Tang, Chien-Ju Ho, Yang Liu", "title": "Bandit Learning with Delayed Impact of Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic multi-armed bandit (MAB) problem with delayed impact\nof actions. In our setting, actions taken in the past impact the arm rewards in\nthe subsequent future. This delayed impact of actions is prevalent in the real\nworld. For example, the capability to pay back a loan for people in a certain\nsocial group might depend on historically how frequently that group has been\napproved loan applications. If banks keep rejecting loan applications to people\nin a disadvantaged group, it could create a feedback loop and further damage\nthe chance of getting loans for people in that group. In this paper, we\nformulate this delayed and long-term impact of actions within the context of\nmulti-armed bandits. We generalize the classical bandit setting to encode the\ndependency of this \"bias\" due to the action history during learning. The goal\nis to maximize the collected utilities over time while taking into account the\ndynamics created by the delayed impacts of historical actions. We propose an\nalgorithm that achieves a regret of $\\tilde{\\mathcal{O}}(KT^{2/3})$ and show a\nmatching regret lower bound of $\\Omega(KT^{2/3})$, where $K$ is the number of\narms and $T$ is the learning horizon. Our results complement the bandit\nliterature by adding techniques to deal with actions with long-term impacts and\nhave implications in designing fair algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:43:03 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 17:13:13 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 19:28:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Tang", "Wei", ""], ["Ho", "Chien-Ju", ""], ["Liu", "Yang", ""]]}, {"id": "2002.10319", "submitter": "Lang Huang", "authors": "Lang Huang, Chao Zhang, Hongyang Zhang", "title": "Self-Adaptive Training: beyond Empirical Risk Minimization", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose self-adaptive training---a new training algorithm that dynamically\ncorrects problematic training labels by model predictions without incurring\nextra computational cost---to improve generalization of deep learning for\npotentially corrupted training data. This problem is crucial towards robustly\nlearning from data that are corrupted by, e.g., label noises and\nout-of-distribution samples. The standard empirical risk minimization (ERM) for\nsuch data, however, may easily overfit noises and thus suffers from sub-optimal\nperformance. In this paper, we observe that model predictions can substantially\nbenefit the training process: self-adaptive training significantly improves\ngeneralization over ERM under various levels of noises, and mitigates the\noverfitting issue in both natural and adversarial training. We evaluate the\nerror-capacity curve of self-adaptive training: the test error is monotonously\ndecreasing w.r.t. model capacity. This is in sharp contrast to the\nrecently-discovered double-descent phenomenon in ERM which might be a result of\noverfitting of noises. Experiments on CIFAR and ImageNet datasets verify the\neffectiveness of our approach in two applications: classification with label\nnoise and selective classification. We release our code at\nhttps://github.com/LayneH/self-adaptive-training.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:47:10 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:14:50 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Huang", "Lang", ""], ["Zhang", "Chao", ""], ["Zhang", "Hongyang", ""]]}, {"id": "2002.10330", "submitter": "Francisco Arag\\'on-Roy\\'on", "authors": "F. Arag\\'on-Roy\\'on, A. Jim\\'enez-V\\'ilchez, A. Arauzo-Azofra, J. M.\n  Ben\\'itez", "title": "FSinR: an exhaustive package for feature selection", "comments": "17 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature Selection (FS) is a key task in Machine Learning. It consists in\nselecting a number of relevant variables for the model construction or data\nanalysis. We present the R package, FSinR, which implements a variety of widely\nknown filter and wrapper methods, as well as search algorithms. Thus, the\npackage provides the possibility to perform the feature selection process,\nwhich consists in the combination of a guided search on the subsets of features\nwith the filter or wrapper methods that return an evaluation measure of those\nsubsets. In this article, we also present some examples on the usage of the\npackage and a comparison with other packages available in R that contain\nmethods for feature selection.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 15:59:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Arag\u00f3n-Roy\u00f3n", "F.", ""], ["Jim\u00e9nez-V\u00edlchez", "A.", ""], ["Arauzo-Azofra", "A.", ""], ["Ben\u00edtez", "J. M.", ""]]}, {"id": "2002.10336", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu, Ann Lee, Gabriel Synnaeve, Awni Hannun", "title": "Semi-Supervised Speech Recognition via Local Prior Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For sequence transduction tasks like speech recognition, a strong structured\nprior model encodes rich information about the target space, implicitly ruling\nout invalid sequences by assigning them low probability. In this work, we\npropose local prior matching (LPM), a semi-supervised objective that distills\nknowledge from a strong prior (e.g. a language model) to provide learning\nsignal to a discriminative model trained on unlabeled speech. We demonstrate\nthat LPM is theoretically well-motivated, simple to implement, and superior to\nexisting knowledge distillation techniques under comparable settings. Starting\nfrom a baseline trained on 100 hours of labeled speech, with an additional 360\nhours of unlabeled data, LPM recovers 54% and 73% of the word error rate on\nclean and noisy test sets relative to a fully supervised model on the same\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:07:11 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Lee", "Ann", ""], ["Synnaeve", "Gabriel", ""], ["Hannun", "Awni", ""]]}, {"id": "2002.10345", "submitter": "Yige Xu", "authors": "Yige Xu, Xipeng Qiu, Ligao Zhou, Xuanjing Huang", "title": "Improving BERT Fine-Tuning via Self-Ensemble and Self-Distillation", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning pre-trained language models like BERT has become an effective way\nin NLP and yields state-of-the-art results on many downstream tasks. Recent\nstudies on adapting BERT to new tasks mainly focus on modifying the model\nstructure, re-designing the pre-train tasks, and leveraging external data and\nknowledge. The fine-tuning strategy itself has yet to be fully explored. In\nthis paper, we improve the fine-tuning of BERT with two effective mechanisms:\nself-ensemble and self-distillation. The experiments on text classification and\nnatural language inference tasks show our proposed methods can significantly\nimprove the adaption of BERT without any external data or knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:17:12 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Xu", "Yige", ""], ["Qiu", "Xipeng", ""], ["Zhou", "Ligao", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2002.10349", "submitter": "Giuseppe Ughi", "authors": "Giuseppe Ughi, Vinayak Abrol, Jared Tanner", "title": "A Model-Based Derivative-Free Approach to Black-Box Adversarial\n  Examples: BOBYQA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that model-based derivative free optimisation algorithms can\ngenerate adversarial targeted misclassification of deep networks using fewer\nnetwork queries than non-model-based methods. Specifically, we consider the\nblack-box setting, and show that the number of networks queries is less\nimpacted by making the task more challenging either through reducing the\nallowed $\\ell^{\\infty}$ perturbation energy or training the network with\ndefences against adversarial misclassification. We illustrate this by\ncontrasting the BOBYQA algorithm with the state-of-the-art model-free\nadversarial targeted misclassification approaches based on genetic,\ncombinatorial, and direct-search algorithms. We observe that for high\n$\\ell^{\\infty}$ energy perturbations on networks, the aforementioned simpler\nmodel-free methods require the fewest queries. In contrast, the proposed BOBYQA\nbased method achieves state-of-the-art results when the perturbation energy\ndecreases, or if the network is trained against adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:23:09 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ughi", "Giuseppe", ""], ["Abrol", "Vinayak", ""], ["Tanner", "Jared", ""]]}, {"id": "2002.10365", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and David J. Schwab and Ari S. Morcos", "title": "The Early Phase of Neural Network Training", "comments": "ICLR 2020 Camera Ready. Available on OpenReview at\n  https://openreview.net/forum?id=Hkl1iRNFwS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that many important aspects of neural network\nlearning take place within the very earliest iterations or epochs of training.\nFor example, sparse, trainable sub-networks emerge (Frankle et al., 2019),\ngradient descent moves into a small subspace (Gur-Ari et al., 2018), and the\nnetwork undergoes a critical period (Achille et al., 2019). Here, we examine\nthe changes that deep neural networks undergo during this early phase of\ntraining. We perform extensive measurements of the network state during these\nearly iterations of training and leverage the framework of Frankle et al.\n(2019) to quantitatively probe the weight distribution and its reliance on\nvarious aspects of the dataset. We find that, within this framework, deep\nnetworks are not robust to reinitializing with random weights while maintaining\nsigns, and that weight distributions are highly non-independent even after only\na few hundred iterations. Despite this behavior, pre-training with blurred\ninputs or an auxiliary self-supervised task can approximate the changes in\nsupervised networks, suggesting that these changes are not inherently\nlabel-dependent, though labels significantly accelerate this process. Together,\nthese results help to elucidate the network changes occurring during this\npivotal initial period of learning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 16:51:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Frankle", "Jonathan", ""], ["Schwab", "David J.", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2002.10375", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier, Benjamin\n  Piwowarski, Jacopo Staiano", "title": "Discriminative Adversarial Search for Abstractive Summarization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach for sequence decoding, Discriminative\nAdversarial Search (DAS), which has the desirable properties of alleviating the\neffects of exposure bias without requiring external metrics. Inspired by\nGenerative Adversarial Networks (GANs), wherein a discriminator is used to\nimprove the generator, our method differs from GANs in that the generator\nparameters are not updated at training time and the discriminator is only used\nto drive sequence generation at inference time.\n  We investigate the effectiveness of the proposed approach on the task of\nAbstractive Summarization: the results obtained show that a naive application\nof DAS improves over the state-of-the-art methods, with further gains obtained\nvia discriminator retraining. Moreover, we show how DAS can be effective for\ncross-domain adaptation. Finally, all results reported are obtained without\nadditional rule-based filtering strategies, commonly used by the best\nperforming systems available: this indicates that DAS can effectively be\ndeployed without relying on post-hoc modifications of the generated outputs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:07:32 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 07:21:53 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Scialom", "Thomas", ""], ["Dray", "Paul-Alexis", ""], ["Lamprier", "Sylvain", ""], ["Piwowarski", "Benjamin", ""], ["Staiano", "Jacopo", ""]]}, {"id": "2002.10376", "submitter": "Guillaume Leclerc", "authors": "Guillaume Leclerc, Aleksander Madry", "title": "The Two Regimes of Deep Network Training", "comments": "14 pages (5 of appendix), 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate schedule has a major impact on the performance of deep learning\nmodels. Still, the choice of a schedule is often heuristical. We aim to develop\na precise understanding of the effects of different learning rate schedules and\nthe appropriate way to select them. To this end, we isolate two distinct phases\nof training, the first, which we refer to as the \"large-step\" regime, exhibits\na rather poor performance from an optimization point of view but is the primary\ncontributor to model generalization; the latter, \"small-step\" regime exhibits\nmuch more \"convex-like\" optimization behavior but used in isolation produces\nmodels that generalize poorly. We find that by treating these regimes\nseparately-and em specializing our training algorithm to each one of them, we\ncan significantly simplify learning rate schedules.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:08:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Leclerc", "Guillaume", ""], ["Madry", "Aleksander", ""]]}, {"id": "2002.10378", "submitter": "Shanshan Qin", "authors": "Shanshan Qin, Nayantara Mudur and Cengiz Pehlevan", "title": "Contrastive Similarity Matching for Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel biologically-plausible solution to the credit assignment\nproblem motivated by observations in the ventral visual pathway and trained\ndeep neural networks. In both, representations of objects in the same category\nbecome progressively more similar, while objects belonging to different\ncategories become less similar. We use this observation to motivate a\nlayer-specific learning goal in a deep network: each layer aims to learn a\nrepresentational similarity matrix that interpolates between previous and later\nlayers. We formulate this idea using a contrastive similarity matching\nobjective function and derive from it deep neural networks with feedforward,\nlateral, and feedback connections, and neurons that exhibit\nbiologically-plausible Hebbian and anti-Hebbian plasticity. Contrastive\nsimilarity matching can be interpreted as an energy-based learning algorithm,\nbut with significant differences from others in how a contrastive function is\nconstructed.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:10:21 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:48:47 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 16:56:36 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2020 14:21:49 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 02:09:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Qin", "Shanshan", ""], ["Mudur", "Nayantara", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2002.10384", "submitter": "Nikola Konstantinov", "authors": "Nikola Konstantinov, Elias Frantar, Dan Alistarh, Christoph H. Lampert", "title": "On the Sample Complexity of Adversarial Multi-Source PAC Learning", "comments": "International Conference on Machine Learning (ICML) 2020:\n  Camera-ready. Strengthened the definition of adversarial PAC-learnability,\n  added explicit bounds on sample complexity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning from multiple untrusted data sources, a\nscenario of increasing practical relevance given the recent emergence of\ncrowdsourcing and collaborative learning paradigms. Specifically, we analyze\nthe situation in which a learning system obtains datasets from multiple\nsources, some of which might be biased or even adversarially perturbed. It is\nknown that in the single-source case, an adversary with the power to corrupt a\nfixed fraction of the training data can prevent PAC-learnability, that is, even\nin the limit of infinitely much training data, no learning system can approach\nthe optimal test error. In this work we show that, surprisingly, the same is\nnot true in the multi-source setting, where the adversary can arbitrarily\ncorrupt a fixed fraction of the data sources. Our main results are a\ngeneralization bound that provides finite-sample guarantees for this learning\nsetting, as well as corresponding lower bounds. Besides establishing\nPAC-learnability our results also show that in a cooperative learning setting\nsharing data with other parties has provable benefits, even if some\nparticipants are malicious.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:19:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:22:51 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Konstantinov", "Nikola", ""], ["Frantar", "Elias", ""], ["Alistarh", "Dan", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2002.10385", "submitter": "Ben Moews", "authors": "Ben Moews and Gbenga Ibikunle", "title": "Predictive intraday correlations in stable and volatile market\n  environments: Evidence from deep learning", "comments": "15 pages, 6 figures, preprint submitted to Physica A", "journal-ref": null, "doi": "10.1016/j.physa.2020.124392", "report-no": null, "categories": "q-fin.CP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods and theories in finance can be ill-equipped to capture\nhighly non-linear interactions in financial prediction problems based on\nlarge-scale datasets, with deep learning offering a way to gain insights into\ncorrelations in markets as complex systems. In this paper, we apply deep\nlearning to econometrically constructed gradients to learn and exploit lagged\ncorrelations among S&P 500 stocks to compare model behaviour in stable and\nvolatile market environments, and under the exclusion of target stock\ninformation for predictions. In order to measure the effect of time horizons,\nwe predict intraday and daily stock price movements in varying interval lengths\nand gauge the complexity of the problem at hand with a modification of our\nmodel architecture. Our findings show that accuracies, while remaining\nsignificant and demonstrating the exploitability of lagged correlations in\nstock markets, decrease with shorter prediction horizons. We discuss\nimplications for modern finance theory and our work's applicability as an\ninvestigative tool for portfolio managers. Lastly, we show that our model's\nperformance is consistent in volatile markets by exposing it to the environment\nof the recent financial crisis of 2007/2008.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:19:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Moews", "Ben", ""], ["Ibikunle", "Gbenga", ""]]}, {"id": "2002.10389", "submitter": "Renqian Luo", "authors": "Renqian Luo, Xu Tan, Rui Wang, Tao Qin, Enhong Chen, Tie-Yan Liu", "title": "Semi-Supervised Neural Architecture Search", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) relies on a good controller to generate\nbetter architectures or predict the accuracy of given architectures. However,\ntraining the controller requires both abundant and high-quality pairs of\narchitectures and their accuracy, while it is costly to evaluate an\narchitecture and obtain its accuracy. In this paper, we propose SemiNAS, a\nsemi-supervised NAS approach that leverages numerous unlabeled architectures\n(without evaluation and thus nearly no cost). Specifically, SemiNAS 1) trains\nan initial accuracy predictor with a small set of architecture-accuracy data\npairs; 2) uses the trained accuracy predictor to predict the accuracy of large\namount of architectures (without evaluation); and 3) adds the generated data\npairs to the original data to further improve the predictor. The trained\naccuracy predictor can be applied to various NAS algorithms by predicting the\naccuracy of candidate architectures for them. SemiNAS has two advantages: 1) It\nreduces the computational cost under the same accuracy guarantee. On\nNASBench-101 benchmark dataset, it achieves comparable accuracy with\ngradient-based method while using only 1/7 architecture-accuracy pairs. 2) It\nachieves higher accuracy under the same computational cost. It achieves 94.02%\ntest accuracy on NASBench-101, outperforming all the baselines when using the\nsame number of architectures. On ImageNet, it achieves 23.5% top-1 error rate\n(under 600M FLOPS constraint) using 4 GPU-days for search. We further apply it\nto LJSpeech text to speech task and it achieves 97% intelligibility rate in the\nlow-resource setting and 15% test error rate in the robustness setting, with\n9%, 7% improvements over the baseline respectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:23:00 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 16:20:23 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 06:52:02 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 09:44:09 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Luo", "Renqian", ""], ["Tan", "Xu", ""], ["Wang", "Rui", ""], ["Qin", "Tao", ""], ["Chen", "Enhong", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2002.10394", "submitter": "Gr\\'egoire Jauvion", "authors": "Gr\\'egoire Jauvion, Thibaut Cassard, Boris Quennehen, David Lissmyr", "title": "DeepPlume: Very High Resolution Real-Time Air Quality Mapping", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an engine able to predict jointly the real-time\nconcentration of the main pollutants harming people's health: nitrogen dioxyde\n(NO2), ozone (O3) and particulate matter (PM2.5 and PM10, which are\nrespectively the particles whose size are below 2.5 um and 10 um).\n  The engine covers a large part of the world and is fed with real-time\nofficial stations measures, atmospheric models' forecasts, land cover data,\nroad networks and traffic estimates to produce predictions with a very high\nresolution in the range of a few dozens of meters. This resolution makes the\nengine adapted to very innovative applications like street-level air quality\nmapping or air quality adjusted routing.\n  Plume Labs has deployed a similar prediction engine to build several products\naiming at providing air quality data to individuals and businesses. For the\nsake of clarity and reproducibility, the engine presented here has been built\nspecifically for this paper and differs quite significantly from the one used\nin Plume Labs' products. A major difference is in the data sources feeding the\nengine: in particular, this prediction engine does not include mobile sensors\nmeasurements.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:05:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jauvion", "Gr\u00e9goire", ""], ["Cassard", "Thibaut", ""], ["Quennehen", "Boris", ""], ["Lissmyr", "David", ""]]}, {"id": "2002.10399", "submitter": "Niccol\\`o Dalmasso", "authors": "Niccol\\`o Dalmasso and Rafael Izbicki and Ann B. Lee", "title": "Confidence Sets and Hypothesis Testing in a Likelihood-Free Inference\n  Setting", "comments": "20 pages, 8 figures, 6 tables, 4 algorithm boxes", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:2323-2334, 2020", "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation, statistical tests and confidence sets are the\ncornerstones of classical statistics that allow scientists to make inferences\nabout the underlying process that generated the observed data. A key question\nis whether one can still construct hypothesis tests and confidence sets with\nproper coverage and high power in a so-called likelihood-free inference (LFI)\nsetting; that is, a setting where the likelihood is not explicitly known but\none can forward-simulate observable data according to a stochastic model. In\nthis paper, we present $\\texttt{ACORE}$ (Approximate Computation via Odds Ratio\nEstimation), a frequentist approach to LFI that first formulates the classical\nlikelihood ratio test (LRT) as a parametrized classification problem, and then\nuses the equivalence of tests and confidence sets to build confidence regions\nfor parameters of interest. We also present a goodness-of-fit procedure for\nchecking whether the constructed tests and confidence regions are valid.\n$\\texttt{ACORE}$ is based on the key observation that the LRT statistic, the\nrejection probability of the test, and the coverage of the confidence set are\nconditional distribution functions which often vary smoothly as a function of\nthe parameters of interest. Hence, instead of relying solely on samples\nsimulated at fixed parameter settings (as is the convention in standard Monte\nCarlo solutions), one can leverage machine learning tools and data simulated in\nthe neighborhood of a parameter to improve estimates of quantities of interest.\nWe demonstrate the efficacy of $\\texttt{ACORE}$ with both theoretical and\nempirical results. Our implementation is available on Github.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:34:49 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 02:56:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Izbicki", "Rafael", ""], ["Lee", "Ann B.", ""]]}, {"id": "2002.10400", "submitter": "Shashank Rajput", "authors": "Shashank Rajput, Anant Gupta and Dimitris Papailiopoulos", "title": "Closing the convergence gap of SGD without replacement", "comments": "Simplified some proofs and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent without replacement sampling is widely used in\npractice for model training. However, the vast majority of SGD analyses assumes\ndata is sampled with replacement, and when the function minimized is strongly\nconvex, an $\\mathcal{O}\\left(\\frac{1}{T}\\right)$ rate can be established when\nSGD is run for $T$ iterations. A recent line of breakthrough works on SGD\nwithout replacement (SGDo) established an\n$\\mathcal{O}\\left(\\frac{n}{T^2}\\right)$ convergence rate when the function\nminimized is strongly convex and is a sum of $n$ smooth functions, and an\n$\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^3}{T^3}\\right)$ rate for sums of\nquadratics. On the other hand, the tightest known lower bound postulates an\n$\\Omega\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ rate, leaving open the\npossibility of better SGDo convergence rates in the general case. In this\npaper, we close this gap and show that SGD without replacement achieves a rate\nof $\\mathcal{O}\\left(\\frac{1}{T^2}+\\frac{n^2}{T^3}\\right)$ when the sum of the\nfunctions is a quadratic, and offer a new lower bound of\n$\\Omega\\left(\\frac{n}{T^2}\\right)$ for strongly convex functions that are sums\nof smooth functions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:37:28 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 18:32:00 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 00:11:01 GMT"}, {"version": "v4", "created": "Wed, 29 Apr 2020 17:37:19 GMT"}, {"version": "v5", "created": "Wed, 1 Jul 2020 01:26:54 GMT"}, {"version": "v6", "created": "Thu, 9 Jul 2020 14:18:03 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Rajput", "Shashank", ""], ["Gupta", "Anant", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "2002.10404", "submitter": "Myun-Seok Cheon", "authors": "Myun-Seok Cheon", "title": "An Outer-approximation Guided Optimization Approach for Constrained\n  Neural Network Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an outer-approximation guided optimization method for\nconstrained neural network inverse problems with rectified linear units. The\nconstrained neural network inverse problems refer to an optimization problem to\nfind the best set of input values of a given trained neural network in order to\nproduce a predefined desired output in presence of constraints on input values.\nThis paper analyzes the characteristics of optimal solutions of neural network\ninverse problems with rectified activation units and proposes an\nouter-approximation algorithm by exploiting their characteristics. The proposed\nouter-approximation guided optimization comprises primal and dual phases. The\nprimal phase incorporates neighbor curvatures with neighbor\nouter-approximations to expedite the process. The dual phase identifies and\nutilizes the structure of local convex regions to improve the convergence to a\nlocal optimal solution. At last, computation experiments demonstrate the\nsuperiority of the proposed algorithm compared to a projected gradient method.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:49:24 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Cheon", "Myun-Seok", ""]]}, {"id": "2002.10410", "submitter": "Alessandro De Palma", "authors": "Rudy Bunel, Alessandro De Palma, Alban Desmaison, Krishnamurthy\n  Dvijotham, Pushmeet Kohli, Philip H.S. Torr, M. Pawan Kumar", "title": "Lagrangian Decomposition for Neural Network Verification", "comments": "UAI 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental component of neural network verification is the computation of\nbounds on the values their outputs can take. Previous methods have either used\noff-the-shelf solvers, discarding the problem structure, or relaxed the problem\neven further, making the bounds unnecessarily loose. We propose a novel\napproach based on Lagrangian Decomposition. Our formulation admits an efficient\nsupergradient ascent algorithm, as well as an improved proximal algorithm. Both\nthe algorithms offer three advantages: (i) they yield bounds that are provably\nat least as tight as previous dual algorithms relying on Lagrangian\nrelaxations; (ii) they are based on operations analogous to forward/backward\npass of neural networks layers and are therefore easily parallelizable,\namenable to GPU implementation and able to take advantage of the convolutional\nstructure of problems; and (iii) they allow for anytime stopping while still\nproviding valid bounds. Empirically, we show that we obtain bounds comparable\nwith off-the-shelf solvers in a fraction of their running time, and obtain\ntighter bounds in the same time as previous dual algorithms. This results in an\noverall speed-up when employing the bounds for formal verification. Code for\nour algorithms is available at\nhttps://github.com/oval-group/decomposition-plnn-bounds.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:55:10 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 18:00:02 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 17:49:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Bunel", "Rudy", ""], ["De Palma", "Alessandro", ""], ["Desmaison", "Alban", ""], ["Dvijotham", "Krishnamurthy", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Kumar", "M. Pawan", ""]]}, {"id": "2002.10411", "submitter": "Y. A. Joarder", "authors": "Y. A. Joarder, Emran Hossain and Al Faisal Mahmud", "title": "Clustering and Classification with Non-Existence Attributes: A Sentenced\n  Discrepancy Measure Based Technique", "comments": "30 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For some or all of the data instances a number of independent-world\nclustering issues suffer from incomplete data characterization due to losing or\nabsent attributes. Typical clustering approaches cannot be applied directly to\nsuch data unless pre-processing by techniques like imputation or\nmarginalization. We have overcome this drawback by utilizing a Sentenced\nDiscrepancy Measure which we refer to as the Attribute Weighted Penalty based\nDiscrepancy (AWPD). Using the AWPD measure, we modified the K-MEANS++ and\nScalable K-MEANS++ for clustering algorithm and k Nearest Neighbor (kNN) for\nclassification so as to make them directly applicable to datasets with\nnon-existence attributes. We have presented a detailed theoretical analysis\nwhich shows that the new AWPD based K-MEANS++, Scalable K-MEANS++ and kNN\nalgorithm merge into a local prime among the number of iterations is finite. We\nhave reported in depth experiments on numerous benchmark datasets for various\nforms of Non-Existence showing that the projected clustering and classification\ntechniques usually show better results in comparison to some of the renowned\nimputation methods that are generally used to process such insufficient data.\nThis technique is designed to trace invaluable data to: directly apply our\nmethod on the datasets which have Non-Existence attributes and establish a\nmethod for detecting unstructured Non-Existence attributes with the best\naccuracy rate and minimum cost.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:56:06 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Joarder", "Y. A.", ""], ["Hossain", "Emran", ""], ["Mahmud", "Al Faisal", ""]]}, {"id": "2002.10413", "submitter": "Daniel Flam-Shepherd", "authors": "Daniel Flam-Shepherd, Tony Wu, Pascal Friederich and Alan Aspuru-Guzik", "title": "Neural Message Passing on High Order Paths", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural network have achieved impressive results in predicting molecular\nproperties, but they do not directly account for local and hidden structures in\nthe graph such as functional groups and molecular geometry. At each propagation\nstep, GNNs aggregate only over first order neighbours, ignoring important\ninformation contained in subsequent neighbours as well as the relationships\nbetween those higher order connections. In this work, we generalize graph\nneural nets to pass messages and aggregate across higher order paths. This\nallows for information to propagate over various levels and substructures of\nthe graph. We demonstrate our model on a few tasks in molecular property\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 17:58:02 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Flam-Shepherd", "Daniel", ""], ["Wu", "Tony", ""], ["Friederich", "Pascal", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2002.10420", "submitter": "Fahad Sohrab", "authors": "Fahad Sohrab, Jenni Raitoharju", "title": "Boosting rare benthic macroinvertebrates taxa identification with\n  one-class classification", "comments": "5 pages, 1 figure, 2 tables", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308359", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insect monitoring is crucial for understanding the consequences of rapid\necological changes, but taxa identification currently requires tedious manual\nexpert work and cannot be scaled-up efficiently. Deep convolutional neural\nnetworks (CNNs), provide a viable way to significantly increase the\nbiomonitoring volumes. However, taxa abundances are typically very imbalanced\nand the amounts of training images for the rarest classes are simply too low\nfor deep CNNs. As a result, the samples from the rare classes are often\ncompletely missed, while detecting them has biological importance. In this\npaper, we propose combining the trained deep CNN with one-class classifiers to\nimprove the rare species identification. One-class classification models are\ntraditionally trained with much fewer samples and they can provide a mechanism\nto indicate samples potentially belonging to the rare classes for human\ninspection. Our experiments confirm that the proposed approach may indeed\nsupport moving towards partial automation of the taxa identification task.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 09:46:24 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Sohrab", "Fahad", ""], ["Raitoharju", "Jenni", ""]]}, {"id": "2002.10433", "submitter": "Sebastian Risi", "authors": "Sebastian Risi and Mike Preuss", "title": "From Chess and Atari to StarCraft and Beyond: How Game AI is Driving the\n  World of AI", "comments": null, "journal-ref": "KI - Kuenstliche Intelligenz (2020)", "doi": "10.1007/s13218-020-00647-w", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the field of Game AI, which not only deals with creating\nagents that can play a certain game, but also with areas as diverse as creating\ngame content automatically, game analytics, or player modelling. While Game AI\nwas for a long time not very well recognized by the larger scientific\ncommunity, it has established itself as a research area for developing and\ntesting the most advanced forms of AI algorithms and articles covering advances\nin mastering video games such as StarCraft 2 and Quake III appear in the most\nprestigious journals. Because of the growth of the field, a single review\ncannot cover it completely. Therefore, we put a focus on important recent\ndevelopments, including that advances in Game AI are starting to be extended to\nareas outside of games, such as robotics or the synthesis of chemicals. In this\narticle, we review the algorithms and methods that have paved the way for these\nbreakthroughs, report on the other important areas of Game AI research, and\nalso point out exciting directions for the future of Game AI.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:28:54 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Risi", "Sebastian", ""], ["Preuss", "Mike", ""]]}, {"id": "2002.10435", "submitter": "Sitan Chen", "authors": "Sitan Chen, Jerry Li, Ankur Moitra", "title": "Learning Structured Distributions From Untrusted Batches: Faster and\n  Simpler", "comments": "37 pages, version 2 includes experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of learning from untrusted batches introduced by Qiao\nand Valiant [QV17]. Recently, Jain and Orlitsky [JO19] gave a simple\nsemidefinite programming approach based on the cut-norm that achieves\nessentially information-theoretically optimal error in polynomial time.\nConcurrently, Chen et al. [CLM19] considered a variant of the problem where\n$\\mu$ is assumed to be structured, e.g. log-concave, monotone hazard rate,\n$t$-modal, etc. In this case, it is possible to achieve the same error with\nsample complexity sublinear in $n$, and they exhibited a quasi-polynomial time\nalgorithm for doing so using Haar wavelets.\n  In this paper, we find an appealing way to synthesize the techniques of\n[JO19] and [CLM19] to give the best of both worlds: an algorithm which runs in\npolynomial time and can exploit structure in the underlying distribution to\nachieve sublinear sample complexity. Along the way, we simplify the approach of\n[JO19] by avoiding the need for SDP rounding and giving a more direct\ninterpretation of it through the lens of soft filtering, a powerful recent\ntechnique in high-dimensional robust estimation. We validate the usefulness of\nour algorithms in preliminary experimental evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:32:10 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 17:50:33 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Chen", "Sitan", ""], ["Li", "Jerry", ""], ["Moitra", "Ankur", ""]]}, {"id": "2002.10438", "submitter": "Vineel Nagisetty", "authors": "Vineel Nagisetty, Laura Graves, Joseph Scott and Vijay Ganesh", "title": "xAI-GAN: Enhancing Generative Adversarial Networks via Explainable AI\n  Systems", "comments": "7 pages (+ 2 page for reference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a revolutionary class of Deep\nNeural Networks (DNNs) that have been successfully used to generate realistic\nimages, music, text, and other data. However, GAN training presents many\nchallenges, notably it can be very resource-intensive. A potential weakness in\nGANs is that it requires a lot of data for successful training and data\ncollection can be an expensive process. Typically, the corrective feedback from\ndiscriminator DNNs to generator DNNs (namely, the discriminator's assessment of\nthe generated example) is calculated using only one real-numbered value (loss).\nBy contrast, we propose a new class of GAN we refer to as xAI-GAN that\nleverages recent advances in explainable AI (xAI) systems to provide a \"richer\"\nform of corrective feedback from discriminators to generators. Specifically, we\nmodify the gradient descent process using xAI systems that specify the reason\nas to why the discriminator made the classification it did, thus providing the\n\"richer\" corrective feedback that helps the generator to better fool the\ndiscriminator. Using our approach, we observe xAI-GANs provide an improvement\nof up to 23.18% in the quality of generated images on both MNIST and FMNIST\ndatasets over standard GANs as measured by Fr\\'echet Inception Distance (FID).\nWe further compare xAI-GAN trained on 20% of the data with standard GAN trained\non 100% of data on the CIFAR10 dataset and find that xAI-GAN still shows an\nimprovement in FID score. Further, we compare our work with Differentiable\nAugmentation - which has been shown to make GANs data-efficient - and show that\nxAI-GANs outperform GANs trained on Differentiable Augmentation. Moreover, both\ntechniques can be combined to produce even better results. Finally, we argue\nthat xAI-GAN enables users greater control over how models learn than standard\nGANs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:38:13 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 17:14:31 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Nagisetty", "Vineel", ""], ["Graves", "Laura", ""], ["Scott", "Joseph", ""], ["Ganesh", "Vijay", ""]]}, {"id": "2002.10444", "submitter": "Soham De", "authors": "Soham De, Samuel L. Smith", "title": "Batch Normalization Biases Residual Blocks Towards the Identity Function\n  in Deep Networks", "comments": "Camera-ready version of NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch normalization dramatically increases the largest trainable depth of\nresidual networks, and this benefit has been crucial to the empirical success\nof deep residual networks on a wide range of benchmarks. We show that this key\nbenefit arises because, at initialization, batch normalization downscales the\nresidual branch relative to the skip connection, by a normalizing factor on the\norder of the square root of the network depth. This ensures that, early in\ntraining, the function computed by normalized residual blocks in deep networks\nis close to the identity function (on average). We use this insight to develop\na simple initialization scheme that can train deep residual networks without\nnormalization. We also provide a detailed empirical study of residual networks,\nwhich clarifies that, although batch normalized networks can be trained with\nlarger learning rates, this effect is only beneficial in specific compute\nregimes, and has minimal benefits when the batch size is small.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:43:03 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 12:20:43 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 10:18:10 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["De", "Soham", ""], ["Smith", "Samuel L.", ""]]}, {"id": "2002.10445", "submitter": "Yedid Hoshen", "authors": "Liron Bergman and Niv Cohen and Yedid Hoshen", "title": "Deep Nearest Neighbor Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest neighbors is a successful and long-standing technique for anomaly\ndetection. Significant progress has been recently achieved by self-supervised\ndeep methods (e.g. RotNet). Self-supervised features however typically\nunder-perform Imagenet pre-trained features. In this work, we investigate\nwhether the recent progress can indeed outperform nearest-neighbor methods\noperating on an Imagenet pretrained feature space. The simple nearest-neighbor\nbased-approach is experimentally shown to outperform self-supervised methods\nin: accuracy, few shot generalization, training time and noise robustness while\nmaking fewer assumptions on image distributions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:51:33 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Bergman", "Liron", ""], ["Cohen", "Niv", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2002.10453", "submitter": "Siddharth Sharma", "authors": "Siddharth Sharma", "title": "QEML (Quantum Enhanced Machine Learning): Using Quantum Computing to\n  Enhance ML Classifiers and Feature Spaces", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and quantum computing are two technologies that are causing\na paradigm shift in the performance and behavior of certain algorithms,\nachieving previously unattainable results. Machine learning (kernel\nclassification) has become ubiquitous as the forefront method for pattern\nrecognition and has been shown to have numerous societal applications. While\nnot yet fault-tolerant, Quantum computing is an entirely new method of\ncomputation due to its exploitation of quantum phenomena such as superposition\nand entanglement. While current machine learning classifiers like the Support\nVector Machine are seeing gradual improvements in performance, there are still\nsevere limitations on the efficiency and scalability of such algorithms due to\na limited feature space which makes the kernel functions computationally\nexpensive to estimate. By integrating quantum circuits into traditional ML, we\nmay solve this problem through the use of quantum feature space, a technique\nthat improves existing Machine Learning algorithms through the use of\nparallelization and the reduction of the storage space from exponential to\nlinear. This research expands on this concept of the Hilbert space and applies\nit for classical machine learning by implementing the quantum-enhanced version\nof the K nearest neighbors algorithm. This paper first understands the\nmathematical intuition for the implementation of quantum feature space and\nsuccessfully simulates quantum properties and algorithms like Fidelity and\nGrover's Algorithm via the Qiskit python library and the IBM Quantum Experience\nplatform. The primary experiment of this research is to build a noisy\nvariational quantum circuit KNN (QKNN) which mimics the classification methods\nof a traditional KNN classifier. The QKNN utilizes the distance metric of\nHamming Distance and is able to outperform the existing KNN on a 10-dimensional\nBreast Cancer dataset.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 04:14:32 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 04:20:15 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 05:07:27 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sharma", "Siddharth", ""]]}, {"id": "2002.10477", "submitter": "Adel Javanmard", "authors": "Adel Javanmard, Mahdi Soltanolkotabi and Hamed Hassani", "title": "Precise Tradeoffs in Adversarial Training for Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite breakthrough performance, modern learning models are known to be\nhighly vulnerable to small adversarial perturbations in their inputs. While a\nwide variety of recent \\emph{adversarial training} methods have been effective\nat improving robustness to perturbed inputs (robust accuracy), often this\nbenefit is accompanied by a decrease in accuracy on benign inputs (standard\naccuracy), leading to a tradeoff between often competing objectives.\nComplicating matters further, recent empirical evidence suggest that a variety\nof other factors (size and quality of training data, model size, etc.) affect\nthis tradeoff in somewhat surprising ways. In this paper we provide a precise\nand comprehensive understanding of the role of adversarial training in the\ncontext of linear regression with Gaussian features. In particular, we\ncharacterize the fundamental tradeoff between the accuracies achievable by any\nalgorithm regardless of computational power or size of the training data.\nFurthermore, we precisely characterize the standard/robust accuracy and the\ncorresponding tradeoff achieved by a contemporary mini-max adversarial training\napproach in a high-dimensional regime where the number of data points and the\nparameters of the model grow in proportion to each other. Our theory for\nadversarial training algorithms also facilitates the rigorous study of how a\nvariety of factors (size and quality of training data, model\noverparametrization etc.) affect the tradeoff between these two competing\naccuracies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:01:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Javanmard", "Adel", ""], ["Soltanolkotabi", "Mahdi", ""], ["Hassani", "Hamed", ""]]}, {"id": "2002.10487", "submitter": "Ehsan Amid", "authors": "Ehsan Amid and Manfred K. Warmuth", "title": "Reparameterizing Mirror Descent as Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the recent successful applications of neural networks have been based\non training with gradient descent updates. However, for some small networks,\nother mirror descent updates learn provably more efficiently when the target is\nsparse. We present a general framework for casting a mirror descent update as a\ngradient descent update on a different set of parameters. In some cases, the\nmirror descent reparameterization can be described as training a modified\nnetwork with standard backpropagation. The reparameterization framework is\nversatile and covers a wide range of mirror descent updates, even cases where\nthe domain is constrained. Our construction for the reparameterization argument\nis done for the continuous versions of the updates. Finding general criteria\nfor the discrete versions to closely track their continuous counterparts\nremains an interesting open problem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:09:47 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:38:47 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Amid", "Ehsan", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "2002.10501", "submitter": "Ruizhi Deng", "authors": "Ruizhi Deng, Yanshuai Cao, Bo Chang, Leonid Sigal, Greg Mori, Marcus\n  A. Brubaker", "title": "Variational Hyper RNN for Sequence Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel probabilistic sequence model that excels at\ncapturing high variability in time series data, both across sequences and\nwithin an individual sequence. Our method uses temporal latent variables to\ncapture information about the underlying data pattern and dynamically decodes\nthe latent information into modifications of weights of the base decoder and\nrecurrent model. The efficacy of the proposed method is demonstrated on a range\nof synthetic and real-world sequential data that exhibit large scale\nvariations, regime shifts, and complex dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:30:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Deng", "Ruizhi", ""], ["Cao", "Yanshuai", ""], ["Chang", "Bo", ""], ["Sigal", "Leonid", ""], ["Mori", "Greg", ""], ["Brubaker", "Marcus A.", ""]]}, {"id": "2002.10502", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui, Wei Zhang, Ulrich Finkler, George Saon, Michael Picheny,\n  David Kung", "title": "Distributed Training of Deep Neural Network Acoustic Models for\n  Automatic Speech Recognition", "comments": "Accepted to IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past decade has witnessed great progress in Automatic Speech Recognition\n(ASR) due to advances in deep learning. The improvements in performance can be\nattributed to both improved models and large-scale training data. Key to\ntraining such models is the employment of efficient distributed learning\ntechniques. In this article, we provide an overview of distributed training\ntechniques for deep neural network acoustic models for ASR. Starting with the\nfundamentals of data parallel stochastic gradient descent (SGD) and ASR\nacoustic modeling, we will investigate various distributed training strategies\nand their realizations in high performance computing (HPC) environments with an\nemphasis on striking the balance between communication and computation.\nExperiments are carried out on a popular public benchmark to study the\nconvergence, speedup and recognition performance of the investigated\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:31:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Cui", "Xiaodong", ""], ["Zhang", "Wei", ""], ["Finkler", "Ulrich", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""], ["Kung", "David", ""]]}, {"id": "2002.10509", "submitter": "Vikash Sehwag", "authors": "Vikash Sehwag, Shiqi Wang, Prateek Mittal, Suman Jana", "title": "HYDRA: Pruning Adversarially Robust Neural Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In safety-critical but computationally resource-constrained applications,\ndeep learning faces two key challenges: lack of robustness against adversarial\nattacks and large neural network size (often millions of parameters). While the\nresearch community has extensively explored the use of robust training and\nnetwork pruning independently to address one of these challenges, only a few\nrecent works have studied them jointly. However, these works inherit a\nheuristic pruning strategy that was developed for benign training, which\nperforms poorly when integrated with robust training techniques, including\nadversarial training and verifiable robust training. To overcome this\nchallenge, we propose to make pruning techniques aware of the robust training\nobjective and let the training objective guide the search for which connections\nto prune. We realize this insight by formulating the pruning objective as an\nempirical risk minimization problem which is solved efficiently using SGD. We\ndemonstrate that our approach, titled HYDRA, achieves compressed networks with\nstate-of-the-art benign and robust accuracy, simultaneously. We demonstrate the\nsuccess of our approach across CIFAR-10, SVHN, and ImageNet dataset with four\nrobust training techniques: iterative adversarial training, randomized\nsmoothing, MixTrain, and CROWN-IBP. We also demonstrate the existence of highly\nrobust sub-networks within non-robust networks. Our code and compressed\nnetworks are publicly available at\n\\url{https://github.com/inspire-group/compactness-robustness}.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 19:54:53 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 14:26:57 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 15:02:00 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sehwag", "Vikash", ""], ["Wang", "Shiqi", ""], ["Mittal", "Prateek", ""], ["Jana", "Suman", ""]]}, {"id": "2002.10516", "submitter": "Ruizhi Deng", "authors": "Ruizhi Deng, Bo Chang, Marcus A. Brubaker, Greg Mori, Andreas Lehrmann", "title": "Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows transform a simple base distribution into a complex target\ndistribution and have proved to be powerful models for data generation and\ndensity estimation. In this work, we propose a novel type of normalizing flow\ndriven by a differential deformation of the Wiener process. As a result, we\nobtain a rich time series model whose observable process inherits many of the\nappealing properties of its base process, such as efficient computation of\nlikelihoods and marginals. Furthermore, our continuous treatment provides a\nnatural framework for irregular time series with an independent arrival\nprocess, including straightforward interpolation. We illustrate the desirable\nproperties of the proposed model on popular stochastic processes and\ndemonstrate its superior flexibility to variational RNN and latent ODE\nbaselines in a series of experiments on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:13:43 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 00:38:32 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 21:02:05 GMT"}, {"version": "v4", "created": "Tue, 13 Jul 2021 04:10:23 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Deng", "Ruizhi", ""], ["Chang", "Bo", ""], ["Brubaker", "Marcus A.", ""], ["Mori", "Greg", ""], ["Lehrmann", "Andreas", ""]]}, {"id": "2002.10523", "submitter": "Puneesh Deora", "authors": "Bhavya Vasudeva, Puneesh Deora, Saumik Bhattacharya, Pyari Mohan\n  Pradhan", "title": "Co-VeGAN: Complex-Valued Generative Adversarial Network for Compressive\n  Sensing MR Image Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive sensing (CS) is widely used to reduce the acquisition time of\nmagnetic resonance imaging (MRI). Although state-of-the-art deep learning based\nmethods have been able to obtain fast, high-quality reconstruction of CS-MR\nimages, their main drawback is that they treat complex-valued MRI data as\nreal-valued entities. Most methods either extract the magnitude from the\ncomplex-valued entities or concatenate them as two real-valued channels. In\nboth the cases, the phase content, which links the real and imaginary parts of\nthe complex-valued entities, is discarded. In order to address the fundamental\nproblem of real-valued deep networks, i.e. their inability to process\ncomplex-valued data, we propose a novel framework based on a complex-valued\ngenerative adversarial network (Co-VeGAN). Our model can process complex-valued\ninput, which enables it to perform high-quality reconstruction of the CS-MR\nimages. Further, considering that phase is a crucial component of\ncomplex-valued entities, we propose a novel complex-valued activation function,\nwhich is sensitive to the phase of the input. Extensive evaluation of the\nproposed approach on different datasets using various sampling masks\ndemonstrates that the proposed model significantly outperforms the existing\nCS-MRI reconstruction techniques in terms of peak signal-to-noise ratio as well\nas structural similarity index. Further, it uses significantly fewer trainable\nparameters to do so, as compared to the real-valued deep learning based\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:28:49 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 11:18:33 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:50:10 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Vasudeva", "Bhavya", ""], ["Deora", "Puneesh", ""], ["Bhattacharya", "Saumik", ""], ["Pradhan", "Pyari Mohan", ""]]}, {"id": "2002.10524", "submitter": "Carlos Martin", "authors": "Carlos Martin, Tuomas Sandholm", "title": "Efficient exploration of zero-sum stochastic games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LG cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the increasingly important and common game-solving setting\nwhere we do not have an explicit description of the game but only oracle access\nto it through gameplay, such as in financial or military simulations and\ncomputer games. During a limited-duration learning phase, the algorithm can\ncontrol the actions of both players in order to try to learn the game and how\nto play it well. After that, the algorithm has to produce a strategy that has\nlow exploitability. Our motivation is to quickly learn strategies that have low\nexploitability in situations where evaluating the payoffs of a queried strategy\nprofile is costly. For the stochastic game setting, we propose using the\ndistribution of state-action value functions induced by a belief distribution\nover possible environments. We compare the performance of various exploration\nstrategies for this task, including generalizations of Thompson sampling and\nBayes-UCB to this new setting. These two consistently outperform other\nstrategies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:30:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Martin", "Carlos", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2002.10525", "submitter": "Wonseok Jeon", "authors": "Wonseok Jeon, Paul Barde, Derek Nowrouzezahrai, Joelle Pineau", "title": "Scalable Multi-Agent Inverse Reinforcement Learning via\n  Actor-Attention-Critic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent adversarial inverse reinforcement learning (MA-AIRL) is a recent\napproach that applies single-agent AIRL to multi-agent problems where we seek\nto recover both policies for our agents and reward functions that promote\nexpert-like behavior. While MA-AIRL has promising results on cooperative and\ncompetitive tasks, it is sample-inefficient and has only been validated\nempirically for small numbers of agents -- its ability to scale to many agents\nremains an open question. We propose a multi-agent inverse RL algorithm that is\nmore sample-efficient and scalable than previous works. Specifically, we employ\nmulti-agent actor-attention-critic (MAAC) -- an off-policy multi-agent RL\n(MARL) method -- for the RL inner loop of the inverse RL procedure. In doing\nso, we are able to increase sample efficiency compared to state-of-the-art\nbaselines, across both small- and large-scale tasks. Moreover, the RL agents\ntrained on the rewards recovered by our method better match the experts than\nthose trained on the rewards derived from the baselines. Finally, our method\nrequires far fewer agent-environment interactions, particularly as the number\nof agents increases.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:30:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Jeon", "Wonseok", ""], ["Barde", "Paul", ""], ["Nowrouzezahrai", "Derek", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.10526", "submitter": "Michael Mahoney", "authors": "Ping Ma, Xinlian Zhang, Xin Xing, Jingyi Ma, and Michael W. Mahoney", "title": "Asymptotic Analysis of Sampling Estimators for Randomized Numerical\n  Linear Algebra Algorithms", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical analysis of Randomized Numerical Linear Algebra (RandNLA)\nalgorithms within the past few years has mostly focused on their performance as\npoint estimators. However, this is insufficient for conducting statistical\ninference, e.g., constructing confidence intervals and hypothesis testing,\nsince the distribution of the estimator is lacking. In this article, we develop\nan asymptotic analysis to derive the distribution of RandNLA sampling\nestimators for the least-squares problem. In particular, we derive the\nasymptotic distribution of a general sampling estimator with arbitrary sampling\nprobabilities. The analysis is conducted in two complementary settings, i.e.,\nwhen the objective of interest is to approximate the full sample estimator or\nis to infer the underlying ground truth model parameters. For each setting, we\nshow that the sampling estimator is asymptotically normally distributed under\nmild regularity conditions. Moreover, the sampling estimator is asymptotically\nunbiased in both settings. Based on our asymptotic analysis, we use two\ncriteria, the Asymptotic Mean Squared Error (AMSE) and the Expected Asymptotic\nMean Squared Error (EAMSE), to identify optimal sampling probabilities. Several\nof these optimal sampling probability distributions are new to the literature,\ne.g., the root leverage sampling estimator and the predictor length sampling\nestimator. Our theoretical results clarify the role of leverage in the sampling\nprocess, and our empirical results demonstrate improvements over existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:34:50 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ma", "Ping", ""], ["Zhang", "Xinlian", ""], ["Xing", "Xin", ""], ["Ma", "Jingyi", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "2002.10539", "submitter": "David Eriksson", "authors": "Eric Hans Lee, David Eriksson, Bolong Cheng, Michael McCourt, David\n  Bindel", "title": "Efficient Rollout Strategies for Bayesian Optimization", "comments": "To appear in UAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a class of sample-efficient global optimization\nmethods, where a probabilistic model conditioned on previous observations is\nused to determine future evaluations via the optimization of an acquisition\nfunction. Most acquisition functions are myopic, meaning that they only\nconsider the impact of the next function evaluation. Non-myopic acquisition\nfunctions consider the impact of the next $h$ function evaluations and are\ntypically computed through rollout, in which $h$ steps of BO are simulated.\nThese rollout acquisition functions are defined as $h$-dimensional integrals,\nand are expensive to compute and optimize. We show that a combination of\nquasi-Monte Carlo, common random numbers, and control variates significantly\nreduce the computational burden of rollout. We then formulate a policy-search\nbased approach that removes the need to optimize the rollout acquisition\nfunction. Finally, we discuss the qualitative behavior of rollout policies in\nthe setting of multi-modal objectives and model error.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:54:08 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 17:52:49 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 03:40:36 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Lee", "Eric Hans", ""], ["Eriksson", "David", ""], ["Cheng", "Bolong", ""], ["McCourt", "Michael", ""], ["Bindel", "David", ""]]}, {"id": "2002.10542", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Sharan Vaswani, Issam Laradji, Simon Lacoste-Julien", "title": "Stochastic Polyak Step-size for SGD: An Adaptive Learning Rate for Fast\n  Convergence", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a stochastic variant of the classical Polyak step-size (Polyak,\n1987) commonly used in the subgradient method. Although computing the Polyak\nstep-size requires knowledge of the optimal function values, this information\nis readily available for typical modern machine learning applications.\nConsequently, the proposed stochastic Polyak step-size (SPS) is an attractive\nchoice for setting the learning rate for stochastic gradient descent (SGD). We\nprovide theoretical convergence guarantees for SGD equipped with SPS in\ndifferent settings, including strongly convex, convex and non-convex functions.\nFurthermore, our analysis results in novel convergence guarantees for SGD with\na constant step-size. We show that SPS is particularly effective when training\nover-parameterized models capable of interpolating the training data. In this\nsetting, we prove that SPS enables SGD to converge to the true solution at a\nfast rate without requiring the knowledge of any problem-dependent constants or\nadditional computational overhead. We experimentally validate our theoretical\nresults via extensive experiments on synthetic and real datasets. We\ndemonstrate the strong performance of SGD with SPS compared to state-of-the-art\noptimization methods when training over-parameterized models.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:57:23 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 01:03:46 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 14:53:59 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Loizou", "Nicolas", ""], ["Vaswani", "Sharan", ""], ["Laradji", "Issam", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "2002.10543", "submitter": "Liang Mi", "authors": "Liang Mi, Tianshu Yu, Jose Bento, Wen Zhang, Baoxin Li, Yalin Wang", "title": "Variational Wasserstein Barycenters for Geometric Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to compute Wasserstein barycenters (WBs) by solving for Monge maps\nwith variational principle. We discuss the metric properties of WBs and explore\ntheir connections, especially the connections of Monge WBs, to K-means\nclustering and co-clustering. We also discuss the feasibility of Monge WBs on\nunbalanced measures and spherical domains. We propose two new problems --\nregularized K-means and Wasserstein barycenter compression. We demonstrate the\nuse of VWBs in solving these clustering-related problems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:01:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mi", "Liang", ""], ["Yu", "Tianshu", ""], ["Bento", "Jose", ""], ["Zhang", "Wen", ""], ["Li", "Baoxin", ""], ["Wang", "Yalin", ""]]}, {"id": "2002.10544", "submitter": "Nikunj Saunshi", "authors": "Sanjeev Arora, Simon S. Du, Sham Kakade, Yuping Luo, and Nikunj\n  Saunshi", "title": "Provable Representation Learning for Imitation Learning via Bi-level\n  Optimization", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common strategy in modern learning systems is to learn a representation\nthat is useful for many tasks, a.k.a. representation learning. We study this\nstrategy in the imitation learning setting for Markov decision processes (MDPs)\nwhere multiple experts' trajectories are available. We formulate representation\nlearning as a bi-level optimization problem where the \"outer\" optimization\ntries to learn the joint representation and the \"inner\" optimization encodes\nthe imitation learning setup and tries to learn task-specific parameters. We\ninstantiate this framework for the imitation learning settings of behavior\ncloning and observation-alone. Theoretically, we show using our framework that\nrepresentation learning can provide sample complexity benefits for imitation\nlearning in both settings. We also provide proof-of-concept experiments to\nverify our theory.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:03:52 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Kakade", "Sham", ""], ["Luo", "Yuping", ""], ["Saunshi", "Nikunj", ""]]}, {"id": "2002.10549", "submitter": "Zhiyuan Li", "authors": "Zhiyuan Li, Jaideep Vitthal Murkute, Prashnna Kumar Gyawali and Linwei\n  Wang", "title": "Progressive Learning and Disentanglement of Hierarchical Representations", "comments": "Main text: 9 pages, 7 figures. Supplements: 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rich representation from data is an important task for deep\ngenerative models such as variational auto-encoder (VAE). However, by\nextracting high-level abstractions in the bottom-up inference process, the goal\nof preserving all factors of variations for top-down generation is compromised.\nMotivated by the concept of \"starting small\", we present a strategy to\nprogressively learn independent hierarchical representations from high- to\nlow-levels of abstractions. The model starts with learning the most abstract\nrepresentation, and then progressively grow the network architecture to\nintroduce new representations at different levels of abstraction. We\nquantitatively demonstrate the ability of the presented model to improve\ndisentanglement in comparison to existing works on two benchmark data sets\nusing three disentanglement metrics, including a new metric we proposed to\ncomplement the previously-presented metric of mutual information gap. We\nfurther present both qualitative and quantitative evidence on how the\nprogression of learning improves disentangling of hierarchical representations.\nBy drawing on the respective advantage of hierarchical representation learning\nand progressive learning, this is to our knowledge the first attempt to improve\ndisentanglement by progressively growing the capacity of VAE to learn\nhierarchical representations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:19:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Li", "Zhiyuan", ""], ["Murkute", "Jaideep Vitthal", ""], ["Gyawali", "Prashnna Kumar", ""], ["Wang", "Linwei", ""]]}, {"id": "2002.10553", "submitter": "Tolga Ergen", "authors": "Mert Pilanci, Tolga Ergen", "title": "Neural Networks are Convex Regularizers: Exact Polynomial-time Convex\n  Optimization Formulations for Two-layer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop exact representations of training two-layer neural networks with\nrectified linear units (ReLUs) in terms of a single convex program with number\nof variables polynomial in the number of training samples and the number of\nhidden neurons. Our theory utilizes semi-infinite duality and minimum norm\nregularization. We show that ReLU networks trained with standard weight decay\nare equivalent to block $\\ell_1$ penalized convex models. Moreover, we show\nthat certain standard convolutional linear networks are equivalent\nsemi-definite programs which can be simplified to $\\ell_1$ regularized linear\nmodels in a polynomial sized discrete Fourier feature space.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:32:41 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 05:26:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Pilanci", "Mert", ""], ["Ergen", "Tolga", ""]]}, {"id": "2002.10558", "submitter": "Hao Sun", "authors": "Chengping Rao, Hao Sun and Yang Liu", "title": "Physics-informed deep learning for incompressible laminar flows", "comments": "5 Pages and 7 Figures", "journal-ref": "Theoretical and Applied Mechanics Letters (2020)", "doi": "10.1016/j.taml.2020.01.039", "report-no": "10(3): 207-212", "categories": "physics.flu-dyn cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed deep learning has drawn tremendous interest in recent years\nto solve computational physics problems, whose basic concept is to embed\nphysical laws to constrain/inform neural networks, with the need of less data\nfor training a reliable model. This can be achieved by incorporating the\nresidual of physics equations into the loss function. Through minimizing the\nloss function, the network could approximate the solution. In this paper, we\npropose a mixed-variable scheme of physics-informed neural network (PINN) for\nfluid dynamics and apply it to simulate steady and transient laminar flows at\nlow Reynolds numbers. A parametric study indicates that the mixed-variable\nscheme can improve the PINN trainability and the solution accuracy. The\npredicted velocity and pressure fields by the proposed PINN approach are also\ncompared with the reference numerical solutions. Simulation results demonstrate\ngreat potential of the proposed PINN for fluid flow simulation with a high\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:51:53 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 00:38:43 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rao", "Chengping", ""], ["Sun", "Hao", ""], ["Liu", "Yang", ""]]}, {"id": "2002.10561", "submitter": "Jiefu Zhang", "authors": "Jiefu Zhang, Leonardo Zepeda-N\\'u\\~nez, Yuan Yao, Lin Lin", "title": "Learning the mapping $\\mathbf{x}\\mapsto \\sum_{i=1}^d x_i^2$: the cost of\n  finding the needle in a haystack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of using machine learning to approximate the mapping\n$\\mathbf{x}\\mapsto\\sum_{i=1}^d x_i^2$ with $x_i\\in[-1,1]$ seems to be a trivial\none. Given the knowledge of the separable structure of the function, one can\ndesign a sparse network to represent the function very accurately, or even\nexactly. When such structural information is not available, and we may only use\na dense neural network, the optimization procedure to find the sparse network\nembedded in the dense network is similar to finding the needle in a haystack,\nusing a given number of samples of the function. We demonstrate that the cost\n(measured by sample complexity) of finding the needle is directly related to\nthe Barron norm of the function. While only a small number of samples is needed\nto train a sparse network, the dense network trained with the same number of\nsamples exhibits large test loss and a large generalization gap. In order to\ncontrol the size of the generalization gap, we find that the use of explicit\nregularization becomes increasingly more important as $d$ increases. The\nnumerically observed sample complexity with explicit regularization scales as\n$\\mathcal{O}(d^{2.5})$, which is in fact better than the theoretically\npredicted sample complexity that scales as $\\mathcal{O}(d^{4})$. Without\nexplicit regularization (also called implicit regularization), the numerically\nobserved sample complexity is significantly higher and is close to\n$\\mathcal{O}(d^{4.5})$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:58:22 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 21:14:02 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zhang", "Jiefu", ""], ["Zepeda-N\u00fa\u00f1ez", "Leonardo", ""], ["Yao", "Yuan", ""], ["Lin", "Lin", ""]]}, {"id": "2002.10566", "submitter": "Ekaterina Abramova", "authors": "Ekaterina Abramova, Derek Bunn", "title": "Forecasting the Intra-Day Spread Densities of Electricity Prices", "comments": "31 pages, 25 figures. arXiv admin note: substantial text overlap with\n  arXiv:1903.06668", "journal-ref": "Energies 2020, 13(3), 687", "doi": "10.3390/en13030687", "report-no": null, "categories": "stat.AP cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intra-day price spreads are of interest to electricity traders, storage and\nelectric vehicle operators. This paper formulates dynamic density functions,\nbased upon skewed-t and similar representations, to model and forecast the\nGerman electricity price spreads between different hours of the day, as\nrevealed in the day-ahead auctions. The four specifications of the density\nfunctions are dynamic and conditional upon exogenous drivers, thereby\npermitting the location, scale and shape parameters of the densities to respond\nhourly to such factors as weather and demand forecasts. The best fitting and\nforecasting specifications for each spread are selected based on the Pinball\nLoss function, following the closed-form analytical solutions of the cumulative\ndistribution functions.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 19:57:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Abramova", "Ekaterina", ""], ["Bunn", "Derek", ""]]}, {"id": "2002.10572", "submitter": "Qianqian Zhang", "authors": "Qianqian Zhang, Walid Saad and Mehdi Bennis", "title": "Millimeter Wave Communications with an Intelligent Reflector:\n  Performance Optimization and Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel framework is proposed to optimize the downlink\nmulti-user communication of a millimeter wave base station, which is assisted\nby a reconfigurable intelligent reflector (IR). In particular, a channel\nestimation approach is developed to measure the channel state information (CSI)\nin real-time. First, for a perfect CSI scenario, the precoding transmission of\nthe BS and the reflection coefficient of the IR are jointly optimized, via an\niterative approach, so as to maximize the sum of downlink rates towards\nmultiple users. Next, in the imperfect CSI scenario, a distributional\nreinforcement learning (DRL) approach is proposed to learn the optimal IR\nreflection and maximize the expectation of downlink capacity. In order to model\nthe transmission rate's probability distribution, a learning algorithm, based\non quantile regression (QR), is developed, and the proposed QR-DRL method is\nproved to converge to a stable distribution of downlink transmission rate.\nSimulation results show that, in the error-free CSI scenario, the proposed\napproach yields over 30% and 2-fold increase in the downlink sum-rate, compared\nwith a fixed IR reflection scheme and direct transmission scheme, respectively.\nSimulation results also show that by deploying more IR elements, the downlink\nsum-rate can be significantly improved. However, as the number of IR components\nincreases, more time is required for channel estimation, and the slope of\nincrease in the IR-aided transmission rate will become smaller. Furthermore,\nunder limited knowledge of CSI, simulation results show that the proposed\nQR-DRL method, which learns a full distribution of the downlink rate, yields a\nbetter prediction accuracy and improves the downlink rate by 10% for online\ndeployments, compared with a Q-learning baseline.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:18:54 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 04:43:11 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Zhang", "Qianqian", ""], ["Saad", "Walid", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2002.10583", "submitter": "Tan Nguyen", "authors": "Bao Wang, Tan M. Nguyen, Andrea L. Bertozzi, Richard G. Baraniuk,\n  Stanley J. Osher", "title": "Scheduled Restart Momentum for Accelerated Stochastic Gradient Descent", "comments": "35 pages, 16 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) with constant momentum and its variants\nsuch as Adam are the optimization algorithms of choice for training deep neural\nnetworks (DNNs). Since DNN training is incredibly computationally expensive,\nthere is great interest in speeding up the convergence. Nesterov accelerated\ngradient (NAG) improves the convergence rate of gradient descent (GD) for\nconvex optimization using a specially designed momentum; however, it\naccumulates error when an inexact gradient is used (such as in SGD), slowing\nconvergence at best and diverging at worst. In this paper, we propose Scheduled\nRestart SGD (SRSGD), a new NAG-style scheme for training DNNs. SRSGD replaces\nthe constant momentum in SGD by the increasing momentum in NAG but stabilizes\nthe iterations by resetting the momentum to zero according to a schedule. Using\na variety of models and benchmarks for image classification, we demonstrate\nthat, in training DNNs, SRSGD significantly improves convergence and\ngeneralization; for instance in training ResNet200 for ImageNet classification,\nSRSGD achieves an error rate of 20.93% vs. the benchmark of 22.13%. These\nimprovements become more significant as the network grows deeper. Furthermore,\non both CIFAR and ImageNet, SRSGD reaches similar or even better error rates\nwith significantly fewer training epochs compared to the SGD baseline.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 23:16:19 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 11:55:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Bao", ""], ["Nguyen", "Tan M.", ""], ["Bertozzi", "Andrea L.", ""], ["Baraniuk", "Richard G.", ""], ["Osher", "Stanley J.", ""]]}, {"id": "2002.10597", "submitter": "Lin Xiao", "authors": "Pengchuan Zhang, Hunter Lang, Qiang Liu and Lin Xiao", "title": "Statistical Adaptive Stochastic Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2020-3", "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical adaptive procedure called SALSA for automatically\nscheduling the learning rate (step size) in stochastic gradient methods. SALSA\nfirst uses a smoothed stochastic line-search procedure to gradually increase\nthe learning rate, then automatically switches to a statistical method to\ndecrease the learning rate. The line search procedure ``warms up'' the\noptimization process, reducing the need for expensive trial and error in\nsetting an initial learning rate. The method for decreasing the learning rate\nis based on a new statistical test for detecting stationarity when using a\nconstant step size. Unlike in prior work, our test applies to a broad class of\nstochastic gradient algorithms without modification. The combined method is\nhighly robust and autonomous, and it matches the performance of the best\nhand-tuned learning rate schedules in our experiments on several deep learning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 00:04:16 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Zhang", "Pengchuan", ""], ["Lang", "Hunter", ""], ["Liu", "Qiang", ""], ["Xiao", "Lin", ""]]}, {"id": "2002.10610", "submitter": "M. Hadi Amini", "authors": "Ahmed Imteaj, Urmish Thakker, Shiqiang Wang, Jian Li, M. Hadi Amini", "title": "Federated Learning for Resource-Constrained IoT Devices: Panoramas and\n  State-of-the-art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, devices are equipped with advanced sensors with higher\nprocessing/computing capabilities. Further, widespread Internet availability\nenables communication among sensing devices. As a result, vast amounts of data\nare generated on edge devices to drive Internet-of-Things (IoT), crowdsourcing,\nand other emerging technologies. The collected extensive data can be\npre-processed, scaled, classified, and finally, used for predicting future\nevents using machine learning (ML) methods. In traditional ML approaches, data\nis sent to and processed in a central server, which encounters communication\noverhead, processing delay, privacy leakage, and security issues. To overcome\nthese challenges, each client can be trained locally based on its available\ndata and by learning from the global model. This decentralized learning\nstructure is referred to as Federated Learning (FL). However, in large-scale\nnetworks, there may be clients with varying computational resource\ncapabilities. This may lead to implementation and scalability challenges for FL\ntechniques. In this paper, we first introduce some recently implemented\nreal-life applications of FL. We then emphasize on the core challenges of\nimplementing the FL algorithms from the perspective of resource limitations\n(e.g., memory, bandwidth, and energy budget) of client clients. We finally\ndiscuss open issues associated with FL and highlight future directions in the\nFL area concerning resource-constrained devices.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:03:29 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Imteaj", "Ahmed", ""], ["Thakker", "Urmish", ""], ["Wang", "Shiqiang", ""], ["Li", "Jian", ""], ["Amini", "M. Hadi", ""]]}, {"id": "2002.10614", "submitter": "Yehuda Dar", "authors": "Yehuda Dar, Paul Mayer, Lorenzo Luzi, Richard G. Baraniuk", "title": "Subspace Fitting Meets Regression: The Effects of Supervision and\n  Orthonormality Constraints on Double Descent of Generalization Errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the linear subspace fitting problem in the overparameterized\nsetting, where the estimated subspace can perfectly interpolate the training\nexamples. Our scope includes the least-squares solutions to subspace fitting\ntasks with varying levels of supervision in the training data (i.e., the\nproportion of input-output examples of the desired low-dimensional mapping) and\northonormality of the vectors defining the learned operator. This flexible\nfamily of problems connects standard, unsupervised subspace fitting that\nenforces strict orthonormality with a corresponding regression task that is\nfully supervised and does not constrain the linear operator structure. This\nclass of problems is defined over a supervision-orthonormality plane, where\neach coordinate induces a problem instance with a unique pair of supervision\nlevel and softness of orthonormality constraints. We explore this plane and\nshow that the generalization errors of the corresponding subspace fitting\nproblems follow double descent trends as the settings become more supervised\nand less orthonormally constrained.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:31:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 12:03:00 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:55:35 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Dar", "Yehuda", ""], ["Mayer", "Paul", ""], ["Luzi", "Lorenzo", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "2002.10619", "submitter": "Ananda Theertha Suresh", "authors": "Yishay Mansour and Mehryar Mohri and Jae Ro and Ananda Theertha Suresh", "title": "Three Approaches for Personalization with Applications to Federated\n  Learning", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard objective in machine learning is to train a single model for all\nusers. However, in many learning scenarios, such as cloud computing and\nfederated learning, it is possible to learn a personalized model per user. In\nthis work, we present a systematic learning-theoretic study of personalization.\nWe propose and analyze three approaches: user clustering, data interpolation,\nand model interpolation. For all three approaches, we provide\nlearning-theoretic guarantees and efficient algorithms for which we also\ndemonstrate the performance empirically. All of our algorithms are\nmodel-agnostic and work for any hypothesis class.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:36:43 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 21:02:14 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mansour", "Yishay", ""], ["Mohri", "Mehryar", ""], ["Ro", "Jae", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "2002.10620", "submitter": "Zhi Xu", "authors": "Devavrat Shah, Varun Somani, Qiaomin Xie, Zhi Xu", "title": "On Reinforcement Learning for Turn-based Zero-sum Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding Nash equilibrium for two-player turn-based\nzero-sum games. Inspired by the AlphaGo Zero (AGZ) algorithm, we develop a\nReinforcement Learning based approach. Specifically, we propose\nExplore-Improve-Supervise (EIS) method that combines \"exploration\", \"policy\nimprovement\"' and \"supervised learning\" to find the value function and policy\nassociated with Nash equilibrium. We identify sufficient conditions for\nconvergence and correctness for such an approach. For a concrete instance of\nEIS where random policy is used for \"exploration\", Monte-Carlo Tree Search is\nused for \"policy improvement\" and Nearest Neighbors is used for \"supervised\nlearning\", we establish that this method finds an $\\varepsilon$-approximate\nvalue function of Nash equilibrium in $\\widetilde{O}(\\varepsilon^{-(d+4)})$\nsteps when the underlying state-space of the game is continuous and\n$d$-dimensional. This is nearly optimal as we establish a lower bound of\n$\\widetilde{\\Omega}(\\varepsilon^{-(d+2)})$ for any policy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:40:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Shah", "Devavrat", ""], ["Somani", "Varun", ""], ["Xie", "Qiaomin", ""], ["Xu", "Zhi", ""]]}, {"id": "2002.10621", "submitter": "Diego Romeres", "authors": "Alberto Dalla Libera, Diego Romeres, Devesh K. Jha, Bill Yerazunis and\n  Daniel Nikovski", "title": "Model-Based Reinforcement Learning for Physical Systems Without Velocity\n  and Acceleration Measurements", "comments": "Accepted at RA-L", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SP eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a derivative-free model learning framework for\nReinforcement Learning (RL) algorithms based on Gaussian Process Regression\n(GPR). In many mechanical systems, only positions can be measured by the\nsensing instruments. Then, instead of representing the system state as\nsuggested by the physics with a collection of positions, velocities, and\naccelerations, we define the state as the set of past position measurements.\nHowever, the equation of motions derived by physical first principles cannot be\ndirectly applied in this framework, being functions of velocities and\naccelerations. For this reason, we introduce a novel derivative-free\nphysically-inspired kernel, which can be easily combined with nonparametric\nderivative-free Gaussian Process models. Tests performed on two real platforms\nshow that the considered state definition combined with the proposed model\nimproves estimation performance and data-efficiency w.r.t. traditional models\nbased on GPR. Finally, we validate the proposed framework by solving two RL\ncontrol problems for two real robotic systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:58:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Libera", "Alberto Dalla", ""], ["Romeres", "Diego", ""], ["Jha", "Devesh K.", ""], ["Yerazunis", "Bill", ""], ["Nikovski", "Daniel", ""]]}, {"id": "2002.10625", "submitter": "Liang Yu", "authors": "Liang Yu, Mingfei Xia, Lin Gao", "title": "A Node Embedding Framework for Integration of Similarity-based Drug\n  Combination Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Drug combination is a sensible strategy for disease treatment by\nimproving the efficacy and reducing concomitant side effects. Due to the large\nnumber of possible combinations among candidate compounds, exhaustive screening\nis prohibitive. Currently, a plenty of studies have focused on predicting\npotential drug combinations. However, these methods are not entirely\nsatisfactory in performance and scalability. Results: In this paper, we\nproposed a Network Embedding framework in Multiplex Networks (NEMN) to predict\nsynthetic drug combinations. Based on a multiplex drug similarity network, we\noffered alternative methods to integrate useful information from different\naspects and to decide quantitative importance of each network. To explain the\nfeasibility of NEMN, we applied our framework to the data of drug-drug\ninteractions, on which it showed better performance in terms of AUPR and ROC.\nFor Drug combination prediction, we found seven novel drug combinations which\nhave been validated by external sources among the top-ranked predictions of our\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 02:24:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yu", "Liang", ""], ["Xia", "Mingfei", ""], ["Gao", "Lin", ""]]}, {"id": "2002.10631", "submitter": "Pascal Poupart", "authors": "Amur Ghose, Abdullah Rashwan, Pascal Poupart", "title": "Batch norm with entropic regularization turns deterministic autoencoders\n  into generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder is a well defined deep generative model that\nutilizes an encoder-decoder framework where an encoding neural network outputs\na non-deterministic code for reconstructing an input. The encoder achieves this\nby sampling from a distribution for every input, instead of outputting a\ndeterministic code per input. The great advantage of this process is that it\nallows the use of the network as a generative model for sampling from the data\ndistribution beyond provided samples for training. We show in this work that\nutilizing batch normalization as a source for non-determinism suffices to turn\ndeterministic autoencoders into generative models on par with variational ones,\nso long as we add a suitable entropic regularization to the training objective.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 02:42:18 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ghose", "Amur", ""], ["Rashwan", "Abdullah", ""], ["Poupart", "Pascal", ""]]}, {"id": "2002.10638", "submitter": "Chunyuan Li", "authors": "Weituo Hao, Chunyuan Li, Xiujun Li, Lawrence Carin, Jianfeng Gao", "title": "Towards Learning a Generic Agent for Vision-and-Language Navigation via\n  Pre-training", "comments": "To appear at CVPR 2020. The first two authors contributed equally to\n  this manuscript. Code: https://github.com/weituo12321/PREVALENT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to navigate in a visual environment following natural-language\ninstructions is a challenging task, because the multimodal inputs to the agent\nare highly variable, and the training data on a new task is often limited. In\nthis paper, we present the first pre-training and fine-tuning paradigm for\nvision-and-language navigation (VLN) tasks. By training on a large amount of\nimage-text-action triplets in a self-supervised learning manner, the\npre-trained model provides generic representations of visual environments and\nlanguage instructions. It can be easily used as a drop-in for existing VLN\nframeworks, leading to the proposed agent called Prevalent. It learns more\neffectively in new tasks and generalizes better in a previously unseen\nenvironment. The performance is validated on three VLN tasks. On the\nRoom-to-Room benchmark, our model improves the state-of-the-art from 47% to 51%\non success rate weighted by path length. Further, the learned representation is\ntransferable to other VLN tasks. On two recent tasks, vision-and-dialog\nnavigation and \"Help, Anna!\" the proposed Prevalent leads to significant\nimprovement over existing methods, achieving a new state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:08:12 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 03:20:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hao", "Weituo", ""], ["Li", "Chunyuan", ""], ["Li", "Xiujun", ""], ["Carin", "Lawrence", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2002.10640", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig,\n  Ruslan Salakhutdinov, William W. Cohen", "title": "Differentiable Reasoning over a Virtual Knowledge Base", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of answering complex multi-hop questions using a corpus\nas a virtual knowledge base (KB). In particular, we describe a neural module,\nDrKIT, that traverses textual data like a KB, softly following paths of\nrelations between mentions of entities in the corpus. At each step the module\nuses a combination of sparse-matrix TFIDF indices and a maximum inner product\nsearch (MIPS) on a special index of contextual representations of the mentions.\nThis module is differentiable, so the full system can be trained end-to-end\nusing gradient based methods, starting from natural language inputs. We also\ndescribe a pretraining scheme for the contextual representation encoder by\ngenerating hard negative examples using existing knowledge bases. We show that\nDrKIT improves accuracy by 9 points on 3-hop questions in the MetaQA dataset,\ncutting the gap between text-based and KB-based state-of-the-art by 70%. On\nHotpotQA, DrKIT leads to a 10% improvement over a BERT-based re-ranking\napproach to retrieving the relevant passages required to answer a question.\nDrKIT is also very efficient, processing 10-100x more queries per second than\nexisting multi-hop systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:13:32 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Zaheer", "Manzil", ""], ["Balachandran", "Vidhisha", ""], ["Neubig", "Graham", ""], ["Salakhutdinov", "Ruslan", ""], ["Cohen", "William W.", ""]]}, {"id": "2002.10645", "submitter": "Marius Hofert", "authors": "Marius Hofert, Avinash Prasad, Mu Zhu", "title": "Multivariate time-series modeling with generative neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative moment matching networks (GMMNs) are introduced as dependence\nmodels for the joint innovation distribution of multivariate time series (MTS).\nFollowing the popular copula-GARCH approach for modeling dependent MTS data, a\nframework based on a GMMN-GARCH approach is presented. First, ARMA-GARCH models\nare utilized to capture the serial dependence within each univariate marginal\ntime series. Second, if the number of marginal time series is large, principal\ncomponent analysis (PCA) is used as a dimension-reduction step. Last, the\nremaining cross-sectional dependence is modeled via a GMMN, the main\ncontribution of this work. GMMNs are highly flexible and easy to simulate from,\nwhich is a major advantage over the copula-GARCH approach. Applications\ninvolving yield curve modeling and the analysis of foreign exchange-rate\nreturns demonstrate the utility of the GMMN-GARCH approach, especially in terms\nof producing better empirical predictive distributions and making better\nprobabilistic forecasts.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:26:52 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 14:54:36 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 05:21:52 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hofert", "Marius", ""], ["Prasad", "Avinash", ""], ["Zhu", "Mu", ""]]}, {"id": "2002.10648", "submitter": "Haotao Wang", "authors": "Haotao Wang, Tianlong Chen, Zhangyang Wang and Kede Ma", "title": "I Am Going MAD: Maximum Discrepancy Competition for Comparing\n  Classifiers Adaptively", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning of hierarchical representations for image classification has\nexperienced an impressive series of successes due in part to the availability\nof large-scale labeled data for training. On the other hand, the trained\nclassifiers have traditionally been evaluated on small and fixed sets of test\nimages, which are deemed to be extremely sparsely distributed in the space of\nall natural images. It is thus questionable whether recent performance\nimprovements on the excessively re-used test sets generalize to real-world\nnatural images with much richer content variations. Inspired by efficient\nstimulus selection for testing perceptual models in psychophysical and\nphysiological studies, we present an alternative framework for comparing image\nclassifiers, which we name the MAximum Discrepancy (MAD) competition. Rather\nthan comparing image classifiers using fixed test images, we adaptively sample\na small test set from an arbitrarily large corpus of unlabeled images so as to\nmaximize the discrepancies between the classifiers, measured by the distance\nover WordNet hierarchy. Human labeling on the resulting model-dependent image\nsets reveals the relative performance of the competing classifiers, and\nprovides useful insights on potential ways to improve them. We report the MAD\ncompetition results of eleven ImageNet classifiers while noting that the\nframework is readily extensible and cost-effective to add future classifiers\ninto the competition. Codes can be found at https://github.com/TAMU-VITA/MAD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:32:29 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Wang", "Haotao", ""], ["Chen", "Tianlong", ""], ["Wang", "Zhangyang", ""], ["Ma", "Kede", ""]]}, {"id": "2002.10657", "submitter": "Satrajit Chatterjee", "authors": "Satrajit Chatterjee", "title": "Coherent Gradients: An Approach to Understanding Generalization in\n  Gradient Descent-based Optimization", "comments": "To appear in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in the Deep Learning community is why neural networks\ntrained with Gradient Descent generalize well on real datasets even though they\nare capable of fitting random data. We propose an approach to answering this\nquestion based on a hypothesis about the dynamics of gradient descent that we\ncall Coherent Gradients: Gradients from similar examples are similar and so the\noverall gradient is stronger in certain directions where these reinforce each\nother. Thus changes to the network parameters during training are biased\ntowards those that (locally) simultaneously benefit many examples when such\nsimilarity exists. We support this hypothesis with heuristic arguments and\nperturbative experiments and outline how this can explain several common\nempirical observations about Deep Learning. Furthermore, our analysis is not\njust descriptive, but prescriptive. It suggests a natural modification to\ngradient descent that can greatly reduce overfitting.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 03:59:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Chatterjee", "Satrajit", ""]]}, {"id": "2002.10670", "submitter": "Eric Hulburd", "authors": "Eric Hulburd", "title": "Exploring BERT Parameter Efficiency on the Stanford Question Answering\n  Dataset v2.0", "comments": "11 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the parameter efficiency of BERT arXiv:1810.04805 on\nversion 2.0 of the Stanford Question Answering dataset (SQuAD2.0). We evaluate\nthe parameter efficiency of BERT while freezing a varying number of final\ntransformer layers as well as including the adapter layers proposed in\narXiv:1902.00751. Additionally, we experiment with the use of context-aware\nconvolutional (CACNN) filters, as described in arXiv:1709.08294v3, as a final\naugmentation layer for the SQuAD2.0 tasks.\n  This exploration is motivated in part by arXiv:1907.10597, which made a\ncompelling case for broadening the evaluation criteria of artificial\nintelligence models to include various measures of resource efficiency. While\nwe do not evaluate these models based on their floating point operation\nefficiency as proposed in arXiv:1907.10597, we examine efficiency with respect\nto training time, inference time, and total number of model parameters. Our\nresults largely corroborate those of arXiv:1902.00751 for adapter modules,\nwhile also demonstrating that gains in F1 score from adding context-aware\nconvolutional filters are not practical due to the increase in training and\ninference time.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:09:48 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 05:16:37 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hulburd", "Eric", ""]]}, {"id": "2002.10671", "submitter": "Xu Chen", "authors": "Qiong Wu and Kaiwen He and Xu Chen", "title": "Personalized Federated Learning for Intelligent IoT Applications: A\n  Cloud-Edge based Framework", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) have widely penetrated in different aspects of\nmodern life and many intelligent IoT services and applications are emerging.\nRecently, federated learning is proposed to train a globally shared model by\nexploiting a massive amount of user-generated data samples on IoT devices while\npreventing data leakage. However, the device, statistical and model\nheterogeneities inherent in the complex IoT environments pose great challenges\nto traditional federated learning, making it unsuitable to be directly\ndeployed. In this article we advocate a personalized federated learning\nframework in a cloud-edge architecture for intelligent IoT applications. To\ncope with the heterogeneity issues in IoT environments, we investigate emerging\npersonalized federated learning methods which are able to mitigate the negative\neffects caused by heterogeneity in different aspects. With the power of edge\ncomputing, the requirements for fast-processing capacity and low latency in\nintelligent IoT applications can also be achieved. We finally provide a case\nstudy of IoT based human activity recognition to demonstrate the effectiveness\nof personalized federated learning for intelligent IoT applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:11:06 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 13:46:54 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 08:44:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Qiong", ""], ["He", "Kaiwen", ""], ["Chen", "Xu", ""]]}, {"id": "2002.10673", "submitter": "Lijun Ding", "authors": "Lijun Ding, Madeleine Udell", "title": "On the simplicity and conditioning of low rank semidefinite programs", "comments": "24 pages, 1 figure, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low rank matrix recovery problems appear widely in statistics, combinatorics,\nand imaging. One celebrated method for solving these problems is to formulate\nand solve a semidefinite program (SDP). It is often known that the exact\nsolution to the SDP with perfect data recovers the solution to the original low\nrank matrix recovery problem. It is more challenging to show that an\napproximate solution to the SDP formulated with noisy problem data acceptably\nsolves the original problem; arguments are usually ad hoc for each problem\nsetting, and can be complex.\n  In this note, we identify a set of conditions that we call simplicity that\nlimit the error due to noisy problem data or incomplete convergence. In this\nsense, simple SDPs are robust: simple SDPs can be (approximately) solved\nefficiently at scale; and the resulting approximate solutions, even with noisy\ndata, can be trusted. Moreover, we show that simplicity holds generically, and\nalso for many structured low rank matrix recovery problems, including the\nstochastic block model, $\\mathbb{Z}_2$ synchronization, and matrix completion.\nFormally, we call an SDP simple if it has a surjective constraint map, admits a\nunique primal and dual solution pair, and satisfies strong duality and strict\ncomplementarity.\n  However, simplicity is not a panacea: we show the Burer-Monteiro formulation\nof the SDP may have spurious second-order critical points, even for a simple\nSDP with a rank 1 solution.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:18:36 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 03:56:03 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ding", "Lijun", ""], ["Udell", "Madeleine", ""]]}, {"id": "2002.10674", "submitter": "Elaina Chai", "authors": "Elaina Chai, Mert Pilanci, Boris Murmann", "title": "Separating the Effects of Batch Normalization on CNN Training Speed and\n  Stability Using Classical Adaptive Filter Theory", "comments": "Presented at Asilomar Conference on Signals, Systems, and Computers,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BatchNorm) is commonly used in Convolutional Neural\nNetworks (CNNs) to improve training speed and stability. However, there is\nstill limited consensus on why this technique is effective. This paper uses\nconcepts from the traditional adaptive filter domain to provide insight into\nthe dynamics and inner workings of BatchNorm. First, we show that the\nconvolution weight updates have natural modes whose stability and convergence\nspeed are tied to the eigenvalues of the input autocorrelation matrices, which\nare controlled by BatchNorm through the convolution layers' channel-wise\nstructure. Furthermore, our experiments demonstrate that the speed and\nstability benefits are distinct effects. At low learning rates, it is\nBatchNorm's amplification of the smallest eigenvalues that improves convergence\nspeed, while at high learning rates, it is BatchNorm's suppression of the\nlargest eigenvalues that ensures stability. Lastly, we prove that in the first\ntraining step, when normalization is needed most, BatchNorm satisfies the same\noptimization as Normalized Least Mean Square (NLMS), while it continues to\napproximate this condition in subsequent steps. The analyses provided in this\npaper lay the groundwork for gaining further insight into the operation of\nmodern neural network structures using adaptive filter theory.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:25:40 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 11:22:32 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Chai", "Elaina", ""], ["Pilanci", "Mert", ""], ["Murmann", "Boris", ""]]}, {"id": "2002.10678", "submitter": "Yuki Ohnishi", "authors": "Yuki Ohnishi and Jean Honorio", "title": "Novel Change of Measure Inequalities with Applications to PAC-Bayesian\n  Bounds and Monte Carlo Estimation", "comments": "20 pages", "journal-ref": "Artificial Intelligence and Statistics (AISTATS), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce several novel change of measure inequalities for two families of\ndivergences: $f$-divergences and $\\alpha$-divergences. We show how the\nvariational representation for $f$-divergences leads to novel change of measure\ninequalities. We also present a multiplicative change of measure inequality for\n$\\alpha$-divergences and a generalized version of Hammersley-Chapman-Robbins\ninequality. Finally, we present several applications of our change of measure\ninequalities, including PAC-Bayesian bounds for various classes of losses and\nnon-asymptotic intervals for Monte Carlo estimates.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 05:36:22 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 10:11:04 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Ohnishi", "Yuki", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.10689", "submitter": "Yilun Xu", "authors": "Yilun Xu, Shengjia Zhao, Jiaming Song, Russell Stewart, Stefano Ermon", "title": "A Theory of Usable Information Under Computational Constraints", "comments": "ICLR 2020 (Talk)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for reasoning about information in complex\nsystems. Our foundation is based on a variational extension of Shannon's\ninformation theory that takes into account the modeling power and computational\nconstraints of the observer. The resulting \\emph{predictive\n$\\mathcal{V}$-information} encompasses mutual information and other notions of\ninformativeness such as the coefficient of determination. Unlike Shannon's\nmutual information and in violation of the data processing inequality,\n$\\mathcal{V}$-information can be created through computation. This is\nconsistent with deep neural networks extracting hierarchies of progressively\nmore informative features in representation learning. Additionally, we show\nthat by incorporating computational constraints, $\\mathcal{V}$-information can\nbe reliably estimated from data even in high dimensions with PAC-style\nguarantees. Empirically, we demonstrate predictive $\\mathcal{V}$-information is\nmore effective than mutual information for structure learning and fair\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 06:09:30 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "Yilun", ""], ["Zhao", "Shengjia", ""], ["Song", "Jiaming", ""], ["Stewart", "Russell", ""], ["Ermon", "Stefano", ""]]}, {"id": "2002.10695", "submitter": "Hung Le", "authors": "Hung Le, Nancy F. Chen", "title": "Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge", "comments": "Accepted at DSTC Workshop at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-Visual Scene-Aware Dialog (AVSD) is an extension from Video Question\nAnswering (QA) whereby the dialogue agent is required to generate natural\nlanguage responses to address user queries and carry on conversations. This is\na challenging task as it consists of video features of multiple modalities,\nincluding text, visual, and audio features. The agent also needs to learn\nsemantic dependencies among user utterances and system responses to make\ncoherent conversations with humans. In this work, we describe our submission to\nthe AVSD track of the 8th Dialogue System Technology Challenge. We adopt\ndot-product attention to combine text and non-text features of input video. We\nfurther enhance the generation capability of the dialogue agent by adopting\npointer networks to point to tokens from multiple source sequences in each\ngeneration step. Our systems achieve high performance in automatic metrics and\nobtain 5th and 6th place in human evaluation among all submissions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 06:41:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Le", "Hung", ""], ["Chen", "Nancy F.", ""]]}, {"id": "2002.10697", "submitter": "Faez Ahmed", "authors": "Faez Ahmed, John Dickerson, Mark Fuge", "title": "Forming Diverse Teams from Sequentially Arriving People", "comments": "Journal of Mechanical Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative work often benefits from having teams or organizations with\nheterogeneous members. In this paper, we present a method to form such diverse\nteams from people arriving sequentially over time. We define a monotone\nsubmodular objective function that combines the diversity and quality of a team\nand propose an algorithm to maximize the objective while satisfying multiple\nconstraints. This allows us to balance both how diverse the team is and how\nwell it can perform the task at hand. Using crowd experiments, we show that, in\npractice, the algorithm leads to large gains in team diversity. Using\nsimulations, we show how to quantify the additional cost of forming diverse\nteams and how to address the problem of simultaneously maximizing diversity for\nseveral attributes (e.g., country of origin, gender). Our method has\napplications in collaborative work ranging from team formation, the assignment\nof workers to teams in crowdsourcing, and reviewer allocation to journal papers\narriving sequentially. Our code is publicly accessible for further research.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:00:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ahmed", "Faez", ""], ["Dickerson", "John", ""], ["Fuge", "Mark", ""]]}, {"id": "2002.10703", "submitter": "Xiaodong Qi", "authors": "Xiaodong Qi, Lansheng Han", "title": "G\\\"odel's Sentence Is An Adversarial Example But Unsolvable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, different types of adversarial examples from different\nfields have emerged endlessly, including purely natural ones without\nperturbations. A variety of defenses are proposed and then broken quickly. Two\nfundamental questions need to be asked: What's the reason for the existence of\nadversarial examples and are adversarial examples unsolvable? In this paper, we\nwill show the reason for the existence of adversarial examples is there are\nnon-isomorphic natural explanations that can all explain data set.\nSpecifically, for two natural explanations of being true and provable,\nG\\\"odel's sentence is an adversarial example but ineliminable. It can't be\nsolved by the re-accumulation of data set or the re-improvement of learning\nalgorithm. Finally, from the perspective of computability, we will prove the\nincomputability for adversarial examples, which are unrecognizable.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:20:17 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Qi", "Xiaodong", ""], ["Han", "Lansheng", ""]]}, {"id": "2002.10709", "submitter": "Arkopal Choudhury", "authors": "Arkopal Choudhury and Michael R. Kosorok", "title": "Missing Data Imputation for Classification Problems", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imputation of missing data is a common application in various classification\nproblems where the feature training matrix has missingness. A widely used\nsolution to this imputation problem is based on the lazy learning technique,\n$k$-nearest neighbor (kNN) approach. However, most of the previous work on\nmissing data does not take into account the presence of the class label in the\nclassification problem. Also, existing kNN imputation methods use variants of\nMinkowski distance as a measure of distance, which does not work well with\nheterogeneous data. In this paper, we propose a novel iterative kNN imputation\ntechnique based on class weighted grey distance between the missing datum and\nall the training data. Grey distance works well in heterogeneous data with\nmissing instances. The distance is weighted by Mutual Information (MI) which is\na measure of feature relevance between the features and the class label. This\nensures that the imputation of the training data is directed towards improving\nclassification performance. This class weighted grey kNN imputation algorithm\ndemonstrates improved performance when compared to other kNN imputation\nalgorithms, as well as standard imputation algorithms such as MICE and\nmissForest, in imputation and classification problems. These problems are based\non simulated scenarios and UCI datasets with various rates of missingness.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:48:45 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Choudhury", "Arkopal", ""], ["Kosorok", "Michael R.", ""]]}, {"id": "2002.10711", "submitter": "Javier Fernandez-Marques", "authors": "Javier Fernandez-Marques, Paul N. Whatmough, Andrew Mundy, Matthew\n  Mattina", "title": "Searching for Winograd-aware Quantized Networks", "comments": "Published as a conference paper at MLSys 2020", "journal-ref": "Proceedings of Machine Learning and Systems (2020), 14-29", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight architectural designs of Convolutional Neural Networks (CNNs)\ntogether with quantization have paved the way for the deployment of demanding\ncomputer vision applications on mobile devices. Parallel to this, alternative\nformulations to the convolution operation such as FFT, Strassen and Winograd,\nhave been adapted for use in CNNs offering further speedups. Winograd\nconvolutions are the fastest known algorithm for spatially small convolutions,\nbut exploiting their full potential comes with the burden of numerical error,\nrendering them unusable in quantized contexts. In this work we propose a\nWinograd-aware formulation of convolution layers which exposes the numerical\ninaccuracies introduced by the Winograd transformations to the learning of the\nmodel parameters, enabling the design of competitive quantized models without\nimpacting model size. We also address the source of the numerical error and\npropose a relaxation on the form of the transformation matrices, resulting in\nup to 10% higher classification accuracy on CIFAR-10. Finally, we propose\nwiNAS, a neural architecture search (NAS) framework that jointly optimizes a\ngiven macro-architecture for accuracy and latency leveraging Winograd-aware\nlayers. A Winograd-aware ResNet-18 optimized with wiNAS for CIFAR-10 results in\n2.66x speedup compared to im2row, one of the most widely used optimized\nconvolution implementations, with no loss in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:53:53 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Fernandez-Marques", "Javier", ""], ["Whatmough", "Paul N.", ""], ["Mundy", "Andrew", ""], ["Mattina", "Matthew", ""]]}, {"id": "2002.10716", "submitter": "Aditi Raghunathan", "authors": "Aditi Raghunathan, Sang Michael Xie, Fanny Yang, John Duchi and Percy\n  Liang", "title": "Understanding and Mitigating the Tradeoff Between Robustness and\n  Accuracy", "comments": "Appearing at International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training augments the training set with perturbations to improve\nthe robust error (over worst-case perturbations), but it often leads to an\nincrease in the standard error (on unperturbed test inputs). Previous\nexplanations for this tradeoff rely on the assumption that no predictor in the\nhypothesis class has low standard and robust error. In this work, we precisely\ncharacterize the effect of augmentation on the standard error in linear\nregression when the optimal linear predictor has zero standard and robust\nerror. In particular, we show that the standard error could increase even when\nthe augmented perturbations have noiseless observations from the optimal linear\npredictor. We then prove that the recently proposed robust self-training (RST)\nestimator improves robust error without sacrificing standard error for\nnoiseless linear regression. Empirically, for neural networks, we find that RST\nwith different adversarial training methods improves both standard and robust\nerror for random and adversarial rotations and adversarial $\\ell_\\infty$\nperturbations in CIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:03:01 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 21:03:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Raghunathan", "Aditi", ""], ["Xie", "Sang Michael", ""], ["Yang", "Fanny", ""], ["Duchi", "John", ""], ["Liang", "Percy", ""]]}, {"id": "2002.10733", "submitter": "Alexander Levine", "authors": "Alexander Levine, Soheil Feizi", "title": "(De)Randomized Smoothing for Certifiable Defense against Patch Attacks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patch adversarial attacks on images, in which the attacker can distort pixels\nwithin a region of bounded size, are an important threat model since they\nprovide a quantitative model for physical adversarial attacks. In this paper,\nwe introduce a certifiable defense against patch attacks that guarantees for a\ngiven image and patch attack size, no patch adversarial examples exist. Our\nmethod is related to the broad class of randomized smoothing robustness schemes\nwhich provide high-confidence probabilistic robustness certificates. By\nexploiting the fact that patch attacks are more constrained than general sparse\nattacks, we derive meaningfully large robustness certificates against them.\nAdditionally, in contrast to smoothing-based defenses against L_p and sparse\nattacks, our defense method against patch attacks is de-randomized, yielding\nimproved, deterministic certificates. Compared to the existing patch\ncertification method proposed by Chiang et al. (2020), which relies on interval\nbound propagation, our method can be trained significantly faster, achieves\nhigh clean and certified robust accuracy on CIFAR-10, and provides certificates\nat ImageNet scale. For example, for a 5-by-5 patch attack on CIFAR-10, our\nmethod achieves up to around 57.6% certified accuracy (with a classifier with\naround 83.8% clean accuracy), compared to at most 30.3% certified accuracy for\nthe existing method (with a classifier with around 47.8% clean accuracy). Our\nresults effectively establish a new state-of-the-art of certifiable defense\nagainst patch attacks on CIFAR-10 and ImageNet. Code is available at\nhttps://github.com/alevine0/patchSmoothing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:39:46 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:09:10 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 06:36:56 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Levine", "Alexander", ""], ["Feizi", "Soheil", ""]]}, {"id": "2002.10738", "submitter": "Anji Liu", "authors": "Anji Liu, Yitao Liang, Guy Van den Broeck", "title": "Off-Policy Deep Reinforcement Learning with Analogous Disentangled\n  Exploration", "comments": "In Proc. of the 19th International Conference on Autonomous Agents\n  and Multiagent Systems, IFAAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning (RL) is concerned with learning a rewarding\npolicy by executing another policy that gathers samples of experience. While\nthe former policy (i.e. target policy) is rewarding but in-expressive (in most\ncases, deterministic), doing well in the latter task, in contrast, requires an\nexpressive policy (i.e. behavior policy) that offers guided and effective\nexploration. Contrary to most methods that make a trade-off between optimality\nand expressiveness, disentangled frameworks explicitly decouple the two\nobjectives, which each is dealt with by a distinct separate policy. Although\nbeing able to freely design and optimize the two policies with respect to their\nown objectives, naively disentangling them can lead to inefficient learning or\nstability issues. To mitigate this problem, our proposed method Analogous\nDisentangled Actor-Critic (ADAC) designs analogous pairs of actors and critics.\nSpecifically, ADAC leverages a key property about Stein variational gradient\ndescent (SVGD) to constraint the expressive energy-based behavior policy with\nrespect to the target one for effective exploration. Additionally, an analogous\ncritic pair is introduced to incorporate intrinsic rewards in a principled\nmanner, with theoretical guarantees on the overall learning stability and\neffectiveness. We empirically evaluate environment-reward-only ADAC on 14\ncontinuous-control tasks and report the state-of-the-art on 10 of them. We\nfurther demonstrate ADAC, when paired with intrinsic rewards, outperform\nalternatives in exploration-challenging tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:49:11 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:19:22 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liu", "Anji", ""], ["Liang", "Yitao", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2002.10742", "submitter": "Michele Lombardi", "authors": "Mattia Silvestri, Michele Lombardi, Michela Milano", "title": "Injecting Domain Knowledge in Neural Networks: a Controlled Experiment\n  on a Constrained Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given enough data, Deep Neural Networks (DNNs) are capable of learning\ncomplex input-output relations with high accuracy. In several domains, however,\ndata is scarce or expensive to retrieve, while a substantial amount of expert\nknowledge is available. It seems reasonable that if we can inject this\nadditional information in the DNN, we could ease the learning process. One such\ncase is that of Constraint Problems, for which declarative approaches exists\nand pure ML solutions have obtained mixed success. Using a classical\nconstrained problem as a case study, we perform controlled experiments to probe\nthe impact of progressively adding domain and empirical knowledge in the DNN.\nOur results are very encouraging, showing that (at least in our setup)\nembedding domain knowledge at training time can have a considerable effect and\nthat a small amount of empirical knowledge is sufficient to obtain practically\nuseful results.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:59:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Silvestri", "Mattia", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10758", "submitter": "Koya Sato", "authors": "Koya Sato, Yasuyuki Satoh, Daisuke Sugimura", "title": "Network-Density-Controlled Decentralized Parallel Stochastic Gradient\n  Descent in Wireless Systems", "comments": "6 pages, 11 figures. Accepted for presentation at IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a communication strategy for decentralized learning on\nwireless systems. Our discussion is based on the decentralized parallel\nstochastic gradient descent (D-PSGD), which is one of the state-of-the-art\nalgorithms for decentralized learning. The main contribution of this paper is\nto raise a novel open question for decentralized learning on wireless systems:\nthere is a possibility that the density of a network topology significantly\ninfluences the runtime performance of D-PSGD. In general, it is difficult to\nguarantee delay-free communications without any communication deterioration in\nreal wireless network systems because of path loss and multi-path fading. These\nfactors significantly degrade the runtime performance of D-PSGD. To alleviate\nsuch problems, we first analyze the runtime performance of D-PSGD by\nconsidering real wireless systems. This analysis yields the key insights that\ndense network topology (1) does not significantly gain the training accuracy of\nD-PSGD compared to sparse one, and (2) strongly degrades the runtime\nperformance because this setting generally requires to utilize a low-rate\ntransmission. Based on these findings, we propose a novel communication\nstrategy, in which each node estimates optimal transmission rates such that\ncommunication time during the D-PSGD optimization is minimized under the\nconstraint of network density, which is characterized by radio propagation\nproperty. The proposed strategy enables to improve the runtime performance of\nD-PSGD in wireless systems. Numerical simulations reveal that the proposed\nstrategy is capable of enhancing the runtime performance of D-PSGD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:20:10 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Sato", "Koya", ""], ["Satoh", "Yasuyuki", ""], ["Sugimura", "Daisuke", ""]]}, {"id": "2002.10766", "submitter": "Michele Lombardi", "authors": "Fabrizio Detassis, Michele Lombardi, Michela Milano", "title": "Teaching the Old Dog New Tricks: Supervised Learning with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding constraint support in Machine Learning has the potential to address\noutstanding issues in data-driven AI systems, such as safety and fairness.\nExisting approaches typically apply constrained optimization techniques to ML\ntraining, enforce constraint satisfaction by adjusting the model design, or use\nconstraints to correct the output. Here, we investigate a different,\ncomplementary, strategy based on \"teaching\" constraint satisfaction to a\nsupervised ML method via the direct use of a state-of-the-art constraint\nsolver: this enables taking advantage of decades of research on constrained\noptimization with limited effort. In practice, we use a decomposition scheme\nalternating master steps (in charge of enforcing the constraints) and learner\nsteps (where any supervised ML model and training algorithm can be employed).\nThe process leads to approximate constraint satisfaction in general, and\nconvergence properties are difficult to establish; despite this fact, we found\nempirically that even a na\\\"ive setup of our approach performs well on ML tasks\nwith fairness constraints, and on classical datasets with synthetic\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:47:39 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 16:39:24 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Detassis", "Fabrizio", ""], ["Lombardi", "Michele", ""], ["Milano", "Michela", ""]]}, {"id": "2002.10767", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski and Ashfaqur Rahman", "title": "Sequence-to-Sequence Imputation of Missing Sensor Data", "comments": null, "journal-ref": "In: Liu J., Bailey J. (eds) AI 2019: Advances in Artificial\n  Intelligence. AI 2019. Lecture Notes in Computer Science, vol 11919.\n  Springer, Cham", "doi": "10.1007/978-3-030-35288-2_22", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the sequence-to-sequence (encoder-decoder) model is considered the\nstate-of-the-art in deep learning sequence models, there is little research\ninto using this model for recovering missing sensor data. The key challenge is\nthat the missing sensor data problem typically comprises three sequences (a\nsequence of observed samples, followed by a sequence of missing samples,\nfollowed by another sequence of observed samples) whereas, the\nsequence-to-sequence model only considers two sequences (an input sequence and\nan output sequence). We address this problem by formulating a\nsequence-to-sequence in a novel way. A forward RNN encodes the data observed\nbefore the missing sequence and a backward RNN encodes the data observed after\nthe missing sequence. A decoder decodes the two encoders in a novel way to\npredict the missing data. We demonstrate that this model produces the lowest\nerrors in 12% more cases than the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:51:20 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["Rahman", "Ashfaqur", ""]]}, {"id": "2002.10769", "submitter": "Xiaopeng Luo Dr.", "authors": "Xin Xu and Xiaopeng Luo", "title": "Can speed up the convergence rate of stochastic gradient methods to\n  $\\mathcal{O}(1/k^2)$ by a gradient averaging strategy?", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the question of whether it is possible to apply a\ngradient averaging strategy to improve on the sublinear convergence rates\nwithout any increase in storage. Our analysis reveals that a positive answer\nrequires an appropriate averaging strategy and iterations that satisfy the\nvariance dominant condition. As an interesting fact, we show that if the\niterative variance we defined is always dominant even a little bit in the\nstochastic gradient iterations, the proposed gradient averaging strategy can\nincrease the convergence rate $\\mathcal{O}(1/k)$ to $\\mathcal{O}(1/k^2)$ in\nprobability for the strongly convex objectives with Lipschitz gradients. This\nconclusion suggests how we should control the stochastic gradient iterations to\nimprove the rate of convergence.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 09:58:23 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "Xin", ""], ["Luo", "Xiaopeng", ""]]}, {"id": "2002.10772", "submitter": "Xien Liu", "authors": "Xien Liu, Song Wang, Xiao Zhang, Xinxin You, Ji Wu and Dejing Dou", "title": "Label-guided Learning for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification is one of the most important and fundamental tasks in\nnatural language processing. Performance of this task mainly dependents on text\nrepresentation learning. Currently, most existing learning frameworks mainly\nfocus on encoding local contextual information between words. These methods\nalways neglect to exploit global clues, such as label information, for encoding\ntext information. In this study, we propose a label-guided learning framework\nLguidedLearn for text representation and classification. Our method is novel\nbut simple that we only insert a label-guided encoding layer into the commonly\nused text representation learning schemas. That label-guided layer performs\nlabel-based attentive encoding to map the universal text embedding (encoded by\na contextual information learner) into different label spaces, resulting in\nlabel-wise embeddings. In our proposed framework, the label-guided layer can be\neasily and directly applied with a contextual encoding method to perform\njointly learning. Text information is encoded based on both the local\ncontextual information and the global label clues. Therefore, the obtained text\nembeddings are more robust and discriminative for text classification.\nExtensive experiments are conducted on benchmark datasets to illustrate the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:05:56 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Liu", "Xien", ""], ["Wang", "Song", ""], ["Zhang", "Xiao", ""], ["You", "Xinxin", ""], ["Wu", "Ji", ""], ["Dou", "Dejing", ""]]}, {"id": "2002.10778", "submitter": "Xiangming Meng", "authors": "Xiangming Meng and Roman Bachmann and Mohammad Emtiyaz Khan", "title": "Training Binary Neural Networks using the Bayesian Learning Rule", "comments": "accepted by ICML 2020, the camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with binary weights are computation-efficient and\nhardware-friendly, but their training is challenging because it involves a\ndiscrete optimization problem. Surprisingly, ignoring the discrete nature of\nthe problem and using gradient-based methods, such as the Straight-Through\nEstimator, still works well in practice. This raises the question: are there\nprincipled approaches which justify such methods? In this paper, we propose\nsuch an approach using the Bayesian learning rule. The rule, when applied to\nestimate a Bernoulli distribution over the binary weights, results in an\nalgorithm which justifies some of the algorithmic choices made by the previous\napproaches. The algorithm not only obtains state-of-the-art performance, but\nalso enables uncertainty estimation for continual learning to avoid\ncatastrophic forgetting. Our work provides a principled approach for training\nbinary neural networks which justifies and extends existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:20:10 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 09:04:24 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 14:48:33 GMT"}, {"version": "v4", "created": "Tue, 18 Aug 2020 00:48:15 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Meng", "Xiangming", ""], ["Bachmann", "Roman", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2002.10788", "submitter": "Emilio Incerto", "authors": "Giulio Garbi and Emilio Incerto and Mirco Tribastone", "title": "Learning Queuing Networks by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3358960.3379134", "report-no": null, "categories": "cs.PF cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that building analytical performance models in practice is\ndifficult because it requires a considerable degree of proficiency in the\nunderlying mathematics. In this paper, we propose a machine-learning approach\nto derive performance models from data. We focus on queuing networks, and\ncrucially exploit a deterministic approximation of their average dynamics in\nterms of a compact system of ordinary differential equations. We encode these\nequations into a recurrent neural network whose weights can be directly related\nto model parameters. This allows for an interpretable structure of the neural\nnetwork, which can be trained from system measurements to yield a white-box\nparameterized model that can be used for prediction purposes such as what-if\nanalyses and capacity planning. Using synthetic models as well as a real case\nstudy of a load-balancing system, we show the effectiveness of our technique in\nyielding models with high predictive power.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:56:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Garbi", "Giulio", ""], ["Incerto", "Emilio", ""], ["Tribastone", "Mirco", ""]]}, {"id": "2002.10790", "submitter": "Yifan Hu", "authors": "Yifan Hu, Siqi Zhang, Xin Chen, Niao He", "title": "Biased Stochastic Gradient Descent for Conditional Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Stochastic Optimization (CSO) covers a variety of applications\nranging from meta-learning and causal inference to invariant learning. However,\nconstructing unbiased gradient estimates in CSO is challenging due to the\ncomposition structure. As an alternative, we propose a biased stochastic\ngradient descent (BSGD) algorithm and study the bias-variance tradeoff under\ndifferent structural assumptions. We establish the sample complexities of BSGD\nfor strongly convex, convex, and weakly convex objectives, under smooth and\nnon-smooth conditions. We also provide matching lower bounds of BSGD for convex\nCSO objectives. Extensive numerical experiments are conducted to illustrate the\nperformance of BSGD on robust logistic regression, model-agnostic meta-learning\n(MAML), and instrumental variable regression (IV).\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:57:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hu", "Yifan", ""], ["Zhang", "Siqi", ""], ["Chen", "Xin", ""], ["He", "Niao", ""]]}, {"id": "2002.10791", "submitter": "Soorya Gopalakrishnan", "authors": "Metehan Cekic, Soorya Gopalakrishnan, Upamanyu Madhow", "title": "Wireless Fingerprinting via Deep Learning: The Impact of Confounding\n  Factors", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we distinguish between two wireless transmitters sending exactly the same\nmessage, using the same protocol? The opportunity for doing so arises due to\nsubtle nonlinear variations across transmitters, even those made by the same\nmanufacturer. Since these effects are difficult to model explicitly, we\ninvestigate learning device fingerprints using complex-valued deep neural\nnetworks (DNNs) that take as input the complex baseband signal at the receiver.\nWe ask whether such fingerprints can be made robust to distribution shifts\nacross time and locations due to clock drift and variations in the wireless\nchannel. In this paper, we point out that, unless proactively discouraged from\ndoing so, DNNs learn these strong confounding features rather than the\nnonlinear device-specific characteristics that we seek to learn. We propose and\nevaluate strategies, based on augmentation and estimation, to promote\ngeneralization across realizations of these confounding factors, using data\nfrom WiFi and ADS-B protocols. We conclude that, while DNN training has the\nadvantage of not requiring explicit signal models, significant modeling\ninsights are required to focus the learning on the effects we wish to capture.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:02:45 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 20:09:07 GMT"}, {"version": "v3", "created": "Tue, 9 Mar 2021 10:59:29 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Cekic", "Metehan", ""], ["Gopalakrishnan", "Soorya", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "2002.10801", "submitter": "Lei Huang", "authors": "Lei Huang, Jie Qin, Li Liu, Fan Zhu, Ling Shao", "title": "Layer-wise Conditioning Analysis in Exploring the Learning Dynamics of\n  DNNs", "comments": "Accepted to ECCV 2020. The code is available at:\n  https://github.com/huangleiBuaa/LayerwiseCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditioning analysis uncovers the landscape of an optimization objective by\nexploring the spectrum of its curvature matrix. This has been well explored\ntheoretically for linear models. We extend this analysis to deep neural\nnetworks (DNNs) in order to investigate their learning dynamics. To this end,\nwe propose layer-wise conditioning analysis, which explores the optimization\nlandscape with respect to each layer independently. Such an analysis is\ntheoretically supported under mild assumptions that approximately hold in\npractice. Based on our analysis, we show that batch normalization (BN) can\nstabilize the training, but sometimes result in the false impression of a local\nminimum, which has detrimental effects on the learning. Besides, we\nexperimentally observe that BN can improve the layer-wise conditioning of the\noptimization problem. Finally, we find that the last linear layer of a very\ndeep residual network displays ill-conditioned behavior. We solve this problem\nby only adding one BN layer before the last linear layer, which achieves\nimproved performance over the original and pre-activation residual networks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:40:27 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 11:21:06 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 13:30:54 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Huang", "Lei", ""], ["Qin", "Jie", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Shao", "Ling", ""]]}, {"id": "2002.10816", "submitter": "Edouard Leurent", "authors": "Edouard Leurent and Denis Efimov and Odalric-Ambrym Maillard", "title": "Robust-Adaptive Control of Linear Systems: beyond Quadratic Costs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of robust and adaptive model predictive control (MPC)\nof a linear system, with unknown parameters that are learned along the way\n(adaptive), in a critical setting where failures must be prevented (robust).\nThis problem has been studied from different perspectives by different\ncommunities. However, the existing theory deals only with the case of quadratic\ncosts (the LQ problem), which limits applications to stabilisation and tracking\ntasks only. In order to handle more general (non-convex) costs that naturally\narise in many practical problems, we carefully select and bring together\nseveral tools from different communities, namely non-asymptotic linear\nregression, recent results in interval prediction, and tree-based planning.\nCombining and adapting the theoretical guarantees at each layer is non trivial,\nand we provide the first end-to-end suboptimality analysis for this setting.\nInterestingly, our analysis naturally adapts to handle many models and combines\nwith a data-driven robust model selection strategy, which enables to relax the\nmodelling assumptions. Last, we strive to preserve tractability at any stage of\nthe method, that we illustrate on two challenging simulated environments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:17 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:15:40 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Leurent", "Edouard", ""], ["Efimov", "Denis", ""], ["Maillard", "Odalric-Ambrym", ""]]}, {"id": "2002.10819", "submitter": "Darko Stern", "authors": "Stefan Eggenreich, Christian Payer, Martin Urschler, Darko \\v{S}tern", "title": "Variational Inference and Bayesian CNNs for Uncertainty Estimation in\n  Multi-Factorial Bone Age Prediction", "comments": "accepted at Medical Imaging Meets NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Additionally to the extensive use in clinical medicine, biological age (BA)\nin legal medicine is used to assess unknown chronological age (CA) in\napplications where identification documents are not available. Automatic\nmethods for age estimation proposed in the literature are predicting point\nestimates, which can be misleading without the quantification of predictive\nuncertainty. In our multi-factorial age estimation method from MRI data, we\nused the Variational Inference approach to estimate the uncertainty of a\nBayesian CNN model. Distinguishing model uncertainty from data uncertainty, we\ninterpreted data uncertainty as biological variation, i.e. the range of\npossible CA of subjects having the same BA.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:30:21 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eggenreich", "Stefan", ""], ["Payer", "Christian", ""], ["Urschler", "Martin", ""], ["\u0160tern", "Darko", ""]]}, {"id": "2002.10832", "submitter": "Jacopo Staiano", "authors": "Thomas Scialom, Patrick Bordes, Paul-Alexis Dray, Jacopo Staiano,\n  Patrick Gallinari", "title": "What BERT Sees: Cross-Modal Transfer for Visual Question Generation", "comments": "INLG 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models have recently contributed to significant advances\nin NLP tasks. Recently, multi-modal versions of BERT have been developed, using\nheavy pre-training relying on vast corpora of aligned textual and image data,\nprimarily applied to classification tasks such as VQA. In this paper, we are\ninterested in evaluating the visual capabilities of BERT out-of-the-box, by\navoiding pre-training made on supplementary data. We choose to study Visual\nQuestion Generation, a task of great interest for grounded dialog, that enables\nto study the impact of each modality (as input can be visual and/or textual).\nMoreover, the generation aspect of the task requires an adaptation since BERT\nis primarily designed as an encoder. We introduce BERT-gen, a BERT-based\narchitecture for text generation, able to leverage on either mono- or multi-\nmodal representations. The results reported under different configurations\nindicate an innate capacity for BERT-gen to adapt to multi-modal data and text\ngeneration, even with few data available, avoiding expensive pre-training. The\nproposed model obtains substantial improvements over the state-of-the-art on\ntwo established VQG datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:44:36 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 13:07:57 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 15:48:35 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Scialom", "Thomas", ""], ["Bordes", "Patrick", ""], ["Dray", "Paul-Alexis", ""], ["Staiano", "Jacopo", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2002.10837", "submitter": "Imke Mayer", "authors": "Imke Mayer, Julie Josse, F\\'elix Raimundo, Jean-Philippe Vert", "title": "MissDeepCausal: Causal Inference from Incomplete Data Using Deep Latent\n  Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring causal effects of a treatment, intervention or policy from\nobservational data is central to many applications. However, state-of-the-art\nmethods for causal inference seldom consider the possibility that covariates\nhave missing values, which is ubiquitous in many real-world analyses. Missing\ndata greatly complicate causal inference procedures as they require an adapted\nunconfoundedness hypothesis which can be difficult to justify in practice. We\ncircumvent this issue by considering latent confounders whose distribution is\nlearned through variational autoencoders adapted to missing values. They can be\nused either as a pre-processing step prior to causal inference but we also\nsuggest to embed them in a multiple imputation strategy to take into account\nthe variability due to missing values. Numerical experiments demonstrate the\neffectiveness of the proposed methodology especially for non-linear models\ncompared to competitors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:58:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Mayer", "Imke", ""], ["Josse", "Julie", ""], ["Raimundo", "F\u00e9lix", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2002.10855", "submitter": "Ryohei Hisano", "authors": "Takahiro Yoshida, Ryohei Hisano, Takaaki Ohnishi", "title": "Gaussian Hierarchical Latent Dirichlet Allocation: Bringing Polysemy\n  Back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are widely used to discover the latent representation of a set\nof documents. The two canonical models are latent Dirichlet allocation, and\nGaussian latent Dirichlet allocation, where the former uses multinomial\ndistributions over words, and the latter uses multivariate Gaussian\ndistributions over pre-trained word embedding vectors as the latent topic\nrepresentations, respectively. Compared with latent Dirichlet allocation,\nGaussian latent Dirichlet allocation is limited in the sense that it does not\ncapture the polysemy of a word such as ``bank.'' In this paper, we show that\nGaussian latent Dirichlet allocation could recover the ability to capture\npolysemy by introducing a hierarchical structure in the set of topics that the\nmodel can use to represent a given document. Our Gaussian hierarchical latent\nDirichlet allocation significantly improves polysemy detection compared with\nGaussian-based models and provides more parsimonious topic representations\ncompared with hierarchical latent Dirichlet allocation. Our extensive\nquantitative experiments show that our model also achieves better topic\ncoherence and held-out document predictive accuracy over a wide range of corpus\nand word embedding vectors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 13:52:20 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Yoshida", "Takahiro", ""], ["Hisano", "Ryohei", ""], ["Ohnishi", "Takaaki", ""]]}, {"id": "2002.10870", "submitter": "Mohammad-Ali Javidian", "authors": "Mohammad Ali Javidian, Marco Valtorta, Pooyan Jamshidi", "title": "AMP Chain Graphs: Minimal Separators and Structure Learning Algorithms", "comments": "This is an arXiv version of the paper that has been accepted for\n  publication in the Journal of Artificial Intelligence Research (JAIR). arXiv\n  admin note: text overlap with arXiv:1211.3295 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding a minimal separator in an\nAndersson-Madigan-Perlman chain graph (AMP CG), namely, finding a set Z of\nnodes that separates a given nonadjacent pair of nodes such that no proper\nsubset of Z separates that pair. We analyze several versions of this problem\nand offer polynomial-time algorithms for each. These include finding a minimal\nseparator from a restricted set of nodes, finding a minimal separator for two\ngiven disjoint sets, and testing whether a given separator is minimal. To\naddress the problem of learning the structure of AMP CGs from data, we show\nthat the PC-like algorithm (Pena, 2012) is order-dependent, in the sense that\nthe output can depend on the order in which the variables are given. We propose\nseveral modifications of the PC-like algorithm that remove part or all of this\norder-dependence. We also extend the decomposition-based approach for learning\nBayesian networks (BNs) proposed by (Xie et al., 2006) to learn AMP CGs, which\ninclude BNs as a special case, under the faithfulness assumption. We prove the\ncorrectness of our extension using the minimal separator results. Using\nstandard benchmarks and synthetically generated models and data in our\nexperiments demonstrate the competitive performance of our decomposition-based\nmethod, called LCD-AMP, in comparison with the (modified versions of) PC-like\nalgorithm. The LCD-AMP algorithm usually outperforms the PC-like algorithm, and\nour modifications of the PC-like algorithm learn structures that are more\nsimilar to the underlying ground truth graphs than the original PC-like\nalgorithm, especially in high-dimensional settings. In particular, we\nempirically show that the results of both algorithms are more accurate and\nstabler when the sample size is reasonably large and the underlying graph is\nsparse.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 18:14:14 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 20:38:42 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Javidian", "Mohammad Ali", ""], ["Valtorta", "Marco", ""], ["Jamshidi", "Pooyan", ""]]}, {"id": "2002.10878", "submitter": "Fatemeh Najibi", "authors": "Fatemeh Najibi, Dimitra Apostolopoulou, and Eduardo Alonso", "title": "Gaussian Process Regression for Probabilistic Short-term Solar Output\n  Forecast", "comments": null, "journal-ref": null, "doi": "10.1016/j.ijepes.2021.106916", "report-no": null, "categories": "stat.AP cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing concerns of climate change, renewable resources such as\nphotovoltaic (PV) have gained popularity as a means of energy generation. The\nsmooth integration of such resources in power system operations is enabled by\naccurate forecasting mechanisms that address their inherent intermittency and\nvariability. This paper proposes a probabilistic framework to predict\nshort-term PV output taking into account the uncertainty of weather. To this\nend, we make use of datasets that comprise of power output and meteorological\ndata such as irradiance, temperature, zenith, and azimuth. First, we categorise\nthe data into four groups based on solar output and time by using k-means\nclustering. Next, a correlation study is performed to choose the weather\nfeatures which affect solar output to a greater extent. Finally, we determine a\nfunction that relates the aforementioned selected features with solar output by\nusing Gaussian Process Regression and Matern 5/2 as a kernel function. We\nvalidate our method with five solar generation plants in different locations\nand compare the results with existing methodologies. More specifically, in\norder to test the proposed model, two different methods are used: (i) 5-fold\ncross-validation; and (ii) holding out 30 random days as test data. To confirm\nthe model accuracy, we apply our framework 30 independent times on each of the\nfour clusters. The average error follows a normal distribution, and with 95%\nconfidence level, it takes values between -1.6% to 1.4%.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 15:54:37 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Najibi", "Fatemeh", ""], ["Apostolopoulou", "Dimitra", ""], ["Alonso", "Eduardo", ""]]}, {"id": "2002.10880", "submitter": "Charlie Nash", "authors": "Charlie Nash, Yaroslav Ganin, S. M. Ali Eslami, Peter W. Battaglia", "title": "PolyGen: An Autoregressive Generative Model of 3D Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polygon meshes are an efficient representation of 3D geometry, and are of\ncentral importance in computer graphics, robotics and games development.\nExisting learning-based approaches have avoided the challenges of working with\n3D meshes, instead using alternative object representations that are more\ncompatible with neural architectures and training approaches. We present an\napproach which models the mesh directly, predicting mesh vertices and faces\nsequentially using a Transformer-based architecture. Our model can condition on\na range of inputs, including object classes, voxels, and images, and because\nthe model is probabilistic it can produce samples that capture uncertainty in\nambiguous scenarios. We show that the model is capable of producing\nhigh-quality, usable meshes, and establish log-likelihood benchmarks for the\nmesh-modelling task. We also evaluate the conditional models on surface\nreconstruction metrics against alternative methods, and demonstrate competitive\nperformance despite not training directly on this task.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 17:16:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Nash", "Charlie", ""], ["Ganin", "Yaroslav", ""], ["Eslami", "S. M. Ali", ""], ["Battaglia", "Peter W.", ""]]}, {"id": "2002.10904", "submitter": "Mark Rucker", "authors": "Mark A. Rucker, Layne T. Watson, Laura E. Barnes and Matthew S. Gerber", "title": "Human Apprenticeship Learning via Kernel-based Inverse Reinforcement\n  Learning", "comments": "31 pages, 23 figures, Submitted to Journal of Artificial Intelligence\n  Research, \"for source code, see https://github.com/mrucker/kpirl-kla\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been well demonstrated that inverse reinforcement learning (IRL) is an\neffective technique for teaching machines to perform tasks at human skill\nlevels given human demonstrations (i.e., human to machine apprenticeship\nlearning). This paper seeks to show that a similar application can be\ndemonstrated with human learners. That is, given demonstrations from human\nexperts inverse reinforcement learning techniques can be used to teach other\nhumans to perform at higher skill levels (i.e., human to human apprenticeship\nlearning). To show this two experiments were conducted using a simple,\nreal-time web game where players were asked to touch targets in order to earn\nas many points as possible. For the experiment player performance was defined\nas the number of targets a player touched, irrespective of the points that a\nplayer actually earned. This allowed for in-game points to be modified and the\neffect of these alterations on performance measured. At no time were\nparticipants told the true performance metric. To determine the point\nmodifications IRL was applied on demonstrations of human experts playing the\ngame. The results of the experiment show with significance that performance\nimproved over the control for select treatment groups. Finally, in addition to\nthe experiment, we also detail the algorithmic challenges we faced when\nconducting the experiment and the techniques we used to overcome them.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:44:25 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:44:26 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rucker", "Mark A.", ""], ["Watson", "Layne T.", ""], ["Barnes", "Laura E.", ""], ["Gerber", "Matthew S.", ""]]}, {"id": "2002.10905", "submitter": "Wolfgang Fuhl", "authors": "Wolfgang Fuhl, Yao Rong, Enkelejda Kasneci", "title": "Fully Convolutional Neural Networks for Raw Eye Tracking Data\n  Segmentation, Generation, and Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use fully convolutional neural networks for the semantic\nsegmentation of eye tracking data. We also use these networks for\nreconstruction, and in conjunction with a variational auto-encoder to generate\neye movement data. The first improvement of our approach is that no input\nwindow is necessary, due to the use of fully convolutional networks and\ntherefore any input size can be processed directly. The second improvement is\nthat the used and generated data is raw eye tracking data (position X, Y and\ntime) without preprocessing. This is achieved by pre-initializing the filters\nin the first layer and by building the input tensor along the z axis. We\nevaluated our approach on three publicly available datasets and compare the\nresults to the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 06:57:09 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 07:13:46 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 12:22:08 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Fuhl", "Wolfgang", ""], ["Rong", "Yao", ""], ["Kasneci", "Enkelejda", ""]]}, {"id": "2002.10908", "submitter": "Yoonmi Hong", "authors": "Yoonmi Hong, Wei-Tang Chang, Geng Chen, Ye Wu, Weili Lin, Dinggang\n  Shen, and Pew-Thian Yap", "title": "Multifold Acceleration of Diffusion MRI via Slice-Interleaved Diffusion\n  Encoding (SIDE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion MRI (dMRI) is a unique imaging technique for in vivo\ncharacterization of tissue microstructure and white matter pathways. However,\nits relatively long acquisition time implies greater motion artifacts when\nimaging, for example, infants and Parkinson's disease patients. To accelerate\ndMRI acquisition, we propose in this paper (i) a diffusion encoding scheme,\ncalled Slice-Interleaved Diffusion Encoding (SIDE), that interleaves each\ndiffusion-weighted (DW) image volume with slices that are encoded with\ndifferent diffusion gradients, essentially allowing the slice-undersampling of\nimage volume associated with each diffusion gradient to significantly reduce\nacquisition time, and (ii) a method based on deep learning for effective\nreconstruction of DW images from the highly slice-undersampled data. Evaluation\nbased on the Human Connectome Project (HCP) dataset indicates that our method\ncan achieve a high acceleration factor of up to 6 with minimal information\nloss. Evaluation using dMRI data acquired with SIDE acquisition demonstrates\nthat it is possible to accelerate the acquisition by as much as 50 folds when\ncombined with multi-band imaging.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:48:17 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Hong", "Yoonmi", ""], ["Chang", "Wei-Tang", ""], ["Chen", "Geng", ""], ["Wu", "Ye", ""], ["Lin", "Weili", ""], ["Shen", "Dinggang", ""], ["Yap", "Pew-Thian", ""]]}, {"id": "2002.10923", "submitter": "Luk\\'a\\v{s} Adam", "authors": "Luk\\'a\\v{s} Adam, V\\'aclav M\\'acha, V\\'aclav \\v{S}m\\'idl, Tom\\'a\\v{s}\n  Pevn\\'y", "title": "General Framework for Binary Classification on Top Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many binary classification problems minimize misclassification above (or\nbelow) a threshold. We show that instances of ranking problems, accuracy at the\ntop or hypothesis testing may be written in this form. We propose a general\nframework to handle these classes of problems and show which known methods\n(both known and newly proposed) fall into this framework. We provide a\ntheoretical analysis of this framework and mention selected possible pitfalls\nthe methods may encounter. We suggest several numerical improvements including\nthe implicit derivative and stochastic gradient descent. We provide an\nextensive numerical study. Based both on the theoretical properties and\nnumerical experiments, we conclude the paper by suggesting which method should\nbe used in which situation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 14:54:53 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Adam", "Luk\u00e1\u0161", ""], ["M\u00e1cha", "V\u00e1clav", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""]]}, {"id": "2002.10936", "submitter": "Matthew Leming", "authors": "Matthew Leming, John Suckling", "title": "Stochastic encoding of graphs in deep learning allows for complex\n  analysis of gender classification in resting-state and task functional brain\n  networks from the UK Biobank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of whole-brain functional connectivity MRI data with\nconvolutional neural networks (CNNs) has shown promise, but the complexity of\nthese models impedes understanding of which aspects of brain activity\ncontribute to classification. While visualization techniques have been\ndeveloped to interpret CNNs, bias inherent in the method of encoding abstract\ninput data, as well as the natural variance of deep learning models, detract\nfrom the accuracy of these techniques. We introduce a stochastic encoding\nmethod in an ensemble of CNNs to classify functional connectomes by gender. We\napplied our method to resting-state and task data from the UK BioBank, using\ntwo visualization techniques to measure the salience of three brain networks\ninvolved in task- and resting-states, and their interaction. To regress\nconfounding factors such as head motion, age, and intracranial volume, we\nintroduced a multivariate balancing algorithm to ensure equal distributions of\nsuch covariates between classes in our data. We achieved a final AUROC of\n0.8459. We found that resting-state data classifies more accurately than task\ndata, with the inner salience network playing the most important role of the\nthree networks overall in classification of resting-state data and connections\nto the central executive network in task data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:10:51 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 16:20:28 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Leming", "Matthew", ""], ["Suckling", "John", ""]]}, {"id": "2002.10937", "submitter": "Jitin Krishnan", "authors": "Jitin Krishnan, Hemant Purohit, and Huzefa Rangwala", "title": "Diversity-Based Generalization for Unsupervised Text Classification\n  under Domain Shift", "comments": "16 pages, 3 figures, 5 Tables, Source Code Available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Domain adaptation approaches seek to learn from a source domain and\ngeneralize it to an unseen target domain. At present, the state-of-the-art\nunsupervised domain adaptation approaches for subjective text classification\nproblems leverage unlabeled target data along with labeled source data. In this\npaper, we propose a novel method for domain adaptation of single-task text\nclassification problems based on a simple but effective idea of diversity-based\ngeneralization that does not require unlabeled target data but still matches\nthe state-of-the-art in performance. Diversity plays the role of promoting the\nmodel to better generalize and be indiscriminate towards domain shift by\nforcing the model not to rely on same features for prediction. We apply this\nconcept on the most explainable component of neural networks, the attention\nlayer. To generate sufficient diversity, we create a multi-head attention model\nand infuse a diversity constraint between the attention heads such that each\nhead will learn differently. We further expand upon our model by tri-training\nand designing a procedure with an additional diversity constraint between the\nattention heads of the tri-trained classifiers. Extensive evaluation using the\nstandard benchmark dataset of Amazon reviews and a newly constructed dataset of\nCrisis events shows that our fully unsupervised method matches with the\ncompeting baselines that uses unlabeled target data. Our results demonstrate\nthat machine learning architectures that ensure sufficient diversity can\ngeneralize better; encouraging future research to design ubiquitously usable\nlearning models without using unlabeled target data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:11:02 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 18:06:10 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Krishnan", "Jitin", ""], ["Purohit", "Hemant", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "2002.10940", "submitter": "Richeng Jin", "authors": "Richeng Jin, Yufan Huang, Xiaofan He, Tianfu Wu, Huaiyu Dai", "title": "Stochastic-Sign SGD for Federated Learning with Theoretical Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) has emerged as a prominent distributed learning\nparadigm. FL entails some pressing needs for developing novel parameter\nestimation approaches with theoretical guarantees of convergence, which are\nalso communication efficient, differentially private and Byzantine resilient in\nthe heterogeneous data distribution settings. Quantization-based SGD solvers\nhave been widely adopted in FL and the recently proposed SIGNSGD with majority\nvote shows a promising direction. However, no existing methods enjoy all the\naforementioned properties. In this paper, we propose an intuitively-simple yet\ntheoretically-sound method based on SIGNSGD to bridge the gap. We present\nStochastic-Sign SGD which utilizes novel stochastic-sign based gradient\ncompressors enabling the aforementioned properties in a unified framework. We\nalso present an error-feedback variant of the proposed Stochastic-Sign SGD\nwhich further improves the learning performance in FL. We test the proposed\nmethod with extensive experiments using deep neural networks on the MNIST\ndataset. The experimental results corroborate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:12:15 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 02:57:54 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 18:21:03 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Jin", "Richeng", ""], ["Huang", "Yufan", ""], ["He", "Xiaofan", ""], ["Wu", "Tianfu", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2002.10941", "submitter": "Tae Jun Ham", "authors": "Tae Jun Ham, Sung Jun Jung, Seonghak Kim, Young H. Oh, Yeonhong Park,\n  Yoonho Song, Jung-Hun Park, Sanghee Lee, Kyoung Park, Jae W. Lee, Deog-Kyoon\n  Jeong", "title": "A$^3$: Accelerating Attention Mechanisms in Neural Networks with\n  Approximation", "comments": "To be published in 2020 IEEE International Symposium on High\n  Performance Computer Architecture (HPCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing computational demands of neural networks, many hardware\naccelerators for the neural networks have been proposed. Such existing neural\nnetwork accelerators often focus on popular neural network types such as\nconvolutional neural networks (CNNs) and recurrent neural networks (RNNs);\nhowever, not much attention has been paid to attention mechanisms, an emerging\nneural network primitive that enables neural networks to retrieve most relevant\ninformation from a knowledge-base, external memory, or past states. The\nattention mechanism is widely adopted by many state-of-the-art neural networks\nfor computer vision, natural language processing, and machine translation, and\naccounts for a large portion of total execution time. We observe today's\npractice of implementing this mechanism using matrix-vector multiplication is\nsuboptimal as the attention mechanism is semantically a content-based search\nwhere a large portion of computations ends up not being used. Based on this\nobservation, we design and architect A3, which accelerates attention mechanisms\nin neural networks with algorithmic approximation and hardware specialization.\nOur proposed accelerator achieves multiple orders of magnitude improvement in\nenergy efficiency (performance/watt) as well as substantial speedup over the\nstate-of-the-art conventional hardware.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 02:09:21 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Ham", "Tae Jun", ""], ["Jung", "Sung Jun", ""], ["Kim", "Seonghak", ""], ["Oh", "Young H.", ""], ["Park", "Yeonhong", ""], ["Song", "Yoonho", ""], ["Park", "Jung-Hun", ""], ["Lee", "Sanghee", ""], ["Park", "Kyoung", ""], ["Lee", "Jae W.", ""], ["Jeong", "Deog-Kyoon", ""]]}, {"id": "2002.10944", "submitter": "Minghui Li", "authors": "Minghui Li, Sherman S. M. Chow, Shengshan Hu, Yuejing Yan, Chao Shen,\n  Qian Wang", "title": "Optimizing Privacy-Preserving Outsourced Convolutional Neural Network\n  Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network is a machine-learning model widely applied in\nvarious prediction tasks, such as computer vision and medical image analysis.\nTheir great predictive power requires extensive computation, which encourages\nmodel owners to host the prediction service in a cloud platform. Recent\nresearches focus on the privacy of the query and results, but they do not\nprovide model privacy against the model-hosting server and may leak partial\ninformation about the results. Some of them further require frequent\ninteractions with the querier or heavy computation overheads, which discourages\nquerier from using the prediction service. This paper proposes a new scheme for\nprivacy-preserving neural network prediction in the outsourced setting, i.e.,\nthe server cannot learn the query, (intermediate) results, and the model.\nSimilar to SecureML (S&P'17), a representative work that provides model\nprivacy, we leverage two non-colluding servers with secret sharing and triplet\ngeneration to minimize the usage of heavyweight cryptography. Further, we adopt\nasynchronous computation to improve the throughput, and design garbled circuits\nfor the non-polynomial activation function to keep the same accuracy as the\nunderlying network (instead of approximating it). Our experiments on MNIST\ndataset show that our scheme achieves an average of 122x, 14.63x, and 36.69x\nreduction in latency compared to SecureML, MiniONN (CCS'17), and EzPC\n(EuroS&P'19), respectively. For the communication costs, our scheme outperforms\nSecureML by 1.09x, MiniONN by 36.69x, and EzPC by 31.32x on average. On the\nCIFAR dataset, our scheme achieves a lower latency by a factor of 7.14x and\n3.48x compared to MiniONN and EzPC, respectively. Our scheme also provides\n13.88x and 77.46x lower communication costs than MiniONN and EzPC on the CIFAR\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 08:47:22 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 11:29:51 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 16:52:16 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Li", "Minghui", ""], ["Chow", "Sherman S. M.", ""], ["Hu", "Shengshan", ""], ["Yan", "Yuejing", ""], ["Shen", "Chao", ""], ["Wang", "Qian", ""]]}, {"id": "2002.10947", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Sijia Liu, Pin-Yu Chen, Mengshu Sun, Caiwen Ding, Bhavya\n  Kailkhura, Xue Lin", "title": "Towards an Efficient and General Framework of Robust Training for Graph\n  Neural Networks", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have made significant advances on several\nfundamental inference tasks. As a result, there is a surge of interest in using\nthese models for making potentially important decisions in high-regret\napplications. However, despite GNNs' impressive performance, it has been\nobserved that carefully crafted perturbations on graph structures (or nodes\nattributes) lead them to make wrong predictions. Presence of these adversarial\nexamples raises serious security concerns. Most of the existing robust GNN\ndesign/training methods are only applicable to white-box settings where model\nparameters are known and gradient based methods can be used by performing\nconvex relaxation of the discrete graph domain. More importantly, these methods\nare not efficient and scalable which make them infeasible in time sensitive\ntasks and massive graph datasets. To overcome these limitations, we propose a\ngeneral framework which leverages the greedy search algorithms and zeroth-order\nmethods to obtain robust GNNs in a generic and an efficient manner. On several\napplications, we show that the proposed techniques are significantly less\ncomputationally expensive and, in some cases, more robust than the\nstate-of-the-art methods making them suitable to large-scale problems which\nwere out of the reach of traditional robust training methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:17:58 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Sun", "Mengshu", ""], ["Ding", "Caiwen", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""]]}, {"id": "2002.10948", "submitter": "Dmitry V. Dylov", "authors": "Dmitrii Krylov, Remi Tachet, Romain Laroche, Michael Rosenblum, Dmitry\n  V. Dylov", "title": "Reinforcement Learning Framework for Deep Brain Stimulation Study", "comments": "7 pages + 1 references, 7 figures. arXiv admin note: text overlap\n  with arXiv:1909.12154", "journal-ref": null, "doi": "10.24963/ijcai.2020/394", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malfunctioning neurons in the brain sometimes operate synchronously,\nreportedly causing many neurological diseases, e.g. Parkinson's. Suppression\nand control of this collective synchronous activity are therefore of great\nimportance for neuroscience, and can only rely on limited engineering trials\ndue to the need to experiment with live human brains. We present the first\nReinforcement Learning gym framework that emulates this collective behavior of\nneurons and allows us to find suppression parameters for the environment of\nsynthetic degenerate models of neurons. We successfully suppress synchrony via\nRL for three pathological signaling regimes, characterize the framework's\nstability to noise, and further remove the unwanted oscillations by engaging\nmultiple PPO agents.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 16:48:43 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Krylov", "Dmitrii", ""], ["Tachet", "Remi", ""], ["Laroche", "Romain", ""], ["Rosenblum", "Michael", ""], ["Dylov", "Dmitry V.", ""]]}, {"id": "2002.10953", "submitter": "Jason T. L. Wang", "authors": "Hao Liu, Chang Liu, Jason T. L. Wang, Haimin Wang", "title": "Predicting Coronal Mass Ejections Using SDO/HMI Vector Magnetic Data\n  Products and Recurrent Neural Networks", "comments": "12 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1905.07095", "journal-ref": "The Astrophysical Journal, Volume 890, Number 1, 2020", "doi": "10.3847/1538-4357/ab6850", "report-no": null, "categories": "astro-ph.SR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two recurrent neural networks (RNNs), one based on gated recurrent\nunits and the other based on long short-term memory, for predicting whether an\nactive region (AR) that produces an M- or X-class flare will also produce a\ncoronal mass ejection (CME). We model data samples in an AR as time series and\nuse the RNNs to capture temporal information of the data samples. Each data\nsample has 18 physical parameters, or features, derived from photospheric\nvector magnetic field data taken by the Helioseismic and Magnetic Imager (HMI)\non board the Solar Dynamics Observatory (SDO). We survey M- and X-class flares\nthat occurred from 2010 May to 2019 May using the Geostationary Operational\nEnvironmental Satellite's X-ray flare catalogs provided by the National Centers\nfor Environmental Information (NCEI), and select those flares with identified\nARs in the NCEI catalogs. In addition, we extract the associations of flares\nand CMEs from the Space Weather Database Of Notifications, Knowledge,\nInformation (DONKI). We use the information gathered above to build the labels\n(positive versus negative) of the data samples at hand. Experimental results\ndemonstrate the superiority of our RNNs over closely related machine learning\nmethods in predicting the labels of the data samples. We also discuss an\nextension of our approach to predict a probabilistic estimate of how likely an\nM- or X-class flare will initiate a CME, with good performance results. To our\nknowledge this is the first time that RNNs have been used for CME prediction.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 11:26:47 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Liu", "Hao", ""], ["Liu", "Chang", ""], ["Wang", "Jason T. L.", ""], ["Wang", "Haimin", ""]]}, {"id": "2002.10964", "submitter": "Sangwoo Mo", "authors": "Sangwoo Mo, Minsu Cho, Jinwoo Shin", "title": "Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs", "comments": "Tech report; High resolution images are in\n  https://github.com/sangwoomo/FreezeD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have shown outstanding performance on\na wide range of problems in computer vision, graphics, and machine learning,\nbut often require numerous training data and heavy computational resources. To\ntackle this issue, several methods introduce a transfer learning technique in\nGAN training. They, however, are either prone to overfitting or limited to\nlearning small distribution shifts. In this paper, we show that simple\nfine-tuning of GANs with frozen lower layers of the discriminator performs\nsurprisingly well. This simple baseline, FreezeD, significantly outperforms\nprevious techniques used in both unconditional and conditional GANs. We\ndemonstrate the consistent effect using StyleGAN and SNGAN-projection\narchitectures on several datasets of Animal Face, Anime Face, Oxford Flower,\nCUB-200-2011, and Caltech-256 datasets. The code and results are available at\nhttps://github.com/sangwoomo/FreezeD.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:30:17 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:53:50 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mo", "Sangwoo", ""], ["Cho", "Minsu", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2002.10974", "submitter": "Nikolaos Dimitriou", "authors": "Nikolaos Dimitriou, Lampros Leontaris, Thanasis Vafeiadis, Dimosthenis\n  Ioannidis, Tracy Wotherspoon, Gregory Tinker, and Dimitrios Tzovaras", "title": "Fault Diagnosis in Microelectronics Attachment via Deep Learning\n  Analysis of 3D Laser Scans", "comments": "10 pages, 12 figures. in IEEE Transactions on Industrial Electronics,\n  2019 (early access)", "journal-ref": null, "doi": "10.1109/TIE.2019.2931220", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common source of defects in manufacturing miniature Printed Circuits Boards\n(PCB) is the attachment of silicon die or other wire bondable components on a\nLiquid Crystal Polymer (LCP) substrate. Typically, a conductive glue is\ndispensed prior to attachment with defects caused either by insufficient or\nexcessive glue. The current practice in electronics industry is to examine the\ndeposited glue by a human operator a process that is both time consuming and\ninefficient especially in preproduction runs where the error rate is high. In\nthis paper we propose a system that automates fault diagnosis by accurately\nestimating the volume of glue deposits before and even after die attachment. To\nthis end a modular scanning system is deployed that produces high resolution\npoint clouds whereas the actual estimation of glue volume is performed by\n(R)egression-Net (RNet), a 3D Convolutional Neural Network (3DCNN). RNet\noutperforms other deep architectures and is able to estimate the volume either\ndirectly from the point cloud of a glue deposit or more interestingly after die\nattachment when only a small part of glue is visible around each die. The\nentire methodology is evaluated under operational conditions where the proposed\nsystem achieves accurate results without delaying the manufacturing process.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:38:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dimitriou", "Nikolaos", ""], ["Leontaris", "Lampros", ""], ["Vafeiadis", "Thanasis", ""], ["Ioannidis", "Dimosthenis", ""], ["Wotherspoon", "Tracy", ""], ["Tinker", "Gregory", ""], ["Tzovaras", "Dimitrios", ""]]}, {"id": "2002.10981", "submitter": "Sanchita Ghose", "authors": "Sanchita Ghose, John J. Prevost", "title": "AutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent\n  Videos with Deep Learning", "comments": "14 pages, 14 figures", "journal-ref": "IEEE TRANSACTIONS ON MULTIMEDIA, 2020", "doi": "10.1109/TMM.2020.3005033", "report-no": null, "categories": "cs.SD cs.CV cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In movie productions, the Foley Artist is responsible for creating an overlay\nsoundtrack that helps the movie come alive for the audience. This requires the\nartist to first identify the sounds that will enhance the experience for the\nlistener thereby reinforcing the Directors's intention for a given scene. In\nthis paper, we present AutoFoley, a fully-automated deep learning tool that can\nbe used to synthesize a representative audio track for videos. AutoFoley can be\nused in the applications where there is either no corresponding audio file\nassociated with the video or in cases where there is a need to identify\ncritical scenarios and provide a synthesized, reinforced soundtrack. An\nimportant performance criterion of the synthesized soundtrack is to be\ntime-synchronized with the input video, which provides for a realistic and\nbelievable portrayal of the synthesized sound. Unlike existing sound prediction\nand generation architectures, our algorithm is capable of precise recognition\nof actions as well as inter-frame relations in fast moving video clips by\nincorporating an interpolation technique and Temporal Relationship Networks\n(TRN). We employ a robust multi-scale Recurrent Neural Network (RNN) associated\nwith a Convolutional Neural Network (CNN) for a better understanding of the\nintricate input-to-output associations over time. To evaluate AutoFoley, we\ncreate and introduce a large scale audio-video dataset containing a variety of\nsounds frequently used as Foley effects in movies. Our experiments show that\nthe synthesized sounds are realistically portrayed with accurate temporal\nsynchronization of the associated visual inputs. Human qualitative testing of\nAutoFoley show over 73% of the test subjects considered the generated\nsoundtrack as original, which is a noteworthy improvement in cross-modal\nresearch in sound synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 09:08:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Ghose", "Sanchita", ""], ["Prevost", "John J.", ""]]}, {"id": "2002.10986", "submitter": "Nikolaos Dimitriou", "authors": "Nikolaos Dimitriou, Lampros Leontaris, Thanasis Vafeiadis, Dimosthenis\n  Ioannidis, Tracy Wotherspoon, Gregory Tinker, Dimitrios Tzovaras", "title": "A Deep Learning Framework for Simulation and Defect Prediction Applied\n  in Microelectronics", "comments": "21 pages, 5 figures", "journal-ref": "Simulation Modelling Practice and Theory, Volume 100, 2020", "doi": "10.1016/j.simpat.2019.102063", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of upcoming events in industrial processes has been a\nlong-standing research goal since it enables optimization of manufacturing\nparameters, planning of equipment maintenance and more importantly prediction\nand eventually prevention of defects. While existing approaches have\naccomplished substantial progress, they are mostly limited to processing of one\ndimensional signals or require parameter tuning to model environmental\nparameters. In this paper, we propose an alternative approach based on deep\nneural networks that simulates changes in the 3D structure of a monitored\nobject in a batch based on previous 3D measurements. In particular, we propose\nan architecture based on 3D Convolutional Neural Networks (3DCNN) in order to\nmodel the geometric variations in manufacturing parameters and predict upcoming\nevents related to sub-optimal performance. We validate our framework on a\nmicroelectronics use-case using the recently published PCB scans dataset where\nwe simulate changes on the shape and volume of glue deposited on an Liquid\nCrystal Polymer (LCP) substrate before the attachment of integrated circuits\n(IC). Experimental evaluation examines the impact of different choices in the\ncost function during training and shows that the proposed method can be\nefficiently used for defect prediction.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 15:54:33 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dimitriou", "Nikolaos", ""], ["Leontaris", "Lampros", ""], ["Vafeiadis", "Thanasis", ""], ["Ioannidis", "Dimosthenis", ""], ["Wotherspoon", "Tracy", ""], ["Tinker", "Gregory", ""], ["Tzovaras", "Dimitrios", ""]]}, {"id": "2002.10990", "submitter": "Matthew Dixon", "authors": "Matthew Dixon and Igor Halperin", "title": "G-Learner and GIRL: Goal Based Wealth Management with Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning approach to goal based wealth management\nproblems such as optimization of retirement plans or target dated funds. In\nsuch problems, an investor seeks to achieve a financial goal by making periodic\ninvestments in the portfolio while being employed, and periodically draws from\nthe account when in retirement, in addition to the ability to re-balance the\nportfolio by selling and buying different assets (e.g. stocks). Instead of\nrelying on a utility of consumption, we present G-Learner: a reinforcement\nlearning algorithm that operates with explicitly defined one-step rewards, does\nnot assume a data generation process, and is suitable for noisy data. Our\napproach is based on G-learning - a probabilistic extension of the Q-learning\nmethod of reinforcement learning.\n  In this paper, we demonstrate how G-learning, when applied to a quadratic\nreward and Gaussian reference policy, gives an entropy-regulated Linear\nQuadratic Regulator (LQR). This critical insight provides a novel and\ncomputationally tractable tool for wealth management tasks which scales to high\ndimensional portfolios. In addition to the solution of the direct problem of\nG-learning, we also present a new algorithm, GIRL, that extends our goal-based\nG-learning approach to the setting of Inverse Reinforcement Learning (IRL)\nwhere rewards collected by the agent are not observed, and should instead be\ninferred. We demonstrate that GIRL can successfully learn the reward parameters\nof a G-Learner agent and thus imitate its behavior. Finally, we discuss\npotential applications of the G-Learner and GIRL algorithms for wealth\nmanagement and robo-advising.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:03:38 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Dixon", "Matthew", ""], ["Halperin", "Igor", ""]]}, {"id": "2002.10994", "submitter": "Anne-Marie Rickmann", "authors": "Anne-Marie Rickmann, Abhijit Guha Roy, Ignacio Sarasua, Christian\n  Wachinger", "title": "Recalibrating 3D ConvNets with Project & Excite", "comments": "Accepted for publication at IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.2972059", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully Convolutional Neural Networks (F-CNNs) achieve state-of-the-art\nperformance for segmentation tasks in computer vision and medical imaging.\nRecently, computational blocks termed squeeze and excitation (SE) have been\nintroduced to recalibrate F-CNN feature maps both channel- and spatial-wise,\nboosting segmentation performance while only minimally increasing the model\ncomplexity. So far, the development of SE blocks has focused on 2D\narchitectures. For volumetric medical images, however, 3D F-CNNs are a natural\nchoice. In this article, we extend existing 2D recalibration methods to 3D and\npropose a generic compress-process-recalibrate pipeline for easy comparison of\nsuch blocks. We further introduce Project & Excite (PE) modules, customized for\n3D networks. In contrast to existing modules, Project \\& Excite does not\nperform global average pooling but compresses feature maps along different\nspatial dimensions of the tensor separately to retain more spatial information\nthat is subsequently used in the excitation step. We evaluate the modules on\ntwo challenging tasks, whole-brain segmentation of MRI scans and whole-body\nsegmentation of CT scans. We demonstrate that PE modules can be easily\nintegrated into 3D F-CNNs, boosting performance up to 0.3 in Dice Score and\noutperforming 3D extensions of other recalibration blocks, while only\nmarginally increasing the model complexity. Our code is publicly available on\nhttps://github.com/ai-med/squeeze_and_excitation .\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:07:17 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Rickmann", "Anne-Marie", ""], ["Roy", "Abhijit Guha", ""], ["Sarasua", "Ignacio", ""], ["Wachinger", "Christian", ""]]}, {"id": "2002.10998", "submitter": "Takanori Fujiwara", "authors": "Yiran Li, Takanori Fujiwara, Yong K. Choi, Katherine K. Kim, Kwan-Liu\n  Ma", "title": "A Visual Analytics System for Multi-model Comparison on Clinical Data\n  Predictions", "comments": "This is the author's version of the article that has been accepted to\n  PacificVis 2020 Visualization Meets AI Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing trend of applying machine learning methods to medical\ndatasets in order to predict patients' future status. Although some of these\nmethods achieve high performance, challenges still exist in comparing and\nevaluating different models through their interpretable information. Such\nanalytics can help clinicians improve evidence-based medical decision making.\nIn this work, we develop a visual analytics system that compares multiple\nmodels' prediction criteria and evaluates their consistency. With our system,\nusers can generate knowledge on different models' inner criteria and how\nconfidently we can rely on each model's prediction for a certain patient.\nThrough a case study of a publicly available clinical dataset, we demonstrate\nthe effectiveness of our visual analytics system to assist clinicians and\nresearchers in comparing and quantitatively evaluating different machine\nlearning methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 20:33:04 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 20:08:20 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Li", "Yiran", ""], ["Fujiwara", "Takanori", ""], ["Choi", "Yong K.", ""], ["Kim", "Katherine K.", ""], ["Ma", "Kwan-Liu", ""]]}, {"id": "2002.11002", "submitter": "Andrew Cropper", "authors": "Andrew Cropper, Sebastijan Duman\\v{c}i\\'c, and Stephen H. Muggleton", "title": "Turning 30: New Ideas in Inductive Logic Programming", "comments": "IJCAI2020 survey paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common criticisms of state-of-the-art machine learning include poor\ngeneralisation, a lack of interpretability, and a need for large amounts of\ntraining data. We survey recent work in inductive logic programming (ILP), a\nform of machine learning that induces logic programs from data, which has shown\npromise at addressing these limitations. We focus on new methods for learning\nrecursive programs that generalise from few examples, a shift from using\nhand-crafted background knowledge to \\emph{learning} background knowledge, and\nthe use of different technologies, notably answer set programming and neural\nnetworks. As ILP approaches 30, we also discuss directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:23:11 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 07:27:32 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 13:36:32 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 09:06:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "2002.11004", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Ryuichi Kiryo, Kosuke Tsujino, Haruki Yukawa", "title": "Language-Independent Tokenisation Rivals Language-Specific Tokenisation\n  for Word Similarity Prediction", "comments": "To appear in the 12th Language Resources and Evaluation (LREC 2020)\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language-independent tokenisation (LIT) methods that do not require labelled\nlanguage resources or lexicons have recently gained popularity because of their\napplicability in resource-poor languages. Moreover, they compactly represent a\nlanguage using a fixed size vocabulary and can efficiently handle unseen or\nrare words. On the other hand, language-specific tokenisation (LST) methods\nhave a long and established history, and are developed using carefully created\nlexicons and training resources. Unlike subtokens produced by LIT methods, LST\nmethods produce valid morphological subwords. Despite the contrasting\ntrade-offs between LIT vs. LST methods, their performance on downstream NLP\ntasks remain unclear. In this paper, we empirically compare the two approaches\nusing semantic similarity measurement as an evaluation task across a diverse\nset of languages. Our experimental results covering eight languages show that\nLST consistently outperforms LIT when the vocabulary size is large, but LIT can\nproduce comparable or better results than LST in many languages with\ncomparatively smaller (i.e. less than 100K words) vocabulary sizes, encouraging\nthe use of LIT when language-specific resources are unavailable, incomplete or\na smaller model is required. Moreover, we find that smoothed inverse frequency\n(SIF) to be an accurate method to create word embeddings from subword\nembeddings for multilingual semantic similarity prediction tasks. Further\nanalysis of the nearest neighbours of tokens show that semantically and\nsyntactically related tokens are closely embedded in subword embedding spaces\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:24:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Bollegala", "Danushka", ""], ["Kiryo", "Ryuichi", ""], ["Tsujino", "Kosuke", ""], ["Yukawa", "Haruki", ""]]}, {"id": "2002.11005", "submitter": "Serge Kas Hanna", "authors": "Serge Kas Hanna, Rawad Bitar, Parimal Parag, Venkat Dasari, and Salim\n  El Rouayheb", "title": "Adaptive Distributed Stochastic Gradient Descent for Minimizing Delay in\n  the Presence of Stragglers", "comments": "Accepted to IEEE ICASSP 2020", "journal-ref": "International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP), 2020", "doi": "10.1109/ICASSP40776.2020.9053961", "report-no": "pp. 4262--4266, May 2020", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting where a master wants to run a distributed stochastic\ngradient descent (SGD) algorithm on $n$ workers each having a subset of the\ndata. Distributed SGD may suffer from the effect of stragglers, i.e., slow or\nunresponsive workers who cause delays. One solution studied in the literature\nis to wait at each iteration for the responses of the fastest $k<n$ workers\nbefore updating the model, where $k$ is a fixed parameter. The choice of the\nvalue of $k$ presents a trade-off between the runtime (i.e., convergence rate)\nof SGD and the error of the model. Towards optimizing the error-runtime\ntrade-off, we investigate distributed SGD with adaptive $k$. We first design an\nadaptive policy for varying $k$ that optimizes this trade-off based on an upper\nbound on the error as a function of the wall-clock time which we derive. Then,\nwe propose an algorithm for adaptive distributed SGD that is based on a\nstatistical heuristic. We implement our algorithm and provide numerical\nsimulations which confirm our intuition and theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:25:22 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hanna", "Serge Kas", ""], ["Bitar", "Rawad", ""], ["Parag", "Parimal", ""], ["Dasari", "Venkat", ""], ["Rouayheb", "Salim El", ""]]}, {"id": "2002.11018", "submitter": "Mathilde Guillemot", "authors": "Mathilde Guillemot, Catherine Heusele, Rodolphe Korichi, Sylvianne\n  Schnebert, Liming Chen", "title": "Breaking Batch Normalization for better explainability of Deep Neural\n  Networks through Layer-wise Relevance Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of transparency of neural networks stays a major break for their\nuse. The Layerwise Relevance Propagation technique builds heat-maps\nrepresenting the relevance of each input in the model s decision. The relevance\nspreads backward from the last to the first layer of the Deep Neural Network.\nLayer-wise Relevance Propagation does not manage normalization layers, in this\nwork we suggest a method to include normalization layers. Specifically, we\nbuild an equivalent network fusing normalization layers and convolutional or\nfully connected layers. Heatmaps obtained with our method on MNIST and CIFAR 10\ndatasets are more accurate for convolutional layers. Our study also prevents\nfrom using Layerwise Relevance Propagation with networks including a\ncombination of connected layers and normalization layer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:06:55 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Guillemot", "Mathilde", ""], ["Heusele", "Catherine", ""], ["Korichi", "Rodolphe", ""], ["Schnebert", "Sylvianne", ""], ["Chen", "Liming", ""]]}, {"id": "2002.11020", "submitter": "Ekrem Aksoy", "authors": "Ekrem Aksoy, Ahmet Yaz{\\i}c{\\i}, Mahmut Kasap", "title": "See, Attend and Brake: An Attention-based Saliency Map Prediction Model\n  for End-to-End Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual perception is the most critical input for driving decisions. In this\nstudy, our aim is to understand relationship between saliency and driving\ndecisions. We present a novel attention-based saliency map prediction model for\nmaking braking decisions This approach constructs a holistic model to the\ndriving task and can be extended for other driving decisions like steering and\nacceleration. The proposed model is a deep neural network model that feeds\nextracted features from input image to a recurrent neural network with an\nattention mechanism. Then predicted saliency map is used to make braking\ndecision. We trained and evaluated using driving attention dataset BDD-A, and\nsaliency dataset CAT2000.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 06:01:35 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Aksoy", "Ekrem", ""], ["Yaz\u0131c\u0131", "Ahmet", ""], ["Kasap", "Mahmut", ""]]}, {"id": "2002.11021", "submitter": "Jakub Breier", "authors": "Jakub Breier, Dirmanto Jap, Xiaolu Hou, Shivam Bhasin, Yang Liu", "title": "SNIFF: Reverse Engineering of Neural Networks with Fault Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been shown to be vulnerable against fault injection\nattacks. These attacks change the physical behavior of the device during the\ncomputation, resulting in a change of value that is currently being computed.\nThey can be realized by various fault injection techniques, ranging from\nclock/voltage glitching to application of lasers to rowhammer. In this paper we\nexplore the possibility to reverse engineer neural networks with the usage of\nfault attacks. SNIFF stands for sign bit flip fault, which enables the reverse\nengineering by changing the sign of intermediate values. We develop the first\nexact extraction method on deep-layer feature extractor networks that provably\nallows the recovery of the model parameters. Our experiments with Keras library\nshow that the precision error for the parameter recovery for the tested\nnetworks is less than $10^{-13}$ with the usage of 64-bit floats, which\nimproves the current state of the art by 6 orders of magnitude. Additionally,\nwe discuss the protection techniques against fault injection attacks that can\nbe applied to enhance the fault resistance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 05:39:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Breier", "Jakub", ""], ["Jap", "Dirmanto", ""], ["Hou", "Xiaolu", ""], ["Bhasin", "Shivam", ""], ["Liu", "Yang", ""]]}, {"id": "2002.11022", "submitter": "Yehui Tang", "authors": "Yehui Tang, Yunhe Wang, Yixing Xu, Boxin Shi, Chao Xu, Chunjing Xu,\n  Chang Xu", "title": "Beyond Dropout: Feature Map Distortion to Regularize Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often consist of a great number of trainable parameters\nfor extracting powerful features from given datasets. On one hand, massive\ntrainable parameters significantly enhance the performance of these deep\nnetworks. On the other hand, they bring the problem of over-fitting. To this\nend, dropout based methods disable some elements in the output feature maps\nduring the training phase for reducing the co-adaptation of neurons. Although\nthe generalization ability of the resulting models can be enhanced by these\napproaches, the conventional binary dropout is not the optimal solution.\nTherefore, we investigate the empirical Rademacher complexity related to\nintermediate layers of deep neural networks and propose a feature distortion\nmethod (Disout) for addressing the aforementioned problem. In the training\nperiod, randomly selected elements in the feature maps will be replaced with\nspecific values by exploiting the generalization error bound. The superiority\nof the proposed feature map distortion for producing deep neural network with\nhigher testing performance is analyzed and demonstrated on several benchmark\nimage datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 13:59:13 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Tang", "Yehui", ""], ["Wang", "Yunhe", ""], ["Xu", "Yixing", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "2002.11039", "submitter": "Bin Hu", "authors": "Shuting Sun, Jianxiu Li, Huayu Chen, Tao Gong, Xiaowei Li, Bin Hu", "title": "A study of resting-state EEG biomarkers for depression recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Depression has become a major health burden worldwide, and\neffective detection depression is a great public-health challenge. This\nElectroencephalography (EEG)-based research is to explore the effective\nbiomarkers for depression recognition. Methods: Resting state EEG data was\ncollected from 24 major depressive patients (MDD) and 29 normal controls using\n128 channel HydroCel Geodesic Sensor Net (HCGSN). To better identify\ndepression, we extracted different types of EEG features including linear\nfeatures, nonlinear features and functional connectivity features phase lagging\nindex (PLI) to comprehensively analyze the EEG signals in patients with MDD.\nAnd using different feature selection methods and classifiers to evaluate the\noptimal feature sets. Results: Functional connectivity feature PLI is superior\nto the linear features and nonlinear features. And when combining all the types\nof features to classify MDD patients, we can obtain the highest classification\naccuracy 82.31% using ReliefF feature selection method and logistic regression\n(LR) classifier. Analyzing the distribution of optimal feature set, it was\nfound that intrahemispheric connection edges of PLI were much more than the\ninterhemispheric connection edges, and the intrahemispheric connection edges\nhad a significant differences between two groups. Conclusion: Functional\nconnectivity feature PLI plays an important role in depression recognition.\nEspecially, intrahemispheric connection edges of PLI might be an effective\nbiomarker to identify depression. And statistic results suggested that MDD\npatients might exist functional dysfunction in left hemisphere.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 08:33:08 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Sun", "Shuting", ""], ["Li", "Jianxiu", ""], ["Chen", "Huayu", ""], ["Gong", "Tao", ""], ["Li", "Xiaowei", ""], ["Hu", "Bin", ""]]}, {"id": "2002.11041", "submitter": "Amir Mosavi Prof", "authors": "Laszlo Nadai, Felde Imre, Sina Ardabili, Tarahom Mesri Gundoshmian,\n  Pinter Gergo, Amir Mosavi", "title": "Performance Analysis of Combine Harvester using Hybrid Model of\n  Artificial Neural Networks Particle Swarm Optimization", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Novel applications of artificial intelligence for tuning the parameters of\nindustrial machines for optimal performance are emerging at a fast pace. Tuning\nthe combine harvesters and improving the machine performance can dramatically\nminimize the wastes during harvesting, and it is also beneficial to machine\nmaintenance. Literature includes several soft computing, machine learning and\noptimization methods that had been used to model the function of harvesters of\nvarious crops. Due to the complexity of the problem, machine learning methods\nhad been recently proposed to predict the optimal performance with promising\nresults. In this paper, through proposing a novel hybrid machine learning model\nbased on artificial neural networks integrated with particle swarm optimization\n(ANN-PSO), the performance analysis of a common combine harvester is presented.\nThe hybridization of machine learning methods with soft computing techniques\nhas recently shown promising results to improve the performance of the combine\nharvesters. This research aims at improving the results further by providing\nmore stable models with higher accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:38:01 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Nadai", "Laszlo", ""], ["Imre", "Felde", ""], ["Ardabili", "Sina", ""], ["Gundoshmian", "Tarahom Mesri", ""], ["Gergo", "Pinter", ""], ["Mosavi", "Amir", ""]]}, {"id": "2002.11042", "submitter": "Amir Mosavi Prof", "authors": "Sina Ardabili, Bertalan Beszedes, Laszlo Nadai, Karoly Szell, Amir\n  Mosavi, Felde Imre", "title": "Comparative Analysis of Single and Hybrid Neuro-Fuzzy-Based Models for\n  an Industrial Heating Ventilation and Air Conditioning Control System", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hybridization of machine learning methods with soft computing techniques is\nan essential approach to improve the performance of the prediction models.\nHybrid machine learning models, particularly, have gained popularity in the\nadvancement of the high-performance control systems. Higher accuracy and better\nperformance for prediction models of exergy destruction and energy consumption\nused in the control circuit of heating, ventilation, and air conditioning\n(HVAC) systems can be highly economical in the industrial scale to save energy.\nThis research proposes two hybrid models of adaptive neuro-fuzzy inference\nsystem-particle swarm optimization (ANFIS-PSO), and adaptive neuro-fuzzy\ninference system-genetic algorithm (ANFIS-GA) for HVAC. The results are further\ncompared with the single ANFIS model. The ANFIS-PSO model with the RMSE of\n0.0065, MAE of 0.0028, and R2 equal to 0.9999, with a minimum deviation of\n0.0691 (KJ/s), outperforms the ANFIS-GA and single ANFIS models.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 22:32:34 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ardabili", "Sina", ""], ["Beszedes", "Bertalan", ""], ["Nadai", "Laszlo", ""], ["Szell", "Karoly", ""], ["Mosavi", "Amir", ""], ["Imre", "Felde", ""]]}, {"id": "2002.11044", "submitter": "Ruthvik Vaila", "authors": "Ruthvik Vaila, Denver Lloyd, Kevin Tetz", "title": "Regression with Deep Learning for Sensor Performance Optimization", "comments": "Accepted in Workshop on Microelectronics and Electron Devices March\n  30th, 2020", "journal-ref": "Workshop on Microelectronics and Electron Devices. March 30th,\n  2020", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks with at least two hidden layers are called deep networks.\nRecent developments in AI and computer programming in general has led to\ndevelopment of tools such as Tensorflow, Keras, NumPy etc. making it easier to\nmodel and draw conclusions from data. In this work we re-approach non-linear\nregression with deep learning enabled by Keras and Tensorflow. In particular,\nwe use deep learning to parametrize a non-linear multivariate relationship\nbetween inputs and outputs of an industrial sensor with an intent to optimize\nthe sensor performance based on selected key metrics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 19:58:58 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 15:18:14 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Vaila", "Ruthvik", ""], ["Lloyd", "Denver", ""], ["Tetz", "Kevin", ""]]}, {"id": "2002.11045", "submitter": "Changyang She", "authors": "Changyang She and Rui Dong and Zhouyou Gu and Zhanwei Hou and Yonghui\n  Li and Wibowo Hardjawana and Chenyang Yang and Lingyang Song and Branka\n  Vucetic", "title": "Deep Learning for Ultra-Reliable and Low-Latency Communications in 6G\n  Networks", "comments": "The manuscript contains 4 figures 2 tables. It has been submitted to\n  IEEE Network (in the second round of revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future 6th generation networks, ultra-reliable and low-latency\ncommunications (URLLC) will lay the foundation for emerging mission-critical\napplications that have stringent requirements on end-to-end delay and\nreliability. Existing works on URLLC are mainly based on theoretical models and\nassumptions. The model-based solutions provide useful insights, but cannot be\ndirectly implemented in practice. In this article, we first summarize how to\napply data-driven supervised deep learning and deep reinforcement learning in\nURLLC, and discuss some open problems of these methods. To address these open\nproblems, we develop a multi-level architecture that enables device\nintelligence, edge intelligence, and cloud intelligence for URLLC. The basic\nidea is to merge theoretical models and real-world data in analyzing the\nlatency and reliability and training deep neural networks (DNNs). Deep transfer\nlearning is adopted in the architecture to fine-tune the pre-trained DNNs in\nnon-stationary networks. Further considering that the computing capacity at\neach user and each mobile edge computing server is limited, federated learning\nis applied to improve the learning efficiency. Finally, we provide some\nexperimental and simulation results and discuss some future directions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 14:38:11 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["She", "Changyang", ""], ["Dong", "Rui", ""], ["Gu", "Zhouyou", ""], ["Hou", "Zhanwei", ""], ["Li", "Yonghui", ""], ["Hardjawana", "Wibowo", ""], ["Yang", "Chenyang", ""], ["Song", "Lingyang", ""], ["Vucetic", "Branka", ""]]}, {"id": "2002.11052", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi and Priyadarshini Panda and Kaushik Roy", "title": "Relevant-features based Auxiliary Cells for Energy Efficient Detection\n  of Natural Errors", "comments": "16 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have demonstrated state-of-the-art performance on many\nclassification tasks. However, they have no inherent capability to recognize\nwhen their predictions are wrong. There have been several efforts in the recent\npast to detect natural errors but the suggested mechanisms pose additional\nenergy requirements. To address this issue, we propose an ensemble of\nclassifiers at hidden layers to enable energy efficient detection of natural\nerrors. In particular, we append Relevant-features based Auxiliary Cells (RACs)\nwhich are class specific binary linear classifiers trained on relevant\nfeatures. The consensus of RACs is used to detect natural errors. Based on\ncombined confidence of RACs, classification can be terminated early, thereby\nresulting in energy efficient detection. We demonstrate the effectiveness of\nour technique on various image classification datasets such as CIFAR-10,\nCIFAR-100 and Tiny-ImageNet.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:22:10 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 01:30:08 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "2002.11054", "submitter": "Uday Bondhugula", "authors": "Chris Lattner, Mehdi Amini, Uday Bondhugula, Albert Cohen, Andy Davis,\n  Jacques Pienaar, River Riddle, Tatiana Shpeisman, Nicolas Vasilache,\n  Oleksandr Zinenko", "title": "MLIR: A Compiler Infrastructure for the End of Moore's Law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work presents MLIR, a novel approach to building reusable and extensible\ncompiler infrastructure. MLIR aims to address software fragmentation, improve\ncompilation for heterogeneous hardware, significantly reduce the cost of\nbuilding domain specific compilers, and aid in connecting existing compilers\ntogether. MLIR facilitates the design and implementation of code generators,\ntranslators and optimizers at different levels of abstraction and also across\napplication domains, hardware targets and execution environments. The\ncontribution of this work includes (1) discussion of MLIR as a research\nartifact, built for extension and evolution, and identifying the challenges and\nopportunities posed by this novel design point in design, semantics,\noptimization specification, system, and engineering. (2) evaluation of MLIR as\na generalized infrastructure that reduces the cost of building\ncompilers-describing diverse use-cases to show research and educational\nopportunities for future programming languages, compilers, execution\nenvironments, and computer architecture. The paper also presents the rationale\nfor MLIR, its original design principles, structures and semantics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:24:50 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 00:38:46 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lattner", "Chris", ""], ["Amini", "Mehdi", ""], ["Bondhugula", "Uday", ""], ["Cohen", "Albert", ""], ["Davis", "Andy", ""], ["Pienaar", "Jacques", ""], ["Riddle", "River", ""], ["Shpeisman", "Tatiana", ""], ["Vasilache", "Nicolas", ""], ["Zinenko", "Oleksandr", ""]]}, {"id": "2002.11080", "submitter": "Lin Chen", "authors": "Yifei Min, Lin Chen, Amin Karbasi", "title": "The Curious Case of Adversarially Robust Models: More Data Can Help,\n  Double Descend, or Hurt Generalization", "comments": "Added theoretical analysis of the Manhattan model and further\n  empirical results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training has shown its ability in producing models that are\nrobust to perturbations on the input data, but usually at the expense of\ndecrease in the standard accuracy. To mitigate this issue, it is commonly\nbelieved that more training data will eventually help such adversarially robust\nmodels generalize better on the benign/unperturbed test data. In this paper,\nhowever, we challenge this conventional belief and show that more training data\ncan hurt the generalization of adversarially robust models in the\nclassification problems. We first investigate the Gaussian mixture\nclassification with a linear loss and identify three regimes based on the\nstrength of the adversary. In the weak adversary regime, more data improves the\ngeneralization of adversarially robust models. In the medium adversary regime,\nwith more training data, the generalization loss exhibits a double descent\ncurve, which implies the existence of an intermediate stage where more training\ndata hurts the generalization. In the strong adversary regime, more data almost\nimmediately causes the generalization error to increase. Then we move to the\nanalysis of a two-dimensional classification problem with a 0-1 loss. We prove\nthat more data always hurts the generalization performance of adversarially\ntrained models with large perturbations. To complement our theoretical results,\nwe conduct empirical studies on Gaussian mixture classification, support vector\nmachines (SVMs), and linear regression.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:25:28 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 23:46:22 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Min", "Yifei", ""], ["Chen", "Lin", ""], ["Karbasi", "Amin", ""]]}, {"id": "2002.11082", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Optimal Gradient Quantization Condition for Communication-Efficient\n  Distributed Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication of gradients is costly for training deep neural networks\nwith multiple devices in computer vision applications. In particular, the\ngrowing size of deep learning models leads to higher communication overheads\nthat defy the ideal linear training speedup regarding the number of devices.\nGradient quantization is one of the common methods to reduce communication\ncosts. However, it can lead to quantization error in the training and result in\nmodel performance degradation. In this work, we deduce the optimal condition of\nboth the binary and multi-level gradient quantization for \\textbf{ANY} gradient\ndistribution. Based on the optimal condition, we develop two novel quantization\nschemes: biased BinGrad and unbiased ORQ for binary and multi-level gradient\nquantization respectively, which dynamically determine the optimal quantization\nlevels. Extensive experimental results on CIFAR and ImageNet datasets with\nseveral popular convolutional neural networks show the superiority of our\nproposed methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:28:39 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2002.11089", "submitter": "Benjamin Eysenbach", "authors": "Benjamin Eysenbach, Xinyang Geng, Sergey Levine, and Ruslan\n  Salakhutdinov", "title": "Rewriting History with Inverse RL: Hindsight Inference for Policy\n  Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task reinforcement learning (RL) aims to simultaneously learn policies\nfor solving many tasks. Several prior works have found that relabeling past\nexperience with different reward functions can improve sample efficiency.\nRelabeling methods typically ask: if, in hindsight, we assume that our\nexperience was optimal for some task, for what task was it optimal? In this\npaper, we show that hindsight relabeling is inverse RL, an observation that\nsuggests that we can use inverse RL in tandem for RL algorithms to efficiently\nsolve many tasks. We use this idea to generalize goal-relabeling techniques\nfrom prior work to arbitrary classes of tasks. Our experiments confirm that\nrelabeling data using inverse RL accelerates learning in general multi-task\nsettings, including goal-reaching, domains with discrete sets of rewards, and\nthose with linear reward functions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:36:31 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Eysenbach", "Benjamin", ""], ["Geng", "Xinyang", ""], ["Levine", "Sergey", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2002.11096", "submitter": "Kyra Gan", "authors": "Kyra Gan, Andrew A. Li, Zachary C. Lipton, Sridhar Tayur", "title": "Causal Inference With Selectively Deconfounded Data", "comments": null, "journal-ref": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130. Copyright 2021 by the author(s)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given only data generated by a standard confounding graph with unobserved\nconfounder, the Average Treatment Effect (ATE) is not identifiable. To estimate\nthe ATE, a practitioner must then either (a) collect deconfounded data;(b) run\na clinical trial; or (c) elucidate further properties of the causal graph that\nmight render the ATE identifiable. In this paper, we consider the benefit of\nincorporating a large confounded observational dataset (confounder unobserved)\nalongside a small deconfounded observational dataset (confounder revealed) when\nestimating the ATE. Our theoretical results suggest that the inclusion of\nconfounded data can significantly reduce the quantity of deconfounded data\nrequired to estimate the ATE to within a desired accuracy level. Moreover, in\nsome cases -- say, genetics -- we could imagine retrospectively selecting\nsamples to deconfound. We demonstrate that by actively selecting these samples\nbased upon the (already observed) treatment and outcome, we can reduce sample\ncomplexity further. Our theoretical and empirical results establish that the\nworst-case relative performance of our approach (vs. a natural benchmark) is\nbounded while our best-case gains are unbounded. Finally, we demonstrate the\nbenefits of selective deconfounding using a large real-world dataset related to\ngenetic mutation in cancer.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:46:19 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 01:06:27 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 15:35:51 GMT"}, {"version": "v4", "created": "Sun, 7 Mar 2021 01:33:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Gan", "Kyra", ""], ["Li", "Andrew A.", ""], ["Lipton", "Zachary C.", ""], ["Tayur", "Sridhar", ""]]}, {"id": "2002.11097", "submitter": "I. Elizabeth Kumar", "authors": "I. Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger,\n  Sorelle Friedler", "title": "Problems with Shapley-value-based explanations as feature importance\n  measures", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Game-theoretic formulations of feature importance have become popular as a\nway to \"explain\" machine learning models. These methods define a cooperative\ngame between the features of a model and distribute influence among these input\nelements using some form of the game's unique Shapley values. Justification for\nthese methods rests on two pillars: their desirable mathematical properties,\nand their applicability to specific motivations for explanations. We show that\nmathematical problems arise when Shapley values are used for feature importance\nand that the solutions to mitigate these necessarily induce further complexity,\nsuch as the need for causal reasoning. We also draw on additional literature to\nargue that Shapley values do not provide explanations which suit human-centric\ngoals of explainability.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:51:14 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:38:36 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kumar", "I. Elizabeth", ""], ["Venkatasubramanian", "Suresh", ""], ["Scheidegger", "Carlos", ""], ["Friedler", "Sorelle", ""]]}, {"id": "2002.11099", "submitter": "Ayush Jain", "authors": "Ayush Jain and Alon Orlitsky", "title": "A General Method for Robust Learning from Batches", "comments": "First Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, data is collected in batches, some of which are corrupt\nor even adversarial. Recent work derived optimal robust algorithms for\nestimating discrete distributions in this setting. We consider a general\nframework of robust learning from batches, and determine the limits of both\nclassification and distribution estimation over arbitrary, including\ncontinuous, domains. Building on these results, we derive the first robust\nagnostic computationally-efficient learning algorithms for piecewise-interval\nclassification, and for piecewise-polynomial, monotone, log-concave, and\ngaussian-mixture distribution estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:53:25 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Jain", "Ayush", ""], ["Orlitsky", "Alon", ""]]}, {"id": "2002.11102", "submitter": "Boyi Li", "authors": "Boyi Li and Felix Wu and Ser-Nam Lim and Serge Belongie and Kilian Q.\n  Weinberger", "title": "On Feature Normalization and Data Augmentation", "comments": "CVPR 2021. Code is available at https://github.com/Boyiliee/MoEx", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moments (a.k.a., mean and standard deviation) of latent features are\noften removed as noise when training image recognition models, to increase\nstability and reduce training time. However, in the field of image generation,\nthe moments play a much more central role. Studies have shown that the moments\nextracted from instance normalization and positional normalization can roughly\ncapture style and shape information of an image. Instead of being discarded,\nthese moments are instrumental to the generation process. In this paper we\npropose Moment Exchange, an implicit data augmentation method that encourages\nthe model to utilize the moment information also for recognition models.\nSpecifically, we replace the moments of the learned features of one training\nimage by those of another, and also interpolate the target labels -- forcing\nthe model to extract training signal from the moments in addition to the\nnormalized features. As our approach is fast, operates entirely in feature\nspace, and mixes different signals than prior methods, one can effectively\ncombine it with existing augmentation approaches. We demonstrate its efficacy\nacross several recognition benchmark data sets where it improves the\ngeneralization capability of highly competitive baseline networks with\nremarkable consistency.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:59:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 18:59:02 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 18:00:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Li", "Boyi", ""], ["Wu", "Felix", ""], ["Lim", "Ser-Nam", ""], ["Belongie", "Serge", ""], ["Weinberger", "Kilian Q.", ""]]}, {"id": "2002.11104", "submitter": "Abiola Osho", "authors": "Abiola Osho, Caden Waters, George Amariucai", "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 20:04:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Osho", "Abiola", ""], ["Waters", "Caden", ""], ["Amariucai", "George", ""]]}, {"id": "2002.11137", "submitter": "Adel Javanmard", "authors": "Negin Golrezaei, Adel Javanmard and Vahab Mirrokni", "title": "Dynamic Incentive-aware Learning: Robust Pricing in Contextual Auctions", "comments": "Accepted for publication in Operations Research Journal (An earlier\n  version of this paper accepted to NeurIPS 2019.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by pricing in ad exchange markets, we consider the problem of\nrobust learning of reserve prices against strategic buyers in repeated\ncontextual second-price auctions. Buyers' valuations for an item depend on the\ncontext that describes the item. However, the seller is not aware of the\nrelationship between the context and buyers' valuations, i.e., buyers'\npreferences. The seller's goal is to design a learning policy to set reserve\nprices via observing the past sales data, and her objective is to minimize her\nregret for revenue, where the regret is computed against a clairvoyant policy\nthat knows buyers' heterogeneous preferences. Given the seller's goal,\nutility-maximizing buyers have the incentive to bid untruthfully in order to\nmanipulate the seller's learning policy. We propose learning policies that are\nrobust to such strategic behavior. These policies use the outcomes of the\nauctions, rather than the submitted bids, to estimate the preferences while\ncontrolling the long-term effect of the outcome of each auction on the future\nreserve prices. When the market noise distribution is known to the seller, we\npropose a policy called Contextual Robust Pricing (CORP) that achieves a\nT-period regret of $O(d\\log(Td) \\log (T))$, where $d$ is the dimension of {the}\ncontextual information. When the market noise distribution is unknown to the\nseller, we propose two policies whose regrets are sublinear in $T$.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:00:29 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Golrezaei", "Negin", ""], ["Javanmard", "Adel", ""], ["Mirrokni", "Vahab", ""]]}, {"id": "2002.11151", "submitter": "Sourjya Roy", "authors": "Sourjya Roy, Shrihari Sridharan, Shubham Jain, and Anand Raghunathan", "title": "TxSim:Modeling Training of Deep Neural Networks on Resistive Crossbar\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistive crossbars have attracted significant interest in the design of Deep\nNeural Network (DNN) accelerators due to their ability to natively execute\nmassively parallel vector-matrix multiplications within dense memory arrays.\nHowever, crossbar-based computations face a major challenge due to a variety of\ndevice and circuit-level non-idealities, which manifest as errors in the\nvector-matrix multiplications and eventually degrade DNN accuracy. To address\nthis challenge, there is a need for tools that can model the functional impact\nof non-idealities on DNN training and inference. Existing efforts towards this\ngoal are either limited to inference, or are too slow to be used for\nlarge-scale DNN training. We propose TxSim, a fast and customizable modeling\nframework to functionally evaluate DNN training on crossbar-based hardware\nconsidering the impact of non-idealities. The key features of TxSim that\ndifferentiate it from prior efforts are: (i) It comprehensively models\nnon-idealities during all training operations (forward propagation, backward\npropagation, and weight update) and (ii) it achieves computational efficiency\nby mapping crossbar evaluations to well-optimized BLAS routines and\nincorporates speedup techniques to further reduce simulation time with minimal\nimpact on accuracy. TxSim achieves orders-of-magnitude improvement in\nsimulation speed over prior works, and thereby makes it feasible to evaluate\ntraining of large-scale DNNs on crossbars. Our experiments using TxSim reveal\nthat the accuracy degradation in DNN training due to non-idealities can be\nsubstantial (3%-10%) for large-scale DNNs, underscoring the need for further\nresearch in mitigation techniques. We also analyze the impact of various device\nand circuit-level parameters and the associated non-idealities to provide key\ninsights that can guide the design of crossbar-based DNN training accelerators.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:29:43 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 20:42:50 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 03:54:43 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Roy", "Sourjya", ""], ["Sridharan", "Shrihari", ""], ["Jain", "Shubham", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2002.11152", "submitter": "Carole Twining Dr", "authors": "Neil A. Thacker, Carole J. Twining, Paul D. Tar, Scott Notley and\n  Visvanathan Ramesh", "title": "Fundamental Issues Regarding Uncertainties in Artificial Neural Networks", "comments": "21 pages, 8 Figures, 2 Tables. To be submitted to Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) implement a specific form of multi-variate\nextrapolation and will generate an output for any input pattern, even when\nthere is no similar training pattern. Extrapolations are not necessarily to be\ntrusted, and in order to support safety critical systems, we require such\nsystems to give an indication of the training sample related uncertainty\nassociated with their output. Some readers may think that this is a well known\nissue which is already covered by the basic principles of pattern recognition.\nWe will explain below how this is not the case and how the conventional\n(Likelihood estimate of) conditional probability of classification does not\ncorrectly assess this uncertainty. We provide a discussion of the standard\ninterpretations of this problem and show how a quantitative approach based upon\nlong standing methods can be practically applied. The methods are illustrated\non the task of early diagnosis of dementing diseases using Magnetic Resonance\nImaging.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 19:32:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Thacker", "Neil A.", ""], ["Twining", "Carole J.", ""], ["Tar", "Paul D.", ""], ["Notley", "Scott", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "2002.11159", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Yaqiong Li, Ling Chen, Bin Li, Scott A. Sisson", "title": "Smoothing Graphons for Modelling Exchangeable Relational Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling exchangeable relational data can be described by \\textit{graphon\ntheory}. Most Bayesian methods for modelling exchangeable relational data can\nbe attributed to this framework by exploiting different forms of graphons.\nHowever, the graphons adopted by existing Bayesian methods are either\npiecewise-constant functions, which are insufficiently flexible for accurate\nmodelling of the relational data, or are complicated continuous functions,\nwhich incur heavy computational costs for inference. In this work, we introduce\na smoothing procedure to piecewise-constant graphons to form {\\em smoothing\ngraphons}, which permit continuous intensity values for describing relations,\nbut without impractically increasing computational costs. In particular, we\nfocus on the Bayesian Stochastic Block Model (SBM) and demonstrate how to adapt\nthe piecewise-constant SBM graphon to the smoothed version. We initially\npropose the Integrated Smoothing Graphon (ISG) which introduces one smoothing\nparameter to the SBM graphon to generate continuous relational intensity\nvalues. We then develop the Latent Feature Smoothing Graphon (LFSG), which\nimproves on the ISG by introducing auxiliary hidden labels to decompose the\ncalculation of the ISG intensity and enable efficient inference. Experimental\nresults on real-world data sets validate the advantages of applying smoothing\nstrategies to the Stochastic Block Model, demonstrating that smoothing graphons\ncan greatly improve AUC and precision for link prediction without increasing\ncomputational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:02:06 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Yaqiong", ""], ["Chen", "Ling", ""], ["Li", "Bin", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.11172", "submitter": "Nikunj Saunshi", "authors": "Nikunj Saunshi, Yi Zhang, Mikhail Khodak, Sanjeev Arora", "title": "A Sample Complexity Separation between Non-Convex and Convex\n  Meta-Learning", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One popular trend in meta-learning is to learn from many training tasks a\ncommon initialization for a gradient-based method that can be used to solve a\nnew task with few samples. The theory of meta-learning is still in its early\nstages, with several recent learning-theoretic analyses of methods such as\nReptile [Nichol et al., 2018] being for convex models. This work shows that\nconvex-case analysis might be insufficient to understand the success of\nmeta-learning, and that even for non-convex models it is important to look\ninside the optimization black-box, specifically at properties of the\noptimization trajectory. We construct a simple meta-learning instance that\ncaptures the problem of one-dimensional subspace learning. For the convex\nformulation of linear regression on this instance, we show that the new task\nsample complexity of any initialization-based meta-learning algorithm is\n$\\Omega(d)$, where $d$ is the input dimension. In contrast, for the non-convex\nformulation of a two layer linear network on the same instance, we show that\nboth Reptile and multi-task representation learning can have new task sample\ncomplexity of $\\mathcal{O}(1)$, demonstrating a separation from convex\nmeta-learning. Crucially, analyses of the training dynamics of these methods\nreveal that they can meta-learn the correct subspace onto which the data should\nbe projected.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 20:55:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Saunshi", "Nikunj", ""], ["Zhang", "Yi", ""], ["Khodak", "Mikhail", ""], ["Arora", "Sanjeev", ""]]}, {"id": "2002.11182", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner, Tor Lattimore, Andreas Krause", "title": "Information Directed Sampling for Linear Partial Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial monitoring is a rich framework for sequential decision making under\nuncertainty that generalizes many well known bandit models, including linear,\ncombinatorial and dueling bandits. We introduce information directed sampling\n(IDS) for stochastic partial monitoring with a linear reward and observation\nstructure. IDS achieves adaptive worst-case regret rates that depend on precise\nobservability conditions of the game. Moreover, we prove lower bounds that\nclassify the minimax regret of all finite games into four possible regimes. IDS\nachieves the optimal rate in all cases up to logarithmic factors, without\ntuning any hyper-parameters. We further extend our results to the contextual\nand the kernelized setting, which significantly increases the range of possible\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:30:56 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kirschner", "Johannes", ""], ["Lattimore", "Tor", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.11187", "submitter": "Sandesh Ghimire", "authors": "Sandesh Ghimire, Prashnna K Gyawali, Linwei Wang", "title": "Reliable Estimation of Kullback-Leibler Divergence by Controlling\n  Discriminator Complexity in the Reproducing Kernel Hilbert Space", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several scalable sample-based methods to compute the Kullback Leibler (KL)\ndivergence between two distributions have been proposed and applied in\nlarge-scale machine learning models. While they have been found to be unstable,\nthe theoretical root cause of the problem is not clear. In this paper, we study\na generative adversarial network based approach that uses a neural network\ndiscriminator to estimate KL divergence. We argue that, in such case, high\nfluctuations in the estimates are a consequence of not controlling the\ncomplexity of the discriminator function space. We provide a theoretical\nunderpinning and remedy for this problem by first constructing a discriminator\nin the Reproducing Kernel Hilbert Space (RKHS). This enables us to leverage\nsample complexity and mean embedding to theoretically relate the error\nprobability bound of the KL estimates to the complexity of the discriminator in\nRKHS. Based on this theory, we then present a scalable way to control the\ncomplexity of the discriminator for a reliable estimation of KL divergence. We\nsupport both our proposed theory and method to control the complexity of the\nRKHS discriminator through controlled experiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:44:52 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 19:06:16 GMT"}, {"version": "v3", "created": "Sat, 26 Sep 2020 22:58:53 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ghimire", "Sandesh", ""], ["Gyawali", "Prashnna K", ""], ["Wang", "Linwei", ""]]}, {"id": "2002.11192", "submitter": "Alessandro Rossi", "authors": "Alessandro Rossi, Sara Ermini, Dario Bernabini, Dario Zanca, Marino\n  Todisco, Alessandro Genovese, and Antonio Rizzo", "title": "End-to-End Models for the Analysis of System 1 and System 2 Interactions\n  based on Eye-Tracking Data", "comments": "11 pages, 2 figures, 1 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While theories postulating a dual cognitive system take hold, quantitative\nconfirmations are still needed to understand and identify interactions between\nthe two systems or conflict events. Eye movements are among the most direct\nmarkers of the individual attentive load and may serve as an important proxy of\ninformation. In this work we propose a computational method, within a modified\nvisual version of the well-known Stroop test, for the identification of\ndifferent tasks and potential conflicts events between the two systems through\nthe collection and processing of data related to eye movements. A statistical\nanalysis shows that the selected variables can characterize the variation of\nattentive load within different scenarios. Moreover, we show that Machine\nLearning techniques allow to distinguish between different tasks with a good\nclassification accuracy and to investigate more in depth the gaze dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 17:46:13 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Rossi", "Alessandro", ""], ["Ermini", "Sara", ""], ["Bernabini", "Dario", ""], ["Zanca", "Dario", ""], ["Todisco", "Marino", ""], ["Genovese", "Alessandro", ""], ["Rizzo", "Antonio", ""]]}, {"id": "2002.11197", "submitter": "Chad Peters", "authors": "Chad Peters, Babak Esfandiari, Mohamad Zalat and Robert West", "title": "Behavior Cloning in OpenAI using Case Based Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Observation (LfO), also known as Behavioral Cloning, is an\napproach for building software agents by recording the behavior of an expert\n(human or artificial) and using the recorded data to generate the required\nbehavior. jLOAF is a platform that uses Case-Based Reasoning to achieve LfO. In\nthis paper we interface jLOAF with the popular OpenAI Gym environment. Our\nexperimental results show how our approach can be used to provide a baseline\nfor comparison in this domain, as well as identify the strengths and weaknesses\nwhen dealing with environmental complexity.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 22:41:56 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Peters", "Chad", ""], ["Esfandiari", "Babak", ""], ["Zalat", "Mohamad", ""], ["West", "Robert", ""]]}, {"id": "2002.11215", "submitter": "Sarthak .", "authors": "Sarthak, Shikhar Shukla, Surya Prakash Tripathi", "title": "EmbPred30: Assessing 30-days Readmission for Diabetic Patients using\n  Categorical Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hospital readmission is a crucial healthcare quality measure that helps in\ndetermining the level of quality of care that a hospital offers to a patient\nand has proven to be immensely expensive. It is estimated that more than $25\nbillion are spent yearly due to readmission of diabetic patients in the USA.\nThis paper benchmarks existing models and proposes a new embedding based\nstate-of-the-art deep neural network(DNN). The model can identify whether a\nhospitalized diabetic patient will be readmitted within 30 days or not with an\naccuracy of 95.2% and Area Under the Receiver Operating Characteristics(AUROC)\nof 97.4% on data collected from 130 US hospitals between 1999-2008. The results\nare encouraging with patients having changes in medication while admitted\nhaving a high chance of getting readmitted. Identifying prospective patients\nfor readmission could help the hospital systems in improving their inpatient\ncare, thereby saving them from unnecessary expenditures.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 22:59:47 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sarthak", "", ""], ["Shukla", "Shikhar", ""], ["Tripathi", "Surya Prakash", ""]]}, {"id": "2002.11219", "submitter": "Tolga Ergen", "authors": "Tolga Ergen, Mert Pilanci", "title": "Convex Geometry and Duality of Over-parameterized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a convex analytic approach to analyze finite width two-layer ReLU\nnetworks. We first prove that an optimal solution to the regularized training\nproblem can be characterized as extreme points of a convex set, where simple\nsolutions are encouraged via its convex geometrical properties. We then\nleverage this characterization to show that an optimal set of parameters yield\nlinear spline interpolation for regression problems involving one dimensional\nor rank-one data. We also characterize the classification decision regions in\nterms of a kernel matrix and minimum $\\ell_1$-norm solutions. This is in\ncontrast to Neural Tangent Kernel which is unable to explain predictions of\nfinite width networks. Our convex geometric characterization also provides\nintuitive explanations of hidden neurons as auto-encoders. In higher\ndimensions, we show that the training problem can be cast as a finite\ndimensional convex problem with infinitely many constraints. Then, we apply\ncertain convex relaxations and introduce a cutting-plane algorithm to globally\noptimize the network. We further analyze the exactness of the relaxations to\nprovide conditions for the convergence to a global optimum. Our analysis also\nshows that optimal network parameters can be also characterized as\ninterpretable closed-form formulas in some practically relevant special cases.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 23:05:33 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 22:41:11 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2020 06:33:08 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ergen", "Tolga", ""], ["Pilanci", "Mert", ""]]}, {"id": "2002.11223", "submitter": "Krishna Pillutla", "authors": "Yassine Laguel, Krishna Pillutla, J\\'er\\^ome Malick, Zaid Harchaoui", "title": "Device Heterogeneity in Federated Learning: A Superquantile Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a federated learning framework to handle heterogeneous client\ndevices which do not conform to the population data distribution. The approach\nhinges upon a parameterized superquantile-based objective, where the parameter\nranges over levels of conformity. We present an optimization algorithm and\nestablish its convergence to a stationary point. We show how to practically\nimplement it using secure aggregation by interleaving iterations of the usual\nfederated averaging method with device filtering. We conclude with numerical\nexperiments on neural networks as well as linear models on tasks from computer\nvision and natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 23:37:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Laguel", "Yassine", ""], ["Pillutla", "Krishna", ""], ["Malick", "J\u00e9r\u00f4me", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.11226", "submitter": "Joel Dabrowski Dr", "authors": "Joel Janek Dabrowski and Johan Pieter de Villiers and Ashfaqur Rahman\n  and Conrad Beyers", "title": "Deep Learning and Statistical Models for Time-Critical Pedestrian\n  Behaviour Prediction", "comments": null, "journal-ref": "In: Gedeon T., Wong K., Lee M. (eds) Neural Information\n  Processing. ICONIP 2019. Communications in Computer and Information Science,\n  vol 1142. Springer, Cham", "doi": "10.1007/978-3-030-36808-1_50", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time it takes for a classifier to make an accurate prediction can be\ncrucial in many behaviour recognition problems. For example, an autonomous\nvehicle should detect hazardous pedestrian behaviour early enough for it to\ntake appropriate measures. In this context, we compare the switching linear\ndynamical system (SLDS) and a three-layered bi-directional long short-term\nmemory (LSTM) neural network, which are applied to infer pedestrian behaviour\nfrom motion tracks. We show that, though the neural network model achieves an\naccuracy of 80%, it requires long sequences to achieve this (100 samples or\nmore). The SLDS, has a lower accuracy of 74%, but it achieves this result with\nshort sequences (10 samples). To our knowledge, such a comparison on sequence\nlength has not been considered in the literature before. The results provide a\nkey intuition of the suitability of the models in time-critical problems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:05:19 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Dabrowski", "Joel Janek", ""], ["de Villiers", "Johan Pieter", ""], ["Rahman", "Ashfaqur", ""], ["Beyers", "Conrad", ""]]}, {"id": "2002.11242", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Xilie Xu, Bo Han, Gang Niu, Lizhen Cui, Masashi\n  Sugiyama, Mohan Kankanhalli", "title": "Attacks Which Do Not Kill Training Make Adversarial Learning Stronger", "comments": "Thirty-seventh International Conference on Machine Learning (ICML\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training based on the minimax formulation is necessary for\nobtaining adversarial robustness of trained models. However, it is conservative\nor even pessimistic so that it sometimes hurts the natural generalization. In\nthis paper, we raise a fundamental question---do we have to trade off natural\ngeneralization for adversarial robustness? We argue that adversarial training\nis to employ confident adversarial data for updating the current model. We\npropose a novel approach of friendly adversarial training (FAT): rather than\nemploying most adversarial data maximizing the loss, we search for least\nadversarial (i.e., friendly adversarial) data minimizing the loss, among the\nadversarial data that are confidently misclassified. Our novel formulation is\neasy to implement by just stopping the most adversarial data searching\nalgorithms such as PGD (projected gradient descent) early, which we call\nearly-stopped PGD. Theoretically, FAT is justified by an upper bound of the\nadversarial risk. Empirically, early-stopped PGD allows us to answer the\nearlier question negatively---adversarial robustness can indeed be achieved\nwithout compromising the natural generalization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:04:38 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 09:53:08 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Xu", "Xilie", ""], ["Han", "Bo", ""], ["Niu", "Gang", ""], ["Cui", "Lizhen", ""], ["Sugiyama", "Masashi", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2002.11246", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Eric Gaussier", "title": "Supervised Categorical Metric Learning with Schatten p-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric learning has been successful in learning new metrics adapted to\nnumerical datasets. However, its development on categorical data still needs\nfurther exploration. In this paper, we propose a method, called CPML for\n\\emph{categorical projected metric learning}, that tries to efficiently~(i.e.\nless computational time and better prediction accuracy) address the problem of\nmetric learning in categorical data. We make use of the Value Distance Metric\nto represent our data and propose new distances based on this representation.\nWe then show how to efficiently learn new metrics. We also generalize several\nprevious regularizers through the Schatten $p$-norm and provides a\ngeneralization bound for it that complements the standard generalization bound\nfor metric learning. Experimental results show that our method provides\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:17:12 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Fan", "Xuhui", ""], ["Gaussier", "Eric", ""]]}, {"id": "2002.11251", "submitter": "Vikas Gupta", "authors": "Vikas Gupta", "title": "Back to the Future: Joint Aware Temporal Deep Learning 3D Human Pose\n  Estimation", "comments": "Our model and code are available at https://vnmr.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new deep learning network that introduces a deeper CNN channel\nfilter and constraints as losses to reduce joint position and motion errors for\n3D video human body pose estimation. Our model outperforms the previous best\nresult from the literature based on mean per-joint position error, velocity\nerror, and acceleration errors on the Human 3.6M benchmark corresponding to a\nnew state-of-the-art mean error reduction in all protocols and motion metrics.\nMean per joint error is reduced by 1%, velocity error by 7% and acceleration by\n13% compared to the best results from the literature. Our contribution\nincreasing positional accuracy and motion smoothness in video can be integrated\nwith future end to end networks without increasing network complexity. Our\nmodel and code are available at https://vnmr.github.io/\n  Keywords: 3D, human, image, pose, action, detection, object, video, visual,\nsupervised, joint, kinematic\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:11:13 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gupta", "Vikas", ""]]}, {"id": "2002.11255", "submitter": "Rungang Han", "authors": "Rungang Han, Rebecca Willett and Anru R. Zhang", "title": "An Optimal Statistical and Computational Framework for Generalized\n  Tensor Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes a flexible framework for generalized low-rank tensor\nestimation problems that includes many important instances arising from\napplications in computational imaging, genomics, and network analysis. The\nproposed estimator consists of finding a low-rank tensor fit to the data under\ngeneralized parametric models. To overcome the difficulty of non-convexity in\nthese problems, we introduce a unified approach of projected gradient descent\nthat adapts to the underlying low-rank structure. Under mild conditions on the\nloss function, we establish both an upper bound on statistical error and the\nlinear rate of computational convergence through a general deterministic\nanalysis. Then we further consider a suite of generalized tensor estimation\nproblems, including sub-Gaussian tensor PCA, tensor regression, and Poisson and\nbinomial tensor PCA. We prove that the proposed algorithm achieves the minimax\noptimal rate of convergence in estimation error. Finally, we demonstrate the\nsuperiority of the proposed framework via extensive experiments on both\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:54:35 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 21:55:11 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Han", "Rungang", ""], ["Willett", "Rebecca", ""], ["Zhang", "Anru R.", ""]]}, {"id": "2002.11256", "submitter": "Cheng Li", "authors": "Cheng Li, Sunil Gupta, Santu Rana, Vu Nguyen, Antonio Robles-Kelly,\n  Svetha Venkatesh", "title": "Incorporating Expert Prior Knowledge into Experimental Design via\n  Posterior Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific experiments are usually expensive due to complex experimental\npreparation and processing. Experimental design is therefore involved with the\ntask of finding the optimal experimental input that results in the desirable\noutput by using as few experiments as possible. Experimenters can often acquire\nthe knowledge about the location of the global optimum. However, they do not\nknow how to exploit this knowledge to accelerate experimental design. In this\npaper, we adopt the technique of Bayesian optimization for experimental design\nsince Bayesian optimization has established itself as an efficient tool for\noptimizing expensive black-box functions. Again, it is unknown how to\nincorporate the expert prior knowledge about the global optimum into Bayesian\noptimization process. To address it, we represent the expert knowledge about\nthe global optimum via placing a prior distribution on it and we then derive\nits posterior distribution. An efficient Bayesian optimization approach has\nbeen proposed via posterior sampling on the posterior distribution of the\nglobal optimum. We theoretically analyze the convergence of the proposed\nalgorithm and discuss the robustness of incorporating expert prior. We evaluate\nthe efficiency of our algorithm by optimizing synthetic functions and tuning\nhyperparameters of classifiers along with a real-world experiment on the\nsynthesis of short polymer fiber. The results clearly demonstrate the\nadvantages of our proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 01:57:36 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Cheng", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Nguyen", "Vu", ""], ["Robles-Kelly", "Antonio", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2002.11258", "submitter": "Nicolas Essis-Breton", "authors": "Nicolas Essis-Breton and Patrice Gaillardetz", "title": "Fast Lower and Upper Estimates for the Price of Constrained Multiple\n  Exercise American Options by Single Pass Lookahead Search and\n  Nearest-Neighbor Martingale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG math.OC q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents fast lower and upper estimates for a large class of\noptions: the class of constrained multiple exercise American options. Typical\noptions in this class are swing options with volume and timing constraints, and\npassport options with multiple lookback rights. The lower estimate algorithm\nuses the artificial intelligence method of lookahead search. The upper estimate\nalgorithm uses the dual approach to option pricing on a nearest-neighbor basis\nfor the martingale space. Probabilistic convergence guarantees are provided.\nSeveral numerical examples illustrate the approaches including a swing option\nwith four constraints, and a passport option with 16 constraints.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:06:06 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Essis-Breton", "Nicolas", ""], ["Gaillardetz", "Patrice", ""]]}, {"id": "2002.11262", "submitter": "Abdul Dakkak", "authors": "Abdul Dakkak, Cheng Li, Jinjun Xiong, Wen-Mei Hwu", "title": "DLSpec: A Deep Learning Task Exchange Specification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) innovations are being introduced at a rapid pace. However,\nthe current lack of standard specification of DL tasks makes sharing, running,\nreproducing, and comparing these innovations difficult. To address this\nproblem, we propose DLSpec, a model-, dataset-, software-, and\nhardware-agnostic DL specification that captures the different aspects of DL\ntasks. DLSpec has been tested by specifying and running hundreds of DL tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:27:50 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Dakkak", "Abdul", ""], ["Li", "Cheng", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-Mei", ""]]}, {"id": "2002.11270", "submitter": "Yang Zhao", "authors": "Yang Zhao, Chaojian Li, Yue Wang, Pengfei Xu, Yongan Zhang, and\n  Yingyan Lin", "title": "DNN-Chip Predictor: An Analytical Performance Predictor for DNN\n  Accelerators with Various Dataflows and Hardware Architectures", "comments": "Accepted by 45th International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent breakthroughs in deep neural networks (DNNs) have spurred a\ntremendously increased demand for DNN accelerators. However, designing DNN\naccelerators is non-trivial as it often takes months/years and requires\ncross-disciplinary knowledge. To enable fast and effective DNN accelerator\ndevelopment, we propose DNN-Chip Predictor, an analytical performance predictor\nwhich can accurately predict DNN accelerators' energy, throughput, and latency\nprior to their actual implementation. Our Predictor features two highlights:\n(1) its analytical performance formulation of DNN ASIC/FPGA accelerators\nfacilitates fast design space exploration and optimization; and (2) it supports\nDNN accelerators with different algorithm-to-hardware mapping methods (i.e.,\ndataflows) and hardware architectures. Experiment results based on 2 DNN models\nand 3 different ASIC/FPGA implementations show that our DNN-Chip Predictor's\npredicted performance differs from those of chip measurements of FPGA/ASIC\nimplementation by no more than 17.66% when using different DNN models, hardware\narchitectures, and dataflows. We will release code upon acceptance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:59:18 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 02:52:32 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zhao", "Yang", ""], ["Li", "Chaojian", ""], ["Wang", "Yue", ""], ["Xu", "Pengfei", ""], ["Zhang", "Yongan", ""], ["Lin", "Yingyan", ""]]}, {"id": "2002.11275", "submitter": "Alex Luedtke", "authors": "Alex Luedtke, Incheoul Chung, Oleg Sofrygin", "title": "Adversarial Monte Carlo Meta-Learning of Optimal Prediction Procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We frame the meta-learning of prediction procedures as a search for an\noptimal strategy in a two-player game. In this game, Nature selects a prior\nover distributions that generate labeled data consisting of features and an\nassociated outcome, and the Predictor observes data sampled from a distribution\ndrawn from this prior. The Predictor's objective is to learn a function that\nmaps from a new feature to an estimate of the associated outcome. We establish\nthat, under reasonable conditions, the Predictor has an optimal strategy that\nis equivariant to shifts and rescalings of the outcome and is invariant to\npermutations of the observations and to shifts, rescalings, and permutations of\nthe features. We introduce a neural network architecture that satisfies these\nproperties. The proposed strategy performs favorably compared to standard\npractice in both parametric and nonparametric experiments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:16:05 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 22:26:02 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Luedtke", "Alex", ""], ["Chung", "Incheoul", ""], ["Sofrygin", "Oleg", ""]]}, {"id": "2002.11277", "submitter": "Waheed Bajwa", "authors": "Muhammad Asad Lodhi and Waheed U. Bajwa", "title": "Learning Product Graphs Underlying Smooth Graph Signals", "comments": "14 pages, 5 figures, and 2 tables; revised version of the preprint of\n  a journal paper; revision includes restructuring of text, improved\n  theoretical results, and additional references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data is often times associated with irregular structures that can\nanalytically be represented as graphs. Having access to this graph, which is\nsometimes trivially evident from domain knowledge, provides a better\nrepresentation of the data and facilitates various information processing\ntasks. However, in cases where the underlying graph is unavailable, it needs to\nbe learned from the data itself for data representation, data processing and\ninference purposes. Existing literature on learning graphs from data has mostly\nconsidered arbitrary graphs, whereas the graphs generating real-world data tend\nto have additional structure that can be incorporated in the graph learning\nprocedure. Structure-aware graph learning methods require learning fewer\nparameters and have the potential to reduce computational, memory and sample\ncomplexities. In light of this, the focus of this paper is to devise a method\nto learn structured graphs from data that are given in the form of product\ngraphs. Product graphs arise naturally in many real-world datasets and provide\nan efficient and compact representation of large-scale graphs through several\nsmaller factor graphs. To this end, first the graph learning problem is posed\nas a linear program, which (on average) outperforms the state-of-the-art graph\nlearning algorithms. This formulation is of independent interest itself as it\nshows that graph learning is possible through a simple linear program.\nAfterwards, an alternating minimization-based algorithm aimed at learning\nvarious types of product graphs is proposed, and local convergence guarantees\nto the true solution are established for this algorithm. Finally the\nperformance gains, reduced sample complexity, and inference capabilities of the\nproposed algorithm over existing methods are also validated through numerical\nsimulations on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:25:15 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 21:16:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Lodhi", "Muhammad Asad", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2002.11293", "submitter": "Mo Zhou", "authors": "Mo Zhou, Zhenxing Niu, Le Wang, Qilin Zhang, Gang Hua", "title": "Adversarial Ranking Attack and Defense", "comments": "ECCV2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) classifiers are vulnerable to adversarial attack,\nwhere an imperceptible perturbation could result in misclassification. However,\nthe vulnerability of DNN-based image ranking systems remains under-explored. In\nthis paper, we propose two attacks against deep ranking systems, i.e.,\nCandidate Attack and Query Attack, that can raise or lower the rank of chosen\ncandidates by adversarial perturbations. Specifically, the expected ranking\norder is first represented as a set of inequalities, and then a triplet-like\nobjective function is designed to obtain the optimal perturbation. Conversely,\na defense method is also proposed to improve the ranking system robustness,\nwhich can mitigate all the proposed attacks simultaneously. Our adversarial\nranking attacks and defense are evaluated on datasets including MNIST,\nFashion-MNIST, and Stanford-Online-Products. Experimental results demonstrate\nthat a typical deep ranking system can be effectively compromised by our\nattacks. Meanwhile, the system robustness can be moderately improved with our\ndefense. Furthermore, the transferable and universal properties of our\nadversary illustrate the possibility of realistic black-box attack.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:03:14 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 04:47:31 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 08:49:00 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhou", "Mo", ""], ["Niu", "Zhenxing", ""], ["Wang", "Le", ""], ["Zhang", "Qilin", ""], ["Hua", "Gang", ""]]}, {"id": "2002.11295", "submitter": "Jianjun Hu", "authors": "Yuqi Song, Joseph Lindsay, Yong Zhao, Alireza Nasiri, Steph-Yves\n  Louis, Jie Ling, Ming Hu, Jianjun Hu", "title": "Machine Learning based prediction of noncentrosymmetric crystal\n  materials", "comments": "13 pages", "journal-ref": null, "doi": "10.1016/j.commatsci.2020.109792", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noncentrosymmetric materials play a critical role in many important\napplications such as laser technology, communication systems,quantum computing,\ncybersecurity, and etc. However, the experimental discovery of new\nnoncentrosymmetric materials is extremely difficult. Here we present a machine\nlearning model that could predict whether the composition of a potential\ncrystalline structure would be centrosymmetric or not. By evaluating a diverse\nset of composition features calculated using matminer featurizer package\ncoupled with different machine learning algorithms, we find that Random Forest\nClassifiers give the best performance for noncentrosymmetric material\nprediction, reaching an accuracy of 84.8% when evaluated with 10 fold\ncross-validation on the dataset with 82,506 samples extracted from Materials\nProject. A random forest model trained with materials with only 3 elements\ngives even higher accuracy of 86.9%. We apply our ML model to screen potential\nnoncentrosymmetric materials from 2,000,000 hypothetical materials generated by\nour inverse design engine and report the top 20 candidate noncentrosymmetric\nmaterials with 2 to 4 elements and top 20 borate candidates\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:05:19 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 00:22:55 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Song", "Yuqi", ""], ["Lindsay", "Joseph", ""], ["Zhao", "Yong", ""], ["Nasiri", "Alireza", ""], ["Louis", "Steph-Yves", ""], ["Ling", "Jie", ""], ["Hu", "Ming", ""], ["Hu", "Jianjun", ""]]}, {"id": "2002.11296", "submitter": "Yi Tay", "authors": "Yi Tay, Dara Bahri, Liu Yang, Donald Metzler, and Da-Cheng Juan", "title": "Sparse Sinkhorn Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sparse Sinkhorn Attention, a new efficient and sparse method for\nlearning to attend. Our method is based on differentiable sorting of internal\nrepresentations. Concretely, we introduce a meta sorting network that learns to\ngenerate latent permutations over sequences. Given sorted sequences, we are\nthen able to compute quasi-global attention with only local windows, improving\nthe memory efficiency of the attention module. To this end, we propose new\nalgorithmic innovations such as Causal Sinkhorn Balancing and SortCut, a\ndynamic sequence truncation method for tailoring Sinkhorn Attention for\nencoding and/or decoding purposes. Via extensive experiments on algorithmic\nseq2seq sorting, language modeling, pixel-wise image generation, document\nclassification and natural language inference, we demonstrate that our memory\nefficient Sinkhorn Attention method is competitive with vanilla attention and\nconsistently outperforms recently proposed efficient Transformer models such as\nSparse Transformers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:18:01 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tay", "Yi", ""], ["Bahri", "Dara", ""], ["Yang", "Liu", ""], ["Metzler", "Donald", ""], ["Juan", "Da-Cheng", ""]]}, {"id": "2002.11297", "submitter": "Yen-Chang Hsu", "authors": "Yen-Chang Hsu, Yilin Shen, Hongxia Jin, Zsolt Kira", "title": "Generalized ODIN: Detecting Out-of-distribution Image without Learning\n  from Out-of-distribution Data", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have attained remarkable performance when applied to\ndata that comes from the same distribution as that of the training set, but can\nsignificantly degrade otherwise. Therefore, detecting whether an example is\nout-of-distribution (OoD) is crucial to enable a system that can reject such\nsamples or alert users. Recent works have made significant progress on OoD\nbenchmarks consisting of small image datasets. However, many recent methods\nbased on neural networks rely on training or tuning with both in-distribution\nand out-of-distribution data. The latter is generally hard to define a-priori,\nand its selection can easily bias the learning. We base our work on a popular\nmethod ODIN, proposing two strategies for freeing it from the needs of tuning\nwith OoD data, while improving its OoD detection performance. We specifically\npropose to decompose confidence scoring as well as a modified input\npre-processing method. We show that both of these significantly help in\ndetection performance. Our further analysis on a larger scale image dataset\nshows that the two types of distribution shifts, specifically semantic shift\nand non-semantic shift, present a significant difference in the difficulty of\nthe problem, providing an analysis of when ODIN-like strategies do or do not\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:18:25 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 18:13:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Hsu", "Yen-Chang", ""], ["Shen", "Yilin", ""], ["Jin", "Hongxia", ""], ["Kira", "Zsolt", ""]]}, {"id": "2002.11304", "submitter": "Faez Ahmed", "authors": "Wei Chen, Faez Ahmed", "title": "PaDGAN: A Generative Adversarial Network for Performance Augmented\n  Diverse Designs", "comments": "Paper published in ASME IDETC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are proven to be a useful tool for automatic design\nsynthesis and design space exploration. When applied in engineering design,\nexisting generative models face three challenges: 1) generated designs lack\ndiversity and do not cover all areas of the design space, 2) it is difficult to\nexplicitly improve the overall performance or quality of generated designs, and\n3) existing models generally do not generate novel designs, outside the domain\nof the training data. In this paper, we simultaneously address these challenges\nby proposing a new Determinantal Point Processes based loss function for\nprobabilistic modeling of diversity and quality. With this new loss function,\nwe develop a variant of the Generative Adversarial Network, named \"Performance\nAugmented Diverse Generative Adversarial Network\" or PaDGAN, which can generate\nnovel high-quality designs with good coverage of the design space. Using three\nsynthetic examples and one real-world airfoil design example, we demonstrate\nthat PaDGAN can generate diverse and high-quality designs. In comparison to a\nvanilla Generative Adversarial Network, on average, it generates samples with a\n28% higher mean quality score with larger diversity and without the mode\ncollapse issue. Unlike typical generative models that usually generate new\ndesigns by interpolating within the boundary of training data, we show that\nPaDGAN expands the design space boundary outside the training data towards\nhigh-quality regions. The proposed method is broadly applicable to many tasks\nincluding design space exploration, design optimization, and creative solution\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:53:39 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 21:52:27 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:43:55 GMT"}, {"version": "v4", "created": "Sun, 21 Jun 2020 03:24:47 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Chen", "Wei", ""], ["Ahmed", "Faez", ""]]}, {"id": "2002.11315", "submitter": "XIaoyu Sun", "authors": "Xiaoyu Sun, Nathaniel J. Krakauer, Alexander Politowicz, Wei-Ting\n  Chen, Qiying Li, Zuoyi Li, Xianjia Shao, Alfred Sunaryo, Mingren Shen, James\n  Wang, Dane Morgan", "title": "Assessing Graph-based Deep Learning Models for Predicting Flash Point", "comments": "26 pages, 6 tabels, 3 figures", "journal-ref": "Mol. Inf. 2020, 39, 1900101", "doi": "10.1002/minf.201900101", "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flash points of organic molecules play an important role in preventing\nflammability hazards and large databases of measured values exist, although\nmillions of compounds remain unmeasured. To rapidly extend existing data to new\ncompounds many researchers have used quantitative structure-property\nrelationship (QSPR) analysis to effectively predict flash points. In recent\nyears graph-based deep learning (GBDL) has emerged as a powerful alternative\nmethod to traditional QSPR. In this paper, GBDL models were implemented in\npredicting flash point for the first time. We assessed the performance of two\nGBDL models, message-passing neural network (MPNN) and graph convolutional\nneural network (GCNN), by comparing methods. Our result shows that MPNN both\noutperforms GCNN and yields slightly worse but comparable performance with\nprevious QSPR studies. The average R2 and Mean Absolute Error (MAE) scores of\nMPNN are, respectively, 2.3% lower and 2.0 K higher than previous comparable\nstudies. To further explore GBDL models, we collected the largest flash point\ndataset to date, which contains 10575 unique molecules. The optimized MPNN\ngives a test data R2 of 0.803 and MAE of 17.8 K on the complete dataset. We\nalso extracted 5 datasets from our integrated dataset based on molecular types\n(acids, organometallics, organogermaniums, organosilicons, and organotins) and\nexplore the quality of the model in these classes.against 12 previous QSPR\nstudies using more traditional\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:10:12 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sun", "Xiaoyu", ""], ["Krakauer", "Nathaniel J.", ""], ["Politowicz", "Alexander", ""], ["Chen", "Wei-Ting", ""], ["Li", "Qiying", ""], ["Li", "Zuoyi", ""], ["Shao", "Xianjia", ""], ["Sunaryo", "Alfred", ""], ["Shen", "Mingren", ""], ["Wang", "James", ""], ["Morgan", "Dane", ""]]}, {"id": "2002.11318", "submitter": "Sandesh Kamath K", "authors": "Sandesh Kamath, Amit Deshpande, K V Subrahmanyam, Vineeth N\n  Balasubramanian", "title": "Can we have it all? On the Trade-off between Spatial and Adversarial\n  Robustness of Neural Networks", "comments": "Preliminary version consisting early experimental results was\n  presented in ICML 2018 Workshop on \"Towards learning with limited labels:\n  Equivariance, Invariance,and Beyond\" as \"Understanding Adversarial Robustness\n  of Symmetric Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  (Non-)robustness of neural networks to small, adversarial pixel-wise\nperturbations, and as more recently shown, to even random spatial\ntransformations (e.g., translations, rotations) entreats both theoretical and\nempirical understanding. Spatial robustness to random translations and\nrotations is commonly attained via equivariant models (e.g., StdCNNs, GCNNs)\nand training augmentation, whereas adversarial robustness is typically achieved\nby adversarial training. In this paper, we prove a quantitative trade-off\nbetween spatial and adversarial robustness in a simple statistical setting. We\ncomplement this empirically by showing that: (a) as the spatial robustness of\nequivariant models improves by training augmentation with progressively larger\ntransformations, their adversarial robustness worsens progressively, and (b) as\nthe state-of-the-art robust models are adversarially trained with progressively\nlarger pixel-wise perturbations, their spatial robustness drops progressively.\nTowards achieving pareto-optimality in this trade-off, we propose a method\nbased on curriculum learning that trains gradually on more difficult\nperturbations (both spatial and adversarial) to improve spatial and adversarial\nrobustness simultaneously.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:25:06 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:32:03 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 06:46:08 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 16:28:42 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Kamath", "Sandesh", ""], ["Deshpande", "Amit", ""], ["Subrahmanyam", "K V", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "2002.11323", "submitter": "Ioannis Panageas", "authors": "Ioannis Panageas, Stratis Skoulakis, Antonios Varvitsiotis, and Xiao\n  Wang", "title": "Convergence to Second-Order Stationarity for Non-negative Matrix\n  Factorization: Provably and Concurrently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is a fundamental non-convex\noptimization problem with numerous applications in Machine Learning (music\nanalysis, document clustering, speech-source separation etc). Despite having\nreceived extensive study, it is poorly understood whether or not there exist\nnatural algorithms that can provably converge to a local minimum. Part of the\nreason is because the objective is heavily symmetric and its gradient is not\nLipschitz. In this paper we define a multiplicative weight update type dynamics\n(modification of the seminal Lee-Seung algorithm) that runs concurrently and\nprovably avoids saddle points (first order stationary points that are not\nsecond order). Our techniques combine tools from dynamical systems such as\nstability and exploit the geometry of the NMF objective by reducing the\nstandard NMF formulation over the non-negative orthant to a new formulation\nover (a scaled) simplex. An important advantage of our method is the use of\nconcurrent updates, which permits implementations in parallel computing\nenvironments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 06:40:23 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 11:17:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Panageas", "Ioannis", ""], ["Skoulakis", "Stratis", ""], ["Varvitsiotis", "Antonios", ""], ["Wang", "Xiao", ""]]}, {"id": "2002.11328", "submitter": "Zitong Yang", "authors": "Zitong Yang, Yaodong Yu, Chong You, Jacob Steinhardt, Yi Ma", "title": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical bias-variance trade-off predicts that bias decreases and\nvariance increase with model complexity, leading to a U-shaped risk curve.\nRecent work calls this into question for neural networks and other\nover-parameterized models, for which it is often observed that larger models\ngeneralize better. We provide a simple explanation for this by measuring the\nbias and variance of neural networks: while the bias is monotonically\ndecreasing as in the classical theory, the variance is unimodal or bell-shaped:\nit increases then decreases with the width of the network. We vary the network\narchitecture, loss function, and choice of dataset and confirm that variance\nunimodality occurs robustly for all models we considered. The risk curve is the\nsum of the bias and variance curves and displays different qualitative shapes\ndepending on the relative scale of bias and variance, with the double descent\ncurve observed in recent literature as a special case. We corroborate these\nempirical results with a theoretical analysis of two-layer linear networks with\nrandom first layer. Finally, evaluation on out-of-distribution data shows that\nmost of the drop in accuracy comes from increased bias while variance increases\nby a relatively small amount. Moreover, we find that deeper models decrease\nbias and increase variance for both in-distribution and out-of-distribution\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:21:54 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 05:35:59 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 03:10:44 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Yang", "Zitong", ""], ["Yu", "Yaodong", ""], ["You", "Chong", ""], ["Steinhardt", "Jacob", ""], ["Ma", "Yi", ""]]}, {"id": "2002.11332", "submitter": "Vidyashankar Sivakumar", "authors": "Vidyashankar Sivakumar, Zhiwei Steven Wu, Arindam Banerjee", "title": "Structured Linear Contextual Bandits: A Sharp and Geometric Smoothed\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit learning algorithms typically involve the balance of exploration and\nexploitation. However, in many practical applications, worst-case scenarios\nneeding systematic exploration are seldom encountered. In this work, we\nconsider a smoothed setting for structured linear contextual bandits where the\nadversarial contexts are perturbed by Gaussian noise and the unknown parameter\n$\\theta^*$ has structure, e.g., sparsity, group sparsity, low rank, etc. We\npropose simple greedy algorithms for both the single- and multi-parameter\n(i.e., different parameter for each context) settings and provide a unified\nregret analysis for $\\theta^*$ with any assumed structure. The regret bounds\nare expressed in terms of geometric quantities such as Gaussian widths\nassociated with the structure of $\\theta^*$. We also obtain sharper regret\nbounds compared to earlier work for the unstructured $\\theta^*$ setting as a\nconsequence of our improved analysis. We show there is implicit exploration in\nthe smoothed setting where a simple greedy algorithm works.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:29:24 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Sivakumar", "Vidyashankar", ""], ["Wu", "Zhiwei Steven", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2002.11338", "submitter": "Zhanzhan Cheng", "authors": "Zhanzhan Cheng, Yunlu Xu, Mingjian Cheng, Yu Qiao, Shiliang Pu, Yi Niu\n  and Fei Wu", "title": "Refined Gate: A Simple and Effective Gating Mechanism for Recurrent\n  Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recurrent neural network (RNN) has been widely studied in sequence learning\ntasks, while the mainstream models (e.g., LSTM and GRU) rely on the gating\nmechanism (in control of how information flows between hidden states). However,\nthe vanilla gates in RNN (e.g., the input gate in LSTM) suffer from the problem\nof gate undertraining, which can be caused by various factors, such as the\nsaturating activation functions, the gate layouts (e.g., the gate number and\ngating functions), or even the suboptimal memory state etc.. Those may result\nin failures of learning gating switch roles and thus the weak performance. In\nthis paper, we propose a new gating mechanism within general gated recurrent\nneural networks to handle this issue. Specifically, the proposed gates directly\nshort connect the extracted input features to the outputs of vanilla gates,\ndenoted as refined gates. The refining mechanism allows enhancing gradient\nback-propagation as well as extending the gating activation scope, which can\nguide RNN to reach possibly deeper minima. We verify the proposed gating\nmechanism on three popular types of gated RNNs including LSTM, GRU and MGU.\nExtensive experiments on 3 synthetic tasks, 3 language modeling tasks and 5\nscene text recognition benchmarks demonstrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:51:38 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 13:59:48 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Cheng", "Zhanzhan", ""], ["Xu", "Yunlu", ""], ["Cheng", "Mingjian", ""], ["Qiao", "Yu", ""], ["Pu", "Shiliang", ""], ["Niu", "Yi", ""], ["Wu", "Fei", ""]]}, {"id": "2002.11340", "submitter": "Yaohua Zang", "authors": "Gang Bao, Xiaojing Ye, Yaohua Zang, Haomin Zhou", "title": "Numerical Solution of Inverse Problems by Weak Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6420/abb447", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a weak adversarial network approach to numerically solve a class\nof inverse problems, including electrical impedance tomography and dynamic\nelectrical impedance tomography problems. We leverage the weak formulation of\nPDE in the given inverse problem, and parameterize the solution and the test\nfunction as deep neural networks. The weak formulation and the boundary\nconditions induce a minimax problem of a saddle function of the network\nparameters. As the parameters are alternatively updated, the network gradually\napproximates the solution of the inverse problem. We provide theoretical\njustifications on the convergence of the proposed algorithm. Our method is\ncompletely mesh-free without any spatial discretization, and is particularly\nsuitable for problems with high dimensionality and low regularity on solutions.\nNumerical experiments on a variety of test inverse problems demonstrate the\npromising accuracy and efficiency of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 07:58:37 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 16:19:26 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Bao", "Gang", ""], ["Ye", "Xiaojing", ""], ["Zang", "Yaohua", ""], ["Zhou", "Haomin", ""]]}, {"id": "2002.11349", "submitter": "Kumar Abhishek", "authors": "Kumar Abhishek, Shweta Jain and Sujit Gujar", "title": "Designing Truthful Contextual Multi-Armed Bandits based Sponsored Search\n  Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  For sponsored search auctions, we consider contextual multi-armed bandit\nproblem in the presence of strategic agents. In this setting, at each round, an\nadvertising platform (center) runs an auction to select the best-suited ads\nrelevant to the query posted by the user. It is in the best interest of the\ncenter to select an ad that has a high expected value (i.e., probability of\ngetting a click $\\times$ value it derives from a click of the ad). The\nprobability of getting a click (CTR) is unknown to the center and depends on\nthe user's profile (context) posting the query. Further, the value derived for\na click is the private information to the advertiser and thus needs to be\nelicited truthfully. The existing solution in this setting is not practical as\nit suffers from very high regret ($O(T^{\\frac{2}{3}})$).\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:24:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Abhishek", "Kumar", ""], ["Jain", "Shweta", ""], ["Gujar", "Sujit", ""]]}, {"id": "2002.11360", "submitter": "Yuejiao Sun", "authors": "Tianyi Chen, Yuejiao Sun, Wotao Yin", "title": "LASG: Lazily Aggregated Stochastic Gradients for Communication-Efficient\n  Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper targets solving distributed machine learning problems such as\nfederated learning in a communication-efficient fashion. A class of new\nstochastic gradient descent (SGD) approaches have been developed, which can be\nviewed as the stochastic generalization to the recently developed lazily\naggregated gradient (LAG) method --- justifying the name LASG. LAG adaptively\npredicts the contribution of each round of communication and chooses only the\nsignificant ones to perform. It saves communication while also maintains the\nrate of convergence. However, LAG only works with deterministic gradients, and\napplying it to stochastic gradients yields poor performance. The key components\nof LASG are a set of new rules tailored for stochastic gradients that can be\nimplemented either to save download, upload, or both. The new algorithms\nadaptively choose between fresh and stale stochastic gradients and have\nconvergence rates comparable to the original SGD. LASG achieves impressive\nempirical performance --- it typically saves total communication by an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:58:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Chen", "Tianyi", ""], ["Sun", "Yuejiao", ""], ["Yin", "Wotao", ""]]}, {"id": "2002.11361", "submitter": "Ananya Kumar", "authors": "Ananya Kumar, Tengyu Ma, Percy Liang", "title": "Understanding Self-Training for Gradual Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems must adapt to data distributions that evolve over\ntime, in applications ranging from sensor networks and self-driving car\nperception modules to brain-machine interfaces. We consider gradual domain\nadaptation, where the goal is to adapt an initial classifier trained on a\nsource domain given only unlabeled data that shifts gradually in distribution\ntowards a target domain. We prove the first non-vacuous upper bound on the\nerror of self-training with gradual shifts, under settings where directly\nadapting to the target domain can result in unbounded error. The theoretical\nanalysis leads to algorithmic insights, highlighting that regularization and\nlabel sharpening are essential even when we have infinite data, and suggesting\nthat self-training works particularly well for shifts with small\nWasserstein-infinity distance. Leveraging the gradual shift structure leads to\nhigher accuracies on a rotating MNIST dataset and a realistic Portraits\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:59:40 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kumar", "Ananya", ""], ["Ma", "Tengyu", ""], ["Liang", "Percy", ""]]}, {"id": "2002.11364", "submitter": "Zhize Li", "authors": "Zhize Li and Dmitry Kovalev and Xun Qian and Peter Richt\\'arik", "title": "Acceleration for Compressed Gradient Descent in Distributed and\n  Federated Optimization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the high communication cost in distributed and federated learning\nproblems, methods relying on compression of communicated messages are becoming\nincreasingly popular. While in other contexts the best performing gradient-type\nmethods invariably rely on some form of acceleration/momentum to reduce the\nnumber of iterations, there are no methods which combine the benefits of both\ngradient compression and acceleration. In this paper, we remedy this situation\nand propose the first accelerated compressed gradient descent (ACGD) methods.\nIn the single machine regime, we prove that ACGD enjoys the rate\n$O\\Big((1+\\omega)\\sqrt{\\frac{L}{\\mu}}\\log \\frac{1}{\\epsilon}\\Big)$ for\n$\\mu$-strongly convex problems and\n$O\\Big((1+\\omega)\\sqrt{\\frac{L}{\\epsilon}}\\Big)$ for convex problems,\nrespectively, where $\\omega$ is the compression parameter. Our results improve\nupon the existing non-accelerated rates $O\\Big((1+\\omega)\\frac{L}{\\mu}\\log\n\\frac{1}{\\epsilon}\\Big)$ and $O\\Big((1+\\omega)\\frac{L}{\\epsilon}\\Big)$,\nrespectively, and recover the optimal rates of accelerated gradient descent as\na special case when no compression ($\\omega=0$) is applied. We further propose\na distributed variant of ACGD (called ADIANA) and prove the convergence rate\n$\\widetilde{O}\\Big(\\omega+\\sqrt{\\frac{L}{\\mu}}+\\sqrt{\\big(\\frac{\\omega}{n}+\\sqrt{\\frac{\\omega}{n}}\\big)\\frac{\\omega\nL}{\\mu}}\\Big)$, where $n$ is the number of devices/workers and $\\widetilde{O}$\nhides the logarithmic factor $\\log \\frac{1}{\\epsilon}$. This improves upon the\nprevious best result $\\widetilde{O}\\Big(\\omega + \\frac{L}{\\mu}+\\frac{\\omega\nL}{n\\mu} \\Big)$ achieved by the DIANA method of Mishchenko et al. (2019).\nFinally, we conduct several experiments on real-world datasets which\ncorroborate our theoretical results and confirm the practical superiority of\nour accelerated methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:03:23 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 21:36:17 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Li", "Zhize", ""], ["Kovalev", "Dmitry", ""], ["Qian", "Xun", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2002.11369", "submitter": "Adri\\'an Javaloy", "authors": "Adri\\'an Javaloy, Isabel Valera", "title": "Lipschitz standardization for multivariate learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic learning is increasingly being tackled as an optimization\nproblem, with gradient-based approaches as predominant methods. When modelling\nmultivariate likelihoods, a usual but undesirable outcome is that the learned\nmodel fits only a subset of the observed variables, overlooking the rest. In\nthis work, we study this problem through the lens of multitask learning (MTL),\nwhere similar effects have been broadly studied. While MTL solutions do not\ndirectly apply in the probabilistic setting (as they cannot handle the\nlikelihood constraints) we show that similar ideas may be leveraged during data\npreprocessing. First, we show that data standardization often helps under\ncommon continuous likelihoods, but it is not enough in the general case,\nspecially under mixed continuous and discrete likelihood models. In order for\nbalance multivariate learning, we then propose a novel data preprocessing,\nLipschitz standardization, which balances the local Lipschitz smoothness across\nvariables. Our experiments on real-world datasets show that Lipschitz\nstandardization leads to more accurate multivariate models than the ones\nlearned using existing data preprocessing techniques. The models and datasets\nemployed in the experiments can be found in\nhttps://github.com/adrianjav/lipschitz-standardization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:20:10 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 14:23:49 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 21:24:54 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Javaloy", "Adri\u00e1n", ""], ["Valera", "Isabel", ""]]}, {"id": "2002.11379", "submitter": "Anirudh Joshi", "authors": "Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Phil Chen, Amirhossein\n  Kiani, Jeremy Irvin, Andrew Y. Ng, Matthew P. Lungren", "title": "CheXpedition: Investigating Generalization Challenges for Translation of\n  Chest X-Ray Algorithms to the Clinical Setting", "comments": "Accepted as workshop paper at ACM Conference on Health, Inference,\n  and Learning (CHIL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Although there have been several recent advances in the application of deep\nlearning algorithms to chest x-ray interpretation, we identify three major\nchallenges for the translation of chest x-ray algorithms to the clinical\nsetting. We examine the performance of the top 10 performing models on the\nCheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology\ndetection on photos of chest x-rays, and (3) pathology detection on data from\nan external institution. First, we find that the top 10 chest x-ray models on\nthe CheXpert competition achieve an average AUC of 0.851 on the task of\ndetecting TB on two public TB datasets without fine-tuning or including the TB\nlabels in training data. Second, we find that the average performance of the\nmodels on photos of x-rays (AUC = 0.916) is similar to their performance on the\noriginal chest x-ray images (AUC = 0.924). Third, we find that the models\ntested on an external dataset either perform comparably to or exceed the\naverage performance of radiologists. We believe that our investigation will\ninform rapid translation of deep learning algorithms to safe and effective\nclinical decision support tools that can be validated prospectively with large\nimpact studies and clinical trials.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:44:21 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 07:15:57 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Rajpurkar", "Pranav", ""], ["Joshi", "Anirudh", ""], ["Pareek", "Anuj", ""], ["Chen", "Phil", ""], ["Kiani", "Amirhossein", ""], ["Irvin", "Jeremy", ""], ["Ng", "Andrew Y.", ""], ["Lungren", "Matthew P.", ""]]}, {"id": "2002.11385", "submitter": "Xingbo Fu", "authors": "Xingbo Fu, Feng Gao, Jiang Wu", "title": "When Do Drivers Concentrate? Attention-based Driver Behavior Modeling\n  With Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver distraction a significant risk to driving safety. Apart from spatial\ndomain, research on temporal inattention is also necessary. This paper aims to\nfigure out the pattern of drivers' temporal attention allocation. In this\npaper, we propose an actor-critic method - Attention-based Twin Delayed Deep\nDeterministic policy gradient (ATD3) algorithm to approximate a driver' s\naction according to observations and measure the driver' s attention allocation\nfor consecutive time steps in car-following model. Considering reaction time,\nwe construct the attention mechanism in the actor network to capture temporal\ndependencies of consecutive observations. In the critic network, we employ Twin\nDelayed Deep Deterministic policy gradient algorithm (TD3) to address\noverestimated value estimates persisting in the actor-critic algorithm. We\nconduct experiments on real-world vehicle trajectory datasets and show that the\naccuracy of our proposed approach outperforms seven baseline algorithms.\nMoreover, the results reveal that the attention of the drivers in smooth\nvehicles is uniformly distributed in previous observations while they keep\ntheir attention to recent observations when sudden decreases of relative speeds\noccur. This study is the first contribution to drivers' temporal attention and\nprovides scientific support for safety measures in transportation systems from\nthe perspective of data mining.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 09:56:36 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 06:09:55 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Fu", "Xingbo", ""], ["Gao", "Feng", ""], ["Wu", "Jiang", ""]]}, {"id": "2002.11394", "submitter": "Xuhui Fan", "authors": "Xuhui Fan, Bin Li, Ling Luo, Scott A. Sisson", "title": "Bayesian Nonparametric Space Partitions: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian nonparametric space partition (BNSP) models provide a variety of\nstrategies for partitioning a $D$-dimensional space into a set of blocks. In\nthis way, the data points lie in the same block would share certain kinds of\nhomogeneity. BNSP models can be applied to various areas, such as\nregression/classification trees, random feature construction, relational\nmodeling, etc. In this survey, we investigate the current progress of BNSP\nresearch through the following three perspectives: models, which review various\nstrategies for generating the partitions in the space and discuss their\ntheoretical foundation `self-consistency'; applications, which cover the\ncurrent mainstream usages of BNSP models and their potential future practises;\nand challenges, which identify the current unsolved problems and valuable\nfuture research topics. As there are no comprehensive reviews of BNSP\nliterature before, we hope that this survey can induce further exploration and\nexploitation on this topic.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:25:04 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 13:09:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Fan", "Xuhui", ""], ["Li", "Bin", ""], ["Luo", "Ling", ""], ["Sisson", "Scott A.", ""]]}, {"id": "2002.11416", "submitter": "Jalpa Shah", "authors": "Jalpa Shah and Biswajit Mishra", "title": "Analytical Equations based Prediction Approach for PM2.5 using\n  Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Particulate matter pollution is one of the deadliest types of air pollution\nworldwide due to its significant impacts on the global environment and human\nhealth. Particulate Matter (PM2.5) is one of the important particulate\npollutants to measure the Air Quality Index (AQI). The conventional instruments\nused by the air quality monitoring stations to monitor PM2.5 are costly,\nbulkier, time-consuming, and power-hungry. Furthermore, due to limited data\navailability and non-scalability, these stations cannot provide high spatial\nand temporal resolution in real-time. To overcome the disadvantages of existing\nmethodology this article presents analytical equations based prediction\napproach for PM2.5 using an Artificial Neural Network (ANN). Since the derived\nanalytical equations for the prediction can be computed using a Wireless Sensor\nNode (WSN) or low-cost processing tool, it demonstrates the usefulness of the\nproposed approach. Moreover, the study related to correlation among the PM2.5\nand other pollutants is performed to select the appropriate predictors. The\nlarge authenticate data set of Central Pollution Control Board (CPCB) online\nstation, India is used for the proposed approach. The RMSE and coefficient of\ndetermination (R2) obtained for the proposed prediction approach using eight\npredictors are 1.7973 ug/m3 and 0.9986 respectively. While the proposed\napproach results show RMSE of 7.5372 ug/m3 and R2 of 0.9708 using three\npredictors. Therefore, the results demonstrate that the proposed approach is\none of the promising approaches for monitoring PM2.5 without power-hungry gas\nsensors and bulkier analyzers.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 11:39:18 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Shah", "Jalpa", ""], ["Mishra", "Biswajit", ""]]}, {"id": "2002.11423", "submitter": "Jaime Pizarroso Gonzalo", "authors": "J. Pizarroso, J. Portela and A. Mu\\~noz", "title": "NeuralSens: Sensitivity Analysis of Neural Networks", "comments": "28 pages, 12 figures, submitted to Journal of Statistical Software\n  (JSS) https://www.jstatsoft.org/index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are important tools for data-intensive analysis and are\ncommonly applied to model non-linear relationships between dependent and\nindependent variables. However, neural networks are usually seen as \"black\nboxes\" that offer minimal information about how the input variables are used to\npredict the response in a fitted model. This article describes the\n\\pkg{NeuralSens} package that can be used to perform sensitivity analysis of\nneural networks using the partial derivatives method. Functions in the package\ncan be used to obtain the sensitivities of the output with respect to the input\nvariables, evaluate variable importance based on sensitivity measures and\ncharacterize relationships between input and output variables. Methods to\ncalculate sensitivities are provided for objects from common neural network\npackages in \\proglang{R}, including \\pkg{neuralnet}, \\pkg{nnet}, \\pkg{RSNNS},\n\\pkg{h2o}, \\pkg{neural}, \\pkg{forecast} and \\pkg{caret}. The article presents\nan overview of the techniques for obtaining information from neural network\nmodels, a theoretical foundation of how are calculated the partial derivatives\nof the output with respect to the inputs of a multi-layer perceptron model, a\ndescription of the package structure and functions, and applied examples to\ncompare \\pkg{NeuralSens} functions with analogous functions from other\navailable \\proglang{R} packages.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:05:59 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:01:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pizarroso", "J.", ""], ["Portela", "J.", ""], ["Mu\u00f1oz", "A.", ""]]}, {"id": "2002.11429", "submitter": "Janis Keuper", "authors": "Peter Michael Habelitz and Janis Keuper", "title": "PHS: A Toolbox for Parallel Hyperparameter Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an open source python framework named PHS - Parallel\nHyperparameter Search to enable hyperparameter optimization on numerous compute\ninstances of any arbitrary python function. This is achieved with minimal\nmodifications inside the target function. Possible applications appear in\nexpensive to evaluate numerical computations which strongly depend on\nhyperparameters such as machine learning. Bayesian optimization is chosen as a\nsample efficient method to propose the next query set of parameters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:17:54 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 12:30:00 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Habelitz", "Peter Michael", ""], ["Keuper", "Janis", ""]]}, {"id": "2002.11434", "submitter": "Kira Vinogradova", "authors": "Kira Vinogradova, Alexandr Dibrov, Gene Myers", "title": "Towards Interpretable Semantic Segmentation via Gradient-weighted Class\n  Activation Mapping", "comments": "2 pages, 2 figures. AAAI 2020 camera-ready", "journal-ref": "Proceedings of the Thirty-Fourth AAAI Conference on Artificial\n  Intelligence, New York, USA, Feb 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have become state-of-the-art in a wide range of\nimage recognition tasks. The interpretation of their predictions, however, is\nan active area of research. Whereas various interpretation methods have been\nsuggested for image classification, the interpretation of image segmentation\nstill remains largely unexplored. To that end, we propose SEG-GRAD-CAM, a\ngradient-based method for interpreting semantic segmentation. Our method is an\nextension of the widely-used Grad-CAM method, applied locally to produce\nheatmaps showing the relevance of individual pixels for semantic segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:32:40 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Vinogradova", "Kira", ""], ["Dibrov", "Alexandr", ""], ["Myers", "Gene", ""]]}, {"id": "2002.11436", "submitter": "Luk\\'a\\v{s} Adam", "authors": "V\\'aclav M\\'acha, Luk\\'a\\v{s} Adam, V\\'aclav \\v{S}m\\'idl", "title": "Nonlinear classifiers for ranking problems based on kernelized SVM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classification problems focus on maximizing the performance only on the\nsamples with the highest relevance instead of all samples. As an example, we\ncan mention ranking problems, accuracy at the top or search engines where only\nthe top few queries matter. In our previous work, we derived a general\nframework including several classes of these linear classification problems. In\nthis paper, we extend the framework to nonlinear classifiers. Utilizing a\nsimilarity to SVM, we dualize the problems, add kernels and propose a\ncomponentwise dual ascent method. This allows us to perform one iteration in\nless than 20 milliseconds on relatively large datasets such as FashionMNIST.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:37:11 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["M\u00e1cha", "V\u00e1clav", ""], ["Adam", "Luk\u00e1\u0161", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""]]}, {"id": "2002.11440", "submitter": "L.A. Prashanth", "authors": "Nirav Bhavsar and Prashanth L.A", "title": "Non-asymptotic bounds for stochastic optimization with biased noisy\n  gradient oracles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce biased gradient oracles to capture a setting where the function\nmeasurements have an estimation error that can be controlled through a batch\nsize parameter. Our proposed oracles are appealing in several practical\ncontexts, for instance, risk measure estimation from a batch of independent and\nidentically distributed (i.i.d.) samples, or simulation optimization, where the\nfunction measurements are `biased' due to computational constraints. In either\ncase, increasing the batch size reduces the estimation error. We highlight the\napplicability of our biased gradient oracles in a risk-sensitive reinforcement\nlearning setting. In the stochastic non-convex optimization context, we analyze\na variant of the randomized stochastic gradient (RSG) algorithm with a biased\ngradient oracle. We quantify the convergence rate of this algorithm by deriving\nnon-asymptotic bounds on its performance. Next, in the stochastic convex\noptimization setting, we derive non-asymptotic bounds for the last iterate of a\nstochastic gradient descent (SGD) algorithm with a biased gradient oracle.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:53:04 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 11:50:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bhavsar", "Nirav", ""], ["A", "Prashanth L.", ""]]}, {"id": "2002.11442", "submitter": "Maarten Buyl", "authors": "Maarten Buyl, Tijl De Bie", "title": "DeBayes: a Bayesian Method for Debiasing Network Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms are increasingly deployed for high-impact\nautomated decision making, ethical and increasingly also legal standards demand\nthat they treat all individuals fairly, without discrimination based on their\nage, gender, race or other sensitive traits. In recent years much progress has\nbeen made on ensuring fairness and reducing bias in standard machine learning\nsettings. Yet, for network embedding, with applications in vulnerable domains\nranging from social network analysis to recommender systems, current options\nremain limited both in number and performance. We thus propose DeBayes: a\nconceptually elegant Bayesian method that is capable of learning debiased\nembeddings by using a biased prior. Our experiments show that these\nrepresentations can then be used to perform link prediction that is\nsignificantly more fair in terms of popular metrics such as demographic parity\nand equalized opportunity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:57:05 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 10:41:11 GMT"}, {"version": "v3", "created": "Fri, 30 Apr 2021 10:18:43 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Buyl", "Maarten", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.11448", "submitter": "Ilya Tolstikhin", "authors": "Thomas Unterthiner, Daniel Keysers, Sylvain Gelly, Olivier Bousquet,\n  Ilya Tolstikhin", "title": "Predicting Neural Network Accuracy from Weights", "comments": "Updated the Small CNN Zoo dataset: reduced the maximal learning rate\n  and got rid of multiple bad runs. Replaced all the experiments with the new\n  numbers. Added MLP. Fixed typo in the abstract (R2 score instead of Kendall's\n  tau). Added several earlier related works to the literature overview", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show experimentally that the accuracy of a trained neural network can be\npredicted surprisingly well by looking only at its weights, without evaluating\nit on input data. We motivate this task and introduce a formal setting for it.\nEven when using simple statistics of the weights, the predictors are able to\nrank neural networks by their performance with very high accuracy (R2 score\nmore than 0.98). Furthermore, the predictors are able to rank networks trained\non different, unobserved datasets and with different architectures. We release\na collection of 120k convolutional neural networks trained on four different\ndatasets to encourage further research in this area, with the goal of\nunderstanding network training and performance better.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:06:14 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 08:07:41 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 12:05:10 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 10:38:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Unterthiner", "Thomas", ""], ["Keysers", "Daniel", ""], ["Gelly", "Sylvain", ""], ["Bousquet", "Olivier", ""], ["Tolstikhin", "Ilya", ""]]}, {"id": "2002.11451", "submitter": "Th\\'eo Galy-Fajou", "authors": "Th\\'eo Galy-Fajou, Florian Wenzel, Manfred Opper", "title": "Automated Augmented Conjugate Inference for Non-conjugate Gaussian\n  Process Models", "comments": "Accepted at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose automated augmented conjugate inference, a new inference method\nfor non-conjugate Gaussian processes (GP) models. Our method automatically\nconstructs an auxiliary variable augmentation that renders the GP model\nconditionally conjugate. Building on the conjugate structure of the augmented\nmodel, we develop two inference methods. First, a fast and scalable stochastic\nvariational inference method that uses efficient block coordinate ascent\nupdates, which are computed in closed form. Second, an asymptotically correct\nGibbs sampler that is useful for small datasets. Our experiments show that our\nmethod are up two orders of magnitude faster and more robust than existing\nstate-of-the-art black-box methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:10:00 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Galy-Fajou", "Th\u00e9o", ""], ["Wenzel", "Florian", ""], ["Opper", "Manfred", ""]]}, {"id": "2002.11474", "submitter": "Siyue Wang", "authors": "Peiyan Dong, Siyue Wang, Wei Niu, Chengming Zhang, Sheng Lin, Zhengang\n  Li, Yifan Gong, Bin Ren, Xue Lin, Yanzhi Wang, and Dingwen Tao", "title": "RTMobile: Beyond Real-Time Mobile Acceleration of RNNs for Speech\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) based automatic speech recognition has\nnowadays become prevalent on mobile devices such as smart phones. However,\nprevious RNN compression techniques either suffer from hardware performance\noverhead due to irregularity or significant accuracy loss due to the preserved\nregularity for hardware friendliness. In this work, we propose RTMobile that\nleverages both a novel block-based pruning approach and compiler optimizations\nto accelerate RNN inference on mobile devices. Our proposed RTMobile is the\nfirst work that can achieve real-time RNN inference on mobile platforms.\nExperimental results demonstrate that RTMobile can significantly outperform\nexisting RNN hardware acceleration methods in terms of inference accuracy and\ntime. Compared with prior work on FPGA, RTMobile using Adreno 640 embedded GPU\non GRU can improve the energy-efficiency by about 40$\\times$ while maintaining\nthe same inference time.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 00:07:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Dong", "Peiyan", ""], ["Wang", "Siyue", ""], ["Niu", "Wei", ""], ["Zhang", "Chengming", ""], ["Lin", "Sheng", ""], ["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Ren", "Bin", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""], ["Tao", "Dingwen", ""]]}, {"id": "2002.11477", "submitter": "Robin Karlsson", "authors": "Robin Karlsson, Erik Sjoberg", "title": "Learning a Directional Soft Lane Affordance Model for Road Scenes Using\n  Self-Supervision", "comments": "Accepted for IEEE IV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans navigate complex environments in an organized yet flexible manner,\nadapting to the context and implicit social rules. Understanding these\nnaturally learned patterns of behavior is essential for applications such as\nautonomous vehicles. However, algorithmically defining these implicit rules of\nhuman behavior remains difficult. This work proposes a novel self-supervised\nmethod for training a probabilistic network model to estimate the regions\nhumans are most likely to drive in as well as a multimodal representation of\nthe inferred direction of travel at each point. The model is trained on\nindividual human trajectories conditioned on a representation of the driving\nenvironment. The model is shown to successfully generalize to new road scenes,\ndemonstrating potential for real-world application as a prior for socially\nacceptable driving behavior in challenging or ambiguous scenarios which are\npoorly handled by explicit traffic rules.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 00:57:34 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 13:19:45 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Karlsson", "Robin", ""], ["Sjoberg", "Erik", ""]]}, {"id": "2002.11497", "submitter": "Sanghyun Hong", "authors": "Sanghyun Hong, Varun Chandrasekaran, Yi\\u{g}itcan Kaya, Tudor\n  Dumitra\\c{s}, Nicolas Papernot", "title": "On the Effectiveness of Mitigating Data Poisoning Attacks with Gradient\n  Shaping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are vulnerable to data poisoning attacks. Prior\ntaxonomies that focus on specific scenarios, e.g., indiscriminate or targeted,\nhave enabled defenses for the corresponding subset of known attacks. Yet, this\nintroduces an inevitable arms race between adversaries and defenders. In this\nwork, we study the feasibility of an attack-agnostic defense relying on\nartifacts that are common to all poisoning attacks. Specifically, we focus on a\ncommon element between all attacks: they modify gradients computed to train the\nmodel. We identify two main artifacts of gradients computed in the presence of\npoison: (1) their $\\ell_2$ norms have significantly higher magnitudes than\nthose of clean gradients, and (2) their orientation differs from clean\ngradients. Based on these observations, we propose the prerequisite for a\ngeneric poisoning defense: it must bound gradient magnitudes and minimize\ndifferences in orientation. We call this gradient shaping. As an exemplar tool\nto evaluate the feasibility of gradient shaping, we use differentially private\nstochastic gradient descent (DP-SGD), which clips and perturbs individual\ngradients during training to obtain privacy guarantees. We find that DP-SGD,\neven in configurations that do not result in meaningful privacy guarantees,\nincreases the model's robustness to indiscriminate attacks. It also mitigates\nworst-case targeted attacks and increases the adversary's cost in multi-poison\nscenarios. The only attack we find DP-SGD to be ineffective against is a\nstrong, yet unrealistic, indiscriminate attack. Our results suggest that, while\nwe currently lack a generic poisoning defense, gradient shaping is a promising\ndirection for future research.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:04:16 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 19:00:01 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Hong", "Sanghyun", ""], ["Chandrasekaran", "Varun", ""], ["Kaya", "Yi\u011fitcan", ""], ["Dumitra\u015f", "Tudor", ""], ["Papernot", "Nicolas", ""]]}, {"id": "2002.11498", "submitter": "Mohammed Nabil El Korso M. N. El Korso", "authors": "Martin Brossard, Virginie Ollier, Mohammed Nabil El Korso, R\\'emy\n  Boyer and Pascal Larzabal", "title": "Multi-frequency calibration for DOA estimation with distributed sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate direction finding in the presence of sensor gain\nuncertainties and directional perturbations for sensor array processing in a\nmulti-frequency scenario. Specifically, we adopt a distributed optimization\nscheme in which coherence models are incorporated and local agents exchange\ninformation only between connected nodes in the network, i.e., without a fusion\ncenter. Numerical simulations highlight the advantages of the proposed parallel\niterative technique in terms of statistical and computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 21:16:43 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Brossard", "Martin", ""], ["Ollier", "Virginie", ""], ["Korso", "Mohammed Nabil El", ""], ["Boyer", "R\u00e9my", ""], ["Larzabal", "Pascal", ""]]}, {"id": "2002.11501", "submitter": "Hankz Hankui Zhuo", "authors": "Huiling Zhu, Xin Luo, and Hankz Hankui Zhuo", "title": "Dual Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning embeds nodes in large graphs as low-dimensional\nvectors and is of great benefit to many downstream applications. Most embedding\nframeworks, however, are inherently transductive and unable to generalize to\nunseen nodes or learn representations across different graphs. Although\ninductive approaches can generalize to unseen nodes, they neglect different\ncontexts of nodes and cannot learn node embeddings dually. In this paper, we\npresent a context-aware unsupervised dual encoding framework, \\textbf{CADE}, to\ngenerate representations of nodes by combining real-time neighborhoods with\nneighbor-attentioned representation, and preserving extra memory of known\nnodes. We exhibit that our approach is effective by comparing to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 04:50:17 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Zhu", "Huiling", ""], ["Luo", "Xin", ""], ["Zhuo", "Hankz Hankui", ""]]}, {"id": "2002.11505", "submitter": "Janne H. Korhonen", "authors": "Vitaly Aksenov and Dan Alistarh and Janne H. Korhonen", "title": "Relaxed Scheduling for Scalable Belief Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to leverage large-scale hardware parallelism has been one of the\nkey enablers of the accelerated recent progress in machine learning.\nConsequently, there has been considerable effort invested into developing\nefficient parallel variants of classic machine learning algorithms. However,\ndespite the wealth of knowledge on parallelization, some classic machine\nlearning algorithms often prove hard to parallelize efficiently while\nmaintaining convergence.\n  In this paper, we focus on efficient parallel algorithms for the key machine\nlearning task of inference on graphical models, in particular on the\nfundamental belief propagation algorithm. We address the challenge of\nefficiently parallelizing this classic paradigm by showing how to leverage\nscalable relaxed schedulers in this context. We present an extensive empirical\nstudy, showing that our approach outperforms previous parallel belief\npropagation implementations both in terms of scalability and in terms of\nwall-clock convergence time, on a range of practical applications.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:28:04 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:54:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Alistarh", "Dan", ""], ["Korhonen", "Janne H.", ""]]}, {"id": "2002.11511", "submitter": "Bulbul Ahmmed", "authors": "B. Ahmmed, M. K. Mudunuru, S. Karra, S. C. James, and V. V. Vesselinov", "title": "A Comparative Study of Machine Learning Models for Predicting the State\n  of Reactive Mixing", "comments": "31 pages", "journal-ref": null, "doi": "10.1016/j.jcp.2021.110147", "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate predictions of reactive mixing are critical for many Earth and\nenvironmental science problems. To investigate mixing dynamics over time under\ndifferent scenarios, a high-fidelity, finite-element-based numerical model is\nbuilt to solve the fast, irreversible bimolecular reaction-diffusion equations\nto simulate a range of reactive-mixing scenarios. A total of 2,315 simulations\nare performed using different sets of model input parameters comprising various\nspatial scales of vortex structures in the velocity field, time-scales\nassociated with velocity oscillations, the perturbation parameter for the\nvortex-based velocity, anisotropic dispersion contrast, and molecular\ndiffusion. Outputs comprise concentration profiles of the reactants and\nproducts. The inputs and outputs of these simulations are concatenated into\nfeature and label matrices, respectively, to train 20 different machine\nlearning (ML) emulators to approximate system behavior. The 20 ML emulators\nbased on linear methods, Bayesian methods, ensemble learning methods, and\nmultilayer perceptron (MLP), are compared to assess these models. The ML\nemulators are specifically trained to classify the state of mixing and predict\nthree quantities of interest (QoIs) characterizing species production, decay,\nand degree of mixing. Linear classifiers and regressors fail to reproduce the\nQoIs; however, ensemble methods (classifiers and regressors) and the MLP\naccurately classify the state of reactive mixing and the QoIs. Among ensemble\nmethods, random forest and decision-tree-based AdaBoost faithfully predict the\nQoIs. At run time, trained ML emulators are $\\approx10^5$ times faster than the\nhigh-fidelity numerical simulations. Speed and accuracy of the ensemble and MLP\nmodels facilitate uncertainty quantification, which usually requires 1,000s of\nmodel run, to estimate the uncertainty bounds on the QoIs.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 22:50:19 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ahmmed", "B.", ""], ["Mudunuru", "M. K.", ""], ["Karra", "S.", ""], ["James", "S. C.", ""], ["Vesselinov", "V. V.", ""]]}, {"id": "2002.11519", "submitter": "Alberto Gandolfi", "authors": "Alberto Gandolfi", "title": "Decidability of Sample Complexity of PAC Learning in finite setting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we observe that the sample complexity of PAC machine\nlearning of various concepts, including learning the maximum (EMX), can be\nexactly determined when the support of the probability measures considered as\nmodels satisfies an a-priori bound. This result contrasts with the recently\ndiscovered undecidability of EMX within ZFC for finitely supported\nprobabilities (with no a priori bound). Unfortunately, the decision procedure\nis at present, at least doubly exponential in the number of points times the\nuniform bound on the support size.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:27:36 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gandolfi", "Alberto", ""]]}, {"id": "2002.11522", "submitter": "Alexandru Cristian Mara", "authors": "Alexandru Mara, Jefrey Lijffijt and Tijl De Bie", "title": "Benchmarking Network Embedding Models for Link Prediction: Are We Making\n  Progress?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding methods map a network's nodes to vectors in an embedding\nspace, in such a way that these representations are useful for estimating some\nnotion of similarity or proximity between pairs of nodes in the network. The\nquality of these node representations is then showcased through results of\ndownstream prediction tasks. Commonly used benchmark tasks such as link\nprediction, however, present complex evaluation pipelines and an abundance of\ndesign choices. This, together with a lack of standardized evaluation setups\ncan obscure the real progress in the field. In this paper, we aim to shed light\non the state-of-the-art of network embedding methods for link prediction and\nshow, using a consistent evaluation pipeline, that only thin progress has been\nmade over the last years. The newly conducted benchmark that we present here,\nincluding 17 embedding methods, also shows that many approaches are\noutperformed even by simple heuristics. Finally, we argue that standardized\nevaluation tools can repair this situation and boost future progress in this\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 16:59:09 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 14:45:59 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 08:57:10 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 11:37:54 GMT"}, {"version": "v5", "created": "Thu, 3 Sep 2020 12:48:59 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Mara", "Alexandru", ""], ["Lijffijt", "Jefrey", ""], ["De Bie", "Tijl", ""]]}, {"id": "2002.11531", "submitter": "Jakob Lindqvist", "authors": "Jakob Lindqvist, Amanda Olmin, Fredrik Lindsten, Lennart Svensson", "title": "A general framework for ensemble distribution distillation", "comments": null, "journal-ref": "2020 IEEE 30th International Workshop on Machine Learning for\n  Signal Processing (MLSP), Espoo, Finland, 2020, pp. 1-6", "doi": "10.1109/MLSP49062.2020.9231703", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of neural networks have been shown to give better performance than\nsingle networks, both in terms of predictions and uncertainty estimation.\nAdditionally, ensembles allow the uncertainty to be decomposed into aleatoric\n(data) and epistemic (model) components, giving a more complete picture of the\npredictive uncertainty. Ensemble distillation is the process of compressing an\nensemble into a single model, often resulting in a leaner model that still\noutperforms the individual ensemble members. Unfortunately, standard\ndistillation erases the natural uncertainty decomposition of the ensemble. We\npresent a general framework for distilling both regression and classification\nensembles in a way that preserves the decomposition. We demonstrate the desired\nbehaviour of our framework and show that its predictive performance is on par\nwith standard distillation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:34:43 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 11:20:35 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lindqvist", "Jakob", ""], ["Olmin", "Amanda", ""], ["Lindsten", "Fredrik", ""], ["Svensson", "Lennart", ""]]}, {"id": "2002.11537", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Ricardo Pio Monti, Diederik P. Kingma, Aapo\n  Hyv\\\"arinen", "title": "ICE-BeeM: Identifiable Conditional Energy-Based Deep Models Based on\n  Nonlinear ICA", "comments": "Accepted for publication at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the identifiability theory of probabilistic models and establish\nsufficient conditions under which the representations learned by a very broad\nfamily of conditional energy-based models are unique in function space, up to a\nsimple transformation. In our model family, the energy function is the\ndot-product between two feature extractors, one for the dependent variable, and\none for the conditioning variable. We show that under mild conditions, the\nfeatures are unique up to scaling and permutation. Our results extend recent\ndevelopments in nonlinear ICA, and in fact, they lead to an important\ngeneralization of ICA models. In particular, we show that our model can be used\nfor the estimation of the components in the framework of Independently\nModulated Component Analysis (IMCA), a new generalization of nonlinear ICA that\nrelaxes the independence assumption. A thorough empirical study shows that\nrepresentations learned by our model from real-world image datasets are\nidentifiable, and improve performance in transfer learning and semi-supervised\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:43:30 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 09:39:39 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 18:18:44 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 17:49:11 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Monti", "Ricardo Pio", ""], ["Kingma", "Diederik P.", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "2002.11541", "submitter": "Mano Vikash Janardhanan", "authors": "Mano Vikash Janardhanan, Lev Reyzin", "title": "On Learning a Hidden Directed Graph with Path Queries", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of reconstructing a directed graph\nusing path queries. In this query model of learning, a graph is hidden from the\nlearner, and the learner can access information about it with path queries. For\na source and destination node, a path query returns whether there is a directed\npath from the source to the destination node in the hidden graph. In this paper\nwe first give bounds for learning graphs on $n$ vertices and $k$ strongly\nconnected components. We then study the case of bounded degree directed trees\nand give new algorithms for learning \"almost-trees\" -- directed trees to which\nextra edges have been added. We also give some lower bound constructions\njustifying our approach.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:49:20 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 05:23:13 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Janardhanan", "Mano Vikash", ""], ["Reyzin", "Lev", ""]]}, {"id": "2002.11544", "submitter": "Francesca Mignacco", "authors": "Francesca Mignacco, Florent Krzakala, Yue M. Lu and Lenka Zdeborov\\'a", "title": "The role of regularization in classification of high-dimensional noisy\n  Gaussian mixture", "comments": "8 pages + appendix, 6 figures", "journal-ref": "International Conference on Machine Learning, ICML 2020", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a high-dimensional mixture of two Gaussians in the noisy regime\nwhere even an oracle knowing the centers of the clusters misclassifies a small\nbut finite fraction of the points. We provide a rigorous analysis of the\ngeneralization error of regularized convex classifiers, including ridge, hinge\nand logistic regression, in the high-dimensional limit where the number $n$ of\nsamples and their dimension $d$ go to infinity while their ratio is fixed to\n$\\alpha= n/d$. We discuss surprising effects of the regularization that in some\ncases allows to reach the Bayes-optimal performances. We also illustrate the\ninterpolation peak at low regularization, and analyze the role of the\nrespective sizes of the two clusters.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:54:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mignacco", "Francesca", ""], ["Krzakala", "Florent", ""], ["Lu", "Yue M.", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2002.11545", "submitter": "Yilun Jin", "authors": "Yilun Jin, Xiguang Wei, Yang Liu, Qiang Yang", "title": "Towards Utilizing Unlabeled Data in Federated Learning: A Survey and\n  Prospective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) proposed in recent years has received significant\nattention from researchers in that it can bring separate data sources together\nand build machine learning models in a collaborative but private manner. Yet,\nin most applications of FL, such as keyboard prediction, labeling data requires\nvirtually no additional efforts, which is not generally the case. In reality,\nacquiring large-scale labeled datasets can be extremely costly, which motivates\nresearch works that exploit unlabeled data to help build machine learning\nmodels. However, to the best of our knowledge, few existing works aim to\nutilize unlabeled data to enhance federated learning, which leaves a\npotentially promising research topic. In this paper, we identify the need to\nexploit unlabeled data in FL, and survey possible research fields that can\ncontribute to the goal.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:56:52 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 11:44:11 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Jin", "Yilun", ""], ["Wei", "Xiguang", ""], ["Liu", "Yang", ""], ["Yang", "Qiang", ""]]}, {"id": "2002.11557", "submitter": "David Garc\\'ia-Soriano", "authors": "David Garc\\'ia-Soriano, Konstantin Kutzkov, Francesco Bonchi,\n  Charalampos Tsourakakis", "title": "Query-Efficient Correlation Clustering", "comments": "To appear in WWW 2020", "journal-ref": null, "doi": "10.1145/3366423.3380220", "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlation clustering is arguably the most natural formulation of\nclustering. Given n objects and a pairwise similarity measure, the goal is to\ncluster the objects so that, to the best possible extent, similar objects are\nput in the same cluster and dissimilar objects are put in different clusters.\n  A main drawback of correlation clustering is that it requires as input the\n$\\Theta(n^2)$ pairwise similarities. This is often infeasible to compute or\neven just to store. In this paper we study \\emph{query-efficient} algorithms\nfor correlation clustering. Specifically, we devise a correlation clustering\nalgorithm that, given a budget of $Q$ queries, attains a solution whose\nexpected number of disagreements is at most $3\\cdot OPT + O(\\frac{n^3}{Q})$,\nwhere $OPT$ is the optimal cost for the instance. Its running time is $O(Q)$,\nand can be easily made non-adaptive (meaning it can specify all its queries at\nthe outset and make them in parallel) with the same guarantees. Up to constant\nfactors, our algorithm yields a provably optimal trade-off between the number\nof queries $Q$ and the worst-case error attained, even for adaptive algorithms.\n  Finally, we perform an experimental study of our proposed method on both\nsynthetic and real data, showing the scalability and the accuracy of our\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:18:20 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Garc\u00eda-Soriano", "David", ""], ["Kutzkov", "Konstantin", ""], ["Bonchi", "Francesco", ""], ["Tsourakakis", "Charalampos", ""]]}, {"id": "2002.11559", "submitter": "Sukai Wang", "authors": "Sukai Wang, Yuxiang Sun, Chengju Liu, Ming Liu", "title": "PointTrackNet: An End-to-End Network For 3-D Object Detection and\n  Tracking From Point Clouds", "comments": "7 pages, ICRA-RAL2020 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning-based multi-object tracking (MOT) frameworks are\nbecoming popular for 3-D point clouds. Most traditional tracking approaches use\nfilters (e.g., Kalman filter or particle filter) to predict object locations in\na time sequence, however, they are vulnerable to extreme motion conditions,\nsuch as sudden braking and turning. In this letter, we propose PointTrackNet,\nan end-to-end 3-D object detection and tracking network, to generate foreground\nmasks, 3-D bounding boxes, and point-wise tracking association displacements\nfor each detected object. The network merely takes as input two adjacent\npoint-cloud frames. Experimental results on the KITTI tracking dataset show\ncompetitive results over the state-of-the-arts, especially in the irregularly\nand rapidly changing scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:19:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Wang", "Sukai", ""], ["Sun", "Yuxiang", ""], ["Liu", "Chengju", ""], ["Liu", "Ming", ""]]}, {"id": "2002.11561", "submitter": "Javier Naranjo-Alcazar", "authors": "Javier Naranjo-Alcazar, Sergi Perez-Castanos, Pedro Zuccarrello and\n  Maximo Cobos", "title": "An Open-set Recognition and Few-Shot Learning Dataset for Audio Event\n  Classification in Domestic Environments", "comments": "To be submitted to Expert System with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of training a deep neural network with a small set of positive\nsamples is known as few-shot learning (FSL). It is widely known that\ntraditional deep learning (DL) algorithms usually show very good performance\nwhen trained with large datasets. However, in many applications, it is not\npossible to obtain such a high number of samples. In the image domain, typical\nFSL applications are those related to face recognition. In the audio domain,\nmusic fraud or speaker recognition can be clearly benefited from FSL methods.\nThis paper deals with the application of FSL to the detection of specific and\nintentional acoustic events given by different types of sound alarms, such as\ndoor bells or fire alarms, using a limited number of samples. These sounds\ntypically occur in domestic environments where many events corresponding to a\nwide variety of sound classes take place. Therefore, the detection of such\nalarms in a practical scenario can be considered an open-set recognition (OSR)\nproblem. To address the lack of a dedicated public dataset for audio FSL,\nresearchers usually make modifications on other available datasets. This paper\nis aimed at providing the audio recognition community with a carefully\nannotated dataset for FSL and OSR comprised of 1360 clips from 34 classes\ndivided into pattern sounds and unwanted sounds. To facilitate and promote\nresearch in this area, results with two baseline systems (one trained from\nscratch and another based on transfer learning), are presented.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:26:45 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 14:30:45 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 12:46:34 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 16:17:48 GMT"}, {"version": "v5", "created": "Sat, 14 Mar 2020 14:25:45 GMT"}, {"version": "v6", "created": "Wed, 18 Mar 2020 09:26:51 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Naranjo-Alcazar", "Javier", ""], ["Perez-Castanos", "Sergi", ""], ["Zuccarrello", "Pedro", ""], ["Cobos", "Maximo", ""]]}, {"id": "2002.11564", "submitter": "Rohitkumar Arasanipalai", "authors": "Rohitkumar Arasanipalai, Aakriti Agrawal and Debasish Ghose", "title": "Mid-flight Propeller Failure Detection and Control of\n  Propeller-deficient Quadcopter using Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadcopters can suffer from loss of propellers in mid-flight, thus requiring\na need to have a system that detects single and multiple propeller failures and\nan adaptive controller that stabilizes the propeller-deficient quadcopter. This\npaper presents reinforcement learning based controllers for quadcopters with 4,\n3, and 2 (opposing) functional propellers. The paper also proposes a neural\nnetwork based propeller fault detection system to detect propeller loss and\nswitch to the appropriate controller. The simulation results demonstrate a\nstable quadcopter with efficient waypoint tracking for all controllers. The\ndetection system is able to detect propeller failure in a short time and\nstabilize the quadcopter.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:31:22 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:31:05 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Arasanipalai", "Rohitkumar", ""], ["Agrawal", "Aakriti", ""], ["Ghose", "Debasish", ""]]}, {"id": "2002.11565", "submitter": "Raphael Ettedgui", "authors": "Rafael Pinot, Raphael Ettedgui, Geovani Rizk, Yann Chevaleyre, Jamal\n  Atif", "title": "Randomization matters. How to defend against strong adversarial attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is there a classifier that ensures optimal robustness against all adversarial\nattacks? This paper answers this question by adopting a game-theoretic point of\nview. We show that adversarial attacks and defenses form an infinite zero-sum\ngame where classical results (e.g. Sion theorem) do not apply. We demonstrate\nthe non-existence of a Nash equilibrium in our game when the classifier and the\nAdversary are both deterministic, hence giving a negative answer to the above\nquestion in the deterministic regime. Nonetheless, the question remains open in\nthe randomized regime. We tackle this problem by showing that, undermild\nconditions on the dataset distribution, any deterministic classifier can be\noutperformed by a randomized one. This gives arguments for using randomization,\nand leads us to a new algorithm for building randomized classifiers that are\nrobust to strong adversarial attacks. Empirical results validate our\ntheoretical analysis, and show that our defense method considerably outperforms\nAdversarial Training against state-of-the-art attacks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:31:31 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 11:27:26 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 10:11:46 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 12:52:40 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 12:53:03 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Pinot", "Rafael", ""], ["Ettedgui", "Raphael", ""], ["Rizk", "Geovani", ""], ["Chevaleyre", "Yann", ""], ["Atif", "Jamal", ""]]}, {"id": "2002.11569", "submitter": "Leslie Rice", "authors": "Leslie Rice, Eric Wong, J. Zico Kolter", "title": "Overfitting in adversarially robust deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common practice in deep learning to use overparameterized networks and\ntrain for as long as possible; there are numerous studies that show, both\ntheoretically and empirically, that such practices surprisingly do not unduly\nharm the generalization performance of the classifier. In this paper, we\nempirically study this phenomenon in the setting of adversarially trained deep\nnetworks, which are trained to minimize the loss under worst-case adversarial\nperturbations. We find that overfitting to the training set does in fact harm\nrobust performance to a very large degree in adversarially robust training\nacross multiple datasets (SVHN, CIFAR-10, CIFAR-100, and ImageNet) and\nperturbation models ($\\ell_\\infty$ and $\\ell_2$). Based upon this observed\neffect, we show that the performance gains of virtually all recent algorithmic\nimprovements upon adversarial training can be matched by simply using early\nstopping. We also show that effects such as the double descent curve do still\noccur in adversarially trained models, yet fail to explain the observed\noverfitting. Finally, we study several classical and modern deep learning\nremedies for overfitting, including regularization and data augmentation, and\nfind that no approach in isolation improves significantly upon the gains\nachieved by early stopping. All code for reproducing the experiments as well as\npretrained model weights and training logs can be found at\nhttps://github.com/locuslab/robust_overfitting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:40:50 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 14:33:26 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Rice", "Leslie", ""], ["Wong", "Eric", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2002.11572", "submitter": "Aditya Saligrama", "authors": "Aditya Saligrama and Guillaume Leclerc", "title": "Revisiting Ensembles in an Adversarial Context: Improving Natural\n  Accuracy", "comments": "5 pages, accepted to ICLR 2020 Workshop on Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A necessary characteristic for the deployment of deep learning models in real\nworld applications is resistance to small adversarial perturbations while\nmaintaining accuracy on non-malicious inputs. While robust training provides\nmodels that exhibit better adversarial accuracy than standard models, there is\nstill a significant gap in natural accuracy between robust and non-robust\nmodels which we aim to bridge. We consider a number of ensemble methods\ndesigned to mitigate this performance difference. Our key insight is that model\ntrained to withstand small attacks, when ensembled, can often withstand\nsignificantly larger attacks, and this concept can in turn be leveraged to\noptimize natural accuracy. We consider two schemes, one that combines\npredictions from several randomly initialized robust models, and the other that\nfuses features from robust and standard models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:45:58 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Saligrama", "Aditya", ""], ["Leclerc", "Guillaume", ""]]}, {"id": "2002.11576", "submitter": "Matthew Vowels", "authors": "Matthew J. Vowels, Necati Cihan Camgoz and Richard Bowden", "title": "NestedVAE: Isolating Common Factors via Weak Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair and unbiased machine learning is an important and active field of\nresearch, as decision processes are increasingly driven by models that learn\nfrom data. Unfortunately, any biases present in the data may be learned by the\nmodel, thereby inappropriately transferring that bias into the decision making\nprocess. We identify the connection between the task of bias reduction and that\nof isolating factors common between domains whilst encouraging domain specific\ninvariance. To isolate the common factors we combine the theory of deep latent\nvariable models with information bottleneck theory for scenarios whereby data\nmay be naturally paired across domains and no additional supervision is\nrequired. The result is the Nested Variational AutoEncoder (NestedVAE). Two\nouter VAEs with shared weights attempt to reconstruct the input and infer a\nlatent space, whilst a nested VAE attempts to reconstruct the latent\nrepresentation of one image, from the latent representation of its paired\nimage. In so doing, the nested VAE isolates the common latent factors/causes\nand becomes invariant to unwanted factors that are not shared between paired\nimages. We also propose a new metric to provide a balanced method of evaluating\nconsistency and classifier performance across domains which we refer to as the\nAdjusted Parity metric. An evaluation of NestedVAE on both domain and attribute\ninvariance, change detection, and learning common factors for the prediction of\nbiological sex demonstrates that NestedVAE significantly outperforms\nalternative methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 15:49:57 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Vowels", "Matthew J.", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2002.11582", "submitter": "Yi Zhou", "authors": "Yi Zhou and Zhe Wang and Kaiyi Ji and Yingbin Liang and Vahid Tarokh", "title": "Proximal Gradient Algorithm with Momentum and Flexible Parameter Restart\n  for Nonconvex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various types of parameter restart schemes have been proposed for accelerated\ngradient algorithms to facilitate their practical convergence in convex\noptimization. However, the convergence properties of accelerated gradient\nalgorithms under parameter restart remain obscure in nonconvex optimization. In\nthis paper, we propose a novel accelerated proximal gradient algorithm with\nparameter restart (named APG-restart) for solving nonconvex and nonsmooth\nproblems. Our APG-restart is designed to 1) allow for adopting flexible\nparameter restart schemes that cover many existing ones; 2) have a global\nsub-linear convergence rate in nonconvex and nonsmooth optimization; and 3)\nhave guaranteed convergence to a critical point and have various types of\nasymptotic convergence rates depending on the parameterization of local\ngeometry in nonconvex and nonsmooth optimization. Numerical experiments\ndemonstrate the effectiveness of our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:06:27 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:58:47 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 15:23:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhou", "Yi", ""], ["Wang", "Zhe", ""], ["Ji", "Kaiyi", ""], ["Liang", "Yingbin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2002.11589", "submitter": "Carolyn Kim", "authors": "Carolyn Kim, Mohsen Bayati", "title": "Recommendation on a Budget: Column Space Recovery from Partially\n  Observed Entries with Random or Active Sampling", "comments": "A shorter version is accepted to AISTATS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze alternating minimization for column space recovery of a partially\nobserved, approximately low rank matrix with a growing number of columns and a\nfixed budget of observations per column. In this work, we prove that if the\nbudget is greater than the rank of the matrix, column space recovery succeeds\n-- as the number of columns grows, the estimate from alternating minimization\nconverges to the true column space with probability tending to one. From our\nproof techniques, we naturally formulate an active sampling strategy for\nchoosing entries of a column that is theoretically and empirically (on\nsynthetic and real data) better than the commonly studied uniformly random\nsampling strategy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:17:05 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 00:14:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kim", "Carolyn", ""], ["Bayati", "Mohsen", ""]]}, {"id": "2002.11590", "submitter": "Emilio Leonardi", "authors": "Evgenia Christoforou, Alessandro Nordio, Alberto Tarable, Emilio\n  Leonardi", "title": "Ranking a set of objects: a graph based least-square approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of ranking $N$ objects starting from a set of noisy\npairwise comparisons provided by a crowd of equal workers. We assume that\nobjects are endowed with intrinsic qualities and that the probability with\nwhich an object is preferred to another depends only on the difference between\nthe qualities of the two competitors. We propose a class of non-adaptive\nranking algorithms that rely on a least-squares optimization criterion for the\nestimation of qualities. Such algorithms are shown to be asymptotically optimal\n(i.e., they require $O(\\frac{N}{\\epsilon^2}\\log \\frac{N}{\\delta})$ comparisons\nto be $(\\epsilon, \\delta)$-PAC). Numerical results show that our schemes are\nvery efficient also in many non-asymptotic scenarios exhibiting a performance\nsimilar to the maximum-likelihood algorithm. Moreover, we show how they can be\nextended to adaptive schemes and test them on real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:19:09 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Christoforou", "Evgenia", ""], ["Nordio", "Alessandro", ""], ["Tarable", "Alberto", ""], ["Leonardi", "Emilio", ""]]}, {"id": "2002.11601", "submitter": "Zhao Shen-Yi", "authors": "Shen-Yi Zhao, Yin-Peng Xie, and Wu-Jun Li", "title": "Stagewise Enlargement of Batch Size for SGD-based Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research shows that the batch size can seriously affect the\nperformance of stochastic gradient descent~(SGD) based learning, including\ntraining speed and generalization ability. A larger batch size typically\nresults in less parameter updates. In distributed training, a larger batch size\nalso results in less frequent communication. However, a larger batch size can\nmake a generalization gap more easily. Hence, how to set a proper batch size\nfor SGD has recently attracted much attention. Although some methods about\nsetting batch size have been proposed, the batch size problem has still not\nbeen well solved. In this paper, we first provide theory to show that a proper\nbatch size is related to the gap between initialization and optimum of the\nmodel parameter. Then based on this theory, we propose a novel method, called\n\\underline{s}tagewise \\underline{e}nlargement of \\underline{b}atch\n\\underline{s}ize~(\\mbox{SEBS}), to set proper batch size for SGD. More\nspecifically, \\mbox{SEBS} adopts a multi-stage scheme, and enlarges the batch\nsize geometrically by stage. We theoretically prove that, compared to classical\nstagewise SGD which decreases learning rate by stage, \\mbox{SEBS} can reduce\nthe number of parameter updates without increasing generalization error. SEBS\nis suitable for \\mbox{SGD}, momentum \\mbox{SGD} and AdaGrad. Empirical results\non real data successfully verify the theories of \\mbox{SEBS}. Furthermore,\nempirical results also show that SEBS can outperform other baselines.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:40:31 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 03:13:52 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhao", "Shen-Yi", ""], ["Xie", "Yin-Peng", ""], ["Li", "Wu-Jun", ""]]}, {"id": "2002.11603", "submitter": "Frederik Harder", "authors": "Frederik Harder, Kamil Adamczewski, Mijung Park", "title": "DP-MERF: Differentially Private Mean Embeddings with Random Features for\n  Practical Privacy-Preserving Data Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a differentially private data generation paradigm using random\nfeature representations of kernel mean embeddings when comparing the\ndistribution of true data with that of synthetic data. We exploit the random\nfeature representations for two important benefits. First, we require a minimal\nprivacy cost for training deep generative models. This is because unlike\nkernel-based distance metrics that require computing the kernel matrix on all\npairs of true and synthetic data points, we can detach the data-dependent term\nfrom the term solely dependent on synthetic data. Hence, we need to perturb the\ndata-dependent term only once and then use it repeatedly during the generator\ntraining. Second, we can obtain an analytic sensitivity of the kernel mean\nembedding as the random features are norm bounded by construction. This removes\nthe necessity of hyper-parameter search for a clipping norm to handle the\nunknown sensitivity of a generator network. We provide several variants of our\nalgorithm, differentially-private mean embeddings with random features\n(DP-MERF) to jointly generate labels and input features for datasets such as\nheterogeneous tabular data and image data. Our algorithm achieves drastically\nbetter privacy-utility trade-offs than existing methods when tested on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:41:41 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 22:45:06 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 16:32:31 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 08:59:13 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2021 14:38:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Harder", "Frederik", ""], ["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "2002.11609", "submitter": "Jiahao Su", "authors": "Jiahao Su, Shiqi Wang, Furong Huang", "title": "ARMA Nets: Expanding Receptive Field for Dense Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global information is essential for dense prediction problems, whose goal is\nto compute a discrete or continuous label for each pixel in the images.\nTraditional convolutional layers in neural networks, initially designed for\nimage classification, are restrictive in these problems since the filter size\nlimits their receptive fields. In this work, we propose to replace any\ntraditional convolutional layer with an autoregressive moving-average (ARMA)\nlayer, a novel module with an adjustable receptive field controlled by the\nlearnable autoregressive coefficients. Compared with traditional convolutional\nlayers, our ARMA layer enables explicit interconnections of the output neurons\nand learns its receptive field by adapting the autoregressive coefficients of\nthe interconnections. ARMA layer is adjustable to different types of tasks: for\ntasks where global information is crucial, it is capable of learning relatively\nlarge autoregressive coefficients to allow for an output neuron's receptive\nfield covering the entire input; for tasks where only local information is\nrequired, it can learn small or near zero autoregressive coefficients and\nautomatically reduces to a traditional convolutional layer. We show both\ntheoretically and empirically that the effective receptive field of networks\nwith ARMA layers (named as ARMA networks) expands with larger autoregressive\ncoefficients. We also provably solve the instability problem of learning and\nprediction in the ARMA layer through a re-parameterization mechanism.\nAdditionally, we demonstrate that ARMA networks substantially improve their\nbaselines on challenging dense prediction tasks including video prediction and\nsemantic segmentation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 23:18:27 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 04:12:39 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Su", "Jiahao", ""], ["Wang", "Shiqi", ""], ["Huang", "Furong", ""]]}, {"id": "2002.11611", "submitter": "Eren Sezener", "authors": "Eren Sezener, Marcus Hutter, David Budden, Jianan Wang, Joel Veness", "title": "Online Learning in Contextual Bandits using Gated Linear Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new and completely online contextual bandit algorithm called\nGated Linear Contextual Bandits (GLCB). This algorithm is based on Gated Linear\nNetworks (GLNs), a recently introduced deep learning architecture with\nproperties well-suited to the online setting. Leveraging data-dependent gating\nproperties of the GLN we are able to estimate prediction uncertainty with\neffectively zero algorithmic overhead. We empirically evaluate GLCB compared to\n9 state-of-the-art algorithms that leverage deep neural networks, on a standard\nbenchmark suite of discrete and continuous contextual bandit problems. GLCB\nobtains median first-place despite being the only online method, and we further\nsupport these results with a theoretical study of its convergence properties.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 11:50:43 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 09:38:19 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Sezener", "Eren", ""], ["Hutter", "Marcus", ""], ["Budden", "David", ""], ["Wang", "Jianan", ""], ["Veness", "Joel", ""]]}, {"id": "2002.11613", "submitter": "Lovedeep Gondara", "authors": "Lovedeep Gondara, Ke Wang, Ricardo Silva Carvalho", "title": "The Differentially Private Lottery Ticket Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the differentially private lottery ticket mechanism (DPLTM). An\nend-to-end differentially private training paradigm based on the lottery ticket\nhypothesis. Using \"high-quality winners\", selected via our custom score\nfunction, DPLTM significantly improves the privacy-utility trade-off over the\nstate-of-the-art. We show that DPLTM converges faster, allowing for early\nstopping with reduced privacy budget consumption. We further show that the\ntickets from DPLTM are transferable across datasets, domains, and\narchitectures. Our extensive evaluation on several public datasets provides\nevidence to our claims.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 06:15:54 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Gondara", "Lovedeep", ""], ["Wang", "Ke", ""], ["Carvalho", "Ricardo Silva", ""]]}, {"id": "2002.11621", "submitter": "Adriano Fazzone", "authors": "Giorgio Barnab\\`o and Adriano Fazzone and Stefano Leonardi and Chris\n  Schwiegelshohn", "title": "Algorithms for Fair Team Formation in Online Labour Marketplaces", "comments": "Accepted at \"FATES 2019 : 1st Workshop on Fairness, Accountability,\n  Transparency, Ethics, and Society on the Web\" (http://fates19.isti.cnr.it)", "journal-ref": "\"Companion Proceedings of The 2019 World Wide Web Conference\",\n  2019, pages 484-490", "doi": "10.1145/3308560.3317587", "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As freelancing work keeps on growing almost everywhere due to a sharp\ndecrease in communication costs and to the widespread of Internet-based labour\nmarketplaces (e.g., guru.com, feelancer.com, mturk.com, upwork.com), many\nresearchers and practitioners have started exploring the benefits of\noutsourcing and crowdsourcing. Since employers often use these platforms to\nfind a group of workers to complete a specific task, researchers have focused\ntheir efforts on the study of team formation and matching algorithms and on the\ndesign of effective incentive schemes. Nevertheless, just recently, several\nconcerns have been raised on possibly unfair biases introduced through the\nalgorithms used to carry out these selection and matching procedures. For this\nreason, researchers have started studying the fairness of algorithms related to\nthese online marketplaces, looking for intelligent ways to overcome the\nalgorithmic bias that frequently arises. Broadly speaking, the aim is to\nguarantee that, for example, the process of hiring workers through the use of\nmachine learning and algorithmic data analysis tools does not discriminate,\neven unintentionally, on grounds of nationality or gender. In this short paper,\nwe define the Fair Team Formation problem in the following way: given an online\nlabour marketplace where each worker possesses one or more skills, and where\nall workers are divided into two or more not overlapping classes (for examples,\nmen and women), we want to design an algorithm that is able to find a team with\nall the skills needed to complete a given task, and that has the same number of\npeople from all classes. We provide inapproximability results for the Fair Team\nFormation problem together with four algorithms for the problem itself. We also\ntested the effectiveness of our algorithmic solutions by performing experiments\nusing real data from an online labor marketplace.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:33:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Barnab\u00f2", "Giorgio", ""], ["Fazzone", "Adriano", ""], ["Leonardi", "Stefano", ""], ["Schwiegelshohn", "Chris", ""]]}, {"id": "2002.11624", "submitter": "Byungsoo Kim", "authors": "Youngnam Lee, Dongmin Shin, HyunBin Loh, Jaemin Lee, Piljae Chae,\n  Junghyun Cho, Seoyon Park, Jinhwan Lee, Jineon Baek, Byungsoo Kim, Youngduck\n  Choi", "title": "Deep Attentive Study Session Dropout Prediction in Mobile Learning\n  Environment", "comments": "CSEDU 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student dropout prediction provides an opportunity to improve student\nengagement, which maximizes the overall effectiveness of learning experiences.\nHowever, researches on student dropout were mainly conducted on school dropout\nor course dropout, and study session dropout in a mobile learning environment\nhas not been considered thoroughly. In this paper, we investigate the study\nsession dropout prediction problem in a mobile learning environment. First, we\ndefine the concept of the study session, study session dropout and study\nsession dropout prediction task in a mobile learning environment. Based on the\ndefinitions, we propose a novel Transformer based model for predicting study\nsession dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile\nLearning Environment. DAS has an encoder-decoder structure which is composed of\nstacked multi-head attention and point-wise feed-forward networks. The deep\nattentive computations in DAS are capable of capturing complex relations among\ndynamic student interactions. To the best of our knowledge, this is the first\nattempt to investigate study session dropout in a mobile learning environment.\nEmpirical evaluations on a large-scale dataset show that DAS achieves the best\nperformance with a significant improvement in area under the receiver operating\ncharacteristic curve compared to baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:05:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:35:20 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:54:26 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 01:27:49 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 04:59:06 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lee", "Youngnam", ""], ["Shin", "Dongmin", ""], ["Loh", "HyunBin", ""], ["Lee", "Jaemin", ""], ["Chae", "Piljae", ""], ["Cho", "Junghyun", ""], ["Park", "Seoyon", ""], ["Lee", "Jinhwan", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Choi", "Youngduck", ""]]}, {"id": "2002.11631", "submitter": "Zhenyu Zhao", "authors": "Huigang Chen, Totte Harinen, Jeong-Yoon Lee, Mike Yung, Zhenyu Zhao", "title": "CausalML: Python Package for Causal Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CausalML is a Python implementation of algorithms related to causal inference\nand machine learning. Algorithms combining causal inference and machine\nlearning have been a trending topic in recent years. This package tries to\nbridge the gap between theoretical work on methodology and practical\napplications by making a collection of methods in this field available in\nPython. This paper introduces the key concepts, scope, and use cases of this\npackage.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:35:33 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 18:34:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Huigang", ""], ["Harinen", "Totte", ""], ["Lee", "Jeong-Yoon", ""], ["Yung", "Mike", ""], ["Zhao", "Zhenyu", ""]]}, {"id": "2002.11635", "submitter": "Manuel Kaspar", "authors": "Manuel Kaspar, Juan David Munoz Osorio, J\\\"urgen Bock", "title": "Sim2Real Transfer for Reinforcement Learning without Dynamics\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show how to use the Operational Space Control framework (OSC)\nunder joint and cartesian constraints for reinforcement learning in cartesian\nspace. Our method is therefore able to learn fast and with adjustable degrees\nof freedom, while we are able to transfer policies without additional dynamics\nrandomizations on a KUKA LBR iiwa peg in-hole task. Before learning in\nsimulation starts, we perform a system identification for aligning the\nsimulation environment as far as possible with the dynamics of a real robot.\nAdding constraints to the OSC controller allows us to learn in a safe way on\nthe real robot or to learn a flexible, goal conditioned policy that can be\neasily transferred from simulation to the real robot.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:10:21 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Kaspar", "Manuel", ""], ["Osorio", "Juan David Munoz", ""], ["Bock", "J\u00fcrgen", ""]]}, {"id": "2002.11637", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Vikas Dhiman, Nikolay Atanasov", "title": "Learning Navigation Costs from Demonstration in Partially Observable\n  Environments", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on inverse reinforcement learning (IRL) to enable safe and\nefficient autonomous navigation in unknown partially observable environments.\nThe objective is to infer a cost function that explains expert-demonstrated\nnavigation behavior while relying only on the observations and state-control\ntrajectory used by the expert. We develop a cost function representation\ncomposed of two parts: a probabilistic occupancy encoder, with recurrent\ndependence on the observation sequence, and a cost encoder, defined over the\noccupancy features. The representation parameters are optimized by\ndifferentiating the error between demonstrated controls and a control policy\ncomputed from the cost encoder. Such differentiation is typically computed by\ndynamic programming through the value function over the whole state space. We\nobserve that this is inefficient in large partially observable environments\nbecause most states are unexplored. Instead, we rely on a closed-form\nsubgradient of the cost-to-go obtained only over a subset of promising states\nvia an efficient motion-planning algorithm such as A* or RRT. Our experiments\nshow that our model exceeds the accuracy of baseline IRL algorithms in robot\nnavigation tasks, while substantially improving the efficiency of training and\ntest-time inference.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:15:10 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Wang", "Tianyu", ""], ["Dhiman", "Vikas", ""], ["Atanasov", "Nikolay", ""]]}, {"id": "2002.11642", "submitter": "Masahiro Kato", "authors": "Masahiro Kato, Masatoshi Uehara, Shota Yasui", "title": "Off-Policy Evaluation and Learning for External Validity under a\n  Covariate Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider evaluating and training a new policy for the evaluation data by\nusing the historical data obtained from a different policy. The goal of\noff-policy evaluation (OPE) is to estimate the expected reward of a new policy\nover the evaluation data, and that of off-policy learning (OPL) is to find a\nnew policy that maximizes the expected reward over the evaluation data.\nAlthough the standard OPE and OPL assume the same distribution of covariate\nbetween the historical and evaluation data, a covariate shift often exists,\ni.e., the distribution of the covariate of the historical data is different\nfrom that of the evaluation data. In this paper, we derive the efficiency bound\nof OPE under a covariate shift. Then, we propose doubly robust and efficient\nestimators for OPE and OPL under a covariate shift by using a nonparametric\nestimator of the density ratio between the historical and evaluation data\ndistributions. We also discuss other possible estimators and compare their\ntheoretical properties. Finally, we confirm the effectiveness of the proposed\nestimators through experiments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:18:43 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 17:48:31 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 01:40:41 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kato", "Masahiro", ""], ["Uehara", "Masatoshi", ""], ["Yasui", "Shota", ""]]}, {"id": "2002.11650", "submitter": "Chara Podimata", "authors": "Akshay Krishnamurthy, Thodoris Lykouris, Chara Podimata, and Robert\n  Schapire", "title": "Contextual Search in the Presence of Irrational Agents", "comments": "Compared to the first version titled \"Corrupted Multidimensional\n  Binary Search: Learning in the Presence of Irrational Agents\", this version\n  provides a broader scope of behavioral models of irrationality, specifies how\n  the results apply to different loss functions, and discusses the power and\n  limitations of additional algorithmic approaches", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.GT econ.GN q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study contextual search, a generalization of binary search in higher\ndimensions, which captures settings such as feature-based dynamic pricing.\nStandard game-theoretic formulations of this problem assume that agents act in\naccordance with a specific behavioral model. In practice, however, some agents\nmay not prescribe to the dominant behavioral model or may act in ways that are\nseemingly arbitrarily irrational. Existing algorithms heavily depend on the\nbehavioral model being (approximately) accurate for all agents and have poor\nperformance in the presence of even a few such arbitrarily irrational agents.\n  We initiate the study of contextual search when some of the agents can behave\nin ways inconsistent with the underlying behavioral model. In particular, we\nprovide two algorithms, one built on robustifying multidimensional binary\nsearch methods and one on translating the setting to a proxy setting\nappropriate for gradient descent. Our techniques draw inspiration from learning\ntheory, game theory, high-dimensional geometry, and convex analysis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:25:53 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 16:16:00 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 17:26:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Krishnamurthy", "Akshay", ""], ["Lykouris", "Thodoris", ""], ["Podimata", "Chara", ""], ["Schapire", "Robert", ""]]}, {"id": "2002.11651", "submitter": "Hussein Mozannar", "authors": "Hussein Mozannar, Mesrob I. Ohannessian, Nathan Srebro", "title": "Fair Learning with Private Demographic Data", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive attributes such as race are rarely available to learners in real\nworld settings as their collection is often restricted by laws and regulations.\nWe give a scheme that allows individuals to release their sensitive information\nprivately while still allowing any downstream entity to learn\nnon-discriminatory predictors. We show how to adapt non-discriminatory learners\nto work with privatized protected attributes giving theoretical guarantees on\nperformance. Finally, we highlight how the methodology could apply to learning\nfair predictors in settings where protected attributes are only available for a\nsubset of the data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:26:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:48:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mozannar", "Hussein", ""], ["Ohannessian", "Mesrob I.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.11661", "submitter": "Sebastian Macaluso", "authors": "Craig S. Greenberg, Sebastian Macaluso, Nicholas Monath, Ji-Ah Lee,\n  Patrick Flaherty, Kyle Cranmer, Andrew McGregor, Andrew McCallum", "title": "Data Structures & Algorithms for Exact Inference in Hierarchical\n  Clustering", "comments": "27 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a fundamental task often used to discover\nmeaningful structures in data, such as phylogenetic trees, taxonomies of\nconcepts, subtypes of cancer, and cascades of particle decays in particle\nphysics. Typically approximate algorithms are used for inference due to the\ncombinatorial number of possible hierarchical clusterings. In contrast to\nexisting methods, we present novel dynamic-programming algorithms for\n\\emph{exact} inference in hierarchical clustering based on a novel trellis data\nstructure, and we prove that we can exactly compute the partition function,\nmaximum likelihood hierarchy, and marginal probabilities of sub-hierarchies and\nclusters. Our algorithms scale in time and space proportional to the powerset\nof $N$ elements which is super-exponentially more efficient than explicitly\nconsidering each of the (2N-3)!! possible hierarchies. Also, for larger\ndatasets where our exact algorithms become infeasible, we introduce an\napproximate algorithm based on a sparse trellis that compares well to other\nbenchmarks. Exact methods are relevant to data analyses in particle physics and\nfor finding correlations among gene expression in cancer genomics, and we give\nexamples in both areas, where our algorithms outperform greedy and beam search\nbaselines. In addition, we consider Dasgupta's cost with synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:43:53 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 16:19:28 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 15:18:02 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Greenberg", "Craig S.", ""], ["Macaluso", "Sebastian", ""], ["Monath", "Nicholas", ""], ["Lee", "Ji-Ah", ""], ["Flaherty", "Patrick", ""], ["Cranmer", "Kyle", ""], ["McGregor", "Andrew", ""], ["McCallum", "Andrew", ""]]}, {"id": "2002.11665", "submitter": "Yi Hao", "authors": "Yi Hao, Alon Orlitsky", "title": "Profile Entropy: A Fundamental Measure for the Learnability and\n  Compressibility of Discrete Distributions", "comments": "56 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The profile of a sample is the multiset of its symbol frequencies. We show\nthat for samples of discrete distributions, profile entropy is a fundamental\nmeasure unifying the concepts of estimation, inference, and compression.\nSpecifically, profile entropy a) determines the speed of estimating the\ndistribution relative to the best natural estimator; b) characterizes the rate\nof inferring all symmetric properties compared with the best estimator over any\nlabel-invariant distribution collection; c) serves as the limit of profile\ncompression, for which we derive optimal near-linear-time block and sequential\nalgorithms. To further our understanding of profile entropy, we investigate its\nattributes, provide algorithms for approximating its value, and determine its\nmagnitude for numerous structural distribution families.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:49:04 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Hao", "Yi", ""], ["Orlitsky", "Alon", ""]]}, {"id": "2002.11669", "submitter": "Fanta Camara", "authors": "Fanta Camara, Nicola Bellotto, Serhan Cosar, Dimitris Nathanael,\n  Matthias Althoff, Jingyuan Wu, Johannes Ruenz, Andr\\'e Dietrich and Charles\n  W. Fox", "title": "Pedestrian Models for Autonomous Driving Part I: Low-Level Models, from\n  Sensing to Tracking", "comments": "Accepted for publication in the IEEE Transactions on Intelligent\n  Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.3006768", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles (AVs) must share space with pedestrians, both in\ncarriageway cases such as cars at pedestrian crossings and off-carriageway\ncases such as delivery vehicles navigating through crowds on pedestrianized\nhigh-streets. Unlike static obstacles, pedestrians are active agents with\ncomplex, interactive motions. Planning AV actions in the presence of\npedestrians thus requires modelling of their probable future behaviour as well\nas detecting and tracking them. This narrative review article is Part I of a\npair, together surveying the current technology stack involved in this process,\norganising recent research into a hierarchical taxonomy ranging from low-level\nimage detection to high-level psychology models, from the perspective of an AV\ndesigner. This self-contained Part I covers the lower levels of this stack,\nfrom sensing, through detection and recognition, up to tracking of pedestrians.\nTechnologies at these levels are found to be mature and available as\nfoundations for use in high-level systems, such as behaviour modelling,\nprediction and interaction control.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:57:42 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 14:42:27 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Camara", "Fanta", ""], ["Bellotto", "Nicola", ""], ["Cosar", "Serhan", ""], ["Nathanael", "Dimitris", ""], ["Althoff", "Matthias", ""], ["Wu", "Jingyuan", ""], ["Ruenz", "Johannes", ""], ["Dietrich", "Andr\u00e9", ""], ["Fox", "Charles W.", ""]]}, {"id": "2002.11670", "submitter": "Sylvain Peyronnet", "authors": "Ilyes Kacher and Maxime Portaz and Hicham Randrianarivo and Sylvain\n  Peyronnet", "title": "Graphcore C2 Card performance for image-based deep learning application:\n  A Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Graphcore has introduced an IPU Processor for accelerating machine\nlearning applications. The architecture of the processor has been designed to\nachieve state of the art performance on current machine intelligence models for\nboth training and inference.\n  In this paper, we report on a benchmark in which we have evaluated the\nperformance of IPU processors on deep neural networks for inference. We focus\non deep vision models such as ResNeXt. We report the observed latency,\nthroughput and energy efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:58:24 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 22:17:19 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Kacher", "Ilyes", ""], ["Portaz", "Maxime", ""], ["Randrianarivo", "Hicham", ""], ["Peyronnet", "Sylvain", ""]]}, {"id": "2002.11675", "submitter": "Fabrizio Albertetti", "authors": "Fabrizio Albertetti, Hatem Ghorbel", "title": "Workload Prediction of Business Processes -- An Approach Based on\n  Process Mining and Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the interconnectedness and digitization of industrial\nmachines, known as Industry 4.0, pave the way for new analytical techniques.\nIndeed, the availability and the richness of production-related data enables\nnew data-driven methods. In this paper, we propose a process mining approach\naugmented with artificial intelligence that (1) reconstructs the historical\nworkload of a company and (2) predicts the workload using neural networks. Our\nmethod relies on logs, representing the history of business processes related\nto manufacturing. These logs are used to quantify the supply and demand and are\nfed into a recurrent neural network model to predict customer orders. The\ncorresponding activities to fulfill these orders are then sampled from history\nwith a replay mechanism, based on criteria such as trace frequency and\nactivities similarity. An evaluation and illustration of the method is\nperformed on the administrative processes of Heraeus Materials SA. The workload\nprediction on a one-year test set achieves an MAPE score of 19% for a one-week\nforecast. The case study suggests a reasonable accuracy and confirms that a\ngood understanding of the historical workload combined to articulated\npredictions are of great help for supporting management decisions and can\ndecrease costs with better resources planning on a medium-term level.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 08:19:23 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Albertetti", "Fabrizio", ""], ["Ghorbel", "Hatem", ""]]}, {"id": "2002.11684", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Chi Jin, Michael I. Jordan", "title": "Provable Meta-Learning of Linear Representations", "comments": "Lower bound slightly improved to include task diversity parameter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning, or learning-to-learn, seeks to design algorithms that can\nutilize previous experience to rapidly learn new skills or adapt to new\nenvironments. Representation learning -- a key tool for performing\nmeta-learning -- learns a data representation that can transfer knowledge\nacross multiple tasks, which is essential in regimes where data is scarce.\nDespite a recent surge of interest in the practice of meta-learning, the\ntheoretical underpinnings of meta-learning algorithms are lacking, especially\nin the context of learning transferable representations. In this paper, we\nfocus on the problem of multi-task linear regression -- in which multiple\nlinear regression models share a common, low-dimensional linear representation.\nHere, we provide provably fast, sample-efficient algorithms to address the dual\nchallenges of (1) learning a common set of features from multiple, related\ntasks, and (2) transferring this knowledge to new, unseen tasks. Both are\ncentral to the general problem of meta-learning. Finally, we complement these\nresults by providing information-theoretic lower bounds on the sample\ncomplexity of learning these linear features.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:21:34 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 20:40:37 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 22:20:33 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 22:15:30 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Jin", "Chi", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2002.11686", "submitter": "Jaidip Kotak", "authors": "Jaidip Kotak and Yuval Elovici", "title": "IoT Device Identification Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-57805-3_8", "report-no": null, "categories": "cs.CR cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing use of IoT devices in organizations has increased the number of\nattack vectors available to attackers due to the less secure nature of the\ndevices. The widely adopted bring your own device (BYOD) policy which allows an\nemployee to bring any IoT device into the workplace and attach it to an\norganization's network also increases the risk of attacks. In order to address\nthis threat, organizations often implement security policies in which only the\nconnection of white-listed IoT devices is permitted. To monitor adherence to\nsuch policies and protect their networks, organizations must be able to\nidentify the IoT devices connected to their networks and, more specifically, to\nidentify connected IoT devices that are not on the white-list (unknown\ndevices). In this study, we applied deep learning on network traffic to\nautomatically identify IoT devices connected to the network. In contrast to\nprevious work, our approach does not require that complex feature engineering\nbe applied on the network traffic, since we represent the communication\nbehavior of IoT devices using small images built from the IoT devices network\ntraffic payloads. In our experiments, we trained a multiclass classifier on a\npublicly available dataset, successfully identifying 10 different IoT devices\nand the traffic of smartphones and computers, with over 99% accuracy. We also\ntrained multiclass classifiers to detect unauthorized IoT devices connected to\nthe network, achieving over 99% overall average detection accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 12:24:49 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kotak", "Jaidip", ""], ["Elovici", "Yuval", ""]]}, {"id": "2002.11701", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Cao Xiao, Lucas M. Glass, M. Brandon Westover, and\n  Jimeng Sun", "title": "CLARA: Clinical Report Auto-completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating clinical reports from raw recordings such as X-rays and\nelectroencephalogram (EEG) is an essential and routine task for doctors.\nHowever, it is often time-consuming to write accurate and detailed reports.\nMost existing methods try to generate the whole reports from the raw input with\nlimited success because 1) generated reports often contain errors that need\nmanual review and correction, 2) it does not save time when doctors want to\nwrite additional information into the report, and 3) the generated reports are\nnot customized based on individual doctors' preference. We propose {\\it\nCL}inic{\\it A}l {\\it R}eport {\\it A}uto-completion (CLARA), an interactive\nmethod that generates reports in a sentence by sentence fashion based on\ndoctors' anchor words and partially completed sentences. CLARA searches for\nmost relevant sentences from existing reports as the template for the current\nreport. The retrieved sentences are sequentially modified by combining with the\ninput feature representations to create the final report. In our experimental\nevaluation, CLARA achieved 0.393 CIDEr and 0.248 BLEU-4 on X-ray reports and\n0.482 CIDEr and 0.491 BLEU-4 for EEG reports for sentence-level generation,\nwhich is up to 35% improvement over the best baseline. Also via our qualitative\nevaluation, CLARA is shown to produce reports which have a significantly higher\nlevel of approval by doctors in a user study (3.74 out of 5 for CLARA vs 2.52\nout of 5 for the baseline).\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:45:00 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:32:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Biswal", "Siddharth", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Westover", "M. Brandon", ""], ["Sun", "Jimeng", ""]]}, {"id": "2002.11705", "submitter": "Aris Anagnostopoulos", "authors": "Tesi Aliaj and Aris Anagnostopoulos and Stefano Piersanti", "title": "Firms Default Prediction with Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academics and practitioners have studied over the years models for predicting\nfirms bankruptcy, using statistical and machine-learning approaches. An earlier\nsign that a company has financial difficulties and may eventually bankrupt is\ngoing in \\emph{default}, which, loosely speaking means that the company has\nbeen having difficulties in repaying its loans towards the banking system.\nFirms default status is not technically a failure but is very relevant for bank\nlending policies and often anticipates the failure of the company. Our study\nuses, for the first time according to our knowledge, a very large database of\ngranular credit data from the Italian Central Credit Register of Bank of Italy\nthat contain information on all Italian companies' past behavior towards the\nentire Italian banking system to predict their default using machine-learning\ntechniques. Furthermore, we combine these data with other information regarding\ncompanies' public balance sheet data. We find that ensemble techniques and\nrandom forest provide the best results, corroborating the findings of Barboza\net al. (Expert Syst. Appl., 2017).\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 10:09:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Aliaj", "Tesi", ""], ["Anagnostopoulos", "Aris", ""], ["Piersanti", "Stefano", ""]]}, {"id": "2002.11708", "submitter": "Alexander Li", "authors": "Alexander C. Li, Lerrel Pinto, Pieter Abbeel", "title": "Generalized Hindsight for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key reasons for the high sample complexity in reinforcement\nlearning (RL) is the inability to transfer knowledge from one task to another.\nIn standard multi-task RL settings, low-reward data collected while trying to\nsolve one task provides little to no signal for solving that particular task\nand is hence effectively wasted. However, we argue that this data, which is\nuninformative for one task, is likely a rich source of information for other\ntasks. To leverage this insight and efficiently reuse data, we present\nGeneralized Hindsight: an approximate inverse reinforcement learning technique\nfor relabeling behaviors with the right tasks. Intuitively, given a behavior\ngenerated under one task, Generalized Hindsight returns a different task that\nthe behavior is better suited for. Then, the behavior is relabeled with this\nnew task before being used by an off-policy RL optimizer. Compared to standard\nrelabeling techniques, Generalized Hindsight provides a substantially more\nefficient reuse of samples, which we empirically demonstrate on a suite of\nmulti-task navigation and manipulation tasks. Videos and code can be accessed\nhere: https://sites.google.com/view/generalized-hindsight.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:57:05 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Li", "Alexander C.", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2002.11711", "submitter": "Yuan Liu Prof.", "authors": "Yuan Liu, Shuai Sun, Zhengpeng Ai, Shuangfeng Zhang, Zelei Liu, Han Yu", "title": "FedCoin: A Peer-to-Peer Payment System for Federated Learning", "comments": "7 pages, 6 figures,21 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Federated learning (FL) is an emerging collaborative machine learning method\nto train models on distributed datasets with privacy concerns. To properly\nincentivize data owners to contribute their efforts, Shapley Value (SV) is\noften adopted to fairly assess their contribution. However, the calculation of\nSV is time-consuming and computationally costly. In this paper, we propose\nFedCoin, a blockchain-based peer-to-peer payment system for FL to enable a\nfeasible SV based profit distribution. In FedCoin, blockchain consensus\nentities calculate SVs and a new block is created based on the proof of Shapley\n(PoSap) protocol. It is in contrast to the popular BitCoin network where\nconsensus entities \"mine\" new blocks by solving meaningless puzzles. Based on\nthe computed SVs, a scheme for dividing the incentive payoffs among FL clients\nwith nonrepudiation and tamper-resistance properties is proposed. Experimental\nresults based on real-world data show that FedCoin can promote high-quality\ndata from FL clients through accurately computing SVs with an upper bound on\nthe computational resources required for reaching consensus. It opens\nopportunities for non-data owners to play a role in FL.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 03:43:48 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Yuan", ""], ["Sun", "Shuai", ""], ["Ai", "Zhengpeng", ""], ["Zhang", "Shuangfeng", ""], ["Liu", "Zelei", ""], ["Yu", "Han", ""]]}, {"id": "2002.11743", "submitter": "Jay Whang", "authors": "Jay Whang, Erik M. Lindgren, Alexandros G. Dimakis", "title": "Composing Normalizing Flows for Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an inverse problem with a normalizing flow prior, we wish to estimate\nthe distribution of the underlying signal conditioned on the observations. We\napproach this problem as a task of conditional inference on the pre-trained\nunconditional flow model. We first establish that this is computationally hard\nfor a large class of flow models. Motivated by this, we propose a framework for\napproximate inference that estimates the target conditional as a composition of\ntwo flow models. This formulation leads to a stable variational inference\ntraining procedure that avoids adversarial training. Our method is evaluated on\na variety of inverse problems and is shown to produce high-quality samples with\nuncertainty quantification. We further demonstrate that our approach can be\namortized for zero-shot inference.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 19:01:11 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 05:06:00 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 18:00:48 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Whang", "Jay", ""], ["Lindgren", "Erik M.", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "2002.11750", "submitter": "Binghui Wang", "authors": "Binghui Wang, Xiaoyu Cao, Jinyuan jia, and Neil Zhenqiang Gong", "title": "On Certifying Robustness against Backdoor Attacks via Randomized\n  Smoothing", "comments": "CVPR 2020 Workshop on Adversarial Machine Learning in Computer\n  Vision, 2020. DeepMind Best Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack is a severe security threat to deep neural networks (DNNs).\nWe envision that, like adversarial examples, there will be a cat-and-mouse game\nfor backdoor attacks, i.e., new empirical defenses are developed to defend\nagainst backdoor attacks but they are soon broken by strong adaptive backdoor\nattacks. To prevent such cat-and-mouse game, we take the first step towards\ncertified defenses against backdoor attacks. Specifically, in this work, we\nstudy the feasibility and effectiveness of certifying robustness against\nbackdoor attacks using a recent technique called randomized smoothing.\nRandomized smoothing was originally developed to certify robustness against\nadversarial examples. We generalize randomized smoothing to defend against\nbackdoor attacks. Our results show the theoretical feasibility of using\nrandomized smoothing to certify robustness against backdoor attacks. However,\nwe also find that existing randomized smoothing methods have limited\neffectiveness at defending against backdoor attacks, which highlight the needs\nof new theory and methods to certify robustness against backdoor attacks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 19:15:46 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 18:53:12 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 13:02:37 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 16:15:42 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Wang", "Binghui", ""], ["Cao", "Xiaoyu", ""], ["jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2002.11770", "submitter": "Hao Li", "authors": "Hao Li, Pratik Chaudhari, Hao Yang, Michael Lam, Avinash Ravichandran,\n  Rahul Bhotika, Stefano Soatto", "title": "Rethinking the Hyperparameters for Fine-tuning", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning from pre-trained ImageNet models has become the de-facto standard\nfor various computer vision tasks. Current practices for fine-tuning typically\ninvolve selecting an ad-hoc choice of hyperparameters and keeping them fixed to\nvalues normally used for training from scratch. This paper re-examines several\ncommon practices of setting hyperparameters for fine-tuning. Our findings are\nbased on extensive empirical evaluation for fine-tuning on various transfer\nlearning benchmarks. (1) While prior works have thoroughly investigated\nlearning rate and batch size, momentum for fine-tuning is a relatively\nunexplored parameter. We find that the value of momentum also affects\nfine-tuning performance and connect it with previous theoretical findings. (2)\nOptimal hyperparameters for fine-tuning, in particular, the effective learning\nrate, are not only dataset dependent but also sensitive to the similarity\nbetween the source domain and target domain. This is in contrast to\nhyperparameters for training from scratch. (3) Reference-based regularization\nthat keeps models close to the initial model does not necessarily apply for\n\"dissimilar\" datasets. Our findings challenge common practices of fine-tuning\nand encourages deep learning practitioners to rethink the hyperparameters for\nfine-tuning.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 18:59:52 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Li", "Hao", ""], ["Chaudhari", "Pratik", ""], ["Yang", "Hao", ""], ["Lam", "Michael", ""], ["Ravichandran", "Avinash", ""], ["Bhotika", "Rahul", ""], ["Soatto", "Stefano", ""]]}, {"id": "2002.11787", "submitter": "Yucheng Lu", "authors": "Yucheng Lu and Christopher De Sa", "title": "Moniqua: Modulo Quantized Communication in Decentralized SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running Stochastic Gradient Descent (SGD) in a decentralized fashion has\nshown promising results. In this paper we propose Moniqua, a technique that\nallows decentralized SGD to use quantized communication. We prove in theory\nthat Moniqua communicates a provably bounded number of bits per iteration,\nwhile converging at the same asymptotic rate as the original algorithm does\nwith full-precision communication. Moniqua improves upon prior works in that it\n(1) requires zero additional memory, (2) works with 1-bit quantization, and (3)\nis applicable to a variety of decentralized algorithms. We demonstrate\nempirically that Moniqua converges faster with respect to wall clock time than\nother quantized decentralized algorithms. We also show that Moniqua is robust\nto very low bit-budgets, allowing 1-bit-per-parameter communication without\ncompromising validation accuracy when training ResNet20 and ResNet110 on\nCIFAR10.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 20:58:57 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:46:25 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 04:12:51 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Lu", "Yucheng", ""], ["De Sa", "Christopher", ""]]}, {"id": "2002.11791", "submitter": "Yinjun Wu", "authors": "Yinjun Wu, Val Tannen, Susan B. Davidson", "title": "PrIU: A Provenance-Based Approach for Incrementally Updating Regression\n  Models", "comments": "28 Pages, published in 2020 ACM SIGMOD International Conference on\n  Management of Data (SIGMOD 2020)", "journal-ref": null, "doi": "10.1145/3318464.3380571", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous use of machine learning algorithms brings new challenges to\ntraditional database problems such as incremental view update. Much effort is\nbeing put in better understanding and debugging machine learning models, as\nwell as in identifying and repairing errors in training datasets. Our focus is\non how to assist these activities when they have to retrain the machine\nlearning model after removing problematic training samples in cleaning or\nselecting different subsets of training data for interpretability. This paper\npresents an efficient provenance-based approach, PrIU, and its optimized\nversion, PrIU-opt, for incrementally updating model parameters without\nsacrificing prediction accuracy. We prove the correctness and convergence of\nthe incrementally updated model parameters, and validate it experimentally.\nExperimental results show that up to two orders of magnitude speed-ups can be\nachieved by PrIU-opt compared to simply retraining the model from scratch, yet\nobtaining highly similar models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:04:06 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wu", "Yinjun", ""], ["Tannen", "Val", ""], ["Davidson", "Susan B.", ""]]}, {"id": "2002.11794", "submitter": "Eric Wallace", "authors": "Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer, Dan\n  Klein, Joseph E. Gonzalez", "title": "Train Large, Then Compress: Rethinking Model Size for Efficient Training\n  and Inference of Transformers", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since hardware resources are limited, the objective of training deep learning\nmodels is typically to maximize accuracy subject to the time and memory\nconstraints of training and inference. We study the impact of model size in\nthis setting, focusing on Transformer models for NLP tasks that are limited by\ncompute: self-supervised pretraining and high-resource machine translation. We\nfirst show that even though smaller Transformer models execute faster per\niteration, wider and deeper models converge in significantly fewer steps.\nMoreover, this acceleration in convergence typically outpaces the additional\ncomputational overhead of using larger models. Therefore, the most\ncompute-efficient training strategy is to counterintuitively train extremely\nlarge models but stop after a small number of iterations.\n  This leads to an apparent trade-off between the training efficiency of large\nTransformer models and the inference efficiency of small Transformer models.\nHowever, we show that large models are more robust to compression techniques\nsuch as quantization and pruning than small models. Consequently, one can get\nthe best of both worlds: heavily compressed, large models achieve higher\naccuracy than lightly compressed, small models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:17:13 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 00:23:39 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Zhuohan", ""], ["Wallace", "Eric", ""], ["Shen", "Sheng", ""], ["Lin", "Kevin", ""], ["Keutzer", "Kurt", ""], ["Klein", "Dan", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2002.11798", "submitter": "Sicheng Zhu", "authors": "Sicheng Zhu, Xiao Zhang, David Evans", "title": "Learning Adversarially Robust Representations via Worst-Case Mutual\n  Information Maximization", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training machine learning models that are robust against adversarial inputs\nposes seemingly insurmountable challenges. To better understand adversarial\nrobustness, we consider the underlying problem of learning robust\nrepresentations. We develop a notion of representation vulnerability that\ncaptures the maximum change of mutual information between the input and output\ndistributions, under the worst-case input perturbation. Then, we prove a\ntheorem that establishes a lower bound on the minimum adversarial risk that can\nbe achieved for any downstream classifier based on its representation\nvulnerability. We propose an unsupervised learning method for obtaining\nintrinsically robust representations by maximizing the worst-case mutual\ninformation between the input and output distributions. Experiments on\ndownstream classification tasks support the robustness of the representations\nfound using unsupervised learning with our training principle.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:20:40 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 15:18:54 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhu", "Sicheng", ""], ["Zhang", "Xiao", ""], ["Evans", "David", ""]]}, {"id": "2002.11803", "submitter": "Cyril Zhang", "authors": "Naman Agarwal, Rohan Anil, Elad Hazan, Tomer Koren, Cyril Zhang", "title": "Disentangling Adaptive Gradient Methods from Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate several confounding factors in the evaluation of optimization\nalgorithms for deep learning. Primarily, we take a deeper look at how adaptive\ngradient methods interact with the learning rate schedule, a notoriously\ndifficult-to-tune hyperparameter which has dramatic effects on the convergence\nand generalization of neural network training. We introduce a \"grafting\"\nexperiment which decouples an update's magnitude from its direction, finding\nthat many existing beliefs in the literature may have arisen from insufficient\nisolation of the implicit schedule of step sizes. Alongside this contribution,\nwe present some empirical and theoretical retrospectives on the generalization\nof adaptive gradient methods, aimed at bringing more clarity to this space.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:42:49 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Agarwal", "Naman", ""], ["Anil", "Rohan", ""], ["Hazan", "Elad", ""], ["Koren", "Tomer", ""], ["Zhang", "Cyril", ""]]}, {"id": "2002.11804", "submitter": "Xiao Xu", "authors": "Xiao Xu, Qing Zhao", "title": "Memory-Constrained No-Regret Learning in Adversarial Bandits", "comments": "Accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2021.3070201", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial bandit problem with memory constraints is studied where only\nthe statistics of a subset of arms can be stored. A hierarchical learning\npolicy that requires only a sublinear order of memory space in terms of the\nnumber of arms is developed. Its sublinear regret orders with respect to the\ntime horizon are established for both weak regret and shifting regret. This\nwork appears to be the first on memory-constrained bandit problems under the\nadversarial setting.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:43:45 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 08:04:40 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Xu", "Xiao", ""], ["Zhao", "Qing", ""]]}, {"id": "2002.11810", "submitter": "Miaoyun Zhao", "authors": "Miaoyun Zhao, Yulai Cong, Lawrence Carin", "title": "On Leveraging Pretrained GANs for Generation with Limited Data", "comments": "Accepted at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown generative adversarial networks (GANs) can generate\nhighly realistic images, that are often indistinguishable (by humans) from real\nimages. Most images so generated are not contained in the training dataset,\nsuggesting potential for augmenting training sets with GAN-generated data.\nWhile this scenario is of particular relevance when there are limited data\navailable, there is still the issue of training the GAN itself based on that\nlimited data. To facilitate this, we leverage existing GAN models pretrained on\nlarge-scale datasets (like ImageNet) to introduce additional knowledge (which\nmay not exist within the limited data), following the concept of transfer\nlearning. Demonstrated by natural-image generation, we reveal that low-level\nfilters (those close to observations) of both the generator and discriminator\nof pretrained GANs can be transferred to facilitate generation in a\nperceptually-distinct target domain with limited training data. To further\nadapt the transferred filters to the target domain, we propose adaptive filter\nmodulation (AdaFM). An extensive set of experiments is presented to demonstrate\nthe effectiveness of the proposed techniques on generation with limited data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 21:53:36 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:42:46 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 03:59:02 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Zhao", "Miaoyun", ""], ["Cong", "Yulai", ""], ["Carin", "Lawrence", ""]]}, {"id": "2002.11816", "submitter": "Vu Luong", "authors": "Anh Vu Luong, Tien Thanh Nguyen and Alan Wee-Chung Liew", "title": "Streaming Active Deep Forest for Evolving Data Stream Classification", "comments": "7 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Neural Networks (DNNs) have gained progressive momentum\nin many areas of machine learning. The layer-by-layer process of DNNs has\ninspired the development of many deep models, including deep ensembles. The\nmost notable deep ensemble-based model is Deep Forest, which can achieve highly\ncompetitive performance while having much fewer hyper-parameters comparing to\nDNNs. In spite of its huge success in the batch learning setting, no effort has\nbeen made to adapt Deep Forest to the context of evolving data streams. In this\nwork, we introduce the Streaming Deep Forest (SDF) algorithm, a\nhigh-performance deep ensemble method specially adapted to stream\nclassification. We also present the Augmented Variable Uncertainty (AVU) active\nlearning strategy to reduce the labeling cost in the streaming context. We\ncompare the proposed methods to state-of-the-art streaming algorithms in a wide\nrange of datasets. The results show that by following the AVU active learning\nstrategy, SDF with only 70\\% of labeling budget significantly outperforms other\nmethods trained with all instances.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:00:39 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Luong", "Anh Vu", ""], ["Nguyen", "Tien Thanh", ""], ["Liew", "Alan Wee-Chung", ""]]}, {"id": "2002.11821", "submitter": "Ankit Raj", "authors": "Ankit Raj, Yoram Bresler, Bo Li", "title": "Improving Robustness of Deep-Learning-Based Image Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning-based methods for different applications have been shown\nvulnerable to adversarial examples. These examples make deployment of such\nmodels in safety-critical tasks questionable. Use of deep neural networks as\ninverse problem solvers has generated much excitement for medical imaging\nincluding CT and MRI, but recently a similar vulnerability has also been\ndemonstrated for these tasks. We show that for such inverse problem solvers,\none should analyze and study the effect of adversaries in the\nmeasurement-space, instead of the signal-space as in previous work. In this\npaper, we propose to modify the training strategy of end-to-end\ndeep-learning-based inverse problem solvers to improve robustness. We introduce\nan auxiliary network to generate adversarial examples, which is used in a\nmin-max formulation to build robust image reconstruction networks.\nTheoretically, we show for a linear reconstruction scheme the min-max\nformulation results in a singular-value(s) filter regularized solution, which\nsuppresses the effect of adversarial examples occurring because of\nill-conditioning in the measurement matrix. We find that a linear network using\nthe proposed min-max learning scheme indeed converges to the same solution. In\naddition, for non-linear Compressed Sensing (CS) reconstruction using deep\nnetworks, we show significant improvement in robustness using the proposed\napproach over other methods. We complement the theory by experiments for CS on\ntwo different datasets and evaluate the effect of increasing perturbations on\ntrained networks. We find the behavior for ill-conditioned and well-conditioned\nmeasurement matrices to be qualitatively different.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:12:36 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Raj", "Ankit", ""], ["Bresler", "Yoram", ""], ["Li", "Bo", ""]]}, {"id": "2002.11828", "submitter": "Konstantin Berlin", "authors": "Konstantin Berlin and Ajay Lakshminarayanarao", "title": "A Simple and Agile Cloud Infrastructure to Support Cybersecurity\n  Oriented Machine Learning Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating up to date, well labeled datasets for machine learning (ML)\nsecurity models is a unique engineering challenge, as large data volumes,\ncomplexity of labeling, and constant concept drift makes it difficult to\ngenerate effective training datasets. Here we describe a simple, resilient\ncloud infrastructure for generating ML training and testing datasets, that has\nenhanced the speed at which our team is able to research and keep in production\na multitude of security ML models.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:38:40 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Berlin", "Konstantin", ""], ["Lakshminarayanarao", "Ajay", ""]]}, {"id": "2002.11829", "submitter": "Or Litany", "authors": "Or Litany, Ari Morcos, Srinath Sridhar, Leonidas Guibas, Judy Hoffman", "title": "Representation Learning Through Latent Canonicalizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to learn a representation on a large annotated data source that\ngeneralizes to a target domain using limited new supervision. Many prior\napproaches to this problem have focused on learning \"disentangled\"\nrepresentations so that as individual factors vary in a new domain, only a\nportion of the representation need be updated. In this work, we seek the\ngeneralization power of disentangled representations, but relax the requirement\nof explicit latent disentanglement and instead encourage linearity of\nindividual factors of variation by requiring them to be manipulable by learned\nlinear transformations. We dub these transformations latent canonicalizers, as\nthey aim to modify the value of a factor to a pre-determined (but arbitrary)\ncanonical value (e.g., recoloring the image foreground to black). Assuming a\nsource domain with access to meta-labels specifying the factors of variation\nwithin an image, we demonstrate experimentally that our method helps reduce the\nnumber of observations needed to generalize to a similar target domain when\ncompared to a number of supervised baselines.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 22:50:12 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Litany", "Or", ""], ["Morcos", "Ari", ""], ["Sridhar", "Srinath", ""], ["Guibas", "Leonidas", ""], ["Hoffman", "Judy", ""]]}, {"id": "2002.11833", "submitter": "Jean Harb", "authors": "Jean Harb, Tom Schaul, Doina Precup and Pierre-Luc Bacon", "title": "Policy Evaluation Networks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many reinforcement learning algorithms use value functions to guide the\nsearch for better policies. These methods estimate the value of a single policy\nwhile generalizing across many states. The core idea of this paper is to flip\nthis convention and estimate the value of many policies, for a single set of\nstates. This approach opens up the possibility of performing direct gradient\nascent in policy space without seeing any new data. The main challenge for this\napproach is finding a way to represent complex policies that facilitates\nlearning and generalization. To address this problem, we introduce a scalable,\ndifferentiable fingerprinting mechanism that retains essential policy\ninformation in a concise embedding. Our empirical results demonstrate that\ncombining these three elements (learned Policy Evaluation Network, policy\nfingerprints, gradient ascent) can produce policies that outperform those that\ngenerated the training data, in zero-shot manner.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:00:27 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Harb", "Jean", ""], ["Schaul", "Tom", ""], ["Precup", "Doina", ""], ["Bacon", "Pierre-Luc", ""]]}, {"id": "2002.11835", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Danilo P. Mandic", "title": "Tensor Decompositions in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper surveys the topic of tensor decompositions in modern machine\nlearning applications. It focuses on three active research topics of\nsignificant relevance for the community. After a brief review of consolidated\nworks on multi-way data analysis, we consider the use of tensor decompositions\nin compressing the parameter space of deep learning models. Lastly, we discuss\nhow tensor methods can be leveraged to yield richer adaptive representations of\ncomplex data, including structured information. The paper concludes with a\ndiscussion on interesting open research challenges.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:07:19 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Bacciu", "Davide", ""], ["Mandic", "Danilo P.", ""]]}, {"id": "2002.11843", "submitter": "Ruthvik Vaila", "authors": "Ruthvik Vaila, John Chiasson, Vishal Saxena", "title": "A Deep Unsupervised Feature Learning Spiking Neural Network with\n  Binarized Classification Layers for EMNIST Classification using SpykeFlow", "comments": "A section of of this work is Submitted to IEEE TETCI 2020 Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End user AI is trained on large server farms with data collected from the\nusers. With ever increasing demand for IOT devices, there is a need for deep\nlearning approaches that can be implemented (at the edge) in an energy\nefficient manner. In this work we approach this using spiking neural networks.\nThe unsupervised learning technique of spike timing dependent plasticity (STDP)\nusing binary activations are used to extract features from spiking input data.\nGradient descent (backpropagation) is used only on the output layer to perform\nthe training for classification. The accuracies obtained for the balanced\nEMNIST data set compare favorably with other approaches. The effect of\nstochastic gradient descent (SGD) approximations on learning capabilities of\nour network are also explored.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:47:35 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 18:35:35 GMT"}, {"version": "v3", "created": "Thu, 21 May 2020 13:59:09 GMT"}, {"version": "v4", "created": "Wed, 28 Oct 2020 12:54:03 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Vaila", "Ruthvik", ""], ["Chiasson", "John", ""], ["Saxena", "Vishal", ""]]}, {"id": "2002.11847", "submitter": "Ankush Garg", "authors": "Ankush Garg, Yuan Cao, and Qi Ge", "title": "Echo State Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present neural machine translation (NMT) models inspired by echo state\nnetwork (ESN), named Echo State NMT (ESNMT), in which the encoder and decoder\nlayer weights are randomly generated then fixed throughout training. We show\nthat even with this extremely simple model construction and training procedure,\nESNMT can already reach 70-80% quality of fully trainable baselines. We examine\nhow spectral radius of the reservoir, a key quantity that characterizes the\nmodel, determines the model behavior. Our findings indicate that randomized\nnetworks can work well even for complicated sequence-to-sequence prediction NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:08:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Garg", "Ankush", ""], ["Cao", "Yuan", ""], ["Ge", "Qi", ""]]}, {"id": "2002.11860", "submitter": "Geoffrey Negiar", "authors": "Geoffrey N\\'egiar, Gideon Dresdner, Alicia Tsai, Laurent El Ghaoui,\n  Francesco Locatello, Robert M. Freund, Fabian Pedregosa", "title": "Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization", "comments": "To appear in the Proceedings of the 37th International Conference on\n  Machine Learning, 2020. Main text: 9 pages, 1 figure. Fixes previously found\n  error", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Stochastic Frank-Wolfe (a.k.a. conditional gradient)\nalgorithm for constrained smooth finite-sum minimization with a generalized\nlinear prediction/structure. This class of problems includes empirical risk\nminimization with sparse, low-rank, or other structured constraints. The\nproposed method is simple to implement, does not require step-size tuning, and\nhas a constant per-iteration cost that is independent of the dataset size.\nFurthermore, as a byproduct of the method we obtain a stochastic estimator of\nthe Frank-Wolfe gap that can be used as a stopping criterion. Depending on the\nsetting, the proposed method matches or improves on the best computational\nguarantees for Stochastic Frank-Wolfe algorithms. Benchmarks on several\ndatasets highlight different regimes in which the proposed method exhibits a\nfaster empirical convergence than related methods. Finally, we provide an\nimplementation of all considered methods in an open-source package.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:47:21 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:13:30 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 14:39:42 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 14:59:17 GMT"}, {"version": "v5", "created": "Fri, 26 Jun 2020 11:46:35 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["N\u00e9giar", "Geoffrey", ""], ["Dresdner", "Gideon", ""], ["Tsai", "Alicia", ""], ["Ghaoui", "Laurent El", ""], ["Locatello", "Francesco", ""], ["Freund", "Robert M.", ""], ["Pedregosa", "Fabian", ""]]}, {"id": "2002.11863", "submitter": "Chuang Niu", "authors": "Chuang Niu, Jun Zhang, Ge Wang, Jimin Liang", "title": "GATCluster: Self-Supervised Gaussian-Attention Network for Image\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a self-supervised Gaussian ATtention network for image Clustering\n(GATCluster). Rather than extracting intermediate features first and then\nperforming the traditional clustering algorithm, GATCluster directly outputs\nsemantic cluster labels without further post-processing. Theoretically, we give\na Label Feature Theorem to guarantee the learned features are one-hot encoded\nvectors, and the trivial solutions are avoided. To train the GATCluster in a\ncompletely unsupervised manner, we design four self-learning tasks with the\nconstraints of transformation invariance, separability maximization, entropy\nanalysis, and attention mapping. Specifically, the transformation invariance\nand separability maximization tasks learn the relationships between sample\npairs. The entropy analysis task aims to avoid trivial solutions. To capture\nthe object-oriented semantics, we design a self-supervised attention mechanism\nthat includes a parameterized attention module and a soft-attention loss. All\nthe guiding signals for clustering are self-generated during the training\nprocess. Moreover, we develop a two-step learning algorithm that is\nmemory-efficient for clustering large-size images. Extensive experiments\ndemonstrate the superiority of our proposed method in comparison with the\nstate-of-the-art image clustering benchmarks. Our code has been made publicly\navailable at https://github.com/niuchuangnn/GATCluster.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 00:57:18 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 20:09:39 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Niu", "Chuang", ""], ["Zhang", "Jun", ""], ["Wang", "Ge", ""], ["Liang", "Jimin", ""]]}, {"id": "2002.11867", "submitter": "Zhiqian Chen", "authors": "Zhiqian Chen, Fanglan Chen, Lei Zhang, Taoran Ji, Kaiqun Fu, Liang\n  Zhao, Feng Chen, Lingfei Wu, Charu Aggarwal and Chang-Tien Lu", "title": "Bridging the Gap between Spatial and Spectral Domains: A Survey on Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning's success has been widely recognized in a variety of machine\nlearning tasks, including image classification, audio recognition, and natural\nlanguage processing. As an extension of deep learning beyond these domains,\ngraph neural networks (GNNs) are designed to handle the non-Euclidean\ngraph-structure which is intractable to previous deep learning techniques.\nExisting GNNs are presented using various techniques, making direct comparison\nand cross-reference more complex. Although existing studies categorize GNNs\ninto spatial-based and spectral-based techniques, there hasn't been a thorough\nexamination of their relationship. To close this gap, this study presents a\nsingle framework that systematically incorporates most GNNs. We organize\nexisting GNNs into spatial and spectral domains, as well as expose the\nconnections within each domain. A review of spectral graph theory and\napproximation theory builds a strong relationship across the spatial and\nspectral domains in further investigation.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 01:15:10 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 01:53:31 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 12:31:13 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 15:54:42 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Zhiqian", ""], ["Chen", "Fanglan", ""], ["Zhang", "Lei", ""], ["Ji", "Taoran", ""], ["Fu", "Kaiqun", ""], ["Zhao", "Liang", ""], ["Chen", "Feng", ""], ["Wu", "Lingfei", ""], ["Aggarwal", "Charu", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "2002.11869", "submitter": "Anurag Sarkar", "authors": "Anurag Sarkar, Zhihan Yang, Seth Cooper", "title": "Controllable Level Blending between Games using Variational Autoencoders", "comments": "6 pages, 11 figures, Sixth Experimental AI in Games Workshop at AIIDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work explored blending levels from existing games to create levels\nfor a new game that mixes properties of the original games. In this paper, we\nuse Variational Autoencoders (VAEs) for improving upon such techniques. VAEs\nare artificial neural networks that learn and use latent representations of\ndatasets to generate novel outputs. We train a VAE on level data from Super\nMario Bros. and Kid Icarus, enabling it to capture the latent space spanning\nboth games. We then use this space to generate level segments that combine\nproperties of levels from both games. Moreover, by applying evolutionary search\nin the latent space, we evolve level segments satisfying specific constraints.\nWe argue that these affordances make the VAE-based approach especially suitable\nfor co-creative level design and compare its performance with similar\ngenerative models like the GAN and the VAE-GAN.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 01:38:35 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sarkar", "Anurag", ""], ["Yang", "Zhihan", ""], ["Cooper", "Seth", ""]]}, {"id": "2002.11875", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Pascal Poupart and Yaoliang Yu", "title": "Optimality and Stability in Non-convex Smooth Games", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the recent wide applications of non-convex smooth games, we\nprovide a unified approach to \"local optimal\" points in such games, which\nincludes local Nash equilibria, local minimax points (Jin et al. 2019) and the\nmore general local robust points. To understand these definitions further, we\nstudy their corresponding first- and second-order necessary and sufficient\nconditions and find that they all satisfy stationarity. This motivates us to\nanalyze the local stability of several popular gradient algorithms near\ncorresponding local solutions. Our results indicate the necessity of new\nalgorithms and analysis. As a concrete example, we give the exact existence\nconditions of local (global) minimax points and local robust points for\nquadratic games, and demonstrate their many special properties.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:16:01 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 03:02:00 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Zhang", "Guojun", ""], ["Poupart", "Pascal", ""], ["Yu", "Yaoliang", ""]]}, {"id": "2002.11879", "submitter": "Tanmay Gangwani", "authors": "Tanmay Gangwani, Jian Peng", "title": "State-only Imitation with Transition Dynamics Mismatch", "comments": "ICLR 2020 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation Learning (IL) is a popular paradigm for training agents to achieve\ncomplicated goals by leveraging expert behavior, rather than dealing with the\nhardships of designing a correct reward function. With the environment modeled\nas a Markov Decision Process (MDP), most of the existing IL algorithms are\ncontingent on the availability of expert demonstrations in the same MDP as the\none in which a new imitator policy is to be learned. This is uncharacteristic\nof many real-life scenarios where discrepancies between the expert and the\nimitator MDPs are common, especially in the transition dynamics function.\nFurthermore, obtaining expert actions may be costly or infeasible, making the\nrecent trend towards state-only IL (where expert demonstrations constitute only\nstates or observations) ever so promising. Building on recent adversarial\nimitation approaches that are motivated by the idea of divergence minimization,\nwe present a new state-only IL algorithm in this paper. It divides the overall\noptimization objective into two subproblems by introducing an indirection step\nand solves the subproblems iteratively. We show that our algorithm is\nparticularly effective when there is a transition dynamics mismatch between the\nexpert and imitator MDPs, while the baseline IL methods suffer from performance\ndegradation. To analyze this, we construct several interesting MDPs by\nmodifying the configuration parameters for the MuJoCo locomotion tasks from\nOpenAI Gym.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:27:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gangwani", "Tanmay", ""], ["Peng", "Jian", ""]]}, {"id": "2002.11881", "submitter": "Yu Zhang", "authors": "Yu Zhang, Gongbo Liang, Tawfiq Salem, Nathan Jacobs", "title": "Defense-PointNet: Protecting PointNet Against Adversarial Attacks", "comments": "Accepted by IEEE International Conference on Big Data (BigData)\n  Workshop: The Next Frontier of Big Data From LiDAR, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable performance across a broad range of tasks, neural networks\nhave been shown to be vulnerable to adversarial attacks. Many works focus on\nadversarial attacks and defenses on 2D images, but few focus on 3D point\nclouds. In this paper, our goal is to enhance the adversarial robustness of\nPointNet, which is one of the most widely used models for 3D point clouds. We\napply the fast gradient sign attack method (FGSM) on 3D point clouds and find\nthat FGSM can be used to generate not only adversarial images but also\nadversarial point clouds. To minimize the vulnerability of PointNet to\nadversarial attacks, we propose Defense-PointNet. We compare our model with two\nbaseline approaches and show that Defense-PointNet significantly improves the\nrobustness of the network against adversarial samples.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:35:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhang", "Yu", ""], ["Liang", "Gongbo", ""], ["Salem", "Tawfiq", ""], ["Jacobs", "Nathan", ""]]}, {"id": "2002.11882", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Thanh Thi Nguyen, Doug Creighton, Saeid Nahavandi", "title": "A Visual Communication Map for Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.13433.62563", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning has been applied successfully to solve various\nreal-world problems and the number of its applications in the multi-agent\nsettings has been increasing. Multi-agent learning distinctly poses significant\nchallenges in the effort to allocate a concealed communication medium. Agents\nreceive thorough knowledge from the medium to determine subsequent actions in a\ndistributed nature. Apparently, the goal is to leverage the cooperation of\nmultiple agents to achieve a designated objective efficiently. Recent studies\ntypically combine a specialized neural network with reinforcement learning to\nenable communication between agents. This approach, however, limits the number\nof agents or necessitates the homogeneity of the system. In this paper, we have\nproposed a more scalable approach that not only deals with a great number of\nagents but also enables collaboration between dissimilar functional agents and\ncompatibly combined with any deep reinforcement learning methods. Specifically,\nwe create a global communication map to represent the status of each agent in\nthe system visually. The visual map and the environmental state are fed to a\nshared-parameter network to train multiple agents concurrently. Finally, we\nselect the Asynchronous Advantage Actor-Critic (A3C) algorithm to demonstrate\nour proposed scheme, namely Visual communication map for Multi-agent A3C\n(VMA3C). Simulation results show that the use of visual communication map\nimproves the performance of A3C regarding learning speed, reward achievement,\nand robustness in multi-agent problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:38:21 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 12:12:47 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nguyen", "Thanh Thi", ""], ["Creighton", "Doug", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2002.11883", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Thanh Thi Nguyen, Hai Nguyen, Doug Creighton, Saeid\n  Nahavandi", "title": "Review, Analysis and Design of a Comprehensive Deep Reinforcement\n  Learning Framework", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.16789.06883", "report-no": null, "categories": "cs.LG cs.AI cs.GT cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The integration of deep learning to reinforcement learning (RL) has enabled\nRL to perform efficiently in high-dimensional environments. Deep RL methods\nhave been applied to solve many complex real-world problems in recent years.\nHowever, development of a deep RL-based system is challenging because of\nvarious issues such as the selection of a suitable deep RL algorithm, its\nnetwork configuration, training time, training methods, and so on. This paper\nproposes a comprehensive software framework that not only plays a vital role in\ndesigning a connect-the-dots deep RL architecture but also provides a guideline\nto develop a realistic RL application in a short time span. We have designed\nand developed a deep RL-based software framework that strictly ensures\nflexibility, robustness, and scalability. By inheriting the proposed\narchitecture, software managers can foresee any challenges when designing a\ndeep RL-based system. As a result, they can expedite the design process and\nactively control every stage of software development, which is especially\ncritical in agile development environments. To enforce generalization, the\nproposed architecture does not depend on a specific RL algorithm, a network\nconfiguration, the number of agents, or the type of agents. Using our\nframework, software developers can develop and integrate new RL algorithms or\nnew types of agents, and can flexibly change network configuration or the\nnumber of agents.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:38:47 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 12:05:04 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nguyen", "Thanh Thi", ""], ["Nguyen", "Hai", ""], ["Creighton", "Doug", ""], ["Nahavandi", "Saeid", ""]]}, {"id": "2002.11885", "submitter": "Gaurav Nagesh Shetty", "authors": "Gaurav N.Shetty, Konstantinos Slavakis, Ukash Nakarmi, Gesualdo\n  Scutari, and Leslie Ying", "title": "Kernel Bi-Linear Modeling for Reconstructing Data on Manifolds: The\n  Dynamic-MRI Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a kernel-based framework for reconstructing data on\nmanifolds, tailored to fit the dynamic-(d)MRI-data recovery problem. The\nproposed methodology exploits simple tangent-space geometries of manifolds in\nreproducing kernel Hilbert spaces and follows classical kernel-approximation\narguments to form the data-recovery task as a bi-linear inverse problem.\nDeparting from mainstream approaches, the proposed methodology uses no training\ndata, employs no graph Laplacian matrix to penalize the optimization task, uses\nno costly (kernel) pre-imaging step to map feature points back to the input\nspace, and utilizes complex-valued kernel functions to account for k-space\ndata. The framework is validated on synthetically generated dMRI data, where\ncomparisons against state-of-the-art schemes highlight the rich potential of\nthe proposed approach in data-recovery problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:42:08 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shetty", "Gaurav N.", ""], ["Slavakis", "Konstantinos", ""], ["Nakarmi", "Ukash", ""], ["Scutari", "Gesualdo", ""], ["Ying", "Leslie", ""]]}, {"id": "2002.11887", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Ruoxi Sun, C. Daniel Freeman, Ben\n  Poole, Jascha Sohl-Dickstein", "title": "Using a thousand optimization tasks to learn hyperparameter search\n  strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TaskSet, a dataset of tasks for use in training and evaluating\noptimizers. TaskSet is unique in its size and diversity, containing over a\nthousand tasks ranging from image classification with fully connected or\nconvolutional neural networks, to variational autoencoders, to non-volume\npreserving flows on a variety of datasets. As an example application of such a\ndataset we explore meta-learning an ordered list of hyperparameters to try\nsequentially. By learning this hyperparameter list from data generated using\nTaskSet we achieve large speedups in sample efficiency over random search. Next\nwe use the diversity of the TaskSet and our method for learning hyperparameter\nlists to empirically explore the generalization of these lists to new\noptimization tasks in a variety of settings including ImageNet classification\nwith Resnet50 and LM1B language modeling with transformers. As part of this\nwork we have opensourced code for all tasks, as well as ~29 million training\ncurves for these problems and the corresponding hyperparameters.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 02:49:10 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 23:01:28 GMT"}, {"version": "v3", "created": "Wed, 1 Apr 2020 00:35:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Sun", "Ruoxi", ""], ["Freeman", "C. Daniel", ""], ["Poole", "Ben", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "2002.11890", "submitter": "Bo Peng", "authors": "Bo Peng, Zhiyun Ren, Srinivasan Parthasarathy and Xia Ning", "title": "HAM: Hybrid Associations Models for Sequential Recommendation", "comments": "This paper has been accepted by IEEE Transactions on Knowledge and\n  Data Engineering (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential recommendation aims to identify and recommend the next few items\nfor a user that the user is most likely to purchase/review, given the user's\npurchase/rating trajectories. It becomes an effective tool to help users select\nfavorite items from a variety of options. In this manuscript, we developed\nhybrid associations models (HAM) to generate sequential recommendations using\nthree factors: 1) users' long-term preferences, 2) sequential, high-order and\nlow-order association patterns in the users' most recent purchases/ratings, and\n3) synergies among those items. HAM uses simplistic pooling to represent a set\nof items in the associations, and element-wise product to represent item\nsynergies of arbitrary orders. We compared HAM models with the most recent,\nstate-of-the-art methods on six public benchmark datasets in three different\nexperimental settings. Our experimental results demonstrate that HAM models\nsignificantly outperform the state of the art in all the experimental settings,\nwith an improvement as much as 46.6%. In addition, our run-time performance\ncomparison in testing demonstrates that HAM models are much more efficient than\nthe state-of-the-art methods, and are able to achieve significant speedup as\nmuch as 139.7 folds.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:04:16 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 21:09:36 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 14:14:41 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Peng", "Bo", ""], ["Ren", "Zhiyun", ""], ["Parthasarathy", "Srinivasan", ""], ["Ning", "Xia", ""]]}, {"id": "2002.11896", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "Gradient Boosted Normalizing Flows", "comments": "Appearing in the 34th Conference on Neural Information Processing\n  Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By chaining a sequence of differentiable invertible transformations,\nnormalizing flows (NF) provide an expressive method of posterior approximation,\nexact density evaluation, and sampling. The trend in normalizing flow\nliterature has been to devise deeper, more complex transformations to achieve\ngreater flexibility. We propose an alternative: Gradient Boosted Normalizing\nFlows (GBNF) model a density by successively adding new NF components with\ngradient boosting. Under the boosting framework, each new NF component\noptimizes a sample weighted likelihood objective, resulting in new components\nthat are fit to the residuals of the previously trained components. The GBNF\nformulation results in a mixture model structure, whose flexibility increases\nas more components are added. Moreover, GBNFs offer a wider, as opposed to\nstrictly deeper, approach that improves existing NFs at the cost of additional\ntraining---not more complex transformations. We demonstrate the effectiveness\nof this technique for density estimation and, by coupling GBNF with a\nvariational autoencoder, generative modeling of images. Our results show that\nGBNFs outperform their non-boosted analog, and, in some cases, produce better\nresults with smaller, simpler flows.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:12:08 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 19:55:35 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 05:06:45 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 20:09:27 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "2002.11903", "submitter": "Youngbin Park", "authors": "Taewon Kim, Yeseong Park, Youngbin Park and Il Hong Suh", "title": "Acceleration of Actor-Critic Deep Reinforcement Learning for Visual\n  Grasping in Clutter by State Representation Learning Based on Disentanglement\n  of a Raw Input Image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a robotic grasping task in which diverse unseen target objects exist in a\ncluttered environment, some deep learning-based methods have achieved\nstate-of-the-art results using visual input directly. In contrast, actor-critic\ndeep reinforcement learning (RL) methods typically perform very poorly when\ngrasping diverse objects, especially when learning from raw images and sparse\nrewards. To make these RL techniques feasible for vision-based grasping tasks,\nwe employ state representation learning (SRL), where we encode essential\ninformation first for subsequent use in RL. However, typical representation\nlearning procedures are unsuitable for extracting pertinent information for\nlearning the grasping skill, because the visual inputs for representation\nlearning, where a robot attempts to grasp a target object in clutter, are\nextremely complex. We found that preprocessing based on the disentanglement of\na raw input image is the key to effectively capturing a compact representation.\nThis enables deep RL to learn robotic grasping skills from highly varied and\ndiverse visual inputs. We demonstrate the effectiveness of this approach with\nvarying levels of disentanglement in a realistic simulated environment.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 03:58:51 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kim", "Taewon", ""], ["Park", "Yeseong", ""], ["Park", "Youngbin", ""], ["Suh", "Il Hong", ""]]}, {"id": "2002.11912", "submitter": "Randall Balestriero", "authors": "Randall Balestriero, Sebastien Paris, Richard Baraniuk", "title": "Max-Affine Spline Insights into Deep Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We connect a large class of Generative Deep Networks (GDNs) with spline\noperators in order to derive their properties, limitations, and new\nopportunities. By characterizing the latent space partition, dimension and\nangularity of the generated manifold, we relate the manifold dimension and\napproximation error to the sample size. The manifold-per-region affine subspace\ndefines a local coordinate basis; we provide necessary and sufficient\nconditions relating those basis vectors with disentanglement. We also derive\nthe output probability density mapped onto the generated manifold in terms of\nthe latent space density, which enables the computation of key statistics such\nas its Shannon entropy. This finding also enables the computation of the GDN\nlikelihood, which provides a new mechanism for model comparison as well as\nproviding a quality measure for (generated) samples under the learned\ndistribution. We demonstrate how low entropy and/or multimodal distributions\nare not naturally modeled by DGNs and are a cause of training instabilities.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:20:02 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Balestriero", "Randall", ""], ["Paris", "Sebastien", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2002.11919", "submitter": "Yao Yao", "authors": "Yao Yao, Chen Gong, Jiehui Deng, Jian Yang", "title": "Network Cooperation with Progressive Disambiguation for Partial Label\n  Learning", "comments": "7 pages,3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Label Learning (PLL) aims to train a classifier when each training\ninstance is associated with a set of candidate labels, among which only one is\ncorrect but is not accessible during the training phase. The common strategy\ndealing with such ambiguous labeling information is to disambiguate the\ncandidate label sets. Nonetheless, existing methods ignore the disambiguation\ndifficulty of instances and adopt the single-trend training mechanism. The\nformer would lead to the vulnerability of models to the false positive labels\nand the latter may arouse error accumulation problem. To remedy these two\ndrawbacks, this paper proposes a novel approach termed \"Network Cooperation\nwith Progressive Disambiguation\" (NCPD) for PLL. Specifically, we devise a\nprogressive disambiguation strategy of which the disambiguation operations are\nperformed on simple instances firstly and then gradually on more complicated\nones. Therefore, the negative impacts brought by the false positive labels of\ncomplicated instances can be effectively mitigated as the disambiguation\nability of the model has been strengthened via learning from the simple\ninstances. Moreover, by employing artificial neural networks as the backbone,\nwe utilize a network cooperation mechanism which trains two networks\ncollaboratively by letting them interact with each other. As two networks have\ndifferent disambiguation ability, such interaction is beneficial for both\nnetworks to reduce their respective disambiguation errors, and thus is much\nbetter than the existing algorithms with single-trend training process.\nExtensive experimental results on various benchmark and practical datasets\ndemonstrate the superiority of our NCPD to other state-of-the-art PLL methods.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 09:50:39 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Yao", "Yao", ""], ["Gong", "Chen", ""], ["Deng", "Jiehui", ""], ["Yang", "Jian", ""]]}, {"id": "2002.11921", "submitter": "Aditya Kusupati", "authors": "Oindrila Saha, Aditya Kusupati, Harsha Vardhan Simhadri, Manik Varma,\n  Prateek Jain", "title": "RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference", "comments": "25 pages, 8 figures. Published at Advances in Neural Information\n  Processing Systems (NeurIPS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Convolutional Neural Networks (CNNs) designed for computer vision\ntasks tend to have large intermediate activation maps. These require large\nworking memory and are thus unsuitable for deployment on resource-constrained\ndevices typically used for inference on the edge. Aggressively downsampling the\nimages via pooling or strided convolutions can address the problem but leads to\na significant decrease in accuracy due to gross aggregation of the feature map\nby standard pooling operators. In this paper, we introduce RNNPool, a novel\npooling operator based on Recurrent Neural Networks (RNNs), that efficiently\naggregates features over large patches of an image and rapidly downsamples\nactivation maps. Empirical evaluation indicates that an RNNPool layer can\neffectively replace multiple blocks in a variety of architectures such as\nMobileNets, DenseNet when applied to standard vision tasks like image\nclassification and face detection. That is, RNNPool can significantly decrease\ncomputational complexity and peak memory usage for inference while retaining\ncomparable accuracy. We use RNNPool with the standard S3FD architecture to\nconstruct a face detection method that achieves state-of-the-art MAP for tiny\nARM Cortex-M4 class microcontrollers with under 256 KB of RAM. Code is released\nat https://github.com/Microsoft/EdgeML.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:22:44 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 21:05:24 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Saha", "Oindrila", ""], ["Kusupati", "Aditya", ""], ["Simhadri", "Harsha Vardhan", ""], ["Varma", "Manik", ""], ["Jain", "Prateek", ""]]}, {"id": "2002.11923", "submitter": "Fan Yang", "authors": "Hu Ding, Ruizhe Qin, Jiawei Huang", "title": "The Effectiveness of Johnson-Lindenstrauss Transform for High\n  Dimensional Optimization With Adversarial Outliers, and the Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider robust optimization problems in high dimensions.\nBecause a real-world dataset may contain significant noise or even specially\ncrafted samples from some attacker, we are particularly interested in the\noptimization problems with arbitrary (and potentially adversarial) outliers. We\nfocus on two fundamental optimization problems: {\\em SVM with outliers} and\n{\\em $k$-center clustering with outliers}. They are in fact extremely\nchallenging combinatorial optimization problems, since we cannot impose any\nrestriction on the adversarial outliers. Therefore, their computational\ncomplexities are quite high especially when we consider the instances in high\ndimensional spaces. The {\\em Johnson-Lindenstrauss (JL) Transform} is one of\nthe most popular methods for dimension reduction. Though the JL transform has\nbeen widely studied in the past decades, its effectiveness for dealing with\nadversarial outliers has never been investigated before (to the best of our\nknowledge). Based on some novel insights from the geometry, we prove that the\ncomplexities of these two problems can be significantly reduced through the JL\ntransform. Moreover, we prove that the solution in the dimensionality-reduced\nspace can be efficiently recovered in the original $\\mathbb{R}^d$ while the\nquality is still preserved. In the experiments, we compare JL transform with\nseveral other well known dimension reduction methods, and study their\nperformances on synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:23:35 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 00:14:01 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 12:07:19 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2020 09:01:54 GMT"}, {"version": "v5", "created": "Sun, 21 Feb 2021 13:18:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ding", "Hu", ""], ["Qin", "Ruizhe", ""], ["Huang", "Jiawei", ""]]}, {"id": "2002.11930", "submitter": "Yuming Shen", "authors": "Yuming Shen, Jie Qin, Jiaxin Chen, Mengyang Yu, Li Liu, Fan Zhu, Fumin\n  Shen, Ling Shao", "title": "Auto-Encoding Twin-Bottleneck Hashing", "comments": "CVPR 2020 Accepted, Code at https://github.com/ymcidence/TBH", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional unsupervised hashing methods usually take advantage of\nsimilarity graphs, which are either pre-computed in the high-dimensional space\nor obtained from random anchor points. On the one hand, existing methods\nuncouple the procedures of hash function learning and graph construction. On\nthe other hand, graphs empirically built upon original data could introduce\nbiased prior knowledge of data relevance, leading to sub-optimal retrieval\nperformance. In this paper, we tackle the above problems by proposing an\nefficient and adaptive code-driven graph, which is updated by decoding in the\ncontext of an auto-encoder. Specifically, we introduce into our framework twin\nbottlenecks (i.e., latent variables) that exchange crucial information\ncollaboratively. One bottleneck (i.e., binary codes) conveys the high-level\nintrinsic data structure captured by the code-driven graph to the other (i.e.,\ncontinuous variables for low-level detail information), which in turn\npropagates the updated network feedback for the encoder to learn more\ndiscriminative binary codes. The auto-encoding learning objective literally\nrewards the code-driven graph to learn an optimal encoder. Moreover, the\nproposed model can be simply optimized by gradient descent without violating\nthe binary constraints. Experiments on benchmarked datasets clearly show the\nsuperiority of our framework over the state-of-the-art hashing methods. Our\nsource code can be found at https://github.com/ymcidence/TBH.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 05:58:12 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 09:14:58 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Shen", "Yuming", ""], ["Qin", "Jie", ""], ["Chen", "Jiaxin", ""], ["Yu", "Mengyang", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Shen", "Fumin", ""], ["Shao", "Ling", ""]]}, {"id": "2002.11934", "submitter": "Tomojit Ghosh", "authors": "Tomojit Ghosh and Michael Kirby", "title": "Supervised Dimensionality Reduction and Visualization using\n  Centroid-encoder", "comments": "25 pages (including 3 reference pages), 12 figures. I am planning to\n  submit the paper to JMLR very soon. Centroid-encoder was applied on a\n  biological pathway data\n  (https://www.sciencedirect.com/science/article/pii/S1046202317300439). In\n  this paper we throughly analyzed the algorithm and compared it with\n  state-of-the art techniques on a 8 data sets including MNIST, USPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing high-dimensional data is an essential task in Data Science and\nMachine Learning. The Centroid-Encoder (CE) method is similar to the\nautoencoder but incorporates label information to keep objects of a class close\ntogether in the reduced visualization space. CE exploits nonlinearity and\nlabels to encode high variance in low dimensions while capturing the global\nstructure of the data. We present a detailed analysis of the method using a\nwide variety of data sets and compare it with other supervised dimension\nreduction techniques, including NCA, nonlinear NCA, t-distributed NCA,\nt-distributed MCML, supervised UMAP, supervised PCA, Colored Maximum Variance\nUnfolding, supervised Isomap, Parametric Embedding, supervised Neighbor\nRetrieval Visualizer, and Multiple Relational Embedding. We empirically show\nthat centroid-encoder outperforms most of these techniques. We also show that\nwhen the data variance is spread across multiple modalities, centroid-encoder\nextracts a significant amount of information from the data in low dimensional\nspace. This key feature establishes its value to use it as a tool for data\nvisualization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:08:22 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 23:22:24 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ghosh", "Tomojit", ""], ["Kirby", "Michael", ""]]}, {"id": "2002.11936", "submitter": "Yuki Suzuki", "authors": "Yuki Suzuki, Kazuki Yamagata, Yanagawa Masahiro, Shoji Kido, Noriyuki\n  Tomiyama", "title": "Weak Supervision in Convolutional Neural Network for Semantic\n  Segmentation of Diffuse Lung Diseases Using Partially Annotated Dataset", "comments": "Accepted at SPIE Medical Imaging 2020: Computer-Aided Diagnosis", "journal-ref": null, "doi": "10.1117/12.2548930", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided diagnosis system for diffuse lung diseases (DLDs) is necessary\nfor the objective assessment of the lung diseases. In this paper, we develop\nsemantic segmentation model for 5 kinds of DLDs. DLDs considered in this work\nare consolidation, ground glass opacity, honeycombing, emphysema, and normal.\nConvolutional neural network (CNN) is one of the most promising technique for\nsemantic segmentation among machine learning algorithms. While creating\nannotated dataset for semantic segmentation is laborious and time consuming,\ncreating partially annotated dataset, in which only one chosen class is\nannotated for each image, is easier since annotators only need to focus on one\nclass at a time during the annotation task. In this paper, we propose a new\nweak supervision technique that effectively utilizes partially annotated\ndataset. The experiments using partially annotated dataset composed 372 CT\nimages demonstrated that our proposed technique significantly improved\nsegmentation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:17:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 11:04:49 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Suzuki", "Yuki", ""], ["Yamagata", "Kazuki", ""], ["Masahiro", "Yanagawa", ""], ["Kido", "Shoji", ""], ["Tomiyama", "Noriyuki", ""]]}, {"id": "2002.11940", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Jun Zhou, Xiaolong Li, Yuan Qi, Yujing Jiao,\n  and Xingyu Zhong", "title": "How Much Can A Retailer Sell? Sales Forecasting on Tmall", "comments": "Accepted by PAKDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-series forecasting is an important task in both academic and industry,\nwhich can be applied to solve many real forecasting problems like stock,\nwater-supply, and sales predictions. In this paper, we study the case of\nretailers' sales forecasting on Tmall|the world's leading online B2C platform.\nBy analyzing the data, we have two main observations, i.e., sales seasonality\nafter we group different groups of retails and a Tweedie distribution after we\ntransform the sales (target to forecast). Based on our observations, we design\ntwo mechanisms for sales forecasting, i.e., seasonality extraction and\ndistribution transformation. First, we adopt Fourier decomposition to\nautomatically extract the seasonalities for different categories of retailers,\nwhich can further be used as additional features for any established regression\nalgorithms. Second, we propose to optimize the Tweedie loss of sales after\nlogarithmic transformations. We apply these two mechanisms to classic\nregression models, i.e., neural network and Gradient Boosting Decision Tree,\nand the experimental results on Tmall dataset show that both mechanisms can\nsignificantly improve the forecasting results.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 06:41:00 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Qi", "Yuan", ""], ["Jiao", "Yujing", ""], ["Zhong", "Xingyu", ""]]}, {"id": "2002.11945", "submitter": "Sumon Bose Mr.", "authors": "Sumon Kumar Bose, Jyotibdha Acharya, and Arindam Basu", "title": "Is my Neural Network Neuromorphic? Taxonomy, Recent Trends and Future\n  Directions in Neuromorphic Engineering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we review recent work published over the last 3 years under\nthe umbrella of Neuromorphic engineering to analyze what are the common\nfeatures among such systems. We see that there is no clear consensus but each\nsystem has one or more of the following features:(1) Analog computing (2) Non\nvonNeumann Architecture and low-precision digital processing (3) Spiking Neural\nNetworks (SNN) with components closely related to biology. We compare recent\nmachine learning accelerator chips to show that indeed analog processing and\nreduced bit precision architectures have best throughput, energy and area\nefficiencies. However, pure digital architectures can also achieve quite high\nefficiencies by just adopting a non von-Neumann architecture. Given the design\nautomation tools for digital hardware design, it raises a question on the\nlikelihood of adoption of analog processing in the near future for industrial\ndesigns. Next, we argue about the importance of defining standards and choosing\nproper benchmarks for the progress of neuromorphic system designs and propose\nsome desired characteristics of such benchmarks. Finally, we show brain-machine\ninterfaces as a potential task that fulfils all the criteria of such\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:10:23 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Bose", "Sumon Kumar", ""], ["Acharya", "Jyotibdha", ""], ["Basu", "Arindam", ""]]}, {"id": "2002.11949", "submitter": "Kaihua Tang", "authors": "Kaihua Tang, Yulei Niu, Jianqiang Huang, Jiaxin Shi, Hanwang Zhang", "title": "Unbiased Scene Graph Generation from Biased Training", "comments": "This paper is accepted by CVPR 2020. The code is publicly available\n  on GitHub: https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's scene graph generation (SGG) task is still far from practical, mainly\ndue to the severe training bias, e.g., collapsing diverse \"human walk on / sit\non / lay on beach\" into \"human on beach\". Given such SGG, the down-stream tasks\nsuch as VQA can hardly infer better scene structures than merely a bag of\nobjects. However, debiasing in SGG is not trivial because traditional debiasing\nmethods cannot distinguish between the good and bad bias, e.g., good context\nprior (e.g., \"person read book\" rather than \"eat\") and bad long-tailed bias\n(e.g., \"near\" dominating \"behind / in front of\"). In this paper, we present a\nnovel SGG framework based on causal inference but not the conventional\nlikelihood. We first build a causal graph for SGG, and perform traditional\nbiased training with the graph. Then, we propose to draw the counterfactual\ncausality from the trained graph to infer the effect from the bad bias, which\nshould be removed. In particular, we use Total Direct Effect (TDE) as the\nproposed final predicate score for unbiased SGG. Note that our framework is\nagnostic to any SGG model and thus can be widely applied in the community who\nseeks unbiased predictions. By using the proposed Scene Graph Diagnosis toolkit\non the SGG benchmark Visual Genome and several prevailing models, we observed\nsignificant improvements over the previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:29:53 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 15:46:25 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2020 07:55:13 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Tang", "Kaihua", ""], ["Niu", "Yulei", ""], ["Huang", "Jianqiang", ""], ["Shi", "Jiaxin", ""], ["Zhang", "Hanwang", ""]]}, {"id": "2002.11952", "submitter": "Christian Wagner", "authors": "Philipp Leinen, Malte Esders, Kristof T. Sch\\\"utt, Christian Wagner,\n  Klaus-Robert M\\\"uller, F. Stefan Tautz", "title": "Autonomous robotic nanofabrication with reinforcement learning", "comments": "3 figures", "journal-ref": "Sci. Adv. 6, eabb6987 (2020)", "doi": "10.1126/sciadv.abb6987", "report-no": null, "categories": "cond-mat.mes-hall cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to handle single molecules as effectively as macroscopic\nbuilding-blocks would enable the construction of complex supramolecular\nstructures inaccessible to self-assembly. The fundamental challenges\nobstructing this goal are the uncontrolled variability and poor observability\nof atomic-scale conformations. Here, we present a strategy to work around both\nobstacles, and demonstrate autonomous robotic nanofabrication by manipulating\nsingle molecules. Our approach employs reinforcement learning (RL), which finds\nsolution strategies even in the face of large uncertainty and sparse feedback.\nWe demonstrate the potential of our RL approach by removing molecules\nautonomously with a scanning probe microscope from a supramolecular structure\n-- an exemplary task of subtractive manufacturing at the nanoscale. Our RL\nagent reaches an excellent performance, enabling us to automate a task which\npreviously had to be performed by a human. We anticipate that our work opens\nthe way towards autonomous agents for the robotic construction of functional\nsupramolecular structures with speed, precision and perseverance beyond our\ncurrent capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:37:20 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 12:48:43 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Leinen", "Philipp", ""], ["Esders", "Malte", ""], ["Sch\u00fctt", "Kristof T.", ""], ["Wagner", "Christian", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Tautz", "F. Stefan", ""]]}, {"id": "2002.11955", "submitter": "Daniel Y. Fu", "authors": "Daniel Y. Fu, Mayee F. Chen, Frederic Sala, Sarah M. Hooper, Kayvon\n  Fatahalian, Christopher R\\'e", "title": "Fast and Three-rious: Speeding Up Weak Supervision with Triplet Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak supervision is a popular method for building machine learning models\nwithout relying on ground truth annotations. Instead, it generates\nprobabilistic training labels by estimating the accuracies of multiple noisy\nlabeling sources (e.g., heuristics, crowd workers). Existing approaches use\nlatent variable estimation to model the noisy sources, but these methods can be\ncomputationally expensive, scaling superlinearly in the data. In this work, we\nshow that, for a class of latent variable models highly applicable to weak\nsupervision, we can find a closed-form solution to model parameters, obviating\nthe need for iterative solutions like stochastic gradient descent (SGD). We use\nthis insight to build FlyingSquid, a weak supervision framework that runs\norders of magnitude faster than previous weak supervision approaches and\nrequires fewer assumptions. In particular, we prove bounds on generalization\nerror without assuming that the latent variable model can exactly parameterize\nthe underlying data distribution. Empirically, we validate FlyingSquid on\nbenchmark weak supervision datasets and find that it achieves the same or\nhigher quality compared to previous approaches without the need to tune an SGD\nprocedure, recovers model parameters 170 times faster on average, and enables\nnew video analysis and online learning applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 07:51:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 12:45:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Fu", "Daniel Y.", ""], ["Chen", "Mayee F.", ""], ["Sala", "Frederic", ""], ["Hooper", "Sarah M.", ""], ["Fatahalian", "Kayvon", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2002.11962", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Can We Find Near-Approximately-Stationary Points of Nonsmooth Nonconvex\n  Functions?", "comments": "This paper is superseded by arXiv:2104.06763, which contains major\n  additional results", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that given a bounded, smooth nonconvex function, standard\ngradient-based methods can find $\\epsilon$-stationary points (where the\ngradient norm is less than $\\epsilon$) in $\\mathcal{O}(1/\\epsilon^2)$\niterations. However, many important nonconvex optimization problems, such as\nthose associated with training modern neural networks, are inherently not\nsmooth, making these results inapplicable. Moreover, as recently pointed out in\nZhang et al. [2020], it is generally impossible to provide finite-time\nguarantees for finding an $\\epsilon$-stationary point of nonsmooth functions.\nPerhaps the most natural relaxation of this is to find points which are near\nsuch $\\epsilon$-stationary points. In this paper, we show that even this\nrelaxed goal is hard to obtain in general, given only black-box access to the\nfunction values and gradients. We also discuss the pros and cons of alternative\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:26:34 GMT"}, {"version": "v2", "created": "Sat, 14 Mar 2020 04:33:50 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 19:09:29 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "2002.11963", "submitter": "Elise Van Der Pol", "authors": "Elise van der Pol, Thomas Kipf, Frans A. Oliehoek, Max Welling", "title": "Plannable Approximations to MDP Homomorphisms: Equivariance under\n  Actions", "comments": "To appear in Proceedings of the International Conference on\n  Autonomous Agents and Multi-Agent Systems (AAMAS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work exploits action equivariance for representation learning in\nreinforcement learning. Equivariance under actions states that transitions in\nthe input space are mirrored by equivalent transitions in latent space, while\nthe map and transition functions should also commute. We introduce a\ncontrastive loss function that enforces action equivariance on the learned\nrepresentations. We prove that when our loss is zero, we have a homomorphism of\na deterministic Markov Decision Process (MDP). Learning equivariant maps leads\nto structured latent spaces, allowing us to build a model on which we plan\nthrough value iteration. We show experimentally that for deterministic MDPs,\nthe optimal policy in the abstract MDP can be successfully lifted to the\noriginal MDP. Moreover, the approach easily adapts to changes in the goal\nstates. Empirically, we show that in such MDPs, we obtain better\nrepresentations in fewer epochs compared to representation learning approaches\nusing reconstructions, while generalizing better to new goals than model-free\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:29:10 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["van der Pol", "Elise", ""], ["Kipf", "Thomas", ""], ["Oliehoek", "Frans A.", ""], ["Welling", "Max", ""]]}, {"id": "2002.11977", "submitter": "Zan Gao", "authors": "Z. Gao, K.X Xue, S.H Wan", "title": "Multiple Discrimination and Pairwise CNN for View-based 3D Object\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development and wide application of computer, camera device,\nnetwork and hardware technology, 3D object (or model) retrieval has attracted\nwidespread attention and it has become a hot research topic in the computer\nvision domain. Deep learning features already available in 3D object retrieval\nhave been proven to be better than the retrieval performance of hand-crafted\nfeatures. However, most existing networks do not take into account the impact\nof multi-view image selection on network training, and the use of contrastive\nloss alone only forcing the same-class samples to be as close as possible. In\nthis work, a novel solution named Multi-view Discrimination and Pairwise CNN\n(MDPCNN) for 3D object retrieval is proposed to tackle these issues. It can\nsimultaneously input of multiple batches and multiple views by adding the Slice\nlayer and the Concat layer. Furthermore, a highly discriminative network is\nobtained by training samples that are not easy to be classified by clustering.\nLastly, we deploy the contrastive-center loss and contrastive loss as the\noptimization objective that has better intra-class compactness and inter-class\nseparability. Large-scale experiments show that the proposed MDPCNN can achieve\na significant performance over the state-of-the-art algorithms in 3D object\nretrieval.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:11:23 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gao", "Z.", ""], ["Xue", "K. X", ""], ["Wan", "S. H", ""]]}, {"id": "2002.11982", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Chaochao Chen, Bowen Song, Li Wang, Jun Zhou, Kenny Q.\n  Zhu", "title": "Adapted tree boosting for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Secure online transaction is an essential task for e-commerce platforms.\nAlipay, one of the world's leading cashless payment platform, provides the\npayment service to both merchants and individual customers. The fraud detection\nmodels are built to protect the customers, but stronger demands are raised by\nthe new scenes, which are lacking in training data and labels. The proposed\nmodel makes a difference by utilizing the data under similar old scenes and the\ndata under a new scene is treated as the target domain to be promoted. Inspired\nby this real case in Alipay, we view the problem as a transfer learning problem\nand design a set of revise strategies to transfer the source domain models to\nthe target domain under the framework of gradient boosting tree models. This\nwork provides an option for the cold-starting and data-sharing problems.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:14:46 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 03:14:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fang", "Wenjing", ""], ["Chen", "Chaochao", ""], ["Song", "Bowen", ""], ["Wang", "Li", ""], ["Zhou", "Jun", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2002.11985", "submitter": "Prakhar Ganesh", "authors": "Prakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan\n  Sajjad, Preslav Nakov, Deming Chen, Marianne Winslett", "title": "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT", "comments": "To appear in TACL 2021. The arXiv version is a pre-MIT Press\n  publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained Transformer-based models have achieved state-of-the-art\nperformance for various Natural Language Processing (NLP) tasks. However, these\nmodels often have billions of parameters, and, thus, are too resource-hungry\nand computation-intensive to suit low-capability devices or applications with\nstrict latency requirements. One potential remedy for this is model\ncompression, which has attracted a lot of research attention. Here, we\nsummarize the research in compressing Transformers, focusing on the especially\npopular BERT model. In particular, we survey the state of the art in\ncompression for BERT, we clarify the current best practices for compressing\nlarge-scale Transformer models, and we provide insights into the workings of\nvarious methods. Our categorization and analysis also shed light on promising\nfuture research directions for achieving lightweight, accurate, and generic NLP\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:20:31 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 02:38:20 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ganesh", "Prakhar", ""], ["Chen", "Yao", ""], ["Lou", "Xin", ""], ["Khan", "Mohammad Ali", ""], ["Yang", "Yin", ""], ["Sajjad", "Hassan", ""], ["Nakov", "Preslav", ""], ["Chen", "Deming", ""], ["Winslett", "Marianne", ""]]}, {"id": "2002.12011", "submitter": "Atsutoshi Kumagai", "authors": "Atsutoshi Kumagai, Tomoharu Iwata, Yasuhiro Fujiwara", "title": "Semi-supervised Anomaly Detection on Attributed Graphs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple yet effective method for detecting anomalous instances on\nan attribute graph with label information of a small number of instances.\nAlthough with standard anomaly detection methods it is usually assumed that\ninstances are independent and identically distributed, in many real-world\napplications, instances are often explicitly connected with each other,\nresulting in so-called attributed graphs. The proposed method embeds nodes\n(instances) on the attributed graph in the latent space by taking into account\ntheir attributes as well as the graph structure based on graph convolutional\nnetworks (GCNs). To learn node embeddings specialized for anomaly detection, in\nwhich there is a class imbalance due to the rarity of anomalies, the parameters\nof a GCN are trained to minimize the volume of a hypersphere that encloses the\nnode embeddings of normal instances while embedding anomalous ones outside the\nhypersphere. This enables us to detect anomalies by simply calculating the\ndistances between the node embeddings and hypersphere center. The proposed\nmethod can effectively propagate label information on a small amount of nodes\nto unlabeled ones by taking into account the node's attributes, graph\nstructure, and class imbalance. In experiments with five real-world attributed\ngraph datasets, we demonstrate that the proposed method achieves better\nperformance than various existing anomaly detection methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:06:22 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kumagai", "Atsutoshi", ""], ["Iwata", "Tomoharu", ""], ["Fujiwara", "Yasuhiro", ""]]}, {"id": "2002.12014", "submitter": "Andrey Kolobov", "authors": "Andrey Kolobov, S\\'ebastien Bubeck, Julian Zimmert", "title": "Online Learning for Active Cache Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-armed bandit (MAB) models make two implicit assumptions: an\narm generates a payoff only when it is played, and the agent observes every\npayoff that is generated. This paper introduces synchronization bandits, a MAB\nvariant where all arms generate costs at all times, but the agent observes an\narm's instantaneous cost only when the arm is played. Synchronization MABs are\ninspired by online caching scenarios such as Web crawling, where an arm\ncorresponds to a cached item and playing the arm means downloading its fresh\ncopy from a server. We present MirrorSync, an online learning algorithm for\nsynchronization bandits, establish an adversarial regret of $O(T^{2/3})$ for\nit, and show how to make it practical.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:10:44 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 08:49:53 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Kolobov", "Andrey", ""], ["Bubeck", "S\u00e9bastien", ""], ["Zimmert", "Julian", ""]]}, {"id": "2002.12017", "submitter": "SeongMin Kye", "authors": "Seong Min Kye, Hae Beom Lee, Hoirin Kim, and Sung Ju Hwang", "title": "Meta-Learned Confidence for Few-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transductive inference is an effective means of tackling the data deficiency\nproblem in few-shot learning settings. A popular transductive inference\ntechnique for few-shot metric-based approaches, is to update the prototype of\neach class with the mean of the most confident query examples, or\nconfidence-weighted average of all the query samples. However, a caveat here is\nthat the model confidence may be unreliable, which may lead to incorrect\npredictions. To tackle this issue, we propose to meta-learn the confidence for\neach query sample, to assign optimal weights to unlabeled queries such that\nthey improve the model's transductive inference performance on unseen tasks. We\nachieve this by meta-learning an input-adaptive distance metric over a task\ndistribution under various model and data perturbations, which will enforce\nconsistency on the model predictions under diverse uncertainties for unseen\ntasks. Moreover, we additionally suggest a regularization which explicitly\nenforces the consistency on the predictions across the different dimensions of\na high-dimensional embedding vector. We validate our few-shot learning model\nwith meta-learned confidence on four benchmark datasets, on which it largely\noutperforms strong recent baselines and obtains new state-of-the-art results.\nFurther application on semi-supervised few-shot learning tasks also yields\nsignificant performance improvements over the baselines. The source code of our\nalgorithm is available at https://github.com/seongmin-kye/MCT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:22:17 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:13:47 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Kye", "Seong Min", ""], ["Lee", "Hae Beom", ""], ["Kim", "Hoirin", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "2002.12018", "submitter": "Siqi Ye", "authors": "Siqi Ye, Yong Long, Il Yong Chun", "title": "Momentum-Net for Low-Dose CT Image Reconstruction", "comments": "Five pages conference paper. Accepted by 2020 Asilomar Conference on\n  Signals, Systems, and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies the recent fast iterative neural network framework,\nMomentum-Net, using appropriate models to low-dose X-ray computed tomography\n(LDCT) image reconstruction. At each layer of the proposed Momentum-Net, the\nmodel-based image reconstruction module solves the majorized penalized weighted\nleast-square problem, and the image refining module uses a four-layer\nconvolutional neural network (CNN). Experimental results with the NIH AAPM-Mayo\nClinic Low Dose CT Grand Challenge dataset show that the proposed Momentum-Net\narchitecture significantly improves image reconstruction accuracy, compared to\na state-of-the-art noniterative image denoising deep neural network (NN),\nWavResNet (in LDCT). We also investigated the spectral normalization technique\nthat applies to image refining NN learning to satisfy the nonexpansive NN\nproperty; however, experimental results show that this does not improve the\nimage reconstruction performance of Momentum-Net.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 10:26:22 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 01:34:59 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 12:30:16 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 02:02:16 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Ye", "Siqi", ""], ["Long", "Yong", ""], ["Chun", "Il Yong", ""]]}, {"id": "2002.12036", "submitter": "Francisco Javier Bald\\'an", "authors": "Francisco J. Bald\\'an and Jos\\'e M. Ben\\'itez", "title": "Complexity Measures and Features for Times Series classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of time series is a growing problem in different disciplines\ndue to the progressive digitalization of the world. Currently, the state of the\nart in time series classification is dominated by Collective of\nTransformation-Based Ensembles. This algorithm is composed of several\nclassifiers of diverse nature that are combined according to their results in\nan internal cross validation procedure. Its high complexity prevents it from\nbeing applied to large datasets. One Nearest Neighbours with Dynamic Time\nWarping remains the base classifier in any time series classification problem,\nfor its simplicity and good results. Despite their good performance, they share\na weakness, which is that they are not interpretable. In the field of time\nseries classification, there is a tradeoff between accuracy and\ninterpretability. In this work, we propose a set of characteristics capable of\nextracting information of the structure of the time series in order to face\ntime series classification problems. The use of these characteristics allows\nthe use of traditional classification algorithms in time series problems. The\nexperimental results demonstrate a statistically significant improvement in the\naccuracy of the results obtained by our proposal with respect to the original\ntime series. Apart from the improvement in accuracy, our proposal is able to\noffer interpretable results based on the set of characteristics proposed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 11:08:08 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:09:53 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Bald\u00e1n", "Francisco J.", ""], ["Ben\u00edtez", "Jos\u00e9 M.", ""]]}, {"id": "2002.12047", "submitter": "Ethan Harris", "authors": "Ethan Harris, Antonia Marcu, Matthew Painter, Mahesan Niranjan, Adam\n  Pr\\\"ugel-Bennett, Jonathon Hare", "title": "FMix: Enhancing Mixed Sample Data Augmentation", "comments": "Code available at https://github.com/ecs-vlc/FMix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Sample Data Augmentation (MSDA) has received increasing attention in\nrecent years, with many successful variants such as MixUp and CutMix. By\nstudying the mutual information between the function learned by a VAE on the\noriginal data and on the augmented data we show that MixUp distorts learned\nfunctions in a way that CutMix does not. We further demonstrate this by showing\nthat MixUp acts as a form of adversarial training, increasing robustness to\nattacks such as Deep Fool and Uniform Noise which produce examples similar to\nthose generated by MixUp. We argue that this distortion prevents models from\nlearning about sample specific features in the data, aiding generalisation\nperformance. In contrast, we suggest that CutMix works more like a traditional\naugmentation, improving performance by preventing memorisation without\ndistorting the data distribution. However, we argue that an MSDA which builds\non CutMix to include masks of arbitrary shape, rather than just square, could\nfurther prevent memorisation whilst preserving the data distribution in the\nsame way. To this end, we propose FMix, an MSDA that uses random binary masks\nobtained by applying a threshold to low frequency images sampled from Fourier\nspace. These random masks can take on a wide range of shapes and can be\ngenerated for use with one, two, and three dimensional data. FMix improves\nperformance over MixUp and CutMix, without an increase in training time, for a\nnumber of models across a range of data sets and problem settings, obtaining a\nnew single model state-of-the-art result on CIFAR-10 without external data.\nFinally, we show that a consequence of the difference between interpolating\nMSDA such as MixUp and masking MSDA such as FMix is that the two can be\ncombined to improve performance even further. Code for all experiments is\nprovided at https://github.com/ecs-vlc/FMix .\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 11:46:33 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 13:12:35 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 14:47:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Harris", "Ethan", ""], ["Marcu", "Antonia", ""], ["Painter", "Matthew", ""], ["Niranjan", "Mahesan", ""], ["Pr\u00fcgel-Bennett", "Adam", ""], ["Hare", "Jonathon", ""]]}, {"id": "2002.12054", "submitter": "Gholamreza Salimi-Khorshidi", "authors": "Danijela Horak, Simiao Yu, Gholamreza Salimi-Khorshidi", "title": "Topology Distance: A Topology-Based Approach For Evaluating Generative\n  Adversarial Networks", "comments": "Submitted to ICML 2020; 12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic evaluation of the goodness of Generative Adversarial Networks\n(GANs) has been a challenge for the field of machine learning. In this work, we\npropose a distance complementary to existing measures: Topology Distance (TD),\nthe main idea behind which is to compare the geometric and topological features\nof the latent manifold of real data with those of generated data. More\nspecifically, we build Vietoris-Rips complex on image features, and define TD\nbased on the differences in persistent-homology groups of the two manifolds. We\ncompare TD with the most commonly used and relevant measures in the field,\nincluding Inception Score (IS), Frechet Inception Distance (FID), Kernel\nInception Distance (KID) and Geometry Score (GS), in a range of experiments on\nvarious datasets. We demonstrate the unique advantage and superiority of our\nproposed approach over the aforementioned metrics. A combination of our\nempirical results and the theoretical argument we propose in favour of TD,\nstrongly supports the claim that TD is a powerful candidate metric that\nresearchers can employ when aiming to automatically evaluate the goodness of\nGANs' learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:06:41 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Horak", "Danijela", ""], ["Yu", "Simiao", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "2002.12056", "submitter": "Dalonng Zhang", "authors": "Dalong Zhang, Xianzheng Song, Ziqi Liu, Zhiqiang Zhang, Xin Huang, Lin\n  Wang, Jun Zhou", "title": "DSSLP: A Distributed Framework for Semi-supervised Link Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction is widely used in a variety of industrial applications, such\nas merchant recommendation, fraudulent transaction detection, and so on.\nHowever, it's a great challenge to train and deploy a link prediction model on\nindustrial-scale graphs with billions of nodes and edges. In this work, we\npresent a scalable and distributed framework for semi-supervised link\nprediction problem (named DSSLP), which is able to handle industrial-scale\ngraphs. Instead of training model on the whole graph, DSSLP is proposed to\ntrain on the \\emph{$k$-hops neighborhood} of nodes in a mini-batch setting,\nwhich helps reduce the scale of the input graph and distribute the training\nprocedure. In order to generate negative examples effectively, DSSLP contains a\ndistributed batched runtime sampling module. It implements uniform and dynamic\nsampling approaches, and is able to adaptively construct positive and negative\nexamples to guide the training process. Moreover, DSSLP proposes a model-split\nstrategy to accelerate the speed of inference process of the link prediction\ntask. Experimental results demonstrate that the effectiveness and efficiency of\nDSSLP in serval public datasets as well as real-world datasets of\nindustrial-scale graphs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:11:37 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 14:45:50 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Dalong", ""], ["Song", "Xianzheng", ""], ["Liu", "Ziqi", ""], ["Zhang", "Zhiqiang", ""], ["Huang", "Xin", ""], ["Wang", "Lin", ""], ["Zhou", "Jun", ""]]}, {"id": "2002.12062", "submitter": "Jiacheng Li", "authors": "Jiacheng Li, Ninghui Li, Bruno Ribeiro", "title": "Membership Inference Attacks and Defenses in Classification Models", "comments": null, "journal-ref": null, "doi": "10.1145/3422337.3447836", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the membership inference (MI) attack against classifiers, where the\nattacker's goal is to determine whether a data instance was used for training\nthe classifier. Through systematic cataloging of existing MI attacks and\nextensive experimental evaluations of them, we find that a model's\nvulnerability to MI attacks is tightly related to the generalization gap -- the\ndifference between training accuracy and test accuracy. We then propose a\ndefense against MI attacks that aims to close the gap by intentionally reduces\nthe training accuracy. More specifically, the training process attempts to\nmatch the training and validation accuracies, by means of a new {\\em set\nregularizer} using the Maximum Mean Discrepancy between the softmax output\nempirical distributions of the training and validation sets. Our experimental\nresults show that combining this approach with another simple defense (mix-up\ntraining) significantly improves state-of-the-art defense against MI attacks,\nwith minimal impact on testing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:35:36 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 03:53:24 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 01:43:20 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Li", "Jiacheng", ""], ["Li", "Ninghui", ""], ["Ribeiro", "Bruno", ""]]}, {"id": "2002.12078", "submitter": "Sampo Kuutti", "authors": "Sampo Kuutti, Saber Fallah, Richard Bowden", "title": "Training Adversarial Agents to Exploit Weaknesses in Deep Control\n  Policies", "comments": "2020 IEEE International Conference on Robotics and Automation (ICRA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become an increasingly common technique for various control\nproblems, such as robotic arm manipulation, robot navigation, and autonomous\nvehicles. However, the downside of using deep neural networks to learn control\npolicies is their opaque nature and the difficulties of validating their\nsafety. As the networks used to obtain state-of-the-art results become\nincreasingly deep and complex, the rules they have learned and how they operate\nbecome more challenging to understand. This presents an issue, since in\nsafety-critical applications the safety of the control policy must be ensured\nto a high confidence level. In this paper, we propose an automated black box\ntesting framework based on adversarial reinforcement learning. The technique\nuses an adversarial agent, whose goal is to degrade the performance of the\ntarget model under test. We test the approach on an autonomous vehicle problem,\nby training an adversarial reinforcement learning agent, which aims to cause a\ndeep neural network-driven autonomous vehicle to collide. Two neural networks\ntrained for autonomous driving are compared, and the results from the testing\nare used to compare the robustness of their learned control policies. We show\nthat the proposed framework is able to find weaknesses in both control policies\nthat were not evident during online testing and therefore, demonstrate a\nsignificant benefit over manual testing methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:14:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kuutti", "Sampo", ""], ["Fallah", "Saber", ""], ["Bowden", "Richard", ""]]}, {"id": "2002.12086", "submitter": "Jiri Vahala", "authors": "Tomas Brazdil, Krishnendu Chatterjee, Petr Novotny, Jiri Vahala", "title": "Reinforcement Learning of Risk-Constrained Policies in Markov Decision\n  Processes", "comments": "Published on AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDPs) are the defacto frame-work for sequential\ndecision making in the presence ofstochastic uncertainty. A classical\noptimization criterion forMDPs is to maximize the expected discounted-sum\npay-off, which ignores low probability catastrophic events withhighly negative\nimpact on the system. On the other hand,risk-averse policies require the\nprobability of undesirableevents to be below a given threshold, but they do not\naccountfor optimization of the expected payoff. We consider MDPswith\ndiscounted-sum payoff with failure states which repre-sent catastrophic\noutcomes. The objective of risk-constrainedplanning is to maximize the expected\ndiscounted-sum payoffamong risk-averse policies that ensure the probability to\nen-counter a failure state is below a desired threshold. Our maincontribution\nis an efficient risk-constrained planning algo-rithm that combines UCT-like\nsearch with a predictor learnedthrough interaction with the MDP (in the style\nof AlphaZero)and with a risk-constrained action selection via linear\npro-gramming. We demonstrate the effectiveness of our approachwith experiments\non classical MDPs from the literature, in-cluding benchmarks with an order of\n10^6 states.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:36:36 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Brazdil", "Tomas", ""], ["Chatterjee", "Krishnendu", ""], ["Novotny", "Petr", ""], ["Vahala", "Jiri", ""]]}, {"id": "2002.12104", "submitter": "Hamid Usefi", "authors": "Majid Afshar, Hamid Usefi", "title": "High-Dimensional Feature Selection for Genomic Datasets", "comments": null, "journal-ref": "August 2020, Knowledge-Based Systems 206(4):106370", "doi": "10.1016/j.knosys.2020.106370", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in machine learning and pattern recognition is the process\nof recognizing the most important features. In this paper, we provide a new\nfeature selection method (DRPT) that consists of first removing the irrelevant\nfeatures and then detecting correlations between the remaining features. Let\n$D=[A\\mid \\mathbf{b}]$ be a dataset, where $\\mathbf{b}$ is the class label and\n$A$ is a matrix whose columns are the features. We solve $A\\mathbf{x} =\n\\mathbf{b}$ using the least squares method and the pseudo-inverse of $A$. Each\ncomponent of $\\mathbf{x}$ can be viewed as an assigned weight to the\ncorresponding column (feature). We define a threshold based on the local maxima\nof $\\mathbf{x}$ and remove those features whose weights are smaller than the\nthreshold.\n  To detect the correlations in the reduced matrix, which we still call $A$, we\nconsider a perturbation $\\tilde A$ of $A$. We prove that correlations are\nencoded in $\\Delta\\mathbf{x}=\\mid \\mathbf{x} -\\tilde{\\mathbf{x}}\\mid $, where\n$\\tilde{\\mathbf{x}}$ is the least quares solution of\n  $\\tilde A\\tilde{\\mathbf{x}}=\\mathbf{b}$. We cluster features first based on\n$\\Delta\\mathbf{x}$ and then using the entropy of features. Finally, a feature\nis selected from each sub-cluster based on its weight and entropy. The\neffectiveness of DRPT has been verified by performing a series of comparisons\nwith seven state-of-the-art feature selection methods over ten genetic datasets\nranging up from 9,117 to 267,604 features. The results show that, over all, the\nperformance of DRPT is favorable in several aspects compared to each feature\nselection algorithm.\n  \\e\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 14:17:39 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:00:02 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Afshar", "Majid", ""], ["Usefi", "Hamid", ""]]}, {"id": "2002.12133", "submitter": "Aritz D. Martinez", "authors": "Aritz D. Martinez, Eneko Osaba, Javier Del Ser and Francisco Herrera", "title": "Simultaneously Evolving Deep Reinforcement Learning Models using\n  Multifactorial Optimization", "comments": "8 pages, 5 figures, submitted to IEEE Conference on Evolutionary\n  Computation 2020 (IEEE CEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Multifactorial Optimization (MFO) has gained a notable\nmomentum in the research community. MFO is known for its inherent capability to\nefficiently address multiple optimization tasks at the same time, while\ntransferring information among such tasks to improve their convergence speed.\nOn the other hand, the quantum leap made by Deep Q Learning (DQL) in the\nMachine Learning field has allowed facing Reinforcement Learning (RL) problems\nof unprecedented complexity. Unfortunately, complex DQL models usually find it\ndifficult to converge to optimal policies due to the lack of exploration or\nsparse rewards. In order to overcome these drawbacks, pre-trained models are\nwidely harnessed via Transfer Learning, extrapolating knowledge acquired in a\nsource task to the target task. Besides, meta-heuristic optimization has been\nshown to reduce the lack of exploration of DQL models. This work proposes a MFO\nframework capable of simultaneously evolving several DQL models towards solving\ninterrelated RL tasks. Specifically, our proposed framework blends together the\nbenefits of meta-heuristic optimization, Transfer Learning and DQL to automate\nthe process of knowledge transfer and policy learning of distributed RL agents.\nA thorough experimentation is presented and discussed so as to assess the\nperformance of the framework, its comparison to the traditional methodology for\nTransfer Learning in terms of convergence, speed and policy quality , and the\nintertask relationships found and exploited over the search process.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 10:36:57 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 10:47:41 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Martinez", "Aritz D.", ""], ["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2002.12135", "submitter": "Jiajun Cai", "authors": "Qiquan Shi, Jiaming Yin, Jiajun Cai, Andrzej Cichocki, Tatsuya Yokota,\n  Lei Chen, Mingxuan Yuan, Jia Zeng", "title": "Block Hankel Tensor ARIMA for Multiple Short Time Series Forecasting", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel approach for multiple time series forecasting. At\nfirst, multi-way delay embedding transform (MDT) is employed to represent time\nseries as low-rank block Hankel tensors (BHT). Then, the higher-order tensors\nare projected to compressed core tensors by applying Tucker decomposition. At\nthe same time, the generalized tensor Autoregressive Integrated Moving Average\n(ARIMA) is explicitly used on consecutive core tensors to predict future\nsamples. In this manner, the proposed approach tactically incorporates the\nunique advantages of MDT tensorization (to exploit mutual correlations) and\ntensor ARIMA coupled with low-rank Tucker decomposition into a unified\nframework. This framework exploits the low-rank structure of block Hankel\ntensors in the embedded space and captures the intrinsic correlations among\nmultiple TS, which thus can improve the forecasting results, especially for\nmultiple short time series. Experiments conducted on three public datasets and\ntwo industrial datasets verify that the proposed BHT-ARIMA effectively improves\nforecasting accuracy and reduces computational cost compared with the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 11:29:56 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Shi", "Qiquan", ""], ["Yin", "Jiaming", ""], ["Cai", "Jiajun", ""], ["Cichocki", "Andrzej", ""], ["Yokota", "Tatsuya", ""], ["Chen", "Lei", ""], ["Yuan", "Mingxuan", ""], ["Zeng", "Jia", ""]]}, {"id": "2002.12143", "submitter": "Ramanujam Madhavan", "authors": "Ramanujam Madhavan, Mohit Wadhwa", "title": "Fairness-Aware Learning with Prejudice Free Representations", "comments": null, "journal-ref": null, "doi": "10.1145/3340531", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are extensively being used to make decisions that\nhave a significant impact on human life. These models are trained over\nhistorical data that may contain information about sensitive attributes such as\nrace, sex, religion, etc. The presence of such sensitive attributes can impact\ncertain population subgroups unfairly. It is straightforward to remove\nsensitive features from the data; however, a model could pick up prejudice from\nlatent sensitive attributes that may exist in the training data. This has led\nto the growing apprehension about the fairness of the employed models. In this\npaper, we propose a novel algorithm that can effectively identify and treat\nlatent discriminating features. The approach is agnostic of the learning\nalgorithm and generalizes well for classification as well as regression tasks.\nIt can also be used as a key aid in proving that the model is free of\ndiscrimination towards regulatory compliance if the need arises. The approach\nhelps to collect discrimination-free features that would improve the model\nperformance while ensuring the fairness of the model. The experimental results\nfrom our evaluations on publicly available real-world datasets show a\nnear-ideal fairness measurement in comparison to other methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:06:31 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Madhavan", "Ramanujam", ""], ["Wadhwa", "Mohit", ""]]}, {"id": "2002.12144", "submitter": "George Cevora", "authors": "George Cevora", "title": "Fair Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The influence of human judgement is ubiquitous in datasets used across the\nanalytics industry, yet humans are known to be sub-optimal decision makers\nprone to various biases. Analysing biased datasets then leads to biased\noutcomes of the analysis. Bias by protected characteristics (e.g. race) is of\nparticular interest as it may not only make the output of analytical process\nsub-optimal, but also illegal. Countering the bias by constraining the\nanalytical outcomes to be fair is problematic because A) fairness lacks a\nuniversally accepted definition, while at the same time some definitions are\nmutually exclusive, and B) the use of optimisation constraints ensuring\nfairness is incompatible with most analytical pipelines. Both problems are\nsolved by methods which remove bias from the data and returning an altered\ndataset. This approach aims to not only remove the actual bias variable (e.g.\nrace), but also alter all proxy variables (e.g. postcode) so the bias variable\nis not detectable from the rest of the data. The advantage of using this\napproach is that the definition of fairness as a lack of detectable bias in the\ndata (as opposed to the output of analysis) is universal and therefore solves\nproblem (A). Furthermore, as the data is altered to remove bias the problem (B)\ndisappears because the analytical pipelines can remain unchanged. This approach\nhas been adopted by several technical solutions. None of them, however, seems\nto be satisfactory in terms of ability to remove multivariate, non-linear and\nnon-binary biases. Therefore, in this paper I propose the concept of Fair\nAdversarial Networks as an easy-to-implement general method for removing bias\nfrom data. This paper demonstrates that Fair Adversarial Networks achieve this\naim.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 16:39:38 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Cevora", "George", ""]]}, {"id": "2002.12156", "submitter": "Mohammadhosein Hasanbeig", "authors": "Mohammadhosein Hasanbeig, Alessandro Abate, Daniel Kroening", "title": "Cautious Reinforcement Learning with Logical Constraints", "comments": "Accepted to AAMAS 2020. arXiv admin note: text overlap with\n  arXiv:1902.00778", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concept of an adaptive safe padding that forces\nReinforcement Learning (RL) to synthesise optimal control policies while\nensuring safety during the learning process. Policies are synthesised to\nsatisfy a goal, expressed as a temporal logic formula, with maximal\nprobability. Enforcing the RL agent to stay safe during learning might limit\nthe exploration, however we show that the proposed architecture is able to\nautomatically handle the trade-off between efficient progress in exploration\n(towards goal satisfaction) and ensuring safety. Theoretical guarantees are\navailable on the optimality of the synthesised policies and on the convergence\nof the learning algorithm. Experimental results are provided to showcase the\nperformance of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 00:01:08 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2020 10:26:21 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Hasanbeig", "Mohammadhosein", ""], ["Abate", "Alessandro", ""], ["Kroening", "Daniel", ""]]}, {"id": "2002.12158", "submitter": "Sungwon Han", "authors": "Sungwon Han, Yizhan Xu, Sungwon Park, Meeyoung Cha, Cheng-Te Li", "title": "A Comprehensive Approach to Unsupervised Embedding Learning based on AND\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised embedding learning aims to extract good representation from data\nwithout the need for any manual labels, which has been a critical challenge in\nmany supervised learning tasks. This paper proposes a new unsupervised\nembedding approach, called Super-AND, which extends the current\nstate-of-the-art model. Super-AND has its unique set of losses that can gather\nsimilar samples nearby within a low-density space while keeping invariant\nfeatures intact against data augmentation. Super-AND outperforms all existing\napproaches and achieves an accuracy of 89.2% on the image classification task\nfor CIFAR-10. We discuss the practical implications of this method in assisting\nsemi-supervised tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 13:22:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Han", "Sungwon", ""], ["Xu", "Yizhan", ""], ["Park", "Sungwon", ""], ["Cha", "Meeyoung", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2002.12162", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Sijia Liu, Pin-Yu Chen, Pu Zhao, Xue Lin", "title": "Defending against Backdoor Attack on Deep Neural Networks", "comments": "This workshop manuscript is not a publication and will not be\n  published anywhere", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks (DNNs) have achieved a great success in various\ncomputer vision tasks, it is recently found that they are vulnerable to\nadversarial attacks. In this paper, we focus on the so-called \\textit{backdoor\nattack}, which injects a backdoor trigger to a small portion of training data\n(also known as data poisoning) such that the trained DNN induces\nmisclassification while facing examples with this trigger. To be specific, we\ncarefully study the effect of both real and synthetic backdoor attacks on the\ninternal response of vanilla and backdoored DNNs through the lens of Gard-CAM.\nMoreover, we show that the backdoor attack induces a significant bias in neuron\nactivation in terms of the $\\ell_\\infty$ norm of an activation map compared to\nits $\\ell_1$ and $\\ell_2$ norm. Spurred by our results, we propose the\n\\textit{$\\ell_\\infty$-based neuron pruning} to remove the backdoor from the\nbackdoored DNN. Experiments show that our method could effectively decrease the\nattack success rate, and also hold a high classification accuracy for clean\nimages.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 02:03:00 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:13:32 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Xu", "Kaidi", ""], ["Liu", "Sijia", ""], ["Chen", "Pin-Yu", ""], ["Zhao", "Pu", ""], ["Lin", "Xue", ""]]}, {"id": "2002.12164", "submitter": "Varun Mannam", "authors": "Varun Mannam, Arman Kazemi", "title": "Performance Analysis of Semi-supervised Learning in the Small-data\n  Regime using VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extracting large amounts of data from biological samples is not feasible due\nto radiation issues, and image processing in the small-data regime is one of\nthe critical challenges when working with a limited amount of data. In this\nwork, we applied an existing algorithm named Variational Auto Encoder (VAE)\nthat pre-trains a latent space representation of the data to capture the\nfeatures in a lower-dimension for the small-data regime input. The fine-tuned\nlatent space provides constant weights that are useful for classification. Here\nwe will present the performance analysis of the VAE algorithm with different\nlatent space sizes in the semi-supervised learning using the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:19:54 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 19:50:39 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mannam", "Varun", ""], ["Kazemi", "Arman", ""]]}, {"id": "2002.12168", "submitter": "Jilin Hu", "authors": "Jilin Hu, Jianbing Shen, Bin Yang, Ling Shao", "title": "Infinitely Wide Graph Convolutional Networks: Semi-supervised Learning\n  via Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks~(GCNs) have recently demonstrated\npromising results on graph-based semi-supervised classification, but little\nwork has been done to explore their theoretical properties. Recently, several\ndeep neural networks, e.g., fully connected and convolutional neural networks,\nwith infinite hidden units have been proved to be equivalent to Gaussian\nprocesses~(GPs). To exploit both the powerful representational capacity of GCNs\nand the great expressive power of GPs, we investigate similar properties of\ninfinitely wide GCNs. More specifically, we propose a GP regression model via\nGCNs~(GPGC) for graph-based semi-supervised learning. In the process, we\nformulate the kernel matrix computation of GPGC in an iterative analytical\nform. Finally, we derive a conditional distribution for the labels of\nunobserved nodes based on the graph structure, labels for the observed nodes,\nand the feature matrix of all the nodes. We conduct extensive experiments to\nevaluate the semi-supervised classification performance of GPGC and demonstrate\nthat it outperforms other state-of-the-art methods by a clear margin on all the\ndatasets while being efficient.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 10:02:32 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Hu", "Jilin", ""], ["Shen", "Jianbing", ""], ["Yang", "Bin", ""], ["Shao", "Ling", ""]]}, {"id": "2002.12169", "submitter": "Sicheng Zhao", "authors": "Sicheng Zhao, Bo Li, Colorado Reed, Pengfei Xu, Kurt Keutzer", "title": "Multi-source Domain Adaptation in the Deep Learning Era: A Systematic\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical applications, it is often difficult and expensive to obtain\nenough large-scale labeled data to train deep neural networks to their full\ncapability. Therefore, transferring the learned knowledge from a separate,\nlabeled source domain to an unlabeled or sparsely labeled target domain becomes\nan appealing alternative. However, direct transfer often results in significant\nperformance decay due to domain shift. Domain adaptation (DA) addresses this\nproblem by minimizing the impact of domain shift between the source and target\ndomains. Multi-source domain adaptation (MDA) is a powerful extension in which\nthe labeled data may be collected from multiple sources with different\ndistributions. Due to the success of DA methods and the prevalence of\nmulti-source data, MDA has attracted increasing attention in both academia and\nindustry. In this survey, we define various MDA strategies and summarize\navailable datasets for evaluation. We also compare modern MDA methods in the\ndeep learning era, including latent space transformation and intermediate\ndomain generation. Finally, we discuss future research directions for MDA.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 08:07:58 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhao", "Sicheng", ""], ["Li", "Bo", ""], ["Reed", "Colorado", ""], ["Xu", "Pengfei", ""], ["Keutzer", "Kurt", ""]]}, {"id": "2002.12173", "submitter": "Eric Adjakossa", "authors": "Eric Adjakossa (LPSM), Yannig Goude (EDF R&D), Olivier Wintenberger\n  (LPSM UMR)", "title": "Kalman Recursions Aggregated Online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we aim at improving the prediction of expert aggregation by\nusing the underlying properties of the models that provide expert predictions.\nWe restrict ourselves to the case where expert predictions come from Kalman\nrecursions, fitting state-space models. By using exponential weights, we\nconstruct different algorithms of Kalman recursions Aggregated Online (KAO)\nthat compete with the best expert or the best convex combination of experts in\na more or less adaptive way. We improve the existing results on expert\naggregation literature when the experts are Kalman recursions by taking\nadvantage of the second-order properties of the Kalman recursions. We apply our\napproach to Kalman recursions and extend it to the general adversarial expert\nsetting by state-space modeling the errors of the experts. We apply these new\nalgorithms to a real dataset of electricity consumption and show how it can\nimprove forecast performances comparing to other exponentially weighted average\nprocedures.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 14:53:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adjakossa", "Eric", "", "LPSM"], ["Goude", "Yannig", "", "EDF R&D"], ["Wintenberger", "Olivier", "", "LPSM UMR"]]}, {"id": "2002.12174", "submitter": "Bei Peng", "authors": "Tabish Rashid, Bei Peng, Wendelin B\\\"ohmer, Shimon Whiteson", "title": "Optimistic Exploration even with a Pessimistic Initialisation", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimistic initialisation is an effective strategy for efficient exploration\nin reinforcement learning (RL). In the tabular case, all provably efficient\nmodel-free algorithms rely on it. However, model-free deep RL algorithms do not\nuse optimistic initialisation despite taking inspiration from these provably\nefficient tabular algorithms. In particular, in scenarios with only positive\nrewards, Q-values are initialised at their lowest possible values due to\ncommonly used network initialisation schemes, a pessimistic initialisation.\nMerely initialising the network to output optimistic Q-values is not enough,\nsince we cannot ensure that they remain optimistic for novel state-action\npairs, which is crucial for exploration. We propose a simple count-based\naugmentation to pessimistically initialised Q-values that separates the source\nof optimism from the neural network. We show that this scheme is provably\nefficient in the tabular setting and extend it to the deep RL setting. Our\nalgorithm, Optimistic Pessimistically Initialised Q-Learning (OPIQ), augments\nthe Q-value estimates of a DQN-based agent with count-derived bonuses to ensure\noptimism during both action selection and bootstrapping. We show that OPIQ\noutperforms non-optimistic DQN variants that utilise a pseudocount-based\nintrinsic motivation in hard exploration tasks, and that it predicts optimistic\nestimates for novel state-action pairs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:15:53 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Rashid", "Tabish", ""], ["Peng", "Bei", ""], ["B\u00f6hmer", "Wendelin", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2002.12177", "submitter": "Aj Piergiovanni", "authors": "AJ Piergiovanni, Anelia Angelova, Michael S. Ryoo", "title": "Evolving Losses for Unsupervised Video Representation Learning", "comments": "arXiv admin note: text overlap with arXiv:1906.03248", "journal-ref": "CVPR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method to learn video representations from large-scale\nunlabeled video data. Ideally, this representation will be generic and\ntransferable, directly usable for new tasks such as action recognition and zero\nor few-shot learning. We formulate unsupervised representation learning as a\nmulti-modal, multi-task learning problem, where the representations are shared\nacross different modalities via distillation. Further, we introduce the concept\nof loss function evolution by using an evolutionary search algorithm to\nautomatically find optimal combination of loss functions capturing many\n(self-supervised) tasks and modalities. Thirdly, we propose an unsupervised\nrepresentation evaluation metric using distribution matching to a large\nunlabeled dataset as a prior constraint, based on Zipf's law. This unsupervised\nconstraint, which is not guided by any labeling, produces similar results to\nweakly-supervised, task-specific ones. The proposed unsupervised representation\nlearning results in a single RGB network and outperforms previous methods.\nNotably, it is also more effective than several label-based methods (e.g.,\nImageNet), with the exception of large, fully labeled video datasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 16:56:07 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Piergiovanni", "AJ", ""], ["Angelova", "Anelia", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "2002.12207", "submitter": "Toshiaki Tsuji", "authors": "Masahide Oikawa, Kyo Kutsuzawa, Sho Sakaino, Toshiaki Tsuji", "title": "Assembly robots with optimized control stiffness through reinforcement\n  learning", "comments": "Under review at the IEEE Robotics Automation Letter (RAL) and the\n  IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increased demand for task automation in robots. Contact-rich\ntasks, wherein multiple contact transitions occur in a series of operations,\nare extensively being studied to realize high accuracy. In this study, we\npropose a methodology that uses reinforcement learning (RL) to achieve high\nperformance in robots for the execution of assembly tasks that require precise\ncontact with objects without causing damage. The proposed method ensures the\nonline generation of stiffness matrices that help improve the performance of\nlocal trajectory optimization. The method has an advantage of rapid response\nowing to short sampling time of the trajectory planning. The effectiveness of\nthe method was verified via experiments involving two contact-rich tasks. The\nresults indicate that the proposed method can be implemented in various\ncontact-rich manipulations. A demonstration video shows the performance.\n(https://youtu.be/gxSCl7Tp4-0)\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:54:43 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Oikawa", "Masahide", ""], ["Kutsuzawa", "Kyo", ""], ["Sakaino", "Sho", ""], ["Tsuji", "Toshiaki", ""]]}, {"id": "2002.12211", "submitter": "Krzysztof Fiok", "authors": "Krzysztof Fiok (1), Waldemar Karwowski (1), Maciej Wilamowski (2) ((1)\n  University of Central Florida, Department of Industrial Engineering and\n  Management Systems, Orlando, Florida, USA (2) University of Warsaw, Faculty\n  of Economic Sciences, Warsaw, Poland)", "title": "Prediction of adverse events in Afghanistan: regression analysis of time\n  series data grouped not by geographic dependencies", "comments": "10 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study was to approach a difficult regression task on highly\nunbalanced data regarding active theater of war in Afghanistan. Our focus was\nset on predicting the negative events number without distinguishing precise\nnature of the events given historical data on investment and negative events\nper each of predefined 400 Afghanistan districts. In contrast with previous\nresearch on the matter, we propose an approach to analysis of time series data\nthat benefits from non-conventional aggregation of these territorial entities.\nBy carrying out initial exploratory data analysis we demonstrate that dividing\ndata according to our proposal allows to identify strong trend and seasonal\ncomponents in the selected target variable. Utilizing this approach we also\ntried to estimate which data regarding investments is most important for\nprediction performance. Based on our exploratory analysis and previous research\nwe prepared 5 sets of independent variables that were fed to 3 machine learning\nregression models. The results expressed by mean absolute and mean square\nerrors indicate that leveraging historical data regarding target variable\nallows for reasonable performance, however unfortunately other proposed\nindependent variables does not seem to improve prediction quality.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 15:58:51 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Fiok", "Krzysztof", ""], ["Karwowski", "Waldemar", ""], ["Wilamowski", "Maciej", ""]]}, {"id": "2002.12222", "submitter": "Yue Zhao", "authors": "Yue Zhao, Yuwei Wu, Caihua Chen, Andrew Lim", "title": "On Isometry Robustness of Deep 3D Point Cloud Models under Adversarial\n  Attacks", "comments": "This paper was accepted for presentation at CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning in 3D domain has achieved revolutionary performance in\nmany tasks, the robustness of these models has not been sufficiently studied or\nexplored. Regarding the 3D adversarial samples, most existing works focus on\nmanipulation of local points, which may fail to invoke the global geometry\nproperties, like robustness under linear projection that preserves the\nEuclidean distance, i.e., isometry. In this work, we show that existing\nstate-of-the-art deep 3D models are extremely vulnerable to isometry\ntransformations. Armed with the Thompson Sampling, we develop a black-box\nattack with success rate over 95% on ModelNet40 data set. Incorporating with\nthe Restricted Isometry Property, we propose a novel framework of white-box\nattack on top of spectral norm based perturbation. In contrast to previous\nworks, our adversarial samples are experimentally shown to be strongly\ntransferable. Evaluated on a sequence of prevailing 3D models, our white-box\nattack achieves success rates from 98.88% to 100%. It maintains a successful\nattack rate over 95% even within an imperceptible rotation range $[\\pm\n2.81^{\\circ}]$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:11:22 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 10:35:50 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhao", "Yue", ""], ["Wu", "Yuwei", ""], ["Chen", "Caihua", ""], ["Lim", "Andrew", ""]]}, {"id": "2002.12229", "submitter": "You Lu", "authors": "You Lu, Bert Huang", "title": "Woodbury Transformations for Deep Generative Flows", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normalizing flows are deep generative models that allow efficient likelihood\ncalculation and sampling. The core requirement for this advantage is that they\nare constructed using functions that can be efficiently inverted and for which\nthe determinant of the function's Jacobian can be efficiently computed.\nResearchers have introduced various such flow operations, but few of these\nallow rich interactions among variables without incurring significant\ncomputational costs. In this paper, we introduce Woodbury transformations,\nwhich achieve efficient invertibility via the Woodbury matrix identity and\nefficient determinant calculation via Sylvester's determinant identity. In\ncontrast with other operations used in state-of-the-art normalizing flows,\nWoodbury transformations enable (1) high-dimensional interactions, (2)\nefficient sampling, and (3) efficient likelihood evaluation. Other similar\noperations, such as 1x1 convolutions, emerging convolutions, or periodic\nconvolutions allow at most two of these three advantages. In our experiments on\nmultiple image datasets, we find that Woodbury transformations allow learning\nof higher-likelihood models than other flow architectures while still enjoying\ntheir efficiency advantages.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:21:43 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 01:56:52 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 15:22:26 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Lu", "You", ""], ["Huang", "Bert", ""]]}, {"id": "2002.12242", "submitter": "Zakaria Mhammedi", "authors": "Zakaria Mhammedi, Wouter M. Koolen", "title": "Lipschitz and Comparator-Norm Adaptivity in Online Learning", "comments": "30 Pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Online Convex Optimization in the unbounded setting where neither\npredictions nor gradient are constrained. The goal is to simultaneously adapt\nto both the sequence of gradients and the comparator. We first develop\nparameter-free and scale-free algorithms for a simplified setting with hints.\nWe present two versions: the first adapts to the squared norms of both\ncomparator and gradients separately using $O(d)$ time per round, the second\nadapts to their squared inner products (which measure variance only in the\ncomparator direction) in time $O(d^3)$ per round. We then generalize two prior\nreductions to the unbounded setting; one to not need hints, and a second to\ndeal with the range ratio problem (which already arises in prior work). We\ndiscuss their optimality in light of prior and new lower bounds. We apply our\nmethods to obtain sharper regret bounds for scale-invariant online prediction\nwith linear models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:42:41 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 14:14:05 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mhammedi", "Zakaria", ""], ["Koolen", "Wouter M.", ""]]}, {"id": "2002.12247", "submitter": "Spyros Gidaris", "authors": "Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick P\\'erez,\n  Matthieu Cord", "title": "Learning Representations by Predicting Bags of Visual Words", "comments": "Accepted to CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning targets to learn convnet-based image\nrepresentations from unlabeled data. Inspired by the success of NLP methods in\nthis area, in this work we propose a self-supervised approach based on\nspatially dense image descriptions that encode discrete visual concepts, here\ncalled visual words. To build such discrete representations, we quantize the\nfeature maps of a first pre-trained self-supervised convnet, over a k-means\nbased vocabulary. Then, as a self-supervised task, we train another convnet to\npredict the histogram of visual words of an image (i.e., its Bag-of-Words\nrepresentation) given as input a perturbed version of that image. The proposed\ntask forces the convnet to learn perturbation-invariant and context-aware image\nfeatures, useful for downstream image understanding tasks. We extensively\nevaluate our method and demonstrate very strong empirical results, e.g., our\npre-trained self-supervised representations transfer better on detection task\nand similarly on classification over classes \"unseen\" during pre-training, when\ncompared to the supervised case.\n  This also shows that the process of image discretization into visual words\ncan provide the basis for very powerful self-supervised approaches in the image\ndomain, thus allowing further connections to be made to related methods from\nthe NLP domain that have been extremely successful so far.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:45:25 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Gidaris", "Spyros", ""], ["Bursuc", "Andrei", ""], ["Komodakis", "Nikos", ""], ["P\u00e9rez", "Patrick", ""], ["Cord", "Matthieu", ""]]}, {"id": "2002.12253", "submitter": "Maxim Panov", "authors": "Achille Thin, Nikita Kotelevskii, Jean-Stanislas Denain, Leo\n  Grinsztajn, Alain Durmus, Maxim Panov and Eric Moulines", "title": "MetFlow: A New Efficient Method for Bridging the Gap between Markov\n  Chain Monte Carlo and Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we propose a new computationally efficient method to\ncombine Variational Inference (VI) with Markov Chain Monte Carlo (MCMC). This\napproach can be used with generic MCMC kernels, but is especially well suited\nto \\textit{MetFlow}, a novel family of MCMC algorithms we introduce, in which\nproposals are obtained using Normalizing Flows. The marginal distribution\nproduced by such MCMC algorithms is a mixture of flow-based distributions, thus\ndrastically increasing the expressivity of the variational family. Unlike\nprevious methods following this direction, our approach is amenable to the\nreparametrization trick and does not rely on computationally expensive reverse\nkernels. Extensive numerical experiments show clear computational and\nperformance improvements over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:50:30 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Thin", "Achille", ""], ["Kotelevskii", "Nikita", ""], ["Denain", "Jean-Stanislas", ""], ["Grinsztajn", "Leo", ""], ["Durmus", "Alain", ""], ["Panov", "Maxim", ""], ["Moulines", "Eric", ""]]}, {"id": "2002.12256", "submitter": "Richard Wang", "authors": "Usman Sajid, Hasan Sajid, Hongcheng Wang, Guanghui Wang", "title": "ZoomCount: A Zooming Mechanism for Crowd Counting in Static Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach for crowd counting in low to high\ndensity scenarios in static images. Current approaches cannot handle huge crowd\ndiversity well and thus perform poorly in extreme cases, where the crowd\ndensity in different regions of an image is either too low or too high, leading\nto crowd underestimation or overestimation. The proposed solution is based on\nthe observation that detecting and handling such extreme cases in a specialized\nway leads to better crowd estimation. Additionally, existing methods find it\nhard to differentiate between the actual crowd and the cluttered background\nregions, resulting in further count overestimation. To address these issues, we\npropose a simple yet effective modular approach, where an input image is first\nsubdivided into fixed-size patches and then fed to a four-way classification\nmodule labeling each image patch as low, medium, high-dense or no-crowd. This\nmodule also provides a count for each label, which is then analyzed via a\nspecifically devised novel decision module to decide whether the image belongs\nto any of the two extreme cases (very low or very high density) or a normal\ncase. Images, specified as high- or low-density extreme or a normal case, pass\nthrough dedicated zooming or normal patch-making blocks respectively before\nrouting to the regressor in the form of fixed-size patches for crowd estimate.\nExtensive experimental evaluations demonstrate that the proposed approach\noutperforms the state-of-the-art methods on four benchmarks under most of the\nevaluation criteria.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:57:04 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sajid", "Usman", ""], ["Sajid", "Hasan", ""], ["Wang", "Hongcheng", ""], ["Wang", "Guanghui", ""]]}, {"id": "2002.12257", "submitter": "Joel Brogan", "authors": "Max Ruby, David S. Bolme, Joel Brogan, David Cornett III, Baldemar\n  Delgado, Gavin Jager, Christi Johnson, Jose Martinez-Mendoza, Hector\n  Santos-Villalobos, Nisha Srinivas", "title": "The Mertens Unrolled Network (MU-Net): A High Dynamic Range Fusion\n  Neural Network for Through the Windshield Driver Recognition", "comments": "Accepted to SPEI Autonomous Systems: Sensors, Processing and Security\n  for Vehicles & Infrastructure 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Face recognition of vehicle occupants through windshields in unconstrained\nenvironments poses a number of unique challenges ranging from glare, poor\nillumination, driver pose and motion blur. In this paper, we further develop\nthe hardware and software components of a custom vehicle imaging system to\nbetter overcome these challenges. After the build out of a physical prototype\nsystem that performs High Dynamic Range (HDR) imaging, we collect a small\ndataset of through-windshield image captures of known drivers. We then\nre-formulate the classical Mertens-Kautz-Van Reeth HDR fusion algorithm as a\npre-initialized neural network, which we name the Mertens Unrolled Network\n(MU-Net), for the purpose of fine-tuning the HDR output of through-windshield\nimages. Reconstructed faces from this novel HDR method are then evaluated and\ncompared against other traditional and experimental HDR methods in a\npre-trained state-of-the-art (SOTA) facial recognition pipeline, verifying the\nefficacy of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 16:57:36 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ruby", "Max", ""], ["Bolme", "David S.", ""], ["Brogan", "Joel", ""], ["Cornett", "David", "III"], ["Delgado", "Baldemar", ""], ["Jager", "Gavin", ""], ["Johnson", "Christi", ""], ["Martinez-Mendoza", "Jose", ""], ["Santos-Villalobos", "Hector", ""], ["Srinivas", "Nisha", ""]]}, {"id": "2002.12277", "submitter": "Meshal Alfarhood", "authors": "Meshal Alfarhood and Jianlin Cheng", "title": "CATA++: A Collaborative Dual Attentive Autoencoder Method for\n  Recommending Scientific Articles", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3029722", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems today have become an essential component of any\ncommercial website. Collaborative filtering approaches, and Matrix\nFactorization (MF) techniques in particular, are widely used in recommender\nsystems. However, the natural data sparsity problem limits their performance\nwhere users generally interact with very few items in the system. Consequently,\nmultiple hybrid models were proposed recently to optimize MF performance by\nincorporating additional contextual information in its learning process.\nAlthough these models improve the recommendation quality, there are two primary\naspects for further improvements: (1) multiple models focus only on some\nportion of the available contextual information and neglect other portions; (2)\nlearning the feature space of the side contextual information needs to be\nfurther enhanced. In this paper, we introduce a Collaborative Dual Attentive\nAutoencoder (CATA++) for recommending scientific articles. CATA++ utilizes an\narticle's content and learns its latent space via two parallel autoencoders. We\nemploy the attention mechanism to capture the most related parts of information\nin order to make more relevant recommendations. Extensive experiments on three\nreal-world datasets have shown that our dual-way learning strategy has\nsignificantly improved the MF performance in comparison with other\nstate-of-the-art MF-based models using various experimental evaluations. The\nsource code of our methods is available at:\nhttps://github.com/jianlin-cheng/CATA.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:35:46 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 09:20:15 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Alfarhood", "Meshal", ""], ["Cheng", "Jianlin", ""]]}, {"id": "2002.12278", "submitter": "Arnab Sharma", "authors": "Arnab Sharma and Heike Wehrheim", "title": "Testing Monotonicity of Machine Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, machine learning (ML) models are increasingly applied in decision\nmaking. This induces an urgent need for quality assurance of ML models with\nrespect to (often domain-dependent) requirements. Monotonicity is one such\nrequirement. It specifies a software as 'learned' by an ML algorithm to give an\nincreasing prediction with the increase of some attribute values. While there\nexist multiple ML algorithms for ensuring monotonicity of the generated model,\napproaches for checking monotonicity, in particular of black-box models, are\nlargely lacking. In this work, we propose verification-based testing of\nmonotonicity, i.e., the formal computation of test inputs on a white-box model\nvia verification technology, and the automatic inference of this approximating\nwhite-box model from the black-box model under test. On the white-box model,\nthe space of test inputs can be systematically explored by a directed\ncomputation of test cases. The empirical evaluation on 90 black-box models\nshows verification-based testing can outperform adaptive random testing as well\nas property-based techniques with respect to effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:38:06 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Sharma", "Arnab", ""], ["Wehrheim", "Heike", ""]]}, {"id": "2002.12287", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Simone Scardapane", "title": "Deep Randomized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized Neural Networks explore the behavior of neural systems where the\nmajority of connections are fixed, either in a stochastic or a deterministic\nfashion. Typical examples of such systems consist of multi-layered neural\nnetwork architectures where the connections to the hidden layer(s) are left\nuntrained after initialization. Limiting the training algorithms to operate on\na reduced set of weights inherently characterizes the class of Randomized\nNeural Networks with a number of intriguing features. Among them, the extreme\nefficiency of the resulting learning processes is undoubtedly a striking\nadvantage with respect to fully trained architectures. Besides, despite the\ninvolved simplifications, randomized neural systems possess remarkable\nproperties both in practice, achieving state-of-the-art results in multiple\ndomains, and theoretically, allowing to analyze intrinsic properties of neural\narchitectures (e.g. before training of the hidden layers' connections). In\nrecent years, the study of Randomized Neural Networks has been extended towards\ndeep architectures, opening new research directions to the design of effective\nyet extremely efficient deep learning models in vectorial as well as in more\ncomplex data domains. This chapter surveys all the major aspects regarding the\ndesign and analysis of Randomized Neural Networks, and some of the key results\nwith respect to their approximation capabilities. In particular, we first\nintroduce the fundamentals of randomized neural models in the context of\nfeed-forward networks (i.e., Random Vector Functional Link and equivalent\nmodels) and convolutional filters, before moving to the case of recurrent\nsystems (i.e., Reservoir Computing networks). For both, we focus specifically\non recent results in the domain of deep randomized systems, and (for recurrent\nmodels) their application to structured domains.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:57:58 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 15:19:10 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Scardapane", "Simone", ""]]}, {"id": "2002.12292", "submitter": "Roberta Raileanu", "authors": "Roberta Raileanu and Tim Rockt\\\"aschel", "title": "RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in sparse reward environments remains one of the key challenges\nof model-free reinforcement learning. Instead of solely relying on extrinsic\nrewards provided by the environment, many state-of-the-art methods use\nintrinsic rewards to encourage exploration. However, we show that existing\nmethods fall short in procedurally-generated environments where an agent is\nunlikely to visit a state more than once. We propose a novel type of intrinsic\nreward which encourages the agent to take actions that lead to significant\nchanges in its learned state representation. We evaluate our method on multiple\nchallenging procedurally-generated tasks in MiniGrid, as well as on tasks with\nhigh-dimensional observations used in prior work. Our experiments demonstrate\nthat this approach is more sample efficient than existing exploration methods,\nparticularly for procedurally-generated MiniGrid environments. Furthermore, we\nanalyze the learned behavior as well as the intrinsic reward received by our\nagent. In contrast to previous approaches, our intrinsic reward does not\ndiminish during the course of training and it rewards the agent substantially\nmore for interacting with objects that it can control.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:03:16 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 16:12:58 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Raileanu", "Roberta", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2002.12301", "submitter": "Hiroki Matsutani", "authors": "Rei Ito, Mineto Tsukada, Hiroki Matsutani", "title": "An On-Device Federated Learning Approach for Cooperative Model Update\n  between Edge Devices", "comments": null, "journal-ref": "IEEE Access (2021)", "doi": "10.1109/ACCESS.2021.3093382", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most edge AI focuses on prediction tasks on resource-limited edge devices\nwhile the training is done at server machines. However, retraining or\ncustomizing a model is required at edge devices as the model is becoming\noutdated due to environmental changes over time. To follow such a concept\ndrift, a neural-network based on-device learning approach is recently proposed,\nso that edge devices train incoming data at runtime to update their model. In\nthis case, since a training is done at distributed edge devices, the issue is\nthat only a limited amount of training data can be used for each edge device.\nTo address this issue, one approach is a cooperative learning or federated\nlearning, where edge devices exchange their trained results and update their\nmodel by using those collected from the other devices. In this paper, as an\non-device learning algorithm, we focus on OS-ELM (Online Sequential Extreme\nLearning Machine) to sequentially train a model based on recent samples and\ncombine it with autoencoder for anomaly detection. We extend it for an\non-device federated learning so that edge devices can exchange their trained\nresults and update their model by using those collected from the other edge\ndevices. This cooperative model update is one-shot while it can be repeatedly\napplied to synchronize their model. Our approach is evaluated with anomaly\ndetection tasks generated from a driving dataset of cars, a human activity\ndataset, and MNIST dataset. The results demonstrate that the proposed on-device\nfederated learning can produce a merged model by integrating trained results\nfrom multiple edge devices as accurately as traditional backpropagation based\nneural networks and a traditional federated learning approach with lower\ncomputation or communication cost.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:15:38 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 16:07:35 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 12:20:24 GMT"}, {"version": "v4", "created": "Thu, 10 Jun 2021 12:28:56 GMT"}, {"version": "v5", "created": "Sun, 27 Jun 2021 14:59:30 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ito", "Rei", ""], ["Tsukada", "Mineto", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "2002.12307", "submitter": "Ziqi Liu", "authors": "Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, Le Song", "title": "Heterogeneous Graph Neural Networks for Malicious Account Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, GEM, the first heterogeneous graph neural network approach for\ndetecting malicious accounts at Alipay, one of the world's leading mobile\ncashless payment platform. Our approach, inspired from a connected subgraph\napproach, adaptively learns discriminative embeddings from heterogeneous\naccount-device graphs based on two fundamental weaknesses of attackers, i.e.\ndevice aggregation and activity aggregation. For the heterogeneous graph\nconsists of various types of nodes, we propose an attention mechanism to learn\nthe importance of different types of nodes, while using the sum operator for\nmodeling the aggregation patterns of nodes in each type. Experiments show that\nour approaches consistently perform promising results compared with competitive\nmethods over time.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:26:44 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Ziqi", ""], ["Chen", "Chaochao", ""], ["Yang", "Xinxing", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Song", "Le", ""]]}, {"id": "2002.12312", "submitter": "Liwei Wu", "authors": "Liwei Wu", "title": "Advances in Collaborative Filtering and Ranking", "comments": "PhD Dissertation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this dissertation, we cover some recent advances in collaborative\nfiltering and ranking. In chapter 1, we give a brief introduction of the\nhistory and the current landscape of collaborative filtering and ranking;\nchapter 2 we first talk about pointwise collaborative filtering problem with\ngraph information, and how our proposed new method can encode very deep graph\ninformation which helps four existing graph collaborative filtering algorithms;\nchapter 3 is on the pairwise approach for collaborative ranking and how we\nspeed up the algorithm to near-linear time complexity; chapter 4 is on the new\nlistwise approach for collaborative ranking and how the listwise approach is a\nbetter choice of loss for both explicit and implicit feedback over pointwise\nand pairwise loss; chapter 5 is about the new regularization technique\nStochastic Shared Embeddings (SSE) we proposed for embedding layers and how it\nis both theoretically sound and empirically effectively for 6 different tasks\nacross recommendation and natural language processing; chapter 6 is how we\nintroduce personalization for the state-of-the-art sequential recommendation\nmodel with the help of SSE, which plays an important role in preventing our\npersonalized model from overfitting to the training data; chapter 7, we\nsummarize what we have achieved so far and predict what the future directions\ncan be; chapter 8 is the appendix to all the chapters.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:30:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Wu", "Liwei", ""]]}, {"id": "2002.12317", "submitter": "Ofir Lindenbaum", "authors": "Ariel Jaffe, Yuval Kluger, Ofir Lindenbaum, Jonathan Patsenker, Erez\n  Peterfreund, Stefan Steinerberger", "title": "The Spectral Underpinning of word2vec", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  word2vec due to Mikolov \\textit{et al.} (2013) is a word embedding method\nthat is widely used in natural language processing. Despite its great success\nand frequent use, theoretical justification is still lacking. The main\ncontribution of our paper is to propose a rigorous analysis of the highly\nnonlinear functional of word2vec. Our results suggest that word2vec may be\nprimarily driven by an underlying spectral method. This insight may open the\ndoor to obtaining provable guarantees for word2vec. We support these findings\nby numerical simulations. One fascinating open question is whether the\nnonlinear properties of word2vec that are not captured by the spectral method\nare beneficial and, if so, by what mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:38:21 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 09:17:18 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Jaffe", "Ariel", ""], ["Kluger", "Yuval", ""], ["Lindenbaum", "Ofir", ""], ["Patsenker", "Jonathan", ""], ["Peterfreund", "Erez", ""], ["Steinerberger", "Stefan", ""]]}, {"id": "2002.12319", "submitter": "Vitor Guizilini", "authors": "Vitor Guizilini, Rui Hou, Jie Li, Rares Ambrus, Adrien Gaidon", "title": "Semantically-Guided Representation Learning for Self-Supervised\n  Monocular Depth", "comments": "Proceedings of the Eighth International Conference on Learning\n  Representations (ICLR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised learning is showing great promise for monocular depth\nestimation, using geometry as the only source of supervision. Depth networks\nare indeed capable of learning representations that relate visual appearance to\n3D properties by implicitly leveraging category-level patterns. In this work we\ninvestigate how to leverage more directly this semantic structure to guide\ngeometric representation learning, while remaining in the self-supervised\nregime. Instead of using semantic labels and proxy losses in a multi-task\napproach, we propose a new architecture leveraging fixed pretrained semantic\nsegmentation networks to guide self-supervised representation learning via\npixel-adaptive convolutions. Furthermore, we propose a two-stage training\nprocess to overcome a common semantic bias on dynamic objects via resampling.\nOur method improves upon the state of the art for self-supervised monocular\ndepth prediction over all pixels, fine-grained details, and per semantic\ncategories.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:40:10 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Guizilini", "Vitor", ""], ["Hou", "Rui", ""], ["Li", "Jie", ""], ["Ambrus", "Rares", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2002.12321", "submitter": "Wanrong Zhang", "authors": "Wanrong Zhang, Gautam Kamath, Rachel Cummings", "title": "PAPRIKA: Private Online False Discovery Rate Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.DS cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hypothesis testing, a false discovery occurs when a hypothesis is\nincorrectly rejected due to noise in the sample. When adaptively testing\nmultiple hypotheses, the probability of a false discovery increases as more\ntests are performed. Thus the problem of False Discovery Rate (FDR) control is\nto find a procedure for testing multiple hypotheses that accounts for this\neffect in determining the set of hypotheses to reject. The goal is to minimize\nthe number (or fraction) of false discoveries, while maintaining a high true\npositive rate (i.e., correct discoveries).\n  In this work, we study False Discovery Rate (FDR) control in multiple\nhypothesis testing under the constraint of differential privacy for the sample.\nUnlike previous work in this direction, we focus on the online setting, meaning\nthat a decision about each hypothesis must be made immediately after the test\nis performed, rather than waiting for the output of all tests as in the offline\nsetting. We provide new private algorithms based on state-of-the-art results in\nnon-private online FDR control. Our algorithms have strong provable guarantees\nfor privacy and statistical performance as measured by FDR and power. We also\nprovide experimental results to demonstrate the efficacy of our algorithms in a\nvariety of data environments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:42:23 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 03:06:54 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhang", "Wanrong", ""], ["Kamath", "Gautam", ""], ["Cummings", "Rachel", ""]]}, {"id": "2002.12324", "submitter": "Eric Brachmann", "authors": "Eric Brachmann and Carsten Rother", "title": "Visual Camera Re-Localization from RGB and RGB-D Images Using DSAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a learning-based system that estimates the camera position and\norientation from a single input image relative to a known environment. The\nsystem is flexible w.r.t. the amount of information available at test and at\ntraining time, catering to different applications. Input images can be RGB-D or\nRGB, and a 3D model of the environment can be utilized for training but is not\nnecessary. In the minimal case, our system requires only RGB images and ground\ntruth poses at training time, and it requires only a single RGB image at test\ntime. The framework consists of a deep neural network and fully differentiable\npose optimization. The neural network predicts so called scene coordinates,\ni.e. dense correspondences between the input image and 3D scene space of the\nenvironment. The pose optimization implements robust fitting of pose parameters\nusing differentiable RANSAC (DSAC) to facilitate end-to-end training. The\nsystem, an extension of DSAC++ and referred to as DSAC*, achieves\nstate-of-the-art accuracy an various public datasets for RGB-based\nre-localization, and competitive accuracy for RGB-D-based re-localization.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:45:21 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 12:07:47 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 12:29:26 GMT"}, {"version": "v4", "created": "Fri, 9 Oct 2020 15:03:02 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Brachmann", "Eric", ""], ["Rother", "Carsten", ""]]}, {"id": "2002.12326", "submitter": "Ioana Bica", "authors": "Ioana Bica, James Jordon, Mihaela van der Schaar", "title": "Estimating the Effects of Continuous-valued Interventions using\n  Generative Adversarial Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While much attention has been given to the problem of estimating the effect\nof discrete interventions from observational data, relatively little work has\nbeen done in the setting of continuous-valued interventions, such as treatments\nassociated with a dosage parameter. In this paper, we tackle this problem by\nbuilding on a modification of the generative adversarial networks (GANs)\nframework. Our model, SCIGAN, is flexible and capable of simultaneously\nestimating counterfactual outcomes for several different continuous\ninterventions. The key idea is to use a significantly modified GAN model to\nlearn to generate counterfactual outcomes, which can then be used to learn an\ninference model, using standard supervised methods, capable of estimating these\ncounterfactuals for a new sample. To address the challenges presented by\nshifting to continuous interventions, we propose a novel architecture for our\ndiscriminator - we build a hierarchical discriminator that leverages the\nstructure of the continuous intervention setting. Moreover, we provide\ntheoretical results to support our use of the GAN framework and of the\nhierarchical discriminator. In the experiments section, we introduce a new\nsemi-synthetic data simulation for use in the continuous intervention setting\nand demonstrate improvements over the existing benchmark models.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:46:21 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 20:17:54 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bica", "Ioana", ""], ["Jordon", "James", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2002.12334", "submitter": "Michael P. Kim", "authors": "Amirata Ghorbani, Michael P. Kim, James Zou", "title": "A Distributional Framework for Data Valuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shapley value is a classic notion from game theory, historically used to\nquantify the contributions of individuals within groups, and more recently\napplied to assign values to data points when training machine learning models.\nDespite its foundational role, a key limitation of the data Shapley framework\nis that it only provides valuations for points within a fixed data set. It does\nnot account for statistical aspects of the data and does not give a way to\nreason about points outside the data set. To address these limitations, we\npropose a novel framework -- distributional Shapley -- where the value of a\npoint is defined in the context of an underlying data distribution. We prove\nthat distributional Shapley has several desirable statistical properties; for\nexample, the values are stable under perturbations to the data points\nthemselves and to the underlying data distribution. We leverage these\nproperties to develop a new algorithm for estimating values from data, which\ncomes with formal guarantees and runs two orders of magnitude faster than\nstate-of-the-art algorithms for computing the (non-distributional) data Shapley\nvalues. We apply distributional Shapley to diverse data sets and demonstrate\nits utility in a data market setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:51:35 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Ghorbani", "Amirata", ""], ["Kim", "Michael P.", ""], ["Zou", "James", ""]]}, {"id": "2002.12336", "submitter": "Thanard Kurutach", "authors": "Kara Liu, Thanard Kurutach, Christine Tung, Pieter Abbeel, Aviv Tamar", "title": "Hallucinative Topological Memory for Zero-Shot Visual Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual planning (VP), an agent learns to plan goal-directed behavior from\nobservations of a dynamical system obtained offline, e.g., images obtained from\nself-supervised robot interaction. Most previous works on VP approached the\nproblem by planning in a learned latent space, resulting in low-quality visual\nplans, and difficult training algorithms. Here, instead, we propose a simple VP\nmethod that plans directly in image space and displays competitive performance.\nWe build on the semi-parametric topological memory (SPTM) method: image samples\nare treated as nodes in a graph, the graph connectivity is learned from image\nsequence data, and planning can be performed using conventional graph search\nmethods. We propose two modifications on SPTM. First, we train an energy-based\ngraph connectivity function using contrastive predictive coding that admits\nstable training. Second, to allow zero-shot planning in new domains, we learn a\nconditional VAE model that generates images given a context of the domain, and\nuse these hallucinated samples for building the connectivity graph and\nplanning. We show that this simple approach significantly outperform the\nstate-of-the-art VP methods, in terms of both plan interpretability and success\nrate when using the plan to guide a trajectory-following controller.\nInterestingly, our method can pick up non-trivial visual properties of objects,\nsuch as their geometry, and account for it in the plans.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:54:42 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Liu", "Kara", ""], ["Kurutach", "Thanard", ""], ["Tung", "Christine", ""], ["Abbeel", "Pieter", ""], ["Tamar", "Aviv", ""]]}, {"id": "2002.12345", "submitter": "Shuyue Guan", "authors": "Shuyue Guan, Murray Loew", "title": "A Novel Measure to Evaluate Generative Adversarial Networks Based on\n  Direct Analysis of Generated Images", "comments": "16 pages, 11 figures. Accepted by the Neural Computing and\n  Applications journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Generative Adversarial Network (GAN) is a state-of-the-art technique in\nthe field of deep learning. A number of recent papers address the theory and\napplications of GANs in various fields of image processing. Fewer studies,\nhowever, have directly evaluated GAN outputs. Those that have been conducted\nfocused on using classification performance, e.g., Inception Score (IS) and\nstatistical metrics, e.g., Fr\\'echet Inception Distance (FID). Here, we\nconsider a fundamental way to evaluate GANs by directly analyzing the images\nthey generate, instead of using them as inputs to other classifiers. We\ncharacterize the performance of a GAN as an image generator according to three\naspects: 1) Creativity: non-duplication of the real images. 2) Inheritance:\ngenerated images should have the same style, which retains key features of the\nreal images. 3) Diversity: generated images are different from each other. A\nGAN should not generate a few different images repeatedly. Based on the three\naspects of ideal GANs, we have designed the Likeness Score (LS) to evaluate GAN\nperformance, and have applied it to evaluate several typical GANs. We compared\nour proposed measure with two commonly used GAN evaluation methods: IS and FID,\nand four additional measures. Furthermore, we discuss how these evaluations\ncould help us deepen our understanding of GANs and improve their performance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:59:22 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 05:35:36 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 19:57:29 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 05:18:25 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Guan", "Shuyue", ""], ["Loew", "Murray", ""]]}, {"id": "2002.12351", "submitter": "Hanene Ben Yedder", "authors": "Hanene Ben Yedder and Ben Cardoen and Ghassan Hamarneh", "title": "Deep Learning for Biomedical Image Reconstruction: A Survey", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical imaging is an invaluable resource in medicine as it enables to peer\ninside the human body and provides scientists and physicians with a wealth of\ninformation indispensable for understanding, modelling, diagnosis, and\ntreatment of diseases. Reconstruction algorithms entail transforming signals\ncollected by acquisition hardware into interpretable images. Reconstruction is\na challenging task given the ill-posed of the problem and the absence of exact\nanalytic inverse transforms in practical cases. While the last decades\nwitnessed impressive advancements in terms of new modalities, improved temporal\nand spatial resolution, reduced cost, and wider applicability, several\nimprovements can still be envisioned such as reducing acquisition and\nreconstruction time to reduce patient's exposure to radiation and discomfort\nwhile increasing clinics throughput and reconstruction accuracy. Furthermore,\nthe deployment of biomedical imaging in handheld devices with small power\nrequires a fine balance between accuracy and latency.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:45:12 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Yedder", "Hanene Ben", ""], ["Cardoen", "Ben", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "2002.12356", "submitter": "Andreas Foltyn", "authors": "Maximilian Seitzer, Andreas Foltyn, Felix P. Kemeth", "title": "NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through\n  Learned Aggregation of Convolutional Feature Maps", "comments": "Disentanglement Challenge - 33rd Conference on Neural Information\n  Processing Systems (NeurIPS) - NeurIPS 2019. arXiv admin note: text overlap\n  with arXiv:2002.10003. Acknowledgements added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report to our stage 2 submission to the NeurIPS 2019 disentanglement\nchallenge presents a simple image preprocessing method for learning\ndisentangled latent factors. We propose to train a variational autoencoder on\nregionally aggregated feature maps obtained from networks pretrained on the\nImageNet database, utilizing the implicit inductive bias contained in those\nfeatures for disentanglement. This bias can be further enhanced by explicitly\nfine-tuning the feature maps on auxiliary tasks useful for the challenge, such\nas angle, position estimation, or color classification. Our approach achieved\nthe 2nd place in stage 2 of the challenge. Code is available at\nhttps://github.com/mseitzer/neurips2019-disentanglement-challenge.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 08:46:17 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 15:16:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Seitzer", "Maximilian", ""], ["Foltyn", "Andreas", ""], ["Kemeth", "Felix P.", ""]]}, {"id": "2002.12359", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen and Cristina Soguero-Ruiz and Robert Jenssen", "title": "A Kernel to Exploit Informative Missingness in Multivariate Time Series\n  from EHRs", "comments": "2020 International Workshop on Health Intelligence, AAAI-20. arXiv\n  admin note: text overlap with arXiv:1907.05251", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large fraction of the electronic health records (EHRs) consists of clinical\nmeasurements collected over time, such as lab tests and vital signs, which\nprovide important information about a patient's health status. These sequences\nof clinical measurements are naturally represented as time series,\ncharacterized by multiple variables and large amounts of missing data, which\ncomplicate the analysis. In this work, we propose a novel kernel which is\ncapable of exploiting both the information from the observed values as well the\ninformation hidden in the missing patterns in multivariate time series (MTS)\noriginating e.g. from EHRs. The kernel, called TCK$_{IM}$, is designed using an\nensemble learning strategy in which the base models are novel mixed mode\nBayesian mixture models which can effectively exploit informative missingness\nwithout having to resort to imputation methods. Moreover, the ensemble approach\nensures robustness to hyperparameters and therefore TCK$_{IM}$ is particularly\nwell suited if there is a lack of labels - a known challenge in medical\napplications. Experiments on three real-world clinical datasets demonstrate the\neffectiveness of the proposed kernel.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 09:54:44 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Jenssen", "Robert", ""]]}, {"id": "2002.12361", "submitter": "Tom Jurgenson", "authors": "Tom Jurgenson, Or Avner, Edward Groshev, Aviv Tamar", "title": "Sub-Goal Trees -- a Framework for Goal-Based Reinforcement Learning", "comments": "ICML2020, 8 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1906.05329", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many AI problems, in robotics and other domains, are goal-based, essentially\nseeking trajectories leading to various goal states. Reinforcement learning\n(RL), building on Bellman's optimality equation, naturally optimizes for a\nsingle goal, yet can be made multi-goal by augmenting the state with the goal.\nInstead, we propose a new RL framework, derived from a dynamic programming\nequation for the all pairs shortest path (APSP) problem, which naturally solves\nmulti-goal queries. We show that this approach has computational benefits for\nboth standard and approximate dynamic programming. Interestingly, our\nformulation prescribes a novel protocol for computing a trajectory: instead of\npredicting the next state given its predecessor, as in standard RL, a\ngoal-conditioned trajectory is constructed by first predicting an intermediate\nstate between start and goal, partitioning the trajectory into two. Then,\nrecursively, predicting intermediate points on each sub-segment, until a\ncomplete trajectory is obtained. We call this trajectory structure a sub-goal\ntree. Building on it, we additionally extend the policy gradient methodology to\nrecursively predict sub-goals, resulting in novel goal-based algorithms.\nFinally, we apply our method to neural motion planning, where we demonstrate\nsignificant improvements compared to standard RL on navigating a 7-DoF robot\narm between obstacles.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:32:13 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:42:22 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jurgenson", "Tom", ""], ["Avner", "Or", ""], ["Groshev", "Edward", ""], ["Tamar", "Aviv", ""]]}, {"id": "2002.12364", "submitter": "Jonathan Baxter", "authors": "Jonathan Baxter", "title": "Theoretical Models of Learning to Learn", "comments": "arXiv admin note: text overlap with arXiv:1106.0245", "journal-ref": "in Learning to Learn (edited by Sebastian Thrun and Lorien Pratt),\n  159-179 (1998)", "doi": "10.1007/978-1-4615-5529-2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Machine can only learn if it is biased in some way. Typically the bias is\nsupplied by hand, for example through the choice of an appropriate set of\nfeatures. However, if the learning machine is embedded within an {\\em\nenvironment} of related tasks, then it can {\\em learn} its own bias by learning\nsufficiently many tasks from the environment. In this paper two models of bias\nlearning (or equivalently, learning to learn) are introduced and the main\ntheoretical results presented. The first model is a PAC-type model based on\nempirical process theory, while the second is a hierarchical Bayes model.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:35:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Baxter", "Jonathan", ""]]}, {"id": "2002.12386", "submitter": "Zafiirah Hosenie", "authors": "Zafiirah Hosenie, Robert Lyon, Benjamin Stappers, Arrykrishna\n  Mootoovaloo and Vanessa McBride", "title": "Imbalance Learning for Variable Star Classification", "comments": "11 pages, 8 figures, Accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/staa642", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate automated classification of variable stars into their respective\nsub-types is difficult. Machine learning based solutions often fall foul of the\nimbalanced learning problem, which causes poor generalisation performance in\npractice, especially on rare variable star sub-types. In previous work, we\nattempted to overcome such deficiencies via the development of a hierarchical\nmachine learning classifier. This 'algorithm-level' approach to tackling\nimbalance, yielded promising results on Catalina Real-Time Survey (CRTS) data,\noutperforming the binary and multi-class classification schemes previously\napplied in this area. In this work, we attempt to further improve hierarchical\nclassification performance by applying 'data-level' approaches to directly\naugment the training data so that they better describe under-represented\nclasses. We apply and report results for three data augmentation methods in\nparticular: $\\textit{R}$andomly $\\textit{A}$ugmented $\\textit{S}$ampled\n$\\textit{L}$ight curves from magnitude $\\textit{E}$rror ($\\texttt{RASLE}$),\naugmenting light curves with Gaussian Process modelling ($\\texttt{GpFit}$) and\nthe Synthetic Minority Over-sampling Technique ($\\texttt{SMOTE}$). When\ncombining the 'algorithm-level' (i.e. the hierarchical scheme) together with\nthe 'data-level' approach, we further improve variable star classification\naccuracy by 1-4$\\%$. We found that a higher classification rate is obtained\nwhen using $\\texttt{GpFit}$ in the hierarchical model. Further improvement of\nthe metric scores requires a better standard set of correctly identified\nvariable stars and, perhaps enhanced features are needed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:01:05 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Hosenie", "Zafiirah", ""], ["Lyon", "Robert", ""], ["Stappers", "Benjamin", ""], ["Mootoovaloo", "Arrykrishna", ""], ["McBride", "Vanessa", ""]]}, {"id": "2002.12388", "submitter": "Jens Eisert", "authors": "A. Goe{\\ss}mann, M. G\\\"otte, I. Roth, R. Sweke, G. Kutyniok, J. Eisert", "title": "Tensor network approaches for learning non-linear dynamical laws", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given observations of a physical system, identifying the underlying\nnon-linear governing equation is a fundamental task, necessary both for gaining\nunderstanding and generating deterministic future predictions. Of most\npractical relevance are automated approaches to theory building that scale\nefficiently for complex systems with many degrees of freedom. To date,\navailable scalable methods aim at a data-driven interpolation, without\nexploiting or offering insight into fundamental underlying physical principles,\nsuch as locality of interactions. In this work, we show that various physical\nconstraints can be captured via tensor network based parameterizations for the\ngoverning equation, which naturally ensures scalability. In addition to\nproviding analytic results motivating the use of such models for realistic\nphysical systems, we demonstrate that efficient rank-adaptive optimization\nalgorithms can be used to learn optimal tensor network models without requiring\na~priori knowledge of the exact tensor ranks. As such, we provide a\nphysics-informed approach to recovering structured dynamical laws from data,\nwhich adaptively balances the need for expressivity and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:02:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goe\u00dfmann", "A.", ""], ["G\u00f6tte", "M.", ""], ["Roth", "I.", ""], ["Sweke", "R.", ""], ["Kutyniok", "G.", ""], ["Eisert", "J.", ""]]}, {"id": "2002.12394", "submitter": "Ujjal Kr Dutta", "authors": "Ujjal Kr Dutta, Mehrtash Harandi and Chellu Chandra Sekhar", "title": "Affinity guided Geometric Semi-Supervised Metric Learning", "comments": "Paper accepted in NeurIPS 2020 workshop on Differential Geometry\n  meets Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revamp the forgotten classical Semi-Supervised Distance\nMetric Learning (SSDML) problem from a Riemannian geometric lens, to leverage\nstochastic optimization within a end-to-end deep framework. The motivation\ncomes from the fact that apart from a few classical SSDML approaches learning a\nlinear Mahalanobis metric, deep SSDML has not been studied. We first extend\nexisting SSDML methods to their deep counterparts and then propose a new method\nto overcome their limitations. Due to the nature of constraints on our metric\nparameters, we leverage Riemannian optimization. Our deep SSDML method with a\nnovel affinity propagation based triplet mining strategy outperforms its\ncompetitors.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:10:21 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 17:49:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Dutta", "Ujjal Kr", ""], ["Harandi", "Mehrtash", ""], ["Sekhar", "Chellu Chandra", ""]]}, {"id": "2002.12398", "submitter": "Maurice Weber", "authors": "Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Tao Xie, Ce Zhang,\n  Bo Li", "title": "Provable Robust Learning Based on Transformation-Specific Smoothing", "comments": "58 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) systems become pervasive, safeguarding their\nsecurity is critical. Recent work has demonstrated that motivated adversaries\ncould add adversarial perturbations to the test data to mislead ML systems. So\nfar, most research has focused on providing provable robustness guarantees for\nML models against a specific Lp norm bounded adversarial perturbation. However,\nin practice previous work has shown that there are other types of realistic\nadversarial transformations whose semantic meaning has been leveraged to attack\nML systems. In this paper, we aim to provide a unified framework for certifying\nML robustness against general adversarial transformations. First, we identify\nthe semantic transformations as different categories: resolvable (e.g.,\nGaussian blur and brightness) and differentially resolvable transformations\n(e.g., rotation and scaling). We then provide sufficient conditions and\nstrategies for certifying certain transformations. For instance, we propose a\nnovel sampling-based interpolation approach with estimated Lipschitz upper\nbound to certify the robustness against differentially resolvable\ntransformations. In addition, we theoretically optimize the smoothing\nstrategies for certifying the robustness of ML models against different\ntransformations. For instance, we show that smoothing by sampling from\nexponential distribution provides a tighter robustness bound than Gaussian.\nExtensive experiments on 7 semantic transformations show that our proposed\nunified framework significantly outperforms the state-of-the-art certified\nrobustness approaches on several datasets including ImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:19:32 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 11:45:20 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 16:20:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Li", "Linyi", ""], ["Weber", "Maurice", ""], ["Xu", "Xiaojun", ""], ["Rimanic", "Luka", ""], ["Xie", "Tao", ""], ["Zhang", "Ce", ""], ["Li", "Bo", ""]]}, {"id": "2002.12399", "submitter": "Jayden Ooi", "authors": "Andy Su, Jayden Ooi, Tyler Lu, Dale Schuurmans, Craig Boutilier", "title": "ConQUR: Mitigating Delusional Bias in Deep Q-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Delusional bias is a fundamental source of error in approximate Q-learning.\nTo date, the only techniques that explicitly address delusion require\ncomprehensive search using tabular value estimates. In this paper, we develop\nefficient methods to mitigate delusional bias by training Q-approximators with\nlabels that are \"consistent\" with the underlying greedy policy class. We\nintroduce a simple penalization scheme that encourages Q-labels used across\ntraining batches to remain (jointly) consistent with the expressible policy\nclass. We also propose a search framework that allows multiple Q-approximators\nto be generated and tracked, thus mitigating the effect of premature (implicit)\npolicy commitments. Experimental results demonstrate that these methods can\nimprove the performance of Q-learning in a variety of Atari games, sometimes\ndramatically.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:22:51 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Su", "Andy", ""], ["Ooi", "Jayden", ""], ["Lu", "Tyler", ""], ["Schuurmans", "Dale", ""], ["Boutilier", "Craig", ""]]}, {"id": "2002.12404", "submitter": "Dongrui Wu", "authors": "Yuqi Cui, Huidong Wang, Dongrui Wu", "title": "Supervised Enhanced Soft Subspace Clustering (SESSC) for TSK Fuzzy\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy c-means based clustering algorithms are frequently used for\nTakagi-Sugeno-Kang (TSK) fuzzy classifier antecedent parameter estimation. One\nrule is initialized from each cluster. However, most of these clustering\nalgorithms are unsupervised, which waste valuable label information in the\ntraining data. This paper proposes a supervised enhanced soft subspace\nclustering (SESSC) algorithm, which considers simultaneously the within-cluster\ncompactness, between-cluster separation, and label information in clustering.\nIt can effectively deal with high-dimensional data, be used as a classifier\nalone, or be integrated into a TSK fuzzy classifier to further improve its\nperformance. Experiments on nine UCI datasets from various application domains\ndemonstrated that SESSC based initialization outperformed other clustering\napproaches, especially when the number of rules is small.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:39:19 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Cui", "Yuqi", ""], ["Wang", "Huidong", ""], ["Wu", "Dongrui", ""]]}, {"id": "2002.12406", "submitter": "Yansong Gao Mr.", "authors": "Yansong Gao and Pratik Chaudhari", "title": "A Free-Energy Principle for Representation Learning", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper employs a formal connection of machine learning with\nthermodynamics to characterize the quality of learnt representations for\ntransfer learning. We discuss how information-theoretic functional such as\nrate, distortion and classification loss of a model lie on a convex, so-called\nequilibrium surface.We prescribe dynamical processes to traverse this surface\nunder constraints, e.g., an iso-classification process that trades off rate and\ndistortion to keep the classification loss unchanged. We demonstrate how this\nprocess can be used for transferring representations from a source dataset to a\ntarget dataset while keeping the classification loss constant. Experimental\nvalidation of the theoretical results is provided on standard\nimage-classification datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:44:49 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Gao", "Yansong", ""], ["Chaudhari", "Pratik", ""]]}, {"id": "2002.12410", "submitter": "Peter Richt\\'arik", "authors": "Aleksandr Beznosikov and Samuel Horv\\'ath and Peter Richt\\'arik and\n  Mher Safaryan", "title": "On Biased Compression for Distributed Learning", "comments": "39 pages, 10 Figures, 25 Theorems and Lemmas, 8 New Compression\n  Operators, 2 Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, various communication compression techniques have\nemerged as an indispensable tool helping to alleviate the communication\nbottleneck in distributed learning. However, despite the fact {\\em biased}\ncompressors often show superior performance in practice when compared to the\nmuch more studied and understood {\\em unbiased} compressors, very little is\nknown about them. In this work we study three classes of biased compression\noperators, two of which are new, and their performance when applied to\n(stochastic) gradient descent and distributed (stochastic) gradient descent. We\nshow for the first time that biased compressors can lead to linear convergence\nrates both in the single node and distributed settings. Our {\\em distributed}\nSGD method enjoys the ergodic rate $\\mathcal{O}\\left(\\frac{\\delta L \\exp(-K)\n}{\\mu} + \\frac{(C + D)}{K\\mu}\\right)$, where $\\delta$ is a compression\nparameter which grows when more compression is applied, $L$ and $\\mu$ are the\nsmoothness and strong convexity constants, $C$ captures stochastic gradient\nnoise ($C=0$ if full gradients are computed on each node) and $D$ captures the\nvariance of the gradients at the optimum ($D=0$ for over-parameterized models).\nFurther, via a theoretical study of several synthetic and empirical\ndistributions of communicated gradients, we shed light on why and by how much\nbiased compressors outperform their unbiased variants. Finally, we propose a\nnew highly performing biased compressor---combination of Top-$k$ and natural\ndithering---which in our experiments outperforms all other compression\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:52:24 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Beznosikov", "Aleksandr", ""], ["Horv\u00e1th", "Samuel", ""], ["Richt\u00e1rik", "Peter", ""], ["Safaryan", "Mher", ""]]}, {"id": "2002.12411", "submitter": "Ali Ayub", "authors": "Ali Ayub and Alan Wagner", "title": "Cognitively-Inspired Model for Incremental Learning Using a Few Examples", "comments": "Added link to the code in the paper", "journal-ref": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR) Workshops, 2020", "doi": "10.1109/CVPRW50498.2020.00119", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental learning attempts to develop a classifier which learns\ncontinuously from a stream of data segregated into different classes. Deep\nlearning approaches suffer from catastrophic forgetting when learning classes\nincrementally, while most incremental learning approaches require a large\namount of training data per class. We examine the problem of incremental\nlearning using only a few training examples, referred to as Few-Shot\nIncremental Learning (FSIL). To solve this problem, we propose a novel approach\ninspired by the concept learning model of the hippocampus and the neocortex\nthat represents each image class as centroids and does not suffer from\ncatastrophic forgetting. We evaluate our approach on three class-incremental\nlearning benchmarks: Caltech-101, CUBS-200-2011 and CIFAR-100 for incremental\nand few-shot incremental learning and show that our approach achieves\nstate-of-the-art results in terms of classification accuracy over all learned\nclasses.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:52:42 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 05:09:37 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 06:55:06 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ayub", "Ali", ""], ["Wagner", "Alan", ""]]}, {"id": "2002.12414", "submitter": "Mahmoud Assran", "authors": "Mahmoud Assran and Michael Rabbat", "title": "On the Convergence of Nesterov's Accelerated Gradient Method in\n  Stochastic Settings", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML 2020)", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Nesterov's accelerated gradient method with constant step-size and\nmomentum parameters in the stochastic approximation setting (unbiased gradients\nwith bounded variance) and the finite-sum setting (where randomness is due to\nsampling mini-batches). To build better insight into the behavior of Nesterov's\nmethod in stochastic settings, we focus throughout on objectives that are\nsmooth, strongly-convex, and twice continuously differentiable. In the\nstochastic approximation setting, Nesterov's method converges to a neighborhood\nof the optimal point at the same accelerated rate as in the deterministic\nsetting. Perhaps surprisingly, in the finite-sum setting, we prove that\nNesterov's method may diverge with the usual choice of step-size and momentum,\nunless additional conditions on the problem related to conditioning and data\ncoherence are satisfied. Our results shed light as to why Nesterov's method may\nfail to converge or achieve acceleration in the finite-sum setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:56:41 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:01:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Assran", "Mahmoud", ""], ["Rabbat", "Michael", ""]]}, {"id": "2002.12418", "submitter": "Huan Wang", "authors": "Xiaotang Jiang, Huan Wang, Yiliu Chen, Ziqi Wu, Lichuan Wang, Bin Zou,\n  Yafeng Yang, Zongyang Cui, Yu Cai, Tianhang Yu, Chengfei Lv, Zhihua Wu", "title": "MNN: A Universal and Efficient Inference Engine", "comments": "Accepted by MLSys 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying deep learning models on mobile devices draws more and more\nattention recently. However, designing an efficient inference engine on devices\nis under the great challenges of model compatibility, device diversity, and\nresource limitation. To deal with these challenges, we propose Mobile Neural\nNetwork (MNN), a universal and efficient inference engine tailored to mobile\napplications. In this paper, the contributions of MNN include: (1) presenting a\nmechanism called pre-inference that manages to conduct runtime optimization;\n(2)deliveringthorough kernel optimization on operators to achieve optimal\ncomputation performance; (3) introducing backend abstraction module which\nenables hybrid scheduling and keeps the engine lightweight. Extensive benchmark\nexperiments demonstrate that MNN performs favorably against other popular\nlightweight deep learning frameworks. MNN is available to public at:\nhttps://github.com/alibaba/MNN.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 20:03:16 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Jiang", "Xiaotang", ""], ["Wang", "Huan", ""], ["Chen", "Yiliu", ""], ["Wu", "Ziqi", ""], ["Wang", "Lichuan", ""], ["Zou", "Bin", ""], ["Yang", "Yafeng", ""], ["Cui", "Zongyang", ""], ["Cai", "Yu", ""], ["Yu", "Tianhang", ""], ["Lv", "Chengfei", ""], ["Wu", "Zhihua", ""]]}, {"id": "2002.12435", "submitter": "Rahul Singh", "authors": "Rahul Singh, Abhishek Gupta and Ness B. Shroff", "title": "Learning in Markov Decision Processes under Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reinforcement learning (RL) in Markov Decision Processes in which\nan agent repeatedly interacts with an environment that is modeled by a\ncontrolled Markov process. At each time step $t$, it earns a reward, and also\nincurs a cost-vector consisting of $M$ costs. We design learning algorithms\nthat maximize the cumulative reward earned over a time horizon of $T$\ntime-steps, while simultaneously ensuring that the average values of the $M$\ncost expenditures are bounded by agent-specified thresholds\n$c^{ub}_i,i=1,2,\\ldots,M$. The considerations on the cumulative cost\nexpenditures departs from the existing literature, in that the agent now\nadditionally needs to balance the cost expenses in an online manner, while\nsimultaneously performing the exploration-exploitation trade-off that is\ntypically encountered in RL tasks.\n  In order to measure the performance of a reinforcement learning algorithm\nthat satisfies the average cost constraints, we define an $M+1$ dimensional\nregret vector that is composed of its reward regret, and $M$ cost regrets. The\nreward regret measures the sub-optimality in the cumulative reward, while the\n$i$-th component of the cost regret vector is the difference between its $i$-th\ncumulative cost expense and the expected cost expenditures $Tc^{ub}_i$. We\nprove that with a high probablity, the regret vector of UCRL-CMDP is\nupper-bounded as $O\\left( S\\sqrt{AT^{1.5}\\log(T)}\\right)$, where $S$ is the\nnumber of states, $A$ is the number of actions, and $T$ is the time horizon. We\nfurther show how to reduce the regret of a desired subset of the $M$ costs, at\nthe expense of increasing the regrets of rewards and the remaining costs. To\nthe best of our knowledge, ours is the only work that considers non-episodic RL\nunder average cost constraints, and derive algorithms that can~\\emph{tune the\nregret vector} according to the agent's requirements on its cost regrets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 20:58:39 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 17:11:36 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Singh", "Rahul", ""], ["Gupta", "Abhishek", ""], ["Shroff", "Ness B.", ""]]}, {"id": "2002.12446", "submitter": "Aaron Zweig", "authors": "Aaron Zweig and Joan Bruna", "title": "Provably Efficient Third-Person Imitation from Offline Observation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation in imitation learning represents an essential step towards\nimproving generalizability. However, even in the restricted setting of\nthird-person imitation where transfer is between isomorphic Markov Decision\nProcesses, there are no strong guarantees on the performance of transferred\npolicies. We present problem-dependent, statistical learning guarantees for\nthird-person imitation from observation in an offline setting, and a lower\nbound on performance in the online setting.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:18:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zweig", "Aaron", ""], ["Bruna", "Joan", ""]]}, {"id": "2002.12455", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei Zhang", "title": "Is the Meta-Learning Idea Able to Improve the Generalization of Deep\n  Neural Networks on the Standard Supervised Learning?", "comments": null, "journal-ref": "ICPR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial efforts have been made on improving the generalization abilities\nof deep neural networks (DNNs) in order to obtain better performances without\nintroducing more parameters. On the other hand, meta-learning approaches\nexhibit powerful generalization on new tasks in few-shot learning. Intuitively,\nfew-shot learning is more challenging than the standard supervised learning as\neach target class only has a very few or no training samples. The natural\nquestion that arises is whether the meta-learning idea can be used for\nimproving the generalization of DNNs on the standard supervised learning. In\nthis paper, we propose a novel meta-learning based training procedure (MLTP)\nfor DNNs and demonstrate that the meta-learning idea can indeed improve the\ngeneralization abilities of DNNs. MLTP simulates the meta-training process by\nconsidering a batch of training samples as a task. The key idea is that the\ngradient descent step for improving the current task performance should also\nimprove a new task performance, which is ignored by the current standard\nprocedure for training neural networks. MLTP also benefits from all the\nexisting training techniques such as dropout, weight decay, and batch\nnormalization. We evaluate MLTP by training a variety of small and large neural\nnetworks on three benchmark datasets, i.e., CIFAR-10, CIFAR-100, and Tiny\nImageNet. The experimental results show a consistently improved generalization\nperformance on all the DNNs with different sizes, which verifies the promise of\nMLTP and demonstrates that the meta-learning idea is indeed able to improve the\ngeneralization of DNNs on the standard supervised learning.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:29:54 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Deng", "Xiang", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2002.12460", "submitter": "Yuxin Sun", "authors": "Yuxin Sun and Benny Chain and Samuel Kaski and John Shawe-Taylor", "title": "Correlated Feature Selection with Extended Exclusive Group Lasso", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many high dimensional classification or regression problems set in a\nbiological context, the complete identification of the set of informative\nfeatures is often as important as predictive accuracy, since this can provide\nmechanistic insight and conceptual understanding. Lasso and related algorithms\nhave been widely used since their sparse solutions naturally identify a set of\ninformative features. However, Lasso performs erratically when features are\ncorrelated. This limits the use of such algorithms in biological problems,\nwhere features such as genes often work together in pathways, leading to sets\nof highly correlated features. In this paper, we examine the performance of a\nLasso derivative, the exclusive group Lasso, in this setting. We propose fast\nalgorithms to solve the exclusive group Lasso, and introduce a solution to the\ncase when the underlying group structure is unknown. The solution combines\nstability selection with random group allocation and introduction of artificial\nfeatures. Experiments with both synthetic and real-world data highlight the\nadvantages of this proposed methodology over Lasso in comprehensive selection\nof informative features.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:55:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sun", "Yuxin", ""], ["Chain", "Benny", ""], ["Kaski", "Samuel", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2002.12461", "submitter": "Vinorth Varatharasan", "authors": "Vinorth Varatharasan, Alice Shuang Shuang Rao, Eric Toutounji,\n  Ju-Hyeon Hong, Hyo-Sang Shin", "title": "Target Detection, Tracking and Avoidance System for Low-cost UAVs using\n  AI-Based Approaches", "comments": "IEEE RED-UAS 2019 Conference", "journal-ref": null, "doi": "10.1109/REDUAS47371.2019.8999683", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An onboard target detection, tracking and avoidance system has been developed\nin this paper, for low-cost UAV flight controllers using AI-Based approaches.\nThe aim of the proposed system is that an ally UAV can either avoid or track an\nunexpected enemy UAV with a net to protect itself. In this point of view, a\nsimple and robust target detection, tracking and avoidance system is designed.\nTwo open-source tools were used for the aim: a state-of-the-art object\ndetection technique called SSD and an API for MAVLink compatible systems called\nMAVSDK. The MAVSDK performs velocity control when a UAV is detected so that the\nmanoeuvre is done simply and efficiently. The proposed system was verified with\nSoftware in the loop (SITL) and Hardware in the loop (HITL) simulators. The\nsimplicity of this algorithm makes it innovative, and therefore it should be\nused in future applications needing robust performances with low-cost hardware\nsuch as delivery drone applications.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:58:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Varatharasan", "Vinorth", ""], ["Rao", "Alice Shuang Shuang", ""], ["Toutounji", "Eric", ""], ["Hong", "Ju-Hyeon", ""], ["Shin", "Hyo-Sang", ""]]}, {"id": "2002.12462", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Tal Hassner, Matthias Seeger, Cedric Archambeau", "title": "LEEP: A New Measure to Evaluate Transferability of Learned\n  Representations", "comments": "Published at the International Conference on Machine Learning (ICML)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new measure to evaluate the transferability of representations\nlearned by classifiers. Our measure, the Log Expected Empirical Prediction\n(LEEP), is simple and easy to compute: when given a classifier trained on a\nsource data set, it only requires running the target data set through this\nclassifier once. We analyze the properties of LEEP theoretically and\ndemonstrate its effectiveness empirically. Our analysis shows that LEEP can\npredict the performance and convergence speed of both transfer and\nmeta-transfer learning methods, even for small or imbalanced data. Moreover,\nLEEP outperforms recently proposed transferability measures such as negative\nconditional entropy and H scores. Notably, when transferring from ImageNet to\nCIFAR100, LEEP can achieve up to 30% improvement compared to the best competing\nmethod in terms of the correlations with actual transfer accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:02:20 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 02:33:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Hassner", "Tal", ""], ["Seeger", "Matthias", ""], ["Archambeau", "Cedric", ""]]}, {"id": "2002.12463", "submitter": "Marc Fischer", "authors": "Marc Fischer, Maximilian Baader, Martin Vechev", "title": "Certified Defense to Image Transformations via Randomized Smoothing", "comments": "Conference Paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend randomized smoothing to cover parameterized transformations (e.g.,\nrotations, translations) and certify robustness in the parameter space (e.g.,\nrotation angle). This is particularly challenging as interpolation and rounding\neffects mean that image transformations do not compose, in turn preventing\ndirect certification of the perturbed image (unlike certification with $\\ell^p$\nnorms). We address this challenge by introducing three different defenses, each\nwith a different guarantee (heuristic, distributional and individual) stemming\nfrom the method used to bound the interpolation error. Importantly, in the\nindividual case, we show how to efficiently compute the inverse of an image\ntransformation, enabling us to provide individual guarantees in the online\nsetting. We provide an implementation of all methods at\nhttps://github.com/eth-sri/transformation-smoothing.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:02:32 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 10:40:34 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 15:03:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Fischer", "Marc", ""], ["Baader", "Maximilian", ""], ["Vechev", "Martin", ""]]}, {"id": "2002.12467", "submitter": "Vinorth Varatharasan", "authors": "Vinorth Varatharasan, Hyo-Sang Shin, Antonios Tsourdos, Nick Colosimo", "title": "Improving Learning Effectiveness For Object Detection and Classification\n  in Cluttered Backgrounds", "comments": "IEEE RED-UAS 2019 Conference", "journal-ref": null, "doi": "10.1109/REDUAS47371.2019.8999695", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usually, Neural Networks models are trained with a large dataset of images in\nhomogeneous backgrounds. The issue is that the performance of the network\nmodels trained could be significantly degraded in a complex and heterogeneous\nenvironment. To mitigate the issue, this paper develops a framework that\npermits to autonomously generate a training dataset in heterogeneous cluttered\nbackgrounds. It is clear that the learning effectiveness of the proposed\nframework should be improved in complex and heterogeneous environments,\ncompared with the ones with the typical dataset. In our framework, a\nstate-of-the-art image segmentation technique called DeepLab is used to extract\nobjects of interest from a picture and Chroma-key technique is then used to\nmerge the extracted objects of interest into specific heterogeneous\nbackgrounds. The performance of the proposed framework is investigated through\nempirical tests and compared with that of the model trained with the COCO\ndataset. The results show that the proposed framework outperforms the model\ncompared. This implies that the learning effectiveness of the framework\ndeveloped is superior to the models with the typical dataset.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 22:28:48 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Varatharasan", "Vinorth", ""], ["Shin", "Hyo-Sang", ""], ["Tsourdos", "Antonios", ""], ["Colosimo", "Nick", ""]]}, {"id": "2002.12475", "submitter": "Alec Koppel", "authors": "Junyu Zhang, Amrit Singh Bedi, Mengdi Wang, Alec Koppel", "title": "Cautious Reinforcement Learning via Distributional Risk in the Dual\n  Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the estimation of risk-sensitive policies in reinforcement learning\nproblems defined by a Markov Decision Process (MDPs) whose state and action\nspaces are countably finite. Prior efforts are predominately afflicted by\ncomputational challenges associated with the fact that risk-sensitive MDPs are\ntime-inconsistent. To ameliorate this issue, we propose a new definition of\nrisk, which we call caution, as a penalty function added to the dual objective\nof the linear programming (LP) formulation of reinforcement learning. The\ncaution measures the distributional risk of a policy, which is a function of\nthe policy's long-term state occupancy distribution. To solve this problem in\nan online model-free manner, we propose a stochastic variant of primal-dual\nmethod that uses Kullback-Lieber (KL) divergence as its proximal term. We\nestablish that the number of iterations/samples required to attain\napproximately optimal solutions of this scheme matches tight dependencies on\nthe cardinality of the state and action spaces, but differs in its dependence\non the infinity norm of the gradient of the risk measure. Experiments\ndemonstrate the merits of this approach for improving the reliability of reward\naccumulation without additional computational burdens.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 23:18:04 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Junyu", ""], ["Bedi", "Amrit Singh", ""], ["Wang", "Mengdi", ""], ["Koppel", "Alec", ""]]}, {"id": "2002.12478", "submitter": "Qingsong Wen", "authors": "Qingsong Wen, Liang Sun, Fan Yang, Xiaomin Song, Jingkun Gao, Xue\n  Wang, Huan Xu", "title": "Time Series Data Augmentation for Deep Learning: A Survey", "comments": "8 pages, 2 figures, 3 tables, 61 referred papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning performs remarkably well on many time series analysis tasks\nrecently. The superior performance of deep neural networks relies heavily on a\nlarge number of training data to avoid overfitting. However, the labeled data\nof many real-world time series applications may be limited such as\nclassification in medical time series and anomaly detection in AIOps. As an\neffective way to enhance the size and quality of the training data, data\naugmentation is crucial to the successful application of deep learning models\non time series data. In this paper, we systematically review different data\naugmentation methods for time series. We propose a taxonomy for the reviewed\nmethods, and then provide a structured review for these methods by highlighting\ntheir strengths and limitations. We also empirically compare different data\naugmentation methods for different tasks including time series anomaly\ndetection, classification, and forecasting. Finally, we discuss and highlight\nfive future directions to provide useful research guidance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 23:38:11 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 03:40:17 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wen", "Qingsong", ""], ["Sun", "Liang", ""], ["Yang", "Fan", ""], ["Song", "Xiaomin", ""], ["Gao", "Jingkun", ""], ["Wang", "Xue", ""], ["Xu", "Huan", ""]]}, {"id": "2002.12486", "submitter": "Fengqi You", "authors": "Shipu Zhao, Fengqi You", "title": "Distributionally Robust Chance Constrained Programming with Generative\n  Adversarial Networks (GANs)", "comments": null, "journal-ref": "AIChE Journal, Volume 66, Issue 6, June 2020, e16963", "doi": "10.1002/aic.16963", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel deep learning based data-driven optimization\nmethod. A novel generative adversarial network (GAN) based data-driven\ndistributionally robust chance constrained programming framework is proposed.\nGAN is applied to fully extract distributional information from historical data\nin a nonparametric and unsupervised way without a priori approximation or\nassumption. Since GAN utilizes deep neural networks, complicated data\ndistributions and modes can be learned, and it can model uncertainty\nefficiently and accurately. Distributionally robust chance constrained\nprogramming takes into consideration ambiguous probability distributions of\nuncertain parameters. To tackle the computational challenges, sample average\napproximation method is adopted, and the required data samples are generated by\nGAN in an end-to-end way through the differentiable networks. The proposed\nframework is then applied to supply chain optimization under demand\nuncertainty. The applicability of the proposed approach is illustrated through\na county-level case study of a spatially explicit biofuel supply chain in\nIllinois.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:05:22 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhao", "Shipu", ""], ["You", "Fengqi", ""]]}, {"id": "2002.12499", "submitter": "Dibya Ghosh", "authors": "William Fedus, Dibya Ghosh, John D. Martin, Marc G. Bellemare, Yoshua\n  Bengio, Hugo Larochelle", "title": "On Catastrophic Interference in Atari 2600 Games", "comments": "First two authors contributed equally. Code available to reproduce\n  experiments at\n  https://github.com/google-research/google-research/tree/master/memento", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning is sample inefficient. One hypothesis\n-- speculated, but not confirmed -- is that catastrophic interference within an\nenvironment inhibits learning. We test this hypothesis through a large-scale\nempirical study in the Arcade Learning Environment (ALE) and, indeed, find\nsupporting evidence. We show that interference causes performance to plateau;\nthe network cannot train on segments beyond the plateau without degrading the\npolicy used to reach there. By synthetically controlling for interference, we\ndemonstrate performance boosts across architectures, learning algorithms and\nenvironments. A more refined analysis shows that learning one segment of a game\noften increases prediction errors elsewhere. Our study provides a clear\nempirical link between catastrophic interference and sample efficiency in\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:55:03 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 17:36:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Fedus", "William", ""], ["Ghosh", "Dibya", ""], ["Martin", "John D.", ""], ["Bellemare", "Marc G.", ""], ["Bengio", "Yoshua", ""], ["Larochelle", "Hugo", ""]]}, {"id": "2002.12500", "submitter": "Akanksha Saran", "authors": "Akanksha Saran, Ruohan Zhang, Elaine Schaertl Short and Scott Niekum", "title": "Efficiently Guiding Imitation Learning Agents with Human Gaze", "comments": "AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human gaze is known to be an intention-revealing signal in human\ndemonstrations of tasks. In this work, we use gaze cues from human\ndemonstrators to enhance the performance of agents trained via three popular\nimitation learning methods -- behavioral cloning (BC), behavioral cloning from\nobservation (BCO), and Trajectory-ranked Reward EXtrapolation (T-REX). Based on\nsimilarities between the attention of reinforcement learning agents and human\ngaze, we propose a novel approach for utilizing gaze data in a computationally\nefficient manner, as part of an auxiliary loss function, which guides a network\nto have higher activations in image regions where the human's gaze fixated.\nThis work is a step towards augmenting any existing convolutional imitation\nlearning agent's training with auxiliary gaze data. Our auxiliary\ncoverage-based gaze loss (CGL) guides learning toward a better reward function\nor policy, without adding any additional learnable parameters and without\nrequiring gaze data at test time. We find that our proposed approach improves\nthe performance by 95% for BC, 343% for BCO, and 390% for T-REX, averaged over\n20 different Atari games. We also find that compared to a prior\nstate-of-the-art imitation learning method assisted by human gaze (AGIL), our\nmethod achieves better performance, and is more efficient in terms of learning\nwith fewer demonstrations. We further interpret trained CGL agents with a\nsaliency map visualization method to explain their performance. At last, we\nshow that CGL can help alleviate a well-known causal confusion problem in\nimitation learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 00:55:30 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 19:18:57 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 15:46:26 GMT"}, {"version": "v4", "created": "Wed, 21 Apr 2021 21:39:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Saran", "Akanksha", ""], ["Zhang", "Ruohan", ""], ["Short", "Elaine Schaertl", ""], ["Niekum", "Scott", ""]]}, {"id": "2002.12501", "submitter": "Maximilian Nickel", "authors": "Maximilian Nickel, Matthew Le", "title": "Learning Multivariate Hawkes Processes at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Hawkes Processes (MHPs) are an important class of temporal point\nprocesses that have enabled key advances in understanding and predicting social\ninformation systems. However, due to their complex modeling of temporal\ndependencies, MHPs have proven to be notoriously difficult to scale, what has\nlimited their applications to relatively small domains. In this work, we\npropose a novel model and computational approach to overcome this important\nlimitation. By exploiting a characteristic sparsity pattern in real-world\ndiffusion processes, we show that our approach allows to compute the exact\nlikelihood and gradients of an MHP -- independently of the ambient dimensions\nof the underlying network. We show on synthetic and real-world datasets that\nour model does not only achieve state-of-the-art predictive results, but also\nimproves runtime performance by multiple orders of magnitude compared to\nstandard methods on sparse event sequences. In combination with easily\ninterpretable latent variables and influence structures, this allows us to\nanalyze diffusion processes at previously unattainable scale.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 01:18:01 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Nickel", "Maximilian", ""], ["Le", "Matthew", ""]]}, {"id": "2002.12520", "submitter": "Matt Gorbett", "authors": "Matt Gorbett, Nathaniel Blanchard", "title": "Utilizing Network Properties to Detect Erroneous Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to a wide range of erroneous inputs such as\nadversarial, corrupted, out-of-distribution, and misclassified examples. In\nthis work, we train a linear SVM classifier to detect these four types of\nerroneous data using hidden and softmax feature vectors of pre-trained neural\nnetworks. Our results indicate that these faulty data types generally exhibit\nlinearly separable activation properties from correct examples, giving us the\nability to reject bad inputs with no extra training or overhead. We\nexperimentally validate our findings across a diverse range of datasets,\ndomains, pre-trained models, and adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 03:20:55 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 16:43:55 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Gorbett", "Matt", ""], ["Blanchard", "Nathaniel", ""]]}, {"id": "2002.12521", "submitter": "Licheng Xiao", "authors": "Licheng Xiao, Hairong Wang, Nam Ling", "title": "Improved Image Coding Autoencoder With Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we build autoencoder based pipelines for extreme end-to-end\nimage compression based on Ball\\'e's approach, which is the state-of-the-art\nopen source implementation in image compression using deep learning. We\ndeepened the network by adding one more hidden layer before each strided\nconvolutional layer with exactly the same number of down-samplings and\nup-samplings. Our approach outperformed Ball\\'e's approach, and achieved around\n4.0% reduction in bits per pixel (bpp), 0.03% increase in multi-scale\nstructural similarity (MS-SSIM), and only 0.47% decrease in peak\nsignal-to-noise ratio (PSNR), It also outperforms all traditional image\ncompression methods including JPEG2000 and HEIC by at least 20% in terms of\ncompression efficiency at similar reconstruction image quality. Regarding\nencoding and decoding time, our approach takes similar amount of time compared\nwith traditional methods with the support of GPU, which means it's almost ready\nfor industrial applications.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 03:21:47 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Xiao", "Licheng", ""], ["Wang", "Hairong", ""], ["Ling", "Nam", ""]]}, {"id": "2002.12528", "submitter": "Yinxiao Li", "authors": "Yinxiao Li", "title": "Handling Position Bias for Unbiased Learning to Rank in Hotels Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, search ranking and recommendation systems rely on a lot of data to\ntrain machine learning models such as Learning-to-Rank (LTR) models to rank\nresults for a given query, and implicit user feedbacks (e.g. click data) have\nbecome the dominant source of data collection due to its abundance and low\ncost, especially for major Internet companies. However, a drawback of this data\ncollection approach is the data could be highly biased, and one of the most\nsignificant biases is the position bias, where users are biased towards\nclicking on higher ranked results. In this work, we will investigate the\nmarginal importance of properly handling the position bias in an online test\nenvironment in Tripadvisor Hotels search. We propose an empirically effective\nmethod of handling the position bias that fully leverages the user action data.\nWe take advantage of the fact that when user clicks a result, he has almost\ncertainly observed all the results above, and the propensities of the results\nbelow the clicked result will be estimated by a simple but effective position\nbias model. The online A/B test results show that this method leads to an\nimproved search ranking model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 03:48:42 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Li", "Yinxiao", ""]]}, {"id": "2002.12530", "submitter": "Furao Shen", "authors": "Hongyan Hao, Yan Wang, Yudi Xia, Jian Zhao, Furao Shen", "title": "Temporal Convolutional Attention-based Network For Sequence Modeling", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of feed-forward models, the default model for sequence\nmodeling has gradually evolved to replace recurrent networks. Many powerful\nfeed-forward models based on convolutional networks and attention mechanism\nwere proposed and show more potential to handle sequence modeling tasks. We\nwonder that is there an architecture that can not only achieve an approximate\nsubstitution of recurrent network, but also absorb the advantages of\nfeed-forward models. So we propose an exploratory architecture referred to\nTemporal Convolutional Attention-based Network (TCAN) which combines temporal\nconvolutional network and attention mechanism. TCAN includes two parts, one is\nTemporal Attention (TA) which captures relevant features inside the sequence,\nthe other is Enhanced Residual (ER) which extracts shallow layer's important\ninformation and transfers to deep layers. We improve the state-of-the-art\nresults of bpc/perplexity to 26.92 on word-level PTB, 1.043 on character-level\nPTB, and 6.66 on WikiText-2.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 03:53:31 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 00:16:05 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Hao", "Hongyan", ""], ["Wang", "Yan", ""], ["Xia", "Yudi", ""], ["Zhao", "Jian", ""], ["Shen", "Furao", ""]]}, {"id": "2002.12537", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Kimia Nadjahi, Umut Simsekli, Shahin Shahrampour", "title": "Generalized Sliced Distances for Probability Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability metrics have become an indispensable part of modern statistics\nand machine learning, and they play a quintessential role in various\napplications, including statistical hypothesis testing and generative modeling.\nHowever, in a practical setting, the convergence behavior of the algorithms\nbuilt upon these distances have not been well established, except for a few\nspecific cases. In this paper, we introduce a broad family of probability\nmetrics, coined as Generalized Sliced Probability Metrics (GSPMs), that are\ndeeply rooted in the generalized Radon transform. We first verify that GSPMs\nare metrics. Then, we identify a subset of GSPMs that are equivalent to maximum\nmean discrepancy (MMD) with novel positive definite kernels, which come with a\nunique geometric interpretation. Finally, by exploiting this connection, we\nconsider GSPM-based gradient flows for generative modeling applications and\nshow that under mild assumptions, the gradient flow converges to the global\noptimum. We illustrate the utility of our approach on both real and synthetic\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 04:18:00 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Kolouri", "Soheil", ""], ["Nadjahi", "Kimia", ""], ["Simsekli", "Umut", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2002.12538", "submitter": "Nave Frost", "authors": "Sanjoy Dasgupta, Nave Frost, Michal Moshkovitz, Cyrus Rashtchian", "title": "Explainable $k$-Means and $k$-Medians Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a popular form of unsupervised learning for geometric data.\nUnfortunately, many clustering algorithms lead to cluster assignments that are\nhard to explain, partially because they depend on all the features of the data\nin a complicated way. To improve interpretability, we consider using a small\ndecision tree to partition a data set into clusters, so that clusters can be\ncharacterized in a straightforward manner. We study this problem from a\ntheoretical viewpoint, measuring cluster quality by the $k$-means and\n$k$-medians objectives: Must there exist a tree-induced clustering whose cost\nis comparable to that of the best unconstrained clustering, and if so, how can\nit be found? In terms of negative results, we show, first, that popular\ntop-down decision tree algorithms may lead to clusterings with arbitrarily\nlarge cost, and second, that any tree-induced clustering must in general incur\nan $\\Omega(\\log k)$ approximation factor compared to the optimal clustering. On\nthe positive side, we design an efficient algorithm that produces explainable\nclusters using a tree with $k$ leaves. For two means/medians, we show that a\nsingle threshold cut suffices to achieve a constant factor approximation, and\nwe give nearly-matching lower bounds. For general $k \\geq 2$, our algorithm is\nan $O(k)$ approximation to the optimal $k$-medians and an $O(k^2)$\napproximation to the optimal $k$-means. Prior to our work, no algorithms were\nknown with provable guarantees independent of dimension and input size.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 04:21:53 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 00:43:14 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Frost", "Nave", ""], ["Moshkovitz", "Michal", ""], ["Rashtchian", "Cyrus", ""]]}, {"id": "2002.12547", "submitter": "Ariel Jaffe", "authors": "Ariel Jaffe, Noah Amsel, Yariv Aizenbud, Boaz Nadler, Joseph T. Chang,\n  Yuval Kluger", "title": "Spectral neighbor joining for reconstruction of latent tree models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in multiple scientific applications is that the\ndistribution of observed data can be modeled by a latent tree graphical model.\nAn important example is phylogenetics, where the tree models the evolutionary\nlineages of a set of observed organisms. Given a set of independent\nrealizations of the random variables at the leaves of the tree, a key challenge\nis to infer the underlying tree topology. In this work we develop Spectral\nNeighbor Joining (SNJ), a novel method to recover the structure of latent tree\ngraphical models. Given a matrix that contains a measure of similarity between\nall pairs of observed variables, SNJ computes a spectral measure of cohesion\nbetween groups of observed variables. We prove that SNJ is consistent, and\nderive a sufficient condition for correct tree recovery from an estimated\nsimilarity matrix. Combining this condition with a concentration of measure\nresult on the similarity matrix, we bound the number of samples required to\nrecover the tree with high probability. We illustrate via extensive simulations\nthat in comparison to several other reconstruction methods, SNJ requires fewer\nsamples to accurately recover trees with a large number of leaves or long\nedges.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:13:08 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 01:57:45 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 02:15:30 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jaffe", "Ariel", ""], ["Amsel", "Noah", ""], ["Aizenbud", "Yariv", ""], ["Nadler", "Boaz", ""], ["Chang", "Joseph T.", ""], ["Kluger", "Yuval", ""]]}, {"id": "2002.12561", "submitter": "Cheng-Xiang Wang", "authors": "Jie Huang, Cheng-Xiang Wang, Lu Bai, Jian Sun, Yang Yang, Jie Li, Olav\n  Tirkkonen, and Ming-Tuo Zhou", "title": "A Big Data Enabled Channel Model for 5G Wireless Communication Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standardization process of the fifth generation (5G) wireless\ncommunications has recently been accelerated and the first commercial 5G\nservices would be provided as early as in 2018. The increasing of enormous\nsmartphones, new complex scenarios, large frequency bands, massive antenna\nelements, and dense small cells will generate big datasets and bring 5G\ncommunications to the era of big data. This paper investigates various\napplications of big data analytics, especially machine learning algorithms in\nwireless communications and channel modeling. We propose a big data and machine\nlearning enabled wireless channel model framework. The proposed channel model\nis based on artificial neural networks (ANNs), including feed-forward neural\nnetwork (FNN) and radial basis function neural network (RBF-NN). The input\nparameters are transmitter (Tx) and receiver (Rx) coordinates, Tx-Rx distance,\nand carrier frequency, while the output parameters are channel statistical\nproperties, including the received power, root mean square (RMS) delay spread\n(DS), and RMS angle spreads (ASs). Datasets used to train and test the ANNs are\ncollected from both real channel measurements and a geometry based stochastic\nmodel (GBSM). Simulation results show good performance and indicate that\nmachine learning algorithms can be powerful analytical tools for future\nmeasurement-based wireless channel modeling.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:56:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Jie", ""], ["Wang", "Cheng-Xiang", ""], ["Bai", "Lu", ""], ["Sun", "Jian", ""], ["Yang", "Yang", ""], ["Li", "Jie", ""], ["Tirkkonen", "Olav", ""], ["Zhou", "Ming-Tuo", ""]]}, {"id": "2002.12563", "submitter": "Ziang Long", "authors": "Ziang Long and Penghang Yin and Jack Xin", "title": "Global Convergence and Geometric Characterization of Slow to Fast Weight\n  Evolution in Neural Network Training for Classifying Linearly Non-Separable\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the dynamics of gradient descent in learning neural\nnetworks for classification problems. Unlike in existing works, we consider the\nlinearly non-separable case where the training data of different classes lie in\northogonal subspaces. We show that when the network has sufficient (but not\nexceedingly large) number of neurons, (1) the corresponding minimization\nproblem has a desirable landscape where all critical points are global minima\nwith perfect classification; (2) gradient descent is guaranteed to converge to\nthe global minima. Moreover, we discovered a geometric condition on the network\nweights so that when it is satisfied, the weight evolution transitions from a\nslow phase of weight direction spreading to a fast phase of weight convergence.\nThe geometric condition says that the convex hull of the weights projected on\nthe unit sphere contains the origin.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:56:55 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 22:37:33 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 08:50:41 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Long", "Ziang", ""], ["Yin", "Penghang", ""], ["Xin", "Jack", ""]]}, {"id": "2002.12570", "submitter": "Yoichi Sasaki", "authors": "Yoichi Sasaki, Kosuke Akimoto, Takanori Maehara", "title": "Learning Directly from Grammar Compressed Text", "comments": "12 pages, 4 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks using numerous text data have been successfully applied to a\nvariety of tasks. While massive text data is usually compressed using\ntechniques such as grammar compression, almost all of the previous machine\nlearning methods assume already decompressed sequence data as their input. In\nthis paper, we propose a method to directly apply neural sequence models to\ntext data compressed with grammar compression algorithms without decompression.\nTo encode the unique symbols that appear in compression rules, we introduce\ncomposer modules to incrementally encode the symbols into vector\nrepresentations. Through experiments on real datasets, we empirically showed\nthat the proposal model can achieve both memory and computational efficiency\nwhile maintaining moderate performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 06:51:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Sasaki", "Yoichi", ""], ["Akimoto", "Kosuke", ""], ["Maehara", "Takanori", ""]]}, {"id": "2002.12578", "submitter": "Fahad Shamshad", "authors": "Fahad Shamshad, Ali Ahmed", "title": "Class-Specific Blind Deconvolutional Phase Retrieval Under a Generative\n  Prior", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the highly ill-posed problem of jointly recovering\ntwo real-valued signals from the phaseless measurements of their circular\nconvolution. The problem arises in various imaging modalities such as Fourier\nptychography, X-ray crystallography, and in visible light communication. We\npropose to solve this inverse problem using alternating gradient descent\nalgorithm under two pretrained deep generative networks as priors; one is\ntrained on sharp images and the other on blur kernels. The proposed recovery\nalgorithm strives to find a sharp image and a blur kernel in the range of the\nrespective pre-generators that \\textit{best} explain the forward measurement\nmodel. In doing so, we are able to reconstruct quality image estimates.\nMoreover, the numerics show that the proposed approach performs well on the\nchallenging measurement models that reflect the physically realizable imaging\nsystems and is also robust to noise\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:36:28 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Shamshad", "Fahad", ""], ["Ahmed", "Ali", ""]]}, {"id": "2002.12585", "submitter": "Fenglin Liu", "authors": "Fenglin Liu, Xuancheng Ren, Yuanxin Liu, Kai Lei and Xu Sun", "title": "Exploring and Distilling Cross-Modal Information for Image Captioning", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, attention-based encoder-decoder models have been used extensively\nin image captioning. Yet there is still great difficulty for the current\nmethods to achieve deep image understanding. In this work, we argue that such\nunderstanding requires visual attention to correlated image regions and\nsemantic attention to coherent attributes of interest. Based on the\nTransformer, to perform effective attention, we explore image captioning from a\ncross-modal perspective and propose the Global-and-Local Information\nExploring-and-Distilling approach that explores and distills the source\ninformation in vision and language. It globally provides the aspect vector, a\nspatial and relational representation of images based on caption contexts,\nthrough the extraction of salient region groupings and attribute collocations,\nand locally extracts the fine-grained regions and attributes in reference to\nthe aspect vector for word selection. Our Transformer-based model achieves a\nCIDEr score of 129.3 in offline COCO evaluation on the COCO testing set with\nremarkable efficiency in terms of accuracy, speed, and parameter budget.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:46:48 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 11:53:51 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Liu", "Fenglin", ""], ["Ren", "Xuancheng", ""], ["Liu", "Yuanxin", ""], ["Lei", "Kai", ""], ["Sun", "Xu", ""]]}, {"id": "2002.12588", "submitter": "Mahsa Paknezhad", "authors": "Mahsa Paknezhad, Sheng Yang Michael Loh, Yukti Choudhury, Valerie Koh\n  Cui Koh, TimothyTay Kwang Yong, Hui Shan Tan, Ravindran Kanesvaran, Puay Hoon\n  Tan, John Yuen Shyi Peng, Weimiao Yu, Yongcheng Benjamin Tan, Yong Zhen Loy,\n  Min-Han Tan, Hwee Kuan Lee", "title": "Regional Registration of Whole Slide Image Stacks Containing Highly\n  Deformed Artefacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: High resolution 2D whole slide imaging provides rich information\nabout the tissue structure. This information can be a lot richer if these 2D\nimages can be stacked into a 3D tissue volume. A 3D analysis, however, requires\naccurate reconstruction of the tissue volume from the 2D image stack. This task\nis not trivial due to the distortions that each individual tissue slice\nexperiences while cutting and mounting the tissue on the glass slide.\nPerforming registration for the whole tissue slices may be adversely affected\nby the deformed tissue regions. Consequently, regional registration is found to\nbe more effective. In this paper, we propose an accurate and robust regional\nregistration algorithm for whole slide images which incrementally focuses\nregistration on the area around the region of interest. Results: Using mean\nsimilarity index as the metric, the proposed algorithm (mean $\\pm$ std: $0.84\n\\pm 0.11$) followed by a fine registration algorithm ($0.86 \\pm 0.08$)\noutperformed the state-of-the-art linear whole tissue registration algorithm\n($0.74 \\pm 0.19$) and the regional version of this algorithm ($0.81 \\pm 0.15$).\nThe proposed algorithm also outperforms the state-of-the-art nonlinear\nregistration algorithm (original : $0.82 \\pm 0.12$, regional : $0.77 \\pm 0.22$)\nfor whole slide images and a recently proposed patch-based registration\nalgorithm (patch size 256: $0.79 \\pm 0.16$ , patch size 512: $0.77 \\pm 0.16$)\nfor medical images. Availability: The C++ implementation code is available\nonline at the github repository:\nhttps://github.com/MahsaPaknezhad/WSIRegistration\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 07:57:56 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Paknezhad", "Mahsa", ""], ["Loh", "Sheng Yang Michael", ""], ["Choudhury", "Yukti", ""], ["Koh", "Valerie Koh Cui", ""], ["Yong", "TimothyTay Kwang", ""], ["Tan", "Hui Shan", ""], ["Kanesvaran", "Ravindran", ""], ["Tan", "Puay Hoon", ""], ["Peng", "John Yuen Shyi", ""], ["Yu", "Weimiao", ""], ["Tan", "Yongcheng Benjamin", ""], ["Loy", "Yong Zhen", ""], ["Tan", "Min-Han", ""], ["Lee", "Hwee Kuan", ""]]}, {"id": "2002.12592", "submitter": "Asifullah Khan", "authors": "Aqsa Saeed Qureshi, Asifullah Khan, and Muhammad Waleed Khan", "title": "Wind Speed Prediction using Deep Ensemble Learning with a Jet-like\n  Architecture", "comments": "Pages: 14, Tables: 6, Figures: 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wind is one of the most increasingly used renewable energy resources.\nAccurate and reliable forecast of wind speed is necessary for efficient power\nproduction; however, it is not an easy task because it depends upon\nmeteorological features of the surrounding region. Deep learning is extensively\nused these days for performing feature extraction. It has also been observed\nthat the integration of several learning models, known as ensemble learning,\ngenerally gives better performance compared to a single model. The design of\nwings, tail, and nose of a jet improves the aerodynamics resulting in a smooth\nand controlled flight of the jet against the variations of the air currents.\nInspired by the shape and working of a jet, a novel Deep Ensemble Learning\nusing Jet-like Architecture (DEL-Jet) technique is proposed to enhance the\ndiversity and robustness of a learning system against the variations in the\ninput space. The diverse feature spaces of the base-regressors are exploited\nusing the jet-like ensemble architecture. Two Convolutional Neural Networks (as\njet wings) and one deep Auto-Encoder (as jet tail) are used to extract the\ndiverse feature spaces from the input data. After that, nonlinear PCA (as jet\nmain body) is employed to reduce the dimensionality of extracted feature space.\nFinally, both the reduced and the original feature spaces are exploited to\ntrain the meta-regressor (as jet nose) for forecasting the wind speed. The\nperformance of the proposed DEL-Jet technique is evaluated for ten independent\nruns and shows that the deep and jet-like architecture helps in improving the\nrobustness and generalization of the learning system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:33:41 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 16:41:12 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Qureshi", "Aqsa Saeed", ""], ["Khan", "Asifullah", ""], ["Khan", "Muhammad Waleed", ""]]}, {"id": "2002.12597", "submitter": "Makoto Takamoto", "authors": "Makoto Takamoto, Yusuke Morishita, and Hitoshi Imaoka", "title": "An Efficient Method of Training Small Models for Regression Problems\n  with Knowledge Distillation", "comments": "7 pages, 2 figures, draft version of a paper accepted for IEEE 3rd\n  International Conference on Multimedia Information Processing and Retrieval\n  (MIPR2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing deep neural network (DNN) models becomes a very important and\nnecessary technique for real-world applications, such as deploying those models\non mobile devices. Knowledge distillation is one of the most popular methods\nfor model compression, and many studies have been made on developing this\ntechnique. However, those studies mainly focused on classification problems,\nand very few attempts have been made on regression problems, although there are\nmany application of DNNs on regression problems. In this paper, we propose a\nnew formalism of knowledge distillation for regression problems. First, we\npropose a new loss function, teacher outlier rejection loss, which rejects\noutliers in training samples using teacher model predictions. Second, we\nconsider a multi-task network with two outputs: one estimates training labels\nwhich is in general contaminated by noisy labels; And the other estimates\nteacher model's output which is expected to modify the noise labels following\nthe memorization effects. By considering the multi-task network, training of\nthe feature extraction of student models becomes more effective, and it allows\nus to obtain a better student model than one trained from scratch. We performed\ncomprehensive evaluation with one simple toy model: sinusoidal function, and\ntwo open datasets: MPIIGaze, and Multi-PIE. Our results show consistent\nimprovement in accuracy regardless of the annotation error level in the\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 08:46:12 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Takamoto", "Makoto", ""], ["Morishita", "Yusuke", ""], ["Imaoka", "Hitoshi", ""]]}, {"id": "2002.12613", "submitter": "Pier Giuseppe Sessa", "authors": "Pier Giuseppe Sessa, Ilija Bogunovic, Maryam Kamgarpour, Andreas\n  Krause", "title": "Mixed Strategies for Robust Optimization of Unknown Objectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust optimization problems, where the goal is to optimize an\nunknown objective function against the worst-case realization of an uncertain\nparameter. For this setting, we design a novel sample-efficient algorithm\nGP-MRO, which sequentially learns about the unknown objective from noisy point\nevaluations. GP-MRO seeks to discover a robust and randomized mixed strategy,\nthat maximizes the worst-case expected objective value. To achieve this, it\ncombines techniques from online learning with nonparametric confidence bounds\nfrom Gaussian processes. Our theoretical results characterize the number of\nsamples required by GP-MRO to discover a robust near-optimal mixed strategy for\ndifferent GP kernels of interest. We experimentally demonstrate the performance\nof our algorithm on synthetic datasets and on human-assisted trajectory\nplanning tasks for autonomous vehicles. In our simulations, we show that robust\ndeterministic strategies can be overly conservative, while the mixed strategies\nfound by GP-MRO significantly improve the overall performance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:28:17 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:19:06 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Sessa", "Pier Giuseppe", ""], ["Bogunovic", "Ilija", ""], ["Kamgarpour", "Maryam", ""], ["Krause", "Andreas", ""]]}, {"id": "2002.12620", "submitter": "Yiming Cui", "authors": "Ziqing Yang, Yiming Cui, Zhipeng Chen, Wanxiang Che, Ting Liu, Shijin\n  Wang, Guoping Hu", "title": "TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural\n  Language Processing", "comments": "To appear at ACL 2020 Demo Session", "journal-ref": null, "doi": "10.18653/v1/2020.acl-demos.2", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce TextBrewer, an open-source knowledge distillation\ntoolkit designed for natural language processing. It works with different\nneural network models and supports various kinds of supervised learning tasks,\nsuch as text classification, reading comprehension, sequence labeling.\nTextBrewer provides a simple and uniform workflow that enables quick setting up\nof distillation experiments with highly flexible configurations. It offers a\nset of predefined distillation methods and can be extended with custom code. As\na case study, we use TextBrewer to distill BERT on several typical NLP tasks.\nWith simple configurations, we achieve results that are comparable with or even\nhigher than the public distilled BERT models with similar numbers of\nparameters. Our toolkit is available through: http://textbrewer.hfl-rc.com\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:44:07 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 02:34:38 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Yang", "Ziqing", ""], ["Cui", "Yiming", ""], ["Chen", "Zhipeng", ""], ["Che", "Wanxiang", ""], ["Liu", "Ting", ""], ["Wang", "Shijin", ""], ["Hu", "Guoping", ""]]}, {"id": "2002.12623", "submitter": "Florian Bernard", "authors": "Florian Bernard, Zeeshan Khan Suri, Christian Theobalt", "title": "MINA: Convex Mixed-Integer Programming for Non-Rigid Shape Alignment", "comments": "to appear at CVPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a convex mixed-integer programming formulation for non-rigid shape\nmatching. To this end, we propose a novel shape deformation model based on an\nefficient low-dimensional discrete model, so that finding a globally optimal\nsolution is tractable in (most) practical cases. Our approach combines several\nfavourable properties: it is independent of the initialisation, it is much more\nefficient to solve to global optimality compared to analogous quadratic\nassignment problem formulations, and it is highly flexible in terms of the\nvariants of matching problems it can handle. Experimentally we demonstrate that\nour approach outperforms existing methods for sparse shape matching, that it\ncan be used for initialising dense shape matching methods, and we showcase its\nflexibility on several examples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:54:06 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Bernard", "Florian", ""], ["Suri", "Zeeshan Khan", ""], ["Theobalt", "Christian", ""]]}, {"id": "2002.12626", "submitter": "Akihiro Yabe", "authors": "Akihiro Yabe", "title": "Causality and Robust Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision-maker must consider cofounding bias when attempting to apply\nmachine learning prediction, and, while feature selection is widely recognized\nas important process in data-analysis, it could cause cofounding bias. A causal\nBayesian network is a standard tool for describing causal relationships, and if\nrelationships are known, then adjustment criteria can determine with which\nfeatures cofounding bias disappears. A standard modification would thus utilize\ncausal discovery algorithms for preventing cofounding bias in feature\nselection. Causal discovery algorithms, however, essentially rely on the\nfaithfulness assumption, which turn out to be easily violated in practical\nfeature selection settings. In this paper, we propose a meta-algorithm that can\nremedy existing feature selection algorithms in terms of cofounding bias. Our\nalgorithm is induced from a novel adjustment criterion that requires rather\nthan faithfulness, an assumption which can be induced from another well-known\nassumption of the causal sufficiency. We further prove that the features added\nthrough our modification convert cofounding bias into prediction variance. With\nthe aid of existing robust optimization technologies that regularize risky\nstrategies with high variance, then, we are able to successfully improve the\nthroughput performance of decision-making optimization, as is shown in our\nexperimental results.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:02:59 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Yabe", "Akihiro", ""]]}, {"id": "2002.12636", "submitter": "Alexander Tschantz", "authors": "Alexander Tschantz, Beren Millidge, Anil K. Seth, Christopher L.\n  Buckley", "title": "Reinforcement Learning through Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.SY eess.SY math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The central tenet of reinforcement learning (RL) is that agents seek to\nmaximize the sum of cumulative rewards. In contrast, active inference, an\nemerging framework within cognitive and computational neuroscience, proposes\nthat agents act to maximize the evidence for a biased generative model. Here,\nwe illustrate how ideas from active inference can augment traditional RL\napproaches by (i) furnishing an inherent balance of exploration and\nexploitation, and (ii) providing a more flexible conceptualization of reward.\nInspired by active inference, we develop and implement a novel objective for\ndecision making, which we term the free energy of the expected future. We\ndemonstrate that the resulting algorithm successfully balances exploration and\nexploitation, simultaneously achieving robust performance on several\nchallenging RL benchmarks with sparse, well-shaped, and no rewards.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:28:21 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Tschantz", "Alexander", ""], ["Millidge", "Beren", ""], ["Seth", "Anil K.", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "2002.12640", "submitter": "Meyer Scetbon", "authors": "Meyer Scetbon and Zaid Harchaoui", "title": "A Spectral Analysis of Dot-product Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present eigenvalue decay estimates of integral operators associated with\ncompositional dot-product kernels. The estimates improve on previous ones\nestablished for power series kernels on spheres. This allows us to obtain the\nvolumes of balls in the corresponding reproducing kernel Hilbert spaces. We\ndiscuss the consequences on statistical estimation with compositional dot\nproduct kernels and highlight interesting trade-offs between the approximation\nerror and the statistical error depending on the number of compositions and the\nsmoothness of the kernels.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:31:38 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 16:48:31 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Scetbon", "Meyer", ""], ["Harchaoui", "Zaid", ""]]}, {"id": "2002.12641", "submitter": "Manli Zhang", "authors": "Jianhong Zhang, Manli Zhang, Zhiwu Lu, Tao Xiang and Jirong Wen", "title": "AdarGCN: Adaptive Aggregation GCN for Few-Shot Learning", "comments": "The code is at github - https://github.com/RiceZJH/AdarGCN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing few-shot learning (FSL) methods assume that there exist sufficient\ntraining samples from source classes for knowledge transfer to target classes\nwith few training samples. However, this assumption is often invalid,\nespecially when it comes to fine-grained recognition. In this work, we define a\nnew FSL setting termed few-shot fewshot learning (FSFSL), under which both the\nsource and target classes have limited training samples. To overcome the source\nclass data scarcity problem, a natural option is to crawl images from the web\nwith class names as search keywords. However, the crawled images are inevitably\ncorrupted by large amount of noise (irrelevant images) and thus may harm the\nperformance. To address this problem, we propose a graph convolutional network\n(GCN)-based label denoising (LDN) method to remove the irrelevant images.\nFurther, with the cleaned web images as well as the original clean training\nimages, we propose a GCN-based FSL method. For both the LDN and FSL tasks, a\nnovel adaptive aggregation GCN (AdarGCN) model is proposed, which differs from\nexisting GCN models in that adaptive aggregation is performed based on a\nmulti-head multi-level aggregation module. With AdarGCN, how much and how far\ninformation carried by each graph node is propagated in the graph structure can\nbe determined automatically, therefore alleviating the effects of both noisy\nand outlying training samples. Extensive experiments show the superior\nperformance of our AdarGCN under both the new FSFSL and the conventional FSL\nsettings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:34:36 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 08:05:17 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Zhang", "Jianhong", ""], ["Zhang", "Manli", ""], ["Lu", "Zhiwu", ""], ["Xiang", "Tao", ""], ["Wen", "Jirong", ""]]}, {"id": "2002.12642", "submitter": "Buse Melis Ozyildirim", "authors": "Buse Melis Ozyildirim (1), Mariam Kiran (2) ((1) Department of\n  Computer Engineering Cukurova University, (2) Energy Sciences Network\n  Lawrence Berkeley National Laboratory)", "title": "Do optimization methods in deep learning applications matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in deep learning, exponential data growth and increasing model\ncomplexity, developing efficient optimization methods are attracting much\nresearch attention. Several implementations favor the use of Conjugate Gradient\n(CG) and Stochastic Gradient Descent (SGD) as being practical and elegant\nsolutions to achieve quick convergence, however, these optimization processes\nalso present many limitations in learning across deep learning applications.\nRecent research is exploring higher-order optimization functions as better\napproaches, but these present very complex computational challenges for\npractical use. Comparing first and higher-order optimization functions, in this\npaper, our experiments reveal that Levemberg-Marquardt (LM) significantly\nsupersedes optimal convergence but suffers from very large processing time\nincreasing the training complexity of both, classification and reinforcement\nlearning problems. Our experiments compare off-the-shelf optimization\nfunctions(CG, SGD, LM and L-BFGS) in standard CIFAR, MNIST, CartPole and\nFlappyBird experiments.The paper presents arguments on which optimization\nfunctions to use and further, which functions would benefit from\nparallelization efforts to improve pretraining time and learning rate\nconvergence.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:36:40 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ozyildirim", "Buse Melis", ""], ["Kiran", "Mariam", ""]]}, {"id": "2002.12645", "submitter": "Joanna Rownicka", "authors": "Jennifer Williams, Joanna Rownicka, Pilar Oplustil, Simon King", "title": "Comparison of Speech Representations for Automatic Quality Estimation in\n  Multi-Speaker Text-to-Speech Synthesis", "comments": "accepted at Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to characterize how different speakers contribute to the perceived\noutput quality of multi-speaker Text-to-Speech (TTS) synthesis. We\nautomatically rate the quality of TTS using a neural network (NN) trained on\nhuman mean opinion score (MOS) ratings. First, we train and evaluate our NN\nmodel on 13 different TTS and voice conversion (VC) systems from the ASVSpoof\n2019 Logical Access (LA) Dataset. Since it is not known how best to represent\nspeech for this task, we compare 8 different representations alongside MOSNet\nframe-based features. Our representations include image-based spectrogram\nfeatures and x-vector embeddings that explicitly model different types of noise\nsuch as T60 reverberation time. Our NN predicts MOS with a high correlation to\nhuman judgments. We report prediction correlation and error. A key finding is\nthe quality achieved for certain speakers seems consistent, regardless of the\nTTS or VC system. It is widely accepted that some speakers give higher quality\nthan others for building a TTS system: our method provides an automatic way to\nidentify such speakers. Finally, to see if our quality prediction models\ngeneralize, we predict quality scores for synthetic speech using a separate\nmulti-speaker TTS system that was trained on LibriTTS data, and conduct our own\nMOS listening test to compare human ratings with our NN predictions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:44:32 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 09:25:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Williams", "Jennifer", ""], ["Rownicka", "Joanna", ""], ["Oplustil", "Pilar", ""], ["King", "Simon", ""]]}, {"id": "2002.12648", "submitter": "Hang Yang", "authors": "Hang Yang, Zekun Niu, Lilin Yi, Shilin Xiao", "title": "Optical Fiber Channel Modeling Using Conditional Generative Adversarial\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use CGAN (conditional generative adversarial network) to\nmodel the fiber-optic channel and the performance is similar with the\nconventional method, SSFM (split-step Fourier method), while the running time\nis reduced from several minutes to about 2 seconds at 80-km distance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:54:27 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Yang", "Hang", ""], ["Niu", "Zekun", ""], ["Yi", "Lilin", ""], ["Xiao", "Shilin", ""]]}, {"id": "2002.12655", "submitter": "Edgar Sch\\\"onfeld", "authors": "Edgar Sch\\\"onfeld, Bernt Schiele, Anna Khoreva", "title": "A U-Net Based Discriminator for Generative Adversarial Networks", "comments": "CVPR 2020 (Main Conference). Code repository:\n  https://github.com/boschresearch/unetgan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the major remaining challenges for generative adversarial networks\n(GANs) is the capacity to synthesize globally and locally coherent images with\nobject shapes and textures indistinguishable from real images. To target this\nissue we propose an alternative U-Net based discriminator architecture,\nborrowing the insights from the segmentation literature. The proposed U-Net\nbased architecture allows to provide detailed per-pixel feedback to the\ngenerator while maintaining the global coherence of synthesized images, by\nproviding the global image feedback as well. Empowered by the per-pixel\nresponse of the discriminator, we further propose a per-pixel consistency\nregularization technique based on the CutMix data augmentation, encouraging the\nU-Net discriminator to focus more on semantic and structural changes between\nreal and fake images. This improves the U-Net discriminator training, further\nenhancing the quality of generated samples. The novel discriminator improves\nover the state of the art in terms of the standard distribution and image\nquality metrics, enabling the generator to synthesize images with varying\nstructure, appearance and levels of detail, maintaining global and local\nrealism. Compared to the BigGAN baseline, we achieve an average improvement of\n2.7 FID points across FFHQ, CelebA, and the newly introduced COCO-Animals\ndataset. The code is available at https://github.com/boschresearch/unetgan.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:16:54 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 23:22:06 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Sch\u00f6nfeld", "Edgar", ""], ["Schiele", "Bernt", ""], ["Khoreva", "Anna", ""]]}, {"id": "2002.12660", "submitter": "Meysam Goodarzi", "authors": "M. Goodarzi, D. Cvetkovski, N. Maletic, J. Gutierrez and E. Grass", "title": "Synchronization in 5G: a Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a hybrid approach to synchronize large scale\nnetworks. In particular, we draw on Kalman Filtering (KF) along with\ntime-stamps generated by the Precision Time Protocol (PTP) for pairwise node\nsynchronization. Furthermore, we investigate the merit of Factor Graphs (FGs)\nalong with Belief Propagation (BP) algorithm in achieving high precision\nend-to-end network synchronization. Finally, we present the idea of dividing\nthe large-scale network into local synchronization domains, for each of which a\nsuitable sync algorithm is utilized. The simulation results indicate that,\ndespite the simplifications in the hybrid approach, the error in the offset\nestimation remains below 5 ns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:27:48 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goodarzi", "M.", ""], ["Cvetkovski", "D.", ""], ["Maletic", "N.", ""], ["Gutierrez", "J.", ""], ["Grass", "E.", ""]]}, {"id": "2002.12663", "submitter": "Rui Lin", "authors": "Rui Lin, Ching-Yun Ko, Zhuolun He, Cong Chen, Yuan Cheng, Hao Yu,\n  Graziano Chesi, Ngai Wong", "title": "HOTCAKE: Higher Order Tucker Articulated Kernels for Deeper CNN\n  Compression", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging edge computing has promoted immense interests in compacting a\nneural network without sacrificing much accuracy. In this regard, low-rank\ntensor decomposition constitutes a powerful tool to compress convolutional\nneural networks (CNNs) by decomposing the 4-way kernel tensor into multi-stage\nsmaller ones. Building on top of Tucker-2 decomposition, we propose a\ngeneralized Higher Order Tucker Articulated Kernels (HOTCAKE) scheme comprising\nfour steps: input channel decomposition, guided Tucker rank selection, higher\norder Tucker decomposition and fine-tuning. By subjecting each CONV layer to\nHOTCAKE, a highly compressed CNN model with graceful accuracy trade-off is\nobtained. Experiments show HOTCAKE can compress even pre-compressed models and\nproduce state-of-the-art lightweight networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 11:37:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lin", "Rui", ""], ["Ko", "Ching-Yun", ""], ["He", "Zhuolun", ""], ["Chen", "Cong", ""], ["Cheng", "Yuan", ""], ["Yu", "Hao", ""], ["Chesi", "Graziano", ""], ["Wong", "Ngai", ""]]}, {"id": "2002.12674", "submitter": "Sebastian Lunz", "authors": "Sebastian Lunz, Yingzhen Li, Andrew Fitzgibbon, Nate Kushman", "title": "Inverse Graphics GAN: Learning to Generate 3D Shapes from Unstructured\n  2D Data", "comments": "8 pages paper, 3 pages references, 18 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown the ability to learn generative models for 3D shapes\nfrom only unstructured 2D images. However, training such models requires\ndifferentiating through the rasterization step of the rendering process,\ntherefore past work has focused on developing bespoke rendering models which\nsmooth over this non-differentiable process in various ways. Such models are\nthus unable to take advantage of the photo-realistic, fully featured,\nindustrial renderers built by the gaming and graphics industry. In this paper\nwe introduce the first scalable training technique for 3D generative models\nfrom 2D data which utilizes an off-the-shelf non-differentiable renderer. To\naccount for the non-differentiability, we introduce a proxy neural renderer to\nmatch the output of the non-differentiable renderer. We further propose\ndiscriminator output matching to ensure that the neural renderer learns to\nsmooth over the rasterization appropriately. We evaluate our model on images\nrendered from our generated 3D shapes, and show that our model can consistently\nlearn to generate better shapes than existing models when trained with\nexclusively unstructured 2D images.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 12:28:12 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lunz", "Sebastian", ""], ["Li", "Yingzhen", ""], ["Fitzgibbon", "Andrew", ""], ["Kushman", "Nate", ""]]}, {"id": "2002.12688", "submitter": "Chuan Xu", "authors": "Giovanni Neglia and Chuan Xu and Don Towsley and Gianmarco Calbi", "title": "Decentralized gradient methods: does topology matter?", "comments": "A version of this paper is to appear at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus-based distributed optimization methods have recently been advocated\nas alternatives to parameter server and ring all-reduce paradigms for large\nscale training of machine learning models. In this case, each worker maintains\na local estimate of the optimal parameter vector and iteratively updates it by\naveraging the estimates obtained from its neighbors, and applying a correction\non the basis of its local dataset. While theoretical results suggest that\nworker communication topology should have strong impact on the number of epochs\nneeded to converge, previous experiments have shown the opposite conclusion.\nThis paper sheds lights on this apparent contradiction and show how sparse\ntopologies can lead to faster convergence even in the absence of communication\ndelays.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 12:59:25 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Neglia", "Giovanni", ""], ["Xu", "Chuan", ""], ["Towsley", "Don", ""], ["Calbi", "Gianmarco", ""]]}, {"id": "2002.12704", "submitter": "Kefan Chen", "authors": "Kefan Chen, Wei Pang", "title": "ImmuNetNAS: An Immune-network approach for searching Convolutional\n  Neural Network Architectures", "comments": "7 pages, 7 figures, 5 tables. No conference right now", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we propose ImmuNetNAS, a novel Neural Architecture Search\n(NAS) approach inspired by the immune network theory. The core of ImmuNetNAS is\nbuilt on the original immune network algorithm, which iteratively updates the\npopulation through hypermutation and selection, and eliminates the\nself-generation individuals that do not meet the requirements through comparing\nantibody affinity and inter-specific similarity. In addition, in order to\nfacilitate the mutation operation, we propose a novel two-component based\nneural structure coding strategy. Furthermore, an improved mutation strategy\nbased on Standard Genetic Algorithm (SGA) was proposed according to this\nencoding method. Finally, based on the proposed two-component based coding\nmethod, a new antibody affinity calculation method was developed to screen\nsuitable neural architectures. Systematic evaluations demonstrate that our\nsystem has achieved good performance on both the MNIST and CIFAR-10 datasets.\nWe open-source our code on GitHub in order to share it with other deep learning\nresearchers and practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 13:32:57 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chen", "Kefan", ""], ["Pang", "Wei", ""]]}, {"id": "2002.12718", "submitter": "Sachin Goyal", "authors": "Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri\n  and Prateek Jain", "title": "DROCC: Deep Robust One-Class Classification", "comments": "16 pages, 9 figures, Published at International Conference on Machine\n  Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical approaches for one-class problems such as one-class SVM and\nisolation forest require careful feature engineering when applied to structured\ndomains like images. State-of-the-art methods aim to leverage deep learning to\nlearn appropriate features via two main approaches. The first approach based on\npredicting transformations (Golan & El-Yaniv, 2018; Hendrycks et al., 2019a)\nwhile successful in some domains, crucially depends on an appropriate\ndomain-specific set of transformations that are hard to obtain in general. The\nsecond approach of minimizing a classical one-class loss on the learned final\nlayer representations, e.g., DeepSVDD (Ruff et al., 2018) suffers from the\nfundamental drawback of representation collapse. In this work, we propose Deep\nRobust One-Class Classification (DROCC) that is both applicable to most\nstandard domains without requiring any side-information and robust to\nrepresentation collapse. DROCC is based on the assumption that the points from\nthe class of interest lie on a well-sampled, locally linear low dimensional\nmanifold. Empirical evaluation demonstrates that DROCC is highly effective in\ntwo different one-class problem settings and on a range of real-world datasets\nacross different domains: tabular data, images (CIFAR and ImageNet), audio, and\ntime-series, offering up to 20% increase in accuracy over the state-of-the-art\nin anomaly detection. Code is available at https://github.com/microsoft/EdgeML.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:03:31 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 13:28:18 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Goyal", "Sachin", ""], ["Raghunathan", "Aditi", ""], ["Jain", "Moksh", ""], ["Simhadri", "Harsha Vardhan", ""], ["Jain", "Prateek", ""]]}, {"id": "2002.12738", "submitter": "Mohamed Hasan Dr", "authors": "Mohamed Hasan, Matthew Warburton, Wisdom C. Agboh, Mehmet R. Dogar,\n  Matteo Leonetti, He Wang, Faisal Mushtaq, Mark Mon-Williams and Anthony G.\n  Cohn", "title": "Human-like Planning for Reaching in Cluttered Environments", "comments": "To be published in ICRA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans, in comparison to robots, are remarkably adept at reaching for objects\nin cluttered environments. The best existing robot planners are based on random\nsampling of configuration space -- which becomes excessively high-dimensional\nwith large number of objects. Consequently, most planners often fail to\nefficiently find object manipulation plans in such environments. We addressed\nthis problem by identifying high-level manipulation plans in humans, and\ntransferring these skills to robot planners. We used virtual reality to capture\nhuman participants reaching for a target object on a tabletop cluttered with\nobstacles. From this, we devised a qualitative representation of the task space\nto abstract the decision making, irrespective of the number of obstacles. Based\non this representation, human demonstrations were segmented and used to train\ndecision classifiers. Using these classifiers, our planner produced a list of\nwaypoints in task space. These waypoints provided a high-level plan, which\ncould be transferred to an arbitrary robot model and used to initialise a local\ntrajectory optimiser. We evaluated this approach through testing on unseen\nhuman VR data, a physics-based robot simulation, and a real robot (dataset and\ncode are publicly available). We found that the human-like planner outperformed\na state-of-the-art standard trajectory optimisation algorithm, and was able to\ngenerate effective strategies for rapid planning -- irrespective of the number\nof obstacles in the environment.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:28:50 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:23:00 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Hasan", "Mohamed", ""], ["Warburton", "Matthew", ""], ["Agboh", "Wisdom C.", ""], ["Dogar", "Mehmet R.", ""], ["Leonetti", "Matteo", ""], ["Wang", "He", ""], ["Mushtaq", "Faisal", ""], ["Mon-Williams", "Mark", ""], ["Cohn", "Anthony G.", ""]]}, {"id": "2002.12744", "submitter": "Jian Li", "authors": "Jian Li, Yong Liu, Weiping Wang", "title": "Convolutional Spectral Kernel Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, non-stationary spectral kernels have drawn much attention, owing to\nits powerful feature representation ability in revealing long-range\ncorrelations and input-dependent characteristics. However, non-stationary\nspectral kernels are still shallow models, thus they are deficient to learn\nboth hierarchical features and local interdependence. In this paper, to obtain\nhierarchical and local knowledge, we build an interpretable convolutional\nspectral kernel network (\\texttt{CSKN}) based on the inverse Fourier transform,\nwhere we introduce deep architectures and convolutional filters into\nnon-stationary spectral kernel representations. Moreover, based on Rademacher\ncomplexity, we derive the generalization error bounds and introduce two\nregularizers to improve the performance. Combining the regularizers and recent\nadvancements on random initialization, we finally complete the learning\nframework of \\texttt{CSKN}. Extensive experiments results on real-world\ndatasets validate the effectiveness of the learning framework and coincide with\nour theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 14:35:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Li", "Jian", ""], ["Liu", "Yong", ""], ["Wang", "Weiping", ""]]}, {"id": "2002.12755", "submitter": "Chenye Wu", "authors": "Chenbei Lu, Kui Wang, Chenye Wu", "title": "Effective End-to-End Learning Framework for Economic Dispatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional wisdom to improve the effectiveness of economic dispatch is to\ndesign the load forecasting method as accurately as possible. However, this\napproach can be problematic due to the temporal and spatial correlations\nbetween system cost and load prediction errors. This motivates us to adopt the\nnotion of end-to-end machine learning and to propose a task-specific learning\ncriteria to conduct economic dispatch. Specifically, to maximize the data\nutilization, we design an efficient optimization kernel for the learning\nprocess. We provide both theoretical analysis and empirical insights to\nhighlight the effectiveness and efficiency of the proposed learning framework.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 08:04:27 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Lu", "Chenbei", ""], ["Wang", "Kui", ""], ["Wu", "Chenye", ""]]}, {"id": "2002.12756", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Yan Han, Mason Carnahan", "title": "Speech Synthesis using EEG", "comments": "Accepted for publication at IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate speech synthesis using different\nelectroencephalography (EEG) feature sets recently introduced in [1]. We make\nuse of a recurrent neural network (RNN) regression model to predict acoustic\nfeatures directly from EEG features. We demonstrate our results using EEG\nfeatures recorded in parallel with spoken speech as well as using EEG recorded\nin parallel with listening utterances. We provide EEG based speech synthesis\nresults for four subjects in this paper and our results demonstrate the\nfeasibility of synthesizing speech directly from EEG features.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 03:53:45 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:30:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Han", "Yan", ""], ["Carnahan", "Mason", ""]]}, {"id": "2002.12759", "submitter": "Bin Hu", "authors": "Zhenyu Liu, Dongyu Wang, Lan Zhang and Bin Hu", "title": "A Novel Decision Tree for Depression Recognition in Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is a common mental disorder worldwide which causes a range of\nserious outcomes. The diagnosis of depression relies on patient-reported scales\nand psychiatrist interview which may lead to subjective bias. In recent years,\nmore and more researchers are devoted to depression recognition in speech ,\nwhich may be an effective and objective indicator. This study proposes a new\nspeech segment fusion method based on decision tree to improve the depression\nrecognition accuracy and conducts a validation on a sample of 52 subjects (23\ndepressed patients and 29 healthy controls). The recognition accuracy are 75.8%\nand 68.5% for male and female respectively on gender-dependent models. It can\nbe concluded from the data that the proposed decision tree model can improve\nthe depression classification performance.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 10:46:38 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liu", "Zhenyu", ""], ["Wang", "Dongyu", ""], ["Zhang", "Lan", ""], ["Hu", "Bin", ""]]}, {"id": "2002.12761", "submitter": "Qingjian Lin", "authors": "Qingjian Lin, Weicheng Cai, Lin Yang, Junjie Wang, Jun Zhang, Ming Li", "title": "DIHARD II is Still Hard: Experimental Results and Discussions from the\n  DKU-LENOVO Team", "comments": "Submitted to Odyssesy 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the submitted system for the second DIHARD Speech\nDiarization Challenge from the DKULENOVO team. Our diarization system includes\nmultiple modules, namely voice activity detection (VAD), segmentation, speaker\nembedding extraction, similarity scoring, clustering, resegmentation and\noverlap detection. For each module, we explore different techniques to enhance\nperformance. Our final submission employs the ResNet-LSTM based VAD, the Deep\nResNet based speaker embedding, the LSTM based similarity scoring and spectral\nclustering. Variational Bayes (VB) diarization is applied in the resegmentation\nstage and overlap detection also brings slight improvement. Our proposed system\nachieves 18.84% DER in Track1 and 27.90% DER in Track2. Although our systems\nhave reduced the DERs by 27.5% and 31.7% relatively against the official\nbaselines, we believe that the diarization task is still very difficult.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 11:50:32 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 02:46:24 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Lin", "Qingjian", ""], ["Cai", "Weicheng", ""], ["Yang", "Lin", ""], ["Wang", "Junjie", ""], ["Zhang", "Jun", ""], ["Li", "Ming", ""]]}, {"id": "2002.12764", "submitter": "Joel Shor", "authors": "Joel Shor, Aren Jansen, Ronnie Maor, Oran Lang, Omry Tuval, Felix de\n  Chaumont Quitry, Marco Tagliasacchi, Ira Shavitt, Dotan Emanuel, Yinnon Haviv", "title": "Towards Learning a Universal Non-Semantic Representation of Speech", "comments": null, "journal-ref": "Proceedings of INTERSPEECH 2020", "doi": "10.21437/Interspeech.2020-1242", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultimate goal of transfer learning is to reduce labeled data requirements\nby exploiting a pre-existing embedding model trained for different datasets or\ntasks. The visual and language communities have established benchmarks to\ncompare embeddings, but the speech community has yet to do so. This paper\nproposes a benchmark for comparing speech representations on non-semantic\ntasks, and proposes a representation based on an unsupervised triplet-loss\nobjective. The proposed representation outperforms other representations on the\nbenchmark, and even exceeds state-of-the-art performance on a number of\ntransfer learning tasks. The embedding is trained on a publicly available\ndataset, and it is tested on a variety of low-resource downstream tasks,\nincluding personalization tasks and medical domain. The benchmark, models, and\nevaluation code are publicly released.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:38:24 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 17:42:36 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 07:41:51 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 13:46:53 GMT"}, {"version": "v5", "created": "Fri, 19 Jun 2020 06:15:54 GMT"}, {"version": "v6", "created": "Thu, 6 Aug 2020 04:53:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shor", "Joel", ""], ["Jansen", "Aren", ""], ["Maor", "Ronnie", ""], ["Lang", "Oran", ""], ["Tuval", "Omry", ""], ["Quitry", "Felix de Chaumont", ""], ["Tagliasacchi", "Marco", ""], ["Shavitt", "Ira", ""], ["Emanuel", "Dotan", ""], ["Haviv", "Yinnon", ""]]}, {"id": "2002.12776", "submitter": "Radu Grosu", "authors": "Radu Grosu", "title": "ResNets, NeuralODEs and CT-RNNs are Particular Neural Regulatory\n  Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that ResNets, NeuralODEs, and CT-RNNs, are particular neural\nregulatory networks (NRNs), a biophysical model for the nonspiking neurons\nencountered in small species, such as the C.elegans nematode, and in the retina\nof large species. Compared to ResNets, NeuralODEs and CT-RNNs, NRNs have an\nadditional multiplicative term in their synaptic computation, allowing them to\nadapt to each particular input. This additional flexibility makes NRNs $M$\ntimes more succinct than NeuralODEs and CT-RNNs, where $M$ is proportional to\nthe size of the training set. Moreover, as NeuralODEs and CT-RNNs are $N$ times\nmore succinct than ResNets, where $N$ is the number of integration steps\nrequired to compute the output $F(x)$ for a given input $x$, NRNs are in total\n$M\\,{\\cdot}\\,N$ more succinct than ResNets. For a given approximation task,\nthis considerable succinctness allows to learn a very small and therefore\nunderstandable NRN, whose behavior can be explained in terms of well\nestablished architectural motifs, that NRNs share with gene regulatory\nnetworks, such as, activation, inhibition, sequentialization, mutual exclusion,\nand synchronization. To the best of our knowledge, this paper unifies for the\nfirst time the mainstream work on deep neural networks with the one in biology\nand neuroscience in a quantitative fashion.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 18:33:20 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 13:05:48 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 07:20:12 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Grosu", "Radu", ""]]}, {"id": "2002.12789", "submitter": "Chen Liang", "authors": "Chen Liang, Ziqi Liu, Bin Liu, Jun Zhou, Xiaolong Li, Shuang Yang,\n  Yuan Qi", "title": "Uncovering Insurance Fraud Conspiracy with Network Learning", "comments": "Accepted by SIGIR '19. Proceedings of the 42nd International ACM\n  SIGIR Conference on Research and Development in Information Retrieval. 2019", "journal-ref": null, "doi": "10.1145/3331184.3331372", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fraudulent claim detection is one of the greatest challenges the insurance\nindustry faces. Alibaba's return-freight insurance, providing return-shipping\npostage compensations over product return on the e-commerce platform, receives\nthousands of potentially fraudulent claims every day. Such deliberate abuse of\nthe insurance policy could lead to heavy financial losses. In order to detect\nand prevent fraudulent insurance claims, we developed a novel data-driven\nprocedure to identify groups of organized fraudsters, one of the major\ncontributions to financial losses, by learning network information. In this\npaper, we introduce a device-sharing network among claimants, followed by\ndeveloping an automated solution for fraud detection based on graph learning\nalgorithms, to separate fraudsters from regular customers and uncover groups of\norganized fraudsters. This solution applied at Alibaba achieves more than 80%\nprecision while covering 44% more suspicious accounts compared with a\npreviously deployed rule-based classifier after human expert investigations.\nOur approach can easily and effectively generalizes to other types of\ninsurance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 13:15:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liang", "Chen", ""], ["Liu", "Ziqi", ""], ["Liu", "Bin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Yang", "Shuang", ""], ["Qi", "Yuan", ""]]}, {"id": "2002.12794", "submitter": "Mohammad Nikzad", "authors": "Mohammad Nikzad, Aaron Nicolson, Yongsheng Gao, Jun Zhou, Kuldip K.\n  Paliwal, Fanhua Shang", "title": "Deep Residual-Dense Lattice Network for Speech Enhancement", "comments": "8 pages, Accepted by AAAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with residual links (ResNets) and causal\ndilated convolutional units have been the network of choice for deep learning\napproaches to speech enhancement. While residual links improve gradient flow\nduring training, feature diminution of shallow layer outputs can occur due to\nrepetitive summations with deeper layer outputs. One strategy to improve\nfeature re-usage is to fuse both ResNets and densely connected CNNs\n(DenseNets). DenseNets, however, over-allocate parameters for feature re-usage.\nMotivated by this, we propose the residual-dense lattice network (RDL-Net),\nwhich is a new CNN for speech enhancement that employs both residual and dense\naggregations without over-allocating parameters for feature re-usage. This is\nmanaged through the topology of the RDL blocks, which limit the number of\noutputs used for dense aggregations. Our extensive experimental investigation\nshows that RDL-Nets are able to achieve a higher speech enhancement performance\nthan CNNs that employ residual and/or dense aggregations. RDL-Nets also use\nsubstantially fewer parameters and have a lower computational requirement.\nFurthermore, we demonstrate that RDL-Nets outperform many state-of-the-art deep\nlearning approaches to speech enhancement.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:36:30 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Nikzad", "Mohammad", ""], ["Nicolson", "Aaron", ""], ["Gao", "Yongsheng", ""], ["Zhou", "Jun", ""], ["Paliwal", "Kuldip K.", ""], ["Shang", "Fanhua", ""]]}, {"id": "2002.12795", "submitter": "Hossein Valavi", "authors": "Hossein Valavi, Sulin Liu and Peter J. Ramadge", "title": "The Landscape of Matrix Factorization Revisited", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the landscape of the simple matrix factorization problem. For\nlow-rank matrix factorization, prior work has shown that there exist infinitely\nmany critical points all of which are either global minima or strict saddles.\nAt a strict saddle the minimum eigenvalue of the Hessian is negative. Of\ninterest is whether this minimum eigenvalue is uniformly bounded below zero\nover all strict saddles. To answer this we consider orbits of critical points\nunder the general linear group. For each orbit we identify a representative\npoint, called a canonical point. If a canonical point is a strict saddle, so is\nevery point on its orbit. We derive an expression for the minimum eigenvalue of\nthe Hessian at each canonical strict saddle and use this to show that the\nminimum eigenvalue of the Hessian over the set of strict saddles is not\nuniformly bounded below zero. We also show that a known invariance property of\ngradient flow ensures the solution of gradient flow only encounters critical\npoints on an invariant manifold $\\mathcal{M}_C$ determined by the initial\ncondition. We show that, in contrast to the general situation, the minimum\neigenvalue of strict saddles in $\\mathcal{M}_{0}$ is uniformly bounded below\nzero. We obtain an expression for this bound in terms of the singular values of\nthe matrix being factorized. This bound depends on the size of the nonzero\nsingular values and on the separation between distinct nonzero singular values\nof the matrix.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:27:22 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 21:47:17 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Valavi", "Hossein", ""], ["Liu", "Sulin", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "2002.12815", "submitter": "Deepak Nathani", "authors": "Jatin Chauhan, Deepak Nathani, Manohar Kaul", "title": "Few-Shot Learning on Graphs via Super-Classes based on Graph Spectral\n  Measures", "comments": "19 pages, 9 figures, Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to study the problem of few shot graph classification in graph\nneural networks (GNNs) to recognize unseen classes, given limited labeled graph\nexamples. Despite several interesting GNN variants being proposed recently for\nnode and graph classification tasks, when faced with scarce labeled examples in\nthe few shot setting, these GNNs exhibit significant loss in classification\nperformance. Here, we present an approach where a probability measure is\nassigned to each graph based on the spectrum of the graphs normalized\nLaplacian. This enables us to accordingly cluster the graph base labels\nassociated with each graph into super classes, where the Lp Wasserstein\ndistance serves as our underlying distance metric. Subsequently, a super graph\nconstructed based on the super classes is then fed to our proposed GNN\nframework which exploits the latent inter class relationships made explicit by\nthe super graph to achieve better class label separation among the graphs. We\nconduct exhaustive empirical evaluations of our proposed method and show that\nit outperforms both the adaptation of state of the art graph classification\nmethods to few shot scenario and our naive baseline GNNs. Additionally, we also\nextend and study the behavior of our method to semi supervised and active\nlearning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 17:11:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chauhan", "Jatin", ""], ["Nathani", "Deepak", ""], ["Kaul", "Manohar", ""]]}, {"id": "2002.12819", "submitter": "Shengyu Huang", "authors": "Shengyu Huang, Mikhail Usvyatsov and Konrad Schindler", "title": "Indoor Scene Recognition in 3D", "comments": "IROS 2020 - Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognising in what type of environment one is located is an important\nperception task. For instance, for a robot operating in indoors it is helpful\nto be aware whether it is in a kitchen, a hallway or a bedroom. Existing\napproaches attempt to classify the scene based on 2D images or 2.5D range\nimages. Here, we study scene recognition from 3D point cloud (or voxel) data,\nand show that it greatly outperforms methods based on 2D birds-eye views.\nMoreover, we advocate multi-task learning as a way of improving scene\nrecognition, building on the fact that the scene type is highly correlated with\nthe objects in the scene, and therefore with its semantic segmentation into\ndifferent object classes. In a series of ablation studies, we show that\nsuccessful scene recognition is not just the recognition of individual objects\nunique to some scene type (such as a bathtub), but depends on several different\ncues, including coarse 3D geometry, colour, and the (implicit) distribution of\nobject categories. Moreover, we demonstrate that surprisingly sparse 3D data is\nsufficient to classify indoor scenes with good accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 15:47:09 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 21:25:18 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Huang", "Shengyu", ""], ["Usvyatsov", "Mikhail", ""], ["Schindler", "Konrad", ""]]}, {"id": "2002.12826", "submitter": "Marco Podda", "authors": "Marco Podda, Davide Bacciu, Alessio Micheli", "title": "A Deep Generative Model for Fragment-Based Molecule Generation", "comments": null, "journal-ref": "PMLR 108:2240-2250 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecule generation is a challenging open problem in cheminformatics.\nCurrently, deep generative approaches addressing the challenge belong to two\nbroad categories, differing in how molecules are represented. One approach\nencodes molecular graphs as strings of text, and learns their corresponding\ncharacter-based language model. Another, more expressive, approach operates\ndirectly on the molecular graph. In this work, we address two limitations of\nthe former: generation of invalid and duplicate molecules. To improve validity\nrates, we develop a language model for small molecular substructures called\nfragments, loosely inspired by the well-known paradigm of Fragment-Based Drug\nDesign. In other words, we generate molecules fragment by fragment, instead of\natom by atom. To improve uniqueness rates, we present a frequency-based masking\nstrategy that helps generate molecules with infrequent fragments. We show\nexperimentally that our model largely outperforms other language model-based\ncompetitors, reaching state-of-the-art performances typical of graph-based\napproaches. Moreover, generated molecules display molecular properties similar\nto those in the training sample, even in absence of explicit task-specific\nsupervision.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 15:55:11 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Podda", "Marco", ""], ["Bacciu", "Davide", ""], ["Micheli", "Alessio", ""]]}, {"id": "2002.12830", "submitter": "Muhammad Hafidh Firmansyah", "authors": "Muhammad Hafidh Firmansyah, Anand Paul, Deblina Bhattacharya, Gul\n  Malik Urfa", "title": "A.I. based Embedded Speech to Text Using Deepspeech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deepspeech was very useful for development IoT devices that need voice\nrecognition. One of the voice recognition systems is deepspeech from Mozilla.\nDeepspeech is an open-source voice recognition that was using a neural network\nto convert speech spectrogram into a text transcript. This paper shows the\nimplementation process of speech recognition on a low-end computational device.\nDevelopment of English-language speech recognition that has many datasets\nbecome a good point for starting. The model that used results from pre-trained\nmodel that provide by each version of deepspeech, without change of the model\nthat already released, furthermore the benefit of using raspberry pi as a media\nend-to-end speech recognition device become a good thing, user can change and\nmodify of the speech recognition, and also deepspeech can be standalone device\nwithout need continuously internet connection to process speech recognition,\nand even this paper show the power of Tensorflow Lite can make a significant\ndifference on inference by deepspeech rather than using Tensorflow\nnon-Lite.This paper shows the experiment using Deepspeech version 0.1.0, 0.1.1,\nand 0.6.0, and there is some improvement on Deepspeech version 0.6.0, faster\nwhile processing speech-to-text on old hardware raspberry pi 3 b+.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 08:27:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Firmansyah", "Muhammad Hafidh", ""], ["Paul", "Anand", ""], ["Bhattacharya", "Deblina", ""], ["Urfa", "Gul Malik", ""]]}, {"id": "2002.12852", "submitter": "Sushant Veer", "authors": "Sushant Veer and Anirudha Majumdar", "title": "Probably Approximately Correct Vision-Based Planning using Motion\n  Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an approach for learning vision-based planners that\nprovably generalize to novel environments (i.e., environments unseen during\ntraining). We leverage the Probably Approximately Correct (PAC)-Bayes framework\nto obtain an upper bound on the expected cost of policies across all\nenvironments. Minimizing the PAC-Bayes upper bound thus trains policies that\nare accompanied by a certificate of performance on novel environments. The\ntraining pipeline we propose provides strong generalization guarantees for deep\nneural network policies by (a) obtaining a good prior distribution on the space\nof policies using Evolutionary Strategies (ES) followed by (b) formulating the\nPAC-Bayes optimization as an efficiently-solvable parametric convex\noptimization problem. We demonstrate the efficacy of our approach for producing\nstrong generalization guarantees for learned vision-based motion planners\nthrough two simulated examples: (1) an Unmanned Aerial Vehicle (UAV) navigating\nobstacle fields with an onboard vision sensor, and (2) a dynamic quadrupedal\nrobot traversing rough terrains with proprioceptive and exteroceptive sensors.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:29:59 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 02:38:21 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Veer", "Sushant", ""], ["Majumdar", "Anirudha", ""]]}, {"id": "2002.12860", "submitter": "Saiteja Utpala", "authors": "Saiteja Utpala and Piyush Rai", "title": "Quantile Regularization: Towards Implicit Calibration of Regression\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have shown that most deep learning models are often poorly\ncalibrated, i.e., they may produce overconfident predictions that are wrong. It\nis therefore desirable to have models that produce predictive uncertainty\nestimates that are reliable. Several approaches have been proposed recently to\ncalibrate classification models. However, there is relatively little work on\ncalibrating regression models. We present a method for calibrating regression\nmodels based on a novel quantile regularizer defined as the cumulative KL\ndivergence between two CDFs. Unlike most of the existing approaches for\ncalibrating regression models, which are based on post-hoc processing of the\nmodel's output and require an additional dataset, our method is trainable in an\nend-to-end fashion without requiring an additional dataset. The proposed\nregularizer can be used with any training objective for regression. We also\nshow that post-hoc calibration methods like Isotonic Calibration sometimes\ncompound miscalibration whereas our method provides consistently better\ncalibrations. We provide empirical results demonstrating that the proposed\nquantile regularizer significantly improves calibration for regression models\ntrained using approaches, such as Dropout VI and Deep Ensembles.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 16:53:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Utpala", "Saiteja", ""], ["Rai", "Piyush", ""]]}, {"id": "2002.12867", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Noe Casas, Eneko Agirre", "title": "Do all Roads Lead to Rome? Understanding the Role of Initialization in\n  Iterative Back-Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Back-translation provides a simple yet effective approach to exploit\nmonolingual corpora in Neural Machine Translation (NMT). Its iterative variant,\nwhere two opposite NMT models are jointly trained by alternately using a\nsynthetic parallel corpus generated by the reverse model, plays a central role\nin unsupervised machine translation. In order to start producing sound\ntranslations and provide a meaningful training signal to each other, existing\napproaches rely on either a separate machine translation system to warm up the\niterative procedure, or some form of pre-training to initialize the weights of\nthe model. In this paper, we analyze the role that such initialization plays in\niterative back-translation. Is the behavior of the final system heavily\ndependent on it? Or does iterative back-translation converge to a similar\nsolution given any reasonable initialization? Through a series of empirical\nexperiments over a diverse set of warmup systems, we show that, although the\nquality of the initial system does affect final performance, its effect is\nrelatively small, as iterative back-translation has a strong tendency to\nconvergence to a similar solution. As such, the margin of improvement left for\nthe initialization method is narrow, suggesting that future research should\nfocus more on improving the iterative mechanism itself.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:05:55 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Casas", "Noe", ""], ["Agirre", "Eneko", ""]]}, {"id": "2002.12873", "submitter": "Praneeth Narayanamurthy", "authors": "Praneeth Narayanamurthy, Namrata Vaswani, Aditya Ramamoorthy", "title": "Federated Over-Air Subspace Tracking from Incomplete and Corrupted Data", "comments": "New model, algorithm for centralized case; added algorithms to deal\n  with sparse outliers; modified organization significantly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NA math.IT math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace tracking (ST) with missing data (ST-miss) or outliers (Robust ST) or\nboth (Robust ST-miss) has been extensively studied in the last many years. This\nwork provides a new simple algorithm and guarantee for both ST with missing\ndata (ST-miss) and RST-miss. Unlike past work on this topic, the algorithm is\nmuch simpler (uses fewer parameters) and the guarantee does not make the\nartificial assumption of piecewise constant subspace change, although it still\nhandles that setting. Secondly, we extend our approach and its analysis to\nprovably solving these problems when the raw data is federated and when the\nover-air data communication modality is used for information exchange between\nthe $K$ peer nodes and the center.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:17:01 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 21:51:57 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 16:22:16 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Narayanamurthy", "Praneeth", ""], ["Vaswani", "Namrata", ""], ["Ramamoorthy", "Aditya", ""]]}, {"id": "2002.12880", "submitter": "Andrew Wilson", "authors": "Marc Finzi, Samuel Stanton, Pavel Izmailov, Andrew Gordon Wilson", "title": "Generalizing Convolutional Neural Networks for Equivariance to Lie\n  Groups on Arbitrary Continuous Data", "comments": "ICML 2020. Code available at https://github.com/mfinzi/LieConv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The translation equivariance of convolutional layers enables convolutional\nneural networks to generalize well on image problems. While translation\nequivariance provides a powerful inductive bias for images, we often\nadditionally desire equivariance to other transformations, such as rotations,\nespecially for non-image data. We propose a general method to construct a\nconvolutional layer that is equivariant to transformations from any specified\nLie group with a surjective exponential map. Incorporating equivariance to a\nnew group requires implementing only the group exponential and logarithm maps,\nenabling rapid prototyping. Showcasing the simplicity and generality of our\nmethod, we apply the same model architecture to images, ball-and-stick\nmolecular data, and Hamiltonian dynamical systems. For Hamiltonian systems, the\nequivariance of our models is especially impactful, leading to exact\nconservation of linear and angular momentum.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:40:38 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 11:50:51 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 15:08:36 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Finzi", "Marc", ""], ["Stanton", "Samuel", ""], ["Izmailov", "Pavel", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "2002.12886", "submitter": "Alban Main De Boissiere", "authors": "Alban Main de Boissiere, Rita Noumeir", "title": "Infrared and 3D skeleton feature fusion for RGB-D action recognition", "comments": "11 pages, 5 figures, submitted to IEEE Access", "journal-ref": "IEEE Access, vol. 8, pp. 168297-168308, 2020", "doi": "10.1109/ACCESS.2020.3023599", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A challenge of skeleton-based action recognition is the difficulty to\nclassify actions with similar motions and object-related actions. Visual clues\nfrom other streams help in that regard. RGB data are sensible to illumination\nconditions, thus unusable in the dark. To alleviate this issue and still\nbenefit from a visual stream, we propose a modular network (FUSION) combining\nskeleton and infrared data. A 2D convolutional neural network (CNN) is used as\na pose module to extract features from skeleton data. A 3D CNN is used as an\ninfrared module to extract visual cues from videos. Both feature vectors are\nthen concatenated and exploited conjointly using a multilayer perceptron (MLP).\nSkeleton data also condition the infrared videos, providing a crop around the\nperforming subjects and thus virtually focusing the attention of the infrared\nmodule. Ablation studies show that using pre-trained networks on other large\nscale datasets as our modules and data augmentation yield considerable\nimprovements on the action classification accuracy. The strong contribution of\nour cropping strategy is also demonstrated. We evaluate our method on the NTU\nRGB+D dataset, the largest dataset for human action recognition from depth\ncameras, and report state-of-the-art performances.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 17:42:53 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["de Boissiere", "Alban Main", ""], ["Noumeir", "Rita", ""]]}, {"id": "2002.12898", "submitter": "Yanran Li", "authors": "Shuo Wang, Yanran Li, Jiang Zhang, Qingye Meng, Lingwei Meng, Fei Gao", "title": "PM2.5-GNN: A Domain Knowledge Enhanced Graph Neural Network For PM2.5\n  Forecasting", "comments": "Submission to KDD 2020. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When predicting PM2.5 concentrations, it is necessary to consider complex\ninformation sources since the concentrations are influenced by various factors\nwithin a long period. In this paper, we identify a set of critical domain\nknowledge for PM2.5 forecasting and develop a novel graph based model,\nPM2.5-GNN, being capable of capturing long-term dependencies. On a real-world\ndataset, we validate the effectiveness of the proposed model and examine its\nabilities of capturing both fine-grained and long-term influences in PM2.5\nprocess. The proposed PM2.5-GNN has also been deployed online to provide free\nforecasting service.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 03:33:54 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Wang", "Shuo", ""], ["Li", "Yanran", ""], ["Zhang", "Jiang", ""], ["Meng", "Qingye", ""], ["Meng", "Lingwei", ""], ["Gao", "Fei", ""]]}, {"id": "2002.12899", "submitter": "Paul Fergus Dr", "authors": "P. Fergus, C. Chalmers", "title": "BMI: A Behavior Measurement Indicator for Fuel Poverty Using Aggregated\n  Load Readings from Smart Meters", "comments": "33 Pages, 12 Figures, Submitted as a book chapter to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuel poverty affects between 50 and 125 million households in Europe and is a\nsignificant issue for both developed and developing countries globally. This\nmeans that fuel poor residents are unable to adequately warm their home and run\nthe necessary energy services needed for lighting, cooking, hot water, and\nelectrical appliances. The problem is complex but is typically caused by three\nfactors; low income, high energy costs, and energy inefficient homes. In the\nUnited Kingdom (UK), 4 million families are currently living in fuel poverty.\nThose in series financial difficulty are either forced to self-disconnect or\nhave their services terminated by energy providers. Fuel poverty contributed to\n10,000 reported deaths in England in the winter of 2016-2107 due to homes being\ncold. While it is recognized by governments as a social, public health and\nenvironmental policy issue, the European Union (EU) has failed to provide a\ncommon definition of fuel poverty or a conventional set of indicators to\nmeasure it. This chapter discusses current fuel poverty strategies across the\nEU and proposes a new and foundational behavior measurement indicator designed\nto directly assess and monitor fuel poverty risks in households using smart\nmeters, Consumer Access Device (CAD) data and machine learning. By detecting\nActivities of Daily Living (ADLS) through household appliance usage, it is\npossible to spot the early signs of financial difficulty and identify when\nsupport packages are required.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:03:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Fergus", "P.", ""], ["Chalmers", "C.", ""]]}, {"id": "2002.12900", "submitter": "Seyedramin Rasoulinezhad", "authors": "Seyedramin Rasoulinezhad, Sean Fox, Hao Zhou, Lingli Wang, David\n  Boland, Philip H.W. Leong", "title": "MajorityNets: BNNs Utilising Approximate Popcount for Improved\n  Efficiency", "comments": "4 pages", "journal-ref": "International Conference on Field-Programmable Technology, {FPT}\n  2019,Tianjin, China, December 9-13, 2019", "doi": "10.1109/ICFPT47387.2019.00062", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized neural networks (BNNs) have shown exciting potential for utilising\nneural networks in embedded implementations where area, energy and latency\nconstraints are paramount. With BNNs, multiply-accumulate (MAC) operations can\nbe simplified to XnorPopcount operations, leading to massive reductions in both\nmemory and computation resources. Furthermore, multiple efficient\nimplementations of BNNs have been reported on field-programmable gate array\n(FPGA) implementations. This paper proposes a smaller, faster, more\nenergy-efficient approximate replacement for the XnorPopcountoperation, called\nXNorMaj, inspired by state-of-the-art FPGAlook-up table schemes which benefit\nFPGA implementations. Weshow that XNorMaj is up to 2x more resource-efficient\nthan the XnorPopcount operation. While the XNorMaj operation has a minor\ndetrimental impact on accuracy, the resource savings enable us to use larger\nnetworks to recover the loss.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 04:02:43 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Rasoulinezhad", "Seyedramin", ""], ["Fox", "Sean", ""], ["Zhou", "Hao", ""], ["Wang", "Lingli", ""], ["Boland", "David", ""], ["Leong", "Philip H. W.", ""]]}, {"id": "2002.12903", "submitter": "Michael Celentano", "authors": "Michael Celentano, Andrea Montanari, Yuchen Wu", "title": "The estimation error of general first order methods", "comments": "49 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern large-scale statistical models require to estimate thousands to\nmillions of parameters. This is often accomplished by iterative algorithms such\nas gradient descent, projected gradient descent or their accelerated versions.\nWhat are the fundamental limits to these approaches? This question is well\nunderstood from an optimization viewpoint when the underlying objective is\nconvex. Work in this area characterizes the gap to global optimality as a\nfunction of the number of iterations. However, these results have only indirect\nimplications in terms of the gap to statistical optimality.\n  Here we consider two families of high-dimensional estimation problems:\nhigh-dimensional regression and low-rank matrix estimation, and introduce a\nclass of `general first order methods' that aim at efficiently estimating the\nunderlying parameters. This class of algorithms is broad enough to include\nclassical first order optimization (for convex and non-convex objectives), but\nalso other types of algorithms. Under a random design assumption, we derive\nlower bounds on the estimation error that hold in the high-dimensional\nasymptotics in which both the number of observations and the number of\nparameters diverge. These lower bounds are optimal in the sense that there\nexist algorithms whose estimation error matches the lower bounds up to\nasymptotically negligible terms. We illustrate our general results through\napplications to sparse phase retrieval and sparse principal component analysis.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:13:47 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 17:44:58 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Celentano", "Michael", ""], ["Montanari", "Andrea", ""], ["Wu", "Yuchen", ""]]}, {"id": "2002.12909", "submitter": "Laura Greige", "authors": "Laura Greige, Peter Chin", "title": "Reinforcement Learning in FlipIt", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has shown much success in games such as chess,\nbackgammon and Go. However, in most of these games, agents have full knowledge\nof the environment at all times. In this paper, we describe a deep learning\nmodel that successfully optimizes its score using reinforcement learning in a\ngame with incomplete and imperfect information. We apply our model to FlipIt, a\ntwo-player game in which both players, the attacker and the defender, compete\nfor ownership of a shared resource and only receive information on the current\nstate (such as the current owner of the resource, or the time since the\nopponent last moved, etc.) upon making a move. Our model is a deep neural\nnetwork combined with Q-learning and is trained to maximize the defender's time\nof ownership of the resource. Despite the imperfect observations, our model\nsuccessfully learns an optimal cost-effective counter-strategy and shows the\nadvantages of the use of deep reinforcement learning in game theoretic\nscenarios. Our results show that it outperforms the Greedy strategy against\ndistributions such as periodic and exponential distributions without any prior\nknowledge of the opponent's strategy, and we generalize the model to $n$-player\ngames.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:26:24 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Greige", "Laura", ""], ["Chin", "Peter", ""]]}, {"id": "2002.12911", "submitter": "Krishna Reddy Kesari", "authors": "Krishna Reddy Kesari and Jean Honorio", "title": "First Order Methods take Exponential Time to Converge to Global\n  Minimizers of Non-Convex Functions", "comments": null, "journal-ref": "IEEE International Symposium on Information Theory (ISIT), 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms typically perform optimization over a class of\nnon-convex functions. In this work, we provide bounds on the fundamental\nhardness of identifying the global minimizer of a non convex function.\nSpecifically, we design a family of parametrized non-convex functions and\nemploy statistical lower bounds for parameter estimation. We show that the\nparameter estimation problem is equivalent to the problem of function\nidentification in the given family. We then claim that non convex optimization\nis at least as hard as function identification. Jointly, we prove that any\nfirst order method can take exponential time to converge to a global minimizer.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:28:43 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 04:04:06 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kesari", "Krishna Reddy", ""], ["Honorio", "Jean", ""]]}, {"id": "2002.12913", "submitter": "SeugnJu Cho", "authors": "Seungju Cho, Tae Joon Jun, Mingu Kang, Daeyoung Kim", "title": "Applying Tensor Decomposition to image for Robustness against\n  Adversarial Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays the deep learning technology is growing faster and shows dramatic\nperformance in computer vision areas. However, it turns out a deep learning\nbased model is highly vulnerable to some small perturbation called an\nadversarial attack. It can easily fool the deep learning model by adding small\nperturbations. On the other hand, tensor decomposition method widely uses for\ncompressing the tensor data, including data matrix, image, etc. In this paper,\nwe suggest combining tensor decomposition for defending the model against\nadversarial example. We verify this idea is simple and effective to resist\nadversarial attack. In addition, this method rarely degrades the original\nperformance of clean data. We experiment on MNIST, CIFAR10 and ImageNet data\nand show our method robust on state-of-the-art attack methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:30:22 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 14:28:41 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Cho", "Seungju", ""], ["Jun", "Tae Joon", ""], ["Kang", "Mingu", ""], ["Kim", "Daeyoung", ""]]}, {"id": "2002.12915", "submitter": "Colin Wei", "authors": "Colin Wei, Sham Kakade, Tengyu Ma", "title": "The Implicit and Explicit Regularization Effects of Dropout", "comments": "Published in ICML 2020. Code available at\n  https://github.com/cwein3/dropout-analytical", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a widely-used regularization technique, often required to obtain\nstate-of-the-art for a number of architectures. This work demonstrates that\ndropout introduces two distinct but entangled regularization effects: an\nexplicit effect (also studied in prior work) which occurs since dropout\nmodifies the expected training objective, and, perhaps surprisingly, an\nadditional implicit effect from the stochasticity in the dropout training\nupdate. This implicit regularization effect is analogous to the effect of\nstochasticity in small mini-batch stochastic gradient descent. We disentangle\nthese two effects through controlled experiments. We then derive analytic\nsimplifications which characterize each effect in terms of the derivatives of\nthe model and the loss, for deep neural networks. We demonstrate these\nsimplified, analytic regularizers accurately capture the important aspects of\ndropout, showing they faithfully replace dropout in practice.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:31:17 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:18:05 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 07:44:22 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wei", "Colin", ""], ["Kakade", "Sham", ""], ["Ma", "Tengyu", ""]]}, {"id": "2002.12920", "submitter": "Kaidi Xu", "authors": "Kaidi Xu, Zhouxing Shi, Huan Zhang, Yihan Wang, Kai-Wei Chang, Minlie\n  Huang, Bhavya Kailkhura, Xue Lin, Cho-Jui Hsieh", "title": "Automatic Perturbation Analysis for Scalable Certified Robustness and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear relaxation based perturbation analysis (LiRPA) for neural networks,\nwhich computes provable linear bounds of output neurons given a certain amount\nof input perturbation, has become a core component in robustness verification\nand certified defense. The majority of LiRPA-based methods focus on simple\nfeed-forward networks and need particular manual derivations and\nimplementations when extended to other architectures. In this paper, we develop\nan automatic framework to enable perturbation analysis on any neural network\nstructures, by generalizing existing LiRPA algorithms such as CROWN to operate\non general computational graphs. The flexibility, differentiability and ease of\nuse of our framework allow us to obtain state-of-the-art results on LiRPA based\ncertified defense on fairly complicated networks like DenseNet, ResNeXt and\nTransformer that are not supported by prior works. Our framework also enables\nloss fusion, a technique that significantly reduces the computational\ncomplexity of LiRPA for certified defense. For the first time, we demonstrate\nLiRPA based certified defense on Tiny ImageNet and Downscaled ImageNet where\nprevious approaches cannot scale to due to the relatively large number of\nclasses. Our work also yields an open-source library for the community to apply\nLiRPA to areas beyond certified defense without much LiRPA expertise, e.g., we\ncreate a neural network with a probably flat optimization landscape by applying\nLiRPA to network parameters. Our opensource library is available at\nhttps://github.com/KaidiXu/auto_LiRPA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:47:43 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 17:43:48 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 03:26:40 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Xu", "Kaidi", ""], ["Shi", "Zhouxing", ""], ["Zhang", "Huan", ""], ["Wang", "Yihan", ""], ["Chang", "Kai-Wei", ""], ["Huang", "Minlie", ""], ["Kailkhura", "Bhavya", ""], ["Lin", "Xue", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2002.12928", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Zhongwen Xu, Vivek Veeriah, Matteo Hessel, Junhyuk Oh,\n  Hado van Hasselt, David Silver and Satinder Singh", "title": "A Self-Tuning Actor-Critic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms are highly sensitive to the choice of\nhyperparameters, typically requiring significant manual effort to identify\nhyperparameters that perform well on a new domain. In this paper, we take a\nstep towards addressing this issue by using metagradients to automatically\nadapt hyperparameters online by meta-gradient descent (Xu et al., 2018). We\napply our algorithm, Self-Tuning Actor-Critic (STAC), to self-tune all the\ndifferentiable hyperparameters of an actor-critic loss function, to discover\nauxiliary tasks, and to improve off-policy learning using a novel leaky V-trace\noperator. STAC is simple to use, sample efficient and does not require a\nsignificant increase in compute. Ablative studies show that the overall\nperformance of STAC improved as we adapt more hyperparameters. When applied to\nthe Arcade Learning Environment (Bellemare et al. 2012), STAC improved the\nmedian human normalized score in 200M steps from 243% to 364%. When applied to\nthe DM Control suite (Tassa et al., 2018), STAC improved the mean score in 30M\nsteps from 217 to 389 when learning with features, from 108 to 202 when\nlearning from pixels, and from 195 to 295 in the Real-World Reinforcement\nLearning Challenge (Dulac-Arnold et al., 2020).\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:55:38 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 13:30:26 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 15:59:58 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 14:41:37 GMT"}, {"version": "v5", "created": "Wed, 14 Apr 2021 08:43:34 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zahavy", "Tom", ""], ["Xu", "Zhongwen", ""], ["Veeriah", "Vivek", ""], ["Hessel", "Matteo", ""], ["Oh", "Junhyuk", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""], ["Singh", "Satinder", ""]]}]