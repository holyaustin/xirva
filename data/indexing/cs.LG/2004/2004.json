[{"id": "2004.00001", "submitter": "Krishna Subramani", "authors": "Krishna Subramani, Preeti Rao, Alexandre D'Hooge", "title": "VaPar Synth -- A Variational Parametric Model for Audio Synthesis", "comments": "https://github.com/SubramaniKrishna/VaPar-Synth , Accepted in ICASSP\n  2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054181", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of data-driven statistical modeling and abundant computing\npower, researchers are turning increasingly to deep learning for audio\nsynthesis. These methods try to model audio signals directly in the time or\nfrequency domain. In the interest of more flexible control over the generated\nsound, it could be more useful to work with a parametric representation of the\nsignal which corresponds more directly to the musical attributes such as pitch,\ndynamics and timbre. We present VaPar Synth - a Variational Parametric\nSynthesizer which utilizes a conditional variational autoencoder (CVAE) trained\non a suitable parametric representation. We demonstrate our proposed model's\ncapabilities via the reconstruction and generation of instrumental tones with\nflexible control over their pitch.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 16:05:47 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Subramani", "Krishna", ""], ["Rao", "Preeti", ""], ["D'Hooge", "Alexandre", ""]]}, {"id": "2004.00008", "submitter": "Randall Gladen", "authors": "R. W. Gladen, V. A. Chirayath, A. J. Fairchild, M. T. Manry, A. R.\n  Koymen, and A. H. Weiss", "title": "Efficient Machine Learning Approach for Optimizing the Timing Resolution\n  of a High Purity Germanium Detector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cond-mat.mtrl-sci cs.LG hep-ex nucl-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe here an efficient machine-learning based approach for the\noptimization of parameters used for extracting the arrival time of waveforms,\nin particular those generated by the detection of 511 keV annihilation\ngamma-rays by a 60 cm3 coaxial high purity germanium detector (HPGe). The\nmethod utilizes a type of artificial neural network (ANN) called a\nself-organizing map (SOM) to cluster the HPGe waveforms based on the shape of\ntheir rising edges. The optimal timing parameters for HPGe waveforms belonging\nto a particular cluster are found by minimizing the time difference between the\nHPGe signal and a signal produced by a BaF2 scintillation detector. Applying\nthese variable timing parameters to the HPGe signals achieved a\ngamma-coincidence timing resolution of ~ 4.3 ns at the 511 keV photo peak\n(defined as 511 +- 50 keV) and a timing resolution of ~ 6.5 ns for the entire\ngamma spectrum--without rejecting any valid pulses. This timing resolution\napproaches the best obtained by analog nuclear electronics, without the\ncorresponding complexities of analog optimization procedures. We further\ndemonstrate the universality and efficacy of the machine learning approach by\napplying the method to the generation of secondary electron time-of-flight\nspectra following the implantation of energetic positrons on a sample.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:04:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gladen", "R. W.", ""], ["Chirayath", "V. A.", ""], ["Fairchild", "A. J.", ""], ["Manry", "M. T.", ""], ["Koymen", "A. R.", ""], ["Weiss", "A. H.", ""]]}, {"id": "2004.00038", "submitter": "Kayhan Ghafoor", "authors": "Halgurd S. Maghdid, Aras T. Asaad, Kayhan Zrar Ghafoor, Ali Safaa\n  Sadiq, and Muhammad Khurram Khan", "title": "Diagnosing COVID-19 Pneumonia from X-Ray and CT Images using Deep\n  Learning and Transfer Learning Algorithms", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  COVID-19 (also known as 2019 Novel Coronavirus) first emerged in Wuhan, China\nand spread across the globe with unprecedented effect and has now become the\ngreatest crisis of the modern era. The COVID-19 has proved much more pervasive\ndemands for diagnosis that has driven researchers to develop more intelligent,\nhighly responsive and efficient detection methods. In this work, we focus on\nproposing AI tools that can be used by radiologists or healthcare professionals\nto diagnose COVID-19 cases in a quick and accurate manner. However, the lack of\na publicly available dataset of X-ray and CT images makes the design of such AI\ntools a challenging task. To this end, this study aims to build a comprehensive\ndataset of X-rays and CT scan images from multiple sources as well as provides\na simple but an effective COVID-19 detection technique using deep learning and\ntransfer learning algorithms. In this vein, a simple convolution neural network\n(CNN) and modified pre-trained AlexNet model are applied on the prepared X-rays\nand CT scan images dataset. The result of the experiments shows that the\nutilized models can provide accuracy up to 98 % via pre-trained network and\n94.1 % accuracy by using the modified CNN.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:10:10 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Maghdid", "Halgurd S.", ""], ["Asaad", "Aras T.", ""], ["Ghafoor", "Kayhan Zrar", ""], ["Sadiq", "Ali Safaa", ""], ["Khan", "Muhammad Khurram", ""]]}, {"id": "2004.00053", "submitter": "Congzheng Song", "authors": "Congzheng Song and Ananth Raghunathan", "title": "Information Leakage in Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embeddings are functions that map raw input data to low-dimensional vector\nrepresentations, while preserving important semantic information about the\ninputs. Pre-training embeddings on a large amount of unlabeled data and\nfine-tuning them for downstream tasks is now a de facto standard in achieving\nstate of the art learning in many domains.\n  We demonstrate that embeddings, in addition to encoding generic semantics,\noften also present a vector that leaks sensitive information about the input\ndata. We develop three classes of attacks to systematically study information\nthat might be leaked by embeddings. First, embedding vectors can be inverted to\npartially recover some of the input data. As an example, we show that our\nattacks on popular sentence embeddings recover between 50\\%--70\\% of the input\nwords (F1 scores of 0.5--0.7). Second, embeddings may reveal sensitive\nattributes inherent in inputs and independent of the underlying semantic task\nat hand. Attributes such as authorship of text can be easily extracted by\ntraining an inference model on just a handful of labeled embedding vectors.\nThird, embedding models leak moderate amount of membership information for\ninfrequent training data inputs. We extensively evaluate our attacks on various\nstate-of-the-art embedding models in the text domain. We also propose and\nevaluate defenses that can prevent the leakage to some extent at a minor cost\nin utility.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:33:36 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 19:58:14 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Song", "Congzheng", ""], ["Raghunathan", "Ananth", ""]]}, {"id": "2004.00070", "submitter": "Davide Abati", "authors": "Davide Abati, Jakub Tomczak, Tijmen Blankevoort, Simone Calderara,\n  Rita Cucchiara, Babak Ehteshami Bejnordi", "title": "Conditional Channel Gated Networks for Task-Aware Continual Learning", "comments": "CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks experience catastrophic forgetting when\noptimized on a sequence of learning problems: as they meet the objective of the\ncurrent training examples, their performance on previous tasks drops\ndrastically. In this work, we introduce a novel framework to tackle this\nproblem with conditional computation. We equip each convolutional layer with\ntask-specific gating modules, selecting which filters to apply on the given\ninput. This way, we achieve two appealing properties. Firstly, the execution\npatterns of the gates allow to identify and protect important filters, ensuring\nno loss in the performance of the model for previously learned tasks. Secondly,\nby using a sparsity objective, we can promote the selection of a limited set of\nkernels, allowing to retain sufficient model capacity to digest new\ntasks.Existing solutions require, at test time, awareness of the task to which\neach example belongs to. This knowledge, however, may not be available in many\npractical scenarios. Therefore, we additionally introduce a task classifier\nthat predicts the task label of each example, to deal with settings in which a\ntask oracle is not available. We validate our proposal on four continual\nlearning datasets. Results show that our model consistently outperforms\nexisting methods both in the presence and the absence of a task oracle.\nNotably, on Split SVHN and Imagenet-50 datasets, our model yields up to 23.98%\nand 17.42% improvement in accuracy w.r.t. competing methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:35:07 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Abati", "Davide", ""], ["Tomczak", "Jakub", ""], ["Blankevoort", "Tijmen", ""], ["Calderara", "Simone", ""], ["Cucchiara", "Rita", ""], ["Bejnordi", "Babak Ehteshami", ""]]}, {"id": "2004.00077", "submitter": "Michael Hersche", "authors": "Xiaying Wang, Michael Hersche, Batuhan T\\\"omekce, Burak Kaya, Michele\n  Magno, Luca Benini", "title": "An Accurate EEGNet-based Motor-Imagery Brain-Computer Interface for\n  Low-Power Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an accurate and robust embedded motor-imagery\nbrain-computer interface (MI-BCI). The proposed novel model, based on EEGNet,\nmatches the requirements of memory footprint and computational resources of\nlow-power microcontroller units (MCUs), such as the ARM Cortex-M family.\nFurthermore, the paper presents a set of methods, including temporal\ndownsampling, channel selection, and narrowing of the classification window, to\nfurther scale down the model to relax memory requirements with negligible\naccuracy degradation. Experimental results on the Physionet EEG Motor\nMovement/Imagery Dataset show that standard EEGNet achieves 82.43%, 75.07%, and\n65.07% classification accuracy on 2-, 3-, and 4-class MI tasks in global\nvalidation, outperforming the state-of-the-art (SoA) convolutional neural\nnetwork (CNN) by 2.05%, 5.25%, and 5.48%. Our novel method further scales down\nthe standard EEGNet at a negligible accuracy loss of 0.31% with 7.6x memory\nfootprint reduction and a small accuracy loss of 2.51% with 15x reduction. The\nscaled models are deployed on a commercial Cortex-M4F MCU taking 101ms and\nconsuming 4.28mJ per inference for operating the smallest model, and on a\nCortex-M7 with 44ms and 18.1mJ per inference for the medium-sized model,\nenabling a fully autonomous, wearable, and accurate low-power BCI.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:52:05 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:39:45 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wang", "Xiaying", ""], ["Hersche", "Michael", ""], ["T\u00f6mekce", "Batuhan", ""], ["Kaya", "Burak", ""], ["Magno", "Michele", ""], ["Benini", "Luca", ""]]}, {"id": "2004.00088", "submitter": "Jia Xu Dr.", "authors": "Abdul Rafae Khan, Asim Karim, Hassan Sajjad, Faisal Kamiran, and Jia\n  Xu", "title": "A Clustering Framework for Lexical Normalization of Roman Urdu", "comments": null, "journal-ref": null, "doi": "10.1017/S1351324920000285", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Roman Urdu is an informal form of the Urdu language written in Roman script,\nwhich is widely used in South Asia for online textual content. It lacks\nstandard spelling and hence poses several normalization challenges during\nautomatic language processing. In this article, we present a feature-based\nclustering framework for the lexical normalization of Roman Urdu corpora, which\nincludes a phonetic algorithm UrduPhone, a string matching component, a\nfeature-based similarity function, and a clustering algorithm Lex-Var.\nUrduPhone encodes Roman Urdu strings to their pronunciation-based\nrepresentations. The string matching component handles character-level\nvariations that occur when writing Urdu using Roman script.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:21:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Khan", "Abdul Rafae", ""], ["Karim", "Asim", ""], ["Sajjad", "Hassan", ""], ["Kamiran", "Faisal", ""], ["Xu", "Jia", ""]]}, {"id": "2004.00094", "submitter": "Bram Renting", "authors": "Bram M. Renting (1), Holger H. Hoos (2), Catholijn M. Jonker (1 and 2)\n  ((1) Delft University of Technology, (2) Leiden University)", "title": "Automated Configuration of Negotiation Strategies", "comments": "Appears in Proceedings of the 19th International Conference on\n  Autonomous Agents and Multiagent Systems (AAMAS 2020)", "journal-ref": "http://ifaamas.org/Proceedings/aamas2020/pdfs/p1116.pdf", "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidding and acceptance strategies have a substantial impact on the outcome of\nnegotiations in scenarios with linear additive and nonlinear utility functions.\nOver the years, it has become clear that there is no single best strategy for\nall negotiation settings, yet many fixed strategies are still being developed.\nWe envision a shift in the strategy design question from: What is a good\nstrategy?, towards: What could be a good strategy? For this purpose, we\ndeveloped a method leveraging automated algorithm configuration to find the\nbest strategies for a specific set of negotiation settings. By empowering\nautomated negotiating agents using automated algorithm configuration, we obtain\na flexible negotiation agent that can be configured automatically for a rich\nspace of opponents and negotiation scenarios.\n  To critically assess our approach, the agent was tested in an ANAC-like\nbilateral automated negotiation tournament setting against past competitors. We\nshow that our automatically configured agent outperforms all other agents, with\na 5.1% increase in negotiation payoff compared to the next-best agent. We note\nthat without our agent in the tournament, the top-ranked agent wins by a margin\nof only 0.01%.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:31:33 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Renting", "Bram M.", "", "Delft University of Technology"], ["Hoos", "Holger H.", "", "Leiden University"], ["Jonker", "Catholijn M.", "", "1 and 2"]]}, {"id": "2004.00100", "submitter": "Aritra Ghosh", "authors": "Aritra Ghosh, Saayan Mitra, Somdeb Sarkhel, Viswanathan Swaminathan", "title": "Optimal Bidding Strategy without Exploration in Real-time Bidding", "comments": "SIAM SDM 2020. Added supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing utility with a budget constraint is the primary goal for\nadvertisers in real-time bidding (RTB) systems. The policy maximizing the\nutility is referred to as the optimal bidding strategy. Earlier works on\noptimal bidding strategy apply model-based batch reinforcement learning methods\nwhich can not generalize to unknown budget and time constraint. Further, the\nadvertiser observes a censored market price which makes direct evaluation\ninfeasible on batch test datasets. Previous works ignore the losing auctions to\nalleviate the difficulty with censored states; thus significantly modifying the\ntest distribution. We address the challenge of lacking a clear evaluation\nprocedure as well as the error propagated through batch reinforcement learning\nmethods in RTB systems. We exploit two conditional independence structures in\nthe sequential bidding process that allow us to propose a novel practical\nframework using the maximum entropy principle to imitate the behavior of the\ntrue distribution observed in real-time traffic. Moreover, the framework allows\nus to train a model that can generalize to the unseen budget conditions than\nlimit only to those observed in history. We compare our methods on two\nreal-world RTB datasets with several baselines and demonstrate significantly\nimproved performance under various budget settings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:43:28 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ghosh", "Aritra", ""], ["Mitra", "Saayan", ""], ["Sarkhel", "Somdeb", ""], ["Swaminathan", "Viswanathan", ""]]}, {"id": "2004.00101", "submitter": "Hye Won Chung", "authors": "Doyeon Kim and Hye Won Chung", "title": "Crowdsourced Labeling for Worker-Task Specialization Model", "comments": "To appear at IEEE International Symposium on Information Theory\n  (ISIT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider crowdsourced labeling under a $d$-type worker-task specialization\nmodel, where each worker and task is associated with one particular type among\na finite set of types and a worker provides a more reliable answer to tasks of\nthe matched type than to tasks of unmatched types. We design an inference\nalgorithm that recovers binary task labels (up to any given recovery accuracy)\nby using worker clustering, worker skill estimation and weighted majority\nvoting. The designed inference algorithm does not require any information about\nworker/task types, and achieves any targeted recovery accuracy with the best\nknown performance (minimum number of queries per task).\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:27:03 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 06:55:56 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kim", "Doyeon", ""], ["Chung", "Hye Won", ""]]}, {"id": "2004.00115", "submitter": "Hartmut Maennel", "authors": "Hartmut Maennel", "title": "Exact marginal inference in Latent Dirichlet Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume we have potential \"causes\" $z\\in Z$, which produce \"events\" $w$ with\nknown probabilities $\\beta(w|z)$. We observe $w_1,w_2,...,w_n$, what can we say\nabout the distribution of the causes? A Bayesian estimate will assume a prior\non distributions on $Z$ (we assume a Dirichlet prior) and calculate a\nposterior. An average over that posterior then gives a distribution on $Z$,\nwhich estimates how much each cause $z$ contributed to our observations. This\nis the setting of Latent Dirichlet Allocation, which can be applied e.g. to\ntopics \"producing\" words in a document. In this setting usually the number of\nobserved words is large, but the number of potential topics is small. We are\nhere interested in applications with many potential \"causes\" (e.g. locations on\nthe globe), but only a few observations. We show that the exact Bayesian\nestimate can be computed in linear time (and constant space) in $|Z|$ for a\ngiven upper bound on $n$ with a surprisingly simple formula. We generalize this\nalgorithm to the case of sparse probabilities $\\beta(w|z)$, in which we only\nneed to assume that the tree width of an \"interaction graph\" on the\nobservations is limited. On the other hand we also show that without such\nlimitation the problem is NP-hard.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:14:59 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Maennel", "Hartmut", ""]]}, {"id": "2004.00116", "submitter": "Xuesu Xiao", "authors": "Xuesu Xiao, Bo Liu, Garrett Warnell, Jonathan Fink, Peter Stone", "title": "APPLD: Adaptive Planner Parameter Learning from Demonstration", "comments": "Accepted by Robotics and Automation Letters (RAL) and International\n  Conference on Intelligent Robots and Systems (IROS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing autonomous robot navigation systems allow robots to move from one\npoint to another in a collision-free manner. However, when facing new\nenvironments, these systems generally require re-tuning by expert roboticists\nwith a good understanding of the inner workings of the navigation system. In\ncontrast, even users who are unversed in the details of robot navigation\nalgorithms can generate desirable navigation behavior in new environments via\nteleoperation. In this paper, we introduce APPLD, Adaptive Planner Parameter\nLearning from Demonstration, that allows existing navigation systems to be\nsuccessfully applied to new complex environments, given only a human\nteleoperated demonstration of desirable navigation. APPLD is verified on two\nrobots running different navigation systems in different environments.\nExperimental results show that APPLD can outperform navigation systems with the\ndefault and expert-tuned parameters, and even the human demonstrator\nthemselves.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:15:16 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:35:37 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 03:22:45 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 18:35:10 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Xiao", "Xuesu", ""], ["Liu", "Bo", ""], ["Warnell", "Garrett", ""], ["Fink", "Jonathan", ""], ["Stone", "Peter", ""]]}, {"id": "2004.00123", "submitter": "Longfei Zeng", "authors": "Longfei Zeng and Mohammed Sabah", "title": "EOLO: Embedded Object Segmentation only Look Once", "comments": "7 pages, 5 figures, 2 tables, 25 conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an anchor-free and single-shot instance\nsegmentation method, which is conceptually simple with 3 independent branches,\nfully convolutional and can be used by easily embedding it into mobile and\nembedded devices.\n  Our method, refer as EOLO, reformulates the instance segmentation problem as\npredicting semantic segmentation and distinguishing overlapping objects\nproblem, through instance center classification and 4D distance regression on\neach pixel. Moreover, we propose one effective loss function to deal with\nsampling a high-quality center of gravity examples and optimization for 4D\ndistance regression, which can significantly improve the mAP performance.\nWithout any bells and whistles, EOLO achieves 27.7$\\%$ in mask mAP under IoU50\nand reaches 30 FPS on 1080Ti GPU, with a single-model and single-scale\ntraining/testing on the challenging COCO2017 dataset.\n  For the first time, we show the different comprehension of instance\nsegmentation in recent methods, in terms of both up-bottom, down-up, and\ndirect-predict paradigms. Then we illustrate our model and present related\nexperiments and results. We hope that the proposed EOLO framework can serve as\na fundamental baseline for a single-shot instance segmentation task in\nReal-time Industrial Scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:22:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zeng", "Longfei", ""], ["Sabah", "Mohammed", ""]]}, {"id": "2004.00132", "submitter": "Jo\\~ao Ant\\^onio Chagas Nunes", "authors": "Jo\\~ao Ant\\^onio Chagas Nunes, David Mac\\^edo, Cleber Zanchettin", "title": "AM-MobileNet1D: A Portable Model for Speaker Recognition", "comments": "2020 International Joint Conference on Neural Networks (IJCNN)", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207519", "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker Recognition and Speaker Identification are challenging tasks with\nessential applications such as automation, authentication, and security. Deep\nlearning approaches like SincNet and AM-SincNet presented great results on\nthese tasks. The promising performance took these models to real-world\napplications that becoming fundamentally end-user driven and mostly mobile. The\nmobile computation requires applications with reduced storage size,\nnon-processing and memory intensive and efficient energy-consuming. The deep\nlearning approaches, in contrast, usually are energy expensive, demanding\nstorage, processing power, and memory. To address this demand, we propose a\nportable model called Additive Margin MobileNet1D (AM-MobileNet1D) to Speaker\nIdentification on mobile devices. We evaluated the proposed approach on TIMIT\nand MIT datasets obtaining equivalent or better performances concerning the\nbaseline methods. Additionally, the proposed model takes only 11.6 megabytes on\ndisk storage against 91.2 from SincNet and AM-SincNet architectures, making the\nmodel seven times faster, with eight times fewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 21:42:59 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Nunes", "Jo\u00e3o Ant\u00f4nio Chagas", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""]]}, {"id": "2004.00150", "submitter": "Mohammed Ibrahim", "authors": "Mohammed Ibrahim, Susan Gauch, Omar Salman, Mohammed Alqahatani", "title": "Enriching Consumer Health Vocabulary Using Enhanced GloVe Word Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-Access and Collaborative Consumer Health Vocabulary (OAC CHV, or CHV for\nshort), is a collection of medical terms written in plain English. It provides\na list of simple, easy, and clear terms that laymen prefer to use rather than\nan equivalent professional medical term. The National Library of Medicine (NLM)\nhas integrated and mapped the CHV terms to their Unified Medical Language\nSystem (UMLS). These CHV terms mapped to 56000 professional concepts on the\nUMLS. We found that about 48% of these laymen's terms are still jargon and\nmatched with the professional terms on the UMLS. In this paper, we present an\nenhanced word embedding technique that generates new CHV terms from a\nconsumer-generated text. We downloaded our corpus from a healthcare social\nmedia and evaluated our new method based on iterative feedback to word\nembedding using ground truth built from the existing CHV terms. Our feedback\nalgorithm outperformed unmodified GLoVe and new CHV terms have been detected.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:50:24 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 18:02:10 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ibrahim", "Mohammed", ""], ["Gauch", "Susan", ""], ["Salman", "Omar", ""], ["Alqahatani", "Mohammed", ""]]}, {"id": "2004.00161", "submitter": "Victor Schmidt", "authors": "Victor Schmidt, Makesh Narsimhan Sreedhar, Mostafa ElAraby, Irina Rish", "title": "Towards Lifelong Self-Supervision For Unpaired Image-to-Image\n  Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unpaired Image-to-Image Translation (I2IT) tasks often suffer from lack of\ndata, a problem which self-supervised learning (SSL) has recently been very\npopular and successful at tackling. Leveraging auxiliary tasks such as rotation\nprediction or generative colorization, SSL can produce better and more robust\nrepresentations in a low data regime. Training such tasks along an I2IT task is\nhowever computationally intractable as model size and the number of task grow.\nOn the other hand, learning sequentially could incur catastrophic forgetting of\npreviously learned tasks. To alleviate this, we introduce Lifelong\nSelf-Supervision (LiSS) as a way to pre-train an I2IT model (e.g., CycleGAN) on\na set of self-supervised auxiliary tasks. By keeping an exponential moving\naverage of past encoders and distilling the accumulated knowledge, we are able\nto maintain the network's validation performance on a number of tasks without\nany form of replay, parameter isolation or retraining techniques typically used\nin continual learning. We show that models trained with LiSS perform better on\npast tasks, while also being more robust than the CycleGAN baseline to color\nbias and entity entanglement (when two entities are very close).\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:23:51 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Schmidt", "Victor", ""], ["Sreedhar", "Makesh Narsimhan", ""], ["ElAraby", "Mostafa", ""], ["Rish", "Irina", ""]]}, {"id": "2004.00163", "submitter": "Zhekun Luo", "authors": "Zhekun Luo, Devin Guillory, Baifeng Shi, Wei Ke, Fang Wan, Trevor\n  Darrell, Huijuan Xu", "title": "Weakly-Supervised Action Localization with Expectation-Maximization\n  Multi-Instance Learning", "comments": "Accepted at European Conference on Computer Vision (ECCV), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly-supervised action localization requires training a model to localize\nthe action segments in the video given only video level action label. It can be\nsolved under the Multiple Instance Learning (MIL) framework, where a bag\n(video) contains multiple instances (action segments). Since only the bag's\nlabel is known, the main challenge is assigning which key instances within the\nbag to trigger the bag's label. Most previous models use attention-based\napproaches applying attentions to generate the bag's representation from\ninstances, and then train it via the bag's classification. These models,\nhowever, implicitly violate the MIL assumption that instances in negative bags\nshould be uniformly negative. In this work, we explicitly model the key\ninstances assignment as a hidden variable and adopt an Expectation-Maximization\n(EM) framework. We derive two pseudo-label generation schemes to model the E\nand M process and iteratively optimize the likelihood lower bound. We show that\nour EM-MIL approach more accurately models both the learning objective and the\nMIL assumptions. It achieves state-of-the-art performance on two standard\nbenchmarks, THUMOS14 and ActivityNet1.2.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:36:04 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 19:26:17 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Luo", "Zhekun", ""], ["Guillory", "Devin", ""], ["Shi", "Baifeng", ""], ["Ke", "Wei", ""], ["Wan", "Fang", ""], ["Darrell", "Trevor", ""], ["Xu", "Huijuan", ""]]}, {"id": "2004.00166", "submitter": "Jia-Jie Zhu", "authors": "Jia-Jie Zhu, Wittawat Jitkrittum, Moritz Diehl, Bernhard Sch\\\"olkopf", "title": "Worst-Case Risk Quantification under Distributional Ambiguity using\n  Kernel Mean Embedding in Moment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to anticipate rare and impactful events, we propose to quantify the\nworst-case risk under distributional ambiguity using a recent development in\nkernel methods -- the kernel mean embedding. Specifically, we formulate the\ngeneralized moment problem whose ambiguity set (i.e., the moment constraint) is\ndescribed by constraints in the associated reproducing kernel Hilbert space in\na nonparametric manner. We then present the tractable approximation and its\ntheoretical justification. As a concrete application, we numerically test the\nproposed method in characterizing the worst-case constraint violation\nprobability in the context of a constrained stochastic control system.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:51:27 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 15:02:55 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Zhu", "Jia-Jie", ""], ["Jitkrittum", "Wittawat", ""], ["Diehl", "Moritz", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2004.00179", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Min Zhang and Shao-Bo Lin", "title": "Fully-Corrective Gradient Boosting with Squared Hinge: Fast Learning\n  Rates and Early Stopping", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosting is a well-known method for improving the accuracy of weak learners\nin machine learning. However, its theoretical generalization guarantee is\nmissing in literature. In this paper, we propose an efficient boosting method\nwith theoretical generalization guarantees for binary classification. Three key\ningredients of the proposed boosting method are: a) the\n\\textit{fully-corrective greedy} (FCG) update in the boosting procedure, b) a\ndifferentiable \\textit{squared hinge} (also called \\textit{truncated\nquadratic}) function as the loss function, and c) an efficient alternating\ndirection method of multipliers (ADMM) algorithm for the associated FCG\noptimization. The used squared hinge loss not only inherits the robustness of\nthe well-known hinge loss for classification with outliers, but also brings\nsome benefits for computational implementation and theoretical justification.\nUnder some sparseness assumption, we derive a fast learning rate of the order\n${\\cal O}((m/\\log m)^{-1/4})$ for the proposed boosting method, which can be\nfurther improved to ${\\cal O}((m/\\log m)^{-1/2})$ if certain additional noise\nassumption is imposed, where $m$ is the size of sample set. Both derived\nlearning rates are the best ones among the existing generalization results of\nboosting-type methods for classification. Moreover, an efficient early stopping\nscheme is provided for the proposed method. A series of toy simulations and\nreal data experiments are conducted to verify the developed theories and\ndemonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 00:39:24 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zeng", "Jinshan", ""], ["Zhang", "Min", ""], ["Lin", "Shao-Bo", ""]]}, {"id": "2004.00184", "submitter": "Michel Besserve", "authors": "Michel Besserve, R\\'emy Sun, Dominik Janzing and Bernhard Sch\\\"olkopf", "title": "A theory of independent mechanisms for extrapolation in generative\n  models", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models reproduce complex empirical data but cannot\nextrapolate to novel environments. An intuitive idea to promote extrapolation\ncapabilities is to enforce the architecture to have the modular structure of a\ncausal graphical model, where one can intervene on each module independently of\nthe others in the graph. We develop a framework to formalize this intuition,\nusing the principle of Independent Causal Mechanisms, and show how\nover-parameterization of generative neural networks can hinder extrapolation\ncapabilities. Our experiments on the generation of human faces shows successive\nlayers of a generator architecture implement independent mechanisms to some\nextent, allowing meaningful extrapolations. Finally, we illustrate that\nindependence of mechanisms may be enforced during training to improve\nextrapolation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 01:01:43 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Besserve", "Michel", ""], ["Sun", "R\u00e9my", ""], ["Janzing", "Dominik", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2004.00188", "submitter": "Curtis Hawthorne", "authors": "Lee Callender, Curtis Hawthorne, Jesse Engel", "title": "Improving Perceptual Quality of Drum Transcription with the Expanded\n  Groove MIDI Dataset", "comments": "Examples available at https://goo.gl/magenta/e-gmd-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Expanded Groove MIDI dataset (E-GMD), an automatic drum\ntranscription (ADT) dataset that contains 444 hours of audio from 43 drum kits,\nmaking it an order of magnitude larger than similar datasets, and the first\nwith human-performed velocity annotations. We use E-GMD to optimize classifiers\nfor use in downstream generation by predicting expressive dynamics (velocity)\nand show with listening tests that they produce outputs with improved\nperceptual quality, despite similar results on classification metrics. Via the\nlistening tests, we argue that standard classifier metrics, such as accuracy\nand F-measure score, are insufficient proxies of performance in downstream\ntasks because they do not fully align with the perceptual quality of generated\noutputs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 01:24:42 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:44:51 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 12:03:43 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 00:30:10 GMT"}, {"version": "v5", "created": "Tue, 1 Dec 2020 18:11:04 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Callender", "Lee", ""], ["Hawthorne", "Curtis", ""], ["Engel", "Jesse", ""]]}, {"id": "2004.00191", "submitter": "Yanglan  Ou", "authors": "Yanglan Ou, Yuan Xue, Ye Yuan, Tao Xu, Vincent Pisztora, Jia Li,\n  Xiaolei Huang", "title": "Semi-Supervised Cervical Dysplasia Classification With Learnable Graph\n  Convolutional Network", "comments": "ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cervical cancer is the second most prevalent cancer affecting women today. As\nthe early detection of cervical carcinoma relies heavily upon screening and\npre-clinical testing, digital cervicography has great potential as a primary or\nauxiliary screening tool, especially in low-resource regions due to its low\ncost and easy access. Although an automated cervical dysplasia detection system\nhas been desirable, traditional fully-supervised training of such systems\nrequires large amounts of annotated data which are often labor-intensive to\ncollect. To alleviate the need for much manual annotation, we propose a novel\ngraph convolutional network (GCN) based semi-supervised classification model\nthat can be trained with fewer annotations. In existing GCNs, graphs are\nconstructed with fixed features and can not be updated during the learning\nprocess. This limits their ability to exploit new features learned during graph\nconvolution. In this paper, we propose a novel and more flexible GCN model with\na feature encoder that adaptively updates the adjacency matrix during learning\nand demonstrate that this model design leads to improved performance. Our\nexperimental results on a cervical dysplasia classification dataset show that\nthe proposed framework outperforms previous methods under a semi-supervised\nsetting, especially when the labeled samples are scarce.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 01:53:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Ou", "Yanglan", ""], ["Xue", "Yuan", ""], ["Yuan", "Ye", ""], ["Xu", "Tao", ""], ["Pisztora", "Vincent", ""], ["Li", "Jia", ""], ["Huang", "Xiaolei", ""]]}, {"id": "2004.00197", "submitter": "Lei Zhu", "authors": "Tong Wang, Lei Zhu, Zhiyong Cheng, Jingjing Li, and Huaxiang Zhang", "title": "Task-adaptive Asymmetric Deep Cross-modal Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised cross-modal hashing aims to embed the semantic correlations of\nheterogeneous modality data into the binary hash codes with discriminative\nsemantic labels. Because of its advantages on retrieval and storage efficiency,\nit is widely used for solving efficient cross-modal retrieval. However,\nexisting researches equally handle the different tasks of cross-modal\nretrieval, and simply learn the same couple of hash functions in a symmetric\nway for them. Under such circumstance, the uniqueness of different cross-modal\nretrieval tasks are ignored and sub-optimal performance may be brought.\nMotivated by this, we present a Task-adaptive Asymmetric Deep Cross-modal\nHashing (TA-ADCMH) method in this paper. It can learn task-adaptive hash\nfunctions for two sub-retrieval tasks via simultaneous modality representation\nand asymmetric hash learning. Unlike previous cross-modal hashing approaches,\nour learning framework jointly optimizes semantic preserving that transforms\ndeep features of multimedia data into binary hash codes, and the semantic\nregression which directly regresses query modality representation to explicit\nlabel. With our model, the binary codes can effectively preserve semantic\ncorrelations across different modalities, meanwhile, adaptively capture the\nquery semantics. The superiority of TA-ADCMH is proved on two standard datasets\nfrom many aspects.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:09:20 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Wang", "Tong", ""], ["Zhu", "Lei", ""], ["Cheng", "Zhiyong", ""], ["Li", "Jingjing", ""], ["Zhang", "Huaxiang", ""]]}, {"id": "2004.00198", "submitter": "Yanyao Shen", "authors": "Yanyao Shen, Hsiang-fu Yu, Sujay Sanghavi, Inderjit Dhillon", "title": "Extreme Multi-label Classification from Aggregated Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme multi-label classification (XMC) is the problem of finding the\nrelevant labels for an input, from a very large universe of possible labels. We\nconsider XMC in the setting where labels are available only for groups of\nsamples - but not for individual ones. Current XMC approaches are not built for\nsuch multi-instance multi-label (MIML) training data, and MIML approaches do\nnot scale to XMC sizes. We develop a new and scalable algorithm to impute\nindividual-sample labels from the group labels; this can be paired with any\nexisting XMC method to solve the aggregated label problem. We characterize the\nstatistical properties of our algorithm under mild assumptions, and provide a\nnew end-to-end framework for MIML as an extension. Experiments on both\naggregated label XMC and MIML tasks show the advantages over existing\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:13:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Shen", "Yanyao", ""], ["Yu", "Hsiang-fu", ""], ["Sanghavi", "Sujay", ""], ["Dhillon", "Inderjit", ""]]}, {"id": "2004.00201", "submitter": "Jianbin Lin Lin", "authors": "Jianbin Lin, Zhiqiang Zhang, Jun Zhou, Xiaolong Li, Jingli Fang,\n  Yanming Fang, Quan Yu, Yuan Qi", "title": "NetDP: An Industrial-Scale Distributed Network Representation Framework\n  for Default Prediction in Ant Credit Pay", "comments": "2018 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": "10.1109/BigData.2018.8622169", "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Credit Pay is a consumer credit service in Ant Financial Service Group.\nSimilar to credit card, loan default is one of the major risks of this credit\nproduct. Hence, effective algorithm for default prediction is the key to losses\nreduction and profits increment for the company. However, the challenges facing\nin our scenario are different from those in conventional credit card service.\nThe first one is scalability. The huge volume of users and their behaviors in\nAnt Financial requires the ability to process industrial-scale data and perform\nmodel training efficiently. The second challenges is the cold-start problem.\nDifferent from the manual review for credit card application in conventional\nbanks, the credit limit of Ant Credit Pay is automatically offered to users\nbased on the knowledge learned from big data. However, default prediction for\nnew users is suffered from lack of enough credit behaviors. It requires that\nthe proposal should leverage other new data source to alleviate the cold-start\nproblem. Considering the above challenges and the special scenario in Ant\nFinancial, we try to incorporate default prediction with network information to\nalleviate the cold-start problem. In this paper, we propose an industrial-scale\ndistributed network representation framework, termed NetDP, for default\nprediction in Ant Credit Pay. The proposal explores network information\ngenerated by various interaction between users, and blends unsupervised and\nsupervised network representation in a unified framework for default prediction\nproblem. Moreover, we present a parameter-server-based distributed implement of\nour proposal to handle the scalability challenge. Experimental results\ndemonstrate the effectiveness of our proposal, especially in cold-start\nproblem, as well as the efficiency for industrial-scale dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:22:33 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lin", "Jianbin", ""], ["Zhang", "Zhiqiang", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Fang", "Jingli", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""], ["Qi", "Yuan", ""]]}, {"id": "2004.00202", "submitter": "Chiho Choi", "authors": "Chiho Choi, Joon Hee Choi, Srikanth Malla, Jiachen Li", "title": "Shared Cross-Modal Trajectory Prediction for Autonomous Driving", "comments": "CVPR 2021 [Oral]. arXiv admin note: substantial text overlap with\n  arXiv:2011.08436", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Predicting future trajectories of traffic agents in highly interactive\nenvironments is an essential and challenging problem for the safe operation of\nautonomous driving systems. On the basis of the fact that self-driving vehicles\nare equipped with various types of sensors (e.g., LiDAR scanner, RGB camera,\nradar, etc.), we propose a Cross-Modal Embedding framework that aims to benefit\nfrom the use of multiple input modalities. At training time, our model learns\nto embed a set of complementary features in a shared latent space by jointly\noptimizing the objective functions across different types of input data. At\ntest time, a single input modality (e.g., LiDAR data) is required to generate\npredictions from the input perspective (i.e., in the LiDAR space), while taking\nadvantages from the model trained with multiple sensor modalities. An extensive\nevaluation is conducted to show the efficacy of the proposed framework using\ntwo benchmark driving datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:44:30 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 20:14:25 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 21:24:38 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Choi", "Chiho", ""], ["Choi", "Joon Hee", ""], ["Malla", "Srikanth", ""], ["Li", "Jiachen", ""]]}, {"id": "2004.00204", "submitter": "Thi Kim Phung Lai", "authors": "Phung Lai, NhatHai Phan, Han Hu, Anuja Badeti, David Newman, Dejing\n  Dou", "title": "Ontology-based Interpretable Machine Learning for Textual Data", "comments": "Accepted by IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel interpreting framework that learns an\ninterpretable model based on an ontology-based sampling technique to explain\nagnostic prediction models. Different from existing approaches, our algorithm\nconsiders contextual correlation among words, described in domain knowledge\nontologies, to generate semantic explanations. To narrow down the search space\nfor explanations, which is a major problem of long and complicated text data,\nwe design a learnable anchor algorithm, to better extract explanations locally.\nA set of regulations is further introduced, regarding combining learned\ninterpretable representations with anchors to generate comprehensible semantic\nexplanations. An extensive experiment conducted on two real-world datasets\nshows that our approach generates more precise and insightful explanations\ncompared with baseline approaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:51:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lai", "Phung", ""], ["Phan", "NhatHai", ""], ["Hu", "Han", ""], ["Badeti", "Anuja", ""], ["Newman", "David", ""], ["Dou", "Dejing", ""]]}, {"id": "2004.00207", "submitter": "Xin Yang", "authors": "Chaoyu Chen, Xin Yang, Ruobing Huang, Wenlong Shi, Shengfeng Liu,\n  Mingrong Lin, Yuhao Huang, Yong Yang, Yuanji Zhang, Huanjia Luo, Yankai\n  Huang, Yi Xiong, Dong Ni", "title": "Region Proposal Network with Graph Prior and IoU-Balance Loss for\n  Landmark Detection in 3D Ultrasound", "comments": "IEEE International Symposium on Biomedical Imaging (IEEE ISBI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D ultrasound (US) can facilitate detailed prenatal examinations for fetal\ngrowth monitoring. To analyze a 3D US volume, it is fundamental to identify\nanatomical landmarks of the evaluated organs accurately. Typical deep learning\nmethods usually regress the coordinates directly or involve heatmap-matching.\nHowever, these methods struggle to deal with volumes with large sizes and the\nhighly-varying positions and orientations of fetuses. In this work, we exploit\nan object detection framework to detect landmarks in 3D fetal facial US\nvolumes. By regressing multiple parameters of the landmark-centered bounding\nbox (B-box) with a strict criteria, the proposed model is able to pinpoint the\nexact location of the targeted landmarks. Specifically, the model uses a 3D\nregion proposal network (RPN) to generate 3D candidate regions, followed by\nseveral 3D classification branches to select the best candidate. It also adopts\nan IoU-balance loss to improve communications between branches that benefits\nthe learning process. Furthermore, it leverages a distance-based graph prior to\nregularize the training and helps to reduce false positive predictions. The\nperformance of the proposed framework is evaluated on a 3D US dataset to detect\nfive key fetal facial landmarks. Results showed the proposed method outperforms\nsome of the state-of-the-art methods in efficacy and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 03:00:03 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Chen", "Chaoyu", ""], ["Yang", "Xin", ""], ["Huang", "Ruobing", ""], ["Shi", "Wenlong", ""], ["Liu", "Shengfeng", ""], ["Lin", "Mingrong", ""], ["Huang", "Yuhao", ""], ["Yang", "Yong", ""], ["Zhang", "Yuanji", ""], ["Luo", "Huanjia", ""], ["Huang", "Yankai", ""], ["Xiong", "Yi", ""], ["Ni", "Dong", ""]]}, {"id": "2004.00216", "submitter": "Carl Yang", "authors": "Carl Yang, Yuxin Xiao, Yu Zhang, Yizhou Sun, Jiawei Han", "title": "Heterogeneous Network Representation Learning: A Unified Framework with\n  Survey and Benchmark", "comments": "Accepted by IEEE TKDE. All code and data available at\n  https://github.com/yangji9181/HNE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since real-world objects and their interactions are often multi-modal and\nmulti-typed, heterogeneous networks have been widely used as a more powerful,\nrealistic, and generic superclass of traditional homogeneous networks (graphs).\nMeanwhile, representation learning (\\aka~embedding) has recently been\nintensively studied and shown effective for various network mining and\nanalytical tasks. In this work, we aim to provide a unified framework to deeply\nsummarize and evaluate existing research on heterogeneous network embedding\n(HNE), which includes but goes beyond a normal survey. Since there has already\nbeen a broad body of HNE algorithms, as the first contribution of this work, we\nprovide a generic paradigm for the systematic categorization and analysis over\nthe merits of various existing HNE algorithms. Moreover, existing HNE\nalgorithms, though mostly claimed generic, are often evaluated on different\ndatasets. Understandable due to the application favor of HNE, such indirect\ncomparisons largely hinder the proper attribution of improved task performance\ntowards effective data preprocessing and novel technical design, especially\nconsidering the various ways possible to construct a heterogeneous network from\nreal-world application data. Therefore, as the second contribution, we create\nfour benchmark datasets with various properties regarding scale, structure,\nattribute/label availability, and \\etc.~from different sources, towards handy\nand fair evaluations of HNE algorithms. As the third contribution, we carefully\nrefactor and amend the implementations and create friendly interfaces for 13\npopular HNE algorithms, and provide all-around comparisons among them over\nmultiple tasks and experimental settings.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 03:42:11 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 19:07:41 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 01:44:03 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yang", "Carl", ""], ["Xiao", "Yuxin", ""], ["Zhang", "Yu", ""], ["Sun", "Yizhou", ""], ["Han", "Jiawei", ""]]}, {"id": "2004.00218", "submitter": "Sukrit Gupta", "authors": "Satya P. Singh, Lipo Wang, Sukrit Gupta, Haveesh Goli, Parasuraman\n  Padmanabhan and Bal\\'azs Guly\\'as", "title": "3D Deep Learning on Medical Images: A Review", "comments": "Published in Sensors Journal\n  (https://www.mdpi.com/1424-8220/20/18/5097)", "journal-ref": "Sensors 2020, 20, 5097", "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The rapid advancements in machine learning, graphics processing technologies\nand the availability of medical imaging data have led to a rapid increase in\nthe use of deep learning models in the medical domain. This was exacerbated by\nthe rapid advancements in convolutional neural network (CNN) based\narchitectures, which were adopted by the medical imaging community to assist\nclinicians in disease diagnosis. Since the grand success of AlexNet in 2012,\nCNNs have been increasingly used in medical image analysis to improve the\nefficiency of human clinicians. In recent years, three-dimensional (3D) CNNs\nhave been employed for the analysis of medical images. In this paper, we trace\nthe history of how the 3D CNN was developed from its machine learning roots, we\nprovide a brief mathematical description of 3D CNN and provide the\npreprocessing steps required for medical images before feeding them to 3D CNNs.\nWe review the significant research in the field of 3D medical imaging analysis\nusing 3D CNNs (and its variants) in different medical areas such as\nclassification, segmentation, detection and localization. We conclude by\ndiscussing the challenges associated with the use of 3D CNNs in the medical\nimaging domain (and the use of deep learning models in general) and possible\nfuture trends in the field.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 03:56:48 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 05:26:19 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2020 04:28:29 GMT"}, {"version": "v4", "created": "Tue, 13 Oct 2020 08:38:19 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Singh", "Satya P.", ""], ["Wang", "Lipo", ""], ["Gupta", "Sukrit", ""], ["Goli", "Haveesh", ""], ["Padmanabhan", "Parasuraman", ""], ["Guly\u00e1s", "Bal\u00e1zs", ""]]}, {"id": "2004.00221", "submitter": "Alvin Wan", "authors": "Alvin Wan, Lisa Dunlap, Daniel Ho, Jihan Yin, Scott Lee, Henry Jin,\n  Suzanne Petryk, Sarah Adel Bargal, Joseph E. Gonzalez", "title": "NBDT: Neural-Backed Decision Trees", "comments": "8 pages, 7 figures, accepted to ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications such as finance and medicine demand accurate\nand justifiable predictions, barring most deep learning methods from use. In\nresponse, previous work combines decision trees with deep learning, yielding\nmodels that (1) sacrifice interpretability for accuracy or (2) sacrifice\naccuracy for interpretability. We forgo this dilemma by jointly improving\naccuracy and interpretability using Neural-Backed Decision Trees (NBDTs). NBDTs\nreplace a neural network's final linear layer with a differentiable sequence of\ndecisions and a surrogate loss. This forces the model to learn high-level\nconcepts and lessens reliance on highly-uncertain decisions, yielding (1)\naccuracy: NBDTs match or outperform modern neural networks on CIFAR, ImageNet\nand better generalize to unseen classes by up to 16%. Furthermore, our\nsurrogate loss improves the original model's accuracy by up to 2%. NBDTs also\nafford (2) interpretability: improving human trustby clearly identifying model\nmistakes and assisting in dataset debugging. Code and pretrained NBDTs are at\nhttps://github.com/alvinwan/neural-backed-decision-trees.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 04:04:03 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 22:33:20 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 03:06:26 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Wan", "Alvin", ""], ["Dunlap", "Lisa", ""], ["Ho", "Daniel", ""], ["Yin", "Jihan", ""], ["Lee", "Scott", ""], ["Jin", "Henry", ""], ["Petryk", "Suzanne", ""], ["Bargal", "Sarah Adel", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2004.00225", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Jonas Geiping, Liam Fowl, Gavin Taylor, Tom Goldstein", "title": "MetaPoison: Practical General-purpose Clean-label Data Poisoning", "comments": "Conference paper at NeurIPS 2020. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning -- the process by which an attacker takes control of a model\nby making imperceptible changes to a subset of the training data -- is an\nemerging threat in the context of neural networks. Existing attacks for data\npoisoning neural networks have relied on hand-crafted heuristics, because\nsolving the poisoning problem directly via bilevel optimization is generally\nthought of as intractable for deep models. We propose MetaPoison, a first-order\nmethod that approximates the bilevel problem via meta-learning and crafts\npoisons that fool neural networks. MetaPoison is effective: it outperforms\nprevious clean-label poisoning methods by a large margin. MetaPoison is robust:\npoisoned data made for one model transfer to a variety of victim models with\nunknown training settings and architectures. MetaPoison is general-purpose, it\nworks not only in fine-tuning scenarios, but also for end-to-end training from\nscratch, which till now hasn't been feasible for clean-label attacks with deep\nnets. MetaPoison can achieve arbitrary adversary goals -- like using poisons of\none class to make a target image don the label of another arbitrarily chosen\nclass. Finally, MetaPoison works in the real-world. We demonstrate for the\nfirst time successful data poisoning of models trained on the black-box Google\nCloud AutoML API. Code and premade poisons are provided at\nhttps://github.com/wronnyhuang/metapoison\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 04:23:20 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 02:40:40 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Huang", "W. Ronny", ""], ["Geiping", "Jonas", ""], ["Fowl", "Liam", ""], ["Taylor", "Gavin", ""], ["Goldstein", "Tom", ""]]}, {"id": "2004.00227", "submitter": "Ali Siahkoohi", "authors": "Ali Siahkoohi, Gabrio Rizzuti, Felix J. Herrmann", "title": "Uncertainty quantification in imaging and automatic horizon tracking: a\n  Bayesian deep-prior based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In inverse problems, uncertainty quantification (UQ) deals with a\nprobabilistic description of the solution nonuniqueness and data noise\nsensitivity. Setting seismic imaging into a Bayesian framework allows for a\nprincipled way of studying uncertainty by solving for the model posterior\ndistribution. Imaging, however, typically constitutes only the first stage of a\nsequential workflow, and UQ becomes even more relevant when applied to\nsubsequent tasks that are highly sensitive to the inversion outcome. In this\npaper, we focus on how UQ trickles down to horizon tracking for the\ndetermination of stratigraphic models and investigate its sensitivity with\nrespect to the imaging result. As such, the main contribution of this work\nconsists in a data-guided approach to horizon tracking uncertainty analysis.\nThis work is fundamentally based on a special reparameterization of\nreflectivity, known as \"deep prior\". Feasible models are restricted to the\noutput of a convolutional neural network with a fixed input, while weights and\nbiases are Gaussian random variables. Given a deep prior model, the network\nparameters are sampled from the posterior distribution via a Markov chain Monte\nCarlo method, from which the conditional mean and point-wise standard deviation\nof the inferred reflectivities are approximated. For each sample of the\nposterior distribution, a reflectivity is generated, and the horizons are\ntracked automatically. In this way, uncertainty on model parameters naturally\ntranslates to horizon tracking. As part of the validation for the proposed\napproach, we verified that the estimated confidence intervals for the horizon\ntracking coincide with geologically complex regions, such as faults.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 04:26:33 GMT"}, {"version": "v2", "created": "Sat, 4 Apr 2020 22:56:31 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2020 22:42:14 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Siahkoohi", "Ali", ""], ["Rizzuti", "Gabrio", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2004.00234", "submitter": "Jeeyung Kim", "authors": "Jeeyung Kim, Alex Sim, Jinoh Kim, Kesheng Wu", "title": "Botnet Detection Using Recurrent Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Botnets are increasingly used by malicious actors, creating increasing threat\nto a large number of internet users. To address this growing danger, we propose\nto study methods to detect botnets, especially those that are hard to capture\nwith the commonly used methods, such as the signature based ones and the\nexisting anomaly-based ones. More specifically, we propose a novel machine\nlearning based method, named Recurrent Variational Autoencoder (RVAE), for\ndetecting botnets through sequential characteristics of network traffic flow\ndata including attacks by botnets. We validate robustness of our method with\nthe CTU-13 dataset, where we have chosen the testing dataset to have different\ntypes of botnets than those of training dataset. Tests show that RVAE is able\nto detect botnets with the same accuracy as the best known results published in\nliterature. In addition, we propose an approach to assign anomaly score based\non probability distributions, which allows us to detect botnets in streaming\nmode as the new networking statistics becomes available. This on-line detection\ncapability would enable real-time detection of unknown botnets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 05:03:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kim", "Jeeyung", ""], ["Sim", "Alex", ""], ["Kim", "Jinoh", ""], ["Wu", "Kesheng", ""]]}, {"id": "2004.00245", "submitter": "Shao-Bo Lin", "authors": "Zhi Han, Siquan Yu, Shao-Bo Lin, Ding-Xuan Zhou", "title": "Depth Selection for Deep ReLU Nets in Feature Extraction and\n  Generalization", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is recognized to be capable of discovering deep features for\nrepresentation learning and pattern recognition without requiring elegant\nfeature engineering techniques by taking advantage of human ingenuity and prior\nknowledge. Thus it has triggered enormous research activities in machine\nlearning and pattern recognition. One of the most important challenge of deep\nlearning is to figure out relations between a feature and the depth of deep\nneural networks (deep nets for short) to reflect the necessity of depth. Our\npurpose is to quantify this feature-depth correspondence in feature extraction\nand generalization. We present the adaptivity of features to depths and\nvice-verse via showing a depth-parameter trade-off in extracting both single\nfeature and composite features. Based on these results, we prove that\nimplementing the classical empirical risk minimization on deep nets can achieve\nthe optimal generalization performance for numerous learning tasks. Our\ntheoretical results are verified by a series of numerical experiments including\ntoy simulations and a real application of earthquake seismic intensity\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 06:03:01 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Han", "Zhi", ""], ["Yu", "Siquan", ""], ["Lin", "Shao-Bo", ""], ["Zhou", "Ding-Xuan", ""]]}, {"id": "2004.00248", "submitter": "Jiangyan Yi", "authors": "Jiangyan Yi, Jianhua Tao, Ye Bai, Zhengkun Tian, Cunhang Fan", "title": "Adversarial Transfer Learning for Punctuation Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies demonstrate that word embeddings and part-of-speech (POS)\ntags are helpful for punctuation restoration tasks. However, two drawbacks\nstill exist. One is that word embeddings are pre-trained by unidirectional\nlanguage modeling objectives. Thus the word embeddings only contain\nleft-to-right context information. The other is that POS tags are provided by\nan external POS tagger. So computation cost will be increased and incorrect\npredicted tags may affect the performance of restoring punctuation marks during\ndecoding. This paper proposes adversarial transfer learning to address these\nproblems. A pre-trained bidirectional encoder representations from transformers\n(BERT) model is used to initialize a punctuation model. Thus the transferred\nmodel parameters carry both left-to-right and right-to-left representations.\nFurthermore, adversarial multi-task learning is introduced to learn task\ninvariant knowledge for punctuation prediction. We use an extra POS tagging\ntask to help the training of the punctuation predicting task. Adversarial\ntraining is utilized to prevent the shared parameters from containing task\nspecific information. We only use the punctuation predicting task to restore\nmarks during decoding stage. Therefore, it will not need extra computation and\nnot introduce incorrect tags from the POS tagger. Experiments are conducted on\nIWSLT2011 datasets. The results demonstrate that the punctuation predicting\nmodels obtain further performance improvement with task invariant knowledge\nfrom the POS tagging task. Our best model outperforms the previous\nstate-of-the-art model trained only with lexical features by up to 9.2%\nabsolute overall F_1-score on test set.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 06:19:56 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yi", "Jiangyan", ""], ["Tao", "Jianhua", ""], ["Bai", "Ye", ""], ["Tian", "Zhengkun", ""], ["Fan", "Cunhang", ""]]}, {"id": "2004.00251", "submitter": "Hong-Gyu Jung", "authors": "Jin-Woo Seo, Hong-Gyu Jung, Seong-Whan Lee", "title": "Self-Augmentation: Generalizing Deep Networks to Unseen Classes for\n  Few-Shot Learning", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": "10.1016/j.neunet.2021.02.007", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning aims to classify unseen classes with a few training\nexamples. While recent works have shown that standard mini-batch training with\na carefully designed training strategy can improve generalization ability for\nunseen classes, well-known problems in deep networks such as memorizing\ntraining statistics have been less explored for few-shot learning. To tackle\nthis issue, we propose self-augmentation that consolidates self-mix and\nself-distillation. Specifically, we exploit a regional dropout technique called\nself-mix, in which a patch of an image is substituted into other values in the\nsame image. Then, we employ a backbone network that has auxiliary branches with\nits own classifier to enforce knowledge sharing. Lastly, we present a local\nrepresentation learner to further exploit a few training examples for unseen\nclasses. Experimental results show that the proposed method outperforms the\nstate-of-the-art methods for prevalent few-shot benchmarks and improves the\ngeneralization ability.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 06:39:08 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 04:53:01 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 08:37:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Seo", "Jin-Woo", ""], ["Jung", "Hong-Gyu", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2004.00273", "submitter": "Yu Wang", "authors": "Yu Wang, Nima Roohi, Matthew West, Mahesh Viswanathan, and Geir E.\n  Dullerud", "title": "Statistically Model Checking PCTL Specifications on Markov Decision\n  Processes via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Computation Tree Logic (PCTL) is frequently used to formally\nspecify control objectives such as probabilistic reachability and safety. In\nthis work, we focus on model checking PCTL specifications statistically on\nMarkov Decision Processes (MDPs) by sampling, e.g., checking whether there\nexists a feasible policy such that the probability of reaching certain goal\nstates is greater than a threshold. We use reinforcement learning to search for\nsuch a feasible policy for PCTL specifications, and then develop a statistical\nmodel checking (SMC) method with provable guarantees on its error.\nSpecifically, we first use upper-confidence-bound (UCB) based Q-learning to\ndesign an SMC algorithm for bounded-time PCTL specifications, and then extend\nthis algorithm to unbounded-time specifications by identifying a proper\ntruncation time by checking the PCTL specification and its negation at the same\ntime. Finally, we evaluate the proposed method on case studies.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:10:25 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 02:21:22 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Yu", ""], ["Roohi", "Nima", ""], ["West", "Matthew", ""], ["Viswanathan", "Mahesh", ""], ["Dullerud", "Geir E.", ""]]}, {"id": "2004.00275", "submitter": "Yu Wang", "authors": "Yu Wang, Hussein Sibai, Sayan Mitra and Geir E. Dullerud", "title": "Differential Privacy for Sequential Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differential privacy of sequential statistical inference and\nlearning algorithms that are characterized by random termination time. Using\nthe two examples: sequential probability ratio test and sequential empirical\nrisk minimization, we show that the number of steps such algorithms execute\nbefore termination can jeopardize the differential privacy of the input data in\na similar fashion as their outputs, and it is impossible to use the usual\nLaplace mechanism to achieve standard differentially private in these examples.\nTo remedy this, we propose a notion of weak differential privacy and\ndemonstrate its equivalence to the standard case for large i.i.d. samples. We\nshow that using the Laplace mechanism, weak differential privacy can be\nachieved for both the sequential probability ratio test and the sequential\nempirical risk minimization with proper performance guarantees. Finally, we\nprovide preliminary experimental results on the Breast Cancer Wisconsin\n(Diagnostic) and Landsat Satellite Data Sets from the UCI repository.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:14:23 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Wang", "Yu", ""], ["Sibai", "Hussein", ""], ["Mitra", "Sayan", ""], ["Dullerud", "Geir E.", ""]]}, {"id": "2004.00281", "submitter": "Michail Tsagris", "authors": "Michail Tsagris, Zacharias Papadovasilakis, Kleanthi Lakiotaki and\n  Ioannis Tsamardinos", "title": "A generalised OMP algorithm for feature selection with application to\n  gene expression data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection for predictive analytics is the problem of identifying a\nminimal-size subset of features that is maximally predictive of an outcome of\ninterest. To apply to molecular data, feature selection algorithms need to be\nscalable to tens of thousands of available features. In this paper, we propose\ngOMP, a highly-scalable generalisation of the Orthogonal Matching Pursuit\nfeature selection algorithm to several directions: (a) different types of\noutcomes, such as continuous, binary, nominal, and time-to-event, (b) different\ntypes of predictive models (e.g., linear least squares, logistic regression),\n(c) different types of predictive features (continuous, categorical), and (d)\ndifferent, statistical-based stopping criteria. We compare the proposed\nalgorithm against LASSO, a prototypical, widely used algorithm for\nhigh-dimensional data. On dozens of simulated datasets, as well as, real gene\nexpression datasets, gOMP is on par, or outperforms LASSO for case-control\nbinary classification, quantified outcomes (regression), and (censored)\nsurvival times (time-to-event) analysis. gOMP has also several theoretical\nadvantages that are discussed. While gOMP is based on quite simple and basic\nstatistical ideas, easy to implement and to generalize, we also show in an\nextensive evaluation that it is also quite effective in bioinformatics analysis\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:33:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Tsagris", "Michail", ""], ["Papadovasilakis", "Zacharias", ""], ["Lakiotaki", "Kleanthi", ""], ["Tsamardinos", "Ioannis", ""]]}, {"id": "2004.00293", "submitter": "Noemi Mauro", "authors": "Noemi Mauro, Liliana Ardissono, Laura Di Rocco, Michela Bertolotto and\n  Giovanna Guerrini", "title": "Impact of Semantic Granularity on Geographic Information Search Support", "comments": null, "journal-ref": "2018 IEEE/WIC/ACM International Conference on Web Intelligence\n  (WI)", "doi": "10.1109/WI.2018.00-73", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Retrieval research has used semantics to provide accurate\nsearch results, but the analysis of conceptual abstraction has mainly focused\non information integration. We consider session-based query expansion in\nGeographical Information Retrieval, and investigate the impact of semantic\ngranularity (i.e., specificity of concepts representation) on the suggestion of\nrelevant types of information to search for. We study how different levels of\ndetail in knowledge representation influence the capability of guiding the user\nin the exploration of a complex information space. A comparative analysis of\nthe performance of a query expansion model, using three spatial ontologies\ndefined at different semantic granularity levels, reveals that a fine-grained\nrepresentation enhances recall. However, precision depends on how closely the\nontologies match the way people conceptualize and verbally describe the\ngeographic space.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 08:58:25 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Mauro", "Noemi", ""], ["Ardissono", "Liliana", ""], ["Di Rocco", "Laura", ""], ["Bertolotto", "Michela", ""], ["Guerrini", "Giovanna", ""]]}, {"id": "2004.00306", "submitter": "Sravanti Addepalli", "authors": "Sravanti Addepalli, Vivek B.S., Arya Baburaj, Gaurang Sriramanan, R.\n  Venkatesh Babu", "title": "Towards Achieving Adversarial Robustness by Enforcing Feature\n  Consistency Across Bit Planes", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As humans, we inherently perceive images based on their predominant features,\nand ignore noise embedded within lower bit planes. On the contrary, Deep Neural\nNetworks are known to confidently misclassify images corrupted with\nmeticulously crafted perturbations that are nearly imperceptible to the human\neye. In this work, we attempt to address this problem by training networks to\nform coarse impressions based on the information in higher bit planes, and use\nthe lower bit planes only to refine their prediction. We demonstrate that, by\nimposing consistency on the representations learned across differently\nquantized images, the adversarial robustness of networks improves significantly\nwhen compared to a normally trained model. Present state-of-the-art defenses\nagainst adversarial attacks require the networks to be explicitly trained using\nadversarial samples that are computationally expensive to generate. While such\nmethods that use adversarial training continue to achieve the best results,\nthis work paves the way towards achieving robustness without having to\nexplicitly train on adversarial samples. The proposed approach is therefore\nfaster, and also closer to the natural learning process in humans.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:31:10 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Addepalli", "Sravanti", ""], ["S.", "Vivek B.", ""], ["Baburaj", "Arya", ""], ["Sriramanan", "Gaurang", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2004.00307", "submitter": "Filipe Assun\\c{c}\\~ao", "authors": "Filipe Assun\\c{c}\\~ao, Nuno Louren\\c{c}o, Bernardete Ribeiro, and\n  Penousal Machado", "title": "Evolution of Scikit-Learn Pipelines with Dynamic Structured Grammatical\n  Evolution", "comments": "EvoApps 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of Machine Learning (ML) models is a difficult and\ntime-consuming job that comprises a series of sequential and correlated tasks\nthat go from the data pre-processing, and the design and extraction of\nfeatures, to the choice of the ML algorithm and its parameterisation. The task\nis even more challenging considering that the design of features is in many\ncases problem specific, and thus requires domain-expertise. To overcome these\nlimitations Automated Machine Learning (AutoML) methods seek to automate, with\nfew or no human-intervention, the design of pipelines, i.e., automate the\nselection of the sequence of methods that have to be applied to the raw data.\nThese methods have the potential to enable non-expert users to use ML, and\nprovide expert users with solutions that they would unlikely consider. In\nparticular, this paper describes AutoML-DSGE - a novel grammar-based framework\nthat adapts Dynamic Structured Grammatical Evolution (DSGE) to the evolution of\nScikit-Learn classification pipelines. The experimental results include\ncomparing AutoML-DSGE to another grammar-based AutoML framework, Resilient\nClassificationPipeline Evolution (RECIPE), and show that the average\nperformance of the classification pipelines generated by AutoML-DSGE is always\nsuperior to the average performance of RECIPE; the differences are\nstatistically significant in 3 out of the 10 used datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:31:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Assun\u00e7\u00e3o", "Filipe", ""], ["Louren\u00e7o", "Nuno", ""], ["Ribeiro", "Bernardete", ""], ["Machado", "Penousal", ""]]}, {"id": "2004.00315", "submitter": "Linjun Zhou", "authors": "Linjun Zhou, Peng Cui, Xu Jia, Shiqiang Yang, Qi Tian", "title": "Learning to Select Base Classes for Few-shot Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning has attracted intensive research attention in recent years.\nMany methods have been proposed to generalize a model learned from provided\nbase classes to novel classes, but no previous work studies how to select base\nclasses, or even whether different base classes will result in different\ngeneralization performance of the learned model. In this paper, we utilize a\nsimple yet effective measure, the Similarity Ratio, as an indicator for the\ngeneralization performance of a few-shot model. We then formulate the base\nclass selection problem as a submodular optimization problem over Similarity\nRatio. We further provide theoretical analysis on the optimization lower bound\nof different optimization methods, which could be used to identify the most\nappropriate algorithm for different experimental settings. The extensive\nexperiments on ImageNet, Caltech256 and CUB-200-2011 demonstrate that our\nproposed method is effective in selecting a better base dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:55:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhou", "Linjun", ""], ["Cui", "Peng", ""], ["Jia", "Xu", ""], ["Yang", "Shiqiang", ""], ["Tian", "Qi", ""]]}, {"id": "2004.00345", "submitter": "Sergei Popov", "authors": "Anton Sinitsin, Vsevolod Plokhotnyuk, Dmitriy Pyrkin, Sergei Popov,\n  Artem Babenko", "title": "Editable Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  These days deep neural networks are ubiquitously used in a wide range of\ntasks, from image classification and machine translation to face identification\nand self-driving cars. In many applications, a single model error can lead to\ndevastating financial, reputational and even life-threatening consequences.\nTherefore, it is crucially important to correct model mistakes quickly as they\nappear. In this work, we investigate the problem of neural network editing $-$\nhow one can efficiently patch a mistake of the model on a particular sample,\nwithout influencing the model behavior on other samples. Namely, we propose\nEditable Training, a model-agnostic training technique that encourages fast\nediting of the trained model. We empirically demonstrate the effectiveness of\nthis method on large-scale image classification and machine translation tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:26:27 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 08:00:15 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Sinitsin", "Anton", ""], ["Plokhotnyuk", "Vsevolod", ""], ["Pyrkin", "Dmitriy", ""], ["Popov", "Sergei", ""], ["Babenko", "Artem", ""]]}, {"id": "2004.00348", "submitter": "Irene Vlassi Pandi", "authors": "Irene Vlassi Pandi, Earl T. Barr, Andrew D. Gordon, and Charles Sutton", "title": "OptTyper: Probabilistic Type Inference by Optimising Logical and Natural\n  Constraints", "comments": "29 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to the type inference problem for dynamic\nlanguages. Our goal is to combine \\emph{logical} constraints, that is,\ndeterministic information from a type system, with \\emph{natural} constraints,\nthat is, uncertain statistical information about types learnt from sources like\nidentifier names. To this end, we introduce a framework for probabilistic type\ninference that combines logic and learning: logical constraints on the types\nare extracted from the program, and deep learning is applied to predict types\nfrom surface-level code properties that are statistically associated. The\nforemost insight of our method is to constrain the predictions from the\nlearning procedure to respect the logical constraints, which we achieve by\nrelaxing the logical inference problem of type prediction into a continuous\noptimisation problem. We build a tool called OptTyper to predict missing types\nfor TypeScript files. OptTyper combines a continuous interpretation of logical\nconstraints derived by classical static analysis of TypeScript code, with\nnatural constraints obtained from a deep learning model, which learns naming\nconventions for types from a large codebase. By evaluating OptTyper, we show\nthat the combination of logical and natural constraints yields a large\nimprovement in performance over either kind of information individually and\nachieves a 4% improvement over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:32:28 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 17:12:41 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 19:17:53 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Pandi", "Irene Vlassi", ""], ["Barr", "Earl T.", ""], ["Gordon", "Andrew D.", ""], ["Sutton", "Charles", ""]]}, {"id": "2004.00353", "submitter": "Ricky T. Q. Chen", "authors": "Yucen Luo, Alex Beatson, Mohammad Norouzi, Jun Zhu, David Duvenaud,\n  Ryan P. Adams, and Ricky T. Q. Chen", "title": "SUMO: Unbiased Estimation of Log Marginal Probability for Latent\n  Variable Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard variational lower bounds used to train latent variable models\nproduce biased estimates of most quantities of interest. We introduce an\nunbiased estimator of the log marginal likelihood and its gradients for latent\nvariable models based on randomized truncation of infinite series. If\nparameterized by an encoder-decoder architecture, the parameters of the encoder\ncan be optimized to minimize its variance of this estimator. We show that\nmodels trained using our estimator give better test-set likelihoods than a\nstandard importance-sampling based approach for the same average computational\ncost. This estimator also allows use of latent variable models for tasks where\nunbiased estimators, rather than marginal likelihood lower bounds, are\npreferred, such as minimizing reverse KL divergences and estimating score\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:49:30 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 19:42:39 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Luo", "Yucen", ""], ["Beatson", "Alex", ""], ["Norouzi", "Mohammad", ""], ["Zhu", "Jun", ""], ["Duvenaud", "David", ""], ["Adams", "Ryan P.", ""], ["Chen", "Ricky T. Q.", ""]]}, {"id": "2004.00361", "submitter": "Jonathan Daniel Smith", "authors": "Jonathan D. Smith, Kamyar Azizzadenesheli and Zachary E. Ross", "title": "EikoNet: Solving the Eikonal equation with Deep Neural Networks", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.geo-ph physics.optics stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent deep learning revolution has created an enormous opportunity for\naccelerating compute capabilities in the context of physics-based simulations.\nHere, we propose EikoNet, a deep learning approach to solving the Eikonal\nequation, which characterizes the first-arrival-time field in heterogeneous 3D\nvelocity structures. Our grid-free approach allows for rapid determination of\nthe travel time between any two points within a continuous 3D domain. These\ntravel time solutions are allowed to violate the differential equation - which\ncasts the problem as one of optimization - with the goal of finding network\nparameters that minimize the degree to which the equation is violated. In doing\nso, the method exploits the differentiability of neural networks to calculate\nthe spatial gradients analytically, meaning the network can be trained on its\nown without ever needing solutions from a finite difference algorithm. EikoNet\nis rigorously tested on several velocity models and sampling methods to\ndemonstrate robustness and versatility. Training and inference are highly\nparallelized, making the approach well-suited for GPUs. EikoNet has low memory\noverhead, and further avoids the need for travel-time lookup tables. The\ndeveloped approach has important applications to earthquake hypocenter\ninversion, ray multi-pathing, and tomographic modeling, as well as to other\nfields beyond seismology where ray tracing is essential.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:31:53 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 23:04:36 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 15:43:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Smith", "Jonathan D.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Ross", "Zachary E.", ""]]}, {"id": "2004.00362", "submitter": "Kisor Sahu Dr.", "authors": "Ajay K. Gogineni, S. Swayamjyoti, Devadatta Sahoo, Kisor K. Sahu, Raj\n  kishore", "title": "Multi-Class classification of vulnerabilities in Smart Contracts using\n  AWD-LSTM, with pre-trained encoder inspired from natural language processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability detection and safety of smart contracts are of paramount\nimportance because of their immutable nature. Symbolic tools like OYENTE and\nMAIAN are typically used for vulnerability prediction in smart contracts. As\nthese tools are computationally expensive, they are typically used to detect\nvulnerabilities until some predefined invocation depth. These tools require\nmore search time as the invocation depth increases. Since the number of smart\ncontracts is increasing exponentially, it is difficult to analyze the contracts\nusing these traditional tools. Recently a machine learning technique called\nLong Short Term Memory (LSTM) has been used for binary classification, i.e., to\npredict whether a smart contract is vulnerable or not. This technique requires\nnearly constant search time as the invocation depth increases. In the present\narticle, we have shown a multi-class classification, where we classify a smart\ncontract in Suicidal, Prodigal, Greedy, or Normal categories. We used Average\nStochastic Gradient Descent Weight-Dropped LSTM (AWD-LSTM), which is a variant\nof LSTM, to perform classification. We reduced the class imbalance (a large\nnumber of normal contracts as compared to other categories) by considering only\nthe distinct opcode combination for normal contracts. We have achieved a\nweighted average Fbeta score of 90.0%. Hence, such techniques can be used to\nanalyze a large number of smart contracts and help to improve the security of\nthese contracts.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 20:48:09 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gogineni", "Ajay K.", ""], ["Swayamjyoti", "S.", ""], ["Sahoo", "Devadatta", ""], ["Sahu", "Kisor K.", ""], ["kishore", "Raj", ""]]}, {"id": "2004.00363", "submitter": "Paul Ferrand", "authors": "Paul Ferrand, Alexis Decurninge, Maxime Guillaud", "title": "DNN-based Localization from Channel Estimates: Feature Design and\n  Experimental Results", "comments": "Submitted to Globecom 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the use of deep neural networks (DNNs) in the context of channel\nstate information (CSI)-based localization for Massive MIMO cellular systems.\nWe discuss the practical impairments that are likely to be present in practical\nCSI estimates, and introduce a principled approach to feature design for\nCSI-based DNN applications based on the objective of making the features\ninvariant to the considered impairments. We demonstrate the efficiency of this\napproach by applying it to a dataset constituted of geo-tagged CSI measured in\nan outdoors campus environment, and training a DNN to estimate the position of\nthe UE on the basis of the CSI. We provide an experimental evaluation of\nseveral aspects of that learning approach, including localization accuracy,\ngeneralization capability, and data aging.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 15:20:15 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:15:42 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ferrand", "Paul", ""], ["Decurninge", "Alexis", ""], ["Guillaud", "Maxime", ""]]}, {"id": "2004.00367", "submitter": "Sumit Darak Dr", "authors": "Sumit J. Darak and Manjesh K.Hanawal", "title": "Distributed Learning in Ad-Hoc Networks: A Multi-player Multi-armed\n  Bandit Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation networks are expected to be ultra-dense with a very high peak\nrate but relatively lower expected traffic per user. For such scenario,\nexisting central controller based resource allocation may incur substantial\nsignaling (control communications) leading to a negative effect on the quality\nof service (e.g. drop calls), energy and spectrum efficiency. To overcome this\nproblem, cognitive ad-hoc networks (CAHN) that share spectrum with other\nnetworks are being envisioned. They allow some users to identify and\ncommunicate in `free slots' thereby reducing signaling load and allowing the\nhigher number of users per base stations (dense networks). Such networks open\nup many interesting challenges such as resource identification, coordination,\ndynamic and context-aware adaptation for which Machine Learning and Artificial\nIntelligence framework offers novel solutions. In this paper, we discuss\nstate-of-the-art multi-armed multi-player bandit based distributed learning\nalgorithms that allow users to adapt to the environment and coordinate with\nother players/users. We also discuss various open research problems for\nfeasible realization of CAHN and interesting applications in other domains such\nas energy harvesting, Internet of Things, and Smart grids.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:11:47 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Darak", "Sumit J.", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2004.00378", "submitter": "Weiheng Jiang", "authors": "Weiheng Jiang, Xiaogang Wu, Bolin Chen, Wenjiang Feng, Yi Jin", "title": "Time-Frequency Analysis based Blind Modulation Classification for\n  Multiple-Antenna Systems", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Blind modulation classification is an important step to implement cognitive\nradio networks. The multiple-input multiple-output (MIMO) technique is widely\nused in military and civil communication systems. Due to the lack of prior\ninformation about channel parameters and the overlapping of signals in the MIMO\nsystems, the traditional likelihood-based and feature-based approaches cannot\nbe applied in these scenarios directly. Hence, in this paper, to resolve the\nproblem of blind modulation classification in MIMO systems, the time-frequency\nanalysis method based on the windowed short-time Fourier transform is used to\nanalyse the time-frequency characteristics of time-domain modulated signals.\nThen the extracted time-frequency characteristics are converted into RGB\nspectrogram images, and the convolutional neural network based on transfer\nlearning is applied to classify the modulation types according to the RGB\nspectrogram images. Finally, a decision fusion module is used to fuse the\nclassification results of all the receive antennas. Through simulations, we\nanalyse the classification performance at different signal-to-noise ratios\n(SNRs), the results indicate that, for the single-input single-output (SISO)\nnetwork, our proposed scheme can achieve 92.37% and 99.12% average\nclassification accuracy at SNRs of -4 dB and 10 dB, respectively. For the MIMO\nnetwork, our scheme achieves 80.42% and 87.92% average classification accuracy\nat -4 dB and 10 dB, respectively. This outperforms the existing classification\nmethods based on baseband signals.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:27:29 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Jiang", "Weiheng", ""], ["Wu", "Xiaogang", ""], ["Chen", "Bolin", ""], ["Feng", "Wenjiang", ""], ["Jin", "Yi", ""]]}, {"id": "2004.00384", "submitter": "Dongdong Yang", "authors": "Dongdong Yang, Kevin Dyer, Senzhang Wang", "title": "Interpretable Deep Learning Model for Online Multi-touch Attribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online advertising, users may be exposed to a range of different\nadvertising campaigns, such as natural search or referral or organic search,\nbefore leading to a final transaction. Estimating the contribution of\nadvertising campaigns on the user's journey is very meaningful and crucial. A\nmarketer could observe each customer's interaction with different marketing\nchannels and modify their investment strategies accordingly. Existing methods\nincluding both traditional last-clicking methods and recent data-driven\napproaches for the multi-touch attribution (MTA) problem lack enough\ninterpretation on why the methods work. In this paper, we propose a novel model\ncalled DeepMTA, which combines deep learning model and additive feature\nexplanation model for interpretable online multi-touch attribution. DeepMTA\nmainly contains two parts, the phased-LSTMs based conversion prediction model\nto catch different time intervals, and the additive feature attribution model\ncombined with shaley values. Additive feature attribution is explanatory that\ncontains a linear function of binary variables. As the first interpretable deep\nlearning model for MTA, DeepMTA considers three important features in the\ncustomer journey: event sequence order, event frequency and time-decay effect\nof the event. Evaluation on a real dataset shows the proposed conversion\nprediction model achieves 91\\% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 23:21:40 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yang", "Dongdong", ""], ["Dyer", "Kevin", ""], ["Wang", "Senzhang", ""]]}, {"id": "2004.00387", "submitter": "Yang Gao", "authors": "Yang Gao, Yi-Fan Li, Yu Lin, Hang Gao, Latifur Khan", "title": "Deep Learning on Knowledge Graph for Recommender System: A Survey", "comments": "6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in research have demonstrated the effectiveness of knowledge\ngraphs (KG) in providing valuable external knowledge to improve recommendation\nsystems (RS). A knowledge graph is capable of encoding high-order relations\nthat connect two objects with one or multiple related attributes. With the help\nof the emerging Graph Neural Networks (GNN), it is possible to extract both\nobject characteristics and relations from KG, which is an essential factor for\nsuccessful recommendations. In this paper, we provide a comprehensive survey of\nthe GNN-based knowledge-aware deep recommender systems. Specifically, we\ndiscuss the state-of-the-art frameworks with a focus on their core component,\ni.e., the graph embedding module, and how they address practical recommendation\nissues such as scalability, cold-start and so on. We further summarize the\ncommonly-used benchmark datasets, evaluation metrics as well as open-source\ncodes. Finally, we conclude the survey and propose potential research\ndirections in this rapidly growing field.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:53:14 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Gao", "Yang", ""], ["Li", "Yi-Fan", ""], ["Lin", "Yu", ""], ["Gao", "Hang", ""], ["Khan", "Latifur", ""]]}, {"id": "2004.00403", "submitter": "Mark Boss", "authors": "Mark Boss, Varun Jampani, Kihwan Kim, Hendrik P.A. Lensch, Jan Kautz", "title": "Two-shot Spatially-varying BRDF and Shape Estimation", "comments": null, "journal-ref": null, "doi": "10.1109/CVPR42600.2020.00404", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capturing the shape and spatially-varying appearance (SVBRDF) of an object\nfrom images is a challenging task that has applications in both computer vision\nand graphics. Traditional optimization-based approaches often need a large\nnumber of images taken from multiple views in a controlled environment. Newer\ndeep learning-based approaches require only a few input images, but the\nreconstruction quality is not on par with optimization techniques. We propose a\nnovel deep learning architecture with a stage-wise estimation of shape and\nSVBRDF. The previous predictions guide each estimation, and a joint refinement\nnetwork later refines both SVBRDF and shape. We follow a practical mobile image\ncapture setting and use unaligned two-shot flash and no-flash images as input.\nBoth our two-shot image capture and network inference can run on mobile\nhardware. We also create a large-scale synthetic training dataset with\ndomain-randomized geometry and realistic materials. Extensive experiments on\nboth synthetic and real-world datasets show that our network trained on a\nsynthetic dataset can generalize well to real-world images. Comparisons with\nrecent approaches demonstrate the superior performance of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:56:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Boss", "Mark", ""], ["Jampani", "Varun", ""], ["Kim", "Kihwan", ""], ["Lensch", "Hendrik P. A.", ""], ["Kautz", "Jan", ""]]}, {"id": "2004.00404", "submitter": "Songyan Xue", "authors": "Songyan Xue, Yi Ma, Na Yi, and Terence E. Dodgson", "title": "A Modular Neural Network Based Deep Learning Approach for MIMO Signal\n  Detection", "comments": "12 pages, 11 figures, transcation on communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reveal that artificial neural network (ANN) assisted\nmultiple-input multiple-output (MIMO) signal detection can be modeled as\nANN-assisted lossy vector quantization (VQ), named MIMO-VQ, which is basically\na joint statistical channel quantization and signal quantization procedure. It\nis found that the quantization loss increases linearly with the number of\ntransmit antennas, and thus MIMO-VQ scales poorly with the size of MIMO.\nMotivated by this finding, we propose a novel modular neural network based\napproach, termed MNNet, where the whole network is formed by a set of\npre-defined ANN modules. The key of ANN module design lies in the integration\nof parallel interference cancellation in the MNNet, which linearly reduces the\ninterference (or equivalently the number of transmit-antennas) along the\nfeed-forward propagation; and so as the quantization loss. Our simulation\nresults show that the MNNet approach largely improves the deep-learning\ncapacity with near-optimal performance in various cases. Provided that MNNet is\nwell modularized, the learning procedure does not need to be applied on the\nentire network as a whole, but rather at the modular level. Due to this reason,\nMNNet has the advantage of much lower learning complexity than other\ndeep-learning based MIMO detection approaches.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:56:38 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Xue", "Songyan", ""], ["Ma", "Yi", ""], ["Yi", "Na", ""], ["Dodgson", "Terence E.", ""]]}, {"id": "2004.00407", "submitter": "Heeyoung Kwak", "authors": "Heeyoung Kwak, Minwoo Lee, Seunghyun Yoon, Jooyoung Chang, Sangmin\n  Park, Kyomin Jung", "title": "Drug-disease Graph: Predicting Adverse Drug Reaction Signals via Graph\n  Neural Network with Clinical Data", "comments": "To appear at PAKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse Drug Reaction (ADR) is a significant public health concern\nworld-wide. Numerous graph-based methods have been applied to biomedical graphs\nfor predicting ADRs in pre-marketing phases. ADR detection in post-market\nsurveillance is no less important than pre-marketing assessment, and ADR\ndetection with large-scale clinical data have attracted much attention in\nrecent years. However, there are not many studies considering graph structures\nfrom clinical data for detecting an ADR signal, which is a pair of a\nprescription and a diagnosis that might be a potential ADR. In this study, we\ndevelop a novel graph-based framework for ADR signal detection using healthcare\nclaims data. We construct a Drug-disease graph with nodes representing the\nmedical codes. The edges are given as the relationships between two codes,\ncomputed using the data. We apply Graph Neural Network to predict ADR signals,\nusing labels from the Side Effect Resource database. The model shows improved\nAUROC and AUPRC performance of 0.795 and 0.775, compared to other algorithms,\nshowing that it successfully learns node representations expressive of those\nrelationships. Furthermore, our model predicts ADR pairs that do not exist in\nthe established ADR database, showing its capability to supplement the ADR\ndatabase.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:01:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kwak", "Heeyoung", ""], ["Lee", "Minwoo", ""], ["Yoon", "Seunghyun", ""], ["Chang", "Jooyoung", ""], ["Park", "Sangmin", ""], ["Jung", "Kyomin", ""]]}, {"id": "2004.00410", "submitter": "Samuel Harford", "authors": "Samuel Harford, Fazle Karim and Houshang Darabi", "title": "Adversarial Attacks on Multivariate Time Series", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.10755", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification models for the multivariate time series have gained\nsignificant importance in the research community, but not much research has\nbeen done on generating adversarial samples for these models. Such samples of\nadversaries could become a security concern. In this paper, we propose\ntransforming the existing adversarial transformation network (ATN) on a\ndistilled model to attack various multivariate time series classification\nmodels. The proposed attack on the classification model utilizes a distilled\nmodel as a surrogate that mimics the behavior of the attacked classical\nmultivariate time series classification models. The proposed methodology is\ntested onto 1-Nearest Neighbor Dynamic Time Warping (1-NN DTW) and a Fully\nConvolutional Network (FCN), all of which are trained on 18 University of East\nAnglia (UEA) and University of California Riverside (UCR) datasets. We show\nboth models were susceptible to attacks on all 18 datasets. To the best of our\nknowledge, adversarial attacks have only been conducted in the domain of\nunivariate time series and have not been conducted on multivariate time series.\nsuch an attack on time series classification models has never been done before.\nAdditionally, we recommend future researchers that develop time series\nclassification models to incorporating adversarial data samples into their\ntraining data sets to improve resilience on adversarial samples and to consider\nmodel robustness as an evaluative metric.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:15:41 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Harford", "Samuel", ""], ["Karim", "Fazle", ""], ["Darabi", "Houshang", ""]]}, {"id": "2004.00412", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng", "title": "Total Variation Regularization for Compartmental Epidemic Models with\n  Time-Varying Dynamics", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compartmental epidemic models are among the most popular ones in\nepidemiology. For the parameters (e.g., the transmission rate) characterizing\nthese models, the majority of researchers simplify them as constants, while\nsome others manage to detect their continuous variations. In this paper, we aim\nat capturing, on the other hand, discontinuous variations, which better\ndescribe the impact of many noteworthy events, such as city lockdowns, the\nopening of field hospitals, and the mutation of the virus, whose effect should\nbe instant. To achieve this, we balance the model's likelihood by total\nvariation, which regulates the temporal variations of the model parameters. To\ninfer these parameters, instead of using Monte Carlo methods, we design a novel\nyet straightforward optimization algorithm, dubbed Iterated Nelder--Mead, which\nrepeatedly applies the Nelder--Mead algorithm. Experiments conducted on the\nsimulated data demonstrate that our approach can reproduce these\ndiscontinuities and precisely depict the epidemics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:06:10 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 03:39:13 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zheng", "Wenjie", ""]]}, {"id": "2004.00413", "submitter": "Zekarias Tilahun Kefato", "authors": "Zekarias T. Kefato, Sarunas Girdzijauskas", "title": "Gossip and Attend: Context-Sensitive Graph Representation Learning", "comments": "In Proc. of the 14th AAAI International Conference on Web and Social\n  Media, ICWSM 2020. arXiv admin note: text overlap with arXiv:2001.10394", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning (GRL) is a powerful technique for learning\nlow-dimensional vector representation of high-dimensional and often sparse\ngraphs. Most studies explore the structure and metadata associated with the\ngraph using random walks and employ an unsupervised or semi-supervised learning\nschemes. Learning in these methods is context-free, resulting in only a single\nrepresentation per node. Recently studies have argued on the adequacy of a\nsingle representation and proposed context-sensitive approaches, which are\ncapable of extracting multiple node representations for different contexts.\nThis proved to be highly effective in applications such as link prediction and\nranking.\n  However, most of these methods rely on additional textual features that\nrequire complex and expensive RNNs or CNNs to capture high-level features or\nrely on a community detection algorithm to identify multiple contexts of a\nnode.\n  In this study we show that in-order to extract high-quality context-sensitive\nnode representations it is not needed to rely on supplementary node features,\nnor to employ computationally heavy and complex models. We propose GOAT, a\ncontext-sensitive algorithm inspired by gossip communication and a mutual\nattention mechanism simply over the structure of the graph. We show the\nefficacy of GOAT using 6 real-world datasets on link prediction and node\nclustering tasks and compare it against 12 popular and state-of-the-art (SOTA)\nbaselines. GOAT consistently outperforms them and achieves up to 12% and 19%\ngain over the best performing methods on link prediction and clustering tasks,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:23:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kefato", "Zekarias T.", ""], ["Girdzijauskas", "Sarunas", ""]]}, {"id": "2004.00422", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Yisong Yue, Bistra Dilkina", "title": "A General Large Neighborhood Search Framework for Solving Integer Linear\n  Programs", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a strategy for data-driven algorithm design for\nlarge-scale combinatorial optimization problems that can leverage existing\nstate-of-the-art solvers in general purpose ways. The goal is to arrive at new\napproaches that can reliably outperform existing solvers in wall-clock time. We\nfocus on solving integer programs, and ground our approach in the large\nneighborhood search (LNS) paradigm, which iteratively chooses a subset of\nvariables to optimize while leaving the remainder fixed. The appeal of LNS is\nthat it can easily use any existing solver as a subroutine, and thus can\ninherit the benefits of carefully engineered heuristic or complete approaches\nand their software implementations. We show that one can learn a good\nneighborhood selector using imitation and reinforcement learning techniques.\nThrough an extensive empirical validation in bounded-time optimization, we\ndemonstrate that our LNS framework can significantly outperform compared to\nstate-of-the-art commercial solvers such as Gurobi.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 23:08:14 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:19:57 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 22:21:18 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Yue", "Yisong", ""], ["Dilkina", "Bistra", ""]]}, {"id": "2004.00426", "submitter": "Grzegorz Dudek", "authors": "Pawe{\\l} Pe{\\l}ka, Grzegorz Dudek", "title": "Ensemble Forecasting of Monthly Electricity Demand using Pattern\n  Similarity-based Methods", "comments": "12 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2003.01475", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents ensemble forecasting of monthly electricity demand using\npattern similarity-based forecasting methods (PSFMs). PSFMs applied in this\nstudy include $k$-nearest neighbor model, fuzzy neighborhood model, kernel\nregression model, and general regression neural network. An integral part of\nPSFMs is a time series representation using patterns of time series sequences.\nPattern representation ensures the input and output data unification through\nfiltering a trend and equalizing variance. Two types of ensembles are created:\nheterogeneous and homogeneous. The former consists of different type base\nmodels, while the latter consists of a single-type base model. Five strategies\nare used for controlling a diversity of members in a homogeneous approach. The\ndiversity is generated using different subsets of training data, different\nsubsets of features, randomly disrupted input and output variables, and\nrandomly disrupted model parameters. An empirical illustration applies the\nensemble models as well as individual PSFMs for comparison to the monthly\nelectricity demand forecasting for 35 European countries.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 17:26:58 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Pe\u0142ka", "Pawe\u0142", ""], ["Dudek", "Grzegorz", ""]]}, {"id": "2004.00430", "submitter": "Vithya Yogarajan", "authors": "Vithya Yogarajan, Jacob Montiel, Tony Smith, Bernhard Pfahringer", "title": "Seeing The Whole Patient: Using Multi-Label Medical Text Classification\n  Techniques to Enhance Predictions of Medical Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based multi-label medical text classifications can be used\nto enhance the understanding of the human body and aid the need for patient\ncare. We present a broad study on clinical natural language processing\ntechniques to maximise a feature representing text when predicting medical\ncodes on patients with multi-morbidity. We present results of multi-label\nmedical text classification problems with 18, 50 and 155 labels. We compare\nseveral variations to embeddings, text tagging, and pre-processing. For\nimbalanced data we show that labels which occur infrequently, benefit the most\nfrom additional features incorporated in embeddings. We also show that high\ndimensional embeddings pre-trained using health-related data present a\nsignificant improvement in a multi-label setting, similarly to the way they\nimprove performance for binary classification. High dimensional embeddings from\nthis research are made available for public use.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:19:30 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yogarajan", "Vithya", ""], ["Montiel", "Jacob", ""], ["Smith", "Tony", ""], ["Pfahringer", "Bernhard", ""]]}, {"id": "2004.00431", "submitter": "Jaehyung Kim", "authors": "Jaehyung Kim, Jongheon Jeong, Jinwoo Shin", "title": "M2m: Imbalanced Classification via Major-to-minor Translation", "comments": "12 pages; CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most real-world scenarios, labeled training datasets are highly\nclass-imbalanced, where deep neural networks suffer from generalizing to a\nbalanced testing criterion. In this paper, we explore a novel yet simple way to\nalleviate this issue by augmenting less-frequent classes via translating\nsamples (e.g., images) from more-frequent classes. This simple approach enables\na classifier to learn more generalizable features of minority classes, by\ntransferring and leveraging the diversity of the majority information. Our\nexperimental results on a variety of class-imbalanced datasets show that the\nproposed method improves the generalization on minority classes significantly\ncompared to other existing re-sampling or re-weighting methods. The performance\nof our method even surpasses those of previous state-of-the-art methods for the\nimbalanced classification.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:21:17 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 10:48:34 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kim", "Jaehyung", ""], ["Jeong", "Jongheon", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2004.00433", "submitter": "Mohammad Braei", "authors": "Mohammad Braei and Sebastian Wagner", "title": "Anomaly Detection in Univariate Time-series: A Survey on the\n  State-of-the-Art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Anomaly detection for time-series data has been an important research field\nfor a long time. Seminal work on anomaly detection methods has been focussing\non statistical approaches. In recent years an increasing number of machine\nlearning algorithms have been developed to detect anomalies on time-series.\nSubsequently, researchers tried to improve these techniques using (deep) neural\nnetworks. In the light of the increasing number of anomaly detection methods,\nthe body of research lacks a broad comparative evaluation of statistical,\nmachine learning and deep learning methods. This paper studies 20 univariate\nanomaly detection methods from the all three categories. The evaluation is\nconducted on publicly available datasets, which serve as benchmarks for\ntime-series anomaly detection. By analyzing the accuracy of each method as well\nas the computation time of the algorithms, we provide a thorough insight about\nthe performance of these anomaly detection approaches, alongside some general\nnotion of which method is suited for a certain type of data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:22:34 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Braei", "Mohammad", ""], ["Wagner", "Sebastian", ""]]}, {"id": "2004.00436", "submitter": "Sherif Abdelkarim Mr.", "authors": "Sherif Abdelkarim, Aniket Agarwal, Panos Achlioptas, Jun Chen, Jiaji\n  Huang, Boyang Li, Kenneth Church, Mohamed Elhoseiny", "title": "Long Tail Visual Relationship Recognition with Hubless Regularized\n  Relmix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several approaches have been proposed in recent literature to alleviate the\nlong-tail problem, mostly in the object classification task. We propose to\nstudy the task of Long-Tail Visual Relationship Recognition (LTVRR), which aims\nat generalizing on the structured long-tail distribution of visual\nrelationships (e.g., \"rabbit grazing on grass\"). In this setup, subject,\nrelation, and object classes individually follow a long-tail distribution. We\nfirst introduce two large-scale long-tail visual relationship recognition\nbenchmarks to study this task, dubbed as VG8K-LT (5330 objects, 2000\nrelationships) and GQA-LT (1703 objects, 310 relations). VG8K-LT and GQA-LT are\nbuilt upon the widely used Visual Genome and GQA datasets. In contrast to\nexisting benchmarks, some classes appear at a very low frequency ($1-14$\nexamples). We use these benchmarks to study the performance of several\nstate-of-the-art long-tail models on LTVRR setup. We developed a\nvisiolinguistic hubless (ViLHub) loss that consistently encourages visual\nclassifiers to be more predictive of tail classes while being accurate on the\nhead. We also propose relationship Mixup augmentation, dubbed as RelMix, to\nimprove performance on the tail on VG8K-LT and GQA-LT benchmarks with the best\nperformance achieved when combined with ViLHub loss. Benchmarks and code will\nbe made available.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 19:03:29 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 20:13:01 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 21:36:30 GMT"}, {"version": "v4", "created": "Tue, 5 Jan 2021 09:53:50 GMT"}, {"version": "v5", "created": "Wed, 24 Feb 2021 02:52:17 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Abdelkarim", "Sherif", ""], ["Agarwal", "Aniket", ""], ["Achlioptas", "Panos", ""], ["Chen", "Jun", ""], ["Huang", "Jiaji", ""], ["Li", "Boyang", ""], ["Church", "Kenneth", ""], ["Elhoseiny", "Mohamed", ""]]}, {"id": "2004.00438", "submitter": "Lucas Baier", "authors": "Lucas Baier (1), Marcel Hofmann (2), Niklas K\\\"uhl (1), Marisa Mohr (2\n  and 3) and Gerhard Satzger (1) ((1) Karlsruhe Institute of Technology,\n  Karlsruhe, Germany, (2) inovex GmbH, Karlsruhe, Germany (3) University of\n  L\\\"ubeck, L\\\"ubeck, Germany)", "title": "Handling Concept Drifts in Regression Problems -- the Error Intersection\n  Approach", "comments": null, "journal-ref": null, "doi": "10.30844/wi_2020_c1-baier", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are omnipresent for predictions on big data. One\nchallenge of deployed models is the change of the data over time, a phenomenon\ncalled concept drift. If not handled correctly, a concept drift can lead to\nsignificant mispredictions. We explore a novel approach for concept drift\nhandling, which depicts a strategy to switch between the application of simple\nand complex machine learning models for regression tasks. We assume that the\napproach plays out the individual strengths of each model, switching to the\nsimpler model if a drift occurs and switching back to the complex model for\ntypical situations. We instantiate the approach on a real-world data set of\ntaxi demand in New York City, which is prone to multiple drifts, e.g. the\nweather phenomena of blizzards, resulting in a sudden decrease of taxi demand.\nWe are able to show that our suggested approach outperforms all regarded\nbaselines significantly.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:30:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Baier", "Lucas", "", "2\n  and 3"], ["Hofmann", "Marcel", "", "2\n  and 3"], ["K\u00fchl", "Niklas", "", "2\n  and 3"], ["Mohr", "Marisa", "", "2\n  and 3"], ["Satzger", "Gerhard", ""]]}, {"id": "2004.00440", "submitter": "Lu Yu", "authors": "Lu Yu, Bart{\\l}omiej Twardowski, Xialei Liu, Luis Herranz, Kai Wang,\n  Yongmei Cheng, Shangling Jui, Joost van de Weijer", "title": "Semantic Drift Compensation for Class-Incremental Learning", "comments": "Accepted at CVPR2020, Code available at\n  \\url{https://github.com/yulu0724/SDC-IL}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Class-incremental learning of deep networks sequentially increases the number\nof classes to be classified. During training, the network has only access to\ndata of one task at a time, where each task contains several classes. In this\nsetting, networks suffer from catastrophic forgetting which refers to the\ndrastic drop in performance on previous tasks. The vast majority of methods\nhave studied this scenario for classification networks, where for each new task\nthe classification layer of the network must be augmented with additional\nweights to make room for the newly added classes. Embedding networks have the\nadvantage that new classes can be naturally included into the network without\nadding new weights. Therefore, we study incremental learning for embedding\nnetworks. In addition, we propose a new method to estimate the drift, called\nsemantic drift, of features and compensate for it without the need of any\nexemplars. We approximate the drift of previous tasks based on the drift that\nis experienced by current task data. We perform experiments on fine-grained\ndatasets, CIFAR100 and ImageNet-Subset. We demonstrate that embedding networks\nsuffer significantly less from catastrophic forgetting. We outperform existing\nmethods which do not require exemplars and obtain competitive results compared\nto methods which store exemplars. Furthermore, we show that our proposed SDC\nwhen combined with existing methods to prevent forgetting consistently improves\nresults.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 13:31:19 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Yu", "Lu", ""], ["Twardowski", "Bart\u0142omiej", ""], ["Liu", "Xialei", ""], ["Herranz", "Luis", ""], ["Wang", "Kai", ""], ["Cheng", "Yongmei", ""], ["Jui", "Shangling", ""], ["van de Weijer", "Joost", ""]]}, {"id": "2004.00464", "submitter": "Oliver D\\\"urr", "authors": "Beate Sick, Torsten Hothorn, Oliver D\\\"urr", "title": "Deep transformation models: Tackling complex regression problems with\n  neural network based transformation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep transformation model for probabilistic regression. Deep\nlearning is known for outstandingly accurate predictions on complex data but in\nregression tasks, it is predominantly used to just predict a single number.\nThis ignores the non-deterministic character of most tasks. Especially if\ncrucial decisions are based on the predictions, like in medical applications,\nit is essential to quantify the prediction uncertainty. The presented deep\nlearning transformation model estimates the whole conditional probability\ndistribution, which is the most thorough way to capture uncertainty about the\noutcome. We combine ideas from a statistical transformation model (most likely\ntransformation) with recent transformation models from deep learning\n(normalizing flows) to predict complex outcome distributions. The core of the\nmethod is a parameterized transformation function which can be trained with the\nusual maximum likelihood framework using gradient descent. The method can be\ncombined with existing deep learning architectures. For small machine learning\nbenchmark datasets, we report state of the art performance for most dataset and\npartly even outperform it. Our method works for complex input data, which we\ndemonstrate by employing a CNN architecture on image data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:23:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Sick", "Beate", ""], ["Hothorn", "Torsten", ""], ["D\u00fcrr", "Oliver", ""]]}, {"id": "2004.00475", "submitter": "Vivak Patel", "authors": "Vivak Patel", "title": "Stopping Criteria for, and Strong Convergence of, Stochastic Gradient\n  Descent on Bottou-Curtis-Nocedal Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stopping criteria for Stochastic Gradient Descent (SGD) methods play\nimportant roles from enabling adaptive step size schemes to providing rigor for\ndownstream analyses such as asymptotic inference. Unfortunately, current\nstopping criteria for SGD methods are often heuristics that rely on asymptotic\nnormality results or convergence to stationary distributions, which may fail to\nexist for nonconvex functions and, thereby, limit the applicability of such\nstopping criteria. To address this issue, in this work, we rigorously develop\ntwo stopping criteria for SGD that can be applied to a broad class of nonconvex\nfunctions, which we term Bottou-Curtis-Nocedal functions. Moreover, as a\nprerequisite for developing these stopping criteria, we prove that the gradient\nfunction evaluated at SGD's iterates converges strongly to zero for\nBottou-Curtis-Nocedal functions, which addresses an open question in the SGD\nliterature. As a result of our work, our rigorously developed stopping criteria\ncan be used to develop new adaptive step size schemes or bolster other\ndownstream analyses for nonconvex functions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:44:43 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 16:35:35 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Patel", "Vivak", ""]]}, {"id": "2004.00478", "submitter": "Reda Marzouk", "authors": "Reda Marzouk and Colin de la Higuera", "title": "Distance and Equivalence between Finite State Machines and Recurrent\n  Neural Networks: Computational results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need of interpreting Deep Learning (DL) models has led, during the past\nyears, to a proliferation of works concerned by this issue. Among strategies\nwhich aim at shedding some light on how information is represented internally\nin DL models, one consists in extracting symbolic rule-based machines from\nconnectionist models that are supposed to approximate well their behaviour. In\norder to better understand how reasonable these approximation strategies are,\nwe need to know the computational complexity of measuring the quality of\napproximation. In this article, we will prove some computational results\nrelated to the problem of extracting Finite State Machine (FSM) based models\nfrom trained RNN Language models. More precisely, we'll show the following: (a)\nFor general weighted RNN-LMs with a single hidden layer and a ReLu activation:\n- The equivalence problem of a PDFA/PFA/WFA and a weighted first-order RNN-LM\nis undecidable; - As a corollary, the distance problem between languages\ngenerated by PDFA/PFA/WFA and that of a weighted RNN-LM is not recursive; -The\nintersection between a DFA and the cut language of a weighted RNN-LM is\nundecidable; - The equivalence of a PDFA/PFA/WFA and weighted RNN-LM in a\nfinite support is EXP-Hard; (b) For consistent weight RNN-LMs with any\ncomputable activation function: - The Tcheybechev distance approximation is\ndecidable; - The Tcheybechev distance approximation in a finite support is\nNP-Hard. Moreover, our reduction technique from 3-SAT makes this latter fact\neasily generalizable to other RNN architectures (e.g. LSTMs/RNNs), and RNNs\nwith finite precision.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:48:59 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Marzouk", "Reda", ""], ["de la Higuera", "Colin", ""]]}, {"id": "2004.00480", "submitter": "Amir Mosavi Prof", "authors": "Sultan Noman Qasem and Amir Mosavi", "title": "Novel Meta-Heuristic Model for Discrimination between Iron Deficiency\n  Anemia and B-Thalassemia with CBC Indices Based on Dynamic Harmony Search", "comments": "10pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent decades, attention has been directed at anemia classification for\nvarious medical purposes, such as thalassemia screening and predicting iron\ndeficiency anemia (IDA). In this study, a new method has been successfully\ntested for discrimination between IDA and \\b{eta}-thalassemia trait\n(\\b{eta}-TT). The method is based on a Dynamic Harmony Search (DHS). Complete\nblood count (CBC), a fast and inexpensive laboratory test, is used as the input\nof the system. Other models, such as a genetic programming method called\nstructured representation on genetic algorithm in non-linear function fitting\n(STROGANOFF), an artificial neural network (ANN), an adaptive neuro-fuzzy\ninference system (ANFIS), a support vector machine (SVM), k-nearest neighbor\n(KNN), and certain traditional methods, are compared with the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:37:21 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Qasem", "Sultan Noman", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.00490", "submitter": "Jinke Ren", "authors": "Jinke Ren, Yinghui He, Dingzhu Wen, Guanding Yu, Kaibin Huang, and\n  Dongning Guo", "title": "Scheduling for Cellular Federated Edge Learning with Importance and\n  Channel Awareness", "comments": "This is an extended version of a submission to IEEE journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cellular federated edge learning (FEEL), multiple edge devices holding\nlocal data jointly train a neural network by communicating learning updates\nwith an access point without exchanging their data samples. With very limited\ncommunication resources, it is beneficial to schedule the most informative\nlocal learning updates. In this paper, a novel scheduling policy is proposed to\nexploit both diversity in multiuser channels and diversity in the \"importance\"\nof the edge devices' learning updates. First, a new probabilistic scheduling\nframework is developed to yield unbiased update aggregation in FEEL. The\nimportance of a local learning update is measured by its gradient divergence.\nIf one edge device is scheduled in each communication round, the scheduling\npolicy is derived in closed form to achieve the optimal trade-off between\nchannel quality and update importance. The probabilistic scheduling framework\nis then extended to allow scheduling multiple edge devices in each\ncommunication round. Numerical results obtained using popular models and\nlearning datasets demonstrate that the proposed scheduling policy can achieve\nfaster model convergence and higher learning accuracy than conventional\nscheduling policies that only exploit a single type of diversity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:09:45 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 05:25:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ren", "Jinke", ""], ["He", "Yinghui", ""], ["Wen", "Dingzhu", ""], ["Yu", "Guanding", ""], ["Huang", "Kaibin", ""], ["Guo", "Dongning", ""]]}, {"id": "2004.00500", "submitter": "Anirudh Vemula", "authors": "Anirudh Vemula, Wen Sun, J. Andrew Bagnell", "title": "Exploration in Action Space", "comments": "Presented at RSS 2018 in Learning and Inference in Robotics:\n  Integrating Structure, Priors and Models workshop. arXiv admin note: text\n  overlap with arXiv:1901.11503", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter space exploration methods with black-box optimization have recently\nbeen shown to outperform state-of-the-art approaches in continuous control\nreinforcement learning domains. In this paper, we examine reasons why these\nmethods work better and the situations in which they are worse than traditional\naction space exploration methods. Through a simple theoretical analysis, we\nshow that when the parametric complexity required to solve the reinforcement\nlearning problem is greater than the product of action space dimensionality and\nhorizon length, exploration in action space is preferred. This is also shown\nempirically by comparing simple exploration methods on several toy problems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:27:22 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Vemula", "Anirudh", ""], ["Sun", "Wen", ""], ["Bagnell", "J. Andrew", ""]]}, {"id": "2004.00502", "submitter": "Vinayakumar R", "authors": "Simran K, Sriram S, Vinayakumar R, Soman KP", "title": "Deep Learning Approach for Intelligent Named Entity Recognition of Cyber\n  Security", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the amount of Cyber Security data generated in the form of\nunstructured texts, for example, social media resources, blogs, articles, and\nso on has exceptionally increased. Named Entity Recognition (NER) is an initial\nstep towards converting this unstructured data into structured data which can\nbe used by a lot of applications. The existing methods on NER for Cyber\nSecurity data are based on rules and linguistic characteristics. A Deep\nLearning (DL) based approach embedded with Conditional Random Fields (CRFs) is\nproposed in this paper. Several DL architectures are evaluated to find the most\noptimal architecture. The combination of Bidirectional Gated Recurrent Unit\n(Bi-GRU), Convolutional Neural Network (CNN), and CRF performed better compared\nto various other DL frameworks on a publicly available benchmark dataset. This\nmay be due to the reason that the bidirectional structures preserve the\nfeatures related to the future and previous words in a sequence.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:36:19 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["K", "Simran", ""], ["S", "Sriram", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "2004.00503", "submitter": "Vinayakumar R", "authors": "Simran K, Prathiksha Balakrishna, Vinayakumar R, Soman KP", "title": "Deep Learning Approach for Enhanced Cyber Threat Indicators in Twitter\n  Stream", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent days, the amount of Cyber Security text data shared via social\nmedia resources mainly Twitter has increased. An accurate analysis of this data\ncan help to develop cyber threat situational awareness framework for a cyber\nthreat. This work proposes a deep learning based approach for tweet data\nanalysis. To convert the tweets into numerical representations, various text\nrepresentations are employed. These features are feed into deep learning\narchitecture for optimal feature extraction as well as classification. Various\nhyperparameter tuning approaches are used for identifying optimal text\nrepresentation method as well as optimal network parameters and network\nstructures for deep learning models. For comparative analysis, the classical\ntext representation method with classical machine learning algorithm is\nemployed. From the detailed analysis of experiments, we found that the deep\nlearning architecture with advanced text representation methods performed\nbetter than the classical text representation and classical machine learning\nalgorithms. The primary reason for this is that the advanced text\nrepresentation methods have the capability to learn sequential properties which\nexist among the textual data and deep learning architectures learns the optimal\nfeatures along with decreasing the feature size.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:29:42 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["K", "Simran", ""], ["Balakrishna", "Prathiksha", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "2004.00505", "submitter": "Eoin Brophy", "authors": "Eoin Brophy, Willie Muehlhausen, Alan F. Smeaton, Tomas E. Ward", "title": "Optimised Convolutional Neural Networks for Heart Rate Estimation and\n  Human Activity Recognition in Wrist Worn Sensing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wrist-worn smart devices are providing increased insights into human health,\nbehaviour and performance through sophisticated analytics. However, battery\nlife, device cost and sensor performance in the face of movement-related\nartefact present challenges which must be further addressed to see effective\napplications and wider adoption through commoditisation of the technology. We\naddress these challenges by demonstrating, through using a simple optical\nmeasurement, photoplethysmography (PPG) used conventionally for heart rate\ndetection in wrist-worn sensors, that we can provide improved heart rate and\nhuman activity recognition (HAR) simultaneously at low sample rates, without an\ninertial measurement unit. This simplifies hardware design and reduces costs\nand power budgets. We apply two deep learning pipelines, one for human activity\nrecognition and one for heart rate estimation. HAR is achieved through the\napplication of a visual classification approach, capable of robust performance\nat low sample rates. Here, transfer learning is leveraged to retrain a\nconvolutional neural network (CNN) to distinguish characteristics of the PPG\nduring different human activities. For heart rate estimation we use a CNN\nadopted for regression which maps noisy optical signals to heart rate\nestimates. In both cases, comparisons are made with leading conventional\napproaches. Our results demonstrate a low sampling frequency can achieve good\nperformance without significant degradation of accuracy. 5 Hz and 10 Hz were\nshown to have 80.2% and 83.0% classification accuracy for HAR respectively.\nThese same sampling frequencies also yielded a robust heart rate estimation\nwhich was comparative with that achieved at the more energy-intensive rate of\n256 Hz.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:44:58 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Brophy", "Eoin", ""], ["Muehlhausen", "Willie", ""], ["Smeaton", "Alan F.", ""], ["Ward", "Tomas E.", ""]]}, {"id": "2004.00507", "submitter": "Changyang She", "authors": "Rui Dong, Changyang She, Wibowo Hardjawana, Yonghui Li, and Branka\n  Vucetic", "title": "Deep Learning for Radio Resource Allocation with Diverse\n  Quality-of-Service Requirements in 5G", "comments": "The manuscript has been submitted to IEEE TWC. It is in the second\n  round of review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accommodate diverse Quality-of-Service (QoS) requirements in the 5th\ngeneration cellular networks, base stations need real-time optimization of\nradio resources in time-varying network conditions. This brings high computing\noverheads and long processing delays. In this work, we develop a deep learning\nframework to approximate the optimal resource allocation policy that minimizes\nthe total power consumption of a base station by optimizing bandwidth and\ntransmit power allocation. We find that a fully-connected neural network (NN)\ncannot fully guarantee the QoS requirements due to the approximation errors and\nquantization errors of the numbers of subcarriers. To tackle this problem, we\npropose a cascaded structure of NNs, where the first NN approximates the\noptimal bandwidth allocation, and the second NN outputs the transmit power\nrequired to satisfy the QoS requirement with given bandwidth allocation.\nConsidering that the distribution of wireless channels and the types of\nservices in the wireless networks are non-stationary, we apply deep transfer\nlearning to update NNs in non-stationary wireless networks. Simulation results\nvalidate that the cascaded NNs outperform the fully connected NN in terms of\nQoS guarantee. In addition, deep transfer learning can reduce the number of\ntraining samples required to train the NNs remarkably.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 04:48:22 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Dong", "Rui", ""], ["She", "Changyang", ""], ["Hardjawana", "Wibowo", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "2004.00508", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek, Pawe{\\l} Pe{\\l}ka, Slawek Smyl", "title": "A Hybrid Residual Dilated LSTM end Exponential Smoothing Model for\n  Mid-Term Electric Load Forecasting", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a hybrid and hierarchical deep learning model for mid-term\nload forecasting. The model combines exponential smoothing (ETS), advanced Long\nShort-Term Memory (LSTM) and ensembling. ETS extracts dynamically the main\ncomponents of each individual time series and enables the model to learn their\nrepresentation. Multi-layer LSTM is equipped with dilated recurrent skip\nconnections and a spatial shortcut path from lower layers to allow the model to\nbetter capture long-term seasonal relationships and ensure more efficient\ntraining. A common learning procedure for LSTM and ETS, with a penalized\npinball loss, leads to simultaneous optimization of data representation and\nforecasting performance. In addition, ensembling at three levels ensures a\npowerful regularization. A simulation study performed on the monthly\nelectricity demand time series for 35 European countries confirmed the high\nperformance of the proposed model and its competitiveness with classical models\nsuch as ARIMA and ETS as well as state-of-the-art models based on machine\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 10:53:50 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Dudek", "Grzegorz", ""], ["Pe\u0142ka", "Pawe\u0142", ""], ["Smyl", "Slawek", ""]]}, {"id": "2004.00530", "submitter": "Zhuangdi Zhu", "authors": "Zhuangdi Zhu, Kaixiang Lin, Bo Dai, and Jiayu Zhou", "title": "Learning Sparse Rewarded Tasks from Sub-Optimal Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning (RL) has demonstrated its superiority\non many complex sequential decision-making problems. However, heavy dependence\non dense rewards and high sample-complexity impedes the wide adoption of these\nmethods in real-world scenarios. On the other hand, imitation learning (IL)\nlearns effectively in sparse-rewarded tasks by leveraging the existing expert\ndemonstrations. In practice, collecting a sufficient amount of expert\ndemonstrations can be prohibitively expensive, and the quality of\ndemonstrations typically limits the performance of the learning policy. In this\nwork, we propose Self-Adaptive Imitation Learning (SAIL) that can achieve\n(near) optimal performance given only a limited number of sub-optimal\ndemonstrations for highly challenging sparse reward tasks. SAIL bridges the\nadvantages of IL and RL to reduce the sample complexity substantially, by\neffectively exploiting sup-optimal demonstrations and efficiently exploring the\nenvironment to surpass the demonstrated performance. Extensive empirical\nresults show that not only does SAIL significantly improve the\nsample-efficiency but also leads to much better final performance across\ndifferent continuous control tasks, comparing to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:57:15 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Zhu", "Zhuangdi", ""], ["Lin", "Kaixiang", ""], ["Dai", "Bo", ""], ["Zhou", "Jiayu", ""]]}, {"id": "2004.00540", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Sebastian Herzog, Minija Tamosiunaite and Florentin\n  W\\\"org\\\"otter", "title": "Generation of Paths in a Maze using a Deep Network without Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory- or path-planning is a fundamental issue in a wide variety of\napplications. Here we show that it is possible to solve path planning for\nmultiple start- and end-points highly efficiently with a network that consists\nonly of max pooling layers, for which no network training is needed. Different\nfrom competing approaches, very large mazes containing more than half a billion\nnodes with dense obstacle configuration and several thousand path end-points\ncan this way be solved in very short time on parallel hardware.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:08:45 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Herzog", "Sebastian", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.00543", "submitter": "James Tu", "authors": "James Tu, Mengye Ren, Siva Manivasagam, Ming Liang, Bin Yang, Richard\n  Du, Frank Cheng, Raquel Urtasun", "title": "Physically Realizable Adversarial Examples for LiDAR Object Detection", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern autonomous driving systems rely heavily on deep learning models to\nprocess point cloud sensory data; meanwhile, deep models have been shown to be\nsusceptible to adversarial attacks with visually imperceptible perturbations.\nDespite the fact that this poses a security concern for the self-driving\nindustry, there has been very little exploration in terms of 3D perception, as\nmost adversarial attacks have only been applied to 2D flat images. In this\npaper, we address this issue and present a method to generate universal 3D\nadversarial objects to fool LiDAR detectors. In particular, we demonstrate that\nplacing an adversarial object on the rooftop of any target vehicle to hide the\nvehicle entirely from LiDAR detectors with a success rate of 80%. We report\nattack results on a suite of detectors using various input representation of\npoint clouds. We also conduct a pilot study on adversarial defense using data\naugmentation. This is one step closer towards safer self-driving under unseen\nconditions from limited training data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:11:04 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 16:02:41 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Tu", "James", ""], ["Ren", "Mengye", ""], ["Manivasagam", "Siva", ""], ["Liang", "Ming", ""], ["Yang", "Bin", ""], ["Du", "Richard", ""], ["Cheng", "Frank", ""], ["Urtasun", "Raquel", ""]]}, {"id": "2004.00552", "submitter": "Andrea L\\'opez-Incera", "authors": "Andrea L\\'opez-Incera, Katja Ried, Thomas M\\\"uller, Hans J. Briegel", "title": "Development of swarm behavior in artificial learning agents that adapt\n  to different foraging environments", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0243628", "report-no": null, "categories": "q-bio.PE cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective behavior, and swarm formation in particular, has been studied from\nseveral perspectives within a large variety of fields, ranging from biology to\nphysics. In this work, we apply Projective Simulation to model each individual\nas an artificial learning agent that interacts with its neighbors and\nsurroundings in order to make decisions and learn from them. Within a\nreinforcement learning framework, we discuss one-dimensional learning scenarios\nwhere agents need to get to food resources to be rewarded. We observe how\ndifferent types of collective motion emerge depending on the distance the\nagents need to travel to reach the resources. For instance, strongly aligned\nswarms emerge when the food source is placed far away from the region where\nagents are situated initially. In addition, we study the properties of the\nindividual trajectories that occur within the different types of emergent\ncollective dynamics. Agents trained to find distant resources exhibit\nindividual trajectories with L\\'evy-like characteristics as a consequence of\nthe collective motion, whereas agents trained to reach nearby resources present\nBrownian-like trajectories.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:32:13 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["L\u00f3pez-Incera", "Andrea", ""], ["Ried", "Katja", ""], ["M\u00fcller", "Thomas", ""], ["Briegel", "Hans J.", ""]]}, {"id": "2004.00557", "submitter": "Lev Reyzin", "authors": "Lev Reyzin", "title": "Statistical Queries and Statistical Algorithms: Foundations and\n  Applications", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a survey of the foundations of statistical queries and their many\napplications to other areas. We introduce the model, give the main definitions,\nand we explore the fundamental theory statistical queries and how how it\nconnects to various notions of learnability. We also give a detailed summary of\nsome of the applications of statistical queries to other areas, including to\noptimization, to evolvability, and to differential privacy.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:37:10 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:32:38 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Reyzin", "Lev", ""]]}, {"id": "2004.00558", "submitter": "Mariana Souza", "authors": "Mariana A. Souza, Robert Sabourin, George D. C. Cavalcanti and Rafael\n  M. O. Cruz", "title": "Multi-label learning for dynamic model type recommendation", "comments": "Paper accepted to the 2020 International Joint Conference on Neural\n  Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic selection techniques aim at selecting the local experts around each\ntest sample in particular for performing its classification. While generating\nthe classifier on a local scope may make it easier for singling out the locally\ncompetent ones, as in the online local pool (OLP) technique, using the same\nbase-classifier model in uneven distributions may restrict the local level of\ncompetence, since each region may have a data distribution that favors one\nmodel over the others. Thus, we propose in this work a problem-independent\ndynamic base-classifier model recommendation for the OLP technique, which uses\ninformation regarding the behavior of a portfolio of models over the samples of\ndifferent problems to recommend one (or several) of them on a per-instance\nmanner. Our proposed framework builds a multi-label meta-classifier responsible\nfor recommending a set of relevant model types based on the local data\ncomplexity of the region surrounding each test sample. The OLP technique then\nproduces a local pool with the model that yields the highest probability score\nof the meta-classifier. Experimental results show that different data\ndistributions favored different model types on a local scope. Moreover, based\non the performance of an ideal model type selector, it was observed that there\nis a clear advantage in choosing a relevant model type for each test instance.\nOverall, the proposed model type recommender system yielded a statistically\nsimilar performance to the original OLP with fixed base-classifier model. Given\nthe novelty of the approach and the gap in performance between the proposed\nframework and the ideal selector, we regard this as a promising research\ndirection. Code available at\ngithub.com/marianaasouza/dynamic-model-recommender.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:42:12 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Souza", "Mariana A.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""], ["Cruz", "Rafael M. O.", ""]]}, {"id": "2004.00566", "submitter": "Xun Xian", "authors": "Xun Xian, Xinran Wang, Jie Ding, Reza Ghanadan", "title": "Assisted Learning: A Framework for Multi-Organization Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasing number of AI scenarios, collaborations among different\norganizations or agents (e.g., human and robots, mobile units) are often\nessential to accomplish an organization-specific mission. However, to avoid\nleaking useful and possibly proprietary information, organizations typically\nenforce stringent security constraints on sharing modeling algorithms and data,\nwhich significantly limits collaborations. In this work, we introduce the\nAssisted Learning framework for organizations to assist each other in\nsupervised learning tasks without revealing any organization's algorithm, data,\nor even task. An organization seeks assistance by broadcasting task-specific\nbut nonsensitive statistics and incorporating others' feedback in one or more\niterations to eventually improve its predictive performance. Theoretical and\nexperimental studies, including real-world medical benchmarks, show that\nAssisted Learning can often achieve near-oracle learning performance as if data\nand training processes were centralized.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:54:49 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 23:22:35 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 02:34:01 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 19:04:24 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2020 06:35:26 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Xian", "Xun", ""], ["Wang", "Xinran", ""], ["Ding", "Jie", ""], ["Ghanadan", "Reza", ""]]}, {"id": "2004.00567", "submitter": "Marco Pleines", "authors": "Marco Pleines, Jenia Jitsev, Mike Preuss, and Frank Zimmer", "title": "Obstacle Tower Without Human Demonstrations: How Far a Deep Feed-Forward\n  Network Goes with Reinforcement Learning", "comments": "8 pages, 9 figures, 2 tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Obstacle Tower Challenge is the task to master a procedurally generated\nchain of levels that subsequently get harder to complete. Whereas the most top\nperforming entries of last year's competition used human demonstrations or\nreward shaping to learn how to cope with the challenge, we present an approach\nthat performed competitively (placed 7th) but starts completely from scratch by\nmeans of Deep Reinforcement Learning with a relatively simple feed-forward deep\nnetwork structure. We especially look at the generalization performance of the\ntaken approach concerning different seeds and various visual themes that have\nbecome available after the competition, and investigate where the agent fails\nand why. Note that our approach does not possess a short-term memory like\nemploying recurrent hidden states. With this work, we hope to contribute to a\nbetter understanding of what is possible with a relatively simple, flexible\nsolution that can be applied to learning in environments featuring complex 3D\nvisual input where the abstract task structure itself is still fairly simple.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:55:51 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:07:52 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pleines", "Marco", ""], ["Jitsev", "Jenia", ""], ["Preuss", "Mike", ""], ["Zimmer", "Frank", ""]]}, {"id": "2004.00568", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Sebastian Herzog, Timo L\\\"uddecke, Minija\n  Tamosiunaite and Florentin W\\\"org\\\"otter", "title": "One-shot path planning for multi-agent systems using fully convolutional\n  neural network", "comments": null, "journal-ref": "The 3rd International Symposium on Swarm Behavior and Bioinspired\n  Robotics (SWARM 2019), November 20-22, Okinawa, Japan", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning plays a crucial role in robot action execution, since a path or\na motion trajectory for a particular action has to be defined first before the\naction can be executed. Most of the current approaches are iterative methods\nwhere the trajectory is generated iteratively by predicting the next state\nbased on the current state. Moreover, in case of multi-agent systems, paths are\nplanned for each agent separately. In contrast to that, we propose a novel\nmethod by utilising fully convolutional neural network, which allows generation\nof complete paths, even for more than one agent, in one-shot, i.e., with a\nsingle prediction step. We demonstrate that our method is able to successfully\ngenerate optimal or close to optimal paths in more than 98\\% of the cases for\nsingle path predictions. Moreover, we show that although the network has never\nbeen trained on multi-path planning it is also able to generate optimal or\nclose to optimal paths in 85.7\\% and 65.4\\% of the cases when generating two\nand three paths, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:56:39 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Herzog", "Sebastian", ""], ["L\u00fcddecke", "Timo", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.00570", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Ziye Ma, Jingqi Li, Somayeh Sojoudi", "title": "Tightened Convex Relaxations for Neural Network Robustness Certification", "comments": "Proceedings of the 59th IEEE Conference on Decision and Control, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of certifying the robustness of neural\nnetworks to perturbed and adversarial input data. Such certification is\nimperative for the application of neural networks in safety-critical\ndecision-making and control systems. Certification techniques using convex\noptimization have been proposed, but they often suffer from relaxation errors\nthat void the certificate. Our work exploits the structure of ReLU networks to\nimprove relaxation errors through a novel partition-based certification\nprocedure. The proposed method is proven to tighten existing linear programming\nrelaxations, and asymptotically achieves zero relaxation error as the partition\nis made finer. We develop a finite partition that attains zero relaxation error\nand use the result to derive a tractable partitioning scheme that minimizes the\nworst-case relaxation error. Experiments using real data show that the\npartitioning procedure is able to issue robustness certificates in cases where\nprior methods fail. Consequently, partition-based certification procedures are\nfound to provide an intuitive, effective, and theoretically justified method\nfor tightening existing convex relaxation techniques.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:59:21 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 00:04:58 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Ma", "Ziye", ""], ["Li", "Jingqi", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2004.00574", "submitter": "Henning Lange", "authors": "Henning Lange, Steven L. Brunton, Nathan Kutz", "title": "From Fourier to Koopman: Spectral Methods for Long-term Time Series\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose spectral methods for long-term forecasting of temporal signals\nstemming from linear and nonlinear quasi-periodic dynamical systems. For linear\nsignals, we introduce an algorithm with similarities to the Fourier transform\nbut which does not rely on periodicity assumptions, allowing for forecasting\ngiven potentially arbitrary sampling intervals. We then extend this algorithm\nto handle nonlinearities by leveraging Koopman theory. The resulting algorithm\nperforms a spectral decomposition in a nonlinear, data-dependent basis. The\noptimization objective for both algorithms is highly non-convex. However,\nexpressing the objective in the frequency domain allows us to compute global\noptima of the error surface in a scalable and efficient manner, partially by\nexploiting the computational properties of the Fast Fourier Transform. Because\nof their close relation to Bayesian Spectral Analysis, uncertainty\nquantification metrics are a natural byproduct of the spectral forecasting\nmethods. We extensively benchmark these algorithms against other leading\nforecasting methods on a range of synthetic experiments as well as in the\ncontext of real-world power systems and fluid flows.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:04:02 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lange", "Henning", ""], ["Brunton", "Steven L.", ""], ["Kutz", "Nathan", ""]]}, {"id": "2004.00583", "submitter": "Alan JiaXiang Guo", "authors": "Alan J.X. Guo and Fei Zhu", "title": "Improving Deep Hyperspectral Image Classification Performance with\n  Spectral Unmixing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural networks have made great progress in the\nhyperspectral image (HSI) classification. However, the overfitting effect,\nwhich is mainly caused by complicated model structure and small training set,\nremains a major concern. Reducing the complexity of the neural networks could\nprevent overfitting to some extent, but also declines the networks' ability to\nexpress more abstract features. Enlarging the training set is also difficult,\nfor the high expense of acquisition and manual labeling. In this paper, we\npropose an abundance-based multi-HSI classification method. Firstly, we convert\nevery HSI from the spectral domain to the abundance domain by a\ndataset-specific autoencoder. Secondly, the abundance representations from\nmultiple HSIs are collected to form an enlarged dataset. Lastly, we train an\nabundance-based classifier and employ the classifier to predict over all the\ninvolved HSI datasets. Different from the spectra that are usually highly\nmixed, the abundance features are more representative in reduced dimension with\nless noise. This benefits the proposed method to employ simple classifiers and\nenlarged training data, and to expect less overfitting issues. The\neffectiveness of the proposed method is verified by the ablation study and the\ncomparative experiments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:14:05 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 02:52:54 GMT"}, {"version": "v3", "created": "Fri, 3 Apr 2020 16:09:51 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 05:10:08 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Guo", "Alan J. X.", ""], ["Zhu", "Fei", ""]]}, {"id": "2004.00587", "submitter": "Yong-Lu Li", "authors": "Yong-Lu Li, Yue Xu, Xiaohan Mao, Cewu Lu", "title": "Symmetry and Group in Attribute-Object Compositions", "comments": "Accepted to CVPR 2020, supplementary materials included, code\n  available:https://github.com/DirtyHarryLYL/SymNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributes and objects can compose diverse compositions. To model the\ncompositional nature of these general concepts, it is a good choice to learn\nthem through transformations, such as coupling and decoupling. However, complex\ntransformations need to satisfy specific principles to guarantee the\nrationality. In this paper, we first propose a previously ignored principle of\nattribute-object transformation: Symmetry. For example, coupling peeled-apple\nwith attribute peeled should result in peeled-apple, and decoupling peeled from\napple should still output apple. Incorporating the symmetry principle, a\ntransformation framework inspired by group theory is built, i.e. SymNet. SymNet\nconsists of two modules, Coupling Network and Decoupling Network. With the\ngroup axioms and symmetry property as objectives, we adopt Deep Neural Networks\nto implement SymNet and train it in an end-to-end paradigm. Moreover, we\npropose a Relative Moving Distance (RMD) based recognition method to utilize\nthe attribute change instead of the attribute pattern itself to classify\nattributes. Our symmetry learning can be utilized for the Compositional\nZero-Shot Learning task and outperforms the state-of-the-art on widely-used\nbenchmarks. Code is available at https://github.com/DirtyHarryLYL/SymNet.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:16:57 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Li", "Yong-Lu", ""], ["Xu", "Yue", ""], ["Mao", "Xiaohan", ""], ["Lu", "Cewu", ""]]}, {"id": "2004.00588", "submitter": "Kayo Yin", "authors": "Kayo Yin and Jesse Read", "title": "Better Sign Language Translation with STMC-Transformer", "comments": "Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING'2020)", "journal-ref": "28th International Conference on Computational Linguistics 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sign Language Translation (SLT) first uses a Sign Language Recognition (SLR)\nsystem to extract sign language glosses from videos. Then, a translation system\ngenerates spoken language translations from the sign language glosses. This\npaper focuses on the translation system and introduces the STMC-Transformer\nwhich improves on the current state-of-the-art by over 5 and 7 BLEU\nrespectively on gloss-to-text and video-to-text translation of the\nPHOENIX-Weather 2014T dataset. On the ASLG-PC12 corpus, we report an increase\nof over 16 BLEU.\n  We also demonstrate the problem in current methods that rely on gloss\nsupervision. The video-to-text translation of our STMC-Transformer outperforms\ntranslation of GT glosses. This contradicts previous claims that GT gloss\ntranslation acts as an upper bound for SLT performance and reveals that glosses\nare an inefficient representation of sign language. For future SLT research, we\ntherefore suggest an end-to-end training of the recognition and translation\nmodels, or using a different sign language annotation scheme.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:20:04 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 00:59:54 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Yin", "Kayo", ""], ["Read", "Jesse", ""]]}, {"id": "2004.00600", "submitter": "Craig Sherstan", "authors": "Craig Sherstan, Bilal Kartal, Pablo Hernandez-Leal, and Matthew E.\n  Taylor", "title": "Work in Progress: Temporally Extended Auxiliary Tasks", "comments": "Accepted for the Adaptive and Learning Agents (ALA) Workshop at AAMAS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive auxiliary tasks have been shown to improve performance in numerous\nreinforcement learning works, however, this effect is still not well\nunderstood. The primary purpose of the work presented here is to investigate\nthe impact that an auxiliary task's prediction timescale has on the agent's\npolicy performance. We consider auxiliary tasks which learn to make on-policy\npredictions using temporal difference learning. We test the impact of\nprediction timescale using a specific form of auxiliary task in which the input\nimage is used as the prediction target, which we refer to as temporal\ndifference autoencoders (TD-AE). We empirically evaluate the effect of TD-AE on\nthe A2C algorithm in the VizDoom environment using different prediction\ntimescales. While we do not observe a clear relationship between the prediction\ntimescale on performance, we make the following observations: 1) using\nauxiliary tasks allows us to reduce the trajectory length of the A2C algorithm,\n2) in some cases temporally extended TD-AE performs better than a straight\nautoencoder, 3) performance with auxiliary tasks is sensitive to the weight\nplaced on the auxiliary loss, 4) despite this sensitivity, auxiliary tasks\nimproved performance without extensive hyper-parameter tuning. Our overall\nconclusions are that TD-AE increases the robustness of the A2C algorithm to the\ntrajectory length and while promising, further study is required to fully\nunderstand the relationship between auxiliary task prediction timescale and the\nagent's performance.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:36:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 22:45:14 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 21:42:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Sherstan", "Craig", ""], ["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "2004.00601", "submitter": "Eduardo C. Garrido-Merch\\'an", "authors": "Eduardo C. Garrido-Merch\\'an, Daniel Hern\\'andez-Lobato", "title": "Parallel Predictive Entropy Search for Multi-objective Bayesian\n  Optimization with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems often involve the optimization of several objectives\nunder multiple constraints. An example is the hyper-parameter tuning problem of\nmachine learning algorithms. In particular, the minimization of the estimation\nof the generalization error of a deep neural network and at the same time the\nminimization of its prediction time. We may also consider as a constraint that\nthe deep neural network must be implemented in a chip with an area below some\nsize. Here, both the objectives and the constraint are black boxes, i.e.,\nfunctions whose analytical expressions are unknown and are expensive to\nevaluate. Bayesian optimization (BO) methodologies have given state-of-the-art\nresults for the optimization of black-boxes. Nevertheless, most BO methods are\nsequential and evaluate the objectives and the constraints at just one input\nlocation, iteratively. Sometimes, however, we may have resources to evaluate\nseveral configurations in parallel. Notwithstanding, no parallel BO method has\nbeen proposed to deal with the optimization of multiple objectives under\nseveral constraints. If the expensive evaluations can be carried out in\nparallel (as when a cluster of computers is available), sequential evaluations\nresult in a waste of resources. This article introduces PPESMOC, Parallel\nPredictive Entropy Search for Multi-objective Bayesian Optimization with\nConstraints, an information-based batch method for the simultaneous\noptimization of multiple expensive-to-evaluate black-box functions under the\npresence of several constraints. Iteratively, PPESMOC selects a batch of input\nlocations at which to evaluate the black-boxes so as to maximally reduce the\nentropy of the Pareto set of the optimization problem. We present empirical\nevidence in the form of synthetic, benchmark and real-world experiments that\nillustrate the effectiveness of PPESMOC.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:37:58 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:29:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Garrido-Merch\u00e1n", "Eduardo C.", ""], ["Hern\u00e1ndez-Lobato", "Daniel", ""]]}, {"id": "2004.00603", "submitter": "Andrea Celli", "authors": "Andrea Celli, Alberto Marchesi, Gabriele Farina, Nicola Gatti", "title": "No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of simple, uncoupled no-regret dynamics that converge to\ncorrelated equilibria in normal-form games is a celebrated result in the theory\nof multi-agent systems. Specifically, it has been known for more than 20 years\nthat when all players seek to minimize their internal regret in a repeated\nnormal-form game, the empirical frequency of play converges to a normal-form\ncorrelated equilibrium. Extensive-form (that is, tree-form) games generalize\nnormal-form games by modeling both sequential and simultaneous moves, as well\nas private information. Because of the sequential nature and presence of\npartial information in the game, extensive-form correlation has significantly\ndifferent properties than the normal-form counterpart, many of which are still\nopen research directions. Extensive-form correlated equilibrium (EFCE) has been\nproposed as the natural extensive-form counterpart to normal-form correlated\nequilibrium. However, it was currently unknown whether EFCE emerges as the\nresult of uncoupled agent dynamics. In this paper, we give the first uncoupled\nno-regret dynamics that converge to the set of EFCEs in $n$-player general-sum\nextensive-form games with perfect recall. First, we introduce a notion of\ntrigger regret in extensive-form games, which extends that of internal regret\nin normal-form games. When each player has low trigger regret, the empirical\nfrequency of play is close to an EFCE. Then, we give an efficient\nno-trigger-regret algorithm. Our algorithm decomposes trigger regret into local\nsubproblems at each decision point for the player, and constructs a global\nstrategy of the player from the local solutions at each decision point.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:39:00 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 08:54:26 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 16:00:40 GMT"}, {"version": "v4", "created": "Sat, 20 Jun 2020 09:32:36 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Celli", "Andrea", ""], ["Marchesi", "Alberto", ""], ["Farina", "Gabriele", ""], ["Gatti", "Nicola", ""]]}, {"id": "2004.00605", "submitter": "Tomas Hodan", "authors": "Tomas Hodan, Daniel Barath, Jiri Matas", "title": "EPOS: Estimating 6D Pose of Objects with Symmetries", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for estimating the 6D pose of rigid objects with\navailable 3D models from a single RGB input image. The method is applicable to\na broad range of objects, including challenging ones with global or partial\nsymmetries. An object is represented by compact surface fragments which allow\nhandling symmetries in a systematic manner. Correspondences between densely\nsampled pixels and the fragments are predicted using an encoder-decoder\nnetwork. At each pixel, the network predicts: (i) the probability of each\nobject's presence, (ii) the probability of the fragments given the object's\npresence, and (iii) the precise 3D location on each fragment. A data-dependent\nnumber of corresponding 3D locations is selected per pixel, and poses of\npossibly multiple object instances are estimated using a robust and efficient\nvariant of the PnP-RANSAC algorithm. In the BOP Challenge 2019, the method\noutperforms all RGB and most RGB-D and D methods on the T-LESS and LM-O\ndatasets. On the YCB-V dataset, it is superior to all competitors, with a large\nmargin over the second-best RGB method. Source code is at:\ncmp.felk.cvut.cz/epos.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:41:08 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Hodan", "Tomas", ""], ["Barath", "Daniel", ""], ["Matas", "Jiri", ""]]}, {"id": "2004.00642", "submitter": "Paul Henderson", "authors": "Titas Anciukevicius, Christoph H. Lampert, Paul Henderson", "title": "Object-Centric Image Generation with Factored Depths, Locations, and\n  Appearances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model of images that explicitly reasons over the set\nof objects they show. Our model learns a structured latent representation that\nseparates objects from each other and from the background; unlike prior works,\nit explicitly represents the 2D position and depth of each object, as well as\nan embedding of its segmentation mask and appearance. The model can be trained\nfrom images alone in a purely unsupervised fashion without the need for object\nmasks or depth information. Moreover, it always generates complete objects,\neven though a significant fraction of training images contain occlusions.\nFinally, we show that our model can infer decompositions of novel images into\ntheir constituent objects, including accurate prediction of depth ordering and\nsegmentation of occluded parts.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:00:11 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Anciukevicius", "Titas", ""], ["Lampert", "Christoph H.", ""], ["Henderson", "Paul", ""]]}, {"id": "2004.00648", "submitter": "Ignatius Ezeani", "authors": "Ignatius Ezeani, Paul Rayson, Ikechukwu Onyenwe, Chinedu Uchechukwu,\n  Mark Hepple", "title": "Igbo-English Machine Translation: An Evaluation Benchmark", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Although researchers and practitioners are pushing the boundaries and\nenhancing the capacities of NLP tools and methods, works on African languages\nare lagging. A lot of focus on well resourced languages such as English,\nJapanese, German, French, Russian, Mandarin Chinese etc. Over 97% of the\nworld's 7000 languages, including African languages, are low resourced for NLP\ni.e. they have little or no data, tools, and techniques for NLP research. For\ninstance, only 5 out of 2965, 0.19% authors of full text papers in the ACL\nAnthology extracted from the 5 major conferences in 2018 ACL, NAACL, EMNLP,\nCOLING and CoNLL, are affiliated to African institutions. In this work, we\ndiscuss our effort toward building a standard machine translation benchmark\ndataset for Igbo, one of the 3 major Nigerian languages. Igbo is spoken by more\nthan 50 million people globally with over 50% of the speakers are in\nsoutheastern Nigeria. Igbo is low resourced although there have been some\nefforts toward developing IgboNLP such as part of speech tagging and diacritic\nrestoration\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:06:21 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Ezeani", "Ignatius", ""], ["Rayson", "Paul", ""], ["Onyenwe", "Ikechukwu", ""], ["Uchechukwu", "Chinedu", ""], ["Hepple", "Mark", ""]]}, {"id": "2004.00658", "submitter": "Lukas Pfannschmidt", "authors": "Lukas Pfannschmidt, Barbara Hammer", "title": "Sequential Feature Classification in the Context of Redundancies", "comments": "Added new experiment and footnote to reproducable results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of all-relevant feature selection is concerned with finding a\nrelevant feature set with preserved redundancies. There exist several\napproximations to solve this problem but only one could give a distinction\nbetween strong and weak relevance. This approach was limited to the case of\nlinear problems. In this work, we present a new solution for this distinction\nin the non-linear case through the use of random forest models and statistical\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:20:51 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 23:09:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Pfannschmidt", "Lukas", ""], ["Hammer", "Barbara", ""]]}, {"id": "2004.00663", "submitter": "Tolga Birdal", "authors": "Tolga Birdal, Michael Arbel, Umut \\c{S}im\\c{s}ekli, and Leonidas\n  Guibas", "title": "Synchronizing Probability Measures on Rotations via Optimal Transport", "comments": "Accepted for publication at CVPR 2020, includes supplementary\n  material. Project website: https://github.com/SynchInVision/probsync", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new paradigm, $\\textit{measure synchronization}$, for\nsynchronizing graphs with measure-valued edges. We formulate this problem as\nmaximization of the cycle-consistency in the space of probability measures over\nrelative rotations. In particular, we aim at estimating marginal distributions\nof absolute orientations by synchronizing the $\\textit{conditional}$ ones,\nwhich are defined on the Riemannian manifold of quaternions. Such graph\noptimization on distributions-on-manifolds enables a natural treatment of\nmultimodal hypotheses, ambiguities and uncertainties arising in many computer\nvision applications such as SLAM, SfM, and object pose estimation. We first\nformally define the problem as a generalization of the classical rotation graph\nsynchronization, where in our case the vertices denote probability measures\nover rotations. We then measure the quality of the synchronization by using\nSinkhorn divergences, which reduces to other popular metrics such as\nWasserstein distance or the maximum mean discrepancy as limit cases. We propose\na nonparametric Riemannian particle optimization approach to solve the problem.\nEven though the problem is non-convex, by drawing a connection to the recently\nproposed sparse optimization methods, we show that the proposed algorithm\nconverges to the global optimum in a special case of the problem under certain\nconditions. Our qualitative and quantitative experiments show the validity of\nour approach and we bring in new perspectives to the study of synchronization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:44:18 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Birdal", "Tolga", ""], ["Arbel", "Michael", ""], ["\u015eim\u015fekli", "Umut", ""], ["Guibas", "Leonidas", ""]]}, {"id": "2004.00666", "submitter": "Rohit Keshari", "authors": "Rohit Keshari, Richa Singh, Mayank Vatsa", "title": "Generalized Zero-Shot Learning Via Over-Complete Distribution", "comments": "9 pages, 5 figures, Accepted in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well trained and generalized deep neural network (DNN) should be robust to\nboth seen and unseen classes. However, the performance of most of the existing\nsupervised DNN algorithms degrade for classes which are unseen in the training\nset. To learn a discriminative classifier which yields good performance in\nZero-Shot Learning (ZSL) settings, we propose to generate an Over-Complete\nDistribution (OCD) using Conditional Variational Autoencoder (CVAE) of both\nseen and unseen classes. In order to enforce the separability between classes\nand reduce the class scatter, we propose the use of Online Batch Triplet Loss\n(OBTL) and Center Loss (CL) on the generated OCD. The effectiveness of the\nframework is evaluated using both Zero-Shot Learning and Generalized Zero-Shot\nLearning protocols on three publicly available benchmark databases, SUN, CUB\nand AWA2. The results show that generating over-complete distributions and\nenforcing the classifier to learn a transform function from overlapping to\nnon-overlapping distributions can improve the performance on both seen and\nunseen classes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 19:05:28 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Keshari", "Rohit", ""], ["Singh", "Richa", ""], ["Vatsa", "Mayank", ""]]}, {"id": "2004.00667", "submitter": "Gecheng Chen", "authors": "Gecheng Chen, Rui Tuo", "title": "Projection Pursuit Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary goal of computer experiments is to reconstruct the function given\nby the computer code via scattered evaluations. Traditional isotropic Gaussian\nprocess models suffer from the curse of dimensionality, when the input\ndimension is high. Gaussian process models with additive correlation functions\nare scalable to dimensionality, but they are very restrictive as they only work\nfor additive functions. In this work, we consider a projection pursuit model,\nin which the nonparametric part is driven by an additive Gaussian process\nregression. The dimension of the additive function is chosen to be higher than\nthe original input dimension. We show that this dimension expansion can help\napproximate more complex functions. A gradient descent algorithm is proposed to\nmaximize the likelihood function. Simulation studies show that the proposed\nmethod outperforms the traditional Gaussian process models.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 19:12:01 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Chen", "Gecheng", ""], ["Tuo", "Rui", ""]]}, {"id": "2004.00668", "submitter": "Ian Covert", "authors": "Ian Covert, Scott Lundberg, Su-In Lee", "title": "Understanding Global Feature Contributions With Additive Importance\n  Measures", "comments": "NeurIPS 2020 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the inner workings of complex machine learning models is a\nlong-standing problem and most recent research has focused on local\ninterpretability. To assess the role of individual input features in a global\nsense, we explore the perspective of defining feature importance through the\npredictive power associated with each feature. We introduce two notions of\npredictive power (model-based and universal) and formalize this approach with a\nframework of additive importance measures, which unifies numerous methods in\nthe literature. We then propose SAGE, a model-agnostic method that quantifies\npredictive power while accounting for feature interactions. Our experiments\nshow that SAGE can be calculated efficiently and that it assigns more accurate\nimportance values than other methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 19:17:58 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 06:46:04 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Covert", "Ian", ""], ["Lundberg", "Scott", ""], ["Lee", "Su-In", ""]]}, {"id": "2004.00686", "submitter": "Virginia Dignum", "authors": "Thomas Hellstr\\\"om, Virginia Dignum, Suna Bensch", "title": "Bias in Machine Learning -- What is it Good for?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In public media as well as in scientific publications, the term \\emph{bias}\nis used in conjunction with machine learning in many different contexts, and\nwith many different meanings. This paper proposes a taxonomy of these different\nmeanings, terminology, and definitions by surveying the, primarily scientific,\nliterature on machine learning. In some cases, we suggest extensions and\nmodifications to promote a clear terminology and completeness. The survey is\nfollowed by an analysis and discussion on how different types of biases are\nconnected and depend on each other. We conclude that there is a complex\nrelation between bias occurring in the machine learning pipeline that leads to\na model, and the eventual bias of the model (which is typically related to\nsocial discrimination). The former bias may or may not influence the latter, in\na sometimes bad, and sometime good way.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:00:20 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 12:41:03 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Hellstr\u00f6m", "Thomas", ""], ["Dignum", "Virginia", ""], ["Bensch", "Suna", ""]]}, {"id": "2004.00698", "submitter": "Erik Quintanilla", "authors": "Erik Quintanilla, Yogesh Rawat, Andrey Sakryukin, Mubarak Shah, Mohan\n  Kankanhalli", "title": "Adversarial Learning for Personalized Tag Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently seen great progress in image classification due to the\nsuccess of deep convolutional neural networks and the availability of\nlarge-scale datasets. Most of the existing work focuses on single-label image\nclassification. However, there are usually multiple tags associated with an\nimage. The existing works on multi-label classification are mainly based on lab\ncurated labels. Humans assign tags to their images differently, which is mainly\nbased on their interests and personal tagging behavior. In this paper, we\naddress the problem of personalized tag recommendation and propose an\nend-to-end deep network which can be trained on large-scale datasets. The\nuser-preference is learned within the network in an unsupervised way where the\nnetwork performs joint optimization for user-preference and visual encoding. A\njoint training of user-preference and visual encoding allows the network to\nefficiently integrate the visual preference with tagging behavior for a better\nuser recommendation. In addition, we propose the use of adversarial learning,\nwhich enforces the network to predict tags resembling user-generated tags. We\ndemonstrate the effectiveness of the proposed model on two different\nlarge-scale and publicly available datasets, YFCC100M and NUS-WIDE. The\nproposed method achieves significantly better performance on both the datasets\nwhen compared to the baselines and other state-of-the-art methods. The code is\npublicly available at https://github.com/vyzuer/ALTReco.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:41:41 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Quintanilla", "Erik", ""], ["Rawat", "Yogesh", ""], ["Sakryukin", "Andrey", ""], ["Shah", "Mubarak", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2004.00716", "submitter": "Ya-Yen Tsai", "authors": "Ya-Yen Tsai, Bo Xiao, Edward Johns, Guang-Zhong Yang", "title": "Constrained-Space Optimization and Reinforcement Learning for Complex\n  Tasks", "comments": "Accepted for publication in RA-Letters and at ICRA 2020", "journal-ref": "IEEE Robotics and Automation Letters, 5(2) (2020) 682-689", "doi": "10.1109/LRA.2020.2965392", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from Demonstration is increasingly used for transferring operator\nmanipulation skills to robots. In practice, it is important to cater for\nlimited data and imperfect human demonstrations, as well as underlying safety\nconstraints. This paper presents a constrained-space optimization and\nreinforcement learning scheme for managing complex tasks. Through interactions\nwithin the constrained space, the reinforcement learning agent is trained to\noptimize the manipulation skills according to a defined reward function. After\nlearning, the optimal policy is derived from the well-trained reinforcement\nlearning agent, which is then implemented to guide the robot to conduct tasks\nthat are similar to the experts' demonstrations. The effectiveness of the\nproposed method is verified with a robotic suturing task, demonstrating that\nthe learned policy outperformed the experts' demonstrations in terms of the\nsmoothness of the joint motion and end-effector trajectories, as well as the\noverall task completion time.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 21:50:11 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Tsai", "Ya-Yen", ""], ["Xiao", "Bo", ""], ["Johns", "Edward", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "2004.00719", "submitter": "Harbir Antil", "authors": "Harbir Antil, Ratna Khatri, Rainald L\\\"ohner, and Deepanshu Verma", "title": "Fractional Deep Neural Network via Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel algorithmic framework for a deep neural network\n(DNN), which in a mathematically rigorous manner, allows us to incorporate\nhistory (or memory) into the network -- it ensures all layers are connected to\none another. This DNN, called Fractional-DNN, can be viewed as a\ntime-discretization of a fractional in time nonlinear ordinary differential\nequation (ODE). The learning problem then is a minimization problem subject to\nthat fractional ODE as constraints. We emphasize that an analogy between the\nexisting DNN and ODEs, with standard time derivative, is well-known by now. The\nfocus of our work is the Fractional-DNN. Using the Lagrangian approach, we\nprovide a derivation of the backward propagation and the design equations. We\ntest our network on several datasets for classification problems.\nFractional-DNN offers various advantages over the existing DNN. The key\nbenefits are a significant improvement to the vanishing gradient issue due to\nthe memory effect, and better handling of nonsmooth data due to the network's\nability to approximate non-smooth functions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 21:58:21 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Antil", "Harbir", ""], ["Khatri", "Ratna", ""], ["L\u00f6hner", "Rainald", ""], ["Verma", "Deepanshu", ""]]}, {"id": "2004.00762", "submitter": "Michael Iuzzolino", "authors": "Michael L. Iuzzolino, Tetsumichi Umada, Nisar R. Ahmed, and Danielle\n  A. Szafir", "title": "In Automation We Trust: Investigating the Role of Uncertainty in Active\n  Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate how different active learning (AL) query policies coupled with\nclassification uncertainty visualizations affect analyst trust in automated\nclassification systems. A current standard policy for AL is to query the oracle\n(e.g., the analyst) to refine labels for datapoints where the classifier has\nthe highest uncertainty. This is an optimal policy for the automation system as\nit yields maximal information gain. However, model-centric policies neglect the\neffects of this uncertainty on the human component of the system and the\nconsequent manner in which the human will interact with the system\npost-training. In this paper, we present an empirical study evaluating how AL\nquery policies and visualizations lending transparency to classification\ninfluence trust in automated classification of image data. We found that query\npolicy significantly influences an analyst's trust in an image classification\nsystem, and we use these results to propose a set of oracle query policies and\nvisualizations for use during AL training phases that can influence analyst\ntrust in classification.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 00:52:49 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Iuzzolino", "Michael L.", ""], ["Umada", "Tetsumichi", ""], ["Ahmed", "Nisar R.", ""], ["Szafir", "Danielle A.", ""]]}, {"id": "2004.00773", "submitter": "Chuan Chen", "authors": "Yuzheng Li, Chuan Chen, Nan Liu, Huawei Huang, Zibin Zheng and Qiang\n  Yan", "title": "A Blockchain-based Decentralized Federated Learning Framework with\n  Committee Consensus", "comments": "7 pages, 4 figures and 1 table", "journal-ref": null, "doi": "10.1109/MNET.011.2000263", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has been widely studied and applied to various scenarios.\nIn mobile computing scenarios, federated learning protects users from exposing\ntheir private data, while cooperatively training the global model for a variety\nof real-world applications. However, the security of federated learning is\nincreasingly being questioned, due to the malicious clients or central servers'\nconstant attack to the global model or user privacy data. To address these\nsecurity issues, we proposed a decentralized federated learning framework based\non blockchain, i.e., a Blockchain-based Federated Learning framework with\nCommittee consensus (BFLC). The framework uses blockchain for the global model\nstorage and the local model update exchange. To enable the proposed BFLC, we\nalso devised an innovative committee consensus mechanism, which can effectively\nreduce the amount of consensus computing and reduce malicious attacks. We then\ndiscussed the scalability of BFLC, including theoretical security, storage\noptimization, and incentives. Finally, we performed experiments using\nreal-world datasets to verify the effectiveness of the BFLC framework.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:04:16 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Li", "Yuzheng", ""], ["Chen", "Chuan", ""], ["Liu", "Nan", ""], ["Huang", "Huawei", ""], ["Zheng", "Zibin", ""], ["Yan", "Qiang", ""]]}, {"id": "2004.00784", "submitter": "Xue Bin Peng", "authors": "Xue Bin Peng, Erwin Coumans, Tingnan Zhang, Tsang-Wei Lee, Jie Tan,\n  Sergey Levine", "title": "Learning Agile Robotic Locomotion Skills by Imitating Animals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reproducing the diverse and agile locomotion skills of animals has been a\nlongstanding challenge in robotics. While manually-designed controllers have\nbeen able to emulate many complex behaviors, building such controllers involves\na time-consuming and difficult development process, often requiring substantial\nexpertise of the nuances of each skill. Reinforcement learning provides an\nappealing alternative for automating the manual effort involved in the\ndevelopment of controllers. However, designing learning objectives that elicit\nthe desired behaviors from an agent can also require a great deal of\nskill-specific expertise. In this work, we present an imitation learning system\nthat enables legged robots to learn agile locomotion skills by imitating\nreal-world animals. We show that by leveraging reference motion data, a single\nlearning-based approach is able to automatically synthesize controllers for a\ndiverse repertoire behaviors for legged robots. By incorporating sample\nefficient domain adaptation techniques into the training process, our system is\nable to learn adaptive policies in simulation that can then be quickly adapted\nfor real-world deployment. To demonstrate the effectiveness of our system, we\ntrain an 18-DoF quadruped robot to perform a variety of agile behaviors ranging\nfrom different locomotion gaits to dynamic hops and turns.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:56:16 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 23:45:02 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 00:59:24 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Peng", "Xue Bin", ""], ["Coumans", "Erwin", ""], ["Zhang", "Tingnan", ""], ["Lee", "Tsang-Wei", ""], ["Tan", "Jie", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.00794", "submitter": "Zhonghao Wang", "authors": "Zhonghao Wang, Yunchao Wei, Rogerior Feris, Jinjun Xiong, Wen-Mei Hwu,\n  Thomas S. Huang, Humphrey Shi", "title": "Alleviating Semantic-level Shift: A Semi-supervised Domain Adaptation\n  Method for Semantic Segmentation", "comments": "CVPRW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning segmentation from synthetic data and adapting to real data can\nsignificantly relieve human efforts in labelling pixel-level masks. A key\nchallenge of this task is how to alleviate the data distribution discrepancy\nbetween the source and target domains, i.e. reducing domain shift. The common\napproach to this problem is to minimize the discrepancy between feature\ndistributions from different domains through adversarial training. However,\ndirectly aligning the feature distribution globally cannot guarantee\nconsistency from a local view (i.e. semantic-level), which prevents certain\nsemantic knowledge learned on the source domain from being applied to the\ntarget domain. To tackle this issue, we propose a semi-supervised approach\nnamed Alleviating Semantic-level Shift (ASS), which can successfully promote\nthe distribution consistency from both global and local views. Specifically,\nleveraging a small number of labeled data from the target domain, we directly\nextract semantic-level feature representations from both the source and the\ntarget domains by averaging the features corresponding to same categories\nadvised by pixel-level masks. We then feed the produced features to the\ndiscriminator to conduct semantic-level adversarial learning, which\ncollaborates with the adversarial learning from the global view to better\nalleviate the domain shift. We apply our ASS to two domain adaptation tasks,\nfrom GTA5 to Cityscapes and from Synthia to Cityscapes. Extensive experiments\ndemonstrate that: (1) ASS can significantly outperform the current unsupervised\nstate-of-the-arts by employing a small number of annotated samples from the\ntarget domain; (2) ASS can beat the oracle model trained on the whole target\ndataset by over 3 points by augmenting the synthetic source data with annotated\nsamples from the target domain without suffering from the prevalent problem of\noverfitting to the source domain.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 03:25:05 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:38:27 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wang", "Zhonghao", ""], ["Wei", "Yunchao", ""], ["Feris", "Rogerior", ""], ["Xiong", "Jinjun", ""], ["Hwu", "Wen-Mei", ""], ["Huang", "Thomas S.", ""], ["Shi", "Humphrey", ""]]}, {"id": "2004.00801", "submitter": "Riku Arakawa", "authors": "Riku Arakawa and Shintaro Shiba", "title": "Exploration of Reinforcement Learning for Event Camera using Car-like\n  Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the first reinforcement-learning application for robots\nequipped with an event camera. Because of the considerably lower latency of the\nevent camera, it is possible to achieve much faster control of robots compared\nwith the existing vision-based reinforcement-learning applications using\nstandard cameras. To handle a stream of events for reinforcement learning, we\nintroduced an image-like feature and demonstrated the feasibility of training\nan agent in a simulator for two tasks: fast collision avoidance and obstacle\ntracking. Finally, we set up a robot with an event camera in the real world and\nthen transferred the agent trained in the simulator, resulting in successful\nfast avoidance of randomly thrown objects. Incorporating event camera into\nreinforcement learning opens new possibilities for various robotics\napplications that require swift control, such as autonomous vehicles and\ndrones, through end-to-end learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 03:52:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Arakawa", "Riku", ""], ["Shiba", "Shintaro", ""]]}, {"id": "2004.00817", "submitter": "Tai Vu", "authors": "Tai Vu", "title": "Combating The Machine Ethics Crisis: An Educational Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the availability of massive data sets and improved computing\npower have driven the advent of cutting-edge machine learning algorithms.\nHowever, this trend has triggered growing concerns associated with its ethical\nissues. In response to such a phenomenon, this study proposes a feasible\nsolution that combines ethics and computer science materials in artificial\nintelligent classrooms. In addition, the paper presents several arguments and\nevidence in favor of the necessity and effectiveness of this integrated\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 05:04:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Vu", "Tai", ""]]}, {"id": "2004.00843", "submitter": "Marija Vella", "authors": "Marija Vella and Jo\\~ao F. C. Mota", "title": "Robust Single-Image Super-Resolution via CNNs and TV-TV Minimization", "comments": "Under peer review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-image super-resolution is the process of increasing the resolution of\nan image, obtaining a high-resolution (HR) image from a low-resolution (LR)\none. By leveraging large training datasets, convolutional neural networks\n(CNNs) currently achieve the state-of-the-art performance in this task. Yet,\nduring testing/deployment, they fail to enforce consistency between the HR and\nLR images: if we downsample the output HR image, it never matches its LR input.\nBased on this observation, we propose to post-process the CNN outputs with an\noptimization problem that we call TV-TV minimization, which enforces\nconsistency. As our extensive experiments show, such post-processing not only\nimproves the quality of the images, in terms of PSNR and SSIM, but also makes\nthe super-resolution task robust to operator mismatch, i.e., when the true\ndownsampling operator is different from the one used to create the training\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 07:06:55 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Vella", "Marija", ""], ["Mota", "Jo\u00e3o F. C.", ""]]}, {"id": "2004.00849", "submitter": "Bei Liu", "authors": "Zhicheng Huang, Zhaoyang Zeng, Bei Liu, Dongmei Fu, Jianlong Fu", "title": "Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal\n  Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Pixel-BERT to align image pixels with text by deep multi-modal\ntransformers that jointly learn visual and language embedding in a unified\nend-to-end framework. We aim to build a more accurate and thorough connection\nbetween image pixels and language semantics directly from image and sentence\npairs instead of using region-based image features as the most recent vision\nand language tasks. Our Pixel-BERT which aligns semantic connection in pixel\nand text level solves the limitation of task-specific visual representation for\nvision and language tasks. It also relieves the cost of bounding box\nannotations and overcomes the unbalance between semantic labels in visual task\nand language semantic. To provide a better representation for down-stream\ntasks, we pre-train a universal end-to-end model with image and sentence pairs\nfrom Visual Genome dataset and MS-COCO dataset. We propose to use a random\npixel sampling mechanism to enhance the robustness of visual representation and\nto apply the Masked Language Model and Image-Text Matching as pre-training\ntasks. Extensive experiments on downstream tasks with our pre-trained model\nshow that our approach makes the most state-of-the-arts in downstream tasks,\nincluding Visual Question Answering (VQA), image-text retrieval, Natural\nLanguage for Visual Reasoning for Real (NLVR). Particularly, we boost the\nperformance of a single model in VQA task by 2.17 points compared with SOTA\nunder fair comparison.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 07:39:28 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 09:09:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Huang", "Zhicheng", ""], ["Zeng", "Zhaoyang", ""], ["Liu", "Bei", ""], ["Fu", "Dongmei", ""], ["Fu", "Jianlong", ""]]}, {"id": "2004.00857", "submitter": "Manuel Schneckenreither", "authors": "Manuel Schneckenreither", "title": "Average Reward Adjusted Discounted Reinforcement Learning:\n  Near-Blackwell-Optimal Policies for Real-World Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although in recent years reinforcement learning has become very popular the\nnumber of successful applications to different kinds of operations research\nproblems is rather scarce. Reinforcement learning is based on the well-studied\ndynamic programming technique and thus also aims at finding the best stationary\npolicy for a given Markov Decision Process, but in contrast does not require\nany model knowledge. The policy is assessed solely on consecutive states (or\nstate-action pairs), which are observed while an agent explores the solution\nspace. The contributions of this paper are manifold. First we provide deep\ntheoretical insights to the widely applied standard discounted reinforcement\nlearning framework, which give rise to the understanding of why these\nalgorithms are inappropriate when permanently provided with non-zero rewards,\nsuch as costs or profit. Second, we establish a novel near-Blackwell-optimal\nreinforcement learning algorithm. In contrary to former method it assesses the\naverage reward per step separately and thus prevents the incautious combination\nof different types of state values. Thereby, the Laurent Series expansion of\nthe discounted state values forms the foundation for this development and also\nprovides the connection between the two approaches. Finally, we prove the\nviability of our algorithm on a challenging problem set, which includes a\nwell-studied M/M/1 admission control queuing system. In contrast to standard\ndiscounted reinforcement learning our algorithm infers the optimal policy on\nall tested problems. The insights are that in the operations research domain\nmachine learning techniques have to be adapted and advanced to successfully\napply these methods in our settings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:05:18 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Schneckenreither", "Manuel", ""]]}, {"id": "2004.00879", "submitter": "Yimin Fan", "authors": "Yimin Fan, Zhiyuan Wang, Yuanpeng Lin, Haisheng Tan", "title": "Enhance the performance of navigation: A two-stage machine learning\n  approach", "comments": "8 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real time traffic navigation is an important capability in smart\ntransportation technologies, which has been extensively studied these years.\nDue to the vast development of edge devices, collecting real time traffic data\nis no longer a problem. However, real traffic navigation is still considered to\nbe a particularly challenging problem because of the time-varying patterns of\nthe traffic flow and unpredictable accidents/congestion. To give accurate and\nreliable navigation results, predicting the future traffic\nflow(speed,congestion,volume,etc) in a fast and accurate way is of great\nimportance. In this paper, we adopt the ideas of ensemble learning and develop\na two-stage machine learning model to give accurate navigation results. We\nmodel the traffic flow as a time series and apply XGBoost algorithm to get\naccurate predictions on future traffic conditions(1st stage). We then apply the\nTop K Dijkstra algorithm to find a set of shortest paths from the give start\npoint to the destination as the candidates of the output optimal path. With the\nprediction results in the 1st stage, we find one optimal path from the\ncandidates as the output of the navigation algorithm. We show that our\nnavigation algorithm can be greatly improved via EOPF(Enhanced Optimal Path\nFinding), which is based on neural network(2nd stage). We show that our method\ncan be over 7% better than the method without EOPF in many situations, which\nindicates the effectiveness of our model.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:55:27 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Fan", "Yimin", ""], ["Wang", "Zhiyuan", ""], ["Lin", "Yuanpeng", ""], ["Tan", "Haisheng", ""]]}, {"id": "2004.00891", "submitter": "Mattes Mollenhauer", "authors": "Mattes Mollenhauer, Stefan Klus, Christof Sch\\\"utte, P\\'eter Koltai", "title": "Kernel autocovariance operators of stationary processes: Estimation and\n  convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider autocovariance operators of a stationary stochastic process on a\nPolish space that is embedded into a reproducing kernel Hilbert space. We\ninvestigate how empirical estimates of these operators converge along\nrealizations of the process under various conditions. In particular, we examine\nergodic and strongly mixing processes and prove several asymptotic results as\nwell as finite sample error bounds with a detailed analysis for the Gaussian\nkernel. We provide applications of our theory in terms of consistency results\nfor kernel PCA with dependent data and the conditional mean embedding of\ntransition probabilities. Finally, we use our approach to examine the\nnonparametric estimation of Markov transition operators and highlight how our\ntheory can give a consistency analysis for a large family of spectral analysis\nmethods including kernel-based dynamic mode decomposition.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 09:17:32 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Mollenhauer", "Mattes", ""], ["Klus", "Stefan", ""], ["Sch\u00fctte", "Christof", ""], ["Koltai", "P\u00e9ter", ""]]}, {"id": "2004.00909", "submitter": "Ankit Dhall", "authors": "Ankit Dhall", "title": "Learning Representations For Images With Hierarchical Labels", "comments": "Master thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has been studied extensively but there has been limited\nwork in the direction of using non-conventional, external guidance other than\ntraditional image-label pairs to train such models. In this thesis we present a\nset of methods to leverage information about the semantic hierarchy induced by\nclass labels. In the first part of the thesis, we inject label-hierarchy\nknowledge to an arbitrary classifier and empirically show that availability of\nsuch external semantic information in conjunction with the visual semantics\nfrom images boosts overall performance. Taking a step further in this\ndirection, we model more explicitly the label-label and label-image\ninteractions by using order-preserving embedding-based models, prevalent in\nnatural language, and tailor them to the domain of computer vision to perform\nimage classification. Although, contrasting in nature, both the CNN-classifiers\ninjected with hierarchical information, and the embedding-based models\noutperform a hierarchy-agnostic model on the newly presented, real-world ETH\nEntomological Collection image dataset\nhttps://www.research-collection.ethz.ch/handle/20.500.11850/365379.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 09:56:03 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 17:51:39 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dhall", "Ankit", ""]]}, {"id": "2004.00910", "submitter": "Ali Aroudi", "authors": "Ali Aroudi, Tobias de Taillez, and Simon Doclo", "title": "Improving auditory attention decoding performance of linear and\n  non-linear methods using state-space model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the target speaker in hearing aid applications is crucial to\nimprove speech understanding. Recent advances in electroencephalography (EEG)\nhave shown that it is possible to identify the target speaker from single-trial\nEEG recordings using auditory attention decoding (AAD) methods. AAD methods\nreconstruct the attended speech envelope from EEG recordings, based on a linear\nleast-squares cost function or non-linear neural networks, and then directly\ncompare the reconstructed envelope with the speech envelopes of speakers to\nidentify the attended speaker using Pearson correlation coefficients. Since\nthese correlation coefficients are highly fluctuating, for a reliable decoding\na large correlation window is used, which causes a large processing delay. In\nthis paper, we investigate a state-space model using correlation coefficients\nobtained with a small correlation window to improve the decoding performance of\nthe linear and the non-linear AAD methods. The experimental results show that\nthe state-space model significantly improves the decoding performance.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 09:56:06 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Aroudi", "Ali", ""], ["de Taillez", "Tobias", ""], ["Doclo", "Simon", ""]]}, {"id": "2004.00915", "submitter": "Sebastien Gros Prof.", "authors": "Sebastien Gros, Mario Zanon, Alberto Bemporad", "title": "Safe Reinforcement Learning via Projection on a Safe Set: How to Achieve\n  Optimality?", "comments": "Accepted at IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For all its successes, Reinforcement Learning (RL) still struggles to deliver\nformal guarantees on the closed-loop behavior of the learned policy. Among\nother things, guaranteeing the safety of RL with respect to safety-critical\nsystems is a very active research topic. Some recent contributions propose to\nrely on projections of the inputs delivered by the learned policy into a safe\nset, ensuring that the system safety is never jeopardized. Unfortunately, it is\nunclear whether this operation can be performed without disrupting the learning\nprocess. This paper addresses this issue. The problem is analysed in the\ncontext of $Q$-learning and policy gradient techniques. We show that the\nprojection approach is generally disruptive in the context of $Q$-learning\nthough a simple alternative solves the issue, while simple corrections can be\nused in the context of policy gradient methods in order to ensure that the\npolicy gradients are unbiased. The proposed results extend to safe projections\nbased on robust MPC techniques.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:11:30 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gros", "Sebastien", ""], ["Zanon", "Mario", ""], ["Bemporad", "Alberto", ""]]}, {"id": "2004.00917", "submitter": "Lei Huang", "authors": "Lei Huang, Li Liu, Fan Zhu, Diwen Wan, Zehuan Yuan, Bo Li, Ling Shao", "title": "Controllable Orthogonalization in Training DNNs", "comments": "Accepted to CVPR 2020. The Code is available at\n  https://github.com/huangleiBuaa/ONI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orthogonality is widely used for training deep neural networks (DNNs) due to\nits ability to maintain all singular values of the Jacobian close to 1 and\nreduce redundancy in representation. This paper proposes a computationally\nefficient and numerically stable orthogonalization method using Newton's\niteration (ONI), to learn a layer-wise orthogonal weight matrix in DNNs. ONI\nworks by iteratively stretching the singular values of a weight matrix towards\n1. This property enables it to control the orthogonality of a weight matrix by\nits number of iterations. We show that our method improves the performance of\nimage classification networks by effectively controlling the orthogonality to\nprovide an optimal tradeoff between optimization benefits and representational\ncapacity reduction. We also show that ONI stabilizes the training of generative\nadversarial networks (GANs) by maintaining the Lipschitz continuity of a\nnetwork, similar to spectral normalization (SN), and further outperforms SN by\nproviding controllable orthogonality.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:14:27 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Huang", "Lei", ""], ["Liu", "Li", ""], ["Zhu", "Fan", ""], ["Wan", "Diwen", ""], ["Yuan", "Zehuan", ""], ["Li", "Bo", ""], ["Shao", "Ling", ""]]}, {"id": "2004.00930", "submitter": "Dimitrije Markovic", "authors": "Sascha Fr\\\"olich, Dimitrije Markovi\\'c, and Stefan J. Kiebel", "title": "Neuronal Sequence Models for Bayesian Online Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sequential neuronal activity underlies a wide range of processes in the\nbrain. Neuroscientific evidence for neuronal sequences has been reported in\ndomains as diverse as perception, motor control, speech, spatial navigation and\nmemory. Consequently, different dynamical principles have been proposed as\npossible sequence-generating mechanisms. Combining experimental findings with\ncomputational concepts like the Bayesian brain hypothesis and predictive coding\nleads to the interesting possibility that predictive and inferential processes\nin the brain are grounded on generative processes which maintain a sequential\nstructure. While probabilistic inference about ongoing sequences is a useful\ncomputational model for both the analysis of neuroscientific data and a wide\nrange of problems in artificial recognition and motor control, research on the\nsubject is relatively scarce and distributed over different fields in the\nneurosciences. Here we review key findings about neuronal sequences and relate\nthese to the concept of online inference on sequences as a model of\nsensory-motor processing and recognition. We propose that describing sequential\nneuronal activity as an expression of probabilistic inference over sequences\nmay lead to novel perspectives on brain function. Importantly, it is promising\nto translate the key idea of probabilistic inference on sequences to machine\nlearning, in order to address challenges in the real-time recognition of speech\nand human motion.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:52:54 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Fr\u00f6lich", "Sascha", ""], ["Markovi\u0107", "Dimitrije", ""], ["Kiebel", "Stefan J.", ""]]}, {"id": "2004.00935", "submitter": "Avi Segal", "authors": "Laura Schelenz, Avi Segal, and Kobi Gal", "title": "Applying Transparency in Artificial Intelligence based Personalization\n  Systems", "comments": "8 pages; For ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence based systems increasingly use personalization to\nprovide users with relevant content, products, and solutions. Personalization\nis intended to support users and address their respective needs and\npreferences. However, users are becoming increasingly vulnerable to online\nmanipulation due to algorithmic advancements and lack of transparency. Such\nmanipulation decreases users' levels of trust, autonomy, and satisfaction\nconcerning the systems with which they interact. Increasing transparency is an\nimportant goal for personalization based systems. Unfortunately, system\ndesigners lack guidance in assessing and implementing transparency in their\ndeveloped systems.\n  In this work we combine insights from technology ethics and computer science\nto generate a list of transparency best practices for machine generated\npersonalization. Based on these best practices, we develop a checklist to be\nused by designers wishing to evaluate and increase the transparency of their\nalgorithmic systems. Adopting a designer perspective, we apply the checklist to\nprominent online services and discuss its advantages and shortcomings. We\nencourage researchers to adopt the checklist in various environments and to\nwork towards a consensus-based tool for measuring transparency in the\npersonalization community.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 11:07:38 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 13:49:54 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Schelenz", "Laura", ""], ["Segal", "Avi", ""], ["Gal", "Kobi", ""]]}, {"id": "2004.00945", "submitter": "Yong-Lu Li", "authors": "Yong-Lu Li, Liang Xu, Xinpeng Liu, Xijie Huang, Yue Xu, Shiyi Wang,\n  Hao-Shu Fang, Ze Ma, Mingyang Chen, Cewu Lu", "title": "PaStaNet: Toward Human Activity Knowledge Engine", "comments": "Accepted to CVPR 2020, supplementary materials included, code\n  available: http://hake-mvig.cn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing image-based activity understanding methods mainly adopt direct\nmapping, i.e. from image to activity concepts, which may encounter performance\nbottleneck since the huge gap. In light of this, we propose a new path: infer\nhuman part states first and then reason out the activities based on part-level\nsemantics. Human Body Part States (PaSta) are fine-grained action semantic\ntokens, e.g. <hand, hold, something>, which can compose the activities and help\nus step toward human activity knowledge engine. To fully utilize the power of\nPaSta, we build a large-scale knowledge base PaStaNet, which contains 7M+ PaSta\nannotations. And two corresponding models are proposed: first, we design a\nmodel named Activity2Vec to extract PaSta features, which aim to be general\nrepresentations for various activities. Second, we use a PaSta-based Reasoning\nmethod to infer activities. Promoted by PaStaNet, our method achieves\nsignificant improvements, e.g. 6.4 and 13.9 mAP on full and one-shot sets of\nHICO in supervised learning, and 3.2 and 4.2 mAP on V-COCO and images-based AVA\nin transfer learning. Code and data are available at http://hake-mvig.cn/.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 11:35:59 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 11:55:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Yong-Lu", ""], ["Xu", "Liang", ""], ["Liu", "Xinpeng", ""], ["Huang", "Xijie", ""], ["Xu", "Yue", ""], ["Wang", "Shiyi", ""], ["Fang", "Hao-Shu", ""], ["Ma", "Ze", ""], ["Chen", "Mingyang", ""], ["Lu", "Cewu", ""]]}, {"id": "2004.00959", "submitter": "Arif Ahmed Sekh Dr", "authors": "Ratnabali Pal, Arif Ahmed Sekh, Samarjit Kar, Dilip K. Prasad", "title": "Neural network based country wise risk prediction of COVID-19", "comments": null, "journal-ref": "Applied Sciences, 2020", "doi": "10.3390/app10186448", "report-no": null, "categories": "q-bio.PE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent worldwide outbreak of the novel coronavirus (COVID-19) has opened\nup new challenges to the research community. Artificial intelligence (AI)\ndriven methods can be useful to predict the parameters, risks, and effects of\nsuch an epidemic. Such predictions can be helpful to control and prevent the\nspread of such diseases. The main challenges of applying AI is the small volume\nof data and the uncertain nature. Here, we propose a shallow long short-term\nmemory (LSTM) based neural network to predict the risk category of a country.\nWe have used a Bayesian optimization framework to optimize and automatically\ndesign country-specific networks. The results show that the proposed pipeline\noutperforms state-of-the-art methods for data of 180 countries and can be a\nuseful tool for such risk categorization. We have also experimented with the\ntrend data and weather data combined for the prediction. The outcome shows that\nthe weather does not have a significant role. The tool can be used to predict\nlong-duration outbreak of such an epidemic such that we can take preventive\nsteps earlier\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:03:10 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 15:16:15 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Pal", "Ratnabali", ""], ["Sekh", "Arif Ahmed", ""], ["Kar", "Samarjit", ""], ["Prasad", "Dilip K.", ""]]}, {"id": "2004.00974", "submitter": "Sourya Dey", "authors": "Sourya Dey, Saikrishna C. Kanala, Keith M. Chugg, Peter A. Beerel", "title": "Deep-n-Cheap: An Automated Search Framework for Low Complexity Deep\n  Learning", "comments": "Accepted as a conference paper at ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Deep-n-Cheap -- an open-source AutoML framework to search for deep\nlearning models. This search includes both architecture and training\nhyperparameters, and supports convolutional neural networks and multi-layer\nperceptrons. Our framework is targeted for deployment on both benchmark and\ncustom datasets, and as a result, offers a greater degree of search space\ncustomizability as compared to a more limited search over only pre-existing\nmodels from literature. We also introduce the technique of 'search transfer',\nwhich demonstrates the generalization capabilities of the models found by our\nframework to multiple datasets.\n  Deep-n-Cheap includes a user-customizable complexity penalty which trades off\nperformance with training time or number of parameters. Specifically, our\nframework results in models offering performance comparable to state-of-the-art\nwhile taking 1-2 orders of magnitude less time to train than models from other\nAutoML and model search frameworks. Additionally, this work investigates and\ndevelops various insights regarding the search process. In particular, we show\nthe superiority of a greedy strategy and justify our choice of Bayesian\noptimization as the primary search methodology over random / grid search.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 13:00:21 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 01:29:44 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 21:24:04 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Dey", "Sourya", ""], ["Kanala", "Saikrishna C.", ""], ["Chugg", "Keith M.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2004.00979", "submitter": "G\\\"unter Klambauer", "authors": "Markus Hofmarcher, Andreas Mayr, Elisabeth Rumetshofer, Peter Ruch,\n  Philipp Renz, Johannes Schimunek, Philipp Seidl, Andreu Vall, Michael\n  Widrich, Sepp Hochreiter, G\\\"unter Klambauer", "title": "Large-scale ligand-based virtual screening for SARS-CoV-2 inhibitors\n  using deep neural networks", "comments": "Additional results added. Various corrections to formulations and\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the current severe acute respiratory syndrome coronavirus 2\n(SARS-CoV-2) pandemic, there is an urgent need for novel therapies and drugs.\nWe conducted a large-scale virtual screening for small molecules that are\npotential CoV-2 inhibitors. To this end, we utilized \"ChemAI\", a deep neural\nnetwork trained on more than 220M data points across 3.6M molecules from three\npublic drug-discovery databases. With ChemAI, we screened and ranked one\nbillion molecules from the ZINC database for favourable effects against CoV-2.\nWe then reduced the result to the 30,000 top-ranked compounds, which are\nreadily accessible and purchasable via the ZINC database. Additionally, we\nscreened the DrugBank using ChemAI to allow for drug repurposing, which would\nbe a fast way towards a therapy. We provide these top-ranked compounds of ZINC\nand DrugBank as a library for further screening with bioassays at\nhttps://github.com/ml-jku/sars-cov-inhibitors-chemai.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:24:09 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 09:10:24 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 15:58:09 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hofmarcher", "Markus", ""], ["Mayr", "Andreas", ""], ["Rumetshofer", "Elisabeth", ""], ["Ruch", "Peter", ""], ["Renz", "Philipp", ""], ["Schimunek", "Johannes", ""], ["Seidl", "Philipp", ""], ["Vall", "Andreu", ""], ["Widrich", "Michael", ""], ["Hochreiter", "Sepp", ""], ["Klambauer", "G\u00fcnter", ""]]}, {"id": "2004.00993", "submitter": "Xiao Lei Zhang", "authors": "Xiao Lei Zhang, Anish Agarwal", "title": "Augmented Q Imitation Learning (AQIL)", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study of unsupervised learning can be generally divided into two\ncategories: imitation learning and reinforcement learning. In imitation\nlearning the machine learns by mimicking the behavior of an expert system\nwhereas in reinforcement learning the machine learns via direct environment\nfeedback. Traditional deep reinforcement learning takes a significant time\nbefore the machine starts to converge to an optimal policy. This paper proposes\nAugmented Q-Imitation-Learning, a method by which deep reinforcement learning\nconvergence can be accelerated by applying Q-imitation-learning as the initial\ntraining process in traditional Deep Q-learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:08:23 GMT"}, {"version": "v2", "created": "Sun, 5 Apr 2020 17:16:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Xiao Lei", ""], ["Agarwal", "Anish", ""]]}, {"id": "2004.00994", "submitter": "Uri Shaham", "authors": "Uri Shaham, Tom Zahavy, Cesar Caraballo, Shiwani Mahajan, Daisy\n  Massey, Harlan Krumholz", "title": "Learning to Ask Medical Questions using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning-based approach for adaptive and\niterative feature selection. Given a masked vector of input features, a\nreinforcement learning agent iteratively selects certain features to be\nunmasked, and uses them to predict an outcome when it is sufficiently\nconfident. The algorithm makes use of a novel environment setting,\ncorresponding to a non-stationary Markov Decision Process. A key component of\nour approach is a guesser network, trained to predict the outcome from the\nselected features and parametrizing the reward function. Applying our method to\na national survey dataset, we show that it not only outperforms strong\nbaselines when requiring the prediction to be made based on a small number of\ninput features, but is also highly more interpretable. Our code is publicly\navailable at \\url{https://github.com/ushaham/adaptiveFS}.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:21:46 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 08:13:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Shaham", "Uri", ""], ["Zahavy", "Tom", ""], ["Caraballo", "Cesar", ""], ["Mahajan", "Shiwani", ""], ["Massey", "Daisy", ""], ["Krumholz", "Harlan", ""]]}, {"id": "2004.00998", "submitter": "Vivek Gupta", "authors": "Vivek Gupta", "title": "DeepSumm -- Deep Code Summaries using Neural Transformer Architecture", "comments": "arXiv admin note: substantial text overlap with arXiv:1902.01954 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source code summarizing is a task of writing short, natural language\ndescriptions of source code behavior during run time. Such summaries are\nextremely useful for software development and maintenance but are expensive to\nmanually author,hence it is done for small fraction of the code that is\nproduced and is often ignored. Automatic code documentation can possibly solve\nthis at a low cost. This is thus an emerging research field with further\napplications to program comprehension, and software maintenance. Traditional\nmethods often relied on cognitive models that were built in the form of\ntemplates and by heuristics and had varying degree of adoption by the developer\ncommunity. But with recent advancements, end to end data-driven approaches\nbased on neural techniques have largely overtaken the traditional techniques.\nMuch of the current landscape employs neural translation based architectures\nwith recurrence and attention which is resource and time intensive training\nprocedure. In this paper, we employ neural techniques to solve the task of\nsource code summarizing and specifically compare NMT based techniques to more\nsimplified and appealing Transformer architecture on a dataset of Java methods\nand comments. We bring forth an argument to dispense the need of recurrence in\nthe training procedure. To the best of our knowledge, transformer based models\nhave not been used for the task before. With supervised samples of more than\n2.1m comments and code, we reduce the training time by more than 50% and\nachieve the BLEU score of 17.99 for the test set of examples.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:43:29 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gupta", "Vivek", ""]]}, {"id": "2004.00999", "submitter": "Fangzhou Xie", "authors": "Fangzhou Xie", "title": "Pruned Wasserstein Index Generation Model and wigpy Package", "comments": "fix typos and errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent proposal of Wasserstein Index Generation model (WIG) has shown a new\ndirection for automatically generating indices. However, it is challenging in\npractice to fit large datasets for two reasons. First, the Sinkhorn distance is\nnotoriously expensive to compute and suffers from dimensionality severely.\nSecond, it requires to compute a full $N\\times N$ matrix to be fit into memory,\nwhere $N$ is the dimension of vocabulary. When the dimensionality is too large,\nit is even impossible to compute at all. I hereby propose a Lasso-based\nshrinkage method to reduce dimensionality for the vocabulary as a\npre-processing step prior to fitting the WIG model. After we get the word\nembedding from Word2Vec model, we could cluster these high-dimensional vectors\nby $k$-means clustering, and pick most frequent tokens within each cluster to\nform the \"base vocabulary\". Non-base tokens are then regressed on the vectors\nof base token to get a transformation weight and we could thus represent the\nwhole vocabulary by only the \"base tokens\". This variant, called pruned WIG\n(pWIG), will enable us to shrink vocabulary dimension at will but could still\nachieve high accuracy. I also provide a \\textit{wigpy} module in Python to\ncarry out computation in both flavor. Application to Economic Policy\nUncertainty (EPU) index is showcased as comparison with existing methods of\ngenerating time-series sentiment indices.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:26:24 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 00:27:02 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 14:42:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Xie", "Fangzhou", ""]]}, {"id": "2004.01022", "submitter": "Adarsh Barik", "authors": "Adarsh Barik, Jean Honorio", "title": "Provable Sample Complexity Guarantees for Learning of Continuous-Action\n  Graphical Games with Nonparametric Utilities", "comments": "arXiv admin note: text overlap with arXiv:1911.04225", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of learning the exact structure of\ncontinuous-action games with non-parametric utility functions. We propose an\n$\\ell_1$ regularized method which encourages sparsity of the coefficients of\nthe Fourier transform of the recovered utilities. Our method works by accessing\nvery few Nash equilibria and their noisy utilities. Under certain technical\nconditions, our method also recovers the exact structure of these utility\nfunctions, and thus, the exact structure of the game. Furthermore, our method\nonly needs a logarithmic number of samples in terms of the number of players\nand runs in polynomial time. We follow the primal-dual witness framework to\nprovide provable theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:32:27 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Barik", "Adarsh", ""], ["Honorio", "Jean", ""]]}, {"id": "2004.01024", "submitter": "Hansheng Xue", "authors": "Hansheng Xue, Luwei Yang, Wen Jiang, Yi Wei, Yi Hu, and Yu Lin", "title": "Modeling Dynamic Heterogeneous Network for Link Prediction using\n  Hierarchical Attention with Temporal RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding aims to learn low-dimensional representations of nodes\nwhile capturing structure information of networks. It has achieved great\nsuccess on many tasks of network analysis such as link prediction and node\nclassification. Most of existing network embedding algorithms focus on how to\nlearn static homogeneous networks effectively. However, networks in the real\nworld are more complex, e.g., networks may consist of several types of nodes\nand edges (called heterogeneous information) and may vary over time in terms of\ndynamic nodes and edges (called evolutionary patterns). Limited work has been\ndone for network embedding of dynamic heterogeneous networks as it is\nchallenging to learn both evolutionary and heterogeneous information\nsimultaneously. In this paper, we propose a novel dynamic heterogeneous network\nembedding method, termed as DyHATR, which uses hierarchical attention to learn\nheterogeneous information and incorporates recurrent neural networks with\ntemporal attention to capture evolutionary patterns. We benchmark our method on\nfour real-world datasets for the task of link prediction. Experimental results\nshow that DyHATR significantly outperforms several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 17:16:47 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Xue", "Hansheng", ""], ["Yang", "Luwei", ""], ["Jiang", "Wen", ""], ["Wei", "Yi", ""], ["Hu", "Yi", ""], ["Lin", "Yu", ""]]}, {"id": "2004.01025", "submitter": "Suriya Gunasekar", "authors": "Suriya Gunasekar, Blake Woodworth, Nathan Srebro", "title": "Mirrorless Mirror Descent: A Natural Derivation of Mirror Descent", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a primal only derivation of Mirror Descent as a \"partial\"\ndiscretization of gradient flow on a Riemannian manifold where the metric\ntensor is the Hessian of the Mirror Descent potential. We contrast this\ndiscretization to Natural Gradient Descent, which is obtained by a \"full\"\nforward Euler discretization. This view helps shed light on the relationship\nbetween the methods and allows generalizing Mirror Descent to general\nRiemannian geometries, even when the metric tensor is {\\em not} a Hessian, and\nthus there is no \"dual.\"\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 14:31:04 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:49:21 GMT"}, {"version": "v3", "created": "Fri, 2 Jul 2021 00:33:01 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Gunasekar", "Suriya", ""], ["Woodworth", "Blake", ""], ["Srebro", "Nathan", ""]]}, {"id": "2004.01028", "submitter": "Christos Fotis", "authors": "C. Fotis, N. Meimetis, A. Sardis and L.G. Alexopoulos", "title": "DeepSIBA: Chemical Structure-based Inference of Biological Alterations", "comments": "Article: 19 pages, Electronic Supplementary Information (included):\n  16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting whether a chemical structure shares a desired biological effect\ncan have a significant impact for in-silico compound screening in early drug\ndiscovery. In this study, we developed a deep learning model where compound\nstructures are represented as graphs and then linked to their biological\nfootprint. To make this complex problem computationally tractable, compound\ndifferences were mapped to biological effect alterations using Siamese Graph\nConvolutional Neural Networks. The proposed model was able to learn new\nrepresentations from chemical structures and identify structurally dissimilar\ncompounds that affect similar biological processes with high precision.\nAdditionally, by utilizing deep ensembles to estimate uncertainty, we were able\nto provide reliable and accurate predictions for chemical structures that are\nvery different from the ones used during training. Finally, we present a novel\ninference approach, where the trained models are used to estimate the signaling\npathways affected by a compound perturbation in a specific cell line, using\nonly its chemical structure as input. As a use case, this approach was used to\ninfer signaling pathways affected by FDA-approved anticancer drugs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:29:45 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Fotis", "C.", ""], ["Meimetis", "N.", ""], ["Sardis", "A.", ""], ["Alexopoulos", "L. G.", ""]]}, {"id": "2004.01029", "submitter": "Titas De", "authors": "Titas De", "title": "Introducing Anisotropic Minkowski Functionals for Local Structure\n  Analysis and Prediction of Biomechanical Strength of Proximal Femur Specimens", "comments": null, "journal-ref": "Master's Thesis - 2013", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bone fragility and fracture caused by osteoporosis or injury are prevalent in\nadults over the age of 50 and can reduce their quality of life. Hence,\npredicting the biomechanical bone strength, specifically of the proximal femur,\nthrough non-invasive imaging-based methods is an important goal for the\ndiagnosis of Osteoporosis as well as estimating fracture risk. Dual X-ray\nabsorptiometry (DXA) has been used as a standard clinical procedure for\nassessment and diagnosis of bone strength and osteoporosis through bone mineral\ndensity (BMD) measurements. However, previous studies have shown that\nquantitative computer tomography (QCT) can be more sensitive and specific to\ntrabecular bone characterization because it reduces the overlap effects and\ninterferences from the surrounding soft tissue and cortical shell.\n  This study proposes a new method to predict the bone strength of proximal\nfemur specimens from quantitative multi-detector computer tomography (MDCT)\nimages. Texture analysis methods such as conventional statistical moments (BMD\nmean), Isotropic Minkowski Functionals (IMF) and Anisotropic Minkowski\nFunctionals (AMF) are used to quantify BMD properties of the trabecular bone\nmicro-architecture. Combinations of these extracted features are then used to\npredict the biomechanical strength of the femur specimens using sophisticated\nmachine learning techniques such as multiregression (MultiReg) and support\nvector regression with linear kernel (SVRlin). The prediction performance\nachieved with these feature sets is compared to the standard approach that uses\nthe mean BMD of the specimens and multiregression models using root mean square\nerror (RMSE).\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 14:33:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["De", "Titas", ""]]}, {"id": "2004.01030", "submitter": "Lachlan Kermode", "authors": "Lachlan Kermode, Jan Freyberg, Alican Akturk, Robert Trafford, Denis\n  Kochetkov, Rafael Pardinas, Eyal Weizman, and Julien Cornebise", "title": "Objects of violence: synthetic data for practical ML in human rights\n  investigations", "comments": "Presented at NeurIPS 2019 in the AI for Social Good track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a machine learning workflow to search for, identify, and\nmeaningfully triage videos and images of munitions, weapons, and military\nequipment, even when limited training data exists for the object of interest.\nThis workflow is designed to expedite the work of OSINT (\"open source\nintelligence\") researchers in human rights investigations. It consists of three\ncomponents: automatic rendering and annotating of synthetic datasets that make\nup for a lack of training data; training image classifiers from combined sets\nof photographic and synthetic data; and mtriage, an open source software that\norchestrates these classifiers' deployment to triage public domain media, and\nvisualise predictions in a web interface. We show that synthetic data helps to\ntrain classifiers more effectively, and that certain approaches yield better\nresults for different architectures. We then demonstrate our workflow in two\nreal-world human rights investigations: the use of the Triple-Chaser tear gas\ngrenade against civilians, and the verification of allegations of military\npresence in Ukraine in 2014.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:50:43 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Kermode", "Lachlan", ""], ["Freyberg", "Jan", ""], ["Akturk", "Alican", ""], ["Trafford", "Robert", ""], ["Kochetkov", "Denis", ""], ["Pardinas", "Rafael", ""], ["Weizman", "Eyal", ""], ["Cornebise", "Julien", ""]]}, {"id": "2004.01071", "submitter": "Fabio Pizzati", "authors": "Fabio Pizzati, Pietro Cerri, Raoul de Charette", "title": "Model-based occlusion disentanglement for image-to-image translation", "comments": "ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image-to-image translation is affected by entanglement phenomena, which may\noccur in case of target data encompassing occlusions such as raindrops, dirt,\netc. Our unsupervised model-based learning disentangles scene and occlusions,\nwhile benefiting from an adversarial pipeline to regress physical parameters of\nthe occlusion model. The experiments demonstrate our method is able to handle\nvarying types of occlusions and generate highly realistic translations,\nqualitatively and quantitatively outperforming the state-of-the-art on multiple\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:24:41 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 09:27:54 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Pizzati", "Fabio", ""], ["Cerri", "Pietro", ""], ["de Charette", "Raoul", ""]]}, {"id": "2004.01077", "submitter": "Daniel Becking", "authors": "Arturo Marban, Daniel Becking, Simon Wiedemann and Wojciech Samek", "title": "Learning Sparse & Ternary Neural Networks with Entropy-Constrained\n  Trained Ternarization (EC2T)", "comments": "Proceedings of the CVPR'20 Joint Workshop on Efficient Deep Learning\n  in Computer Vision. Code is available at\n  https://github.com/d-becking/efficientCNNs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) have shown remarkable success in a variety of\nmachine learning applications. The capacity of these models (i.e., number of\nparameters), endows them with expressive power and allows them to reach the\ndesired performance. In recent years, there is an increasing interest in\ndeploying DNNs to resource-constrained devices (i.e., mobile devices) with\nlimited energy, memory, and computational budget. To address this problem, we\npropose Entropy-Constrained Trained Ternarization (EC2T), a general framework\nto create sparse and ternary neural networks which are efficient in terms of\nstorage (e.g., at most two binary-masks and two full-precision values are\nrequired to save a weight matrix) and computation (e.g., MAC operations are\nreduced to a few accumulations plus two multiplications). This approach\nconsists of two steps. First, a super-network is created by scaling the\ndimensions of a pre-trained model (i.e., its width and depth). Subsequently,\nthis super-network is simultaneously pruned (using an entropy constraint) and\nquantized (that is, ternary values are assigned layer-wise) in a training\nprocess, resulting in a sparse and ternary network representation. We validate\nthe proposed approach in CIFAR-10, CIFAR-100, and ImageNet datasets, showing\nits effectiveness in image classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:38:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 09:37:47 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Marban", "Arturo", ""], ["Becking", "Daniel", ""], ["Wiedemann", "Simon", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.01097", "submitter": "Ivana Kaji\\'c", "authors": "Ivana Kaji\\'c, Eser Ayg\\\"un and Doina Precup", "title": "Learning to cooperate: Emergent communication in multi-agent navigation", "comments": "Accepted to CogSci 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent communication in artificial agents has been studied to understand\nlanguage evolution, as well as to develop artificial systems that learn to\ncommunicate with humans. We show that agents performing a cooperative\nnavigation task in various gridworld environments learn an interpretable\ncommunication protocol that enables them to efficiently, and in many cases,\noptimally, solve the task. An analysis of the agents' policies reveals that\nemergent signals spatially cluster the state space, with signals referring to\nspecific locations and spatial directions such as \"left\", \"up\", or \"upper left\nroom\". Using populations of agents, we show that the emergent protocol has\nbasic compositional structure, thus exhibiting a core property of natural\nlanguage.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:17 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:13:39 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kaji\u0107", "Ivana", ""], ["Ayg\u00fcn", "Eser", ""], ["Precup", "Doina", ""]]}, {"id": "2004.01098", "submitter": "Weichao Mao", "authors": "Weichao Mao, Kaiqing Zhang, Erik Miehling, Tamer Ba\\c{s}ar", "title": "Information State Embedding in Partially Observable Cooperative\n  Multi-Agent Reinforcement Learning", "comments": "Accepted to CDC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-agent reinforcement learning (MARL) under partial observability has\nlong been considered challenging, primarily due to the requirement for each\nagent to maintain a belief over all other agents' local histories -- a domain\nthat generally grows exponentially over time. In this work, we investigate a\npartially observable MARL problem in which agents are cooperative. To enable\nthe development of tractable algorithms, we introduce the concept of an\ninformation state embedding that serves to compress agents' histories. We\nquantify how the compression error influences the resulting value functions for\ndecentralized control. Furthermore, we propose an instance of the embedding\nbased on recurrent neural networks (RNNs). The embedding is then used as an\napproximate information state, and can be fed into any MARL algorithm. The\nproposed embed-then-learn pipeline opens the black-box of existing (partially\nobservable) MARL algorithms, allowing us to establish some theoretical\nguarantees (error bounds of value functions) while still achieving competitive\nperformance with many end-to-end approaches.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:03:42 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 16:35:16 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 03:55:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Mao", "Weichao", ""], ["Zhang", "Kaiqing", ""], ["Miehling", "Erik", ""], ["Ba\u015far", "Tamer", ""]]}, {"id": "2004.01110", "submitter": "Ehsan Yaghoubi", "authors": "Ehsan Yaghoubi, Diana Borza, Jo\\~ao Neves, Aruna Kumar, Hugo\n  Proen\\c{c}a", "title": "An Attention-Based Deep Learning Model for Multiple Pedestrian\n  Attributes Recognition", "comments": "Submitted to Image and Vision Computing journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic characterization of pedestrians in surveillance footage is a\ntough challenge, particularly when the data is extremely diverse with cluttered\nbackgrounds, and subjects are captured from varying distances, under multiple\nposes, with partial occlusion. Having observed that the state-of-the-art\nperformance is still unsatisfactory, this paper provides a novel solution to\nthe problem, with two-fold contributions: 1) considering the strong semantic\ncorrelation between the different full-body attributes, we propose a multi-task\ndeep model that uses an element-wise multiplication layer to extract more\ncomprehensive feature representations. In practice, this layer serves as a\nfilter to remove irrelevant background features, and is particularly important\nto handle complex, cluttered data; and 2) we introduce a weighted-sum term to\nthe loss function that not only relativizes the contribution of each task (kind\nof attributed) but also is crucial for performance improvement in\nmultiple-attribute inference settings. Our experiments were performed on two\nwell-known datasets (RAP and PETA) and point for the superiority of the\nproposed method with respect to the state-of-the-art. The code is available at\nhttps://github.com/Ehsan-Yaghoubi/MAN-PAR-.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:21:14 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Yaghoubi", "Ehsan", ""], ["Borza", "Diana", ""], ["Neves", "Jo\u00e3o", ""], ["Kumar", "Aruna", ""], ["Proen\u00e7a", "Hugo", ""]]}, {"id": "2004.01122", "submitter": "Xiaodi Wu", "authors": "Shaopeng Zhu, Shih-Han Hung, Shouvanik Chakrabarti, and Xiaodi Wu", "title": "On the Principles of Differentiable Quantum Programming Languages", "comments": "Codes are available at https://github.com/LibertasSpZ/adcompile", "journal-ref": null, "doi": "10.1145/3385412.3386011", "report-no": null, "categories": "cs.PL cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Quantum Circuits (VQCs), or the so-called quantum\nneural-networks, are predicted to be one of the most important near-term\nquantum applications, not only because of their similar promises as classical\nneural-networks, but also because of their feasibility on near-term noisy\nintermediate-size quantum (NISQ) machines. The need for gradient information in\nthe training procedure of VQC applications has stimulated the development of\nauto-differentiation techniques for quantum circuits. We propose the first\nformalization of this technique, not only in the context of quantum circuits\nbut also for imperative quantum programs (e.g., with controls), inspired by the\nsuccess of differentiable programming languages in classical machine learning.\nIn particular, we overcome a few unique difficulties caused by exotic quantum\nfeatures (such as quantum no-cloning) and provide a rigorous formulation of\ndifferentiation applied to bounded-loop imperative quantum programs, its\ncode-transformation rules, as well as a sound logic to reason about their\ncorrectness. Moreover, we have implemented our code transformation in OCaml and\ndemonstrated the resource-efficiency of our scheme both analytically and\nempirically. We also conduct a case study of training a VQC instance with\ncontrols, which shows the advantage of our scheme over existing\nauto-differentiation for quantum circuits without controls.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:46:13 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Zhu", "Shaopeng", ""], ["Hung", "Shih-Han", ""], ["Chakrabarti", "Shouvanik", ""], ["Wu", "Xiaodi", ""]]}, {"id": "2004.01123", "submitter": "Sergey Kovalchuk", "authors": "Anastasia A. Funkner, Aleksey N. Yakovlev, Sergey V. Kovalchuk", "title": "Surrogate-assisted performance tuning of knowledge discovery algorithms:\n  application to clinical pathway evolutionary modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an approach for surrogate-assisted tuning of knowledge\ndiscovery algorithms. The approach is based on the prediction of both the\nquality and performance of the target algorithm. The prediction is furtherly\nused as objectives for the optimization and tuning of the algorithm. The\napproach is investigated using clinical pathways (CP) discovery problem\nresolved using the evolutionary-based clustering of electronic health records\n(EHR). Target algorithm and the proposed approach were applied to the discovery\nof CPs for Acute Coronary Syndrome patients in 3434 EHRs of patients treated in\nAlmazov National Medical Research Center (Saint Petersburg, Russia). The study\ninvestigates the possible acquisition of interpretable clusters of typical CPs\nwithin a single disease. It shows how the approach could be used to improve\ncomplex data-driven analytical knowledge discovery algorithms. The study of the\nresults includes the feature importance of the best surrogate model and\ndiscover how the parameters of input data influence the predictions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 16:49:43 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Funkner", "Anastasia A.", ""], ["Yakovlev", "Aleksey N.", ""], ["Kovalchuk", "Sergey V.", ""]]}, {"id": "2004.01136", "submitter": "Mengyue Yang", "authors": "Mengyue Yang, Qingyang Li, Zhiwei Qin, Jieping Ye", "title": "Hierarchical Adaptive Contextual Bandits for Resource Constraint based\n  Recommendation", "comments": "Accepted for publication at WWW (The Web Conference) 2020", "journal-ref": null, "doi": "10.1145/3366423.3380115", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit (MAB) achieves cutting-edge performance on a\nvariety of problems. When it comes to real-world scenarios such as\nrecommendation system and online advertising, however, it is essential to\nconsider the resource consumption of exploration. In practice, there is\ntypically non-zero cost associated with executing a recommendation (arm) in the\nenvironment, and hence, the policy should be learned with a fixed exploration\ncost constraint. It is challenging to learn a global optimal policy directly,\nsince it is a NP-hard problem and significantly complicates the exploration and\nexploitation trade-off of bandit algorithms. Existing approaches focus on\nsolving the problems by adopting the greedy policy which estimates the expected\nrewards and costs and uses a greedy selection based on each arm's expected\nreward/cost ratio using historical observation until the exploration resource\nis exhausted. However, existing methods are hard to extend to infinite time\nhorizon, since the learning process will be terminated when there is no more\nresource. In this paper, we propose a hierarchical adaptive contextual bandit\nmethod (HATCH) to conduct the policy learning of contextual bandits with a\nbudget constraint. HATCH adopts an adaptive method to allocate the exploration\nresource based on the remaining resource/time and the estimation of reward\ndistribution among different user contexts. In addition, we utilize full of\ncontextual feature information to find the best personalized recommendation.\nFinally, in order to prove the theoretical guarantee, we present a regret bound\nanalysis and prove that HATCH achieves a regret bound as low as $O(\\sqrt{T})$.\nThe experimental results demonstrate the effectiveness and efficiency of the\nproposed method on both synthetic data sets and the real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:04:52 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 16:56:29 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yang", "Mengyue", ""], ["Li", "Qingyang", ""], ["Qin", "Zhiwei", ""], ["Ye", "Jieping", ""]]}, {"id": "2004.01141", "submitter": "Simon Lindst{\\aa}hl", "authors": "Simon Lindst{\\aa}hl, Alexandre Proutiere, Andreas Johnsson", "title": "Predictive Bandits", "comments": "10 pages, 4 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a new class of stochastic bandit problems, referred to\nas predictive bandits. In each round, the decision maker first decides whether\nto gather information about the rewards of particular arms (so that their\nrewards in this round can be predicted). These measurements are costly, and may\nbe corrupted by noise. The decision maker then selects an arm to be actually\nplayed in the round. Predictive bandits find applications in many areas; e.g.\nthey can be applied to channel selection problems in radio communication\nsystems. In this paper, we provide the first theoretical results about\npredictive bandits, and focus on scenarios where the decision maker is allowed\nto measure at most one arm per round. We derive asymptotic instance-specific\nregret lower bounds for these problems, and develop algorithms whose regret\nmatch these fundamental limits. We illustrate the performance of our algorithms\nthrough numerical experiments. In particular, we highlight the gains that can\nbe achieved by using reward predictions, and investigate the impact of the\nnoise in the corresponding measurements.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:12:33 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Lindst\u00e5hl", "Simon", ""], ["Proutiere", "Alexandre", ""], ["Johnsson", "Andreas", ""]]}, {"id": "2004.01143", "submitter": "Ping Li", "authors": "Xiaoyun Li, Jie Gui, Ping Li", "title": "Randomized Kernel Multi-view Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many artificial intelligence and computer vision systems, the same object\ncan be observed at distinct viewpoints or by diverse sensors, which raises the\nchallenges for recognizing objects from different, even heterogeneous views.\nMulti-view discriminant analysis (MvDA) is an effective multi-view subspace\nlearning method, which finds a discriminant common subspace by jointly learning\nmultiple view-specific linear projections for object recognition from multiple\nviews, in a non-pairwise way. In this paper, we propose the kernel version of\nmulti-view discriminant analysis, called kernel multi-view discriminant\nanalysis (KMvDA). To overcome the well-known computational bottleneck of kernel\nmethods, we also study the performance of using random Fourier features (RFF)\nto approximate Gaussian kernels in KMvDA, for large scale learning. Theoretical\nanalysis on stability of this approximation is developed. We also conduct\nexperiments on several popular multi-view datasets to illustrate the\neffectiveness of our proposed strategy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:15:32 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Li", "Xiaoyun", ""], ["Gui", "Jie", ""], ["Li", "Ping", ""]]}, {"id": "2004.01144", "submitter": "Yingqi Gu", "authors": "Yingqi Gu, Akshay Zalkikar, Lara Kelly, Kieran Daly, Tomas E. Ward", "title": "Predicting Injectable Medication Adherence via a Smart Sharps Bin and\n  Machine Learning", "comments": "This paper has been accepted by IEEE IoT World Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medication non-adherence is a widespread problem affecting over 50% of people\nwho have chronic illness and need chronic treatment. Non-adherence exacerbates\nhealth risks and drives significant increases in treatment costs. In order to\naddress these challenges, the importance of predicting patients' adherence has\nbeen recognised. In other words, it is important to improve the efficiency of\ninterventions of the current healthcare system by prioritizing resources to the\npatients who are most likely to be non-adherent. Our objective in this work is\nto make predictions regarding individual patients' behaviour in terms of taking\ntheir medication on time during their next scheduled medication opportunity. We\ndo this by leveraging a number of machine learning models. In particular, we\ndemonstrate the use of a connected IoT device; a \"Smart Sharps Bin\", invented\nby HealthBeacon Ltd.; to monitor and track injection disposal of patients in\ntheir home environment. Using extensive data collected from these devices, five\nmachine learning models, namely Extra Trees Classifier, Random Forest, XGBoost,\nGradient Boosting and Multilayer Perception were trained and evaluated on a\nlarge dataset comprising 165,223 historic injection disposal records collected\nfrom 5,915 HealthBeacon units over the course of 3 years. The testing work was\nconducted on real-time data generated by the smart device over a time period\nafter the model training was complete, i.e. true future data. The proposed\nmachine learning approach demonstrated very good predictive performance\nexhibiting an Area Under the Receiver Operating Characteristic Curve (ROC AUC)\nof 0.86.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:16:51 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Gu", "Yingqi", ""], ["Zalkikar", "Akshay", ""], ["Kelly", "Lara", ""], ["Daly", "Kieran", ""], ["Ward", "Tomas E.", ""]]}, {"id": "2004.01157", "submitter": "Jaron Jia Rong Lee", "authors": "Jaron J. R. Lee, Ilya Shpitser", "title": "Identification Methods With Arbitrary Interventional Distributions as\n  Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference quantifies cause-effect relationships by estimating\ncounterfactual parameters from data. This entails using \\emph{identification\ntheory} to establish a link between counterfactual parameters of interest and\ndistributions from which data is available. A line of work characterized\nnon-parametric identification for a wide variety of causal parameters in terms\nof the \\emph{observed data distribution}. More recently, identification results\nhave been extended to settings where experimental data from interventional\ndistributions is also available. In this paper, we use Single World\nIntervention Graphs and a nested factorization of models associated with mixed\ngraphs to give a very simple view of existing identification theory for\nexperimental data. We use this view to yield general identification algorithms\nfor settings where the input distributions consist of an arbitrary set of\nobservational and experimental distributions, including marginal and\nconditional distributions. We show that for problems where inputs are\ninterventional marginal distributions of a certain type (ancestral marginals),\nour algorithm is complete.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:27:18 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 16:43:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Jaron J. R.", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2004.01160", "submitter": "Zackory Erickson", "authors": "Zackory Erickson, Eliot Xing, Bharat Srirangam, Sonia Chernova, and\n  Charles C. Kemp", "title": "Multimodal Material Classification for Robots using Spectroscopy and\n  High Resolution Texture Imaging", "comments": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  (IROS 2020), 8 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Material recognition can help inform robots about how to properly interact\nwith and manipulate real-world objects. In this paper, we present a multimodal\nsensing technique, leveraging near-infrared spectroscopy and close-range high\nresolution texture imaging, that enables robots to estimate the materials of\nhousehold objects. We release a dataset of high resolution texture images and\nspectral measurements collected from a mobile manipulator that interacted with\n144 household objects. We then present a neural network architecture that\nlearns a compact multimodal representation of spectral measurements and texture\nimages. When generalizing material classification to new objects, we show that\nthis multimodal representation enables a robot to recognize materials with\ngreater performance as compared to prior state-of-the-art approaches. Finally,\nwe present how a robot can combine this high resolution local sensing with\nimages from the robot's head-mounted camera to achieve accurate material\nclassification over a scene of objects on a table.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:33:54 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 19:45:38 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Erickson", "Zackory", ""], ["Xing", "Eliot", ""], ["Srirangam", "Bharat", ""], ["Chernova", "Sonia", ""], ["Kemp", "Charles C.", ""]]}, {"id": "2004.01167", "submitter": "Francisco Javier D\\'iez", "authors": "Iago Par\\'is, Raquel S\\'anchez-Cauce, Francisco Javier D\\'iez", "title": "Sum-product networks: A survey", "comments": "24 pages, 6 figures, 97 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sum-product network (SPN) is a probabilistic model, based on a rooted\nacyclic directed graph, in which terminal nodes represent univariate\nprobability distributions and non-terminal nodes represent convex combinations\n(weighted sums) and products of probability functions. They are closely related\nto probabilistic graphical models, in particular to Bayesian networks with\nmultiple context-specific independencies. Their main advantage is the\npossibility of building tractable models from data, i.e., models that can\nperform several inference tasks in time proportional to the number of links in\nthe graph. They are somewhat similar to neural networks and can address the\nsame kinds of problems, such as image processing and natural language\nunderstanding. This paper offers a survey of SPNs, including their definition,\nthe main algorithms for inference and learning from data, the main\napplications, a brief review of software libraries, and a comparison with\nrelated models\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:46:29 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Par\u00eds", "Iago", ""], ["S\u00e1nchez-Cauce", "Raquel", ""], ["D\u00edez", "Francisco Javier", ""]]}, {"id": "2004.01168", "submitter": "Tara Safavi", "authors": "Tara Safavi, Danai Koutra, Edgar Meij", "title": "Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy\n  Link Prediction", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Little is known about the trustworthiness of predictions made by knowledge\ngraph embedding (KGE) models. In this paper we take initial steps toward this\ndirection by investigating the calibration of KGE models, or the extent to\nwhich they output confidence scores that reflect the expected correctness of\npredicted knowledge graph triples. We first conduct an evaluation under the\nstandard closed-world assumption (CWA), in which predicted triples not already\nin the knowledge graph are considered false, and show that existing calibration\ntechniques are effective for KGE under this common but narrow assumption. Next,\nwe introduce the more realistic but challenging open-world assumption (OWA), in\nwhich unobserved predictions are not considered true or false until\nground-truth labels are obtained. Here, we show that existing calibration\ntechniques are much less effective under the OWA than the CWA, and provide\nexplanations for this discrepancy. Finally, to motivate the utility of\ncalibration for KGE from a practitioner's perspective, we conduct a unique case\nstudy of human-AI collaboration, showing that calibrated predictions can\nimprove human performance in a knowledge graph completion task.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:46:47 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 16:02:54 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 09:31:15 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Safavi", "Tara", ""], ["Koutra", "Danai", ""], ["Meij", "Edgar", ""]]}, {"id": "2004.01181", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Simon Alford, Vijay Gadepally, Michael Jones, Lauren\n  Milechin, Albert Reuther, Ryan Robinett, Sid Samsi", "title": "GraphChallenge.org Sparse Deep Neural Network Performance", "comments": "7 pages, 7 figures, 80 references, to be submitted to IEEE HPEC 2020.\n  This work reports new updated results on prior work reported in\n  arXiv:1909.05631. arXiv admin note: substantial text overlap with\n  arXiv:1807.03165, arXiv:1708.02937. arXiv admin note: text overlap with\n  arXiv:2003.09269", "journal-ref": null, "doi": "10.1109/HPEC43674.2020.9286253", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to\ndeveloping new solutions for analyzing graphs and sparse data. Sparse AI\nanalytics present unique scalability difficulties. The Sparse Deep Neural\nNetwork (DNN) Challenge draws upon prior challenges from machine learning, high\nperformance computing, and visual analytics to create a challenge that is\nreflective of emerging sparse AI systems. The sparse DNN challenge is based on\na mathematically well-defined DNN inference computation and can be implemented\nin any programming environment. In 2019 several sparse DNN challenge\nsubmissions were received from a wide range of authors and organizations. This\npaper presents a performance analysis of the best performers of these\nsubmissions. These submissions show that their state-of-the-art sparse DNN\nexecution time, $T_{\\rm DNN}$, is a strong function of the number of DNN\noperations performed, $N_{\\rm op}$. The sparse DNN challenge provides a clear\npicture of current sparse DNN systems and underscores the need for new\ninnovations to achieve high performance on very large sparse DNNs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 00:29:12 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:38:52 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Kepner", "Jeremy", ""], ["Alford", "Simon", ""], ["Gadepally", "Vijay", ""], ["Jones", "Michael", ""], ["Milechin", "Lauren", ""], ["Reuther", "Albert", ""], ["Robinett", "Ryan", ""], ["Samsi", "Sid", ""]]}, {"id": "2004.01184", "submitter": "Aboul Ella Hassanien Abo", "authors": "Nour Eldeen M. Khalifa, Mohamed Hamed N. Taha, Aboul Ella Hassanien,\n  Sally Elghamrawy", "title": "Detection of Coronavirus (COVID-19) Associated Pneumonia based on\n  Generative Adversarial Networks and a Fine-Tuned Deep Transfer Learning Model\n  using Chest X-ray Dataset", "comments": "15 pages, 3 Tables and 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 coronavirus is one of the devastating viruses according to the\nworld health organization. This novel virus leads to pneumonia, which is an\ninfection that inflames the lungs' air sacs of a human. One of the methods to\ndetect those inflames is by using x-rays for the chest. In this paper, a\npneumonia chest x-ray detection based on generative adversarial networks (GAN)\nwith a fine-tuned deep transfer learning for a limited dataset will be\npresented. The use of GAN positively affects the proposed model robustness and\nmade it immune to the overfitting problem and helps in generating more images\nfrom the dataset. The dataset used in this research consists of 5863 X-ray\nimages with two categories: Normal and Pneumonia. This research uses only 10%\nof the dataset for training data and generates 90% of images using GAN to prove\nthe efficiency of the proposed model. Through the paper, AlexNet, GoogLeNet,\nSqueeznet, and Resnet18 are selected as deep transfer learning models to detect\nthe pneumonia from chest x-rays. Those models are selected based on their small\nnumber of layers on their architectures, which will reflect in reducing the\ncomplexity of the models and the consumed memory and time. Using a combination\nof GAN and deep transfer models proved it is efficiency according to testing\naccuracy measurement. The research concludes that the Resnet18 is the most\nappropriate deep transfer model according to testing accuracy measurement and\nachieved 99% with the other performance metrics such as precision, recall, and\nF1 score while using GAN as an image augmenter. Finally, a comparison result\nwas carried out at the end of the research with related work which used the\nsame dataset except that this research used only 10% of original dataset. The\npresented work achieved a superior result than the related work in terms of\ntesting accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:14:37 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Khalifa", "Nour Eldeen M.", ""], ["Taha", "Mohamed Hamed N.", ""], ["Hassanien", "Aboul Ella", ""], ["Elghamrawy", "Sally", ""]]}, {"id": "2004.01185", "submitter": "Titas De", "authors": "Axel Wismueller, Titas De, Eva Lochmueller, Felix Eckstein, Mahesh B.\n  Nagarajan", "title": "Introducing Anisotropic Minkowski Functionals and Quantitative\n  Anisotropy Measures for Local Structure Analysis in Biomedical Imaging", "comments": "SPIE Medical Imaging 2013. arXiv admin note: text overlap with\n  arXiv:2002.07156", "journal-ref": null, "doi": "10.1117/86720I-86720I-8", "report-no": null, "categories": "eess.IV cs.CV cs.LG math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of Minkowski Functionals to characterize local structure in\ndifferent biological tissue types has been demonstrated in a variety of medical\nimage processing tasks. We introduce anisotropic Minkowski Functionals (AMFs)\nas a novel variant that captures the inherent anisotropy of the underlying\ngray-level structures. To quantify the anisotropy characterized by our\napproach, we further introduce a method to compute a quantitative measure\nmotivated by a technique utilized in MR diffusion tensor imaging, namely\nfractional anisotropy. We showcase the applicability of our method in the\nresearch context of characterizing the local structure properties of trabecular\nbone micro-architecture in the proximal femur as visualized on multi-detector\nCT. To this end, AMFs were computed locally for each pixel of ROIs extracted\nfrom the head, neck and trochanter regions. Fractional anisotropy was then used\nto quantify the local anisotropy of the trabecular structures found in these\nROIs and to compare its distribution in different anatomical regions. Our\nresults suggest a significantly greater concentration of anisotropic trabecular\nstructures in the head and neck regions when compared to the trochanter region\n(p < 10-4). We also evaluated the ability of such AMFs to predict bone strength\nin the femoral head of proximal femur specimens obtained from 50 donors. Our\nresults suggest that such AMFs, when used in conjunction with multi-regression\nmodels, can outperform more conventional features such as BMD in predicting\nfailure load. We conclude that such anisotropic Minkowski Functionals can\ncapture valuable information regarding directional attributes of local\nstructure, which may be useful in a wide scope of biomedical imaging\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 14:13:50 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wismueller", "Axel", ""], ["De", "Titas", ""], ["Lochmueller", "Eva", ""], ["Eckstein", "Felix", ""], ["Nagarajan", "Mahesh B.", ""]]}, {"id": "2004.01190", "submitter": "Gadi Naveh", "authors": "Gadi Naveh, Oded Ben-David, Haim Sompolinsky and Zohar Ringel", "title": "Predicting the outputs of finite networks trained with noisy gradients", "comments": "8 pages + appendix, 7 figures overall", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent line of works studied wide deep neural networks (DNNs) by\napproximating them as Gaussian Processes (GPs). A DNN trained with gradient\nflow was shown to map to a GP governed by the Neural Tangent Kernel (NTK),\nwhereas earlier works showed that a DNN with an i.i.d. prior over its weights\nmaps to the so-called Neural Network Gaussian Process (NNGP). Here we consider\na DNN training protocol, involving noise, weight decay and finite width, whose\noutcome corresponds to a certain non-Gaussian stochastic process. An analytical\nframework is then introduced to analyze this non-Gaussian process, whose\ndeviation from a GP is controlled by the finite width. Our contribution is\nthree-fold: (i) In the infinite width limit, we establish a correspondence\nbetween DNNs trained with noisy gradients and the NNGP, not the NTK. (ii) We\nprovide a general analytical form for the finite width correction (FWC) for\nDNNs with arbitrary activation functions and depth and use it to predict the\noutputs of empirical finite networks with high accuracy. Analyzing the FWC\nbehavior as a function of $n$, the training set size, we find that it is\nnegligible for both the very small $n$ regime, and, surprisingly, for the large\n$n$ regime (where the GP error scales as $O(1/n)$). (iii) We flesh-out\nalgebraically how these FWCs can improve the performance of finite\nconvolutional neural networks (CNNs) relative to their GP counterparts on image\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:00:01 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 10:17:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Naveh", "Gadi", ""], ["Ben-David", "Oded", ""], ["Sompolinsky", "Haim", ""], ["Ringel", "Zohar", ""]]}, {"id": "2004.01215", "submitter": "Inkit Padhi", "authors": "Vijil Chenthamarakshan, Payel Das, Samuel C. Hoffman, Hendrik\n  Strobelt, Inkit Padhi, Kar Wai Lim, Benjamin Hoover, Matteo Manica, Jannis\n  Born, Teodoro Laino, Aleksandra Mojsilovic", "title": "CogMol: Target-Specific and Selective Drug Design for COVID-19 Using\n  Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel nature of SARS-CoV-2 calls for the development of efficient de novo\ndrug design approaches. In this study, we propose an end-to-end framework,\nnamed CogMol (Controlled Generation of Molecules), for designing new drug-like\nsmall molecules targeting novel viral proteins with high affinity and\noff-target selectivity. CogMol combines adaptive pre-training of a molecular\nSMILES Variational Autoencoder (VAE) and an efficient multi-attribute\ncontrolled sampling scheme that uses guidance from attribute predictors trained\non latent features. To generate novel and optimal drug-like molecules for\nunseen viral targets, CogMol leverages a protein-molecule binding affinity\npredictor that is trained using SMILES VAE embeddings and protein sequence\nembeddings learned unsupervised from a large corpus. CogMol framework is\napplied to three SARS-CoV-2 target proteins: main protease, receptor-binding\ndomain of the spike protein, and non-structural protein 9 replicase. The\ngenerated candidates are novel at both molecular and chemical scaffold levels\nwhen compared to the training data. CogMol also includes insilico screening for\nassessing toxicity of parent molecules and their metabolites with a multi-task\ntoxicity classifier, synthetic feasibility with a chemical retrosynthesis\npredictor, and target structure binding with docking simulations. Docking\nreveals favorable binding of generated molecules to the target protein\nstructure, where 87-95 % of high affinity molecules showed docking free energy\n< -6 kcal/mol. When compared to approved drugs, the majority of designed\ncompounds show low parent molecule and metabolite toxicity and high synthetic\nfeasibility. In summary, CogMol handles multi-constraint design of\nsynthesizable, low-toxic, drug-like molecules with high target specificity and\nselectivity, and does not need target-dependent fine-tuning of the framework or\ntarget structure information.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:17:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 00:16:56 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chenthamarakshan", "Vijil", ""], ["Das", "Payel", ""], ["Hoffman", "Samuel C.", ""], ["Strobelt", "Hendrik", ""], ["Padhi", "Inkit", ""], ["Lim", "Kar Wai", ""], ["Hoover", "Benjamin", ""], ["Manica", "Matteo", ""], ["Born", "Jannis", ""], ["Laino", "Teodoro", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "2004.01218", "submitter": "Eli Sherman", "authors": "Eli Sherman, David Arbour, Ilya Shpitser", "title": "General Identification of Dynamic Treatment Regimes Under Interference", "comments": "2020 Conference on Artificial Intelligence and Statistics (AIStats)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applied fields, researchers are often interested in tailoring\ntreatments to unit-level characteristics in order to optimize an outcome of\ninterest. Methods for identifying and estimating treatment policies are the\nsubject of the dynamic treatment regime literature. Separately, in many\nsettings the assumption that data are independent and identically distributed\ndoes not hold due to inter-subject dependence. The phenomenon where a subject's\noutcome is dependent on his neighbor's exposure is known as interference. These\nareas intersect in myriad real-world settings. In this paper we consider the\nproblem of identifying optimal treatment policies in the presence of\ninterference. Using a general representation of interference, via\nLauritzen-Wermuth-Freydenburg chain graphs (Lauritzen and Richardson, 2002), we\nformalize a variety of policy interventions under interference and extend\nexisting identification theory (Tian, 2008; Sherman and Shpitser, 2018).\nFinally, we illustrate the efficacy of policy maximization under interference\nin a simulation study.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:22:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Sherman", "Eli", ""], ["Arbour", "David", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2004.01221", "submitter": "Sriram Ganapathy", "authors": "Bharat Padi, Anand Mohan and Sriram Ganapathy", "title": "Towards Relevance and Sequence Modeling in Language Recognition", "comments": "https://github.com/iiscleap/lre-relevance-weighting Accepted to IEEE\n  Transactions on Audio, Speech and Language Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of automatic language identification (LID) involving multiple\ndialects of the same language family in the presence of noise is a challenging\nproblem. In these scenarios, the identity of the language/dialect may be\nreliably present only in parts of the temporal sequence of the speech signal.\nThe conventional approaches to LID (and for speaker recognition) ignore the\nsequence information by extracting long-term statistical summary of the\nrecording assuming an independence of the feature frames. In this paper, we\npropose a neural network framework utilizing short-sequence information in\nlanguage recognition. In particular, a new model is proposed for incorporating\nrelevance in language recognition, where parts of speech data are weighted more\nbased on their relevance for the language recognition task. This relevance\nweighting is achieved using the bidirectional long short-term memory (BLSTM)\nnetwork with attention modeling. We explore two approaches, the first approach\nuses segment level i-vector/x-vector representations that are aggregated in the\nneural model and the second approach where the acoustic features are directly\nmodeled in an end-to-end neural model. Experiments are performed using the\nlanguage recognition task in NIST LRE 2017 Challenge using clean, noisy and\nmulti-speaker speech data as well as in the RATS language recognition corpus.\nIn these experiments on noisy LRE tasks as well as the RATS dataset, the\nproposed approach yields significant improvements over the conventional\ni-vector/x-vector based language recognition approaches as well as with other\nprevious models incorporating sequence information.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 18:31:18 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Padi", "Bharat", ""], ["Mohan", "Anand", ""], ["Ganapathy", "Sriram", ""]]}, {"id": "2004.01227", "submitter": "Fabio Gonzalez", "authors": "Fabio A. Gonz\\'alez, Vladimir Vargas-Calder\\'on, Herbert Vinck-Posada", "title": "Supervised Learning with Quantum Measurements", "comments": "Supplementary material integrated into main text. Typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reports a novel method for supervised machine learning based on\nthe mathematical formalism that supports quantum mechanics. The method uses\nprojective quantum measurement as a way of building a prediction function.\nSpecifically, the relationship between input and output variables is\nrepresented as the state of a bipartite quantum system. The state is estimated\nfrom training samples through an averaging process that produces a density\nmatrix. Prediction of the label for a new sample is made by performing a\nprojective measurement on the bipartite system with an operator, prepared from\nthe new input sample, and applying a partial trace to obtain the state of the\nsubsystem representing the output. The method can be seen as a generalization\nof Bayesian inference classification and as a type of kernel-based learning\nmethod. One remarkable characteristic of the method is that it does not require\nlearning any parameters through optimization. We illustrate the method with\ndifferent 2-D classification benchmark problems and different quantum\ninformation encodings.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 19:08:38 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 15:09:28 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Gonz\u00e1lez", "Fabio A.", ""], ["Vargas-Calder\u00f3n", "Vladimir", ""], ["Vinck-Posada", "Herbert", ""]]}, {"id": "2004.01228", "submitter": "Mikaela Angelina Uy", "authors": "Mikaela Angelina Uy and Jingwei Huang and Minhyuk Sung and Tolga\n  Birdal and Leonidas Guibas", "title": "Deformation-Aware 3D Model Embedding and Retrieval", "comments": "Accepted for publication at ECCV 2020. Project page under\n  https://deformscan2cad.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new problem of retrieving 3D models that are deformable to a\ngiven query shape and present a novel deep deformation-aware embedding to solve\nthis retrieval task. 3D model retrieval is a fundamental operation for\nrecovering a clean and complete 3D model from a noisy and partial 3D scan.\nHowever, given a finite collection of 3D shapes, even the closest model to a\nquery may not be satisfactory. This motivates us to apply 3D model deformation\ntechniques to adapt the retrieved model so as to better fit the query. Yet,\ncertain restrictions are enforced in most 3D deformation techniques to preserve\nimportant features of the original model that prevent a perfect fitting of the\ndeformed model to the query. This gap between the deformed model and the query\ninduces asymmetric relationships among the models, which cannot be handled by\ntypical metric learning techniques. Thus, to retrieve the best models for\nfitting, we propose a novel deep embedding approach that learns the asymmetric\nrelationships by leveraging location-dependent egocentric distance fields. We\nalso propose two strategies for training the embedding network. We demonstrate\nthat both of these approaches outperform other baselines in our experiments\nwith both synthetic and real data. Our project page can be found at\nhttps://deformscan2cad.github.io/.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 19:10:57 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 02:38:26 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 05:10:25 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Uy", "Mikaela Angelina", ""], ["Huang", "Jingwei", ""], ["Sung", "Minhyuk", ""], ["Birdal", "Tolga", ""], ["Guibas", "Leonidas", ""]]}, {"id": "2004.01254", "submitter": "Constantin Waubert de Puiseau", "authors": "Richard Meyes, Constantin Waubert de Puiseau, Andres Posada-Moreno,\n  Tobias Meisen", "title": "Under the Hood of Neural Networks: Characterizing Learned\n  Representations by Functional Neuron Populations and Network Ablations", "comments": "17 pages, 14 figures, adjusted \"under review\" statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for more transparency of the decision-making processes in artificial\nneural networks steadily increases driven by their applications in safety\ncritical and ethically challenging domains such as autonomous driving or\nmedical diagnostics. We address today's lack of transparency of neural networks\nand shed light on the roles of single neurons and groups of neurons within the\nnetwork fulfilling a learned task. Inspired by research in the field of\nneuroscience, we characterize the learned representations by activation\npatterns and network ablations, revealing functional neuron populations that a)\nact jointly in response to specific stimuli or b) have similar impact on the\nnetwork's performance after being ablated. We find that neither a neuron's\nmagnitude or selectivity of activation, nor its impact on network performance\nare sufficient stand-alone indicators for its importance for the overall task.\nWe argue that such indicators are essential for future advances in transfer\nlearning and modern neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 20:45:01 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:09:15 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Meyes", "Richard", ""], ["de Puiseau", "Constantin Waubert", ""], ["Posada-Moreno", "Andres", ""], ["Meisen", "Tobias", ""]]}, {"id": "2004.01255", "submitter": "Yifan Xu", "authors": "Zheng Ding, Yifan Xu, Weijian Xu, Gaurav Parmar, Yang Yang, Max\n  Welling, Zhuowen Tu", "title": "Guided Variational Autoencoder for Disentanglement Learning", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm, guided variational autoencoder (Guided-VAE), that is\nable to learn a controllable generative model by performing latent\nrepresentation disentanglement learning. The learning objective is achieved by\nproviding signals to the latent encoding/embedding in VAE without changing its\nmain backbone architecture, hence retaining the desirable properties of the\nVAE. We design an unsupervised strategy and a supervised strategy in Guided-VAE\nand observe enhanced modeling and controlling capability over the vanilla VAE.\nIn the unsupervised strategy, we guide the VAE learning by introducing a\nlightweight decoder that learns latent geometric transformation and principal\ncomponents; in the supervised strategy, we use an adversarial excitation and\ninhibition mechanism to encourage the disentanglement of the latent variables.\nGuided-VAE enjoys its transparency and simplicity for the general\nrepresentation learning task, as well as disentanglement learning. On a number\nof experiments for representation learning, improved synthesis/sampling, better\ndisentanglement for classification, and reduced classification errors in\nmeta-learning have been observed.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 20:49:15 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ding", "Zheng", ""], ["Xu", "Yifan", ""], ["Xu", "Weijian", ""], ["Parmar", "Gaurav", ""], ["Yang", "Yang", ""], ["Welling", "Max", ""], ["Tu", "Zhuowen", ""]]}, {"id": "2004.01257", "submitter": "Kareem El-Safty", "authors": "Ahmed M. El-Mahalawy, Kareem H. El-Safty", "title": "Classical and quantum regression analysis for the optoelectronic\n  performance of NTCDA/p-Si UV photodiode", "comments": "25 pages, single column file, 16 figures, 3 tables, updated the\n  values in table 3, added github repository in the paper, increased the DPI of\n  the figures. submitted to Optik", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY physics.app-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the pivotal role of UV photodiodes in many technological applications\nin tandem with the high efficiency achieved by machine learning techniques in\nregression and classification problems, different artificial intelligence\ntechniques are adopted model the performance of organic/inorganic\nheterojunction UV photodiode. Herein, the performance of a fabricated\nAu/NTCDA/p-Si/Al photodiode was explained in details and showed an excellent\nresponsivity, and detectivity for UV light of intensities ranges from 20 to 80\n${mW/cm^2}$. The fabricated photodiodes exhibited a linear current-irradiance\nrelationship under illumination up to 65 ${mW/cm^2}$. It also exhibits good\nresponse times of ${t_{rise} = 408}$ ms and ${t_{fall} = 490}$ ms. Furthermore,\nwe have not only fitted the characteristic I-V curve but also evaluated three\nclassical algorithms; k-nearest neighbour, artificial neural network, and\ngenetic programming besides using a quantum neural network to predict the\nbehaviour of the fabricated device. The models have achieved outstanding\nresults and managed to capture the trend of the target values. The Quantum\nNeural Network has been used for the first time to model the photodiode. The\nmodels can be used instead of repeating the fabrication process. This means a\nreduction in cost and manufacturing time.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 17:40:20 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:02:23 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2020 17:09:26 GMT"}, {"version": "v4", "created": "Mon, 12 Apr 2021 01:44:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["El-Mahalawy", "Ahmed M.", ""], ["El-Safty", "Kareem H.", ""]]}, {"id": "2004.01258", "submitter": "Ying-Cheng Lai", "authors": "Huawei Fan, Junjie Jiang, Chun Zhang, Xingang Wang, and Ying-Cheng Lai", "title": "Long-term prediction of chaotic systems with recurrent neural networks", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.AO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing systems, a class of recurrent neural networks, have\nrecently been exploited for model-free, data-based prediction of the state\nevolution of a variety of chaotic dynamical systems. The prediction horizon\ndemonstrated has been about half dozen Lyapunov time. Is it possible to\nsignificantly extend the prediction time beyond what has been achieved so far?\nWe articulate a scheme incorporating time-dependent but sparse data inputs into\nreservoir computing and demonstrate that such rare \"updates\" of the actual\nstate practically enable an arbitrarily long prediction horizon for a variety\nof chaotic systems. A physical understanding based on the theory of temporal\nsynchronization is developed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 18:59:44 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fan", "Huawei", ""], ["Jiang", "Junjie", ""], ["Zhang", "Chun", ""], ["Wang", "Xingang", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "2004.01275", "submitter": "Usama Masood", "authors": "Ali Imran, Iryna Posokhova, Haneya N. Qureshi, Usama Masood, Muhammad\n  Sajid Riaz, Kamran Ali, Charles N. John, MD Iftikhar Hussain, Muhammad Nabeel", "title": "AI4COVID-19: AI Enabled Preliminary Diagnosis for COVID-19 from Cough\n  Samples via an App", "comments": "Accepted in Informatics in Medicine Unlocked 2020", "journal-ref": "Informatics in Medicine Unlocked, vol. 20, p. 100378, 2020", "doi": "10.1016/j.imu.2020.100378", "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The inability to test at scale has become humanity's Achille's\nheel in the ongoing war against the COVID-19 pandemic. A scalable screening\ntool would be a game changer. Building on the prior work on cough-based\ndiagnosis of respiratory diseases, we propose, develop and test an Artificial\nIntelligence (AI)-powered screening solution for COVID-19 infection that is\ndeployable via a smartphone app. The app, named AI4COVID-19 records and sends\nthree 3-second cough sounds to an AI engine running in the cloud, and returns a\nresult within two minutes. Methods: Cough is a symptom of over thirty\nnon-COVID-19 related medical conditions. This makes the diagnosis of a COVID-19\ninfection by cough alone an extremely challenging multidisciplinary problem. We\naddress this problem by investigating the distinctness of pathomorphological\nalterations in the respiratory system induced by COVID-19 infection when\ncompared to other respiratory infections. To overcome the COVID-19 cough\ntraining data shortage we exploit transfer learning. To reduce the misdiagnosis\nrisk stemming from the complex dimensionality of the problem, we leverage a\nmulti-pronged mediator centered risk-averse AI architecture. Results: Results\nshow AI4COVID-19 can distinguish among COVID-19 coughs and several types of\nnon-COVID-19 coughs. The accuracy is promising enough to encourage a\nlarge-scale collection of labeled cough data to gauge the generalization\ncapability of AI4COVID-19. AI4COVID-19 is not a clinical grade testing tool.\nInstead, it offers a screening tool deployable anytime, anywhere, by anyone. It\ncan also be a clinical decision assistance tool used to channel\nclinical-testing and treatment to those who need it the most, thereby saving\nmore lives.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 21:39:34 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 02:06:26 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:59:39 GMT"}, {"version": "v4", "created": "Thu, 16 Apr 2020 05:55:56 GMT"}, {"version": "v5", "created": "Tue, 5 May 2020 22:53:50 GMT"}, {"version": "v6", "created": "Sun, 27 Sep 2020 21:32:17 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Imran", "Ali", ""], ["Posokhova", "Iryna", ""], ["Qureshi", "Haneya N.", ""], ["Masood", "Usama", ""], ["Riaz", "Muhammad Sajid", ""], ["Ali", "Kamran", ""], ["John", "Charles N.", ""], ["Hussain", "MD Iftikhar", ""], ["Nabeel", "Muhammad", ""]]}, {"id": "2004.01293", "submitter": "William Underwood", "authors": "William George Underwood, Andrew Elliott, Mihai Cucuringu", "title": "Motif-Based Spectral Clustering of Weighted Directed Networks", "comments": "38 pages, 20 figures", "journal-ref": "Applied Network Science 5, 62 (2020)", "doi": "10.1007/s41109-020-00293-z", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an essential technique for network analysis, with applications\nin a diverse range of fields. Although spectral clustering is a popular and\neffective method, it fails to consider higher-order structure and can perform\npoorly on directed networks. One approach is to capture and cluster\nhigher-order structures using motif adjacency matrices. However, current\nformulations fail to take edge weights into account, and thus are somewhat\nlimited when weight is a key component of the network under study.\n  We address these shortcomings by exploring motif-based weighted spectral\nclustering methods. We present new and computationally useful matrix formulae\nfor motif adjacency matrices on weighted networks, which can be used to\nconstruct efficient algorithms for any anchored or non-anchored motif on three\nnodes. In a very sparse regime, our proposed method can handle graphs with a\nmillion nodes and tens of millions of edges. We further use our framework to\nconstruct a motif-based approach for clustering bipartite networks.\n  We provide comprehensive experimental results, demonstrating (i) the\nscalability of our approach, (ii) advantages of higher-order clustering on\nsynthetic examples, and (iii) the effectiveness of our techniques on a variety\nof real world data sets; and compare against several techniques from the\nliterature. We conclude that motif-based spectral clustering is a valuable tool\nfor analysis of directed and bipartite weighted networks, which is also\nscalable and easy to implement.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 22:45:28 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 18:25:01 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Underwood", "William George", ""], ["Elliott", "Andrew", ""], ["Cucuringu", "Mihai", ""]]}, {"id": "2004.01298", "submitter": "Edward Zhu", "authors": "Edward L. Zhu, Yvonne R. St\\\"urz, Ugo Rosolia, Francesco Borrelli", "title": "Trajectory Optimization for Nonlinear Multi-Agent Systems using\n  Decentralized Learning Model Predictive Control", "comments": "8 pages, 2 figures, accepted at Conference on Decision and Control\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a decentralized minimum-time trajectory optimization scheme based\non learning model predictive control for multi-agent systems with nonlinear\ndecoupled dynamics and coupled state constraints. By performing the same task\niteratively, data from previous task executions is used to construct and\nimprove local time-varying safe sets and an approximate value function. These\nare used in a decoupled MPC problem as terminal sets and terminal cost\nfunctions. Our framework results in a decentralized controller, which requires\nno communication between agents over each iteration of task execution, and\nguarantees persistent feasibility, finite-time closed-loop convergence, and\nnon-decreasing performance of the global system over task iterations. Numerical\nexperiments of a multi-vehicle collision avoidance scenario demonstrate the\neffectiveness of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:04:10 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 17:04:50 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 20:18:25 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 05:00:29 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Zhu", "Edward L.", ""], ["St\u00fcrz", "Yvonne R.", ""], ["Rosolia", "Ugo", ""], ["Borrelli", "Francesco", ""]]}, {"id": "2004.01299", "submitter": "Ping Li", "authors": "Xiaoyun Li, Chengxi Wu, Ping Li", "title": "IVFS: Simple and Efficient Feature Selection for High Dimensional\n  Topology Preservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is an important tool to deal with high dimensional data. In\nunsupervised case, many popular algorithms aim at maintaining the structure of\nthe original data. In this paper, we propose a simple and effective feature\nselection algorithm to enhance sample similarity preservation through a new\nperspective, topology preservation, which is represented by persistent diagrams\nfrom the context of computational topology. This method is designed upon a\nunified feature selection framework called IVFS, which is inspired by random\nsubset method. The scheme is flexible and can handle cases where the problem is\nanalytically intractable. The proposed algorithm is able to well preserve the\npairwise distances, as well as topological patterns, of the full data. We\ndemonstrate that our algorithm can provide satisfactory performance under a\nsharp sub-sampling rate, which supports efficient implementation of our\nproposed method to large scale datasets. Extensive experiments validate the\neffectiveness of the proposed feature selection scheme.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:05:00 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Li", "Xiaoyun", ""], ["Wu", "Chengxi", ""], ["Li", "Ping", ""]]}, {"id": "2004.01302", "submitter": "Aritra Mitra", "authors": "Aritra Mitra, John A. Richards, Saurabh Bagchi and Shreyas Sundaram", "title": "Distributed Inference with Sparse and Quantized Communication", "comments": "Accepted for publication in the IEEE Transactions of Signal\n  Processing as a regular paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.GT cs.IT cs.LG cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed inference where agents in a network\nobserve a stream of private signals generated by an unknown state, and aim to\nuniquely identify this state from a finite set of hypotheses. We focus on\nscenarios where communication between agents is costly, and takes place over\nchannels with finite bandwidth. To reduce the frequency of communication, we\ndevelop a novel event-triggered distributed learning rule that is based on the\nprinciple of diffusing low beliefs on each false hypothesis. Building on this\nprinciple, we design a trigger condition under which an agent broadcasts only\nthose components of its belief vector that have adequate innovation, to only\nthose neighbors that require such information. We prove that our rule\nguarantees convergence to the true state exponentially fast almost surely\ndespite sparse communication, and that it has the potential to significantly\nreduce information flow from uninformative agents to informative agents. Next,\nto deal with finite-precision communication channels, we propose a distributed\nlearning rule that leverages the idea of adaptive quantization. We show that by\nsequentially refining the range of the quantizers, every agent can learn the\ntruth exponentially fast almost surely, while using just $1$ bit to encode its\nbelief on each hypothesis. For both our proposed algorithms, we rigorously\ncharacterize the trade-offs between communication-efficiency and the learning\nrate.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:08:51 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 17:36:49 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 02:54:50 GMT"}, {"version": "v4", "created": "Mon, 7 Jun 2021 17:45:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Mitra", "Aritra", ""], ["Richards", "John A.", ""], ["Bagchi", "Saurabh", ""], ["Sundaram", "Shreyas", ""]]}, {"id": "2004.01305", "submitter": "Ping Li", "authors": "Peng Yang and Ping Li", "title": "Distributed Primal-Dual Optimization for Online Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional online multi-task learning algorithms suffer from two critical\nlimitations: 1) Heavy communication caused by delivering high velocity of\nsequential data to a central machine; 2) Expensive runtime complexity for\nbuilding task relatedness. To address these issues, in this paper we consider a\nsetting where multiple tasks are geographically located in different places,\nwhere one task can synchronize data with others to leverage knowledge of\nrelated tasks. Specifically, we propose an adaptive primal-dual algorithm,\nwhich not only captures task-specific noise in adversarial learning but also\ncarries out a projection-free update with runtime efficiency. Moreover, our\nmodel is well-suited to decentralized periodic-connected tasks as it allows the\nenergy-starved or bandwidth-constraint tasks to postpone the update.\nTheoretical results demonstrate the convergence guarantee of our distributed\nalgorithm with an optimal regret. Empirical results confirm that the proposed\nmodel is highly effective on various real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:36:07 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Yang", "Peng", ""], ["Li", "Ping", ""]]}, {"id": "2004.01306", "submitter": "Aritra Mitra", "authors": "Shreyas Sundaram and Aritra Mitra", "title": "Distributed Hypothesis Testing and Social Learning in Finite Time with a\n  Finite Amount of Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed hypothesis testing (or social\nlearning) where a network of agents seeks to identify the true state of the\nworld from a finite set of hypotheses, based on a series of stochastic signals\nthat each agent receives. Prior work on this problem has provided distributed\nalgorithms that guarantee asymptotic learning of the true state, with\ncorresponding efforts to improve the rate of learning. In this paper, we first\nargue that one can readily modify existing asymptotic learning algorithms to\nenable learning in finite time, effectively yielding arbitrarily large\n(asymptotic) rates. We then provide a simple algorithm for finite-time learning\nwhich only requires the agents to exchange a binary vector (of length equal to\nthe number of possible hypotheses) with their neighbors at each time-step.\nFinally, we show that if the agents know the diameter of the network, our\nalgorithm can be further modified to allow all agents to learn the true state\nand stop transmitting to their neighbors after a finite number of time-steps.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:38:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Sundaram", "Shreyas", ""], ["Mitra", "Aritra", ""]]}, {"id": "2004.01307", "submitter": "Md Selim", "authors": "Md Selim, Jie Zhang, Baowei Fei, Guo-Qiang Zhang and Jin Chen", "title": "STAN-CT: Standardizing CT Image using Generative Adversarial Network", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computed tomography (CT) plays an important role in lung malignancy\ndiagnostics and therapy assessment and facilitating precision medicine\ndelivery. However, the use of personalized imaging protocols poses a challenge\nin large-scale cross-center CT image radiomic studies. We present an end-to-end\nsolution called STAN-CT for CT image standardization and normalization, which\neffectively reduces discrepancies in image features caused by using different\nimaging protocols or using different CT scanners with the same imaging\nprotocol. STAN-CT consists of two components: 1) a novel Generative Adversarial\nNetworks (GAN) model that is capable of effectively learning the data\ndistribution of a standard imaging protocol with only a few rounds of generator\ntraining, and 2) an automatic DICOM reconstruction pipeline with systematic\nimage quality control that ensure the generation of high-quality standard DICOM\nimages. Experimental results indicate that the training efficiency and model\nperformance of STAN-CT have been significantly improved compared to the\nstate-of-the-art CT image standardization and normalization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 23:43:06 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Selim", "Md", ""], ["Zhang", "Jie", ""], ["Fei", "Baowei", ""], ["Zhang", "Guo-Qiang", ""], ["Chen", "Jin", ""]]}, {"id": "2004.01339", "submitter": "Tianshu Chu", "authors": "Tianshu Chu, Sandeep Chinchali, Sachin Katti", "title": "Multi-agent Reinforcement Learning for Networked System Control", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers multi-agent reinforcement learning (MARL) in networked\nsystem control. Specifically, each agent learns a decentralized control policy\nbased on local observations and messages from connected neighbors. We formulate\nsuch a networked MARL (NMARL) problem as a spatiotemporal Markov decision\nprocess and introduce a spatial discount factor to stabilize the training of\neach local agent. Further, we propose a new differentiable communication\nprotocol, called NeurComm, to reduce information loss and non-stationarity in\nNMARL. Based on experiments in realistic NMARL scenarios of adaptive traffic\nsignal control and cooperative adaptive cruise control, an appropriate spatial\ndiscount factor effectively enhances the learning curves of non-communicative\nMARL algorithms, while NeurComm outperforms existing communication protocols in\nboth learning efficiency and control performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 02:21:07 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:54:46 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Chu", "Tianshu", ""], ["Chinchali", "Sandeep", ""], ["Katti", "Sachin", ""]]}, {"id": "2004.01351", "submitter": "Younkwan Lee", "authors": "Younkwan Lee, Jihyo Jeon, Jongmin Yu, Moongu Jeon", "title": "Context-Aware Multi-Task Learning for Traffic Scene Recognition in\n  Autonomous Vehicles", "comments": "Accepted to IV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic scene recognition, which requires various visual classification\ntasks, is a critical ingredient in autonomous vehicles. However, most existing\napproaches treat each relevant task independently from one another, never\nconsidering the entire system as a whole. Because of this, they are limited to\nutilizing a task-specific set of features for all possible tasks of\ninference-time, which ignores the capability to leverage common task-invariant\ncontextual knowledge for the task at hand. To address this problem, we propose\nan algorithm to jointly learn the task-specific and shared representations by\nadopting a multi-task learning network. Specifically, we present a lower bound\nfor the mutual information constraint between shared feature embedding and\ninput that is considered to be able to extract common contextual information\nacross tasks while preserving essential information of each task jointly. The\nlearned representations capture richer contextual information without\nadditional task-specific network. Extensive experiments on the large-scale\ndataset HSD demonstrate the effectiveness and superiority of our network over\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:09:26 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lee", "Younkwan", ""], ["Jeon", "Jihyo", ""], ["Yu", "Jongmin", ""], ["Jeon", "Moongu", ""]]}, {"id": "2004.01355", "submitter": "Vishnu Suresh Lokhande", "authors": "Vishnu Suresh Lokhande, Aditya Kumar Akash, Sathya N. Ravi and Vikas\n  Singh", "title": "FairALM: Augmented Lagrangian Method for Training Fair Models with\n  Little Regret", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic decision making based on computer vision and machine learning\ntechnologies continue to permeate our lives. But issues related to biases of\nthese models and the extent to which they treat certain segments of the\npopulation unfairly, have led to concern in the general public. It is now\naccepted that because of biases in the datasets we present to the models, a\nfairness-oblivious training will lead to unfair models. An interesting topic is\nthe study of mechanisms via which the de novo design or training of the model\ncan be informed by fairness measures. Here, we study mechanisms that impose\nfairness concurrently while training the model. While existing fairness based\napproaches in vision have largely relied on training adversarial modules\ntogether with the primary classification/regression task, in an effort to\nremove the influence of the protected attribute or variable, we show how ideas\nbased on well-known optimization concepts can provide a simpler alternative. In\nour proposed scheme, imposing fairness just requires specifying the protected\nattribute and utilizing our optimization routine. We provide a detailed\ntechnical analysis and present experiments demonstrating that various fairness\nmeasures from the literature can be reliably imposed on a number of training\ntasks in vision in a manner that is interpretable.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:18:53 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 00:17:37 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lokhande", "Vishnu Suresh", ""], ["Akash", "Aditya Kumar", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "2004.01358", "submitter": "Wenjing Fang", "authors": "Wenjing Fang, Jun Zhou, Xiaolong Li, and Kenny Q. Zhu", "title": "Unpack Local Model Interpretation for GBDT", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A gradient boosting decision tree (GBDT), which aggregates a collection of\nsingle weak learners (i.e. decision trees), is widely used for data mining\ntasks. Because GBDT inherits the good performance from its ensemble essence,\nmuch attention has been drawn to the optimization of this model. With its\npopularization, an increasing need for model interpretation arises. Besides the\ncommonly used feature importance as a global interpretation, feature\ncontribution is a local measure that reveals the relationship between a\nspecific instance and the related output. This work focuses on the local\ninterpretation and proposes an unified computation mechanism to get the\ninstance-level feature contributions for GBDT in any version. Practicality of\nthis mechanism is validated by the listed experiments as well as applications\nin real industry scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:25:07 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fang", "Wenjing", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Zhu", "Kenny Q.", ""]]}, {"id": "2004.01369", "submitter": "Rong Yan", "authors": "Rong Yan and Guangchao Geng and Quanyuan Jiang", "title": "Data-Driven Transient Stability Boundary Generation for Online Security\n  Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient stability boundary (TSB) is an important tool in power system\nonline security monitoring, but practically it suffers from high computational\nburden using state-of-the-art methods, such as time-domain simulation (TDS),\nwith numerous scenarios taken into account (e.g., operating points (OPs) and\nN-1 contingencies). The purpose of this work is to establish a data-driven\nframework to generate sufficient critical samples close to the boundary within\na limited time, covering all critical scenarios in current OP. Therefore,\naccurate TSB can be periodically refreshed by tracking current OP in time. The\nidea is to develop a search strategy to obtain more data samples near the\nstability boundary, while traverse the rest part with fewer samples. To achieve\nthis goal, a specially designed transient index sensitivity based search\nstrategy and critical scenarios selection mechanism are proposed, in order to\nfind out the most representative scenarios and periodically update TSB for\nonline monitoring. Two case studies validate effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 04:45:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Yan", "Rong", ""], ["Geng", "Guangchao", ""], ["Jiang", "Quanyuan", ""]]}, {"id": "2004.01375", "submitter": "Tingyi Wanyan", "authors": "Tingyi Wanyan, Chenwei Zhang, Ariful Azad, Xiaomin Liang, Daifeng Li,\n  Ying Ding", "title": "Attribute2vec: Deep Network Embedding Through Multi-Filtering GCN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-filtering Graph Convolution Neural Network (GCN) framework\nfor network embedding task. It uses multiple local GCN filters to do feature\nextraction in every propagation layer. We show this approach could capture\ndifferent important aspects of node features against the existing attribute\nembedding based method. We also show that with multi-filtering GCN approach, we\ncan achieve significant improvement against baseline methods when training data\nis limited. We also perform many empirical experiments and demonstrate the\nbenefit of using multiple filters against single filter as well as most current\nexisting network embedding methods for both the link prediction and node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:06:16 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Wanyan", "Tingyi", ""], ["Zhang", "Chenwei", ""], ["Azad", "Ariful", ""], ["Liang", "Xiaomin", ""], ["Li", "Daifeng", ""], ["Ding", "Ying", ""]]}, {"id": "2004.01376", "submitter": "Matthew Engelhard", "authors": "Matthew Engelhard, Samuel Berchuck, Joshua D'Arcy, Ricardo Henao", "title": "Neural Conditional Event Time Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event time models predict occurrence times of an event of interest based on\nknown features. Recent work has demonstrated that neural networks achieve\nstate-of-the-art event time predictions in a variety of settings. However,\nstandard event time models suppose that the event occurs, eventually, in all\ncases. Consequently, no distinction is made between a) the probability of event\noccurrence, and b) the predicted time of occurrence. This distinction is\ncritical when predicting medical diagnoses, equipment defects, social media\nposts, and other events that or may not occur, and for which the features\naffecting a) may be different from those affecting b). In this work, we develop\na conditional event time model that distinguishes between these components,\nimplement it as a neural network with a binary stochastic layer representing\nfinite event occurrence, and show how it may be learned from right-censored\nevent times via maximum likelihood estimation. Results demonstrate superior\nevent occurrence and event time predictions on synthetic data, medical events\n(MIMIC-III), and social media posts (Reddit), comprising 21 total prediction\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:08:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Engelhard", "Matthew", ""], ["Berchuck", "Samuel", ""], ["D'Arcy", "Joshua", ""], ["Henao", "Ricardo", ""]]}, {"id": "2004.01377", "submitter": "Da Li", "authors": "Da Li, Yongxin Yang, Yi-Zhe Song and Timothy Hospedales", "title": "Sequential Learning for Domain Generalization", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a sequential learning framework for Domain\nGeneralization (DG), the problem of training a model that is robust to domain\nshift by design. Various DG approaches have been proposed with different\nmotivating intuitions, but they typically optimize for a single step of domain\ngeneralization -- training on one set of domains and generalizing to one other.\nOur sequential learning is inspired by the idea lifelong learning, where\naccumulated experience means that learning the $n^{th}$ thing becomes easier\nthan the $1^{st}$ thing. In DG this means encountering a sequence of domains\nand at each step training to maximise performance on the next domain. The\nperformance at domain $n$ then depends on the previous $n-1$ learning problems.\nThus backpropagating through the sequence means optimizing performance not just\nfor the next domain, but all following domains. Training on all such sequences\nof domains provides dramatically more `practice' for a base DG learner compared\nto existing approaches, thus improving performance on a true testing domain.\nThis strategy can be instantiated for different base DG algorithms, but we\nfocus on its application to the recently proposed Meta-Learning Domain\ngeneralization (MLDG). We show that for MLDG it leads to a simple to implement\nand fast algorithm that provides consistent performance improvement on a\nvariety of DG benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:10:33 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Li", "Da", ""], ["Yang", "Yongxin", ""], ["Song", "Yi-Zhe", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2004.01382", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Hossein Ghanei-Yakhdan, Shohreh Kasaei,\n  Kamal Nasrollahi, Thomas B. Moeslund", "title": "Effective Fusion of Deep Multitasking Representations for Robust Visual\n  Tracking", "comments": "2020 Springer. Personal use of this material is permitted. Permission\n  from Springer must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual object tracking remains an active research field in computer vision\ndue to persisting challenges with various problem-specific factors in\nreal-world scenes. Many existing tracking methods based on discriminative\ncorrelation filters (DCFs) employ feature extraction networks (FENs) to model\nthe target appearance during the learning process. However, using deep feature\nmaps extracted from FENs based on different residual neural networks (ResNets)\nhas not previously been investigated. This paper aims to evaluate the\nperformance of twelve state-of-the-art ResNet-based FENs in a DCF-based\nframework to determine the best for visual tracking purposes. First, it ranks\ntheir best feature maps and explores the generalized adoption of the best\nResNet-based FEN into another DCF-based method. Then, the proposed method\nextracts deep semantic information from a fully convolutional FEN and fuses it\nwith the best ResNet-based feature maps to strengthen the target representation\nin the learning process of continuous convolution filters. Finally, it\nintroduces a new and efficient semantic weighting method (using semantic\nsegmentation feature maps on each video frame) to reduce the drift problem.\nExtensive experimental results on the well-known OTB-2013, OTB-2015, TC-128 and\nVOT-2018 visual tracking datasets demonstrate that the proposed method\neffectively outperforms state-of-the-art methods in terms of precision and\nrobustness of visual tracking.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 05:33:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""], ["Nasrollahi", "Kamal", ""], ["Moeslund", "Thomas B.", ""]]}, {"id": "2004.01387", "submitter": "Supriyo Ghosh", "authors": "Supriyo Ghosh, Sean Laguna, Shiau Hong Lim, Laura Wynter and Hasan\n  Poonawala", "title": "A Deep Ensemble Multi-Agent Reinforcement Learning Approach for Air\n  Traffic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air traffic control is an example of a highly challenging operational problem\nthat is readily amenable to human expertise augmentation via decision support\ntechnologies. In this paper, we propose a new intelligent decision making\nframework that leverages multi-agent reinforcement learning (MARL) to\ndynamically suggest adjustments of aircraft speeds in real-time. The goal of\nthe system is to enhance the ability of an air traffic controller to provide\neffective guidance to aircraft to avoid air traffic congestion, near-miss\nsituations, and to improve arrival timeliness. We develop a novel deep ensemble\nMARL method that can concisely capture the complexity of the air traffic\ncontrol problem by learning to efficiently arbitrate between the decisions of a\nlocal kernel-based RL model and a wider-reaching deep MARL model. The proposed\nmethod is trained and evaluated on an open-source air traffic management\nsimulator developed by Eurocontrol. Extensive empirical results on a real-world\ndataset including thousands of aircraft demonstrate the feasibility of using\nmulti-agent RL for the problem of en-route air traffic control and show that\nour proposed deep ensemble MARL method significantly outperforms three\nstate-of-the-art benchmark approaches.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 06:03:53 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ghosh", "Supriyo", ""], ["Laguna", "Sean", ""], ["Lim", "Shiau Hong", ""], ["Wynter", "Laura", ""], ["Poonawala", "Hasan", ""]]}, {"id": "2004.01388", "submitter": "Shulong Li", "authors": "Chenjie Zhou MD, Jianhua Ma Ph.D, Xiaoping Xu MD, Lei Feng MD,\n  Adilijiang Yimamu MD, Xianlong Wang MD, Zhiming Li MD, Jianhua Mo MS,\n  Chengyan Huang MS, Dexia Kong MS, Yi Gao MD, Shulong Li Ph.D", "title": "Predicting the risk of pancreatic cancer with a CT-based ensemble AI\n  algorithm", "comments": "14 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: Pancreatic cancer is a lethal disease, hard to diagnose and\nusually results in poor prognosis and high mortality. Developing an artificial\nintelligence (AI) algorithm to accurately and universally predict the early\ncancer risk of all kinds of pancreatic cancer is extremely important. We\npropose an ensemble AI algorithm to predict universally cancer risk of all\nkinds of pancreatic lesions with noncontrast CT. Methods: Our algorithm\ncombines the radiomics method and a support tensor machine (STM) by the\nevidence reasoning (ER) technique to construct a binary classifier, called\nRadSTM-ER. RadSTM-ER takes advantage of the handcrafted features used in\nradiomics and learning features learned automatically by the STM from the CTs\nfor presenting better characteristics of lesions. The patient cohort consisted\nof 135 patients with pathological diagnosis results where 97 patients had\nmalignant lesions. Twenty-seven patients were randomly selected as independent\ntest samples, and the remaining patients were used in a 5-fold cross validation\nexperiment to confirm the hyperparameters, select optimal handcrafted features\nand train the model. Results: RadSTM-ER achieved independent test results: an\narea under the receiver operating characteristic curve of 0.8951, an accuracy\nof 85.19%, a sensitivity of 88.89%, a specificity of 77.78%, a positive\npredictive value of 88.89% and a negative predictive value of 77.78%.\nConclusions: These results are better than the diagnostic performance of the\nfive experimental radiologists, four conventional AI algorithms, which\ninitially demonstrate the potential of noncontrast CT-based RadSTM-ER in cancer\nrisk prediction for all kinds of pancreatic lesions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 06:06:43 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["MD", "Chenjie Zhou", ""], ["D", "Jianhua Ma Ph.", ""], ["MD", "Xiaoping Xu", ""], ["MD", "Lei Feng", ""], ["MD", "Adilijiang Yimamu", ""], ["MD", "Xianlong Wang", ""], ["MD", "Zhiming Li", ""], ["MS", "Jianhua Mo", ""], ["MS", "Chengyan Huang", ""], ["MS", "Dexia Kong", ""], ["MD", "Yi Gao", ""], ["D", "Shulong Li Ph.", ""]]}, {"id": "2004.01395", "submitter": "Binxin Ru", "authors": "Binxin Ru, Pedro Esperanca, Fabio Carlucci", "title": "Neural Architecture Generator Optimization", "comments": "20 pages, 9 figures, neural architecture search, Thirty-fourth\n  Conference on Neural Information Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) was first proposed to achieve\nstate-of-the-art performance through the discovery of new architecture\npatterns, without human intervention. An over-reliance on expert knowledge in\nthe search space design has however led to increased performance (local optima)\nwithout significant architectural breakthroughs, thus preventing truly novel\nsolutions from being reached. In this work we 1) are the first to investigate\ncasting NAS as a problem of finding the optimal network generator and 2) we\npropose a new, hierarchical and graph-based search space capable of\nrepresenting an extremely large variety of network types, yet only requiring\nfew continuous hyper-parameters. This greatly reduces the dimensionality of the\nproblem, enabling the effective use of Bayesian Optimisation as a search\nstrategy. At the same time, we expand the range of valid architectures,\nmotivating a multi-objective learning approach. We demonstrate the\neffectiveness of this strategy on six benchmark datasets and show that our\nsearch space generates extremely lightweight yet highly competitive models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 06:38:07 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:22:40 GMT"}, {"version": "v3", "created": "Sat, 2 Jan 2021 16:28:40 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Ru", "Binxin", ""], ["Esperanca", "Pedro", ""], ["Carlucci", "Fabio", ""]]}, {"id": "2004.01407", "submitter": "Ming Liang", "authors": "Ming Liang, Yao Meng, Jiyu Wang, David Lubkeman, Ning Lu", "title": "FeederGAN: Synthetic Feeder Generation via Deep Graph Adversarial Nets", "comments": "Accepted by IEEE Trans. on Smart Grid", "journal-ref": null, "doi": "10.1109/TSG.2020.3025259", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel, automated, generative adversarial networks (GAN)\nbased synthetic feeder generation mechanism, abbreviated as FeederGAN.\nFeederGAN digests real feeder models represented by directed graphs via a deep\nlearning framework powered by GAN and graph convolutional networks (GCN).\nInformation of a distribution feeder circuit is extracted from its model input\nfiles so that the device connectivity is mapped onto the adjacency matrix and\nthe device characteristics, such as circuit types (i.e., 3-phase, 2-phase, and\n1-phase) and component attributes (e.g., length and current ratings), are\nmapped onto the attribute matrix. Then, Wasserstein distance is used to\noptimize the GAN and GCN is used to discriminate the generated graphs from the\nactual ones. A greedy method based on graph theory is developed to reconstruct\nthe feeder using the generated adjacency and attribute matrices. Our results\nshow that the GAN generated feeders resemble the actual feeder in both topology\nand attributes verified by visual inspection and by empirical statistics\nobtained from actual distribution feeders.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 07:29:39 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:26:23 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Liang", "Ming", ""], ["Meng", "Yao", ""], ["Wang", "Jiyu", ""], ["Lubkeman", "David", ""], ["Lu", "Ning", ""]]}, {"id": "2004.01422", "submitter": "Juan Antonio P\\'erez-Ortiz", "authors": "Felipe S\\'anchez-Mart\\'inez, Juan Antonio P\\'erez-Ortiz, Rafael C.\n  Carrasco", "title": "Learning synchronous context-free grammars with multiple specialised\n  non-terminals for hierarchical phrase-based translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translation models based on hierarchical phrase-based statistical machine\ntranslation (HSMT) have shown better performances than the non-hierarchical\nphrase-based counterparts for some language pairs. The standard approach to\nHSMT learns and apply a synchronous context-free grammar with a single\nnon-terminal. The hypothesis behind the grammar refinement algorithm presented\nin this work is that this single non-terminal is overloaded, and insufficiently\ndiscriminative, and therefore, an adequate split of it into more specialised\nsymbols could lead to improved models. This paper presents a method to learn\nsynchronous context-free grammars with a huge number of initial non-terminals,\nwhich are then grouped via a clustering algorithm. Our experiments show that\nthe resulting smaller set of non-terminals correctly capture the contextual\ninformation that makes it possible to statistically significantly improve the\nBLEU score of the standard HSMT approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 08:09:07 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["S\u00e1nchez-Mart\u00ednez", "Felipe", ""], ["P\u00e9rez-Ortiz", "Juan Antonio", ""], ["Carrasco", "Rafael C.", ""]]}, {"id": "2004.01430", "submitter": "Sebastien Gros Prof.", "authors": "Sebastien Gros, Mario Zanon", "title": "Reinforcement Learning for Mixed-Integer Problems Based on MPC", "comments": "Accepted at IFAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model Predictive Control has been recently proposed as policy approximation\nfor Reinforcement Learning, offering a path towards safe and explainable\nReinforcement Learning. This approach has been investigated for Q-learning and\nactor-critic methods, both in the context of nominal Economic MPC and Robust\n(N)MPC, showing very promising results. In that context, actor-critic methods\nseem to be the most reliable approach. Many applications include a mixture of\ncontinuous and integer inputs, for which the classical actor-critic methods\nneed to be adapted. In this paper, we present a policy approximation based on\nmixed-integer MPC schemes, and propose a computationally inexpensive technique\nto generate exploration in the mixed-integer input space that ensures a\nsatisfaction of the constraints. We then propose a simple compatible advantage\nfunction approximation for the proposed policy, that allows one to build the\ngradient of the mixed-integer MPC-based policy.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 08:43:27 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Gros", "Sebastien", ""], ["Zanon", "Mario", ""]]}, {"id": "2004.01442", "submitter": "Laurent Condat", "authors": "Grigory Malinovsky, Dmitry Kovalev, Elnur Gasanov, Laurent Condat,\n  Peter Richt\\'arik", "title": "From Local SGD to Local Fixed-Point Methods for Federated Learning", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for solving optimization problems or finding saddle points of\nconvex-concave functions are fixed-point algorithms. In this work we consider\nthe generic problem of finding a fixed point of an average of operators, or an\napproximation thereof, in a distributed setting. Our work is motivated by the\nneeds of federated learning. In this context, each local operator models the\ncomputations done locally on a mobile device. We investigate two strategies to\nachieve such a consensus: one based on a fixed number of local steps, and the\nother based on randomized computations. In both cases, the goal is to limit\ncommunication of the locally-computed variables, which is often the bottleneck\nin distributed frameworks. We perform convergence analysis of both methods and\nconduct a number of experiments highlighting the benefits of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 09:24:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 17:42:08 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Malinovsky", "Grigory", ""], ["Kovalev", "Dmitry", ""], ["Gasanov", "Elnur", ""], ["Condat", "Laurent", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2004.01454", "submitter": "Yuxuan Song", "authors": "Yuxuan Song, Minkai Xu, Lantao Yu, Hao Zhou, Shuo Shao, Yong Yu", "title": "Infomax Neural Joint Source-Channel Coding via Adversarial Bit Flip", "comments": "AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Shannon theory states that it is asymptotically optimal to separate\nthe source and channel coding as two independent processes, in many practical\ncommunication scenarios this decomposition is limited by the finite bit-length\nand computational power for decoding. Recently, neural joint source-channel\ncoding (NECST) is proposed to sidestep this problem. While it leverages the\nadvancements of amortized inference and deep learning to improve the encoding\nand decoding process, it still cannot always achieve compelling results in\nterms of compression and error correction performance due to the limited\nrobustness of its learned coding networks. In this paper, motivated by the\ninherent connections between neural joint source-channel coding and discrete\nrepresentation learning, we propose a novel regularization method called\nInfomax Adversarial-Bit-Flip (IABF) to improve the stability and robustness of\nthe neural joint source-channel coding scheme. More specifically, on the\nencoder side, we propose to explicitly maximize the mutual information between\nthe codeword and data; while on the decoder side, the amortized reconstruction\nis regularized within an adversarial framework. Extensive experiments conducted\non various real-world datasets evidence that our IABF can achieve\nstate-of-the-art performances on both compression and error correction\nbenchmarks and outperform the baselines by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:00:02 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Song", "Yuxuan", ""], ["Xu", "Minkai", ""], ["Yu", "Lantao", ""], ["Zhou", "Hao", ""], ["Shao", "Shuo", ""], ["Yu", "Yong", ""]]}, {"id": "2004.01457", "submitter": "Daan Crommelin", "authors": "Daan Crommelin, Wouter Edeling", "title": "Resampling with neural networks for stochastic parameterization in\n  multiscale systems", "comments": "27 pages, 17 figures. Submitted", "journal-ref": null, "doi": "10.1016/j.physd.2021.132894", "report-no": null, "categories": "math.NA cs.LG cs.NA physics.ao-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In simulations of multiscale dynamical systems, not all relevant processes\ncan be resolved explicitly. Taking the effect of the unresolved processes into\naccount is important, which introduces the need for paramerizations. We present\na machine-learning method, used for the conditional resampling of observations\nor reference data from a fully resolved simulation. It is based on the\nprobabilistic classiffcation of subsets of reference data, conditioned on\nmacroscopic variables. This method is used to formulate a parameterization that\nis stochastic, taking the uncertainty of the unresolved scales into account. We\nvalidate our approach on the Lorenz 96 system, using two different parameter\nsettings which are challenging for parameterization methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:09:18 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Crommelin", "Daan", ""], ["Edeling", "Wouter", ""]]}, {"id": "2004.01468", "submitter": "Rayyan Ahmad Khan", "authors": "Rayyan Ahmad Khan, Muhammad Umer Anwaar and Martin Kleinsteuber", "title": "Epitomic Variational Graph Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a widely used generative model for learning\nlatent representations. Burda et al. in their seminal paper showed that\nlearning capacity of VAE is limited by over-pruning. It is a phenomenon where a\nsignificant number of latent variables fail to capture any information about\nthe input data and the corresponding hidden units become inactive. This\nadversely affects learning diverse and interpretable latent representations. As\nvariational graph autoencoder (VGAE) extends VAE for graph-structured data, it\ninherits the over-pruning problem. In this paper, we adopt a model based\napproach and propose epitomic VGAE (EVGAE),a generative variational framework\nfor graph datasets which successfully mitigates the over-pruning problem and\nalso boosts the generative ability of VGAE. We consider EVGAE to consist of\nmultiple sparse VGAE models, called epitomes, that are groups of latent\nvariables sharing the latent space. This approach aids in increasing active\nunits as epitomes compete to learn better representation of the graph data. We\nverify our claims via experiments on three benchmark datasets. Our experiments\nshow that EVGAE has a better generative ability than VGAE. Moreover, EVGAE\noutperforms VGAE on link prediction task in citation networks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 11:05:17 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 10:11:12 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 13:10:50 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Khan", "Rayyan Ahmad", ""], ["Anwaar", "Muhammad Umer", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "2004.01495", "submitter": "Usama Masood", "authors": "Charles Bales, Muhammad Nabeel, Charles N. John, Usama Masood, Haneya\n  N. Qureshi, Hasan Farooq, Iryna Posokhova, Ali Imran", "title": "Can Machine Learning Be Used to Recognize and Diagnose Coughs?", "comments": "Accepted in IEEE International Conference on E-Health and\n  Bioengineering - EHB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging wireless technologies, such as 5G and beyond, are bringing new use\ncases to the forefront, one of the most prominent being machine learning\nempowered health care. One of the notable modern medical concerns that impose\nan immense worldwide health burden are respiratory infections. Since cough is\nan essential symptom of many respiratory infections, an automated system to\nscreen for respiratory diseases based on raw cough data would have a multitude\nof beneficial research and medical applications. In literature, machine\nlearning has already been successfully used to detect cough events in\ncontrolled environments. In this paper, we present a low complexity, automated\nrecognition and diagnostic tool for screening respiratory infections that\nutilizes Convolutional Neural Networks (CNNs) to detect cough within\nenvironment audio and diagnose three potential illnesses (i.e., bronchitis,\nbronchiolitis and pertussis) based on their unique cough audio features. Both\nproposed detection and diagnosis models achieve an accuracy of over 89%, while\nalso remaining computationally efficient. Results show that the proposed system\nis successfully able to detect and separate cough events from background noise.\nMoreover, the proposed single diagnosis model is capable of distinguishing\nbetween different illnesses without the need of separate models.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 20:14:36 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 13:41:37 GMT"}, {"version": "v3", "created": "Sun, 4 Oct 2020 04:00:50 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Bales", "Charles", ""], ["Nabeel", "Muhammad", ""], ["John", "Charles N.", ""], ["Masood", "Usama", ""], ["Qureshi", "Haneya N.", ""], ["Farooq", "Hasan", ""], ["Posokhova", "Iryna", ""], ["Imran", "Ali", ""]]}, {"id": "2004.01496", "submitter": "Antoniya Shivarova", "authors": "Sven Husmann, Antoniya Shivarova, Rick Steinert", "title": "Company classification using machine learning", "comments": "16 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancements in computational power and machine learning\nalgorithms have led to vast improvements in manifold areas of research.\nEspecially in finance, the application of machine learning enables both\nresearchers and practitioners to gain new insights into financial data and\nwell-studied areas such as company classification. In our paper, we demonstrate\nthat unsupervised machine learning algorithms can be used to visualize and\nclassify company data in an economically meaningful and effective way. In\nparticular, we implement the data-driven dimension reduction and visualization\ntool t-distributed stochastic neighbor embedding (t-SNE) in combination with\nspectral clustering. The resulting company groups can then be utilized by\nexperts in the field for empirical analysis and optimal decision making. By\nproviding an exemplary out-of-sample study within a portfolio optimization\nframework, we show that the application of t-SNE and spectral clustering\nimproves the overall portfolio performance. Therefore, we introduce our\napproach to the financial community as a valuable technique in the context of\ndata analysis and company classification.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:36:27 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 08:41:06 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Husmann", "Sven", ""], ["Shivarova", "Antoniya", ""], ["Steinert", "Rick", ""]]}, {"id": "2004.01497", "submitter": "Amir Mosavi Prof", "authors": "Mojtaba Nabipour, Pooyan Nayyeri, Hamed Jabani, Amir Mosavi", "title": "Deep learning for Stock Market Prediction", "comments": "25 pages, 35 tables, 6 figures", "journal-ref": null, "doi": "10.3390/e22080840", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of stock groups' values has always been attractive and challenging\nfor shareholders. This paper concentrates on the future prediction of stock\nmarket groups. Four groups named diversified financials, petroleum,\nnon-metallic minerals and basic metals from Tehran stock exchange are chosen\nfor experimental evaluations. Data are collected for the groups based on ten\nyears of historical records. The values predictions are created for 1, 2, 5,\n10, 15, 20 and 30 days in advance. The machine learning algorithms utilized for\nprediction of future values of stock market groups. We employed Decision Tree,\nBagging, Random Forest, Adaptive Boosting (Adaboost), Gradient Boosting and\neXtreme Gradient Boosting (XGBoost), and Artificial neural network (ANN),\nRecurrent Neural Network (RNN) and Long short-term memory (LSTM). Ten technical\nindicators are selected as the inputs into each of the prediction models.\nFinally, the result of predictions is presented for each technique based on\nthree metrics. Among all the algorithms used in this paper, LSTM shows more\naccurate results with the highest model fitting ability. Also, for tree-based\nmodels, there is often an intense competition between Adaboost, Gradient\nBoosting, and XGBoost.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:50:01 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Nabipour", "Mojtaba", ""], ["Nayyeri", "Pooyan", ""], ["Jabani", "Hamed", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.01498", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Probabilistic Modelling of Price Movements for High-Frequency\n  Trading", "comments": "8 pages, 2 columns, IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent architecture for the probabilistic\nmodelling of high-frequency market prices, important for the risk management of\nautomated trading systems. Our proposed architecture incorporates probabilistic\nmixture models into deep recurrent neural networks. The resulting deep mixture\nmodels simultaneously address several practical challenges important in the\ndevelopment of automated high-frequency trading strategies that were previously\nneglected in the literature: 1) probabilistic forecasting of the price\nmovements; 2) single objective prediction of both the direction and size of the\nprice movements. We train our models on high-frequency Bitcoin market data and\nevaluate them against benchmark models obtained from the literature. We show\nthat our model outperforms the benchmark models in both a metric-based test and\nin a simulated trading scenario\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:25:40 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01499", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Recurrent Modelling of Stationary Bitcoin Price Formation Using the\n  Order Flow", "comments": "10 pages, The 19th International Conference on Artificial\n  Intelligence and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent model based on the order flow for\nthe stationary modelling of the high-frequency directional prices movements.\nThe order flow is the microsecond stream of orders arriving at the exchange,\ndriving the formation of prices seen on the price chart of a stock or currency.\nTo test the stationarity of our proposed model we train our model on data\nbefore the 2017 Bitcoin bubble period and test our model during and after the\nbubble. We show that without any retraining, the proposed model is temporally\nstable even as Bitcoin trading shifts into an extremely volatile \"bubble\ntrouble\" period. The significance of the result is shown by benchmarking\nagainst existing state-of-the-art models in the literature for modelling price\nformation using deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:13:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01502", "submitter": "JongHyeon Min", "authors": "Jonghyeon Min", "title": "Financial Market Trend Forecasting and Performance Analysis Using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial market trend forecasting method is emerging as a hot topic in\nfinancial markets today. Many challenges still currently remain, and various\nresearches related thereto have been actively conducted. Especially, recent\nresearch of neural network-based financial market trend prediction has\nattracted much attention. However, previous researches do not deal with the\nfinancial market forecasting method based on LSTM which has good performance in\ntime series data. There is also a lack of comparative analysis in the\nperformance of neural network-based prediction techniques and traditional\nprediction techniques. In this paper, we propose a financial market trend\nforecasting method using LSTM and analyze the performance with existing\nfinancial market trend forecasting methods through experiments. This method\nprepares the input data set through the data preprocessing process so as to\nreflect all the fundamental data, technical data and qualitative data used in\nthe financial data analysis, and makes comprehensive financial market analysis\nthrough LSTM. In this paper, we experiment and compare performances of existing\nfinancial market trend forecasting models, and performance according to the\nfinancial market environment. In addition, we implement the proposed method\nusing open sources and platform and forecast financial market trends using\nvarious financial data indicators.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:30:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Min", "Jonghyeon", ""]]}, {"id": "2004.01504", "submitter": "Philip Ndikum", "authors": "Philip Ndikum", "title": "Machine Learning Algorithms for Financial Asset Price Forecasting", "comments": "16 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research paper explores the performance of Machine Learning (ML)\nalgorithms and techniques that can be used for financial asset price\nforecasting. The prediction and forecasting of asset prices and returns remains\none of the most challenging and exciting problems for quantitative finance and\npractitioners alike. The massive increase in data generated and captured in\nrecent years presents an opportunity to leverage Machine Learning algorithms.\nThis study directly compares and contrasts state-of-the-art implementations of\nmodern Machine Learning algorithms on high performance computing (HPC)\ninfrastructures versus the traditional and highly popular Capital Asset Pricing\nModel (CAPM) on U.S equities data. The implemented Machine Learning models -\ntrained on time series data for an entire stock universe (in addition to\nexogenous macroeconomic variables) significantly outperform the CAPM on\nout-of-sample (OOS) test data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:14:18 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ndikum", "Philip", ""]]}, {"id": "2004.01509", "submitter": "Amir Mosavi Prof", "authors": "Amir Mosavi, Pedram Ghamisi, Yaser Faghan, Puhong Duan", "title": "Comprehensive Review of Deep Reinforcement Learning Methods and\n  Applications in Economics", "comments": "42 pages, 26 figures", "journal-ref": null, "doi": "10.20944/preprints202003.0309.v1", "report-no": null, "categories": "q-fin.ST cs.LG econ.GN q-fin.EC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity of deep reinforcement learning (DRL) methods in economics have\nbeen exponentially increased. DRL through a wide range of capabilities from\nreinforcement learning (RL) and deep learning (DL) for handling sophisticated\ndynamic business environments offers vast opportunities. DRL is characterized\nby scalability with the potential to be applied to high-dimensional problems in\nconjunction with noisy and nonlinear patterns of economic data. In this work,\nwe first consider a brief review of DL, RL, and deep RL methods in diverse\napplications in economics providing an in-depth insight into the state of the\nart. Furthermore, the architecture of DRL applied to economic applications is\ninvestigated in order to highlight the complexity, robustness, accuracy,\nperformance, computational tasks, risk constraints, and profitability. The\nsurvey results indicate that DRL can provide better performance and higher\naccuracy as compared to the traditional algorithms while facing real economic\nproblems at the presence of risk parameters and the ever-increasing\nuncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:07:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Mosavi", "Amir", ""], ["Ghamisi", "Pedram", ""], ["Faghan", "Yaser", ""], ["Duan", "Puhong", ""]]}, {"id": "2004.01525", "submitter": "Nao Tokui PhD", "authors": "Nao Tokui", "title": "Towards democratizing music production with AI-Design of Variational\n  Autoencoder-based Rhythm Generator as a DAW plugin", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been significant progress in the music generation technique\nutilizing deep learning. However, it is still hard for musicians and artists to\nuse these techniques in their daily music-making practice. This paper proposes\na Variational Autoencoder\\cite{Kingma2014}(VAE)-based rhythm generation system,\nin which musicians can train a deep learning model only by selecting target\nMIDI files, then generate various rhythms with the model. The author has\nimplemented the system as a plugin software for a DAW (Digital Audio\nWorkstation), namely a Max for Live device for Ableton Live. Selected\nprofessional/semi-professional musicians and music producers have used the\nplugin, and they proved that the plugin is a useful tool for making music\ncreatively. The plugin, source code, and demo videos are available online.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 10:50:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Tokui", "Nao", ""]]}, {"id": "2004.01546", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Sridha Sridharan, Mitchell McLaren, Darshana\n  Priyasad, Simon Denman, Clinton Fookes", "title": "Temporarily-Aware Context Modelling using Generative Adversarial\n  Networks for Speech Activity Detection", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech and Language Processing,\n  2020", "doi": "10.1109/TASLP.2020.2982297", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel framework for Speech Activity Detection (SAD).\nInspired by the recent success of multi-task learning approaches in the speech\nprocessing domain, we propose a novel joint learning framework for SAD. We\nutilise generative adversarial networks to automatically learn a loss function\nfor joint prediction of the frame-wise speech/ non-speech classifications\ntogether with the next audio segment. In order to exploit the temporal\nrelationships within the input signal, we propose a temporal discriminator\nwhich aims to ensure that the predicted signal is temporally consistent. We\nevaluate the proposed framework on multiple public benchmarks, including NIST\nOpenSAT' 17, AMI Meeting and HAVIC, where we demonstrate its capability to\noutperform state-of-the-art SAD approaches. Furthermore, our cross-database\nevaluations demonstrate the robustness of the proposed approach across\ndifferent languages, accents, and acoustic environments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:33:13 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Fernando", "Tharindu", ""], ["Sridharan", "Sridha", ""], ["McLaren", "Mitchell", ""], ["Priyasad", "Darshana", ""], ["Denman", "Simon", ""], ["Fookes", "Clinton", ""]]}, {"id": "2004.01549", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Finding Black Cat in a Coal Cellar -- Keyphrase Extraction &\n  Keyphrase-Rubric Relationship Classification from Complex Assignments", "comments": "v1 preprint. Working paper. More results to be added. Text overlap\n  with arXiv:2003.07019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diversity in content and open-ended questions are inherent in complex\nassignments across online graduate programs. The natural scale of these\nprograms poses a variety of challenges across both peer and expert feedback\nincluding rogue reviews. While the identification of relevant content and\nassociating it to predefined rubrics would simplify and improve the grading\nprocess, the research to date is still in a nascent stage. As such in this\npaper we aim to quantify the effectiveness of supervised and unsupervised\napproaches for the task for keyphrase extraction and generic/specific\nkeyphrase-rubric relationship extraction. Through this study, we find that (i)\nunsupervised MultiPartiteRank produces the best result for keyphrase extraction\n(ii) supervised SVM classifier with BERT features that offer the best\nperformance for both generic and specific keyphrase-rubric relationship\nclassification. We finally present a comprehensive analysis and derive useful\nobservations for those interested in these tasks for the future. The source\ncode is released in \\url{https://github.com/manikandan-ravikiran/cs6460-proj}.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:18:02 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 12:09:54 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 13:17:19 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2004.01559", "submitter": "Ville Vestman", "authors": "Ville Vestman, Kong Aik Lee, Tomi H. Kinnunen", "title": "Neural i-vectors", "comments": "Accepted to Odyssey 2020: The Speaker and Language Recognition\n  Workshop. Version 2 (bugfix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embeddings have been demonstrated to outperform their generative\ncounterparts, i-vectors, in recent speaker verification evaluations. To combine\nthe benefits of high performance and generative interpretation, we investigate\nthe use of deep embedding extractor and i-vector extractor in succession. To\nbundle the deep embedding extractor with an i-vector extractor, we adopt\naggregation layers inspired by the Gaussian mixture model (GMM) to the\nembedding extractor networks. The inclusion of GMM-like layer allows the\ndiscriminatively trained network to be used as a provider of sufficient\nstatistics for the i-vector extractor to extract what we call neural i-vectors.\nWe compare the deep embeddings to the proposed neural i-vectors on the Speakers\nin the Wild (SITW) and the Speaker Recognition Evaluation (SRE) 2018 and 2019\ndatasets. On the core-core condition of SITW, our deep embeddings obtain\nperformance comparative to the state-of-the-art. The neural i-vectors obtain\nabout 50% worse performance than the deep embeddings, but on the other hand\noutperform the previous i-vector approaches reported in the literature by a\nclear margin.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:29:31 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 14:47:50 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Vestman", "Ville", ""], ["Lee", "Kong Aik", ""], ["Kinnunen", "Tomi H.", ""]]}, {"id": "2004.01570", "submitter": "Vincent Margot", "authors": "Vincent Margot, George Luta", "title": "A new method to compare the interpretability of rule-based algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is becoming increasingly important for predictive model\nanalysis. Unfortunately, as remarked by many authors, there is still no\nconsensus regarding this notion. The goal of this article is to propose a\ndefinition of the notion of interpretability that allows comparisons of\nrule-based algorithms. This definition consists of three terms, each one being\nquantitatively measured with a simple formula: predictivity, stability and\nsimplicity. While predictivity has been extensively studied to measure the\naccuracy of predictive algorithms, stability is based on the Dice-Sorensen\nindex for comparing two sets of rules generated by an algorithm using two\nindependent samples. The simplicity is based on the sum of the length of the\nrules derived from the predictive model. The new measure for the\ninterpretability of a rule-based algorithm is a weighted sum of the three terms\nmentioned above. We use the new measure to compare the interpretability of\nseveral rule-based algorithms, specifically CART, RuleFit, Node Harvest,\nCovering algorithm and SIRUS for the regression case, and CART, PART and RIPPER\nfor the classification case\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:50:27 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 07:39:24 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 10:49:32 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 08:04:26 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Margot", "Vincent", ""], ["Luta", "George", ""]]}, {"id": "2004.01571", "submitter": "Antoine Baker", "authors": "Antoine Baker, Benjamin Aubin, Florent Krzakala, Lenka Zdeborov\\'a", "title": "TRAMP: Compositional Inference with TRee Approximate Message Passing", "comments": "Source code available at https://github.com/sphinxteam/tramp. For\n  some examples, see https://github.com/benjaminaubin/tramp_examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG eess.SP math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce tramp, standing for TRee Approximate Message Passing, a python\npackage for compositional inference in high-dimensional tree-structured models.\nThe package provides an unifying framework to study several approximate message\npassing algorithms previously derived for a variety of machine learning tasks\nsuch as generalized linear models, inference in multi-layer networks, matrix\nfactorization, and reconstruction using non-separable penalties. For some\nmodels, the asymptotic performance of the algorithm can be theoretically\npredicted by the state evolution, and the measurements entropy estimated by the\nfree entropy formalism. The implementation is modular by design: each module,\nwhich implements a factor, can be composed at will with other modules to solve\ncomplex inference tasks. The user only needs to declare the factor graph of the\nmodel: the inference algorithm, state evolution and entropy estimation are\nfully automated.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:51:10 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 11:27:59 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Baker", "Antoine", ""], ["Aubin", "Benjamin", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2004.01580", "submitter": "Wen-Hao Chiang", "authors": "Wen-Hao Chiang and George Mohler", "title": "Hawkes Process Multi-armed Bandits for Disaster Search and Rescue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework for integrating Hawkes processes with\nmulti-armed bandit algorithms to solve spatio-temporal event forecasting and\ndetection problems when data may be undersampled or spatially biased. In\nparticular, we introduce an upper confidence bound algorithm using Bayesian\nspatial Hawkes process estimation for balancing the tradeoff between exploiting\ngeographic regions where data has been collected and exploring geographic\nregions where data is unobserved. We first validate our model using simulated\ndata and then apply it to the problem of disaster search and rescue using calls\nfor service data from hurricane Harvey in 2017. Our model outperforms the state\nof the art baseline spatial MAB algorithms in terms of cumulative reward and\nseveral other ranking evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:05:09 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Chiang", "Wen-Hao", ""], ["Mohler", "George", ""]]}, {"id": "2004.01582", "submitter": "Qilei Chen", "authors": "Alexander Ding, Qilei Chen, Yu Cao, Benyuan Liu", "title": "Retinopathy of Prematurity Stage Diagnosis Using Object Segmentation and\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retinopathy of Prematurity (ROP) is an eye disorder primarily affecting\npremature infants with lower weights. It causes proliferation of vessels in the\nretina and could result in vision loss and, eventually, retinal detachment,\nleading to blindness. While human experts can easily identify severe stages of\nROP, the diagnosis of earlier stages, which are the most relevant to\ndetermining treatment choice, are much more affected by variability in\nsubjective interpretations of human experts. In recent years, there has been a\nsignificant effort to automate the diagnosis using deep learning. This paper\nbuilds upon the success of previous models and develops a novel architecture,\nwhich combines object segmentation and convolutional neural networks (CNN) to\nconstruct an effective classifier of ROP stages 1-3 based on neonatal retinal\nimages. Motivated by the fact that the formation and shape of a demarcation\nline in the retina is the distinguishing feature between earlier ROP stages,\nour proposed system first trains an object segmentation model to identify the\ndemarcation line at a pixel level and adds the resulting mask as an additional\n\"color\" channel in the original image. Then, the system trains a CNN classifier\nbased on the processed images to leverage information from both the original\nimage and the mask, which helps direct the model's attention to the demarcation\nline. In a number of careful experiments comparing its performance to previous\nobject segmentation systems and CNN-only systems trained on our dataset, our\nnovel architecture significantly outperforms previous systems in accuracy,\ndemonstrating the effectiveness of our proposed pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:07:41 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ding", "Alexander", ""], ["Chen", "Qilei", ""], ["Cao", "Yu", ""], ["Liu", "Benyuan", ""]]}, {"id": "2004.01584", "submitter": "Aristeidis Panos", "authors": "Constantinos Daskalakis, Petros Dellaportas, Aristeidis Panos", "title": "Scalable Gaussian Processes, with Guarantees: Kernel Approximations and\n  Deep Feature Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide approximation guarantees for a linear-time inferential framework\nfor Gaussian processes, using two low-rank kernel approximations based on\nrandom Fourier features and truncation of Mercer expansions. In particular, we\nbound the Kullback-Leibler divergence between the idealized Gaussian process\nand the one resulting from a low-rank approximation to its kernel.\nAdditionally, we present strong evidence that these two approximations,\nenhanced by an initial automatic feature extraction through deep neural\nnetworks, outperform a broad range of state-of-the-art methods in terms of time\nefficiency, negative log-predictive density, and root mean squared error.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:15:10 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:15:32 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 21:59:40 GMT"}, {"version": "v4", "created": "Tue, 3 Nov 2020 23:01:20 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Daskalakis", "Constantinos", ""], ["Dellaportas", "Petros", ""], ["Panos", "Aristeidis", ""]]}, {"id": "2004.01589", "submitter": "Kimmo Kartasalo", "authors": "Peter Str\\\"om (1), Kimmo Kartasalo (1,2), Pekka Ruusuvuori (2,3),\n  Henrik Gr\\\"onberg (1,4), Hemamali Samaratunga (5), Brett Delahunt (6),\n  Toyonori Tsuzuki (7), Lars Egevad (8), Martin Eklund (1) ((1) Department of\n  Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm,\n  Sweden, (2) Faculty of Medicine and Health Technology, Tampere University,\n  Tampere, Finland, (3) Institute of Biomedicine, University of Turku, Turku,\n  Finland, (4) Department of Oncology, St G\\\"oran Hospital, Stockholm, Sweden,\n  (5) Aquesta Uropathology and University of Queensland, Brisbane, Qld,\n  Australia, (6) Department of Pathology and Molecular Medicine, Wellington\n  School of Medicine and Health Sciences, University of Otago, Wellington, New\n  Zealand, (7) Department of Surgical Pathology, School of Medicine, Aichi\n  Medical University, Nagoya, Japan, (8) Department of Oncology and Pathology,\n  Karolinska Institutet, Stockholm, Sweden)", "title": "Detection of Perineural Invasion in Prostate Needle Biopsies with Deep\n  Neural Networks", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The detection of perineural invasion (PNI) by carcinoma in\nprostate biopsies has been shown to be associated with poor prognosis. The\nassessment and quantification of PNI is; however, labor intensive. In the study\nwe aimed to develop an algorithm based on deep neural networks to aid\npathologists in this task.\n  Methods: We collected, digitized and pixel-wise annotated the PNI findings in\neach of the approximately 80,000 biopsy cores from the 7,406 men who underwent\nbiopsy in the prospective and diagnostic STHLM3 trial between 2012 and 2014. In\ntotal, 485 biopsy cores showed PNI. We also digitized more than 10% (n=8,318)\nof the PNI negative biopsy cores. Digitized biopsies from a random selection of\n80% of the men were used to build deep neural networks, and the remaining 20%\nwere used to evaluate the performance of the algorithm.\n  Results: For the detection of PNI in prostate biopsy cores the network had an\nestimated area under the receiver operating characteristics curve of 0.98 (95%\nCI 0.97-0.99) based on 106 PNI positive cores and 1,652 PNI negative cores in\nthe independent test set. For the pre-specified operating point this translates\nto sensitivity of 0.87 and specificity of 0.97. The corresponding positive and\nnegative predictive values were 0.67 and 0.99, respectively. For localizing the\nregions of PNI within a slide we estimated an average intersection over union\nof 0.50 (CI: 0.46-0.55).\n  Conclusion: We have developed an algorithm based on deep neural networks for\ndetecting PNI in prostate biopsies with apparently acceptable diagnostic\nproperties. These algorithms have the potential to aid pathologists in the\nday-to-day work by drastically reducing the number of biopsy cores that need to\nbe assessed for PNI and by highlighting regions of diagnostic interest.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:27:53 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Str\u00f6m", "Peter", ""], ["Kartasalo", "Kimmo", ""], ["Ruusuvuori", "Pekka", ""], ["Gr\u00f6nberg", "Henrik", ""], ["Samaratunga", "Hemamali", ""], ["Delahunt", "Brett", ""], ["Tsuzuki", "Toyonori", ""], ["Egevad", "Lars", ""], ["Eklund", "Martin", ""]]}, {"id": "2004.01602", "submitter": "David F. Nettleton", "authors": "David F. Nettleton, Dimitrios Katsantonis, Argyris Kalaitzidis, Natasa\n  Sarafijanovic-Djukic, Pau Puigdollers and Roberto Confalonieri", "title": "Predicting rice blast disease: machine learning versus process based\n  models", "comments": null, "journal-ref": "BMC Bioinformatics volume 20, Article number: 514 (2019)", "doi": "10.1186/s12859-019-3065-1", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rice is the second most important cereal crop worldwide, and the first in\nterms of number of people who depend on it as a major staple food. Rice blast\ndisease is the most important biotic constraint of rice cultivation causing\neach year millions of dollars of losses. Despite the efforts for breeding new\nresistant varieties, agricultural practices and chemical control are still the\nmost important methods for disease management. Thus, rice blast forecasting is\na primary tool to support rice growers in controlling the disease. In this\nstudy, we compared four models for predicting rice blast disease, two\noperational process-based models (Yoshino and WARM) and two approaches based on\nmachine learning algorithms (M5Rules and RNN), the former inducing a rule-based\nmodel and the latter building a neural network. In situ telemetry is important\nto obtain quality in-field data for predictive models and this was a key aspect\nof the RICE-GUARD project on which this study is based. According to the\nauthors, this is the first time process-based and machine learning modelling\napproaches for supporting plant disease management are compared.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:48:14 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Nettleton", "David F.", ""], ["Katsantonis", "Dimitrios", ""], ["Kalaitzidis", "Argyris", ""], ["Sarafijanovic-Djukic", "Natasa", ""], ["Puigdollers", "Pau", ""], ["Confalonieri", "Roberto", ""]]}, {"id": "2004.01603", "submitter": "Kieran Woodward Mr", "authors": "Kieran Woodward, Eiman Kanjo, David J. Brown and T.M. McGinnity", "title": "On-Device Transfer Learning for Personalising Psychological Stress\n  Modelling using a Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress is a growing concern in modern society adversely impacting the wider\npopulation more than ever before. The accurate inference of stress may result\nin the possibility for personalised interventions. However, individual\ndifferences between people limits the generalisability of machine learning\nmodels to infer emotions as people's physiology when experiencing the same\nemotions widely varies. In addition, it is time consuming and extremely\nchallenging to collect large datasets of individuals' emotions as it relies on\nusers labelling sensor data in real-time for extended periods. We propose the\ndevelopment of a personalised, cross-domain 1D CNN by utilising transfer\nlearning from an initial base model trained using data from 20 participants\ncompleting a controlled stressor experiment. By utilising physiological sensors\n(HR, HRV EDA) embedded within edge computing interfaces that additionally\ncontain a labelling technique, it is possible to collect a small real-world\npersonal dataset that can be used for on-device transfer learning to improve\nmodel personalisation and cross-domain performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:48:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Woodward", "Kieran", ""], ["Kanjo", "Eiman", ""], ["Brown", "David J.", ""], ["McGinnity", "T. M.", ""]]}, {"id": "2004.01608", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Paulo R. de O. da Costa, Jason Rhuggenaath, Yingqian Zhang, Alp Akcay", "title": "Learning 2-opt Heuristics for the Traveling Salesman Problem via Deep\n  Reinforcement Learning", "comments": "To appear in Proceedings Machine Learning Research - ACML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works using deep learning to solve the Traveling Salesman Problem\n(TSP) have focused on learning construction heuristics. Such approaches find\nTSP solutions of good quality but require additional procedures such as beam\nsearch and sampling to improve solutions and achieve state-of-the-art\nperformance. However, few studies have focused on improvement heuristics, where\na given solution is improved until reaching a near-optimal one. In this work,\nwe propose to learn a local search heuristic based on 2-opt operators via deep\nreinforcement learning. We propose a policy gradient algorithm to learn a\nstochastic policy that selects 2-opt operations given a current solution.\nMoreover, we introduce a policy neural network that leverages a pointing\nattention mechanism, which unlike previous works, can be easily extended to\nmore general k-opt moves. Our results show that the learned policies can\nimprove even over random initial solutions and approach near-optimal solutions\nat a faster rate than previous state-of-the-art deep learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:51:54 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 09:50:53 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 16:20:13 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "Jason", ""], ["Zhang", "Yingqian", ""], ["Akcay", "Alp", ""]]}, {"id": "2004.01610", "submitter": "David Major", "authors": "David Major, Dimitrios Lenis, Maria Wimmer, Gert Sluiter, Astrid Berg,\n  and Katja B\\\"uhler", "title": "Interpreting Medical Image Classifiers by Optimization Based\n  Counterfactual Impact Analysis", "comments": "Accepted for publication at IEEE International Symposium on\n  Biomedical Imaging (ISBI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical applicability of automated decision support systems depends on a\nrobust, well-understood classification interpretation. Artificial neural\nnetworks while achieving class-leading scores fall short in this regard.\nTherefore, numerous approaches have been proposed that map a salient region of\nan image to a diagnostic classification. Utilizing heuristic methodology, like\nblurring and noise, they tend to produce diffuse, sometimes misleading results,\nhindering their general adoption. In this work we overcome these issues by\npresenting a model agnostic saliency mapping framework tailored to medical\nimaging. We replace heuristic techniques with a strong neighborhood conditioned\ninpainting approach, which avoids anatomically implausible artefacts. We\nformulate saliency attribution as a map-quality optimization task, enforcing\nconstrained and focused attributions. Experiments on public mammography data\nshow quantitatively and qualitatively more precise localization and clearer\nconveying results than existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:59:08 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Major", "David", ""], ["Lenis", "Dimitrios", ""], ["Wimmer", "Maria", ""], ["Sluiter", "Gert", ""], ["Berg", "Astrid", ""], ["B\u00fchler", "Katja", ""]]}, {"id": "2004.01614", "submitter": "Srinath Jayachandran", "authors": "Srinath Jayachandran, Ashlin Ghosh", "title": "Deep Transfer Learning for Texture Classification in Colorectal Cancer\n  Histology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microscopic examination of tissues or histopathology is one of the diagnostic\nprocedures for detecting colorectal cancer. The pathologist involved in such an\nexamination usually identifies tissue type based on texture analysis,\nespecially focusing on tumour-stroma ratio. In this work, we automate the task\nof tissue classification within colorectal cancer histology samples using deep\ntransfer learning. We use discriminative fine-tuning with one-cycle-policy and\napply structure-preserving colour normalization to boost our results. We also\nprovide visual explanations of the deep neural network's decision on texture\nclassification. With achieving state-of-the-art test accuracy of 96.2% we also\nembark on using deployment friendly architecture called SqueezeNet for\nmemory-limited hardware.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:05:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Jayachandran", "Srinath", ""], ["Ghosh", "Ashlin", ""]]}, {"id": "2004.01618", "submitter": "Timofey Bryksin", "authors": "Timofey Bryksin, Victor Petukhov, Ilya Alexin, Stanislav Prikhodko,\n  Alexey Shpilman, Vladimir Kovalenko, Nikita Povarov", "title": "Using Large-Scale Anomaly Detection on Code to Improve Kotlin Compiler", "comments": null, "journal-ref": null, "doi": "10.1145/3379597.3387447", "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we apply anomaly detection to source code and bytecode to\nfacilitate the development of a programming language and its compiler. We\ndefine anomaly as a code fragment that is different from typical code written\nin a particular programming language. Identifying such code fragments is\nbeneficial to both language developers and end users, since anomalies may\nindicate potential issues with the compiler or with runtime performance.\nMoreover, anomalies could correspond to problems in language design. For this\nstudy, we choose Kotlin as the target programming language. We outline and\ndiscuss approaches to obtaining vector representations of source code and\nbytecode and to the detection of anomalies across vectorized code snippets. The\npaper presents a method that aims to detect two types of anomalies: syntax tree\nanomalies and so-called compiler-induced anomalies that arise only in the\ncompiled bytecode. We describe several experiments that employ different\ncombinations of vectorization and anomaly detection techniques and discuss\ntypes of detected anomalies and their usefulness for language developers. We\ndemonstrate that the extracted anomalies and the underlying extraction\ntechnique provide additional value for language development.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:20:06 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bryksin", "Timofey", ""], ["Petukhov", "Victor", ""], ["Alexin", "Ilya", ""], ["Prikhodko", "Stanislav", ""], ["Shpilman", "Alexey", ""], ["Kovalenko", "Vladimir", ""], ["Povarov", "Nikita", ""]]}, {"id": "2004.01628", "submitter": "Adrian-Catalin Florea", "authors": "Adrian-Catalin Florea, Razvan Andonie", "title": "Weighted Random Search for Hyperparameter Optimization", "comments": "14 pages, 5 figures, journal paper", "journal-ref": "INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL, Vol\n  14, Nr. 2 (2019)", "doi": "10.15837/ijccc.2019.2.3514", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an improved version of Random Search (RS), used here for\nhyperparameter optimization of machine learning algorithms. Unlike the standard\nRS, which generates for each trial new values for all hyperparameters, we\ngenerate new values for each hyperparameter with a probability of change. The\nintuition behind our approach is that a value that already triggered a good\nresult is a good candidate for the next step, and should be tested in new\ncombinations of hyperparameter values. Within the same computational budget,\nour method yields better results than the standard RS. Our theoretical results\nprove this statement. We test our method on a variation of one of the most\ncommonly used objective function for this class of problems (the Grievank\nfunction) and for the hyperparameter optimization of a deep learning CNN\narchitecture. Our results can be generalized to any optimization problem\ndefined on a discrete domain.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 15:41:22 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Florea", "Adrian-Catalin", ""], ["Andonie", "Razvan", ""]]}, {"id": "2004.01643", "submitter": "Martin Hahner", "authors": "Martin Hahner, Dengxin Dai, Alexander Liniger, and Luc Van Gool", "title": "Quantifying Data Augmentation for LiDAR based 3D Object Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we shed light on different data augmentation techniques\ncommonly used in Light Detection and Ranging (LiDAR) based 3D Object Detection.\nWe, therefore, utilize a state of the art voxel-based 3D Object Detection\npipeline called PointPillars and carry out our experiments on the well\nestablished KITTI dataset. We investigate a variety of global and local\naugmentation techniques, where global augmentation techniques are applied to\nthe entire point cloud of a scene and local augmentation techniques are only\napplied to points belonging to individual objects in the scene. Our findings\nshow that both types of data augmentation can lead to performance increases,\nbut it also turns out, that some augmentation techniques, such as individual\nobject translation, for example, can be counterproductive and can hurt overall\nperformance. We show that when we apply our findings to the data augmentation\npolicy of PointPillars we can easily increase its performance by up to 2%. In\norder to provide reproducibility, our code will be publicly available at\nwww.trace.ethz.ch/3D_Object_Detection.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:09:14 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Hahner", "Martin", ""], ["Dai", "Dengxin", ""], ["Liniger", "Alexander", ""], ["Van Gool", "Luc", ""]]}, {"id": "2004.01646", "submitter": "Bo Peng", "authors": "Bo Peng, Zhiyun Ren, Srinivasan Parthasarathy and Xia Ning", "title": "M2: Mixed Models with Preferences, Popularities and Transitions for\n  Next-Basket Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-basket recommendation considers the problem of recommending a set of\nitems into the next basket that users will purchase as a whole. In this paper,\nwe develop a novel mixed model with preferences, popularities and transitions\n(M2) for next-basket recommendation. This method explicitly models three\nimportant factors in next-basket generation process: 1) users' general\npreferences, 2) items' global popularities and 3) transition patterns among\nitems. We also propose a simple encoder-decoder based framework (ed-Trans) to\nbetter model the transition patterns among items. We compared M2 with 5\nstate-of-the-art next-basket recommendation methods on 4 public benchmark\ndatasets. Our experimental results demonstrate that M2 significantly\noutperforms the state-of-the-art methods on all the datasets, with an\nimprovement as much as 19.0% at recall@5. We also compared M2 with these\nbaseline methods in recommending the second next and third next baskets. Our\nexperimental results demonstrate that M2 could consistently outperform the\nbaseline methods in all these tasks, with an improvement as much as 14.4% at\nrecall@5. In addition, we conducted a comprehensive ablation study to verify\nthe effects of the different factors. The results show that learning all the\nfactors together could significantly improve the recommendation performance\ncompared to learning each of them alone. The results also show that ed-Trans in\nlearning item transitions among baskets could outperform recurrent neural\nnetwork-based methods on the benchmark datasets, with an improvement as much as\n20.4% at recall@5. We also have a thorough discussion on various experimental\nprotocols and evaluation metrics for next-basket recommendation evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:11:26 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 15:32:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Peng", "Bo", ""], ["Ren", "Zhiyun", ""], ["Parthasarathy", "Srinivasan", ""], ["Ning", "Xia", ""]]}, {"id": "2004.01648", "submitter": "Manikanta Srikar Yellapragada", "authors": "Manikanta Srikar Yellapragada, Yiting Xie, Benedikt Graf, David\n  Richmond, Arun Krishnan, Arkadiusz Sitek", "title": "Deep Learning based detection of Acute Aortic Syndrome in contrast CT\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acute aortic syndrome (AAS) is a group of life threatening conditions of the\naorta. We have developed an end-to-end automatic approach to detect AAS in\ncomputed tomography (CT) images. Our approach consists of two steps. At first,\nwe extract N cross sections along the segmented aorta centerline for each CT\nscan. These cross sections are stacked together to form a new volume which is\nthen classified using two different classifiers, a 3D convolutional neural\nnetwork (3D CNN) and a multiple instance learning (MIL). We trained, validated,\nand compared two models on 2291 contrast CT volumes. We tested on a set aside\ncohort of 230 normal and 50 positive CT volumes. Our models detected AAS with\nan Area under Receiver Operating Characteristic curve (AUC) of 0.965 and 0.985\nusing 3DCNN and MIL, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:12:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Yellapragada", "Manikanta Srikar", ""], ["Xie", "Yiting", ""], ["Graf", "Benedikt", ""], ["Richmond", "David", ""], ["Krishnan", "Arun", ""], ["Sitek", "Arkadiusz", ""]]}, {"id": "2004.01653", "submitter": "Antoine Ledent", "authors": "Antoine Ledent, Rodrigo Alves, and Marius Kloft", "title": "Orthogonal Inductive Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose orthogonal inductive matrix completion (OMIC), an interpretable\napproach to inductive matrix completion based on a sum of multiple orthonormal\nside information terms, together with nuclear-norm regularization. The approach\nallows us to inject prior knowledge about the eigenvectors of the ground truth\nmatrix. We optimize the approach by a provably converging algorithm, which\noptimizes all components of the model simultaneously. Our method enjoys\ndistribution-free learning guarantees that improve with the quality of the\ninjected knowledge. As a special case of our general framework, we study a\nmodel consisting of a sum of user and item biases (generic behavior), a\nnon-inductive term (specific behavior), and (optionally) an inductive term\nusing side information. Our theoretical analysis shows that\n$\\epsilon$-recovering a ground truth matrix in $\\mathbb{R}^{m\\times n}$\nrequires at most $O\\left( \\frac{n+m+(\\sqrt{n}+\\sqrt{m})\n\\sqrt{mnr}C}{\\epsilon^2}\\right)$ entries, where $r$ (resp. $C$) is the rank\n(resp. maximum entry) of the bias-free part of the ground truth matrix. We\nanalyse the performance of OMIC on several synthetic and real datasets. On\nsynthetic datasets with a sliding scale of user bias relevance, we show that\nOMIC better adapts to different regimes than other methods. On real-life\ndatasets containing user/items recommendations and relevant side information,\nwe find that OMIC surpasses the state-of-the-art, with the added benefit of\ngreater interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:21:23 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 17:41:31 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 10:25:31 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 20:43:50 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Ledent", "Antoine", ""], ["Alves", "Rodrigo", ""], ["Kloft", "Marius", ""]]}, {"id": "2004.01655", "submitter": "Marjan Ghazvininejad", "authors": "Marjan Ghazvininejad, Vladimir Karpukhin, Luke Zettlemoyer, Omer Levy", "title": "Aligned Cross Entropy for Non-Autoregressive Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive machine translation models significantly speed up decoding\nby allowing for parallel prediction of the entire target sequence. However,\nmodeling word order is more challenging due to the lack of autoregressive\nfactors in the model. This difficultly is compounded during training with cross\nentropy loss, which can highly penalize small shifts in word order. In this\npaper, we propose aligned cross entropy (AXE) as an alternative loss function\nfor training of non-autoregressive models. AXE uses a differentiable dynamic\nprogram to assign loss based on the best possible monotonic alignment between\ntarget tokens and model predictions. AXE-based training of conditional masked\nlanguage models (CMLMs) substantially improves performance on major WMT\nbenchmarks, while setting a new state of the art for non-autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:24:47 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ghazvininejad", "Marjan", ""], ["Karpukhin", "Vladimir", ""], ["Zettlemoyer", "Luke", ""], ["Levy", "Omer", ""]]}, {"id": "2004.01689", "submitter": "Fernando Cladera Ojeda", "authors": "Anthony Bisulco, Fernando Cladera Ojeda, Volkan Isler, Daniel D. Lee", "title": "Near-chip Dynamic Vision Filtering for Low-Bandwidth Pedestrian\n  Detection", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel end-to-end system for pedestrian detection using\nDynamic Vision Sensors (DVSs). We target applications where multiple sensors\ntransmit data to a local processing unit, which executes a detection algorithm.\nOur system is composed of (i) a near-chip event filter that compresses and\ndenoises the event stream from the DVS, and (ii) a Binary Neural Network (BNN)\ndetection module that runs on a low-computation edge computing device (in our\ncase a STM32F4 microcontroller). We present the system architecture and provide\nan end-to-end implementation for pedestrian detection in an office environment.\nOur implementation reduces transmission size by up to 99.6% compared to\ntransmitting the raw event stream. The average packet size in our system is\nonly 1397 bits, while 307.2 kb are required to send an uncompressed DVS time\nwindow. Our detector is able to perform a detection every 450 ms, with an\noverall testing F1 score of 83%. The low bandwidth and energy properties of our\nsystem make it ideal for IoT applications.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:36:26 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bisulco", "Anthony", ""], ["Ojeda", "Fernando Cladera", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D.", ""]]}, {"id": "2004.01704", "submitter": "Qiwei Ye", "authors": "Yuxuan Song, Qiwei Ye, Minkai Xu, Tie-Yan Liu", "title": "Discriminator Contrastive Divergence: Semi-Amortized Generative Modeling\n  by Exploring Energy of the Discriminator", "comments": "17 pages, 9 figures, pre-submmited to cvpr2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown great promise in modeling\nhigh dimensional data. The learning objective of GANs usually minimizes some\nmeasure discrepancy, \\textit{e.g.}, $f$-divergence~($f$-GANs) or Integral\nProbability Metric~(Wasserstein GANs). With $f$-divergence as the objective\nfunction, the discriminator essentially estimates the density ratio, and the\nestimated ratio proves useful in further improving the sample quality of the\ngenerator. However, how to leverage the information contained in the\ndiscriminator of Wasserstein GANs (WGAN) is less explored. In this paper, we\nintroduce the Discriminator Contrastive Divergence, which is well motivated by\nthe property of WGAN's discriminator and the relationship between WGAN and\nenergy-based model. Compared to standard GANs, where the generator is directly\nutilized to obtain new samples, our method proposes a semi-amortized generation\nprocedure where the samples are produced with the generator's output as an\ninitial state. Then several steps of Langevin dynamics are conducted using the\ngradient of the discriminator. We demonstrate the benefits of significant\nimproved generation on both synthetic data and several real-world image\ngeneration benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 01:50:16 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Song", "Yuxuan", ""], ["Ye", "Qiwei", ""], ["Xu", "Minkai", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2004.01732", "submitter": "Kai Shu", "authors": "Kai Shu, Guoqing Zheng, Yichuan Li, Subhabrata Mukherjee, Ahmed Hassan\n  Awadallah, Scott Ruston, Huan Liu", "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "comments": "17 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:26:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Shu", "Kai", ""], ["Zheng", "Guoqing", ""], ["Li", "Yichuan", ""], ["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed Hassan", ""], ["Ruston", "Scott", ""], ["Liu", "Huan", ""]]}, {"id": "2004.01735", "submitter": "Yuhong Guo", "authors": "Kevin Hua, Yuhong Guo", "title": "Unsupervised Domain Adaptation with Progressive Domain Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to exploit a label-rich source domain for learning\nclassifiers in a different label-scarce target domain. It is particularly\nchallenging when there are significant divergences between the two domains. In\nthe paper, we propose a novel unsupervised domain adaptation method based on\nprogressive domain augmentation. The proposed method generates virtual\nintermediate domains via domain interpolation, progressively augments the\nsource domain and bridges the source-target domain divergence by conducting\nmultiple subspace alignment on the Grassmann manifold. We conduct experiments\non multiple domain adaptation tasks and the results shows the proposed method\nachieves the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:45:39 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:45:24 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hua", "Kevin", ""], ["Guo", "Yuhong", ""]]}, {"id": "2004.01738", "submitter": "Elizabeth Cole", "authors": "Elizabeth K. Cole, Joseph Y. Cheng, John M. Pauly, and Shreyas S.\n  Vasanawala", "title": "Analysis of Deep Complex-Valued Convolutional Neural Networks for MRI\n  Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world signal sources are complex-valued, having real and imaginary\ncomponents. However, the vast majority of existing deep learning platforms and\nnetwork architectures do not support the use of complex-valued data. MRI data\nis inherently complex-valued, so existing approaches discard the richer\nalgebraic structure of the complex data. In this work, we investigate\nend-to-end complex-valued convolutional neural networks - specifically, for\nimage reconstruction in lieu of two-channel real-valued networks. We apply this\nto magnetic resonance imaging reconstruction for the purpose of accelerating\nscan times and determine the performance of various promising complex-valued\nactivation functions. We find that complex-valued CNNs with complex-valued\nconvolutions provide superior reconstructions compared to real-valued\nconvolutions with the same number of trainable parameters, over a variety of\nnetwork architectures and datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:00:23 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 00:41:29 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 04:02:38 GMT"}, {"version": "v4", "created": "Tue, 12 May 2020 01:21:36 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Cole", "Elizabeth K.", ""], ["Cheng", "Joseph Y.", ""], ["Pauly", "John M.", ""], ["Vasanawala", "Shreyas S.", ""]]}, {"id": "2004.01739", "submitter": "Daron Anderson", "authors": "Daron Anderson and Douglas Leith", "title": "Universal Algorithms: Beyond the Simplex", "comments": "1 figure, 40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bulk of universal algorithms in the online convex optimisation literature\nare variants of the Hedge (exponential weights) algorithm on the simplex. While\nthese algorithms extend to polytope domains by assigning weights to the\nvertices, this process is computationally unfeasible for many important classes\nof polytopes where the number $V$ of vertices depends exponentially on the\ndimension $d$. In this paper we show the Subgradient algorithm is universal,\nmeaning it has $O(\\sqrt N)$ regret in the antagonistic setting and $O(1)$\npseudo-regret in the i.i.d setting, with two main advantages over Hedge: (1)\nThe update step is more efficient as the action vectors have length only $d$\nrather than $V$; and (2) Subgradient gives better performance if the cost\nvectors satisfy Euclidean rather than sup-norm bounds. This paper extends the\nauthors' recent results for Subgradient on the simplex. We also prove the same\n$O(\\sqrt N)$ and $O(1)$ bounds when the domain is the unit ball. To the\nauthors' knowledge this is the first instance of these bounds on a domain other\nthan a polytope.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:00:42 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Anderson", "Daron", ""], ["Leith", "Douglas", ""]]}, {"id": "2004.01743", "submitter": "Zitao Chen", "authors": "Zitao Chen, Niranjhana Narayanan, Bo Fang, Guanpeng Li, Karthik\n  Pattabiraman and Nathan DeBardeleben", "title": "TensorFI: A Flexible Fault Injection Framework for TensorFlow\n  Applications", "comments": "A preliminary version of this work was published in a workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning (ML) has seen increasing adoption in safety-critical\ndomains (e.g., autonomous vehicles), the reliability of ML systems has also\ngrown in importance. While prior studies have proposed techniques to enable\nefficient error-resilience techniques (e.g., selective instruction\nduplication), a fundamental requirement for realizing these techniques is a\ndetailed understanding of the application's resilience.\n  In this work, we present TensorFI, a high-level fault injection (FI)\nframework for TensorFlow-based applications. TensorFI is able to inject both\nhardware and software faults in general TensorFlow programs. TensorFI is a\nconfigurable FI tool that is flexible, easy to use, and portable. It can be\nintegrated into existing TensorFlow programs to assess their resilience for\ndifferent fault types (e.g., faults in particular operators). We use TensorFI\nto evaluate the resilience of 12 ML programs, including DNNs used in the\nautonomous vehicle domain. Our tool is publicly available at\nhttps://github.com/DependableSystemsLab/TensorFI.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 19:26:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chen", "Zitao", ""], ["Narayanan", "Niranjhana", ""], ["Fang", "Bo", ""], ["Li", "Guanpeng", ""], ["Pattabiraman", "Karthik", ""], ["DeBardeleben", "Nathan", ""]]}, {"id": "2004.01764", "submitter": "Nathaniel Bastian PhD", "authors": "Kathleen Kerwin and Nathaniel D. Bastian", "title": "Stacked Generalizations in Imbalanced Fraud Data Sets using Resampling\n  Methods", "comments": "19 pages, 3 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study uses stacked generalization, which is a two-step process of\ncombining machine learning methods, called meta or super learners, for\nimproving the performance of algorithms in step one (by minimizing the error\nrate of each individual algorithm to reduce its bias in the learning set) and\nthen in step two inputting the results into the meta learner with its stacked\nblended output (demonstrating improved performance with the weakest algorithms\nlearning better). The method is essentially an enhanced cross-validation\nstrategy. Although the process uses great computational resources, the\nresulting performance metrics on resampled fraud data show that increased\nsystem cost can be justified. A fundamental key to fraud data is that it is\ninherently not systematic and, as of yet, the optimal resampling methodology\nhas not been identified. Building a test harness that accounts for all\npermutations of algorithm sample set pairs demonstrates that the complex,\nintrinsic data structures are all thoroughly tested. Using a comparative\nanalysis on fraud data that applies stacked generalizations provides useful\ninsight needed to find the optimal mathematical formula to be used for\nimbalanced fraud data sets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:38:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kerwin", "Kathleen", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2004.01800", "submitter": "Ping Hu", "authors": "Ping Hu, Fabian Caba Heilbron, Oliver Wang, Zhe Lin, Stan Sclaroff and\n  Federico Perazzi", "title": "Temporally Distributed Networks for Fast Video Semantic Segmentation", "comments": "[CVPR2020] Project: https://github.com/feinanshan/TDNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TDNet, a temporally distributed network designed for fast and\naccurate video semantic segmentation. We observe that features extracted from a\ncertain high-level layer of a deep CNN can be approximated by composing\nfeatures extracted from several shallower sub-networks. Leveraging the inherent\ntemporal continuity in videos, we distribute these sub-networks over sequential\nframes. Therefore, at each time step, we only need to perform a lightweight\ncomputation to extract a sub-features group from a single sub-network. The full\nfeatures used for segmentation are then recomposed by application of a novel\nattention propagation module that compensates for geometry deformation between\nframes. A grouped knowledge distillation loss is also introduced to further\nimprove the representation power at both full and sub-feature levels.\nExperiments on Cityscapes, CamVid, and NYUD-v2 demonstrate that our method\nachieves state-of-the-art accuracy with significantly faster speed and lower\nlatency.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 22:43:32 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 00:44:51 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Hu", "Ping", ""], ["Heilbron", "Fabian Caba", ""], ["Wang", "Oliver", ""], ["Lin", "Zhe", ""], ["Sclaroff", "Stan", ""], ["Perazzi", "Federico", ""]]}, {"id": "2004.01806", "submitter": "Yeonjong Shin", "authors": "Yeonjong Shin, Jerome Darbon, George Em Karniadakis", "title": "On the convergence of physics informed neural networks for linear\n  second-order elliptic and parabolic type PDEs", "comments": null, "journal-ref": null, "doi": "10.4208/cicp.OA-2020-0193", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Physics informed neural networks (PINNs) are deep learning based techniques\nfor solving partial differential equations (PDEs) encounted in computational\nscience and engineering. Guided by data and physical laws, PINNs find a neural\nnetwork that approximates the solution to a system of PDEs. Such a neural\nnetwork is obtained by minimizing a loss function in which any prior knowledge\nof PDEs and data are encoded. Despite its remarkable empirical success in one,\ntwo or three dimensional problems, there is little theoretical justification\nfor PINNs.\n  As the number of data grows, PINNs generate a sequence of minimizers which\ncorrespond to a sequence of neural networks. We want to answer the question:\nDoes the sequence of minimizers converge to the solution to the PDE? We\nconsider two classes of PDEs: linear second-order elliptic and parabolic. By\nadapting the Schauder approach and the maximum principle, we show that the\nsequence of minimizers strongly converges to the PDE solution in $C^0$.\nFurthermore, we show that if each minimizer satisfies the initial/boundary\nconditions, the convergence mode becomes $H^1$. Computational examples are\nprovided to illustrate our theoretical findings. To the best of our knowledge,\nthis is the first theoretical work that shows the consistency of PINNs.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 22:59:25 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 19:16:36 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Shin", "Yeonjong", ""], ["Darbon", "Jerome", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2004.01819", "submitter": "Rifat Zahan", "authors": "Rifat Zahan, Ian McQuillan and Nathaniel D. Osgood", "title": "DNA Methylation Data to Predict Suicidal and Non-Suicidal Deaths: A\n  Machine Learning Approach", "comments": null, "journal-ref": "In 2018 IEEE International Conference on Healthcare Informatics\n  (ICHI) (pp. 363-365). IEEE (2018, June)", "doi": "10.1109/ICHI.2018.00057", "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this study is to predict suicidal and non-suicidal deaths\nfrom DNA methylation data using a modern machine learning algorithm. We used\nsupport vector machines to classify existing secondary data consisting of\nnormalized values of methylated DNA probe intensities from tissues of two\ncortical brain regions to distinguish suicide cases from control cases. Before\nclassification, we employed Principal component analysis (PCA) and\nt-distributed Stochastic Neighbor Embedding (t-SNE) to reduce the dimension of\nthe data. In comparison to PCA, the modern data visualization method t-SNE\nperforms better in dimensionality reduction. t-SNE accounts for the possible\nnon-linear patterns in low-dimensional data. We applied four-fold\ncross-validation in which the resulting output from t-SNE was used as training\ndata for the Support Vector Machine (SVM). Despite the use of cross-validation,\nthe nominally perfect prediction of suicidal deaths for BA11 data suggests\npossible over-fitting of the model. The study also may have suffered from\n'spectrum bias' since the individuals were only studied from two extreme\nscenarios. This research constitutes a baseline study for classifying suicidal\nand non-suicidal deaths from DNA methylation data. Future studies with larger\nsample size, while possibly incorporating methylation data from living\nindividuals, may reduce the bias and improve the accuracy of the results.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 00:34:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zahan", "Rifat", ""], ["McQuillan", "Ian", ""], ["Osgood", "Nathaniel D.", ""]]}, {"id": "2004.01822", "submitter": "Casey Chu", "authors": "Casey Chu, Kentaro Minami, Kenji Fukumizu", "title": "The equivalence between Stein variational gradient descent and black-box\n  variational inference", "comments": "ICLR 2020, Workshop on Integration of Deep Neural Models and\n  Differential Equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize an equivalence between two popular methods for Bayesian\ninference: Stein variational gradient descent (SVGD) and black-box variational\ninference (BBVI). In particular, we show that BBVI corresponds precisely to\nSVGD when the kernel is the neural tangent kernel. Furthermore, we interpret\nSVGD and BBVI as kernel gradient flows; we do this by leveraging the recent\nperspective that views SVGD as a gradient flow in the space of probability\ndistributions and showing that BBVI naturally motivates a Riemannian structure\non that space. We observe that kernel gradient flow also describes dynamics\nfound in the training of generative adversarial networks (GANs). This work\nthereby unifies several existing techniques in variational inference and\ngenerative modeling and identifies the kernel as a fundamental object governing\nthe behavior of these algorithms, motivating deeper analysis of its properties.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 00:39:12 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chu", "Casey", ""], ["Minami", "Kentaro", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "2004.01823", "submitter": "Andr\\'es Mu\\~noz Garza", "authors": "Andres Munoz, Mohammadreza Zolfaghari, Max Argus and Thomas Brox", "title": "Temporal Shift GAN for Large Scale Video Generation", "comments": "14 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video generation models have become increasingly popular in the last few\nyears, however the standard 2D architectures used today lack natural\nspatio-temporal modelling capabilities. In this paper, we present a network\narchitecture for video generation that models spatio-temporal consistency\nwithout resorting to costly 3D architectures. The architecture facilitates\ninformation exchange between neighboring time points, which improves the\ntemporal consistency of both the high level structure as well as the low-level\ndetails of the generated frames. The approach achieves state-of-the-art\nquantitative performance, as measured by the inception score on the UCF-101\ndataset as well as better qualitative results. We also introduce a new\nquantitative measure (S3) that uses downstream tasks for evaluation. Moreover,\nwe present a new multi-label dataset MaisToy, which enables us to evaluate the\ngeneralization of the model.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 00:40:52 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 19:46:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Munoz", "Andres", ""], ["Zolfaghari", "Mohammadreza", ""], ["Argus", "Max", ""], ["Brox", "Thomas", ""]]}, {"id": "2004.01832", "submitter": "Avery Ma", "authors": "Avery Ma, Fartash Faghri, Nicolas Papernot, Amir-massoud Farahmand", "title": "SOAR: Second-Order Adversarial Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is a common approach to improving the robustness of deep\nneural networks against adversarial examples. In this work, we propose a novel\nregularization approach as an alternative. To derive the regularizer, we\nformulate the adversarial robustness problem under the robust optimization\nframework and approximate the loss function using a second-order Taylor series\nexpansion. Our proposed second-order adversarial regularizer (SOAR) is an upper\nbound based on the Taylor approximation of the inner-max in the robust\noptimization objective. We empirically show that the proposed method\nsignificantly improves the robustness of networks against the $\\ell_\\infty$ and\n$\\ell_2$ bounded perturbations generated using cross-entropy-based PGD on\nCIFAR-10 and SVHN.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 01:35:07 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 22:52:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Ma", "Avery", ""], ["Faghri", "Fartash", ""], ["Papernot", "Nicolas", ""], ["Farahmand", "Amir-massoud", ""]]}, {"id": "2004.01840", "submitter": "Pragya Sur", "authors": "Cynthia Dwork, Christina Ilvento, Guy N. Rothblum, Pragya Sur", "title": "Abstracting Fairness: Oracles, Metrics, and Interpretability", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well understood that classification algorithms, for example, for\ndeciding on loan applications, cannot be evaluated for fairness without taking\ncontext into account. We examine what can be learned from a fairness oracle\nequipped with an underlying understanding of ``true'' fairness. The oracle\ntakes as input a (context, classifier) pair satisfying an arbitrary fairness\ndefinition, and accepts or rejects the pair according to whether the classifier\nsatisfies the underlying fairness truth. Our principal conceptual result is an\nextraction procedure that learns the underlying truth; moreover, the procedure\ncan learn an approximation to this truth given access to a weak form of the\noracle. Since every ``truly fair'' classifier induces a coarse metric, in which\nthose receiving the same decision are at distance zero from one another and\nthose receiving different decisions are at distance one, this extraction\nprocess provides the basis for ensuring a rough form of metric fairness, also\nknown as individual fairness. Our principal technical result is a higher\nfidelity extractor under a mild technical constraint on the weak oracle's\nconception of fairness. Our framework permits the scenario in which many\nclassifiers, with differing outcomes, may all be considered fair. Our results\nhave implications for interpretablity -- a highly desired but poorly defined\nproperty of classification systems that endeavors to permit a human arbiter to\nreject classifiers deemed to be ``unfair'' or illegitimately derived.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 03:14:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dwork", "Cynthia", ""], ["Ilvento", "Christina", ""], ["Rothblum", "Guy N.", ""], ["Sur", "Pragya", ""]]}, {"id": "2004.01857", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Milad Sikaroudi, H.R. Tizhoosh, Fakhri Karray, Mark\n  Crowley", "title": "Weighted Fisher Discriminant Analysis in the Input and Feature Spaces", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 3-15. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_1", "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fisher Discriminant Analysis (FDA) is a subspace learning method which\nminimizes and maximizes the intra- and inter-class scatters of data,\nrespectively. Although, in FDA, all the pairs of classes are treated the same\nway, some classes are closer than the others. Weighted FDA assigns weights to\nthe pairs of classes to address this shortcoming of FDA. In this paper, we\npropose a cosine-weighted FDA as well as an automatically weighted FDA in which\nweights are found automatically. We also propose a weighted FDA in the feature\nspace to establish a weighted kernel FDA for both existing and newly proposed\nweights. Our experiments on the ORL face recognition dataset show the\neffectiveness of the proposed weighting schemes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:17:53 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Sikaroudi", "Milad", ""], ["Tizhoosh", "H. R.", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.01862", "submitter": "Pengtao Xie", "authors": "Yuxiao Liang, Pengtao Xie", "title": "Identifying Radiological Findings Related to COVID-19 from Medical\n  Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease 2019 (COVID-19) has infected more than one million\nindividuals all over the world and caused more than 55,000 deaths, as of April\n3 in 2020. Radiological findings are important sources of information in\nguiding the diagnosis and treatment of COVID-19. However, the existing studies\non how radiological findings are correlated with COVID-19 are conducted\nseparately by different hospitals, which may be inconsistent or even\nconflicting due to population bias. To address this problem, we develop natural\nlanguage processing methods to analyze a large collection of COVID-19\nliterature containing study reports from hospitals all over the world,\nreconcile these results, and draw unbiased and universally-sensible conclusions\nabout the correlation between radiological findings and COVID-19. We apply our\nmethod to the CORD-19 dataset and successfully extract a set of radiological\nfindings that are closely tied to COVID-19.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:33:21 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Liang", "Yuxiao", ""], ["Xie", "Pengtao", ""]]}, {"id": "2004.01864", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Theoretical Insights into the Use of Structural Similarity Index In\n  Generative Models and Inferential Autoencoders", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 112-117. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_10", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models and inferential autoencoders mostly make use of $\\ell_2$\nnorm in their optimization objectives. In order to generate perceptually better\nimages, this short paper theoretically discusses how to use Structural\nSimilarity Index (SSIM) in generative models and inferential autoencoders. We\nfirst review SSIM, SSIM distance metrics, and SSIM kernel. We show that the\nSSIM kernel is a universal kernel and thus can be used in unconditional and\nconditional generated moment matching networks. Then, we explain how to use\nSSIM distance in variational and adversarial autoencoders and unconditional and\nconditional Generative Adversarial Networks (GANs). Finally, we propose to use\nSSIM distance rather than $\\ell_2$ norm in least squares GAN.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:39:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.01875", "submitter": "Nadir Murru", "authors": "Nadir Murru, Rosaria Rossini", "title": "A Bayesian approach for initialization of weights in backpropagation\n  neural net with application to character recognition", "comments": null, "journal-ref": "Neurocomputing, Vol. 193, 92-105, 2016", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence rate of training algorithms for neural networks is heavily\naffected by initialization of weights. In this paper, an original algorithm for\ninitialization of weights in backpropagation neural net is presented with\napplication to character recognition. The initialization method is mainly based\non a customization of the Kalman filter, translating it into Bayesian\nstatistics terms. A metrological approach is used in this context considering\nweights as measurements modeled by mutually dependent normal random variables.\nThe algorithm performance is demonstrated by reporting and discussing results\nof simulation trials. Results are compared with random weights initialization\nand other methods. The proposed method shows an improved convergence rate for\nthe backpropagation training algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 06:42:07 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Murru", "Nadir", ""], ["Rossini", "Rosaria", ""]]}, {"id": "2004.01881", "submitter": "Congying Xia", "authors": "Congying Xia, Chenwei Zhang, Hoang Nguyen, Jiawei Zhang, Philip Yu", "title": "CG-BERT: Conditional Text Generation with BERT for Generalized Few-shot\n  Intent Detection", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate a more realistic and difficult problem setup for\nthe intent detection task in natural language understanding, namely Generalized\nFew-Shot Intent Detection (GFSID). GFSID aims to discriminate a joint label\nspace consisting of both existing intents which have enough labeled data and\nnovel intents which only have a few examples for each class. To approach this\nproblem, we propose a novel model, Conditional Text Generation with BERT\n(CG-BERT). CG-BERT effectively leverages a large pre-trained language model to\ngenerate text conditioned on the intent label. By modeling the utterance\ndistribution with variational inference, CG-BERT can generate diverse\nutterances for the novel intents even with only a few utterances available.\nExperimental results show that CG-BERT achieves state-of-the-art performance on\nthe GFSID task with 1-shot and 5-shot settings on two real-world datasets.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 07:31:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Xia", "Congying", ""], ["Zhang", "Chenwei", ""], ["Nguyen", "Hoang", ""], ["Zhang", "Jiawei", ""], ["Yu", "Philip", ""]]}, {"id": "2004.01893", "submitter": "Neeraj Bokde", "authors": "Neeraj Dhanraj Bokde and Zaher Mundher Yaseen and Gorm Bruun Andersen", "title": "ForecastTB An R Package as a Test-Bench for Time Series Forecasting\n  Application of Wind Speed and Solar Radiation Modeling", "comments": "Published in Energies", "journal-ref": "2020", "doi": "10.3390/en13102578", "report-no": null, "categories": "stat.ME cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces an R package ForecastTB that can be used to compare the\naccuracy of different forecasting methods as related to the characteristics of\na time series dataset. The ForecastTB is a plug-and-play structured module, and\nseveral forecasting methods can be included with simple instructions. The\nproposed test-bench is not limited to the default forecasting and error metric\nfunctions, and users are able to append, remove, or choose the desired methods\nas per requirements. Besides, several plotting functions and statistical\nperformance metrics are provided to visualize the comparative performance and\naccuracy of different forecasting methods. Furthermore, this paper presents\nreal application examples with natural time series datasets (i.e., wind speed\nand solar radiation) to exhibit the features of the ForecastTB package to\nevaluate forecasting comparison analysis as affected by the characteristics of\na dataset. Modeling results indicated the applicability and robustness of the\nproposed R package ForecastTB for time series forecasting.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 08:52:19 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 13:49:21 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Bokde", "Neeraj Dhanraj", ""], ["Yaseen", "Zaher Mundher", ""], ["Andersen", "Gorm Bruun", ""]]}, {"id": "2004.01899", "submitter": "Xuefei Ning", "authors": "Xuefei Ning, Yin Zheng, Tianchen Zhao, Yu Wang, and Huazhong Yang", "title": "A Generic Graph-based Neural Architecture Encoding Scheme for\n  Predictor-based NAS", "comments": "14 pages main text; 10 pages appendix", "journal-ref": "ECCV 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes a novel Graph-based neural ArchiTecture Encoding Scheme,\na.k.a. GATES, to improve the predictor-based neural architecture search.\nSpecifically, different from existing graph-based schemes, GATES models the\noperations as the transformation of the propagating information, which mimics\nthe actual data processing of neural architecture. GATES is a more reasonable\nmodeling of the neural architectures, and can encode architectures from both\nthe \"operation on node\" and \"operation on edge\" cell search spaces\nconsistently. Experimental results on various search spaces confirm GATES's\neffectiveness in improving the performance predictor. Furthermore, equipped\nwith the improved performance predictor, the sample efficiency of the\npredictor-based neural architecture search (NAS) flow is boosted. Codes are\navailable at https://github.com/walkerning/aw_nas.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 09:54:49 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 03:19:33 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2020 01:06:51 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ning", "Xuefei", ""], ["Zheng", "Yin", ""], ["Zhao", "Tianchen", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2004.01902", "submitter": "Nicolas Boull\\'e", "authors": "Nicolas Boull\\'e, Yuji Nakatsukasa, Alex Townsend", "title": "Rational neural networks", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider neural networks with rational activation functions. The choice of\nthe nonlinear activation function in deep learning architectures is crucial and\nheavily impacts the performance of a neural network. We establish optimal\nbounds in terms of network complexity and prove that rational neural networks\napproximate smooth functions more efficiently than ReLU networks with\nexponentially smaller depth. The flexibility and smoothness of rational\nactivation functions make them an attractive alternative to ReLU, as we\ndemonstrate with numerical experiments.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 10:36:11 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 09:16:55 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Nakatsukasa", "Yuji", ""], ["Townsend", "Alex", ""]]}, {"id": "2004.01907", "submitter": "Dianbo Sui", "authors": "Dianbo Sui, Yubo Chen, Binjie Mao, Delai Qiu, Kang Liu and Jun Zhao", "title": "Knowledge Guided Metric Learning for Few-Shot Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of deep-learning-based text classification models relies heavily\non a huge amount of annotation data, which is difficult to obtain. When the\nlabeled data is scarce, models tend to struggle to achieve satisfactory\nperformance. However, human beings can distinguish new categories very\nefficiently with few examples. This is mainly due to the fact that human beings\ncan leverage knowledge obtained from relevant tasks. Inspired by human\nintelligence, we propose to introduce external knowledge into few-shot learning\nto imitate human knowledge. A novel parameter generator network is investigated\nto this end, which is able to use the external knowledge to generate relation\nnetwork parameters. Metrics can be transferred among tasks when equipped with\nthese generated parameters, so that similar tasks use similar metrics while\ndifferent tasks use different metrics. Through experiments, we demonstrate that\nour method outperforms the state-of-the-art few-shot text classification\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 10:56:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sui", "Dianbo", ""], ["Chen", "Yubo", ""], ["Mao", "Binjie", ""], ["Qiu", "Delai", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2004.01909", "submitter": "Jimmy Lin", "authors": "Sheng-Chieh Lin, Jheng-Hong Yang, Rodrigo Nogueira, Ming-Feng Tsai,\n  Chuan-Ju Wang, Jimmy Lin", "title": "Conversational Question Reformulation via Sequence-to-Sequence\n  Architectures and Pretrained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an empirical study of conversational question\nreformulation (CQR) with sequence-to-sequence architectures and pretrained\nlanguage models (PLMs). We leverage PLMs to address the strong token-to-token\nindependence assumption made in the common objective, maximum likelihood\nestimation, for the CQR task. In CQR benchmarks of task-oriented dialogue\nsystems, we evaluate fine-tuned PLMs on the recently-introduced CANARD dataset\nas an in-domain task and validate the models using data from the TREC 2019 CAsT\nTrack as an out-domain task. Examining a variety of architectures with\ndifferent numbers of parameters, we demonstrate that the recent text-to-text\ntransfer transformer (T5) achieves the best results both on CANARD and CAsT\nwith fewer parameters, compared to similar transformer architectures.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 11:07:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lin", "Sheng-Chieh", ""], ["Yang", "Jheng-Hong", ""], ["Nogueira", "Rodrigo", ""], ["Tsai", "Ming-Feng", ""], ["Wang", "Chuan-Ju", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.01942", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Elsa Rizk, Ali H. Sayed", "title": "Tracking Performance of Online Stochastic Learners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilization of online stochastic algorithms is popular in large-scale\nlearning settings due to their ability to compute updates on the fly, without\nthe need to store and process data in large batches. When a constant step-size\nis used, these algorithms also have the ability to adapt to drifts in problem\nparameters, such as data or model properties, and track the optimal solution\nwith reasonable accuracy. Building on analogies with the study of adaptive\nfilters, we establish a link between steady-state performance derived under\nstationarity assumptions and the tracking performance of online learners under\nrandom walk models. The link allows us to infer the tracking performance from\nsteady-state expressions directly and almost by inspection.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 14:16:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Vlaski", "Stefan", ""], ["Rizk", "Elsa", ""], ["Sayed", "Ali H.", ""]]}, {"id": "2004.01973", "submitter": "Xun Wu", "authors": "Xun Wu, Wei-Long Zheng, and Bao-Liang Lu", "title": "Investigating EEG-Based Functional Connectivity Patterns for Multimodal\n  Emotion Recognition", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with the rich studies on the motor brain-computer interface (BCI),\nthe recently emerging affective BCI presents distinct challenges since the\nbrain functional connectivity networks involving emotion are not well\ninvestigated. Previous studies on emotion recognition based on\nelectroencephalography (EEG) signals mainly rely on single-channel-based\nfeature extraction methods. In this paper, we propose a novel emotion-relevant\ncritical subnetwork selection algorithm and investigate three EEG functional\nconnectivity network features: strength, clustering coefficient, and\neigenvector centrality. The discrimination ability of the EEG connectivity\nfeatures in emotion recognition is evaluated on three public emotion EEG\ndatasets: SEED, SEED-V, and DEAP. The strength feature achieves the best\nclassification performance and outperforms the state-of-the-art differential\nentropy feature based on single-channel analysis. The experimental results\nreveal that distinct functional connectivity patterns are exhibited for the\nfive emotions of disgust, fear, sadness, happiness, and neutrality.\nFurthermore, we construct a multimodal emotion recognition model by combining\nthe functional connectivity features from EEG and the features from eye\nmovements or physiological signals using deep canonical correlation analysis.\nThe classification accuracies of multimodal emotion recognition are 95.08/6.42%\non the SEED dataset, 84.51/5.11% on the SEED-V dataset, and 85.34/2.90% and\n86.61/3.76% for arousal and valence on the DEAP dataset, respectively. The\nresults demonstrate the complementary representation properties of the EEG\nconnectivity features with eye movement data. In addition, we find that the\nbrain networks constructed with 18 channels achieve comparable performance with\nthat of the 62-channel network in multimodal emotion recognition and enable\neasier setups for BCI systems in real scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 16:51:56 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wu", "Xun", ""], ["Zheng", "Wei-Long", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "2004.01980", "submitter": "Di Jin", "authors": "Di Jin, Zhijing Jin, Joey Tianyi Zhou, Lisa Orii, Peter Szolovits", "title": "Hooks in the Headline: Learning to Generate Headlines with Controlled\n  Styles", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": "12 pages", "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current summarization systems only produce plain, factual headlines, but do\nnot meet the practical needs of creating memorable titles to increase exposure.\nWe propose a new task, Stylistic Headline Generation (SHG), to enrich the\nheadlines with three style options (humor, romance and clickbait), in order to\nattract more readers. With no style-specific article-headline pair (only a\nstandard headline summarization dataset and mono-style corpora), our method\nTitleStylist generates style-specific headlines by combining the summarization\nand reconstruction tasks into a multitasking framework. We also introduced a\nnovel parameter sharing scheme to further disentangle the style from the text.\nThrough both automatic and human evaluation, we demonstrate that TitleStylist\ncan generate relevant, fluent headlines with three target styles: humor,\nromance, and clickbait. The attraction score of our model generated headlines\nsurpasses that of the state-of-the-art summarization model by 9.68%, and even\noutperforms human-written references.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 17:24:47 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 18:48:19 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 02:21:37 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Jin", "Di", ""], ["Jin", "Zhijing", ""], ["Zhou", "Joey Tianyi", ""], ["Orii", "Lisa", ""], ["Szolovits", "Peter", ""]]}, {"id": "2004.02001", "submitter": "Ming Tu", "authors": "Ming Tu, Jing Huang, Xiaodong He, Bowen Zhou", "title": "Graph Sequential Network for Reasoning over Sequences", "comments": "Part of this paper was presented at NeurIPS 2019 Workshop on Graph\n  Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Graph Neural Network (GNN) has been applied successfully to various\nNLP tasks that require reasoning, such as multi-hop machine reading\ncomprehension. In this paper, we consider a novel case where reasoning is\nneeded over graphs built from sequences, i.e. graph nodes with sequence data.\nExisting GNN models fulfill this goal by first summarizing the node sequences\ninto fixed-dimensional vectors, then applying GNN on these vectors. To avoid\ninformation loss inherent in the early summarization and make sequential\nlabeling tasks on GNN output feasible, we propose a new type of GNN called\nGraph Sequential Network (GSN), which features a new message passing algorithm\nbased on co-attention between a node and each of its neighbors. We validate the\nproposed GSN on two NLP tasks: interpretable multi-hop reading comprehension on\nHotpotQA and graph based fact verification on FEVER. Both tasks require\nreasoning over multiple documents or sentences. Our experimental results show\nthat the proposed GSN attains better performance than the standard GNN based\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 19:18:54 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Tu", "Ming", ""], ["Huang", "Jing", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "2004.02025", "submitter": "Karttikeya Mangalam", "authors": "Karttikeya Mangalam, Harshayu Girase, Shreyas Agarwal, Kuan-Hui Lee,\n  Ehsan Adeli, Jitendra Malik, Adrien Gaidon", "title": "It Is Not the Journey but the Destination: Endpoint Conditioned\n  Trajectory Prediction", "comments": "Accepted at ECCV 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human trajectory forecasting with multiple socially interacting agents is of\ncritical importance for autonomous navigation in human environments, e.g., for\nself-driving cars and social robots. In this work, we present Predicted\nEndpoint Conditioned Network (PECNet) for flexible human trajectory prediction.\nPECNet infers distant trajectory endpoints to assist in long-range multi-modal\ntrajectory prediction. A novel non-local social pooling layer enables PECNet to\ninfer diverse yet socially compliant trajectories. Additionally, we present a\nsimple \"truncation-trick\" for improving few-shot multi-modal trajectory\nprediction performance. We show that PECNet improves state-of-the-art\nperformance on the Stanford Drone trajectory prediction benchmark by ~20.9% and\non the ETH/UCY benchmark by ~40.8%. Project homepage:\nhttps://karttikeya.github.io/publication/htf/\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 21:27:13 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 10:08:04 GMT"}, {"version": "v3", "created": "Sat, 18 Jul 2020 21:33:55 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mangalam", "Karttikeya", ""], ["Girase", "Harshayu", ""], ["Agarwal", "Shreyas", ""], ["Lee", "Kuan-Hui", ""], ["Adeli", "Ehsan", ""], ["Malik", "Jitendra", ""], ["Gaidon", "Adrien", ""]]}, {"id": "2004.02034", "submitter": "Subramanyam Natarajan", "authors": "Arvind Srinivasan, Aprameya Bharadwaj, Manasa Sathyan, S Natarajan", "title": "Optimization of Image Embeddings for Few Shot Learning", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we improve the image embeddings generated in the graph neural\nnetwork solution for few shot learning. We propose alternate architectures for\nexisting networks such as Inception-Net, U-Net, Attention U-Net, and\nSqueeze-Net to generate embeddings and increase the accuracy of the models. We\nimprove the quality of embeddings created at the cost of the time taken to\ngenerate them. The proposed implementations outperform the existing state of\nthe art methods for 1-shot and 5-shot learning on the Omniglot dataset. The\nexperiments involved a testing set and training set which had no common classes\nbetween them. The results for 5-way and 10-way/20-way tests have been\ntabulated.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 22:17:08 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Srinivasan", "Arvind", ""], ["Bharadwaj", "Aprameya", ""], ["Sathyan", "Manasa", ""], ["Natarajan", "S", ""]]}, {"id": "2004.02037", "submitter": "Elif Ecem Bas", "authors": "Elif Ecem Bas, Mohamed A. Moustafa, David Feil-Seifer, Janelle\n  Blankenburg", "title": "Using Machine Learning Approach for Computational Substructure in\n  Real-Time Hybrid Simulation", "comments": "10 Pages, 12 Figures, IMAC 38i Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid simulation (HS) is a widely used structural testing method that\ncombines a computational substructure with a numerical model for\nwell-understood components and an experimental substructure for other parts of\nthe structure that are physically tested. One challenge for fast HS or\nreal-time HS (RTHS) is associated with the analytical substructures of\nrelatively complex structures, which could have large number of degrees of\nfreedoms (DOFs), for instance. These large DOFs computations could be hard to\nperform in real-time, even with the all current hardware capacities. In this\nstudy, a metamodeling technique is proposed to represent the structural dynamic\nbehavior of the analytical substructure. A preliminary study is conducted where\na one-bay one-story concentrically braced frame (CBF) is tested under\nearthquake loading by using a compact HS setup at the University of Nevada,\nReno. The experimental setup allows for using a small-scale brace as the\nexperimental substructure combined with a steel frame at the prototype\nfull-scale for the analytical substructure. Two different machine learning\nalgorithms are evaluated to provide a valid and useful metamodeling solution\nfor analytical substructure. The metamodels are trained with the available data\nthat is obtained from the pure analytical solution of the prototype steel\nframe. The two algorithms used for developing the metamodels are: (1) linear\nregression (LR) model, and (2) basic recurrent neural network (RNN). The\nmetamodels are first validated against the pure analytical response of the\nstructure. Next, RTHS experiments are conducted by using metamodels. RTHS test\nresults using both LR and RNN models are evaluated, and the advantages and\ndisadvantages of these models are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 22:22:40 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Bas", "Elif Ecem", ""], ["Moustafa", "Mohamed A.", ""], ["Feil-Seifer", "David", ""], ["Blankenburg", "Janelle", ""]]}, {"id": "2004.02042", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "ObjectNet Dataset: Reanalysis and Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Barbu et al introduced a dataset called ObjectNet which includes\nobjects in daily life situations. They showed a dramatic performance drop of\nthe state of the art object recognition models on this dataset. Due to the\nimportance and implications of their results regarding generalization ability\nof deep models, we take a second look at their findings. We highlight a major\nproblem with their work which is applying object recognizers to the scenes\ncontaining multiple objects rather than isolated objects. The latter results in\naround 20-30% performance gain using our code. Compared with the results\nreported in the ObjectNet paper, we observe that around 10-15 % of the\nperformance loss can be recovered, without any test time data augmentation. In\naccordance with Barbu et al.'s conclusions, however, we also conclude that deep\nmodels suffer drastically on this dataset. Thus, we believe that ObjectNet\nremains a challenging dataset for testing the generalization power of models\nbeyond datasets on which they have been trained.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 22:45:57 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2004.02043", "submitter": "Olivier Bernard", "authors": "Sarah Leclerc, Erik Smistad, Andreas {\\O}stvik, Frederic Cervenansky,\n  Florian Espinosa, Torvald Espeland, Erik Andreas Rye Berg, Thomas Grenier,\n  Carole Lartizien, Pierre-Marc Jodoin, Lasse Lovstakken, Olivier Bernard", "title": "LU-Net: a multi-task network to improve the robustness of segmentation\n  of left ventriclular structures by deep learning in 2D echocardiography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation of cardiac structures is one of the fundamental steps to\nestimate volumetric indices of the heart. This step is still performed\nsemi-automatically in clinical routine, and is thus prone to inter- and\nintra-observer variability. Recent studies have shown that deep learning has\nthe potential to perform fully automatic segmentation. However, the current\nbest solutions still suffer from a lack of robustness. In this work, we\nintroduce an end-to-end multi-task network designed to improve the overall\naccuracy of cardiac segmentation while enhancing the estimation of clinical\nindices and reducing the number of outliers. Results obtained on a large open\naccess dataset show that our method outperforms the current best performing\ndeep learning solution and achieved an overall segmentation accuracy lower than\nthe intra-observer variability for the epicardial border (i.e. on average a\nmean absolute error of 1.5mm and a Hausdorff distance of 5.1mm) with 11% of\noutliers. Moreover, we demonstrate that our method can closely reproduce the\nexpert analysis for the end-diastolic and end-systolic left ventricular\nvolumes, with a mean correlation of 0.96 and a mean absolute error of 7.6ml.\nConcerning the ejection fraction of the left ventricle, results are more\ncontrasted with a mean correlation coefficient of 0.83 and an absolute mean\nerror of 5.0%, producing scores that are slightly below the intra-observer\nmargin. Based on this observation, areas for improvement are suggested.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 23:07:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Leclerc", "Sarah", ""], ["Smistad", "Erik", ""], ["\u00d8stvik", "Andreas", ""], ["Cervenansky", "Frederic", ""], ["Espinosa", "Florian", ""], ["Espeland", "Torvald", ""], ["Berg", "Erik Andreas Rye", ""], ["Grenier", "Thomas", ""], ["Lartizien", "Carole", ""], ["Jodoin", "Pierre-Marc", ""], ["Lovstakken", "Lasse", ""], ["Bernard", "Olivier", ""]]}, {"id": "2004.02046", "submitter": "Ivan Brugere", "authors": "Ivan Brugere, Tanya Y. Berger-Wolf", "title": "Inferring Network Structure From Data", "comments": "arXiv admin note: substantial text overlap with arXiv:1710.05207", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are complex models for underlying data in many application domains.\nIn most instances, raw data is not natively in the form of a network, but\nderived from sensors, logs, images, or other data. Yet, the impact of the\nvarious choices in translating this data to a network have been largely\nunexamined. In this work, we propose a network model selection methodology that\nfocuses on evaluating a network's utility for varying tasks, together with an\nefficiency measure which selects the most parsimonious model. We demonstrate\nthat this network definition matters in several ways for modeling the behavior\nof the underlying system.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 23:30:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Brugere", "Ivan", ""], ["Berger-Wolf", "Tanya Y.", ""]]}, {"id": "2004.02060", "submitter": "Rahul Paul", "authors": "Lawrence O. Hall, Rahul Paul, Dmitry B. Goldgof, and Gregory M.\n  Goldgof", "title": "Finding Covid-19 from Chest X-rays using Deep Learning on a Small\n  Dataset", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Testing for COVID-19 has been unable to keep up with the demand. Further, the\nfalse negative rate is projected to be as high as 30% and test results can take\nsome time to obtain. X-ray machines are widely available and provide images for\ndiagnosis quickly. This paper explores how useful chest X-ray images can be in\ndiagnosing COVID-19 disease. We have obtained 122 chest X-rays of COVID-19 and\nover 4,000 chest X-rays of viral and bacterial pneumonia. A pretrained deep\nconvolutional neural network has been tuned on 102 COVID-19 cases and 102 other\npneumonia cases in a 10-fold cross validation. The results were all 102\nCOVID-19 cases were correctly classified and there were 8 false positives\nresulting in an AUC of 0.997. On a test set of 20 unseen COVID-19 cases all\nwere correctly classified and more than 95% of 4171 other pneumonia examples\nwere correctly classified. This study has flaws, most critically a lack of\ninformation about where in the disease process the COVID-19 cases were and the\nsmall data set size. More COVID-19 case images will enable a better answer to\nthe question of how useful chest X-rays can be for diagnosing COVID-19 (so\nplease send them).\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 00:58:54 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 18:08:17 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 12:29:26 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 19:12:46 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Hall", "Lawrence O.", ""], ["Paul", "Rahul", ""], ["Goldgof", "Dmitry B.", ""], ["Goldgof", "Gregory M.", ""]]}, {"id": "2004.02072", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz", "title": "Any-Shot Sequential Anomaly Detection in Surveillance Videos", "comments": "Accepted to CVPR 2020: Workshop on Continual Learning in Computer\n  Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos has been recently gaining attention.\nEven though the performance of state-of-the-art methods on publicly available\ndata sets has been competitive, they demand a massive amount of training data.\nAlso, they lack a concrete approach for continuously updating the trained model\nonce new data is available. Furthermore, online decision making is an important\nbut mostly neglected factor in this domain. Motivated by these research gaps,\nwe propose an online anomaly detection method for surveillance videos using\ntransfer learning and any-shot learning, which in turn significantly reduces\nthe training complexity and provides a mechanism that can detect anomalies\nusing only a few labeled nominal examples. Our proposed algorithm leverages the\nfeature extraction power of neural network-based models for transfer learning\nand the any-shot learning capability of statistical detection methods.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 02:15:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2004.02082", "submitter": "Arthur Choi", "authors": "Weijia Shi and Andy Shih and Adnan Darwiche and Arthur Choi", "title": "On Tractable Representations of Binary Neural Networks", "comments": "In Proceedings of the 17th International Conference on Principles of\n  Knowledge Representation and Reasoning (KR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the compilation of a binary neural network's decision function\ninto tractable representations such as Ordered Binary Decision Diagrams (OBDDs)\nand Sentential Decision Diagrams (SDDs). Obtaining this function as an OBDD/SDD\nfacilitates the explanation and formal verification of a neural network's\nbehavior. First, we consider the task of verifying the robustness of a neural\nnetwork, and show how we can compute the expected robustness of a neural\nnetwork, given an OBDD/SDD representation of it. Next, we consider a more\nefficient approach for compiling neural networks, based on a pseudo-polynomial\ntime algorithm for compiling a neuron. We then provide a case study in a\nhandwritten digits dataset, highlighting how two neural networks trained from\nthe same dataset can have very high accuracies, yet have very different levels\nof robustness. Finally, in experiments, we show that it is feasible to obtain\ncompact representations of neural networks as SDDs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 03:21:26 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 03:22:47 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Shi", "Weijia", ""], ["Shih", "Andy", ""], ["Darwiche", "Adnan", ""], ["Choi", "Arthur", ""]]}, {"id": "2004.02086", "submitter": "Chuan Tan", "authors": "Chuan Tan (1), Jin Zhu (1), Pietro Lio' (1) ((1) University of\n  Cambridge)", "title": "Arbitrary Scale Super-Resolution for Brain MRI Images", "comments": "12 pages, 8 figures, 1 table, to appear as a full paper with oral\n  contribution in AIAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent attempts at Super-Resolution for medical images used deep learning\ntechniques such as Generative Adversarial Networks (GANs) to achieve\nperceptually realistic single image Super-Resolution. Yet, they are constrained\nby their inability to generalise to different scale factors. This involves high\nstorage and energy costs as every integer scale factor involves a separate\nneural network. A recent paper has proposed a novel meta-learning technique\nthat uses a Weight Prediction Network to enable Super-Resolution on arbitrary\nscale factors using only a single neural network. In this paper, we propose a\nnew network that combines that technique with SRGAN, a state-of-the-art\nGAN-based architecture, to achieve arbitrary scale, high fidelity\nSuper-Resolution for medical images. By using this network to perform arbitrary\nscale magnifications on images from the Multimodal Brain Tumor Segmentation\nChallenge (BraTS) dataset, we demonstrate that it is able to outperform\ntraditional interpolation methods by up to 20$\\%$ on SSIM scores whilst\nretaining generalisability on brain MRI images. We show that performance across\nscales is not compromised, and that it is able to achieve competitive results\nwith other state-of-the-art methods such as EDSR whilst being fifty times\nsmaller than them. Combining efficiency, performance, and generalisability,\nthis can hopefully become a new foundation for tackling Super-Resolution on\nmedical images.\n  Check out the webapp here: https://metasrgan.herokuapp.com/ Check out the\ngithub tutorial here: https://github.com/pancakewaffles/metasrgan-tutorial\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 03:53:28 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:34:44 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Tan", "Chuan", ""], ["Zhu", "Jin", ""], ["Lio'", "Pietro", ""]]}, {"id": "2004.02088", "submitter": "Chunyuan Li", "authors": "Yang Zhao, Chunyuan Li, Ping Yu, Jianfeng Gao, Changyou Chen", "title": "Feature Quantization Improves GAN Training", "comments": "The first two authors contributed equally to this manuscript. ICML\n  2020. Code: https://github.com/YangNaruto/FQ-GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instability in GAN training has been a long-standing problem despite\nremarkable research efforts. We identify that instability issues stem from\ndifficulties of performing feature matching with mini-batch statistics, due to\na fragile balance between the fixed target distribution and the progressively\ngenerated distribution. In this work, we propose Feature Quantization (FQ) for\nthe discriminator, to embed both true and fake data samples into a shared\ndiscrete space. The quantized values of FQ are constructed as an evolving\ndictionary, which is consistent with feature statistics of the recent\ndistribution history. Hence, FQ implicitly enables robust feature matching in a\ncompact space. Our method can be easily plugged into existing GAN models, with\nlittle computational overhead in training. We apply FQ to 3 representative GAN\nmodels on 9 benchmarks: BigGAN for image generation, StyleGAN for face\nsynthesis, and U-GAT-IT for unsupervised image-to-image translation. Extensive\nexperimental results show that the proposed FQ-GAN can improve the FID scores\nof baseline methods by a large margin on a variety of tasks, achieving new\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 04:06:50 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 00:06:52 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Zhao", "Yang", ""], ["Li", "Chunyuan", ""], ["Yu", "Ping", ""], ["Gao", "Jianfeng", ""], ["Chen", "Changyou", ""]]}, {"id": "2004.02094", "submitter": "Neda Tavakoli", "authors": "Neda Tavakoli", "title": "Locality Sensitive Hashing-based Sequence Alignment Using Deep\n  Bidirectional LSTM Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidirectional Long Short-Term Memory (LSTM) is a special kind of Recurrent\nNeural Network (RNN) architecture which is designed to model sequences and\ntheir long-range dependencies more precisely than RNNs. This paper proposes to\nuse deep bidirectional LSTM for sequence modeling as an approach to perform\nlocality-sensitive hashing (LSH)-based sequence alignment. In particular, we\nuse the deep bidirectional LSTM to learn features of LSH. The obtained LSH is\nthen can be utilized to perform sequence alignment. We demonstrate the\nfeasibility of the modeling sequences using the proposed LSTM-based model by\naligning the short read queries over the reference genome. We use the human\nreference genome as our training dataset, in addition to a set of short reads\ngenerated using Illumina sequencing technology. The ultimate goal is to align\nquery sequences into a reference genome. We first decompose the reference\ngenome into multiple sequences. These sequences are then fed into the\nbidirectional LSTM model and then mapped into fixed-length vectors. These\nvectors are what we call the trained LSH, which can then be used for sequence\nalignment. The case study shows that using the introduced LSTM-based model, we\nachieve higher accuracy with the number of epochs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 05:13:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Tavakoli", "Neda", ""]]}, {"id": "2004.02099", "submitter": "Conrad M Albrecht", "authors": "Conrad M Albrecht, Chris Fisher, Marcus Freitag, Hendrik F Hamann,\n  Sharathchandra Pankanti, Florencia Pezzutti, Francesca Rossi", "title": "Learning and Recognizing Archeological Features from LiDAR Data", "comments": null, "journal-ref": "2019 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData47090.2019.9005548", "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a remote sensing pipeline that processes LiDAR (Light Detection\nAnd Ranging) data through machine & deep learning for the application of\narcheological feature detection on big geo-spatial data platforms such as e.g.\nIBM PAIRS Geoscope.\n  Today, archeologists get overwhelmed by the task of visually surveying huge\namounts of (raw) LiDAR data in order to identify areas of interest for\ninspection on the ground. We showcase a software system pipeline that results\nin significant savings in terms of expert productivity while missing only a\nsmall fraction of the artifacts.\n  Our work employs artificial neural networks in conjunction with an efficient\nspatial segmentation procedure based on domain knowledge. Data processing is\nconstraint by a limited amount of training labels and noisy LiDAR signals due\nto vegetation cover and decay of ancient structures. We aim at identifying\ngeo-spatial areas with archeological artifacts in a supervised fashion allowing\nthe domain expert to flexibly tune parameters based on her needs.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 05:36:37 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Albrecht", "Conrad M", ""], ["Fisher", "Chris", ""], ["Freitag", "Marcus", ""], ["Hamann", "Hendrik F", ""], ["Pankanti", "Sharathchandra", ""], ["Pezzutti", "Florencia", ""], ["Rossi", "Francesca", ""]]}, {"id": "2004.02113", "submitter": "Gwenaelle Cunha Sergio", "authors": "Gwenaelle Cunha Sergio and Minho Lee", "title": "Emotional Video to Audio Transformation Using Deep Recurrent Neural\n  Networks and a Neuro-Fuzzy System", "comments": "Published (https://www.hindawi.com/journals/mpe/2020/8478527/)", "journal-ref": "Mathematical Problems in Engineering 2020 (2020) 1-15", "doi": "10.1155/2020/8478527", "report-no": null, "categories": "cs.SD cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating music with emotion similar to that of an input video is a very\nrelevant issue nowadays. Video content creators and automatic movie directors\nbenefit from maintaining their viewers engaged, which can be facilitated by\nproducing novel material eliciting stronger emotions in them. Moreover, there's\ncurrently a demand for more empathetic computers to aid humans in applications\nsuch as augmenting the perception ability of visually and/or hearing impaired\npeople. Current approaches overlook the video's emotional characteristics in\nthe music generation step, only consider static images instead of videos, are\nunable to generate novel music, and require a high level of human effort and\nskills. In this study, we propose a novel hybrid deep neural network that uses\nan Adaptive Neuro-Fuzzy Inference System to predict a video's emotion from its\nvisual features and a deep Long Short-Term Memory Recurrent Neural Network to\ngenerate its corresponding audio signals with similar emotional inkling. The\nformer is able to appropriately model emotions due to its fuzzy properties, and\nthe latter is able to model data with dynamic time properties well due to the\navailability of the previous hidden state information. The novelty of our\nproposed method lies in the extraction of visual emotional features in order to\ntransform them into audio signals with corresponding emotional aspects for\nusers. Quantitative experiments show low mean absolute errors of 0.217 and\n0.255 in the Lindsey and DEAP datasets respectively, and similar global\nfeatures in the spectrograms. This indicates that our model is able to\nappropriately perform domain transformation between visual and audio features.\nBased on experimental results, our model can effectively generate audio that\nmatches the scene eliciting a similar emotion from the viewer in both datasets,\nand music generated by our model is also chosen more often.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 07:18:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sergio", "Gwenaelle Cunha", ""], ["Lee", "Minho", ""]]}, {"id": "2004.02121", "submitter": "Friedrich Kruber", "authors": "Friedrich Kruber, Jonas Wurst, Michael Botsch", "title": "An Unsupervised Random Forest Clustering Technique for Automatic Traffic\n  Scenario Categorization", "comments": "Copyright 20xx IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2018 21st International Conference on Intelligent Transportation\n  Systems (ITSC)", "doi": "10.1109/ITSC.2018.8569682", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modification of the Random Forest algorithm for the categorization of\ntraffic situations is introduced in this paper. The procedure yields an\nunsupervised machine learning method. The algorithm generates a proximity\nmatrix which contains a similarity measure. This matrix is then reordered with\nhierarchical clustering to achieve a graphically interpretable representation.\nIt is shown how the resulting proximity matrix can be visually interpreted and\nhow the variation of the methods' metaparameter reveals different insights into\nthe data. The proposed method is able to cluster data from any data source. To\ndemonstrate the methods' potential, multiple features derived from a traffic\nsimulation are used in this paper.\n  The knowledge of traffic scenario clusters is crucial to accelerate the\nvalidation process. The clue of the method is that scenario templates can be\ngenerated automatically from actual traffic situations. These templates can be\nemployed in all stages of the development process. The results prove that the\nprocedure is well suited for an automatic categorization of traffic scenarios.\nDiverse other applications can benefit from this work.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 07:55:54 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Kruber", "Friedrich", ""], ["Wurst", "Jonas", ""], ["Botsch", "Michael", ""]]}, {"id": "2004.02126", "submitter": "Friedrich Kruber", "authors": "Friedrich Kruber, Jonas Wurst, Eduardo S\\'anchez Morales, Samarjit\n  Chakraborty, Michael Botsch", "title": "Unsupervised and Supervised Learning with the Random Forest Algorithm\n  for Traffic Scenario Clustering and Classification", "comments": "Copyright 20xx IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2019 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IVS.2019.8813994", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to provide a method, which is able to find\ncategories of traffic scenarios automatically. The architecture consists of\nthree main components: A microscopic traffic simulation, a clustering technique\nand a classification technique for the operational phase. The developed\nsimulation tool models each vehicle separately, while maintaining the\ndependencies between each other. The clustering approach consists of a modified\nunsupervised Random Forest algorithm to find a data adaptive similarity measure\nbetween all scenarios. As part of this, the path proximity, a novel technique\nto determine a similarity based on the Random Forest algorithm is presented. In\nthe second part of the clustering, the similarities are used to define a set of\nclusters. In the third part, a Random Forest classifier is trained using the\ndefined clusters for the operational phase. A thresholding technique is\ndescribed to ensure a certain confidence level for the class assignment. The\nmethod is applied for highway scenarios. The results show that the proposed\nmethod is an excellent approach to automatically categorize traffic scenarios,\nwhich is particularly relevant for testing autonomous vehicle functionality.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 08:26:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Kruber", "Friedrich", ""], ["Wurst", "Jonas", ""], ["Morales", "Eduardo S\u00e1nchez", ""], ["Chakraborty", "Samarjit", ""], ["Botsch", "Michael", ""]]}, {"id": "2004.02131", "submitter": "Wei Ye", "authors": "Wei Ye, Omid Askarisichani, Alex Jones, Ambuj Singh", "title": "DeepMap: Learning Deep Representations for Graph Classification", "comments": "arXiv admin note: text overlap with arXiv:2002.09846", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph-structured data arise in many scenarios. A fundamental problem is to\nquantify the similarities of graphs for tasks such as classification. Graph\nkernels are positive-semidefinite functions that decompose graphs into\nsubstructures and compare them. One problem in the effective implementation of\nthis idea is that the substructures are not independent, which leads to\nhigh-dimensional feature space. In addition, graph kernels cannot capture the\nhigh-order complex interactions between vertices. To mitigate these two\nproblems, we propose a framework called DeepMap to learn deep representations\nfor graph feature maps. The learnt deep representation for a graph is a dense\nand low-dimensional vector that captures complex high-order interactions in a\nvertex neighborhood. DeepMap extends Convolutional Neural Networks (CNNs) to\narbitrary graphs by aligning vertices across graphs and building the receptive\nfield for each vertex. We empirically validate DeepMap on various graph\nclassification benchmarks and demonstrate that it achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 08:49:27 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ye", "Wei", ""], ["Askarisichani", "Omid", ""], ["Jones", "Alex", ""], ["Singh", "Ambuj", ""]]}, {"id": "2004.02136", "submitter": "Nicolo' Savioli", "authors": "Nicol\\`o Savioli", "title": "One-shot screening of potential peptide ligands on HR1 domain in\n  COVID-19 glycosylated spike (S) protein with deep siamese network", "comments": "11 pages, 5 figures, 1 Table, added reference, revisited the\n  introduction", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The novel coronavirus (2019-nCoV) has been declared to be a new international\nhealth emergence and no specific drug has been yet identified. Several methods\nare currently being evaluated such as protease and glycosylated spike (S)\nprotein inhibitors, that outlines the main fusion site among coronavirus and\nhost cells. Notwithstanding, the Heptad Repeat 1 (HR1) domain on the\nglycosylated spike (S) protein is the region with less mutability and then the\nmost encouraging target for new inhibitors drugs.The novelty of the proposed\napproach, compared to others, lies in a precise training of a deep neural\nnetwork toward the 2019-nCoV virus. Where a Siamese Neural Network (SNN) has\nbeen trained to distingue the whole 2019-nCoV protein sequence amongst two\ndifferent viruses family such as HIV-1 and Ebola. In this way, the present deep\nlearning system has precise knowledge of peptide linkage among 2019-nCoV\nprotein structure and differently, of other works, is not trivially trained on\npublic datasets that have not been provided any ligand-peptide information for\n2019-nCoV. Suddenly, the SNN shows a sensitivity of $83\\%$ of peptide affinity\nclassification, where $3027$ peptides on SATPdb bank have been tested towards\nthe specific region HR1 of 2019-nCoV exhibiting an affinity of $93\\%$ for the\npeptidyl-prolyl cis-trans isomerase (PPIase) peptide. This affinity between\nPPIase and HR1 can open new horizons of research since several scientific\npapers have already shown that CsA immunosuppression drug, a main inhibitor of\nPPIase, suppress the reproduction of different CoV virus included SARS-CoV and\nMERS-CoV. Finally, to ensure the scientific reproducibility, code and data have\nbeen made public at the following link: https://github.com/bionick87/2019-nCoV\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:35:41 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 16:07:15 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 09:23:54 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Savioli", "Nicol\u00f2", ""]]}, {"id": "2004.02137", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Anomaly Detection and Prototype Selection Using Polyhedron Curvature", "comments": "Accepted (to appear) in Canadian Conference on Artificial\n  Intelligence (Canadian AI conference) 2020, Springer. This version includes\n  supplementary material for derivation of an equation", "journal-ref": "Canadian Conference on Artificial Intelligence, pp. 238-250.\n  Springer, Cham, 2020", "doi": "10.1007/978-3-030-47358-7_23", "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to anomaly detection called Curvature Anomaly\nDetection (CAD) and Kernel CAD based on the idea of polyhedron curvature. Using\nthe nearest neighbors for a point, we consider every data point as the vertex\nof a polyhedron where the more anomalous point has more curvature. We also\npropose inverse CAD (iCAD) and Kernel iCAD for instance ranking and prototype\nselection by looking at CAD from an opposite perspective. We define the concept\nof anomaly landscape and anomaly path and we demonstrate an application for it\nwhich is image denoising. The proposed methods are straightforward and easy to\nimplement. Our experiments on different benchmarks show that the proposed\nmethods are effective for anomaly detection and prototype selection.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:50:13 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.02138", "submitter": "Pengpeng Liu", "authors": "Pengpeng Liu and Irwin King and Michael Lyu and Jia Xu", "title": "Flow2Stereo: Effective Self-Supervised Learning of Optical Flow and\n  Stereo Matching", "comments": "Published at the Conference on Computer Vision and Pattern\n  Recognition (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unified method to jointly learn optical flow and\nstereo matching. Our first intuition is stereo matching can be modeled as a\nspecial case of optical flow, and we can leverage 3D geometry behind\nstereoscopic videos to guide the learning of these two forms of\ncorrespondences. We then enroll this knowledge into the state-of-the-art\nself-supervised learning framework, and train one single network to estimate\nboth flow and stereo. Second, we unveil the bottlenecks in prior\nself-supervised learning approaches, and propose to create a new set of\nchallenging proxy tasks to boost performance. These two insights yield a single\nmodel that achieves the highest accuracy among all existing unsupervised flow\nand stereo methods on KITTI 2012 and 2015 benchmarks. More remarkably, our\nself-supervised method even outperforms several state-of-the-art fully\nsupervised methods, including PWC-Net and FlowNet2 on KITTI 2012.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:52:04 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Liu", "Pengpeng", ""], ["King", "Irwin", ""], ["Lyu", "Michael", ""], ["Xu", "Jia", ""]]}, {"id": "2004.02164", "submitter": "Tianchen Zhao", "authors": "Xuefei Ning, Tianchen Zhao, Wenshuo Li, Peng Lei, Yu Wang, Huazhong\n  Yang", "title": "DSA: More Efficient Budgeted Pruning via Differentiable Sparsity\n  Allocation", "comments": "The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Budgeted pruning is the problem of pruning under resource constraints. In\nbudgeted pruning, how to distribute the resources across layers (i.e., sparsity\nallocation) is the key problem. Traditional methods solve it by discretely\nsearching for the layer-wise pruning ratios, which lacks efficiency. In this\npaper, we propose Differentiable Sparsity Allocation (DSA), an efficient\nend-to-end budgeted pruning flow. Utilizing a novel differentiable pruning\nprocess, DSA finds the layer-wise pruning ratios with gradient-based\noptimization. It allocates sparsity in continuous space, which is more\nefficient than methods based on discrete evaluation and search. Furthermore,\nDSA could work in a pruning-from-scratch manner, whereas traditional budgeted\npruning methods are applied to pre-trained models. Experimental results on\nCIFAR-10 and ImageNet show that DSA could achieve superior performance than\ncurrent iterative budgeted pruning methods, and shorten the time cost of the\noverall pruning process by at least 1.5x in the meantime.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 11:28:39 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 11:23:05 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 11:05:53 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 08:13:41 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2020 15:26:14 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ning", "Xuefei", ""], ["Zhao", "Tianchen", ""], ["Li", "Wenshuo", ""], ["Lei", "Peng", ""], ["Wang", "Yu", ""], ["Yang", "Huazhong", ""]]}, {"id": "2004.02167", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov, Kishor Patil, Gugan Thoppe", "title": "Change Rate Estimation and Optimal Freshness in Web Page Crawling", "comments": "This paper has been accepted to the 13th EAI International Conference\n  on Performance Evaluation Methodologies and Tools, VALUETOOLS'20, May 18--20,\n  2020, Tsukuba, Japan. This is the author version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For providing quick and accurate results, a search engine maintains a local\nsnapshot of the entire web. And, to keep this local cache fresh, it employs a\ncrawler for tracking changes across various web pages. However, finite\nbandwidth availability and server restrictions impose some constraints on the\ncrawling frequency. Consequently, the ideal crawling rates are the ones that\nmaximise the freshness of the local cache and also respect the above\nconstraints. Azar et al. 2018 recently proposed a tractable algorithm to solve\nthis optimisation problem. However, they assume the knowledge of the exact page\nchange rates, which is unrealistic in practice. We address this issue here.\nSpecifically, we provide two novel schemes for online estimation of page change\nrates. Both schemes only need partial information about the page change\nprocess, i.e., they only need to know if the page has changed or not since the\nlast crawled instance. For both these schemes, we prove convergence and, also,\nderive their convergence rates. Finally, we provide some numerical experiments\nto compare the performance of our proposed estimators with the existing ones\n(e.g., MLE).\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 11:48:38 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Patil", "Kishor", ""], ["Thoppe", "Gugan", ""]]}, {"id": "2004.02172", "submitter": "Eniko Sz\\'ekely", "authors": "Suddhasattwa Das, Dimitrios Giannakis, Enik\\H{o} Sz\\'ekely", "title": "An information-geometric approach to feature extraction and moment\n  reconstruction in dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dimension reduction framework for feature extraction and moment\nreconstruction in dynamical systems that operates on spaces of probability\nmeasures induced by observables of the system rather than directly in the\noriginal data space of the observables themselves as in more conventional\nmethods. Our approach is based on the fact that orbits of a dynamical system\ninduce probability measures over the measurable space defined by (partial)\nobservations of the system. We equip the space of these probability measures\nwith a divergence, i.e., a distance between probability distributions, and use\nthis divergence to define a kernel integral operator. The eigenfunctions of\nthis operator create an orthonormal basis of functions that capture different\ntimescales of the dynamical system. One of our main results shows that the\nevolution of the moments of the dynamics-dependent probability measures can be\nrelated to a time-averaging operator on the original dynamical system. Using\nthis result, we show that the moments can be expanded in the eigenfunction\nbasis, thus opening up the avenue for nonparametric forecasting of the moments.\nIf the collection of probability measures is itself a manifold, we can in\naddition equip the statistical manifold with the Riemannian metric and use\ntechniques from information geometry. We present applications to ergodic\ndynamical systems on the 2-torus and the Lorenz 63 system, and show on a\nreal-world example that a small number of eigenvectors is sufficient to\nreconstruct the moments (here the first four moments) of an atmospheric time\nseries, i.e., the realtime multivariate Madden-Julian oscillation index.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:07:21 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Das", "Suddhasattwa", ""], ["Giannakis", "Dimitrios", ""], ["Sz\u00e9kely", "Enik\u0151", ""]]}, {"id": "2004.02173", "submitter": "Wentong Liao", "authors": "Tongxin Hu, Vasileios Iosifidis, Wentong Liao, Hang Zhang, Michael\n  YingYang, Eirini Ntoutsi, and Bodo Rosenhahn", "title": "FairNN- Conjoint Learning of Fair Representations for Fair Decisions", "comments": "Code will be available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose FairNN a neural network that performs joint feature\nrepresentation and classification for fairness-aware learning. Our approach\noptimizes a multi-objective loss function in which (a) learns a fair\nrepresentation by suppressing protected attributes (b) maintains the\ninformation content by minimizing a reconstruction loss and (c) allows for\nsolving a classification task in a fair manner by minimizing the classification\nerror and respecting the equalized odds-based fairness regularized. Our\nexperiments on a variety of datasets demonstrate that such a joint approach is\nsuperior to separate treatment of unfairness in representation learning or\nsupervised learning. Additionally, our regularizers can be adaptively weighted\nto balance the different components of the loss function, thus allowing for a\nvery general framework for conjoint fair representation learning and decision\nmaking.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:08:30 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 20:00:16 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Hu", "Tongxin", ""], ["Iosifidis", "Vasileios", ""], ["Liao", "Wentong", ""], ["Zhang", "Hang", ""], ["YingYang", "Michael", ""], ["Ntoutsi", "Eirini", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2004.02182", "submitter": "Pourya Shamsolmoali", "authors": "Pourya Shamsolmoali, Masoumeh Zareapoor, Linlin Shen, Abdul Hamid\n  Sadka, Jie Yang", "title": "Imbalanced Data Learning by Minority Class Augmentation using Capsule\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The fact that image datasets are often imbalanced poses an intense challenge\nfor deep learning techniques. In this paper, we propose a method to restore the\nbalance in imbalanced images, by coalescing two concurrent methods, generative\nadversarial networks (GANs) and capsule network. In our model, generative and\ndiscriminative networks play a novel competitive game, in which the generator\ngenerates samples towards specific classes from multivariate probabilities\ndistribution. The discriminator of our model is designed in a way that while\nrecognizing the real and fake samples, it is also requires to assign classes to\nthe inputs. Since GAN approaches require fully observed data during training,\nwhen the training samples are imbalanced, the approaches might generate similar\nsamples which leading to data overfitting. This problem is addressed by\nproviding all the available information from both the class components jointly\nin the adversarial training. It improves learning from imbalanced data by\nincorporating the majority distribution structure in the generation of new\nminority samples. Furthermore, the generator is trained with feature matching\nloss function to improve the training convergence. In addition, prevents\ngeneration of outliers and does not affect majority class space. The\nevaluations show the effectiveness of our proposed methodology; in particular,\nthe coalescing of capsule-GAN is effective at recognizing highly overlapping\nclasses with much fewer parameters compared with the convolutional-GAN.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:36:06 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 04:25:36 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2020 07:47:38 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Shamsolmoali", "Pourya", ""], ["Zareapoor", "Masoumeh", ""], ["Shen", "Linlin", ""], ["Sadka", "Abdul Hamid", ""], ["Yang", "Jie", ""]]}, {"id": "2004.02183", "submitter": "Jay Nandy", "authors": "Jay Nandy, Wynne Hsu, Mong Li Lee", "title": "Approximate Manifold Defense Against Multiple Adversarial Perturbations", "comments": "Workshop on Machine Learning with Guarantees, NeurIPS 2019. IJCNN,\n  2020 (full paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing defenses against adversarial attacks are typically tailored to a\nspecific perturbation type. Using adversarial training to defend against\nmultiple types of perturbation requires expensive adversarial examples from\ndifferent perturbation types at each training step. In contrast, manifold-based\ndefense incorporates a generative network to project an input sample onto the\nclean data manifold. This approach eliminates the need to generate expensive\nadversarial examples while achieving robustness against multiple perturbation\ntypes. However, the success of this approach relies on whether the generative\nnetwork can capture the complete clean data manifold, which remains an open\nproblem for complex input domain. In this work, we devise an approximate\nmanifold defense mechanism, called RBF-CNN, for image classification. Instead\nof capturing the complete data manifold, we use an RBF layer to learn the\ndensity of small image patches. RBF-CNN also utilizes a reconstruction layer\nthat mitigates any minor adversarial perturbations. Further, incorporating our\nproposed reconstruction process for training improves the adversarial\nrobustness of our RBF-CNN models. Experiment results on MNIST and CIFAR-10\ndatasets indicate that RBF-CNN offers robustness for multiple perturbations\nwithout the need for expensive adversarial training.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:36:08 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 08:08:16 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Nandy", "Jay", ""], ["Hsu", "Wynne", ""], ["Lee", "Mong Li", ""]]}, {"id": "2004.02184", "submitter": "Hossein A. Rahmani", "authors": "Mahdi Dehghan, Hossein A. Rahmani, Ahmad Ali Abin, Viet-Vu Vu", "title": "Mining Shape of Expertise: A Novel Approach Based on Convolutional\n  Neural Network", "comments": "IP&M 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert finding addresses the task of retrieving and ranking talented people\non the subject of user query. It is a practical issue in the Community Question\nAnswering networks. Recruiters looking for knowledgeable people for their job\npositions are the most important clients of expert finding systems. In addition\nto employee expertise, the cost of hiring new staff is another significant\nconcern for organizations. An efficient solution to cope with this concern is\nto hire T-shaped experts that are cost-effective. In this study, we have\nproposed a new deep model for T-shaped experts finding based on Convolutional\nNeural Networks. The proposed model tries to match queries and users by\nextracting local and position-invariant features from their corresponding\ndocuments. In other words, it detects users' shape of expertise by learning\npatterns from documents of users and queries simultaneously. The proposed model\ncontains two parallel CNN's that extract latent vectors of users and queries\nbased on their corresponding documents and join them together in the last layer\nto match queries with users. Experiments on a large subset of Stack Overflow\ndocuments indicate the effectiveness of the proposed method against baselines\nin terms of NDCG, MRR, and ERR evaluation metrics.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:44:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dehghan", "Mahdi", ""], ["Rahmani", "Hossein A.", ""], ["Abin", "Ahmad Ali", ""], ["Vu", "Viet-Vu", ""]]}, {"id": "2004.02195", "submitter": "Vivek Sharma", "authors": "Vivek Sharma, Makarand Tapaswi, M. Saquib Sarfraz, Rainer Stiefelhagen", "title": "Clustering based Contrastive Learning for Improving Face Representations", "comments": "To appear at IEEE International Conference on Automatic Face and\n  Gesture Recognition (FG), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A good clustering algorithm can discover natural groupings in data. These\ngroupings, if used wisely, provide a form of weak supervision for learning\nrepresentations. In this work, we present Clustering-based Contrastive Learning\n(CCL), a new clustering-based representation learning approach that uses labels\nobtained from clustering along with video constraints to learn discriminative\nface features. We demonstrate our method on the challenging task of learning\nrepresentations for video face clustering. Through several ablation studies, we\nanalyze the impact of creating pair-wise positive and negative labels from\ndifferent sources. Experiments on three challenging video face clustering\ndatasets: BBT-0101, BF-0502, and ACCIO show that CCL achieves a new\nstate-of-the-art on all datasets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 13:11:44 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sharma", "Vivek", ""], ["Tapaswi", "Makarand", ""], ["Sarfraz", "M. Saquib", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "2004.02199", "submitter": "Lemao Liu", "authors": "Conghui Zhu, Guanlin Li, Lemao Liu, Tiejun Zhao, Shuming Shi", "title": "Understanding Learning Dynamics for Neural Machine Translation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the great success of NMT, there still remains a severe challenge: it\nis hard to interpret the internal dynamics during its training process. In this\npaper we propose to understand learning dynamics of NMT by using a recent\nproposed technique named Loss Change Allocation\n(LCA)~\\citep{lan-2019-loss-change-allocation}. As LCA requires calculating the\ngradient on an entire dataset for each update, we instead present an\napproximate to put it into practice in NMT scenario. %motivated by the lesson\nfrom sgd. Our simulated experiment shows that such approximate calculation is\nefficient and is empirically proved to deliver consistent results to the\nbrute-force implementation. In particular, extensive experiments on two\nstandard translation benchmark datasets reveal some valuable findings.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 13:32:58 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhu", "Conghui", ""], ["Li", "Guanlin", ""], ["Liu", "Lemao", ""], ["Zhao", "Tiejun", ""], ["Shi", "Shuming", ""]]}, {"id": "2004.02200", "submitter": "Seong Tae Kim", "authors": "Seong Tae Kim, Farrukh Mushtaq, Nassir Navab", "title": "Confident Coreset for Active Learning in Medical Image Analysis", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have resulted in great successes in various\napplications. Although semi-supervised or unsupervised learning methods have\nbeen widely investigated, the performance of deep neural networks highly\ndepends on the annotated data. The problem is that the budget for annotation is\nusually limited due to the annotation time and expensive annotation cost in\nmedical data. Active learning is one of the solutions to this problem where an\nactive learner is designed to indicate which samples need to be annotated to\neffectively train a target model. In this paper, we propose a novel active\nlearning method, confident coreset, which considers both uncertainty and\ndistribution for effectively selecting informative samples. By comparative\nexperiments on two medical image analysis tasks, we show that our method\noutperforms other active learning methods.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 13:46:16 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kim", "Seong Tae", ""], ["Mushtaq", "Farrukh", ""], ["Navab", "Nassir", ""]]}, {"id": "2004.02205", "submitter": "Vivek Sharma", "authors": "Vivek Sharma and Makarand Tapaswi and Rainer Stiefelhagen", "title": "Deep Multimodal Feature Encoding for Video Ordering", "comments": "IEEE International Conference on Computer Vision (ICCV) Workshop on\n  Large Scale Holistic Video Understanding. The datasets and code are available\n  at https://github.com/vivoutlaw/tcbp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  True understanding of videos comes from a joint analysis of all its\nmodalities: the video frames, the audio track, and any accompanying text such\nas closed captions. We present a way to learn a compact multimodal feature\nrepresentation that encodes all these modalities. Our model parameters are\nlearned through a proxy task of inferring the temporal ordering of a set of\nunordered videos in a timeline. To this end, we create a new multimodal dataset\nfor temporal ordering that consists of approximately 30K scenes (2-6 clips per\nscene) based on the \"Large Scale Movie Description Challenge\". We analyze and\nevaluate the individual and joint modalities on three challenging tasks: (i)\ninferring the temporal ordering of a set of videos; and (ii) action\nrecognition. We demonstrate empirically that multimodal representations are\nindeed complementary, and can play a key role in improving the performance of\nmany applications.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 14:02:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sharma", "Vivek", ""], ["Tapaswi", "Makarand", ""], ["Stiefelhagen", "Rainer", ""]]}, {"id": "2004.02229", "submitter": "Sameer Wagh", "authors": "Sameer Wagh, Shruti Tople, Fabrice Benhamouda, Eyal Kushilevitz,\n  Prateek Mittal, Tal Rabin", "title": "FALCON: Honest-Majority Maliciously Secure Framework for Private Deep\n  Learning", "comments": "Revised version, contains some more experiments and fixes minor typos\n  in the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Falcon, an end-to-end 3-party protocol for efficient private\ntraining and inference of large machine learning models. Falcon presents four\nmain advantages - (i) It is highly expressive with support for high capacity\nnetworks such as VGG16 (ii) it supports batch normalization which is important\nfor training complex networks such as AlexNet (iii) Falcon guarantees security\nwith abort against malicious adversaries, assuming an honest majority (iv)\nLastly, Falcon presents new theoretical insights for protocol design that make\nit highly efficient and allow it to outperform existing secure deep learning\nsolutions. Compared to prior art for private inference, we are about 8x faster\nthan SecureNN (PETS'19) on average and comparable to ABY3 (CCS'18). We are\nabout 16-200x more communication efficient than either of these. For private\ntraining, we are about 6x faster than SecureNN, 4.4x faster than ABY3 and about\n2-60x more communication efficient. Our experiments in the WAN setting show\nthat over large networks and datasets, compute operations dominate the overall\nlatency of MPC, as opposed to the communication.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 15:20:25 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 19:50:23 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Wagh", "Sameer", ""], ["Tople", "Shruti", ""], ["Benhamouda", "Fabrice", ""], ["Kushilevitz", "Eyal", ""], ["Mittal", "Prateek", ""], ["Rabin", "Tal", ""]]}, {"id": "2004.02235", "submitter": "Dvir Samuel", "authors": "Dvir Samuel, Yuval Atzmon and Gal Chechik", "title": "From Generalized zero-shot learning to long-tail with class descriptors", "comments": "Accepted to WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world data is predominantly unbalanced and long-tailed, but deep models\nstruggle to recognize rare classes in the presence of frequent classes. Often,\nclasses can be accompanied by side information like textual descriptions, but\nit is not fully clear how to use them for learning with unbalanced long-tail\ndata. Such descriptions have been mostly used in (Generalized) Zero-shot\nlearning (ZSL), suggesting that ZSL with class descriptions may also be useful\nfor long-tail distributions. We describe DRAGON, a late-fusion architecture for\nlong-tail learning with class descriptors. It learns to (1) correct the bias\ntowards head classes on a sample-by-sample basis; and (2) fuse information from\nclass-descriptions to improve the tail-class accuracy. We also introduce new\nbenchmarks CUB-LT, SUN-LT, AWA-LT for long-tail learning with\nclass-descriptions, building on existing learning-with-attributes datasets and\na version of Imagenet-LT with class descriptors. DRAGON outperforms\nstate-of-the-art models on the new benchmark. It is also a new SoTA on existing\nbenchmarks for GFSL with class descriptors (GFSL-d) and standard (vision-only)\nlong-tailed learning ImageNet-LT, CIFAR-10, 100, and Places365.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 15:51:31 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 21:41:26 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 13:12:28 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 15:17:56 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Samuel", "Dvir", ""], ["Atzmon", "Yuval", ""], ["Chechik", "Gal", ""]]}, {"id": "2004.02249", "submitter": "S. M. Kamrul Hasan", "authors": "S. M. Kamrul Hasan and Cristian A. Linte", "title": "CondenseUNet: A Memory-Efficient Condensely-Connected Architecture for\n  Bi-ventricular Blood Pool and Myocardium Segmentation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of Cardiac Cine Magnetic Resonance (CMR) Imaging, there has\nbeen a paradigm shift in medical technology, thanks to its capability of\nimaging different structures within the heart without ionizing radiation.\nHowever, it is very challenging to conduct pre-operative planning of minimally\ninvasive cardiac procedures without accurate segmentation and identification of\nthe left ventricle (LV), right ventricle (RV) blood-pool, and LV-myocardium.\nManual segmentation of those structures, nevertheless, is time-consuming and\noften prone to error and biased outcomes. Hence, automatic and computationally\nefficient segmentation techniques are paramount. In this work, we propose a\nnovel memory-efficient Convolutional Neural Network (CNN) architecture as a\nmodification of both CondenseNet, as well as DenseNet for ventricular\nblood-pool segmentation by introducing a bottleneck block and an upsampling\npath. Our experiments show that the proposed architecture runs on the Automated\nCardiac Diagnosis Challenge (ACDC) dataset using half (50%) the memory\nrequirement of DenseNet and one-twelfth (~ 8%) of the memory requirements of\nU-Net, while still maintaining excellent accuracy of cardiac segmentation. We\nvalidated the framework on the ACDC dataset featuring one healthy and four\npathology groups whose heart images were acquired throughout the cardiac cycle\nand achieved the mean dice scores of 96.78% (LV blood-pool), 93.46% (RV\nblood-pool) and 90.1% (LV-Myocardium). These results are promising and promote\nthe proposed methods as a competitive tool for cardiac image segmentation and\nclinical parameter estimation that has the potential to provide fast and\naccurate results, as needed for pre-procedural planning and/or pre-operative\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 16:34:51 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hasan", "S. M. Kamrul", ""], ["Linte", "Cristian A.", ""]]}, {"id": "2004.02270", "submitter": "Mingrui Yang", "authors": "Mingrui Yang, Yun Jiang, Dan Ma, Bhairav B. Mehta, Mark A. Griswold", "title": "Game of Learning Bloch Equation Simulations for MR Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: This work proposes a novel approach to efficiently generate MR\nfingerprints for MR fingerprinting (MRF) problems based on the unsupervised\ndeep learning model generative adversarial networks (GAN). Methods: The GAN\nmodel is adopted and modified for better convergence and performance, resulting\nin an MRF specific model named GAN-MRF. The GAN-MRF model is trained,\nvalidated, and tested using different MRF fingerprints simulated from the Bloch\nequations with certain MRF sequence. The performance and robustness of the\nmodel are further tested by using in vivo data collected on a 3 Tesla scanner\nfrom a healthy volunteer together with MRF dictionaries with different sizes.\nT1, T2 maps are generated and compared quantitatively. Results: The validation\nand testing curves for the GAN-MRF model show no evidence of high bias or high\nvariance problems. The sample MRF fingerprints generated from the trained\nGAN-MRF model agree well with the benchmark fingerprints simulated from the\nBloch equations. The in vivo T1, T2 maps generated from the GAN-MRF\nfingerprints are in good agreement with those generated from the Bloch\nsimulated fingerprints, showing good performance and robustness of the proposed\nGAN-MRF model. Moreover, the MRF dictionary generation time is reduced from\nhours to sub-second for the testing dictionary. Conclusion: The GAN-MRF model\nenables a fast and accurate generation of the MRF fingerprints. It\nsignificantly reduces the MRF dictionary generation process and opens the door\nfor real-time applications and sequence optimization problems.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:15:52 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yang", "Mingrui", ""], ["Jiang", "Yun", ""], ["Ma", "Dan", ""], ["Mehta", "Bhairav B.", ""], ["Griswold", "Mark A.", ""]]}, {"id": "2004.02273", "submitter": "Riccardo La Grassa", "authors": "Riccardo La Grassa, Ignazio Gallo, Nicola Landro", "title": "Dynamic Decision Boundary for One-class Classifiers applied to\n  non-uniformly Sampled Data", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A typical issue in Pattern Recognition is the non-uniformly sampled data,\nwhich modifies the general performance and capability of machine learning\nalgorithms to make accurate predictions. Generally, the data is considered\nnon-uniformly sampled when in a specific area of data space, they are not\nenough, leading us to misclassification problems. This issue cut down the goal\nof the one-class classifiers decreasing their performance. In this paper, we\npropose a one-class classifier based on the minimum spanning tree with a\ndynamic decision boundary (OCdmst) to make good prediction also in the case we\nhave non-uniformly sampled data. To prove the effectiveness and robustness of\nour approach we compare with the most recent one-class classifier reaching the\nstate-of-the-art in most of them.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:29:36 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["La Grassa", "Riccardo", ""], ["Gallo", "Ignazio", ""], ["Landro", "Nicola", ""]]}, {"id": "2004.02274", "submitter": "Ala'eddin Masadeh", "authors": "Ala'eddin Masadeh, Zhengdao Wang, Ahmed E. Kamal", "title": "Reinforcement Learning Architectures: SAC, TAC, and ESAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend is to implement intelligent agents capable of analyzing available\ninformation and utilize it efficiently. This work presents a number of\nreinforcement learning (RL) architectures; one of them is designed for\nintelligent agents. The proposed architectures are called selector-actor-critic\n(SAC), tuner-actor-critic (TAC), and estimator-selector-actor-critic (ESAC).\nThese architectures are improved models of a well known architecture in RL\ncalled actor-critic (AC). In AC, an actor optimizes the used policy, while a\ncritic estimates a value function and evaluate the optimized policy by the\nactor. SAC is an architecture equipped with an actor, a critic, and a selector.\nThe selector determines the most promising action at the current state based on\nthe last estimate from the critic. TAC consists of a tuner, a model-learner, an\nactor, and a critic. After receiving the approximated value of the current\nstate-action pair from the critic and the learned model from the model-learner,\nthe tuner uses the Bellman equation to tune the value of the current\nstate-action pair. ESAC is proposed to implement intelligent agents based on\ntwo ideas, which are lookahead and intuition. Lookahead appears in estimating\nthe values of the available actions at the next state, while the intuition\nappears in maximizing the probability of selecting the most promising action.\nThe newly added elements are an underlying model learner, an estimator, and a\nselector. The model learner is used to approximate the underlying model. The\nestimator uses the approximated value function, the learned underlying model,\nand the Bellman equation to estimate the values of all actions at the next\nstate. The selector is used to determine the most promising action at the next\nstate, which will be used by the actor to optimize the used policy. Finally,\nthe results show the superiority of ESAC compared with the other architectures.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:31:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Masadeh", "Ala'eddin", ""], ["Wang", "Zhengdao", ""], ["Kamal", "Ahmed E.", ""]]}, {"id": "2004.02288", "submitter": "Subendhu Rongali", "authors": "Subendhu Rongali, Abhyuday Jagannatha, Bhanu Pratap Singh Rawat, and\n  Hong Yu", "title": "Continual Domain-Tuning for Pretrained Language Models", "comments": "Updated from a previous shorter version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (LM) such as BERT, DistilBERT, and RoBERTa can be\ntuned for different domains (domain-tuning) by continuing the pre-training\nphase on a new target domain corpus. This simple domain tuning (SDT) technique\nhas been widely used to create domain-tuned models such as BioBERT, SciBERT and\nClinicalBERT. However, during the pretraining phase on the target domain, the\nLM models may catastrophically forget the patterns learned from their source\ndomain. In this work, we study the effects of catastrophic forgetting on\ndomain-tuned LM models and investigate methods that mitigate its negative\neffects. We propose continual learning (CL) based alternatives for SDT, that\naim to reduce catastrophic forgetting. We show that these methods may increase\nthe performance of LM models on downstream target domain tasks. Additionally,\nwe also show that constraining the LM model from forgetting the source domain\nleads to downstream task models that are more robust to domain shifts. We\nanalyze the computational cost of using our proposed CL methods and provide\nrecommendations for computationally lightweight and effective CL domain-tuning\nprocedures.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:31:44 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2021 14:50:02 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rongali", "Subendhu", ""], ["Jagannatha", "Abhyuday", ""], ["Rawat", "Bhanu Pratap Singh", ""], ["Yu", "Hong", ""]]}, {"id": "2004.02289", "submitter": "Jonathan Martinez", "authors": "Jonathan Martinez (1), Kobi Gal (1 and 2), Ece Kamar (3), Levi H. S.\n  Lelis (4) ((1) Ben-Gurion University, (2) University of Edinburgh, (3)\n  Microsoft Research, (4) University of Alberta)", "title": "Personalization in Human-AI Teams: Improving the Compatibility-Accuracy\n  Tradeoff", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI systems that model and interact with users can update their models over\ntime to reflect new information and changes in the environment. Although these\nupdates may improve the overall performance of the AI system, they may actually\nhurt the performance with respect to individual users. Prior work has studied\nthe trade-off between improving the system's accuracy following an update and\nthe compatibility of the updated system with prior user experience. The more\nthe model is forced to be compatible with a prior version, the higher loss in\naccuracy it will incur. In this paper, we show that by personalizing the loss\nfunction to specific users, in some cases it is possible to improve the\ncompatibility-accuracy trade-off with respect to these users (increase the\ncompatibility of the model while sacrificing less accuracy). We present\nexperimental results indicating that this approach provides moderate\nimprovements on average (around 20%) but large improvements for certain users\n(up to 300%).\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:35:18 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:13:22 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Martinez", "Jonathan", "", "1 and 2"], ["Gal", "Kobi", "", "1 and 2"], ["Kamar", "Ece", ""], ["Lelis", "Levi H. S.", ""]]}, {"id": "2004.02290", "submitter": "Jude Tchaye-Kondi", "authors": "Jude Tchaye-Kondi, Yanlong Zhai, Liehuang Zhu", "title": "A new hashing based nearest neighbors selection technique for big\n  datasets", "comments": "8 pages,6 figures", "journal-ref": null, "doi": "10.5121/csit.2021.110708", "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KNN has the reputation to be the word simplest but efficient supervised\nlearning algorithm used for either classification or regression. KNN prediction\nefficiency highly depends on the size of its training data but when this\ntraining data grows KNN suffers from slowness in making decisions since it\nneeds to search nearest neighbors within the entire dataset at each decision\nmaking. This paper proposes a new technique that enables the selection of\nnearest neighbors directly in the neighborhood of a given observation. The\nproposed approach consists of dividing the data space into subcells of a\nvirtual grid built on top of data space. The mapping between the data points\nand subcells is performed using hashing. When it comes to select the nearest\nneighbors of a given observation, we firstly identify the cell the observation\nbelongs by using hashing, and then we look for nearest neighbors from that\ncentral cell and cells around it layer by layer. From our experiment\nperformance analysis on publicly available datasets, our algorithm outperforms\nthe original KNN in time efficiency with a prediction quality as good as that\nof KNN it also offers competitive performance with solutions like KDtree\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:36:00 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 03:26:41 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tchaye-Kondi", "Jude", ""], ["Zhai", "Yanlong", ""], ["Zhu", "Liehuang", ""]]}, {"id": "2004.02307", "submitter": "Abhinav Valada", "authors": "Rohit Mohan, Abhinav Valada", "title": "EfficientPS: Efficient Panoptic Segmentation", "comments": "Ranked # 1 on Cityscapes panoptic segmentation benchmark, ranked # 2\n  among the published methods on Cityscapes semantic segmentation benchmark,\n  and ranked # 2 among the published methods on Cityscapes instance\n  segmentation benchmark. Demo, code and models are available at\n  https://rl.uni-freiburg.de/research/panoptic", "journal-ref": "International Journal of Computer Vision (IJCV), 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the scene in which an autonomous robot operates is critical for\nits competent functioning. Such scene comprehension necessitates recognizing\ninstances of traffic participants along with general scene semantics which can\nbe effectively addressed by the panoptic segmentation task. In this paper, we\nintroduce the Efficient Panoptic Segmentation (EfficientPS) architecture that\nconsists of a shared backbone which efficiently encodes and fuses semantically\nrich multi-scale features. We incorporate a new semantic head that aggregates\nfine and contextual features coherently and a new variant of Mask R-CNN as the\ninstance head. We also propose a novel panoptic fusion module that congruously\nintegrates the output logits from both the heads of our EfficientPS\narchitecture to yield the final panoptic segmentation output. Additionally, we\nintroduce the KITTI panoptic segmentation dataset that contains panoptic\nannotations for the popularly challenging KITTI benchmark. Extensive\nevaluations on Cityscapes, KITTI, Mapillary Vistas and Indian Driving Dataset\ndemonstrate that our proposed architecture consistently sets the new\nstate-of-the-art on all these four benchmarks while being the most efficient\nand fast panoptic segmentation architecture to date.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:15:59 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 00:23:26 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 09:33:18 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mohan", "Rohit", ""], ["Valada", "Abhinav", ""]]}, {"id": "2004.02308", "submitter": "Jose Picado", "authors": "Jose Picado, John Davis, Arash Termehchy, Ga Young Lee", "title": "Learning Over Dirty Data Without Cleaning", "comments": "To be published in Proceedings of the 2020 ACM SIGMOD International\n  Conference on Management of Data (SIGMOD'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world datasets are dirty and contain many errors. Examples of these\nissues are violations of integrity constraints, duplicates, and inconsistencies\nin representing data values and entities. Learning over dirty databases may\nresult in inaccurate models. Users have to spend a great deal of time and\neffort to repair data errors and create a clean database for learning.\nMoreover, as the information required to repair these errors is not often\navailable, there may be numerous possible clean versions for a dirty database.\nWe propose DLearn, a novel relational learning system that learns directly over\ndirty databases effectively and efficiently without any preprocessing. DLearn\nleverages database constraints to learn accurate relational models over\ninconsistent and heterogeneous data. Its learned models represent patterns over\nall possible clean instances of the data in a usable form. Our empirical study\nindicates that DLearn learns accurate models over large real-world databases\nefficiently.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:21:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Picado", "Jose", ""], ["Davis", "John", ""], ["Termehchy", "Arash", ""], ["Lee", "Ga Young", ""]]}, {"id": "2004.02315", "submitter": "Xiaolan Liu", "authors": "Xiaolan Liu, Jiadong Yu, Yue Gao", "title": "Multi-agent Reinforcement Learning for Resource Allocation in IoT\n  networks with Edge Computing", "comments": "10 pages, 7 figures, Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support popular Internet of Things (IoT) applications such as virtual\nreality, mobile games and wearable devices, edge computing provides a front-end\ndistributed computing archetype of centralized cloud computing with low\nlatency. However, it's challenging for end users to offload computation due to\ntheir massive requirements on spectrum and computation resources and frequent\nrequests on Radio Access Technology (RAT). In this paper, we investigate\ncomputation offloading mechanism with resource allocation in IoT edge computing\nnetworks by formulating it as a stochastic game. Here, each end user is a\nlearning agent observing its local environment to learn optimal decisions on\neither local computing or edge computing with the goal of minimizing long term\nsystem cost by choosing its transmit power level, RAT and sub-channel without\nknowing any information of the other end users. Therefore, a multi-agent\nreinforcement learning framework is developed to solve the stochastic game with\na proposed independent learners based multi-agent Q-learning (IL-based MA-Q)\nalgorithm. Simulations demonstrate that the proposed IL-based MA-Q algorithm is\nfeasible to solve the formulated problem and is more energy efficient without\nextra cost on channel estimation at the centralized gateway compared to the\nother two benchmark algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:59:20 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Liu", "Xiaolan", ""], ["Yu", "Jiadong", ""], ["Gao", "Yue", ""]]}, {"id": "2004.02319", "submitter": "Ming-Chang Lee", "authors": "Ming-Chang Lee, Jia-Chun Lin, and Ernst Gunnar Gran", "title": "ReRe: A Lightweight Real-time Ready-to-Go Anomaly Detection Approach for\n  Time Series", "comments": "10 pages, 9 figures, COMPSAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is an active research topic in many different fields such\nas intrusion detection, network monitoring, system health monitoring, IoT\nhealthcare, etc. However, many existing anomaly detection approaches require\neither human intervention or domain knowledge, and may suffer from high\ncomputation complexity, consequently hindering their applicability in\nreal-world scenarios. Therefore, a lightweight and ready-to-go approach that is\nable to detect anomalies in real-time is highly sought-after. Such an approach\ncould be easily and immediately applied to perform time series anomaly\ndetection on any commodity machine. The approach could provide timely anomaly\nalerts and by that enable appropriate countermeasures to be undertaken as early\nas possible. With these goals in mind, this paper introduces ReRe, which is a\nReal-time Ready-to-go proactive Anomaly Detection algorithm for streaming time\nseries. ReRe employs two lightweight Long Short-Term Memory (LSTM) models to\npredict and jointly determine whether or not an upcoming data point is\nanomalous based on short-term historical data points and two long-term\nself-adaptive thresholds. Experiments based on real-world time-series datasets\ndemonstrate the good performance of ReRe in real-time anomaly detection without\nrequiring human intervention or domain knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:26:24 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:12:51 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Lee", "Ming-Chang", ""], ["Lin", "Jia-Chun", ""], ["Gran", "Ernst Gunnar", ""]]}, {"id": "2004.02322", "submitter": "Kadierdan Kaheman", "authors": "Kadierdan Kaheman, J.Nathan Kutz, Steven L. Brunton", "title": "SINDy-PI: A Robust Algorithm for Parallel Implicit Sparse Identification\n  of Nonlinear Dynamics", "comments": "25 pages, 9 figures, 5 tables", "journal-ref": null, "doi": "10.1098/rspa.2020.0279", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately modeling the nonlinear dynamics of a system from measurement data\nis a challenging yet vital topic. The sparse identification of nonlinear\ndynamics (SINDy) algorithm is one approach to discover dynamical systems models\nfrom data. Although extensions have been developed to identify implicit\ndynamics, or dynamics described by rational functions, these extensions are\nextremely sensitive to noise. In this work, we develop SINDy-PI (parallel,\nimplicit), a robust variant of the SINDy algorithm to identify implicit\ndynamics and rational nonlinearities. The SINDy-PI framework includes multiple\noptimization algorithms and a principled approach to model selection. We\ndemonstrate the ability of this algorithm to learn implicit ordinary and\npartial differential equations and conservation laws from limited and noisy\ndata. In particular, we show that the proposed approach is several orders of\nmagnitude more noise robust than previous approaches, and may be used to\nidentify a class of complex ODE and PDE dynamics that were previously\nunattainable with SINDy, including for the double pendulum dynamics and the\nBelousov Zhabotinsky (BZ) reaction.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:35:53 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 23:33:14 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Kaheman", "Kadierdan", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "2004.02326", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier and Vladimir Makarenkov", "title": "XtracTree for Regulator Validation of Bagging Methods Used in Retail\n  Banking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bootstrap aggregation, known as bagging, is one of the most popular ensemble\nmethods used in machine learning (ML). An ensemble method is a supervised ML\nmethod that combines multiple hypotheses to form a single hypothesis used for\nprediction. A bagging algorithm combines multiple classifiers modelled on\ndifferent sub-samples of the same data set to build one large classifier. Large\nretail banks are nowadays using the power of ML algorithms, including decision\ntrees and random forests, to optimize the retail banking activities. However,\nAI bank researchers face a strong challenge from their own model validation\ndepartment as well as from national financial regulators. Each proposed ML\nmodel has to be validated and clear rules for every algorithm-based decision\nhave to be established. In this context, we propose XtracTree, an algorithm\nthat is capable of effectively converting an ML bagging classifier, such as a\ndecision tree or a random forest, into simple \"if-then\" rules satisfying the\nrequirements of model validation. Our algorithm is also capable of highlighting\nthe decision path for each individual sample or a group of samples, addressing\nany concern from the regulators regarding ML \"black-box\". We use a public loan\ndata set from Kaggle to illustrate the usefulness of our approach. Our\nexperiments indicate that, using XtracTree, we are able to ensure a better\nunderstanding for our model, leading to an easier model validation by national\nfinancial regulators and the internal model validation department.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:57:06 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 23:32:03 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Charlier", "Jeremy", ""], ["Makarenkov", "Vladimir", ""]]}, {"id": "2004.02333", "submitter": "Carlos Relvas", "authors": "Carlos Relvas and Andr\\'e Fujita", "title": "Stage I non-small cell lung cancer stratification by using a model-based\n  clustering algorithm with covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is currently the leading cause of cancer deaths. Among various\nsubtypes, the number of patients diagnosed with stage I non-small cell lung\ncancer (NSCLC), particularly adenocarcinoma, has been increasing. It is\nestimated that 30 - 40\\% of stage I patients will relapse, and 10 - 30\\% will\ndie due to recurrence, clearly suggesting the presence of a subgroup that could\nbe benefited by additional therapy. We hypothesize that current attempts to\nidentify stage I NSCLC subgroup failed due to covariate effects, such as the\nage at diagnosis and differentiation, which may be masking the results. In this\ncontext, to stratify stage I NSCLC, we propose CEM-Co, a model-based clustering\nalgorithm that removes/minimizes the effects of undesirable covariates during\nthe clustering process. We applied CEM-Co on a gene expression data set\ncomposed of 129 subjects diagnosed with stage I NSCLC and successfully\nidentified a subgroup with a significantly different phenotype (poor\nprognosis), while standard clustering algorithms failed.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:12:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Relvas", "Carlos", ""], ["Fujita", "Andr\u00e9", ""]]}, {"id": "2004.02334", "submitter": "Thamme Gowda", "authors": "Thamme Gowda, Jonathan May", "title": "Finding the Optimal Vocabulary Size for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": "10.18653/v1/2020.findings-emnlp.352", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We cast neural machine translation (NMT) as a classification task in an\nautoregressive setting and analyze the limitations of both classification and\nautoregression components. Classifiers are known to perform better with\nbalanced class distributions during training. Since the Zipfian nature of\nlanguages causes imbalanced classes, we explore its effect on NMT. We analyze\nthe effect of various vocabulary sizes on NMT performance on multiple languages\nwith many data sizes, and reveal an explanation for why certain vocabulary\nsizes are better than others.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:17:34 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 15:19:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Gowda", "Thamme", ""], ["May", "Jonathan", ""]]}, {"id": "2004.02336", "submitter": "He Li", "authors": "Xi Chen and Jason D. Lee and He Li and Yun Yang", "title": "Distributed Estimation for Principal Component Analysis: an Enlarged\n  Eigenspace Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing size of modern data sets brings many challenges to the existing\nstatistical estimation approaches, which calls for new distributed\nmethodologies. This paper studies distributed estimation for a fundamental\nstatistical machine learning problem, principal component analysis (PCA).\nDespite the massive literature on top eigenvector estimation, much less is\npresented for the top-$L$-dim ($L>1$) eigenspace estimation, especially in a\ndistributed manner. We propose a novel multi-round algorithm for constructing\ntop-$L$-dim eigenspace for distributed data. Our algorithm takes advantage of\nshift-and-invert preconditioning and convex optimization. Our estimator is\ncommunication-efficient and achieves a fast convergence rate. In contrast to\nthe existing divide-and-conquer algorithm, our approach has no restriction on\nthe number of machines. Theoretically, the traditional Davis-Kahan theorem\nrequires the explicit eigengap assumption to estimate the top-$L$-dim\neigenspace. To abandon this eigengap assumption, we consider a new route in our\nanalysis: instead of exactly identifying the top-$L$-dim eigenspace, we show\nthat our estimator is able to cover the targeted top-$L$-dim population\neigenspace. Our distributed algorithm can be applied to a wide range of\nstatistical problems based on PCA, such as principal component regression and\nsingle index model. Finally, We provide simulation studies to demonstrate the\nperformance of the proposed distributed estimator.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 22:28:08 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 19:43:28 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 02:24:02 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Chen", "Xi", ""], ["Lee", "Jason D.", ""], ["Li", "He", ""], ["Yang", "Yun", ""]]}, {"id": "2004.02349", "submitter": "Jonathan Herzig", "authors": "Jonathan Herzig, Pawe{\\l} Krzysztof Nowak, Thomas M\\\"uller, Francesco\n  Piccinno, Julian Martin Eisenschlos", "title": "TAPAS: Weakly Supervised Table Parsing via Pre-training", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Answering natural language questions over tables is usually seen as a\nsemantic parsing task. To alleviate the collection cost of full logical forms,\none popular approach focuses on weak supervision consisting of denotations\ninstead of logical forms. However, training semantic parsers from weak\nsupervision poses difficulties, and in addition, the generated logical forms\nare only used as an intermediate step prior to retrieving the denotation. In\nthis paper, we present TAPAS, an approach to question answering over tables\nwithout generating logical forms. TAPAS trains from weak supervision, and\npredicts the denotation by selecting table cells and optionally applying a\ncorresponding aggregation operator to such selection. TAPAS extends BERT's\narchitecture to encode tables as input, initializes from an effective joint\npre-training of text segments and tables crawled from Wikipedia, and is trained\nend-to-end. We experiment with three different semantic parsing datasets, and\nfind that TAPAS outperforms or rivals semantic parsing models by improving\nstate-of-the-art accuracy on SQA from 55.1 to 67.2 and performing on par with\nthe state-of-the-art on WIKISQL and WIKITQ, but with a simpler model\narchitecture. We additionally find that transfer learning, which is trivial in\nour setting, from WIKISQL to WIKITQ, yields 48.7 accuracy, 4.2 points above the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:18:37 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 15:09:48 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Herzig", "Jonathan", ""], ["Nowak", "Pawe\u0142 Krzysztof", ""], ["M\u00fcller", "Thomas", ""], ["Piccinno", "Francesco", ""], ["Eisenschlos", "Julian Martin", ""]]}, {"id": "2004.02353", "submitter": "Jie Chen", "authors": "Jie Chen, Joel Vaughan, Vijayan N. Nair, Agus Sudjianto", "title": "Adaptive Explainable Neural Networks (AxNNs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning techniques have been successfully applied in several\nfields, the black-box nature of the models presents challenges for interpreting\nand explaining the results. We develop a new framework called Adaptive\nExplainable Neural Networks (AxNN) for achieving the dual goals of good\npredictive performance and model interpretability. For predictive performance,\nwe build a structured neural network made up of ensembles of generalized\nadditive model networks and additive index models (through explainable neural\nnetworks) using a two-stage process. This can be done using either a boosting\nor a stacking ensemble. For interpretability, we show how to decompose the\nresults of AxNN into main effects and higher-order interaction effects. The\ncomputations are inherited from Google's open source tool AdaNet and can be\nefficiently accelerated by training with distributed computing. The results are\nillustrated on simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 23:40:57 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 06:18:04 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Chen", "Jie", ""], ["Vaughan", "Joel", ""], ["Nair", "Vijayan N.", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2004.02359", "submitter": "Ranadeep Daw", "authors": "Ranadeep Daw, Zhuoqiong He", "title": "Deep Neural Network in Cusp Catastrophe Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophe theory was originally proposed to study dynamical systems that\nexhibit sudden shifts in behavior arising from small changes in input. These\nmodels can generate reasonable explanation behind abrupt jumps in nonlinear\ndynamic models. Among the different catastrophe models, the Cusp Catastrophe\nmodel attracted the most attention due to it's relatively simpler dynamics and\nrich domain of application. Due to the complex behavior of the response, the\nparameter space becomes highly non-convex and hence it becomes very hard to\noptimize to figure out the generating parameters. Instead of solving for these\ngenerating parameters, we demonstrated how a Machine learning model can be\ntrained to learn the dynamics of the Cusp catastrophe models, without ever\nreally solving for the generating model parameters. Simulation studies and\napplication on a few famous datasets are used to validate our approach. To our\nknowledge, this is the first paper of such kind where a neural network based\napproach has been applied in Cusp Catastrophe model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 00:25:41 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 02:30:54 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Daw", "Ranadeep", ""], ["He", "Zhuoqiong", ""]]}, {"id": "2004.02360", "submitter": "Zezhong Zhang", "authors": "Zezhong Zhang, Keyu Nie and Ted Tao Yuan", "title": "Moving Metric Detection and Alerting System at eBay", "comments": "The work is oral presented on the AAAI-20 Workshop on Cloud\n  Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At eBay, there are thousands of product health metrics for different domain\nteams to monitor. We built a two-phase alerting system to notify users with\nactionable alerts based on anomaly detection and alert retrieval. In the first\nphase, we developed an efficient anomaly detection algorithm, called Moving\nMetric Detector (MMD), to identify potential alerts among metrics with\ndistribution agnostic criteria. In the second alert retrieval phase, we built\nadditional logic with feedbacks to select valid actionable alerts with\npoint-wise ranking model and business rules. Compared with other trend and\nseasonality decomposition methods, our decomposer is faster and better to\ndetect anomalies in unsupervised cases. Our two-phase approach dramatically\nimproves alert precision and avoids alert spamming in eBay production.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 00:28:39 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Zezhong", ""], ["Nie", "Keyu", ""], ["Yuan", "Ted Tao", ""]]}, {"id": "2004.02380", "submitter": "Philippe Morere", "authors": "Philippe Morere and Fabio Ramos", "title": "Intrinsic Exploration as Multi-Objective RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic motivation enables reinforcement learning (RL) agents to explore\nwhen rewards are very sparse, where traditional exploration heuristics such as\nBoltzmann or e-greedy would typically fail. However, intrinsic exploration is\ngenerally handled in an ad-hoc manner, where exploration is not treated as a\ncore objective of the learning process; this weak formulation leads to\nsub-optimal exploration performance. To overcome this problem, we propose a\nframework based on multi-objective RL where both exploration and exploitation\nare being optimized as separate objectives. This formulation brings the balance\nbetween exploration and exploitation at a policy level, resulting in advantages\nover traditional methods. This also allows for controlling exploration while\nlearning, at no extra cost. Such strategies achieve a degree of control over\nagent exploration that was previously unattainable with classic or intrinsic\nrewards. We demonstrate scalability to continuous state-action spaces by\npresenting a method (EMU-Q) based on our framework, guiding exploration towards\nregions of higher value-function uncertainty. EMU-Q is experimentally shown to\noutperform classic exploration techniques and other intrinsic RL methods on a\ncontinuous control benchmark and on a robotic manipulator.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:37:29 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Morere", "Philippe", ""], ["Ramos", "Fabio", ""]]}, {"id": "2004.02382", "submitter": "Raed Al Kontar", "authors": "Moyan Li, Raed Kontar", "title": "On Negative Transfer and Structure of Latent Functions in Multi-output\n  Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-output Gaussian process ($\\mathcal{MGP}$) is based on the\nassumption that outputs share commonalities, however, if this assumption does\nnot hold negative transfer will lead to decreased performance relative to\nlearning outputs independently or in subsets. In this article, we first define\nnegative transfer in the context of an $\\mathcal{MGP}$ and then derive\nnecessary conditions for an $\\mathcal{MGP}$ model to avoid negative transfer.\nSpecifically, under the convolution construction, we show that avoiding\nnegative transfer is mainly dependent on having a sufficient number of latent\nfunctions $Q$ regardless of the flexibility of the kernel or inference\nprocedure used. However, a slight increase in $Q$ leads to a large increase in\nthe number of parameters to be estimated. To this end, we propose two latent\nstructures that scale to arbitrarily large datasets, can avoid negative\ntransfer and allow any kernel or sparse approximations to be used within. These\nstructures also allow regularization which can provide consistent and automatic\nselection of related outputs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:47:30 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Li", "Moyan", ""], ["Kontar", "Raed", ""]]}, {"id": "2004.02391", "submitter": "Xinglei Wang", "authors": "Xinglei Wang, Xuefeng Guan, Jun Cao, Na Zhang, Huayi Wu", "title": "Forecast Network-Wide Traffic States for Multiple Steps Ahead: A Deep\n  Learning Approach Considering Dynamic Non-Local Spatial Correlation and\n  Non-Stationary Temporal Dependency", "comments": "29 pages, 16 figures, 3 tables", "journal-ref": "Transportation research part C: emerging technologies. 119 (2020):\n  102763", "doi": "10.1016/j.trc.2020.102763", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining accurate information about future traffic flows of all links in a\ntraffic network is of great importance for traffic management and control\napplications. This research studies two particular problems in traffic\nforecasting: (1) capture the dynamic and non-local spatial correlation between\ntraffic links and (2) model the dynamics of temporal dependency for accurate\nmultiple steps ahead predictions. To address these issues, we propose a deep\nlearning framework named Spatial-Temporal Sequence to Sequence model\n(STSeq2Seq). This model builds on sequence to sequence (seq2seq) architecture\nto capture temporal feature and relies on graph convolution for aggregating\nspatial information. Moreover, STSeq2Seq defines and constructs pattern-aware\nadjacency matrices (PAMs) based on pair-wise similarity of the recent traffic\npatterns on traffic links and integrate it into graph convolution operation. It\nalso deploys a novel seq2sesq architecture which couples a convolutional\nencoder and a recurrent decoder with attention mechanism for dynamic modeling\nof long-range dependence between different time steps. We conduct extensive\nexperiments using two publicly-available large-scale traffic datasets and\ncompare STSeq2Seq with other baseline models. The numerical results demonstrate\nthat the proposed model achieves state-of-the-art forecasting performance in\nterms of various error measures. The ablation study verifies the effectiveness\nof PAMs in capturing dynamic non-local spatial correlation and the superiority\nof proposed seq2seq architecture in modeling non-stationary temporal dependency\nfor multiple steps ahead prediction. Furthermore, qualitative analysis is\nconducted on PAMs as well as the attention weights for model interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 03:40:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Wang", "Xinglei", ""], ["Guan", "Xuefeng", ""], ["Cao", "Jun", ""], ["Zhang", "Na", ""], ["Wu", "Huayi", ""]]}, {"id": "2004.02396", "submitter": "Jun Chen", "authors": "Jun Chen, Liang Liu, Yong Liu, Xianfang Zeng", "title": "A Learning Framework for n-bit Quantized Neural Networks toward FPGAs", "comments": "This paper has been accepted for publication in the IEEE Transactions\n  on Neural Networks and Learning Systems", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems 2020", "doi": "10.1109/TNNLS.2020.2980041", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantized neural network (QNN) is an efficient approach for network\ncompression and can be widely used in the implementation of FPGAs. This paper\nproposes a novel learning framework for n-bit QNNs, whose weights are\nconstrained to the power of two. To solve the gradient vanishing problem, we\npropose a reconstructed gradient function for QNNs in back-propagation\nalgorithm that can directly get the real gradient rather than estimating an\napproximate gradient of the expected loss. We also propose a novel QNN\nstructure named n-BQ-NN, which uses shift operation to replace the multiply\noperation and is more suitable for the inference on FPGAs. Furthermore, we also\ndesign a shift vector processing element (SVPE) array to replace all 16-bit\nmultiplications with SHIFT operations in convolution operation on FPGAs. We\nalso carry out comparable experiments to evaluate our framework. The\nexperimental results show that the quantized models of ResNet, DenseNet and\nAlexNet through our learning framework can achieve almost the same accuracies\nwith the original full-precision models. Moreover, when using our learning\nframework to train our n-BQ-NN from scratch, it can achieve state-of-the-art\nresults compared with typical low-precision QNNs. Experiments on Xilinx ZCU102\nplatform show that our n-BQ-NN with our SVPE can execute 2.9 times faster than\nwith the vector processing element (VPE) in inference. As the SHIFT operation\nin our SVPE array will not consume Digital Signal Processings (DSPs) resources\non FPGAs, the experiments have shown that the use of SVPE array also reduces\naverage energy consumption to 68.7% of the VPE array with 16-bit.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:21:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Chen", "Jun", ""], ["Liu", "Liang", ""], ["Liu", "Yong", ""], ["Zeng", "Xianfang", ""]]}, {"id": "2004.02401", "submitter": "Wei Peng", "authors": "Choon Meng Lee, Jianfeng Liu, Wei Peng", "title": "Applying Cyclical Learning Rate to Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In training deep learning networks, the optimizer and related learning rate\nare often used without much thought or with minimal tuning, even though it is\ncrucial in ensuring a fast convergence to a good quality minimum of the loss\nfunction that can also generalize well on the test dataset. Drawing inspiration\nfrom the successful application of cyclical learning rate policy for computer\nvision related convolutional networks and datasets, we explore how cyclical\nlearning rate can be applied to train transformer-based neural networks for\nneural machine translation. From our carefully designed experiments, we show\nthat the choice of optimizers and the associated cyclical learning rate policy\ncan have a significant impact on the performance. In addition, we establish\nguidelines when applying cyclical learning rates to neural machine translation\ntasks. Thus with our work, we hope to raise awareness of the importance of\nselecting the right optimizers and the accompanying learning rate policy, at\nthe same time, encourage further research into easy-to-use learning rate\npolicies.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:45:49 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lee", "Choon Meng", ""], ["Liu", "Jianfeng", ""], ["Peng", "Wei", ""]]}, {"id": "2004.02420", "submitter": "Cunhang Fan", "authors": "Cunhang Fan and Jianhua Tao and Bin Liu and Jiangyan Yi and Zhengqi\n  Wen", "title": "Simultaneous Denoising and Dereverberation Using Deep Embedding Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monaural speech dereverberation is a very challenging task because no spatial\ncues can be used. When the additive noises exist, this task becomes more\nchallenging. In this paper, we propose a joint training method for simultaneous\nspeech denoising and dereverberation using deep embedding features, which is\nbased on the deep clustering (DC). DC is a state-of-the-art method for speech\nseparation that includes embedding learning and K-means clustering. As for our\nproposed method, it contains two stages: denoising and dereverberation. At the\ndenoising stage, the DC network is leveraged to extract noise-free deep\nembedding features. These embedding features are generated from the anechoic\nspeech and residual reverberation signals. They can represent the inferred\nspectral masking patterns of the desired signals, which are discriminative\nfeatures. At the dereverberation stage, instead of using the unsupervised\nK-means clustering algorithm, another supervised neural network is utilized to\nestimate the anechoic speech from these deep embedding features. Finally, the\ndenoising stage and dereverberation stage are optimized by the joint training\nmethod. Experimental results show that the proposed method outperforms the WPE\nand BLSTM baselines, especially in the low SNR condition.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:34:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Fan", "Cunhang", ""], ["Tao", "Jianhua", ""], ["Liu", "Bin", ""], ["Yi", "Jiangyan", ""], ["Wen", "Zhengqi", ""]]}, {"id": "2004.02423", "submitter": "Darren Yates", "authors": "Darren Yates and Md Zahidul Islam", "title": "FastForest: Increasing Random Forest Processing Speed While Maintaining\n  Accuracy", "comments": "20 pages, 10 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Forest remains one of Data Mining's most enduring ensemble algorithms,\nachieving well-documented levels of accuracy and processing speed, as well as\nregularly appearing in new research. However, with data mining now reaching the\ndomain of hardware-constrained devices such as smartphones and Internet of\nThings (IoT) devices, there is continued need for further research into\nalgorithm efficiency to deliver greater processing speed without sacrificing\naccuracy. Our proposed FastForest algorithm delivers an average 24% increase in\nprocessing speed compared with Random Forest whilst maintaining (and frequently\nexceeding) it on classification accuracy over tests involving 45 datasets.\nFastForest achieves this result through a combination of three optimising\ncomponents - Subsample Aggregating ('Subbagging'), Logarithmic Split-Point\nSampling and Dynamic Restricted Subspacing. Moreover, detailed testing of\nSubbagging sizes has found an optimal scalar delivering a positive mix of\nprocessing performance and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:37:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Yates", "Darren", ""], ["Islam", "Md Zahidul", ""]]}, {"id": "2004.02425", "submitter": "Kirankumar Shiragur", "authors": "Nima Anari, Moses Charikar, Kirankumar Shiragur, Aaron Sidford", "title": "The Bethe and Sinkhorn Permanents of Low Rank Matrices and Implications\n  for Profile Maximum Likelihood", "comments": "59 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.LG math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of computing the likelihood of the\nprofile of a discrete distribution, i.e., the probability of observing the\nmultiset of element frequencies, and computing a profile maximum likelihood\n(PML) distribution, i.e., a distribution with the maximum profile likelihood.\nFor each problem we provide polynomial time algorithms that given $n$ i.i.d.\\\nsamples from a discrete distribution, achieve an approximation factor of\n$\\exp\\left(-O(\\sqrt{n} \\log n) \\right)$, improving upon the previous best-known\nbound achievable in polynomial time of $\\exp(-O(n^{2/3} \\log n))$ (Charikar,\nShiragur and Sidford, 2019). Through the work of Acharya, Das, Orlitsky and\nSuresh (2016), this implies a polynomial time universal estimator for symmetric\nproperties of discrete distributions in a broader range of error parameter.\n  We achieve these results by providing new bounds on the quality of\napproximation of the Bethe and Sinkhorn permanents (Vontobel, 2012 and 2014).\nWe show that each of these are $\\exp(O(k \\log(N/k)))$ approximations to the\npermanent of $N \\times N$ matrices with non-negative rank at most $k$,\nimproving upon the previous known bounds of $\\exp(O(N))$. To obtain our results\non PML, we exploit the fact that the PML objective is proportional to the\npermanent of a certain Vandermonde matrix with $\\sqrt{n}$ distinct columns,\ni.e. with non-negative rank at most $\\sqrt{n}$. As a by-product of our work we\nestablish a surprising connection between the convex relaxation in prior work\n(CSS19) and the well-studied Bethe and Sinkhorn approximations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 06:40:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Anari", "Nima", ""], ["Charikar", "Moses", ""], ["Shiragur", "Kirankumar", ""], ["Sidford", "Aaron", ""]]}, {"id": "2004.02435", "submitter": "Mahesh Subedar", "authors": "Shashank Bujimalla, Mahesh Subedar, Omesh Tickoo", "title": "B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian deep neural networks (DNNs) can provide a mathematically grounded\nframework to quantify uncertainty in predictions from image captioning models.\nWe propose a Bayesian variant of policy-gradient based reinforcement learning\ntraining technique for image captioning models to directly optimize\nnon-differentiable image captioning quality metrics such as CIDEr-D. We extend\nthe well-known Self-Critical Sequence Training (SCST) approach for image\ncaptioning models by incorporating Bayesian inference, and refer to it as\nB-SCST. The \"baseline\" for the policy-gradients in B-SCST is generated by\naveraging predictive quality metrics (CIDEr-D) of the captions drawn from the\ndistribution obtained using a Bayesian DNN model. We infer this predictive\ndistribution using Monte Carlo (MC) dropout approximate variational inference.\nWe show that B-SCST improves CIDEr-D scores on Flickr30k, MS COCO and VizWiz\nimage captioning datasets, compared to the SCST approach. We also provide a\nstudy of uncertainty quantification for the predicted captions, and demonstrate\nthat it correlates well with the CIDEr-D scores. To our knowledge, this is the\nfirst such analysis, and it can improve the interpretability of image\ncaptioning model outputs, which is critical for practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:07:41 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:37:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bujimalla", "Shashank", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "2004.02441", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Pratik Chaudhari, Jonas Mueller, Alexander J. Smola", "title": "TraDE: Transformers for Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TraDE, a self-attention-based architecture for auto-regressive\ndensity estimation with continuous and discrete valued data. Our model is\ntrained using a penalized maximum likelihood objective, which ensures that\nsamples from the density estimate resemble the training data distribution. The\nuse of self-attention means that the model need not retain conditional\nsufficient statistics during the auto-regressive process beyond what is needed\nfor each covariate. On standard tabular and image data benchmarks, TraDE\nproduces significantly better density estimates than existing approaches such\nas normalizing flow estimators and recurrent auto-regressive models. However\nlog-likelihood on held-out data only partially reflects how useful these\nestimates are in real-world applications. In order to systematically evaluate\ndensity estimators, we present a suite of tasks such as regression using\ngenerated samples, out-of-distribution detection, and robustness to noise in\nthe training data and demonstrate that TraDE works well in these scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:32:51 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 20:22:00 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Fakoor", "Rasool", ""], ["Chaudhari", "Pratik", ""], ["Mueller", "Jonas", ""], ["Smola", "Alexander J.", ""]]}, {"id": "2004.02457", "submitter": "Anna Kazeykina", "authors": "Giovanni Conforti (CMAP), Anna Kazeykina (LMO), Zhenjie Ren (CEREMADE)", "title": "Game on Random Environment, Mean-field Langevin System and Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG cs.NE math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a type of games regularized by the relative entropy,\nwhere the players' strategies are coupled through a random environment\nvariable. Besides the existence and the uniqueness of equilibria of such games,\nwe prove that the marginal laws of the corresponding mean-field Langevin\nsystems can converge towards the games' equilibria in different settings. As\napplications, the dynamic games can be treated as games on a random environment\nwhen one treats the time horizon as the environment. In practice, our results\ncan be applied to analysing the stochastic gradient descent algorithm for deep\nneural networks in the context of supervised learning as well as for the\ngenerative adversarial networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:59:05 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 21:52:22 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Conforti", "Giovanni", "", "CMAP"], ["Kazeykina", "Anna", "", "LMO"], ["Ren", "Zhenjie", "", "CEREMADE"]]}, {"id": "2004.02489", "submitter": "Dhruval Jain", "authors": "Dhruval Jain, DP Mohanty, Sanjeev Roy, Naresh Purre, Sukumar Moharana", "title": "On-device Filtering of Social Media Images for Efficient Storage", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206933", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificially crafted images such as memes, seasonal greetings, etc are\nflooding the social media platforms today. These eventually start occupying a\nlot of internal memory of smartphones and it gets cumbersome for the user to go\nthrough hundreds of images and delete these synthetic images. To address this,\nwe propose a novel method based on Convolutional Neural Networks (CNNs) for the\non-device filtering of social media images by classifying these synthetic\nimages and allowing the user to delete them in one go. The custom model uses\ndepthwise separable convolution layers to achieve low inference time on\nsmartphones. We have done an extensive evaluation of our model on various\ncamera image datasets to cover most aspects of images captured by a camera.\nVarious sorts of synthetic social media images have also been tested. The\nproposed solution achieves an accuracy of 98.25% on the Places-365 dataset and\n95.81% on the Synthetic image dataset that we have prepared containing 30K\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 08:49:29 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 20:40:49 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Jain", "Dhruval", ""], ["Mohanty", "DP", ""], ["Roy", "Sanjeev", ""], ["Purre", "Naresh", ""], ["Moharana", "Sukumar", ""]]}, {"id": "2004.02541", "submitter": "Daniel Michelsanti", "authors": "Daniel Michelsanti, Olga Slizovskaia, Gloria Haro, Emilia G\\'omez,\n  Zheng-Hua Tan, Jesper Jensen", "title": "Vocoder-Based Speech Synthesis from Silent Videos", "comments": "Accepted to Interspeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both acoustic and visual information influence human perception of speech.\nFor this reason, the lack of audio in a video sequence determines an extremely\nlow speech intelligibility for untrained lip readers. In this paper, we present\na way to synthesise speech from the silent video of a talker using deep\nlearning. The system learns a mapping function from raw video frames to\nacoustic features and reconstructs the speech with a vocoder synthesis\nalgorithm. To improve speech reconstruction performance, our model is also\ntrained to predict text information in a multi-task learning fashion and it is\nable to simultaneously reconstruct and recognise speech in real time. The\nresults in terms of estimated speech quality and intelligibility show the\neffectiveness of our method, which exhibits an improvement over existing\nvideo-to-speech approaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 10:22:04 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 22:00:42 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Michelsanti", "Daniel", ""], ["Slizovskaia", "Olga", ""], ["Haro", "Gloria", ""], ["G\u00f3mez", "Emilia", ""], ["Tan", "Zheng-Hua", ""], ["Jensen", "Jesper", ""]]}, {"id": "2004.02551", "submitter": "Guillaume Tauzin", "authors": "Guillaume Tauzin, Umberto Lupo, Lewis Tunstall, Julian Burella\n  P\\'erez, Matteo Caorsi, Wojciech Reise, Anibal Medina-Mardones, Alberto\n  Dassatti and Kathryn Hess", "title": "giotto-tda: A Topological Data Analysis Toolkit for Machine Learning and\n  Data Exploration", "comments": "7 pages, 2 figures", "journal-ref": "NeurIPS 2020 workshop \"Topological Data Analysis and beyond\"\n  (https://openreview.net/forum?id=fjQtZJOCTXf); JMLR 22\n  (https://www.jmlr.org/papers/v22/20-325.html)", "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce giotto-tda, a Python library that integrates high-performance\ntopological data analysis with machine learning via a scikit-learn-compatible\nAPI and state-of-the-art C++ implementations. The library's ability to handle\nvarious types of data is rooted in a wide range of preprocessing techniques,\nand its strong focus on data exploration and interpretability is aided by an\nintuitive plotting API. Source code, binaries, examples, and documentation can\nbe found at https://github.com/giotto-ai/giotto-tda.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 10:53:57 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 19:05:57 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Tauzin", "Guillaume", ""], ["Lupo", "Umberto", ""], ["Tunstall", "Lewis", ""], ["P\u00e9rez", "Julian Burella", ""], ["Caorsi", "Matteo", ""], ["Reise", "Wojciech", ""], ["Medina-Mardones", "Anibal", ""], ["Dassatti", "Alberto", ""], ["Hess", "Kathryn", ""]]}, {"id": "2004.02555", "submitter": "Yinglong Ma", "authors": "Jingpeng Zhao and Yinglong Ma", "title": "Joint Embedding of Words and Category Labels for Hierarchical\n  Multi-label Text Classification", "comments": "The submitted paper (Identifier: arXiv:2004.02555) has a problem of\n  authorship disputes within a collaboration of authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text classification has become increasingly challenging due to the continuous\nrefinement of classification label granularity and the expansion of\nclassification label scale. To address that, some research has been applied\nonto strategies that exploit the hierarchical structure in problems with a\nlarge number of categories. At present, hierarchical text classification (HTC)\nhas received extensive attention and has broad application prospects. Making\nfull use of the relationship between parent category and child category in text\nclassification task can greatly improve the performance of classification. In\nthis paper, We propose a joint embedding of text and parent category based on\nhierarchical fine-tuning ordered neurons LSTM (HFT-ONLSTM) for HTC. Our method\nmakes full use of the connection between the upper-level and lower-level\nlabels. Experiments show that our model outperforms the state-of-the-art\nhierarchical model at a lower computation cost.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:06:08 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 06:35:41 GMT"}, {"version": "v3", "created": "Wed, 26 Aug 2020 03:20:30 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Zhao", "Jingpeng", ""], ["Ma", "Yinglong", ""]]}, {"id": "2004.02561", "submitter": "Tom Vander Aa", "authors": "Tom Vander Aa, Xiangju Qin, Paul Blomstedt, Roel Wuyts, Wilfried\n  Verachtert, Samuel Kaski", "title": "A High-Performance Implementation of Bayesian Matrix Factorization with\n  Limited Communication", "comments": "European Commission Project: EPEEC - European joint Effort toward a\n  Highly Productive Programming Environment for Heterogeneous Exascale\n  Computing (EC-H2020-80151)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a very common machine learning technique in\nrecommender systems. Bayesian Matrix Factorization (BMF) algorithms would be\nattractive because of their ability to quantify uncertainty in their\npredictions and avoid over-fitting, combined with high prediction accuracy.\nHowever, they have not been widely used on large-scale data because of their\nprohibitive computational cost. In recent work, efforts have been made to\nreduce the cost, both by improving the scalability of the BMF algorithm as well\nas its implementation, but so far mainly separately. In this paper we show that\nthe state-of-the-art of both approaches to scalability can be combined. We\ncombine the recent highly-scalable Posterior Propagation algorithm for BMF,\nwhich parallelizes computation of blocks of the matrix, with a distributed BMF\nimplementation that users asynchronous communication within each block. We show\nthat the combination of the two methods gives substantial improvements in the\nscalability of BMF on web-scale datasets, when the goal is to reduce the\nwall-clock time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:16:30 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 07:41:19 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Aa", "Tom Vander", ""], ["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Wuyts", "Roel", ""], ["Verachtert", "Wilfried", ""], ["Kaski", "Samuel", ""]]}, {"id": "2004.02569", "submitter": "Jyri Kimari", "authors": "Jussi M\\\"a\\\"att\\\"a, Viacheslav Bazaliy, Jyri Kimari, Flyura\n  Djurabekova, Kai Nordlund, Teemu Roos", "title": "Gradient-Based Training and Pruning of Radial Basis Function Networks\n  with an Application in Materials Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many applications, especially in physics and other sciences, call for easily\ninterpretable and robust machine learning techniques. We propose a fully\ngradient-based technique for training radial basis function networks with an\nefficient and scalable open-source implementation. We derive novel closed-form\noptimization criteria for pruning the models for continuous as well as binary\ndata which arise in a challenging real-world material physics problem. The\npruned models are optimized to provide compact and interpretable versions of\nlarger models based on informed assumptions about the data distribution.\nVisualizations of the pruned models provide insight into the atomic\nconfigurations that determine atom-level migration processes in solid matter;\nthese results may inform future research on designing more suitable descriptors\nfor use with machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:32:37 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["M\u00e4\u00e4tt\u00e4", "Jussi", ""], ["Bazaliy", "Viacheslav", ""], ["Kimari", "Jyri", ""], ["Djurabekova", "Flyura", ""], ["Nordlund", "Kai", ""], ["Roos", "Teemu", ""]]}, {"id": "2004.02581", "submitter": "Najmeh Abiri", "authors": "Najmeh Abiri and Mattias Ohlsson", "title": "Variational auto-encoders with Student's t-prior", "comments": null, "journal-ref": "ESANN 2019 Proceedings, 27th European Symposium on Artificial\n  Neural Networks, Computational Intelligence and Machine Learning: Bruges\n  April 2019, Bruges: ESANN , 2019, p. 415-420", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose a new structure for the variational auto-encoders (VAEs) prior,\nwith the weakly informative multivariate Student's t-distribution. In the\nproposed model all distribution parameters are trained, thereby allowing for a\nmore robust approximation of the underlying data distribution. We used\nFashion-MNIST data in two experiments to compare the proposed VAEs with the\nstandard Gaussian priors. Both experiments showed a better reconstruction of\nthe images with VAEs using Student's t-prior distribution.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:54:20 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abiri", "Najmeh", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2004.02583", "submitter": "Chao Yang", "authors": "Chuanfu Xiao and Chao Yang and Min Li", "title": "Efficient Alternating Least Squares Algorithms for Low Multilinear Rank\n  Approximation of Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low multilinear rank approximation, also known as the truncated Tucker\ndecomposition, has been extensively utilized in many applications that involve\nhigher-order tensors. Popular methods for low multilinear rank approximation\nusually rely directly on matrix SVD, therefore often suffer from the notorious\nintermediate data explosion issue and are not easy to parallelize, especially\nwhen the input tensor is large. In this paper, we propose a new class of\ntruncated HOSVD algorithms based on alternating least squares (ALS) for\nefficiently computing the low multilinear rank approximation of tensors. The\nproposed ALS-based approaches are able to eliminate the redundant computations\nof the singular vectors of intermediate matrices and are therefore free of data\nexplosion. Also, the new methods are more flexible with adjustable convergence\ntolerance and are intrinsically parallelizable on high-performance computers.\nTheoretical analysis reveals that the ALS iteration in the proposed algorithms\nis q-linear convergent with a relatively wide convergence region. Numerical\nexperiments with large-scale tensors from both synthetic and real-world\napplications demonstrate that ALS-based methods can substantially reduce the\ntotal cost of the original ones and are highly scalable for parallel computing.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:58:04 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 09:27:28 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 02:56:22 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 02:45:12 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Xiao", "Chuanfu", ""], ["Yang", "Chao", ""], ["Li", "Min", ""]]}, {"id": "2004.02584", "submitter": "Najmeh Abiri", "authors": "Najmeh Abiri, Bj\\\"orn Linse, Patrik Ed\\'en and Mattias Ohlsson", "title": "Establishing strong imputation performance of a denoising autoencoder in\n  a wide range of missing data problems", "comments": null, "journal-ref": "Neurocomputing Volume 365, 6 November 2019, Pages 137-146", "doi": "10.1016/j.neucom.2019.07.065", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Dealing with missing data in data analysis is inevitable. Although powerful\nimputation methods that address this problem exist, there is still much room\nfor improvement. In this study, we examined single imputation based on deep\nautoencoders, motivated by the apparent success of deep learning to efficiently\nextract useful dataset features. We have developed a consistent framework for\nboth training and imputation. Moreover, we benchmarked the results against\nstate-of-the-art imputation methods on different data sizes and\ncharacteristics. The work was not limited to the one-type variable dataset; we\nalso imputed missing data with multi-type variables, e.g., a combination of\nbinary, categorical, and continuous attributes. To evaluate the imputation\nmethods, we randomly corrupted the complete data, with varying degrees of\ncorruption, and then compared the imputed and original values. In all\nexperiments, the developed autoencoder obtained the smallest error for all\nranges of initial data corruption.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:00:30 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abiri", "Najmeh", ""], ["Linse", "Bj\u00f6rn", ""], ["Ed\u00e9n", "Patrik", ""], ["Ohlsson", "Mattias", ""]]}, {"id": "2004.02589", "submitter": "Pourya Farzi", "authors": "Ahmad Hasanpour, Pourya Farzi, Ali Tehrani, Reza Akbari", "title": "Software Defect Prediction Based On Deep Learning Models: Performance\n  Study", "comments": "10 pages, 4 figures, 6 tables, 42 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, defect prediction, one of the major software engineering\nproblems, has been in the focus of researchers since it has a pivotal role in\nestimating software errors and faulty modules. Researchers with the goal of\nimproving prediction accuracy have developed many models for software defect\nprediction. However, there are a number of critical conditions and theoretical\nproblems in order to achieve better results. In this paper, two deep learning\nmodels, Stack Sparse Auto-Encoder (SSAE) and Deep Belief Network (DBN), are\ndeployed to classify NASA datasets, which are unbalanced and have insufficient\nsamples. According to the conducted experiment, the accuracy for the datasets\nwith sufficient samples is enhanced and beside this SSAE model gains better\nresults in comparison to DBN model in the majority of evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 06:02:14 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hasanpour", "Ahmad", ""], ["Farzi", "Pourya", ""], ["Tehrani", "Ali", ""], ["Akbari", "Reza", ""]]}, {"id": "2004.02593", "submitter": "Floris Geerts", "authors": "Floris Geerts, Filip Mazowiecki and Guillermo A. P\\'erez", "title": "Let's Agree to Degree: Comparing Graph Convolutional Networks in the\n  Message-Passing Framework", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we cast neural networks defined on graphs as message-passing\nneural networks (MPNNs) in order to study the distinguishing power of different\nclasses of such models. We are interested in whether certain architectures are\nable to tell vertices apart based on the feature labels given as input with the\ngraph. We consider two variants of MPNNS: anonymous MPNNs whose message\nfunctions depend only on the labels of vertices involved; and degree-aware\nMPNNs in which message functions can additionally use information regarding the\ndegree of vertices. The former class covers a popular formalisms for computing\nfunctions on graphs: graph neural networks (GNN). The latter covers the\nso-called graph convolutional networks (GCNs), a recently introduced variant of\nGNNs by Kipf and Welling. We obtain lower and upper bounds on the\ndistinguishing power of MPNNs in terms of the distinguishing power of the\nWeisfeiler-Lehman (WL) algorithm. Our results imply that (i) the distinguishing\npower of GCNs is bounded by the WL algorithm, but that they are one step ahead;\n(ii) the WL algorithm cannot be simulated by \"plain vanilla\" GCNs but the\naddition of a trade-off parameter between features of the vertex and those of\nits neighbours (as proposed by Kipf and Welling themselves) resolves this\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:14:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Geerts", "Floris", ""], ["Mazowiecki", "Filip", ""], ["P\u00e9rez", "Guillermo A.", ""]]}, {"id": "2004.02594", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao,\n  Dawei Yin", "title": "Data Manipulation: Towards Effective Instance Learning for Neural\n  Dialogue Generation via Learning to Augment and Reweight", "comments": "To appear at ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art neural dialogue models learn from human\nconversations following the data-driven paradigm. As such, a reliable training\ncorpus is the crux of building a robust and well-behaved dialogue model.\nHowever, due to the open-ended nature of human conversations, the quality of\nuser-generated training data varies greatly, and effective training samples are\ntypically insufficient while noisy samples frequently appear. This impedes the\nlearning of those data-driven neural dialogue models. Therefore, effective\ndialogue learning requires not only more reliable learning samples, but also\nfewer noisy samples. In this paper, we propose a data manipulation framework to\nproactively reshape the data distribution towards reliable samples by\naugmenting and highlighting effective learning samples as well as reducing the\neffect of inefficient samples simultaneously. In particular, the data\nmanipulation model selectively augments the training samples and assigns an\nimportance weight to each instance to reform the training data. Note that, the\nproposed data manipulation framework is fully data-driven and learnable. It not\nonly manipulates training samples to optimize the dialogue generation model,\nbut also learns to increase its manipulation skills through gradient descent\nwith validation samples. Extensive experiments show that our framework can\nimprove the dialogue generation performance with respect to various automatic\nevaluation metrics and human judgments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:14:09 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 01:30:15 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 05:48:22 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 09:51:39 GMT"}, {"version": "v5", "created": "Thu, 11 Jun 2020 14:01:55 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Cai", "Hengyi", ""], ["Chen", "Hongshen", ""], ["Song", "Yonghao", ""], ["Zhang", "Cheng", ""], ["Zhao", "Xiaofang", ""], ["Yin", "Dawei", ""]]}, {"id": "2004.02596", "submitter": "Bhushan Kotnis", "authors": "Bhushan Kotnis, Carolin Lawrence, Mathias Niepert", "title": "Answering Complex Queries in Knowledge Graphs with Bidirectional\n  Sequence Encoders", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning for knowledge graphs (KGs) has focused on the problem\nof answering simple link prediction queries. In this work we address the more\nambitious challenge of predicting the answers of conjunctive queries with\nmultiple missing entities. We propose Bi-Directional Query Embedding (BIQE), a\nmethod that embeds conjunctive queries with models based on bi-directional\nattention mechanisms. Contrary to prior work, bidirectional self-attention can\ncapture interactions among all the elements of a query graph. We introduce a\nnew dataset for predicting the answer of conjunctive query and conduct\nexperiments that show BIQE significantly outperforming state of the art\nbaselines.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:17:57 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:07:25 GMT"}, {"version": "v3", "created": "Tue, 2 Feb 2021 22:30:36 GMT"}, {"version": "v4", "created": "Thu, 4 Feb 2021 11:23:52 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Kotnis", "Bhushan", ""], ["Lawrence", "Carolin", ""], ["Niepert", "Mathias", ""]]}, {"id": "2004.02607", "submitter": "Tomas Kulvicius", "authors": "Tomas Kulvicius, Irene Markelic, Minija Tamosiunaite and Florentin\n  W\\\"org\\\"otter", "title": "Semantic Image Search for Robotic Applications", "comments": null, "journal-ref": "22nd International Workshop on Robotics in Alpe-Adria-Danube\n  Region (RAAD 2013), September 11-13, 2013, Portoroz, Slovenia", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization in robotics is one of the most important problems. New\ngeneralization approaches use internet databases in order to solve new tasks.\nModern search engines can return a large amount of information according to a\nquery within milliseconds. However, not all of the returned information is task\nrelevant, partly due to the problem of polysemes. Here we specifically address\nthe problem of object generalization by using image search. We suggest a\nbi-modal solution, combining visual and textual information, based on the\nobservation that humans use additional linguistic cues to demarcate intended\nword meaning. We evaluate the quality of our approach by comparing it to human\nlabelled data and find that, on average, our approach leads to improved results\nin comparison to Google searches, and that it can treat the problem of\npolysemes.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:09:06 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kulvicius", "Tomas", ""], ["Markelic", "Irene", ""], ["Tamosiunaite", "Minija", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "2004.02610", "submitter": "Chuanzheng Wang", "authors": "Chuanzheng Wang, Yinan Li, Stephen L. Smith, Jun Liu", "title": "Continuous Motion Planning with Temporal Logic Specifications using Deep\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a model-free reinforcement learning method to\nsynthesize control policies for motion planning problems with continuous states\nand actions. The robot is modelled as a labeled discrete-time Markov decision\nprocess (MDP) with continuous state and action spaces. Linear temporal logics\n(LTL) are used to specify high-level tasks. We then train deep neural networks\nto approximate the value function and policy using an actor-critic\nreinforcement learning method. The LTL specification is converted into an\nannotated limit-deterministic B\\\"uchi automaton (LDBA) for continuously shaping\nthe reward so that dense rewards are available during training. A na\\\"ive way\nof solving a motion planning problem with LTL specifications using\nreinforcement learning is to sample a trajectory and then assign a high reward\nfor training if the trajectory satisfies the entire LTL formula. However, the\nsampling complexity needed to find such a trajectory is too high when we have a\ncomplex LTL formula for continuous state and action spaces. As a result, it is\nvery unlikely that we get enough reward for training if all sample trajectories\nstart from the initial state in the automata. In this paper, we propose a\nmethod that samples not only an initial state from the state space, but also an\narbitrary state in the automata at the beginning of each training episode. We\ntest our algorithm in simulation using a car-like robot and find out that our\nmethod can learn policies for different working configurations and LTL\nspecifications successfully.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:58:03 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 19:18:54 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Chuanzheng", ""], ["Li", "Yinan", ""], ["Smith", "Stephen L.", ""], ["Liu", "Jun", ""]]}, {"id": "2004.02620", "submitter": "Ciro Javier Diaz Penedo", "authors": "Ciro Javier Diaz Penedo and Lucas Leonardo Silveira Costa", "title": "Grouping headlines", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we deal with the problem of grouping in headlines of the\nnewspaper ABC (Australian Bro-adcasting Corporation) using unsupervised machine\nlearning techniques. We present and discuss the results on the clusters found\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 04:03:56 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Penedo", "Ciro Javier Diaz", ""], ["Costa", "Lucas Leonardo Silveira", ""]]}, {"id": "2004.02621", "submitter": "Mustafa Abdool", "authors": "Mustafa Abdool, Malay Haldar, Prashant Ramanathan, Tyler Sax, Lanbo\n  Zhang, Aamir Mansawala, Shulin Yang, Thomas Legrand", "title": "Managing Diversity in Airbnb Search", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long-standing questions in search systems is the role of diversity\nin results. From a product perspective, showing diverse results provides the\nuser with more choice and should lead to an improved experience. However, this\nintuition is at odds with common machine learning approaches to ranking which\ndirectly optimize the relevance of each individual item without a holistic view\nof the result set. In this paper, we describe our journey in tackling the\nproblem of diversity for Airbnb search, starting from heuristic based\napproaches and concluding with a novel deep learning solution that produces an\nembedding of the entire query context by leveraging Recurrent Neural Networks\n(RNNs). We hope our lessons learned will prove useful to others and motivate\nfurther research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 20:54:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Abdool", "Mustafa", ""], ["Haldar", "Malay", ""], ["Ramanathan", "Prashant", ""], ["Sax", "Tyler", ""], ["Zhang", "Lanbo", ""], ["Mansawala", "Aamir", ""], ["Yang", "Shulin", ""], ["Legrand", "Thomas", ""]]}, {"id": "2004.02625", "submitter": "Amir Mosavi Prof", "authors": "Dangquan Zhang, Muhammad Aqeel Ashraf, Zhenling Liu, Wan-Xi Peng,\n  Mohammad Javad Golkar, Amir Mosavi", "title": "Dynamic Modeling and Adaptive Controlling in GPS-Intelligent Buoy (GIB)\n  Systems Based on Neural-Fuzzy Networks", "comments": "32 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.adhoc.2020.102149", "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, various relations and criteria have been presented to establish a\nproper relationship between control systems and control the Global Positioning\nSystem (GPS)-intelligent buoy system. Given the importance of controlling the\nposition of buoys and the construction of intelligent systems, in this paper,\ndynamic system modeling is applied to position marine buoys through the\nimproved neural network with a backstepping technique. This study aims at\ndeveloping a novel controller based on an adaptive fuzzy neural network to\noptimally track the dynamically positioned vehicle on the water with\nunavailable velocities and unidentified control parameters. In order to model\nthe network with the proposed technique, uncertainties and the unwanted\ndisturbances are studied in the neural network. The presented study aims at\ndeveloping a neural controlling which applies the vectorial back-stepping\ntechnique to the surface ships, which have been dynamically positioned with\nundetermined disturbances and ambivalences. Moreover, the objective function is\nto minimize the output error for the neural network (NN) based on the\nclosed-loop system. The most important feature of the proposed model for the\npositioning buoys is its independence from comparative knowledge or information\non the dynamics and the unwanted disturbances of ships. The numerical and\nobtained consequences demonstrate that the control system can adjust the routes\nand the position of the buoys to the desired objective with relatively few\nposition errors.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:28:53 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Dangquan", ""], ["Ashraf", "Muhammad Aqeel", ""], ["Liu", "Zhenling", ""], ["Peng", "Wan-Xi", ""], ["Golkar", "Mohammad Javad", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.02635", "submitter": "Laurent Condat", "authors": "Adil Salim, Laurent Condat, Konstantin Mishchenko, Peter Richt\\'arik", "title": "Dualize, Split, Randomize: Fast Nonsmooth Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new primal-dual algorithms to minimize the sum of three convex\nfunctions, each having its own oracle. Namely, the first one is differentiable,\nsmooth and possibly stochastic, the second is proximable, and the last one is a\ncomposition of a proximable function with a linear map. By leveraging variance\nreduction, we prove convergence to an exact solution with sublinear or linear\nrates, depending on strong convexity properties. The proposed theory is simple\nand unified by the umbrella of stochastic Davis-Yin splitting, which we first\ndesign in this work. Our theory covers several settings that are not tackled by\nany existing algorithm; we illustrate their importance with real-world\napplications and we show the efficiency of our algorithms by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:48:01 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 09:18:31 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Salim", "Adil", ""], ["Condat", "Laurent", ""], ["Mishchenko", "Konstantin", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2004.02641", "submitter": "Vladislav Kurenkov", "authors": "Vladislav Kurenkov, Hany Hamed, Sergei Savin", "title": "Learning Stabilizing Control Policies for a Tensegrity Hopper with\n  Augmented Random Search", "comments": "To appear in ICIE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider tensegrity hopper - a novel tensegrity-based\nrobot, capable of moving by hopping. The paper focuses on the design of the\nstabilizing control policies, which are obtained with Augmented Random Search\nmethod. In particular, we search for control policies which allow the hopper to\nmaintain vertical stability after performing a single jump. It is demonstrated,\nthat the hopper can maintain a vertical configuration, subject to the different\ninitial conditions and with changing control frequency rates. In particular,\nlowering control frequency from 1000Hz in training to 500Hz in execution did\nnot affect the success rate of the balancing task.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:06:10 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kurenkov", "Vladislav", ""], ["Hamed", "Hany", ""], ["Savin", "Sergei", ""]]}, {"id": "2004.02653", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist", "title": "Gaussian Process Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel way to combine boosting with Gaussian process and mixed\neffects models. This allows for relaxing, first, the linearity assumption for\nthe mean function in Gaussian process and grouped random effects models in a\nflexible non-parametric way and, second, the independence assumption made in\nmost boosting algorithms. The former is advantageous for predictive accuracy\nand for avoiding model misspecifications. The latter is important for more\nefficient learning of the mean function and for obtaining probabilistic\npredictions. In addition, we present an extension that scales to large data\nusing a Vecchia approximation for the Gaussian process model relying on novel\nresults for covariance parameter inference. We obtain increased predictive\naccuracy compared to existing approaches on several simulated and real-world\ndata sets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:19:54 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 20:00:36 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 12:06:59 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sigrist", "Fabio", ""]]}, {"id": "2004.02658", "submitter": "Shunwang Gong", "authors": "Shunwang Gong, Mehdi Bahri, Michael M. Bronstein, Stefanos Zafeiriou", "title": "Geometrically Principled Connections in Graph Neural Networks", "comments": "Presented at Computer Vision and Pattern Recognition (CVPR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolution operators bring the advantages of deep learning to a\nvariety of graph and mesh processing tasks previously deemed out of reach. With\ntheir continued success comes the desire to design more powerful architectures,\noften by adapting existing deep learning techniques to non-Euclidean data. In\nthis paper, we argue geometry should remain the primary driving force behind\ninnovation in the emerging field of geometric deep learning. We relate graph\nneural networks to widely successful computer graphics and data approximation\nmodels: radial basis functions (RBFs). We conjecture that, like RBFs, graph\nconvolution layers would benefit from the addition of simple functions to the\npowerful convolution kernels. We introduce affine skip connections, a novel\nbuilding block formed by combining a fully connected layer with any graph\nconvolution operator. We experimentally demonstrate the effectiveness of our\ntechnique and show the improved performance is the consequence of more than the\nincreased number of parameters. Operators equipped with the affine skip\nconnection markedly outperform their base performance on every task we\nevaluated, i.e., shape reconstruction, dense shape correspondence, and graph\nclassification. We hope our simple and effective approach will serve as a solid\nbaseline and help ease future research in graph neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:25:46 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Gong", "Shunwang", ""], ["Bahri", "Mehdi", ""], ["Bronstein", "Michael M.", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "2004.02671", "submitter": "Nassim Dehouche", "authors": "Nassim Dehouche", "title": "On Evaluating the Quality of Rule-Based Classification Systems", "comments": "ICIC Express Letters Volume 11, Number 10, October 2017", "journal-ref": "ICIC Express Letters ICIC International c 2013 ISSN 1881-803X ICIC\n  Express Letters Volume 11, Number 10, October 2017 c 2013 ISSN 1881-803X\n  Volume 11, Number 10, October 2017", "doi": "10.24507/icicel.11.10.1515", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two indicators are classically used to evaluate the quality of rule-based\nclassification systems: predictive accuracy, i.e. the system's ability to\nsuccessfully reproduce learning data and coverage, i.e. the proportion of\npossible cases for which the logical rules constituting the system apply. In\nthis work, we claim that these two indicators may be insufficient, and\nadditional measures of quality may need to be developed. We theoretically show\nthat classification systems presenting \"good\" predictive accuracy and coverage\ncan, nonetheless, be trivially improved and illustrate this proposition with\nexamples.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:41:49 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Dehouche", "Nassim", ""]]}, {"id": "2004.02673", "submitter": "Michal Nazarczuk", "authors": "Michal Nazarczuk and Krystian Mikolajczyk", "title": "SHOP-VRB: A Visual Reasoning Benchmark for Object Perception", "comments": "International Conference on Robotics and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an approach and a benchmark for visual reasoning in\nrobotics applications, in particular small object grasping and manipulation.\nThe approach and benchmark are focused on inferring object properties from\nvisual and text data. It concerns small household objects with their\nproperties, functionality, natural language descriptions as well as\nquestion-answer pairs for visual reasoning queries along with their\ncorresponding scene semantic representations. We also present a method for\ngenerating synthetic data which allows to extend the benchmark to other objects\nor scenes and propose an evaluation protocol that is more challenging than in\nthe existing datasets. We propose a reasoning system based on symbolic program\nexecution. A disentangled representation of the visual and textual inputs is\nobtained and used to execute symbolic programs that represent a 'reasoning\nprocess' of the algorithm. We perform a set of experiments on the proposed\nbenchmark and compare to results for the state of the art methods. These\nresults expose the shortcomings of the existing benchmarks that may lead to\nmisleading conclusions on the actual performance of the visual reasoning\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:46:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nazarczuk", "Michal", ""], ["Mikolajczyk", "Krystian", ""]]}, {"id": "2004.02687", "submitter": "Alex Glushkovsky", "authors": "Alex Glushkovsky", "title": "AI Giving Back to Statistics? Discovery of the Coordinate System of\n  Univariate Distributions by Beta Variational Autoencoder", "comments": "12 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributions are fundamental statistical elements that play essential\ntheoretical and practical roles. The article discusses experiences of training\nneural networks to classify univariate empirical distributions and to represent\nthem on the two-dimensional latent space forcing disentanglement based on the\ninputs of cumulative distribution functions (CDF). The latent space\nrepresentation has been performed using an unsupervised beta variational\nautoencoder (beta-VAE). It separates distributions of different shapes while\noverlapping similar ones and empirically realises relationships between\ndistributions that are known theoretically. The synthetic experiment of\ngenerated univariate continuous and discrete (Bernoulli) distributions with\nvarying sample sizes and parameters has been performed to support the study.\nThe representation on the latent two-dimensional coordinate system can be seen\nas an additional metadata of the real-world data that disentangles important\ndistribution characteristics, such as shape of the CDF, classification\nprobabilities of underlying theoretical distributions and their parameters,\ninformation entropy, and skewness. Entropy changes, providing an \"arrow of\ntime\", determine dynamic trajectories along representations of distributions on\nthe latent space. In addition, post beta-VAE unsupervised segmentation of the\nlatent space based on weight-of-evidence (WOE) of posterior versus standard\nisotopic two-dimensional normal densities has been applied detecting the\npresence of assignable causes that distinguish exceptional CDF inputs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:11:13 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Glushkovsky", "Alex", ""]]}, {"id": "2004.02696", "submitter": "Arash Mohammadi", "authors": "Parnian Afshar, Shahin Heidarian, Farnoosh Naderkhani, Anastasia\n  Oikonomou, Konstantinos N. Plataniotis, and Arash Mohammadi", "title": "COVID-CAPS: A Capsule Network-based Framework for Identification of\n  COVID-19 cases from X-ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel Coronavirus disease (COVID-19) has abruptly and undoubtedly changed the\nworld as we know it at the end of the 2nd decade of the 21st century. COVID-19\nis extremely contagious and quickly spreading globally making its early\ndiagnosis of paramount importance. Early diagnosis of COVID-19 enables health\ncare professionals and government authorities to break the chain of transition\nand flatten the epidemic curve. The common type of COVID-19 diagnosis test,\nhowever, requires specific equipment and has relatively low sensitivity.\nComputed tomography (CT) scans and X-ray images, on the other hand, reveal\nspecific manifestations associated with this disease. Overlap with other lung\ninfections makes human-centered diagnosis of COVID-19 challenging.\nConsequently, there has been an urgent surge of interest to develop Deep Neural\nNetwork (DNN)-based diagnosis solutions, mainly based on Convolutional Neural\nNetworks (CNNs), to facilitate identification of positive COVID-19 cases. CNNs,\nhowever, are prone to lose spatial information between image instances and\nrequire large datasets. The paper presents an alternative modeling framework\nbased on Capsule Networks, referred to as the COVID-CAPS, being capable of\nhandling small datasets, which is of significant importance due to sudden and\nrapid emergence of COVID-19. Our results based on a dataset of X-ray images\nshow that COVID-CAPS has advantage over previous CNN-based models. COVID-CAPS\nachieved an Accuracy of 95.7%, Sensitivity of 90%, Specificity of 95.8%, and\nArea Under the Curve (AUC) of 0.97, while having far less number of trainable\nparameters in comparison to its counterparts. To further improve diagnosis\ncapabilities of the COVID-CAPS, pre-training based on a new dataset constructed\nfrom an external dataset of X-ray images. Pre-training with a dataset of\nsimilar nature further improved accuracy to 98.3% and specificity to 98.6%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:20:47 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 22:05:31 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Afshar", "Parnian", ""], ["Heidarian", "Shahin", ""], ["Naderkhani", "Farnoosh", ""], ["Oikonomou", "Anastasia", ""], ["Plataniotis", "Konstantinos N.", ""], ["Mohammadi", "Arash", ""]]}, {"id": "2004.02705", "submitter": "Shen Li", "authors": "Shen Li, Renfen Hu, Jinshan Wu", "title": "Quantum Inspired Word Representation and Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word meaning has different aspects, while the existing word representation\n\"compresses\" these aspects into a single vector, and it needs further analysis\nto recover the information in different dimensions. Inspired by quantum\nprobability, we represent words as density matrices, which are inherently\ncapable of representing mixed states. The experiment shows that the density\nmatrix representation can effectively capture different aspects of word meaning\nwhile maintaining comparable reliability with the vector representation.\nFurthermore, we propose a novel method to combine the coherent summation and\nincoherent summation in the computation of both vectors and density matrices.\nIt achieves consistent improvement on word analogy task.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:37:39 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 03:00:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Shen", ""], ["Hu", "Renfen", ""], ["Wu", "Jinshan", ""]]}, {"id": "2004.02718", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Kiryung Lee", "title": "Low-Rank Matrix Estimation From Rank-One Projections by Unlifted Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an estimator with a convex formulation for recovery of low-rank\nmatrices from rank-one projections. Using initial estimates of the factors of\nthe target $d_1\\times d_2$ matrix of rank-$r$, the estimator admits a practical\nsubgradient method operating in a space of dimension $r(d_1+d_2)$. This\nproperty makes the estimator significantly more scalable than the convex\nestimators based on lifting and semidefinite programming. Furthermore, we\npresent a streamlined analysis for exact recovery under the real Gaussian\nmeasurement model, as well as the partially derandomized measurement model by\nusing the spherical $t$-design. We show that under both models the estimator\nsucceeds, with high probability, if the number of measurements exceeds $r^2\n(d_1+d_2)$ up to some logarithmic factors. This sample complexity improves on\nthe existing results for nonconvex iterative algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:57:54 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2021 19:23:16 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Bahmani", "Sohail", ""], ["Lee", "Kiryung", ""]]}, {"id": "2004.02738", "submitter": "Muhammad Asad", "authors": "Muhammad Asad, Ahmed Moustafa, Takayuki Ito and Muhammad Aslam", "title": "Evaluating the Communication Efficiency in Federated Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of advanced technologies, mobile devices are equipped with\ncomputing and sensing capabilities that gather excessive amounts of data. These\namounts of data are suitable for training different learning models. Cooperated\nwith advancements in Deep Learning (DL), these learning models empower numerous\nuseful applications, e.g., image processing, speech recognition, healthcare,\nvehicular network and many more. Traditionally, Machine Learning (ML)\napproaches require data to be centralised in cloud-based data-centres. However,\nthis data is often large in quantity and privacy-sensitive which prevents\nlogging into these data-centres for training the learning models. In turn, this\nresults in critical issues of high latency and communication inefficiency.\nRecently, in light of new privacy legislations in many countries, the concept\nof Federated Learning (FL) has been introduced. In FL, mobile users are\nempowered to learn a global model by aggregating their local models, without\nsharing the privacy-sensitive data. Usually, these mobile users have slow\nnetwork connections to the data-centre where the global model is maintained.\nMoreover, in a complex and large scale network, heterogeneous devices that have\nvarious energy constraints are involved. This raises the challenge of\ncommunication cost when implementing FL at large scale. To this end, in this\nresearch, we begin with the fundamentals of FL, and then, we highlight the\nrecent FL algorithms and evaluate their communication efficiency with detailed\ncomparisons. Furthermore, we propose a set of solutions to alleviate the\nexisting FL problems both from communication perspective and privacy\nperspective.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:31:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Asad", "Muhammad", ""], ["Moustafa", "Ahmed", ""], ["Ito", "Takayuki", ""], ["Aslam", "Muhammad", ""]]}, {"id": "2004.02753", "submitter": "Joshua Knights Mr", "authors": "Joshua Knights, Ben Harwood, Daniel Ward, Anthony Vanderkop, Olivia\n  Mackenzie-Ross, Peyman Moghadam", "title": "Temporally Coherent Embeddings for Self-Supervised Video Representation\n  Learning", "comments": "Accepted at ICPR 2020. Project page:\n  https://csiro-robotics.github.io/TCE-Webpage/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents TCE: Temporally Coherent Embeddings for self-supervised\nvideo representation learning. The proposed method exploits inherent structure\nof unlabeled video data to explicitly enforce temporal coherency in the\nembedding space, rather than indirectly learning it through ranking or\npredictive proxy tasks. In the same way that high-level visual information in\nthe world changes smoothly, we believe that nearby frames in learned\nrepresentations will benefit from demonstrating similar properties. Using this\nassumption, we train our TCE model to encode videos such that adjacent frames\nexist close to each other and videos are separated from one another. Using TCE\nwe learn robust representations from large quantities of unlabeled video data.\nWe thoroughly analyse and evaluate our self-supervised learned TCE models on a\ndownstream task of video action recognition using multiple challenging\nbenchmarks (Kinetics400, UCF101, HMDB51). With a simple but effective 2D-CNN\nbackbone and only RGB stream inputs, TCE pre-trained representations outperform\nall previous selfsupervised 2D-CNN and 3D-CNN pre-trained on UCF101. The code\nand pre-trained models for this paper can be downloaded at:\nhttps://github.com/csiro-robotics/TCE\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 12:25:50 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 00:24:07 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2020 09:03:55 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 05:48:04 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 04:21:35 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Knights", "Joshua", ""], ["Harwood", "Ben", ""], ["Ward", "Daniel", ""], ["Vanderkop", "Anthony", ""], ["Mackenzie-Ross", "Olivia", ""], ["Moghadam", "Peyman", ""]]}, {"id": "2004.02755", "submitter": "Dingkang Wang", "authors": "Dingkang Wang, Lucas Magee, Bing-Xing Huo, Samik Banerjee, Xu Li,\n  Jaikishan Jayakumar, Meng Kuan Lin, Keerthi Ram, Suyi Wang, Yusu Wang, Partha\n  P. Mitra", "title": "Detection and skeletonization of single neurons and tracer injections\n  using topological methods", "comments": "20 pages (14 pages main-text and 6 pages supplementary information).\n  5 main-text figures. 5 supplementary figures. 2 supplementary tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuroscientific data analysis has traditionally relied on linear algebra and\nstochastic process theory. However, the tree-like shapes of neurons cannot be\ndescribed easily as points in a vector space (the subtraction of two neuronal\nshapes is not a meaningful operation), and methods from computational topology\nare better suited to their analysis. Here we introduce methods from Discrete\nMorse (DM) Theory to extract the tree-skeletons of individual neurons from\nvolumetric brain image data, and to summarize collections of neurons labelled\nby tracer injections. Since individual neurons are topologically trees, it is\nsensible to summarize the collection of neurons using a consensus tree-shape\nthat provides a richer information summary than the traditional regional\n'connectivity matrix' approach. The conceptually elegant DM approach lacks\nhand-tuned parameters and captures global properties of the data as opposed to\nprevious approaches which are inherently local. For individual skeletonization\nof sparsely labelled neurons we obtain substantial performance gains over\nstate-of-the-art non-topological methods (over 10% improvements in precision\nand faster proofreading). The consensus-tree summary of tracer injections\nincorporates the regional connectivity matrix information, but in addition\ncaptures the collective collateral branching patterns of the set of neurons\nconnected to the injection site, and provides a bridge between single-neuron\nmorphology and tracer-injection data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 20:58:38 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wang", "Dingkang", ""], ["Magee", "Lucas", ""], ["Huo", "Bing-Xing", ""], ["Banerjee", "Samik", ""], ["Li", "Xu", ""], ["Jayakumar", "Jaikishan", ""], ["Lin", "Meng Kuan", ""], ["Ram", "Keerthi", ""], ["Wang", "Suyi", ""], ["Wang", "Yusu", ""], ["Mitra", "Partha P.", ""]]}, {"id": "2004.02757", "submitter": "Yuanhan Mo", "authors": "Yuanhan Mo and Shuo Wang and Chengliang Dai and Rui Zhou and Zhongzhao\n  Teng and Wenjia Bai and Yike Guo", "title": "Efficient Deep Representation Learning by Adaptive Latent Space Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised deep learning requires a large amount of training samples with\nannotations (e.g. label class for classification task, pixel- or voxel-wised\nlabel map for segmentation tasks), which are expensive and time-consuming to\nobtain. During the training of a deep neural network, the annotated samples are\nfed into the network in a mini-batch way, where they are often regarded of\nequal importance. However, some of the samples may become less informative\nduring training, as the magnitude of the gradient start to vanish for these\nsamples. In the meantime, other samples of higher utility or hardness may be\nmore demanded for the training process to proceed and require more\nexploitation. To address the challenges of expensive annotations and loss of\nsample informativeness, here we propose a novel training framework which\nadaptively selects informative samples that are fed to the training process.\nThe adaptive selection or sampling is performed based on a hardness-aware\nstrategy in the latent space constructed by a generative model. To evaluate the\nproposed training framework, we perform experiments on three different\ndatasets, including MNIST and CIFAR-10 for image classification task and a\nmedical image dataset IVUS for biophysical simulation task. On all three\ndatasets, the proposed framework outperforms a random sampling method, which\ndemonstrates the effectiveness of proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 22:17:02 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 18:25:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mo", "Yuanhan", ""], ["Wang", "Shuo", ""], ["Dai", "Chengliang", ""], ["Zhou", "Rui", ""], ["Teng", "Zhongzhao", ""], ["Bai", "Wenjia", ""], ["Guo", "Yike", ""]]}, {"id": "2004.02758", "submitter": "Anthony Griffin", "authors": "Farah Sarwar, Anthony Griffin, Saeed Ur Rehman, and Timotius Pasang", "title": "Towards Detection of Sheep Onboard a UAV", "comments": "This was accepted for publication and presentation at the Embedded AI\n  for Real-time Machine Vision 2019 in conjunction with the British Machine\n  Vision Conference (BMVC) 2019. It was presented on 12 September 2019 in\n  Cardiff, Wales. 10 pages, 3 figures, and 1 table, note that this is a\n  web-friendly format as used at BMVC, so the pages are about A5 size (but not\n  exactly!)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider the task of detecting sheep onboard an unmanned\naerial vehicle (UAV) flying at an altitude of 80 m. At this height, the sheep\nare relatively small, only about 15 pixels across. Although deep learning\nstrategies have gained enormous popularity in the last decade and are now\nextensively used for object detection in many fields, state-of-the-art\ndetectors perform poorly in the case of smaller objects. We develop a novel\ndataset of UAV imagery of sheep and consider a variety of object detectors to\ndetermine which is the most suitable for our task in terms of both accuracy and\nspeed. Our findings indicate that a UNet detector using the weighted Hausdorff\ndistance as a loss function during training is an excellent option for\ndetection of sheep onboard a UAV.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:40:48 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sarwar", "Farah", ""], ["Griffin", "Anthony", ""], ["Rehman", "Saeed Ur", ""], ["Pasang", "Timotius", ""]]}, {"id": "2004.02762", "submitter": "Elif Surer", "authors": "Ayberk Ayd{\\i}n and Elif Surer", "title": "Using Generative Adversarial Nets on Atari Games for Feature Extraction\n  in Deep Reinforcement Learning", "comments": "in Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) has been successfully applied in several\nresearch domains such as robot navigation and automated video game playing.\nHowever, these methods require excessive computation and interaction with the\nenvironment, so enhancements on sample efficiency are required. The main reason\nfor this requirement is that sparse and delayed rewards do not provide an\neffective supervision for representation learning of deep neural networks. In\nthis study, Proximal Policy Optimization (PPO) algorithm is augmented with\nGenerative Adversarial Networks (GANs) to increase the sample efficiency by\nenforcing the network to learn efficient representations without depending on\nsparse and delayed rewards as supervision. The results show that an increased\nperformance can be obtained by jointly training a DRL agent with a GAN\ndiscriminator.\n  ----\n  Derin Pekistirmeli Ogrenme, robot navigasyonu ve otomatiklestirilmis video\noyunu oynama gibi arastirma alanlarinda basariyla uygulanmaktadir. Ancak,\nkullanilan yontemler ortam ile fazla miktarda etkilesim ve hesaplama\ngerektirmekte ve bu nedenle de ornek verimliligi yonunden iyilestirmelere\nihtiyac duyulmaktadir. Bu gereksinimin en onemli nedeni, gecikmeli ve seyrek\nodul sinyallerinin derin yapay sinir aglarinin etkili betimlemeler\nogrenebilmesi icin yeterli bir denetim saglayamamasidir. Bu calismada,\nProksimal Politika Optimizasyonu algoritmasi Uretici Cekismeli Aglar (UCA) ile\ndesteklenerek derin yapay sinir aglarinin seyrek ve gecikmeli odul sinyallerine\nbagimli olmaksizin etkili betimlemeler ogrenmesi tesvik edilmektedir. Elde\nedilen sonuclar onerilen algoritmanin ornek verimliliginde artis elde ettigini\ngostermektedir.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:46:45 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Ayd\u0131n", "Ayberk", ""], ["Surer", "Elif", ""]]}, {"id": "2004.02766", "submitter": "Tyler Westenbroek", "authors": "Tyler Westenbroek, Eric Mazumdar, David Fridovich-Keil, Valmik Prabhu,\n  Claire J. Tomlin and S. Shankar Sastry", "title": "Technical Report: Adaptive Control for Linearizable Systems Using\n  On-Policy Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a framework for adaptively learning a feedback\nlinearization-based tracking controller for an unknown system using\ndiscrete-time model-free policy-gradient parameter update rules. The primary\nadvantage of the scheme over standard model-reference adaptive control\ntechniques is that it does not require the learned inverse model to be\ninvertible at all instances of time. This enables the use of general function\napproximators to approximate the linearizing controller for the system without\nhaving to worry about singularities. However, the discrete-time and stochastic\nnature of these algorithms precludes the direct application of standard\nmachinery from the adaptive control literature to provide deterministic\nstability proofs for the system. Nevertheless, we leverage these techniques\nalongside tools from the stochastic approximation literature to demonstrate\nthat with high probability the tracking and parameter errors concentrate near\nzero when a certain persistence of excitation condition is satisfied. A\nsimulated example of a double pendulum demonstrates the utility of the proposed\ntheory. 1\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:50:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Westenbroek", "Tyler", ""], ["Mazumdar", "Eric", ""], ["Fridovich-Keil", "David", ""], ["Prabhu", "Valmik", ""], ["Tomlin", "Claire J.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "2004.02769", "submitter": "Luis Miguel L\\'opez-Ramos", "authors": "Luis Miguel Lopez-Ramos, Baltasar Beferull-Lozano", "title": "Online Hyperparameter Search Interleaved with Proximal Parameter Updates", "comments": "6 pages, 3 figures, 1 algorithm; Submitted to the European Signal\n  Processing Conference (EUSIPCO) 2020 (Amsterdam)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a clear need for efficient algorithms to tune hyperparameters for\nstatistical learning schemes, since the commonly applied search methods (such\nas grid search with N-fold cross-validation) are inefficient and/or\napproximate. Previously existing algorithms that efficiently search for\nhyperparameters relying on the smoothness of the cost function cannot be\napplied in problems such as Lasso regression.\n  In this contribution, we develop a hyperparameter optimization method that\nrelies on the structure of proximal gradient methods and does not require a\nsmooth cost function. Such a method is applied to Leave-one-out (LOO)-validated\nLasso and Group Lasso to yield efficient, data-driven, hyperparameter\noptimization algorithms.\n  Numerical experiments corroborate the convergence of the proposed method to a\nlocal optimum of the LOO validation error curve, and the efficiency of its\napproximations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:54:03 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Lopez-Ramos", "Luis Miguel", ""], ["Beferull-Lozano", "Baltasar", ""]]}, {"id": "2004.02772", "submitter": "Haomiao Meng", "authors": "Haomiao Meng, Ying-Qi Zhao, Haoda Fu, Xingye Qiao", "title": "Near-optimal Individualized Treatment Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individualized treatment recommendation (ITR) is an important analytic\nframework for precision medicine. The goal is to assign proper treatments to\npatients based on their individual characteristics. From the machine learning\nperspective, the solution to an ITR problem can be formulated as a weighted\nclassification problem to maximize the average benefit that patients receive\nfrom the recommended treatments. Several methods have been proposed for ITR in\nboth binary and multicategory treatment setups. In practice, one may prefer a\nmore flexible recommendation with multiple treatment options. This motivates us\nto develop methods to obtain a set of near-optimal individualized treatment\nrecommendations alternative to each other, called alternative individualized\ntreatment recommendations (A-ITR). We propose two methods to estimate the\noptimal A-ITR within the outcome weighted learning (OWL) framework. We show the\nconsistency of these methods and obtain an upper bound for the risk between the\ntheoretically optimal recommendation and the estimated one. We also conduct\nsimulation studies, and apply our methods to a real data set for Type 2\ndiabetic patients with injectable antidiabetic treatments. These numerical\nstudies have shown the usefulness of the proposed A-ITR framework. We develop a\nR package aitr which can be found at https://github.com/menghaomiao/aitr.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:59:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Meng", "Haomiao", ""], ["Zhao", "Ying-Qi", ""], ["Fu", "Haoda", ""], ["Qiao", "Xingye", ""]]}, {"id": "2004.02778", "submitter": "Nathan Kallus", "authors": "Nathan Kallus", "title": "Comment: Entropy Learning for Dynamic Treatment Regimes", "comments": null, "journal-ref": "Statistica Sinica 29.4 (2019): 1697-1705", "doi": "10.5705/ss.202019.0115", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I congratulate Profs. Binyan Jiang, Rui Song, Jialiang Li, and Donglin Zeng\n(JSLZ) for an exciting development in conducting inferences on optimal dynamic\ntreatment regimes (DTRs) learned via empirical risk minimization using the\nentropy loss as a surrogate. JSLZ's approach leverages a\nrejection-and-importance-sampling estimate of the value of a given decision\nrule based on inverse probability weighting (IPW) and its interpretation as a\nweighted (or cost-sensitive) classification. Their use of smooth classification\nsurrogates enables their careful approach to analyzing asymptotic\ndistributions. However, even for evaluation purposes, the IPW estimate is\nproblematic as it leads to weights that discard most of the data and are\nextremely variable on whatever remains. In this comment, I discuss an\noptimization-based alternative to evaluating DTRs, review several connections,\nand suggest directions forward. This extends the balanced policy evaluation\napproach of Kallus (2018a) to the longitudinal setting.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:11:05 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kallus", "Nathan", ""]]}, {"id": "2004.02786", "submitter": "Jeffrey Ede BSc MPhys", "authors": "Jeffrey M. Ede", "title": "Adaptive Partial Scanning Transmission Electron Microscopy with\n  Reinforcement Learning", "comments": "13 pages, 3 figures + 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compressed sensing can decrease scanning transmission electron microscopy\nelectron dose and scan time with minimal information loss. Traditionally,\nsparse scans used in compressed sensing sample a static set of probing\nlocations. However, dynamic scans that adapt to specimens are expected to be\nable to match or surpass the performance of static scans as static scans are a\nsubset of possible dynamic scans. Thus, we present a prototype for a contiguous\nsparse scan system that piecewise adapts scan paths to specimens as they are\nscanned. Sampling directions for scan segments are chosen by a recurrent neural\nnetwork based on previously observed scan segments. The recurrent neural\nnetwork is trained by reinforcement learning to cooperate with a feedforward\nconvolutional neural network that completes the sparse scans. This paper\npresents our learning policy, experiments, and example partial scans, and\ndiscusses future research directions. Source code, pretrained models, and\ntraining data is openly accessible at\nhttps://github.com/Jeffrey-Ede/adaptive-scans\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:25:38 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 13:05:52 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 16:06:00 GMT"}, {"version": "v4", "created": "Tue, 22 Dec 2020 14:26:08 GMT"}, {"version": "v5", "created": "Mon, 1 Mar 2021 11:11:30 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 12:15:56 GMT"}, {"version": "v7", "created": "Mon, 8 Mar 2021 18:09:48 GMT"}, {"version": "v8", "created": "Thu, 11 Mar 2021 16:55:09 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ede", "Jeffrey M.", ""]]}, {"id": "2004.02804", "submitter": "Akrem Sellami", "authors": "Akrem Sellami (QARMA, LIS, INT), Fran\\c{c}ois-Xavier Dup\\'e (QARMA,\n  LIS), Bastien Cagna (INT), Hachem Kadri (QARMA, LIS), St\\'ephane Ayache\n  (QARMA, LIS), Thierry Arti\\`eres (QARMA, LIS, ECM), Sylvain Takerkart (INT)", "title": "Mapping individual differences in cortical architecture using multi-view\n  representation learning", "comments": null, "journal-ref": "IJCNN 2020 - International Joint Conference on Neural Networks,\n  Jul 2020, Glasgow, United Kingdom", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, understanding inter-individual differences has recently\nemerged as a major challenge, for which functional magnetic resonance imaging\n(fMRI) has proven invaluable. For this, neuroscientists rely on basic methods\nsuch as univariate linear correlations between single brain features and a\nscore that quantifies either the severity of a disease or the subject's\nperformance in a cognitive task. However, to this date, task-fMRI and\nresting-state fMRI have been exploited separately for this question, because of\nthe lack of methods to effectively combine them. In this paper, we introduce a\nnovel machine learning method which allows combining the activation-and\nconnectivity-based information respectively measured through these two fMRI\nprotocols to identify markers of individual differences in the functional\norganization of the brain. It combines a multi-view deep autoencoder which is\ndesigned to fuse the two fMRI modalities into a joint representation space\nwithin which a predictive model is trained to guess a scalar score that\ncharacterizes the patient. Our experimental results demonstrate the ability of\nthe proposed method to outperform competitive approaches and to produce\ninterpretable and biologically plausible results.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:01:25 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Sellami", "Akrem", "", "QARMA, LIS, INT"], ["Dup\u00e9", "Fran\u00e7ois-Xavier", "", "QARMA,\n  LIS"], ["Cagna", "Bastien", "", "INT"], ["Kadri", "Hachem", "", "QARMA, LIS"], ["Ayache", "St\u00e9phane", "", "QARMA, LIS"], ["Arti\u00e8res", "Thierry", "", "QARMA, LIS, ECM"], ["Takerkart", "Sylvain", "", "INT"]]}, {"id": "2004.02805", "submitter": "Weiya Fan", "authors": "Rui Nie (2), Huan Yang (1), Hejuan Peng (2), Wenbin Luo (2), Weiya Fan\n  (2), Jie Zhang (2), Jing Liao (2), Fang Huang (2), Yufeng Xiao (1) ((1)\n  Depatment of Gastroenterology, Second Affiliated Hospital, Army Medical\n  University (Third Military Medical University), Chongqing, China. (2)\n  Chongqing Jinshan Science & Technology (Group) Co., Ltd., Chongqing, China.)", "title": "Application of Structural Similarity Analysis of Visually Salient Areas\n  and Hierarchical Clustering in the Screening of Similar Wireless Capsule\n  Endoscopic Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small intestinal capsule endoscopy is the mainstream method for inspecting\nsmall intestinal lesions,but a single small intestinal capsule endoscopy will\nproduce 60,000 - 120,000 images, the majority of which are similar and have no\ndiagnostic value. It takes 2 - 3 hours for doctors to identify lesions from\nthese images. This is time-consuming and increase the probability of\nmisdiagnosis and missed diagnosis since doctors are likely to experience visual\nfatigue while focusing on a large number of similar images for an extended\nperiod of time.In order to solve these problems, we proposed a similar wireless\ncapsule endoscope (WCE) image screening method based on structural similarity\nanalysis and the hierarchical clustering of visually salient sub-image blocks.\nThe similarity clustering of images was automatically identified by\nhierarchical clustering based on the hue,saturation,value (HSV) spatial color\ncharacteristics of the images,and the keyframe images were extracted based on\nthe structural similarity of the visually salient sub-image blocks, in order to\naccurately identify and screen out similar small intestinal capsule endoscopic\nimages. Subsequently, the proposed method was applied to the capsule endoscope\nimaging workstation. After screening out similar images in the complete data\ngathered by the Type I OMOM Small Intestinal Capsule Endoscope from 52 cases\ncovering 17 common types of small intestinal lesions, we obtained a lesion\nrecall of 100% and an average similar image reduction ratio of 76%. With\nsimilar images screened out, the average play time of the OMOM image\nworkstation was 18 minutes, which greatly reduced the time spent by doctors\nviewing the images.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 09:03:33 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Nie", "Rui", ""], ["Yang", "Huan", ""], ["Peng", "Hejuan", ""], ["Luo", "Wenbin", ""], ["Fan", "Weiya", ""], ["Zhang", "Jie", ""], ["Liao", "Jing", ""], ["Huang", "Fang", ""], ["Xiao", "Yufeng", ""]]}, {"id": "2004.02806", "submitter": "Zewen Li", "authors": "Zewen Li, Wenjie Yang, Shouheng Peng, Fan Liu", "title": "A Survey of Convolutional Neural Networks: Analysis, Applications, and\n  Prospects", "comments": "21 pages, 33 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Network (CNN) is one of the most significant networks in\nthe deep learning field. Since CNN made impressive achievements in many areas,\nincluding but not limited to computer vision and natural language processing,\nit attracted much attention both of industry and academia in the past few\nyears. The existing reviews mainly focus on the applications of CNN in\ndifferent scenarios without considering CNN from a general perspective, and\nsome novel ideas proposed recently are not covered. In this review, we aim to\nprovide novel ideas and prospects in this fast-growing field as much as\npossible. Besides, not only two-dimensional convolution but also\none-dimensional and multi-dimensional ones are involved. First, this review\nstarts with a brief introduction to the history of CNN. Second, we provide an\noverview of CNN. Third, classic and advanced CNN models are introduced,\nespecially those key points making them reach state-of-the-art results. Fourth,\nthrough experimental analysis, we draw some conclusions and provide several\nrules of thumb for function selection. Fifth, the applications of\none-dimensional, two-dimensional, and multi-dimensional convolution are\ncovered. Finally, some open issues and promising directions for CNN are\ndiscussed to serve as guidelines for future work.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 14:04:10 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Li", "Zewen", ""], ["Yang", "Wenjie", ""], ["Peng", "Shouheng", ""], ["Liu", "Fan", ""]]}, {"id": "2004.02814", "submitter": "Jeroen Van Hautte", "authors": "Jeroen Van Hautte, Vincent Schelstraete, Mika\\\"el Wornoo", "title": "Leveraging the Inherent Hierarchy of Vacancy Titles for Automated Job\n  Ontology Expansion", "comments": "Accepted to the Proceedings of the 6th International Workshop on\n  Computational Terminology (COMPUTERM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays an ever-bigger part in online recruitment, powering\nintelligent matchmaking and job recommendations across many of the world's\nlargest job platforms. However, the main text is rarely enough to fully\nunderstand a job posting: more often than not, much of the required information\nis condensed into the job title. Several organised efforts have been made to\nmap job titles onto a hand-made knowledge base as to provide this information,\nbut these only cover around 60\\% of online vacancies. We introduce a novel,\npurely data-driven approach towards the detection of new job titles. Our method\nis conceptually simple, extremely efficient and competitive with traditional\nNER-based approaches. Although the standalone application of our method does\nnot outperform a finetuned BERT model, it can be applied as a preprocessing\nstep as well, substantially boosting accuracy across several architectures.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:55:41 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Van Hautte", "Jeroen", ""], ["Schelstraete", "Vincent", ""], ["Wornoo", "Mika\u00ebl", ""]]}, {"id": "2004.02830", "submitter": "Artem Zholus", "authors": "Artem Zholus and Evgeny Putin", "title": "Continuous Histogram Loss: Beyond Neural Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity learning has gained a lot of attention from researches in recent\nyears and tons of successful approaches have been recently proposed. However,\nthe majority of the state-of-the-art similarity learning methods consider only\na binary similarity. In this paper we introduce a new loss function called\nContinuous Histogram Loss (CHL) which generalizes recently proposed Histogram\nloss to multiple-valued similarities, i.e. allowing the acceptable values of\nsimilarity to be continuously distributed within some range. The novel loss\nfunction is computed by aggregating pairwise distances and similarities into 2D\nhistograms in a differentiable manner and then computing the probability of\ncondition that pairwise distances will not decrease as the similarities\nincrease. The novel loss is capable of solving a wider range of tasks including\nsimilarity learning, representation learning and data visualization.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:20:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zholus", "Artem", ""], ["Putin", "Evgeny", ""]]}, {"id": "2004.02842", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Jun Yu, Wei Bian, Dacheng Tao", "title": "Detecting Communities in Heterogeneous Multi-Relational Networks:A\n  Message Passing based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community is a common characteristic of networks including social networks,\nbiological networks, computer and information networks, to name a few.\nCommunity detection is a basic step for exploring and analysing these network\ndata. Typically, homogenous network is a type of networks which consists of\nonly one type of objects with one type of links connecting them. There has been\na large body of developments in models and algorithms to detect communities\nover it. However, real-world networks naturally exhibit heterogeneous qualities\nappearing as multiple types of objects with multi-relational links connecting\nthem. Those heterogeneous information could facilitate the community detection\nfor its constituent homogeneous networks, but has not been fully explored. In\nthis paper, we exploit heterogeneous multi-relational networks (HMRNet) and\npropose an efficient message passing based algorithm to simultaneously detect\ncommunities for all homogeneous networks. Specifically, an HMRNet is\nreorganized into a hierarchical structure with homogeneous networks as its\nlayers and heterogeneous links connecting them. To detect communities in such\nan HMRNet, the problem is formulated as a maximum a posterior (MAP) over a\nfactor graph. Finally a message passing based algorithm is derived to find a\nbest solution of the MAP problem. Evaluation on both synthetic and real-world\nnetworks confirms the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:36:24 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Qiao", "Maoying", ""], ["Yu", "Jun", ""], ["Bian", "Wei", ""], ["Tao", "Dacheng", ""]]}, {"id": "2004.02853", "submitter": "Junhwa Hur", "authors": "Junhwa Hur, Stefan Roth", "title": "Optical Flow Estimation in the Deep Learning Age", "comments": "To appear as a book chapter in Modelling Human Motion, N. Noceti, A.\n  Sciutti and F. Rea, Eds., Springer, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Akin to many subareas of computer vision, the recent advances in deep\nlearning have also significantly influenced the literature on optical flow.\nPreviously, the literature had been dominated by classical energy-based models,\nwhich formulate optical flow estimation as an energy minimization problem.\nHowever, as the practical benefits of Convolutional Neural Networks (CNNs) over\nconventional methods have become apparent in numerous areas of computer vision\nand beyond, they have also seen increased adoption in the context of motion\nestimation to the point where the current state of the art in terms of accuracy\nis set by CNN approaches. We first review this transition as well as the\ndevelopments from early work to the current state of CNNs for optical flow\nestimation. Alongside, we discuss some of their technical details and compare\nthem to recapitulate which technical contribution led to the most significant\naccuracy improvements. Then we provide an overview of the various optical flow\napproaches introduced in the deep learning age, including those based on\nalternative learning paradigms (e.g., unsupervised and semi-supervised methods)\nas well as the extension to the multi-frame case, which is able to yield\nfurther accuracy improvements.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:45:43 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hur", "Junhwa", ""], ["Roth", "Stefan", ""]]}, {"id": "2004.02860", "submitter": "Lisa Lee", "authors": "Lisa Lee, Benjamin Eysenbach, Ruslan Salakhutdinov, Shixiang Shane Gu,\n  Chelsea Finn", "title": "Weakly-Supervised Reinforcement Learning for Controllable Behavior", "comments": "Published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a powerful framework for learning to take\nactions to solve tasks. However, in many settings, an agent must winnow down\nthe inconceivably large space of all possible tasks to the single task that it\nis currently being asked to solve. Can we instead constrain the space of tasks\nto those that are semantically meaningful? In this work, we introduce a\nframework for using weak supervision to automatically disentangle this\nsemantically meaningful subspace of tasks from the enormous space of\nnonsensical \"chaff\" tasks. We show that this learned subspace enables efficient\nexploration and provides a representation that captures distance between\nstates. On a variety of challenging, vision-based continuous control problems,\nour approach leads to substantial performance gains, particularly as the\ncomplexity of the environment grows.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:50:28 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 02:03:28 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Lee", "Lisa", ""], ["Eysenbach", "Benjamin", ""], ["Salakhutdinov", "Ruslan", ""], ["Gu", "Shixiang Shane", ""], ["Finn", "Chelsea", ""]]}, {"id": "2004.02863", "submitter": "SeongMin Kye", "authors": "Seong Min Kye, Youngmoon Jung, Hae Beom Lee, Sung Ju Hwang, Hoirin Kim", "title": "Meta-Learning for Short Utterance Speaker Recognition with Imbalance\n  Length Pairs", "comments": "Accepted to Interspeech 2020. The codes are available at\n  https://github.com/seongmin-kye/meta-SR", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practical settings, a speaker recognition system needs to identify a\nspeaker given a short utterance, while the enrollment utterance may be\nrelatively long. However, existing speaker recognition models perform poorly\nwith such short utterances. To solve this problem, we introduce a meta-learning\nframework for imbalance length pairs. Specifically, we use a Prototypical\nNetworks and train it with a support set of long utterances and a query set of\nshort utterances of varying lengths. Further, since optimizing only for the\nclasses in the given episode may be insufficient for learning discriminative\nembeddings for unseen classes, we additionally enforce the model to classify\nboth the support and the query set against the entire set of classes in the\ntraining set. By combining these two learning schemes, our model outperforms\nexisting state-of-the-art speaker verification models learned with a standard\nsupervised learning framework on short utterance (1-2 seconds) on the VoxCeleb\ndatasets. We also validate our proposed model for unseen speaker\nidentification, on which it also achieves significant performance gains over\nthe existing approaches. The codes are available at\nhttps://github.com/seongmin-kye/meta-SR.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:53:14 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 06:55:10 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 10:56:47 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 04:07:46 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 02:21:51 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kye", "Seong Min", ""], ["Jung", "Youngmoon", ""], ["Lee", "Hae Beom", ""], ["Hwang", "Sung Ju", ""], ["Kim", "Hoirin", ""]]}, {"id": "2004.02869", "submitter": "Zekun Hao", "authors": "Zekun Hao, Hadar Averbuch-Elor, Noah Snavely, Serge Belongie", "title": "DualSDF: Semantic Shape Manipulation using a Two-Level Representation", "comments": "Published in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are seeing a Cambrian explosion of 3D shape representations for use in\nmachine learning. Some representations seek high expressive power in capturing\nhigh-resolution detail. Other approaches seek to represent shapes as\ncompositions of simple parts, which are intuitive for people to understand and\neasy to edit and manipulate. However, it is difficult to achieve both fidelity\nand interpretability in the same representation. We propose DualSDF, a\nrepresentation expressing shapes at two levels of granularity, one capturing\nfine details and the other representing an abstracted proxy shape using simple\nand semantically consistent shape primitives. To achieve a tight coupling\nbetween the two representations, we use a variational objective over a shared\nlatent space. Our two-level model gives rise to a new shape manipulation\ntechnique in which a user can interactively manipulate the coarse proxy shape\nand see the changes instantly mirrored in the high-resolution shape. Moreover,\nour model actively augments and guides the manipulation towards producing\nsemantically meaningful shapes, making complex manipulations possible with\nminimal user input.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:59:15 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Hao", "Zekun", ""], ["Averbuch-Elor", "Hadar", ""], ["Snavely", "Noah", ""], ["Belongie", "Serge", ""]]}, {"id": "2004.02872", "submitter": "Sheng Cao", "authors": "Sheng Cao, Chao-Yuan Wu, Philipp Kr\\\"ahenb\\\"uhl", "title": "Lossless Image Compression through Super-Resolution", "comments": "Tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and efficient lossless image compression algorithm. We\nstore a low resolution version of an image as raw pixels, followed by several\niterations of lossless super-resolution. For lossless super-resolution, we\npredict the probability of a high-resolution image, conditioned on the\nlow-resolution input, and use entropy coding to compress this super-resolution\noperator. Super-Resolution based Compression (SReC) is able to achieve\nstate-of-the-art compression rates with practical runtimes on large datasets.\nCode is available online at https://github.com/caoscott/SReC.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 17:59:40 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Cao", "Sheng", ""], ["Wu", "Chao-Yuan", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""]]}, {"id": "2004.02876", "submitter": "Roberto Doriguzzi Corin", "authors": "Roberto Doriguzzi-Corin", "title": "Methods and Techniques for Dynamic Deployability of Software-Defined\n  Security Services", "comments": "arXiv admin note: substantial text overlap with arXiv:2002.04902,\n  arXiv:1901.01704", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent trend of \"network softwarisation\", enabled by emerging\ntechnologies such as Software-Defined Networking (SDN) and Network Function\nVirtualisation (NFV), system administrators of data centres and enterprise\nnetworks have started replacing dedicated hardware-based middleboxes with\nvirtualised network functions running on servers and end hosts. This radical\nchange has facilitated the provisioning of advanced and flexible network\nservices, ultimately helping system administrators and network operators to\ncope with the rapid changes in service requirements and networking workloads.\nThis thesis investigates the challenges of provisioning network security\nservices in \"softwarised\" networks, where the security of residential and\nbusiness users can be provided by means of sets of software-based network\nfunctions running on high performance servers or on commodity compute devices.\nThe study is approached from the perspective of the telecom operator, whose\ngoal is to protect the customers from network threats and, at the same time,\nmaximize the number of provisioned services, and thereby revenue. Specifically,\nthe overall aim of the research presented in this thesis is proposing novel\ntechniques for optimising the resource usage of software-based security\nservices, hence for increasing the chances for the operator to accommodate more\nservice requests while respecting the desired level of network security of its\ncustomers. In this direction, the contributions of this thesis are the\nfollowing: (i) a solution for the dynamic provisioning of security services\nthat minimises the utilisation of computing and network resources, and (ii)\nnovel methods based on Deep Learning and Linux kernel technologies for reducing\nthe CPU usage of software-based security network functions, with specific focus\non the defence against Distributed Denial of Service (DDoS) attacks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 16:04:18 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Doriguzzi-Corin", "Roberto", ""]]}, {"id": "2004.02877", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "Empirical Upper Bound, Error Diagnosis and Invariance Analysis of Modern\n  Object Detectors", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.12451", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection remains as one of the most notorious open problems in\ncomputer vision. Despite large strides in accuracy in recent years, modern\nobject detectors have started to saturate on popular benchmarks raising the\nquestion of how far we can reach with deep learning tools and tricks. Here, by\nemploying 2 state-of-the-art object detection benchmarks, and analyzing more\nthan 15 models over 4 large scale datasets, we I) carefully determine the upper\nbound in AP, which is 91.6% on VOC (test2007), 78.2% on COCO (val2017), and\n58.9% on OpenImages V4 (validation), regardless of the IOU threshold. These\nnumbers are much better than the mAP of the best model (47.9% on VOC, and 46.9%\non COCO; IOUs=.5:.05:.95), II) characterize the sources of errors in object\ndetectors, in a novel and intuitive way, and find that classification error\n(confusion with other classes and misses) explains the largest fraction of\nerrors and weighs more than localization and duplicate errors, and III) analyze\nthe invariance properties of models when surrounding context of an object is\nremoved, when an object is placed in an incongruent background, and when images\nare blurred or flipped vertically. We find that models generate a lot of boxes\non empty regions and that context is more important for detecting small objects\nthan larger ones. Our work taps into the tight relationship between object\ndetection and object recognition and offers insights for building better\nmodels. Our code is publicly available at\nhttps://github.com/aliborji/Deetctionupper bound.git.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:19:43 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2004.02881", "submitter": "Luciano Melodia", "authors": "Luciano Melodia, Richard Lenz", "title": "Estimate of the Neural Network Dimension using Algebraic Topology and\n  Lie Theory", "comments": "The title of this article was formerly \"Parameterization of Neural\n  Networks with Connected Abelian Lie Groups as Data Manifold\"", "journal-ref": "Img.Mine.Theo.Appl.VII 2021 (15-29)", "doi": "10.1007/978-3-030-68821-9_2", "report-no": null, "categories": "stat.ML cs.CG cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an approach to determine the smallest possible\nnumber of neurons in a layer of a neural network in such a way that the\ntopology of the input space can be learned sufficiently well. We introduce a\ngeneral procedure based on persistent homology to investigate topological\ninvariants of the manifold on which we suspect the data set. We specify the\nrequired dimensions precisely, assuming that there is a smooth manifold on or\nnear which the data are located. Furthermore, we require that this space is\nconnected and has a commutative group structure in the mathematical sense.\nThese assumptions allow us to derive a decomposition of the underlying space\nwhose topology is well known. We use the representatives of the $k$-dimensional\nhomology groups from the persistence landscape to determine an integer\ndimension for this decomposition. This number is the dimension of the embedding\nthat is capable of capturing the topology of the data manifold. We derive the\ntheory and validate it experimentally on toy data sets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:15:05 GMT"}, {"version": "v10", "created": "Sun, 13 Dec 2020 14:36:48 GMT"}, {"version": "v11", "created": "Thu, 31 Dec 2020 07:27:13 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 09:32:13 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 13:09:50 GMT"}, {"version": "v4", "created": "Sat, 1 Aug 2020 08:58:54 GMT"}, {"version": "v5", "created": "Thu, 22 Oct 2020 06:17:04 GMT"}, {"version": "v6", "created": "Wed, 28 Oct 2020 08:45:41 GMT"}, {"version": "v7", "created": "Tue, 3 Nov 2020 15:02:55 GMT"}, {"version": "v8", "created": "Tue, 10 Nov 2020 14:29:01 GMT"}, {"version": "v9", "created": "Mon, 16 Nov 2020 09:14:42 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Melodia", "Luciano", ""], ["Lenz", "Richard", ""]]}, {"id": "2004.02913", "submitter": "Guokan Shang", "authors": "Guokan Shang (1 and 2), Antoine Jean-Pierre Tixier (1), Michalis\n  Vazirgiannis (1 and 3), Jean-Pierre Lorr\\'e (2) ((1) \\'Ecole Polytechnique,\n  (2) Linagora, (3) AUEB)", "title": "Speaker-change Aware CRF for Dialogue Act Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in Dialogue Act (DA) classification approaches the task as a\nsequence labeling problem, using neural network models coupled with a\nConditional Random Field (CRF) as the last layer. CRF models the conditional\nprobability of the target DA label sequence given the input utterance sequence.\nHowever, the task involves another important input sequence, that of speakers,\nwhich is ignored by previous work. To address this limitation, this paper\nproposes a simple modification of the CRF layer that takes speaker-change into\naccount. Experiments on the SwDA corpus show that our modified CRF layer\noutperforms the original one, with very wide margins for some DA labels.\nFurther, visualizations demonstrate that our CRF layer can learn meaningful,\nsophisticated transition patterns between DA label pairs conditioned on\nspeaker-change in an end-to-end way. Code is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:03:06 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 01:58:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Shang", "Guokan", "", "1 and 2"], ["Tixier", "Antoine Jean-Pierre", "", "1 and 3"], ["Vazirgiannis", "Michalis", "", "1 and 3"], ["Lorr\u00e9", "Jean-Pierre", ""]]}, {"id": "2004.02919", "submitter": "John Burden", "authors": "John Burden and Daniel Kudenko", "title": "Uniform State Abstraction For Reinforcement Learning", "comments": "8 Pages, 2 figures, Accepted for publication in the European\n  Conference of Artificial Intelligence (ECAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential Based Reward Shaping combined with a potential function based on\nappropriately defined abstract knowledge has been shown to significantly\nimprove learning speed in Reinforcement Learning. MultiGrid Reinforcement\nLearning (MRL) has further shown that such abstract knowledge in the form of a\npotential function can be learned almost solely from agent interaction with the\nenvironment. However, we show that MRL faces the problem of not extending well\nto work with Deep Learning. In this paper we extend and improve MRL to take\nadvantage of modern Deep Learning algorithms such as Deep Q-Networks (DQN). We\nshow that DQN augmented with our approach perform significantly better on\ncontinuous control tasks than its Vanilla counterpart and DQN augmented with\nMRL.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:13:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Burden", "John", ""], ["Kudenko", "Daniel", ""]]}, {"id": "2004.02932", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Hossein Ghanei-Yakhdan, Shohreh Kasaei", "title": "Beyond Background-Aware Correlation Filters: Adaptive Context Modeling\n  by Hand-Crafted and Deep RGB Features for Visual Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the background-aware correlation filters have achie-ved a\nlot of research interest in the visual target tracking. However, these methods\ncannot suitably model the target appearance due to the exploitation of\nhand-crafted features. On the other hand, the recent deep learning-based visual\ntracking methods have provided a competitive performance along with extensive\ncomputations. In this paper, an adaptive background-aware correlation\nfilter-based tracker is proposed that effectively models the target appearance\nby using either the histogram of oriented gradients (HOG) or convolutional\nneural network (CNN) feature maps. The proposed method exploits the fast 2D\nnon-maximum suppression (NMS) algorithm and the semantic information comparison\nto detect challenging situations. When the HOG-based response map is not\nreliable, or the context region has a low semantic similarity with prior\nregions, the proposed method constructs the CNN context model to improve the\ntarget region estimation. Furthermore, the rejection option allows the proposed\nmethod to update the CNN context model only on valid regions. Comprehensive\nexperimental results demonstrate that the proposed adaptive method clearly\noutperforms the accuracy and robustness of visual target tracking compared to\nthe state-of-the-art methods on the OTB-50, OTB-100, TC-128, UAV-123, and\nVOT-2015 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:48:39 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2004.02933", "submitter": "Seyed Mojtaba Marvasti-Zadeh", "authors": "Seyed Mojtaba Marvasti-Zadeh, Hossein Ghanei-Yakhdan, Shohreh Kasaei", "title": "Efficient Scale Estimation Methods using Lightweight Deep Convolutional\n  Neural Networks for Visual Tracking", "comments": "Accepted Manuscript in Neural Computing and Applications (NCAA),\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, visual tracking methods that are based on discriminative\ncorrelation filters (DCF) have been very promising. However, most of these\nmethods suffer from a lack of robust scale estimation skills. Although a wide\nrange of recent DCF-based methods exploit the features that are extracted from\ndeep convolutional neural networks (CNNs) in their translation model, the scale\nof the visual target is still estimated by hand-crafted features. Whereas the\nexploitation of CNNs imposes a high computational burden, this paper exploits\npre-trained lightweight CNNs models to propose two efficient scale estimation\nmethods, which not only improve the visual tracking performance but also\nprovide acceptable tracking speeds. The proposed methods are formulated based\non either holistic or region representation of convolutional feature maps to\nefficiently integrate into DCF formulations to learn a robust scale model in\nthe frequency domain. Moreover, against the conventional scale estimation\nmethods with iterative feature extraction of different target regions, the\nproposed methods exploit proposed one-pass feature extraction processes that\nsignificantly improve the computational efficiency. Comprehensive experimental\nresults on the OTB-50, OTB-100, TC-128 and VOT-2018 visual tracking datasets\ndemonstrate that the proposed visual tracking methods outperform the\nstate-of-the-art methods, effectively.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:49:37 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 08:22:24 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Marvasti-Zadeh", "Seyed Mojtaba", ""], ["Ghanei-Yakhdan", "Hossein", ""], ["Kasaei", "Shohreh", ""]]}, {"id": "2004.02942", "submitter": "Rhys Compton", "authors": "Rhys Compton, Eibe Frank, Panos Patros, Abigail Koay", "title": "Embedding Java Classes with code2vec: Improvements from Variable\n  Obfuscation", "comments": "In 17th International Conference on Mining Software Repositories\n  (MSR) 2020, Seoul, Republic of Korea. 11 pages", "journal-ref": null, "doi": "10.1145/3379597.3387445", "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic source code analysis in key areas of software engineering, such as\ncode security, can benefit from Machine Learning (ML). However, many standard\nML approaches require a numeric representation of data and cannot be applied\ndirectly to source code. Thus, to enable ML, we need to embed source code into\nnumeric feature vectors while maintaining the semantics of the code as much as\npossible. code2vec is a recently released embedding approach that uses the\nproxy task of method name prediction to map Java methods to feature vectors.\nHowever, experimentation with code2vec shows that it learns to rely on variable\nnames for prediction, causing it to be easily fooled by typos or adversarial\nattacks. Moreover, it is only able to embed individual Java methods and cannot\nembed an entire collection of methods such as those present in a typical Java\nclass, making it difficult to perform predictions at the class level (e.g., for\nthe identification of malicious Java classes). Both shortcomings are addressed\nin the research presented in this paper. We investigate the effect of\nobfuscating variable names during the training of a code2vec model to force it\nto rely on the structure of the code rather than specific names and consider a\nsimple approach to creating class-level embeddings by aggregating sets of\nmethod embeddings. Our results, obtained on a challenging new collection of\nsource-code classification problems, indicate that obfuscating variable names\nproduces an embedding model that is both impervious to variable naming and more\naccurately reflects code semantics. The datasets, models, and code are shared\nfor further ML research on source code.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:05:18 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Compton", "Rhys", ""], ["Frank", "Eibe", ""], ["Patros", "Panos", ""], ["Koay", "Abigail", ""]]}, {"id": "2004.02956", "submitter": "Raanan Fattal", "authors": "Adam Kaufman and Raanan Fattal", "title": "Deblurring using Analysis-Synthesis Networks Pair", "comments": null, "journal-ref": "Computer Vision and Pattern Recognition (CVPR) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind image deblurring remains a challenging problem for modern artificial\nneural networks. Unlike other image restoration problems, deblurring networks\nfail behind the performance of existing deblurring algorithms in case of\nuniform and 3D blur models. This follows from the diverse and profound effect\nthat the unknown blur-kernel has on the deblurring operator.\n  We propose a new architecture which breaks the deblurring network into an\nanalysis network which estimates the blur, and a synthesis network that uses\nthis kernel to deblur the image. Unlike existing deblurring networks, this\ndesign allows us to explicitly incorporate the blur-kernel in the network's\ntraining. In addition, we introduce new cross-correlation layers that allow\nbetter blur estimations, as well as unique components that allow the estimate\nblur to control the action of the synthesis deblurring action.\n  Evaluating the new approach over established benchmark datasets shows its\nability to achieve state-of-the-art deblurring accuracy on various tests, as\nwell as offer a major speedup in runtime.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:32:51 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Kaufman", "Adam", ""], ["Fattal", "Raanan", ""]]}, {"id": "2004.02958", "submitter": "Shoaib Ahmed Siddiqui", "authors": "Shoaib Ahmed Siddiqui, Dominique Mercier, Andreas Dengel, Sheraz Ahmed", "title": "TSInsight: A local-global attribution framework for interpretability in\n  time-series data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise in the employment of deep learning methods in safety-critical\nscenarios, interpretability is more essential than ever before. Although many\ndifferent directions regarding interpretability have been explored for visual\nmodalities, time-series data has been neglected with only a handful of methods\ntested due to their poor intelligibility. We approach the problem of\ninterpretability in a novel way by proposing TSInsight where we attach an\nauto-encoder to the classifier with a sparsity-inducing norm on its output and\nfine-tune it based on the gradients from the classifier and a reconstruction\npenalty. TSInsight learns to preserve features that are important for\nprediction by the classifier and suppresses those that are irrelevant i.e.\nserves as a feature attribution method to boost interpretability. In contrast\nto most other attribution frameworks, TSInsight is capable of generating both\ninstance-based and model-based explanations. We evaluated TSInsight along with\n9 other commonly used attribution methods on 8 different time-series datasets\nto validate its efficacy. Evaluation results show that TSInsight naturally\nachieves output space contraction, therefore, is an effective tool for the\ninterpretability of deep time-series models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:34:25 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Siddiqui", "Shoaib Ahmed", ""], ["Mercier", "Dominique", ""], ["Dengel", "Andreas", ""], ["Ahmed", "Sheraz", ""]]}, {"id": "2004.02965", "submitter": "Yi Ding", "authors": "Yi Ding, Neethu Robinson, Qiuhao Zeng, Duo Chen, Aung Aung Phyo Wai,\n  Tih-Shih Lee, Cuntai Guan", "title": "TSception: A Deep Learning Framework for Emotion Detection Using EEG", "comments": "Authors information updated only. Accepted to be published in: 2020\n  International Joint Conference on Neural Networks (IJCNN), Glasgow, July\n  19--24, 2020, part of 2020 IEEE World Congress on Computational Intelligence\n  (IEEE WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep learning framework, TSception, for emotion\ndetection from electroencephalogram (EEG). TSception consists of temporal and\nspatial convolutional layers, which learn discriminative representations in the\ntime and channel domains simultaneously. The temporal learner consists of\nmulti-scale 1D convolutional kernels whose lengths are related to the sampling\nrate of the EEG signal, which learns multiple temporal and frequency\nrepresentations. The spatial learner takes advantage of the asymmetry property\nof emotion responses at the frontal brain area to learn the discriminative\nrepresentations from the left and right hemispheres of the brain. In our study,\na system is designed to study the emotional arousal in an immersive virtual\nreality (VR) environment. EEG data were collected from 18 healthy subjects\nusing this system to evaluate the performance of the proposed deep learning\nnetwork for the classification of low and high emotional arousal states. The\nproposed method is compared with SVM, EEGNet, and LSTM. TSception achieves a\nhigh classification accuracy of 86.03%, which outperforms the prior methods\nsignificantly (p<0.05). The code is available at\nhttps://github.com/deepBrains/TSception\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:10:07 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 01:39:59 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ding", "Yi", ""], ["Robinson", "Neethu", ""], ["Zeng", "Qiuhao", ""], ["Chen", "Duo", ""], ["Wai", "Aung Aung Phyo", ""], ["Lee", "Tih-Shih", ""], ["Guan", "Cuntai", ""]]}, {"id": "2004.02967", "submitter": "Hanxiao Liu", "authors": "Hanxiao Liu, Andrew Brock, Karen Simonyan, Quoc V. Le", "title": "Evolving Normalization-Activation Layers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers and activation functions are fundamental components in\ndeep networks and typically co-locate with each other. Here we propose to\ndesign them using an automated approach. Instead of designing them separately,\nwe unify them into a single tensor-to-tensor computation graph, and evolve its\nstructure starting from basic mathematical functions. Examples of such\nmathematical functions are addition, multiplication and statistical moments.\nThe use of low-level mathematical functions, in contrast to the use of\nhigh-level modules in mainstream NAS, leads to a highly sparse and large search\nspace which can be challenging for search methods. To address the challenge, we\ndevelop efficient rejection protocols to quickly filter out candidate layers\nthat do not work well. We also use multi-objective evolution to optimize each\nlayer's performance across many architectures to prevent overfitting. Our\nmethod leads to the discovery of EvoNorms, a set of new\nnormalization-activation layers with novel, and sometimes surprising structures\nthat go beyond existing design patterns. For example, some EvoNorms do not\nassume that normalization and activation functions must be applied\nsequentially, nor need to center the feature maps, nor require explicit\nactivation functions. Our experiments show that EvoNorms work well on image\nclassification models including ResNets, MobileNets and EfficientNets but also\ntransfer well to Mask R-CNN with FPN/SpineNet for instance segmentation and to\nBigGAN for image synthesis, outperforming BatchNorm and GroupNorm based layers\nin many cases.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:52:48 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 02:58:37 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 16:29:08 GMT"}, {"version": "v4", "created": "Thu, 11 Jun 2020 22:59:31 GMT"}, {"version": "v5", "created": "Fri, 17 Jul 2020 04:42:59 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Liu", "Hanxiao", ""], ["Brock", "Andrew", ""], ["Simonyan", "Karen", ""], ["Le", "Quoc V.", ""]]}, {"id": "2004.02980", "submitter": "Abhinav Kumar", "authors": "Abhinav Kumar, Tim K. Marks, Wenxuan Mou, Ye Wang, Michael Jones,\n  Anoop Cherian, Toshiaki Koike-Akino, Xiaoming Liu, Chen Feng", "title": "LUVLi Face Alignment: Estimating Landmarks' Location, Uncertainty, and\n  Visibility Likelihood", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern face alignment methods have become quite accurate at predicting the\nlocations of facial landmarks, but they do not typically estimate the\nuncertainty of their predicted locations nor predict whether landmarks are\nvisible. In this paper, we present a novel framework for jointly predicting\nlandmark locations, associated uncertainties of these predicted locations, and\nlandmark visibilities. We model these as mixed random variables and estimate\nthem using a deep network trained with our proposed Location, Uncertainty, and\nVisibility Likelihood (LUVLi) loss. In addition, we release an entirely new\nlabeling of a large face alignment dataset with over 19,000 face images in a\nfull range of head poses. Each face is manually labeled with the ground-truth\nlocations of 68 landmarks, with the additional information of whether each\nlandmark is unoccluded, self-occluded (due to extreme head poses), or\nexternally occluded. Not only does our joint estimation yield accurate\nestimates of the uncertainty of predicted landmark locations, but it also\nyields state-of-the-art estimates for the landmark locations themselves on\nmultiple standard face alignment datasets. Our method's estimates of the\nuncertainty of predicted landmark locations could be used to automatically\nidentify input images on which face alignment fails, which can be critical for\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:17:47 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Kumar", "Abhinav", ""], ["Marks", "Tim K.", ""], ["Mou", "Wenxuan", ""], ["Wang", "Ye", ""], ["Jones", "Michael", ""], ["Cherian", "Anoop", ""], ["Koike-Akino", "Toshiaki", ""], ["Liu", "Xiaoming", ""], ["Feng", "Chen", ""]]}, {"id": "2004.02984", "submitter": "Zhiqing Sun", "authors": "Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yiming Yang, Denny\n  Zhou", "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) has recently achieved great success by\nusing huge pre-trained models with hundreds of millions of parameters. However,\nthese models suffer from heavy model sizes and high latency such that they\ncannot be deployed to resource-limited mobile devices. In this paper, we\npropose MobileBERT for compressing and accelerating the popular BERT model.\nLike the original BERT, MobileBERT is task-agnostic, that is, it can be\ngenerically applied to various downstream NLP tasks via simple fine-tuning.\nBasically, MobileBERT is a thin version of BERT_LARGE, while equipped with\nbottleneck structures and a carefully designed balance between self-attentions\nand feed-forward networks. To train MobileBERT, we first train a specially\ndesigned teacher model, an inverted-bottleneck incorporated BERT_LARGE model.\nThen, we conduct knowledge transfer from this teacher to MobileBERT. Empirical\nstudies show that MobileBERT is 4.3x smaller and 5.5x faster than BERT_BASE\nwhile achieving competitive results on well-known benchmarks. On the natural\nlanguage inference tasks of GLUE, MobileBERT achieves a GLUEscore o 77.7 (0.6\nlower than BERT_BASE), and 62 ms latency on a Pixel 4 phone. On the SQuAD\nv1.1/v2.0 question answering task, MobileBERT achieves a dev F1 score of\n90.0/79.2 (1.5/2.1 higher than BERT_BASE).\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:20:58 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 23:54:36 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Sun", "Zhiqing", ""], ["Yu", "Hongkun", ""], ["Song", "Xiaodan", ""], ["Liu", "Renjie", ""], ["Yang", "Yiming", ""], ["Zhou", "Denny", ""]]}, {"id": "2004.02988", "submitter": "Gustavo A Valencia-Zapata", "authors": "Gustavo A. Valencia-Zapata, Carolina Gonzalez-Canas, Michael G.\n  Zentner, Okan Ersoy, and Gerhard Klimeck", "title": "Probabilistic Diagnostic Tests for Degradation Problems in Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Several studies point out different causes of performance degradation in\nsupervised machine learning. Problems such as class imbalance, overlapping,\nsmall-disjuncts, noisy labels, and sparseness limit accuracy in classification\nalgorithms. Even though a number of approaches either in the form of a\nmethodology or an algorithm try to minimize performance degradation, they have\nbeen isolated efforts with limited scope. Most of these approaches focus on\nremediation of one among many problems, with experimental results coming from\nfew datasets and classification algorithms, insufficient measures of prediction\npower, and lack of statistical validation for testing the real benefit of the\nproposed approach. This paper consists of two main parts: In the first part, a\nnovel probabilistic diagnostic model based on identifying signs and symptoms of\neach problem is presented. Thereby, early and correct diagnosis of these\nproblems is to be achieved in order to select not only the most convenient\nremediation treatment but also unbiased performance metrics. Secondly, the\nbehavior and performance of several supervised algorithms are studied when\ntraining sets have such problems. Therefore, prediction of success for\ntreatments can be estimated across classifiers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:32:35 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 19:12:24 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Valencia-Zapata", "Gustavo A.", ""], ["Gonzalez-Canas", "Carolina", ""], ["Zentner", "Michael G.", ""], ["Ersoy", "Okan", ""], ["Klimeck", "Gerhard", ""]]}, {"id": "2004.02997", "submitter": "Virinchi Roy Surabhi", "authors": "Virinchi Roy Surabhi, Prashanth Krishnamurthy, Hussam Amrouch, Kanad\n  Basu, J\\\"org Henkel, Ramesh Karri, Farshad Khorrami", "title": "Hardware Trojan Detection Using Controlled Circuit Aging", "comments": "21 pages, 34 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2989735", "report-no": null, "categories": "cs.AR cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports a novel approach that uses transistor aging in an\nintegrated circuit (IC) to detect hardware Trojans. When a transistor is aged,\nit results in delays along several paths of the IC. This increase in delay\nresults in timing violations that reveal as timing errors at the output of the\nIC during its operation. We present experiments using aging-aware standard cell\nlibraries to illustrate the usefulness of the technique in detecting hardware\nTrojans. Combining IC aging with over-clocking produces a pattern of bit errors\nat the IC output by the induced timing violations. We use machine learning to\nlearn the bit error distribution at the output of a clean IC. We differentiate\nthe divergence in the pattern of bit errors because of a Trojan in the IC from\nthis baseline distribution. We simulate the golden IC and show robustness to\nIC-to-IC manufacturing variations. The approach is effective and can detect a\nTrojan even if we place it far off the critical paths. Results on benchmarks\nfrom the Trust-hub show a detection accuracy of $\\geq$99%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 21:19:50 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 00:27:40 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 01:03:16 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Surabhi", "Virinchi Roy", ""], ["Krishnamurthy", "Prashanth", ""], ["Amrouch", "Hussam", ""], ["Basu", "Kanad", ""], ["Henkel", "J\u00f6rg", ""], ["Karri", "Ramesh", ""], ["Khorrami", "Farshad", ""]]}, {"id": "2004.03019", "submitter": "Ding Zhou", "authors": "Ding Zhou, Yuanjun Gao, Liam Paninski", "title": "Disentangled Sticky Hierarchical Dirichlet Process Hidden Markov Model", "comments": null, "journal-ref": "ECML 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM) has been\nused widely as a natural Bayesian nonparametric extension of the classical\nHidden Markov Model for learning from sequential and time-series data. A sticky\nextension of the HDP-HMM has been proposed to strengthen the self-persistence\nprobability in the HDP-HMM. However, the sticky HDP-HMM entangles the strength\nof the self-persistence prior and transition prior together, limiting its\nexpressiveness. Here, we propose a more general model: the disentangled sticky\nHDP-HMM (DS-HDP-HMM). We develop novel Gibbs sampling algorithms for efficient\ninference in this model. We show that the disentangled sticky HDP-HMM\noutperforms the sticky HDP-HMM and HDP-HMM on both synthetic and real data, and\napply the new approach to analyze neural data and segment behavioral video\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:10:09 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 00:33:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhou", "Ding", ""], ["Gao", "Yuanjun", ""], ["Paninski", "Liam", ""]]}, {"id": "2004.03021", "submitter": "Yaman Umuroglu", "authors": "Yaman Umuroglu, Yash Akhauri, Nicholas J. Fraser, Michaela Blott", "title": "LogicNets: Co-Designed Neural Networks and Circuits for\n  Extreme-Throughput Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep neural networks for applications that require very high\nthroughput or extremely low latency is a severe computational challenge,\nfurther exacerbated by inefficiencies in mapping the computation to hardware.\nWe present a novel method for designing neural network topologies that directly\nmap to a highly efficient FPGA implementation. By exploiting the equivalence of\nartificial neurons with quantized inputs/outputs and truth tables, we can train\nquantized neural networks that can be directly converted to a netlist of truth\ntables, and subsequently deployed as a highly pipelinable, massively parallel\nFPGA circuit. However, the neural network topology requires careful\nconsideration since the hardware cost of truth tables grows exponentially with\nneuron fan-in. To obtain smaller networks where the whole netlist can be\nplaced-and-routed onto a single FPGA, we derive a fan-in driven hardware cost\nmodel to guide topology design, and combine high sparsity with low-bit\nactivation quantization to limit the neuron fan-in. We evaluate our approach on\ntwo tasks with very high intrinsic throughput requirements in high-energy\nphysics and network intrusion detection. We show that the combination of\nsparsity and low-bit activation quantization results in high-speed circuits\nwith small logic depth and low LUT cost, demonstrating competitive accuracy\nwith less than 15 ns of inference latency and throughput in the hundreds of\nmillions of inferences per second.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:15:41 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Umuroglu", "Yaman", ""], ["Akhauri", "Yash", ""], ["Fraser", "Nicholas J.", ""], ["Blott", "Michaela", ""]]}, {"id": "2004.03027", "submitter": "Yumo Xu", "authors": "Yumo Xu and Mirella Lapata", "title": "Query Focused Multi-Document Summarization with Distant Supervision", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of better modeling query-cluster interactions to\nfacilitate query focused multi-document summarization (QFS). Due to the lack of\ntraining data, existing work relies heavily on retrieval-style methods for\nestimating the relevance between queries and text segments. In this work, we\nleverage distant supervision from question answering where various resources\nare available to more explicitly capture the relationship between queries and\ndocuments. We propose a coarse-to-fine modeling framework which introduces\nseparate modules for estimating whether segments are relevant to the query,\nlikely to contain an answer, and central. Under this framework, a trained\nevidence estimator further discerns which retrieved segments might answer the\nquery for final selection in the summary. We demonstrate that our framework\noutperforms strong comparison systems on standard QFS benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:35:19 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xu", "Yumo", ""], ["Lapata", "Mirella", ""]]}, {"id": "2004.03028", "submitter": "Matheus Gadelha", "authors": "Matheus Gadelha, Giorgio Gori, Duygu Ceylan, Radomir Mech, Nathan\n  Carr, Tamy Boubekeur, Rui Wang, Subhransu Maji", "title": "Learning Generative Models of Shape Handles", "comments": "11 pages, 11 figures, accepted do CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generative model to synthesize 3D shapes as sets of handles --\nlightweight proxies that approximate the original 3D shape -- for applications\nin interactive editing, shape parsing, and building compact 3D representations.\nOur model can generate handle sets with varying cardinality and different types\nof handles (Figure 1). Key to our approach is a deep architecture that predicts\nboth the parameters and existence of shape handles, and a novel similarity\nmeasure that can easily accommodate different types of handles, such as cuboids\nor sphere-meshes. We leverage the recent advances in semantic 3D annotation as\nwell as automatic shape summarizing techniques to supervise our approach. We\nshow that the resulting shape representations are intuitive and achieve\nsuperior quality than previous state-of-the-art. Finally, we demonstrate how\nour method can be used in applications such as interactive shape editing,\ncompletion, and interpolation, leveraging the latent space learned by our model\nto guide these tasks. Project page: http://mgadelha.me/shapehandles.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:35:55 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Gadelha", "Matheus", ""], ["Gori", "Giorgio", ""], ["Ceylan", "Duygu", ""], ["Mech", "Radomir", ""], ["Carr", "Nathan", ""], ["Boubekeur", "Tamy", ""], ["Wang", "Rui", ""], ["Maji", "Subhransu", ""]]}, {"id": "2004.03040", "submitter": "Christopher Thiele", "authors": "Christopher Thiele, Mauricio Araya-Polo, Detlef Hohl", "title": "Deep Neural Network Learning with Second-Order Optimizers -- a Practical\n  Study with a Stochastic Quasi-Gauss-Newton Method", "comments": "8 pages, 3 figures; added reference to code, fixed formatting of\n  title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training in supervised deep learning is computationally demanding, and the\nconvergence behavior is usually not fully understood. We introduce and study a\nsecond-order stochastic quasi-Gauss-Newton (SQGN) optimization method that\ncombines ideas from stochastic quasi-Newton methods, Gauss-Newton methods, and\nvariance reduction to address this problem. SQGN provides excellent accuracy\nwithout the need for experimenting with many hyper-parameter configurations,\nwhich is often computationally prohibitive given the number of combinations and\nthe cost of each training process. We discuss the implementation of SQGN with\nTensorFlow, and we compare its convergence and computational performance to\nselected first-order methods using the MNIST benchmark and a large-scale\nseismic tomography application from Earth science.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 23:41:41 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:28:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Thiele", "Christopher", ""], ["Araya-Polo", "Mauricio", ""], ["Hohl", "Detlef", ""]]}, {"id": "2004.03042", "submitter": "Xin Li", "authors": "Xin Li, Chengyin Li, Dongxiao Zhu", "title": "COVID-MobileXpert: On-Device COVID-19 Patient Triage and Follow-up using\n  Chest X-rays", "comments": "COVID-19, SARS-CoV-2, On-device Machine Learning, Chest X-Ray (CXR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, there has been an emerging need for rapid,\ndedicated, and point-of-care COVID-19 patient disposition techniques to\noptimize resource utilization and clinical workflow. In view of this need, we\npresent COVID-MobileXpert: a lightweight deep neural network (DNN) based mobile\napp that can use chest X-ray (CXR) for COVID-19 case screening and radiological\ntrajectory prediction. We design and implement a novel three-player knowledge\ntransfer and distillation (KTD) framework including a pre-trained attending\nphysician (AP) network that extracts CXR imaging features from a large scale of\nlung disease CXR images, a fine-tuned resident fellow (RF) network that learns\nthe essential CXR imaging features to discriminate COVID-19 from pneumonia\nand/or normal cases with a small amount of COVID-19 cases, and a trained\nlightweight medical student (MS) network to perform on-device COVID-19 patient\ntriage and follow-up. To tackle the challenge of vastly similar and dominant\nfore- and background in medical images, we employ novel loss functions and\ntraining schemes for the MS network to learn the robust features. We\ndemonstrate the significant potential of COVID-MobileXpert for rapid deployment\nvia extensive experiments with diverse MS architecture and tuning parameter\nsettings. The source codes for cloud and mobile based models are available from\nthe following url: https://github.com/xinli0928/COVID-Xray.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 23:43:58 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 04:24:31 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 05:56:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Li", "Xin", ""], ["Li", "Chengyin", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "2004.03045", "submitter": "Jeong-Yoon Lee", "authors": "Jing Pan, Vincent Pham, Mohan Dorairaj, Huigang Chen, Jeong-Yoon Lee\n  (Uber Technologies, San Francisco, CA, USA)", "title": "Adversarial Validation Approach to Concept Drift Problem in User\n  Targeting Automation Systems at Uber", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In user targeting automation systems, concept drift in input data is one of\nthe main challenges. It deteriorates model performance on new data over time.\nPrevious research on concept drift mostly proposed model retraining after\nobserving performance decreases. However, this approach is suboptimal because\nthe system fixes the problem only after suffering from poor performance on new\ndata. Here, we introduce an adversarial validation approach to concept drift\nproblems in user targeting automation systems. With our approach, the system\ndetects concept drift in new data before making inference, trains a model, and\nproduces predictions adapted to the new data. We show that our approach\naddresses concept drift effectively with the AutoML3 Lifelong Machine Learning\nchallenge data as well as in Uber's internal user targeting automation system,\nMaLTA.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:01:34 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 06:23:09 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Pan", "Jing", "", "Uber Technologies, San Francisco, CA, USA"], ["Pham", "Vincent", "", "Uber Technologies, San Francisco, CA, USA"], ["Dorairaj", "Mohan", "", "Uber Technologies, San Francisco, CA, USA"], ["Chen", "Huigang", "", "Uber Technologies, San Francisco, CA, USA"], ["Lee", "Jeong-Yoon", "", "Uber Technologies, San Francisco, CA, USA"]]}, {"id": "2004.03056", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Yizhuo Song, Muhammad R. A. Khandaker, Faisal Tariq, Kai-Kit Wong and\n  Apriana Toding", "title": "Truly Intelligent Reflecting Surface-Aided Secure Communication Using\n  Deep Learning", "comments": "Submitted to IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers machine learning for physical layer security design for\ncommunication in a challenging wireless environment. The radio environment is\nassumed to be programmable with the aid of a meta material-based intelligent\nreflecting surface (IRS) allowing customisable path loss, multi-path fading and\ninterference effects. In particular, the fine-grained reflections from the IRS\nelements are exploited to create channel advantage for maximizing the secrecy\nrate at a legitimate receiver. A deep learning (DL) technique has been\ndeveloped to tune the reflections of the IRS elements in real-time. Simulation\nresults demonstrate that the DL approach yields comparable performance to the\nconventional approaches while significantly reducing the computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:48:58 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 01:54:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Song", "Yizhuo", ""], ["Khandaker", "Muhammad R. A.", ""], ["Tariq", "Faisal", ""], ["Wong", "Kai-Kit", ""], ["Toding", "Apriana", ""]]}, {"id": "2004.03061", "submitter": "Tiago Pimentel", "authors": "Tiago Pimentel, Josef Valvoda, Rowan Hall Maudslay, Ran Zmigrod, Adina\n  Williams, Ryan Cotterell", "title": "Information-Theoretic Probing for Linguistic Structure", "comments": "Accepted for publication at ACL 2020. This is the camera ready\n  version. Code available in https://github.com/rycolab/info-theoretic-probing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks on a diverse set of NLP tasks has led\nresearchers to question how much these networks actually ``know'' about natural\nlanguage. Probes are a natural way of assessing this. When probing, a\nresearcher chooses a linguistic task and trains a supervised model to predict\nannotations in that linguistic task from the network's learned representations.\nIf the probe does well, the researcher may conclude that the representations\nencode knowledge related to the task. A commonly held belief is that using\nsimpler models as probes is better; the logic is that simpler models will\nidentify linguistic structure, but not learn the task itself. We propose an\ninformation-theoretic operationalization of probing as estimating mutual\ninformation that contradicts this received wisdom: one should always select the\nhighest performing probe one can, even if it is more complex, since it will\nresult in a tighter estimate, and thus reveal more of the linguistic\ninformation inherent in the representation. The experimental portion of our\npaper focuses on empirically estimating the mutual information between a\nlinguistic property and BERT, comparing these estimates to several baselines.\nWe evaluate on a set of ten typologically diverse languages often\nunderrepresented in NLP research---plus English---totalling eleven languages.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:06:36 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 21:58:58 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Pimentel", "Tiago", ""], ["Valvoda", "Josef", ""], ["Maudslay", "Rowan Hall", ""], ["Zmigrod", "Ran", ""], ["Williams", "Adina", ""], ["Cotterell", "Ryan", ""]]}, {"id": "2004.03064", "submitter": "Jichao Zhang", "authors": "Jingjing Chen, Jichao Zhang, Enver Sangineto, Jiayuan Fan, Tao Chen,\n  Nicu Sebe", "title": "Coarse-to-Fine Gaze Redirection with Numerical and Pictorial Guidance", "comments": "12 pages, accepted by WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaze redirection aims at manipulating the gaze of a given face image with\nrespect to a desired direction (i.e., a reference angle) and it can be applied\nto many real life scenarios, such as video-conferencing or taking group photos.\nHowever, previous work on this topic mainly suffers of two limitations: (1)\nLow-quality image generation and (2) Low redirection precision. In this paper,\nwe propose to alleviate these problems by means of a novel gaze redirection\nframework which exploits both a numerical and a pictorial direction guidance,\njointly with a coarse-to-fine learning strategy. Specifically, the coarse\nbranch learns the spatial transformation which warps input image according to\ndesired gaze. On the other hand, the fine-grained branch consists of a\ngenerator network with conditional residual image learning and a multi-task\ndiscriminator. This second branch reduces the gap between the previously warped\nimage and the ground-truth image and recovers finer texture details. Moreover,\nwe propose a numerical and pictorial guidance module~(NPG) which uses a\npictorial gazemap description and numerical angles as an extra guide to further\nimprove the precision of gaze redirection. Extensive experiments on a benchmark\ndataset show that the proposed method outperforms the state-of-the-art\napproaches in terms of both image quality and redirection precision. The code\nis available at https://github.com/jingjingchen777/CFGR\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:17:27 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 19:31:08 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 22:37:18 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 06:17:15 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Chen", "Jingjing", ""], ["Zhang", "Jichao", ""], ["Sangineto", "Enver", ""], ["Fan", "Jiayuan", ""], ["Chen", "Tao", ""], ["Sebe", "Nicu", ""]]}, {"id": "2004.03069", "submitter": "Polina Alexeenko", "authors": "Polina Alexeenko and Eilyan Bitar", "title": "Nonparametric Estimation of Uncertainty Sets for Robust Optimization", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a data-driven approach to constructing uncertainty sets for\nrobust optimization problems, where the uncertain problem parameters are\nmodeled as random variables whose joint probability distribution is not known.\nRelying only on independent samples drawn from this distribution, we provide a\nnonparametric method to estimate uncertainty sets whose probability mass is\nguaranteed to approximate a given target mass within a given tolerance with\nhigh confidence. The nonparametric estimators that we consider are also shown\nto obey distribution-free finite-sample performance bounds that imply their\nconvergence in probability to the given target mass. In addition to being\nefficient to compute, the proposed estimators result in uncertainty sets that\nyield computationally tractable robust optimization problems for a large family\nof constraint functions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:47:55 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 19:54:48 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alexeenko", "Polina", ""], ["Bitar", "Eilyan", ""]]}, {"id": "2004.03072", "submitter": "Shijian Li", "authors": "Shijian Li and Robert J. Walls and Tian Guo", "title": "Characterizing and Modeling Distributed Training with Transient Cloud\n  GPU Servers", "comments": "11 pages, 12 figures, 5 tables, in proceedings of 40th IEEE\n  International Conference on Distributed Computing Systems (ICDCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud GPU servers have become the de facto way for deep learning\npractitioners to train complex models on large-scale datasets. However, it is\nchallenging to determine the appropriate cluster configuration---e.g., server\ntype and number---for different training workloads while balancing the\ntrade-offs in training time, cost, and model accuracy. Adding to the complexity\nis the potential to reduce the monetary cost by using cheaper, but revocable,\ntransient GPU servers.\n  In this work, we analyze distributed training performance under diverse\ncluster configurations using CM-DARE, a cloud-based measurement and training\nframework. Our empirical datasets include measurements from three GPU types,\nsix geographic regions, twenty convolutional neural networks, and thousands of\nGoogle Cloud servers. We also demonstrate the feasibility of predicting\ntraining speed and overhead using regression-based models. Finally, we discuss\npotential use cases of our performance modeling such as detecting and\nmitigating performance bottlenecks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:49:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Li", "Shijian", ""], ["Walls", "Robert J.", ""], ["Guo", "Tian", ""]]}, {"id": "2004.03074", "submitter": "Kai Zhang", "authors": "Kai Zhang, V\\'itor Albiero and Kevin W. Bowyer", "title": "A Method for Curation of Web-Scraped Face Image Datasets", "comments": "This paper will appear at IWBF 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-scraped, in-the-wild datasets have become the norm in face recognition\nresearch. The numbers of subjects and images acquired in web-scraped datasets\nare usually very large, with number of images on the millions scale. A variety\nof issues occur when collecting a dataset in-the-wild, including images with\nthe wrong identity label, duplicate images, duplicate subjects and variation in\nquality. With the number of images being in the millions, a manual cleaning\nprocedure is not feasible. But fully automated methods used to date result in a\nless-than-ideal level of clean dataset. We propose a semi-automated method,\nwhere the goal is to have a clean dataset for testing face recognition methods,\nwith similar quality across men and women, to support comparison of accuracy\nacross gender. Our approach removes near-duplicate images, merges duplicate\nsubjects, corrects mislabeled images, and removes images outside a defined\nrange of pose and quality. We conduct the curation on the Asian Face Dataset\n(AFD) and VGGFace2 test dataset. The experiments show that a state-of-the-art\nmethod achieves a much higher accuracy on the datasets after they are curated.\nFinally, we release our cleaned versions of both datasets to the research\ncommunity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:57:32 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zhang", "Kai", ""], ["Albiero", "V\u00edtor", ""], ["Bowyer", "Kevin W.", ""]]}, {"id": "2004.03083", "submitter": "Yadi Wei", "authors": "Yadi Wei, Rishit Sheth, Roni Khardon", "title": "Direct loss minimization algorithms for sparse Gaussian processes", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides a thorough investigation of Direct loss minimization\n(DLM), which optimizes the posterior to minimize predictive loss, in sparse\nGaussian processes. For the conjugate case, we consider DLM for log-loss and\nDLM for square loss showing a significant performance improvement in both\ncases. The application of DLM in non-conjugate cases is more complex because\nthe logarithm of expectation in the log-loss DLM objective is often intractable\nand simple sampling leads to biased estimates of gradients. The paper makes two\ntechnical contributions to address this. First, a new method using product\nsampling is proposed, which gives unbiased estimates of gradients (uPS) for the\nobjective function. Second, a theoretical analysis of biased Monte Carlo\nestimates (bMC) shows that stochastic gradient descent converges despite the\nbiased gradients. Experiments demonstrate empirical success of DLM. A\ncomparison of the sampling methods shows that, while uPS is potentially more\nsample-efficient, bMC provides a better tradeoff in terms of convergence time\nand computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 02:31:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:30:10 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 18:36:12 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Wei", "Yadi", ""], ["Sheth", "Rishit", ""], ["Khardon", "Roni", ""]]}, {"id": "2004.03101", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee and Chitta Baral", "title": "Knowledge Fusion and Semantic Knowledge Ranking for Open Domain Question\n  Answering", "comments": "9 pages. 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Domain Question Answering requires systems to retrieve external\nknowledge and perform multi-hop reasoning by composing knowledge spread over\nmultiple sentences. In the recently introduced open domain question answering\nchallenge datasets, QASC and OpenBookQA, we need to perform retrieval of facts\nand compose facts to correctly answer questions. In our work, we learn a\nsemantic knowledge ranking model to re-rank knowledge retrieved through Lucene\nbased information retrieval systems. We further propose a \"knowledge fusion\nmodel\" which leverages knowledge in BERT-based language models with externally\nretrieved knowledge and improves the knowledge understanding of the BERT-based\nlanguage models. On both OpenBookQA and QASC datasets, the knowledge fusion\nmodel with semantically re-ranked knowledge outperforms previous attempts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:16:47 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 06:46:36 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Baral", "Chitta", ""]]}, {"id": "2004.03104", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Haoyu Tang, Xinyuan Liu, Zhongyu Li, and\n  Huimin Lu", "title": "Generalized Label Enhancement with Sample Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, label distribution learning (LDL) has drawn much attention in\nmachine learning, where LDL model is learned from labelel instances. Different\nfrom single-label and multi-label annotations, label distributions describe the\ninstance by multiple labels with different intensities and accommodate to more\ngeneral scenes. Since most existing machine learning datasets merely provide\nlogical labels, label distributions are unavailable in many real-world\napplications. To handle this problem, we propose two novel label enhancement\nmethods, i.e., Label Enhancement with Sample Correlations (LESC) and\ngeneralized Label Enhancement with Sample Correlations (gLESC). More\nspecifically, LESC employs a low-rank representation of samples in the feature\nspace, and gLESC leverages a tensor multi-rank minimization to further\ninvestigate the sample correlations in both the feature space and label space.\nBenefitting from the sample correlations, the proposed methods can boost the\nperformance of label enhancement. Extensive experiments on 14 benchmark\ndatasets demonstrate the effectiveness and superiority of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:32:36 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 14:17:26 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 02:47:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Tang", "Haoyu", ""], ["Liu", "Xinyuan", ""], ["Li", "Zhongyu", ""], ["Lu", "Huimin", ""]]}, {"id": "2004.03106", "submitter": "Qinghai Zheng", "authors": "Qinghai Zheng, Jihua Zhu, Zhongyu Li, Shanmin Pang, Jun Wang, Lei Chen", "title": "Consistent and Complementary Graph Regularized Multi-view Subspace\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the problem of multi-view clustering, where multiple\nviews contain consistent information and each view also includes complementary\ninformation. Exploration of all information is crucial for good multi-view\nclustering. However, most traditional methods blindly or crudely combine\nmultiple views for clustering and are unable to fully exploit the valuable\ninformation. Therefore, we propose a method that involves consistent and\ncomplementary graph-regularized multi-view subspace clustering (GRMSC), which\nsimultaneously integrates a consistent graph regularizer with a complementary\ngraph regularizer into the objective function. In particular, the consistent\ngraph regularizer learns the intrinsic affinity relationship of data points\nshared by all views. The complementary graph regularizer investigates the\nspecific information of multiple views. It is noteworthy that the consistent\nand complementary regularizers are formulated by two different graphs\nconstructed from the first-order proximity and second-order proximity of\nmultiple views, respectively. The objective function is optimized by the\naugmented Lagrangian multiplier method in order to achieve multi-view\nclustering. Extensive experiments on six benchmark datasets serve to validate\nthe effectiveness of the proposed method over other state-of-the-art multi-view\nclustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:48:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zheng", "Qinghai", ""], ["Zhu", "Jihua", ""], ["Li", "Zhongyu", ""], ["Pang", "Shanmin", ""], ["Wang", "Jun", ""], ["Chen", "Lei", ""]]}, {"id": "2004.03112", "submitter": "Maoying Qiao", "authors": "Maoying Qiao, Tongliang Liu, Jun Yu, Wei Bian, Dacheng Tao", "title": "Repulsive Mixture Models of Exponential Family PCA for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixture extension of exponential family principal component analysis\n(EPCA) was designed to encode much more structural information about data\ndistribution than the traditional EPCA does. For example, due to the linearity\nof EPCA's essential form, nonlinear cluster structures cannot be easily\nhandled, but they are explicitly modeled by the mixing extensions. However, the\ntraditional mixture of local EPCAs has the problem of model redundancy, i.e.,\noverlaps among mixing components, which may cause ambiguity for data\nclustering. To alleviate this problem, in this paper, a\nrepulsiveness-encouraging prior is introduced among mixing components and a\ndiversified EPCA mixture (DEPCAM) model is developed in the Bayesian framework.\nSpecifically, a determinantal point process (DPP) is exploited as a\ndiversity-encouraging prior distribution over the joint local EPCAs. As\nrequired, a matrix-valued measure for L-ensemble kernel is designed, within\nwhich, $\\ell_1$ constraints are imposed to facilitate selecting effective PCs\nof local EPCAs, and angular based similarity measure are proposed. An efficient\nvariational EM algorithm is derived to perform parameter learning and hidden\nvariable inference. Experimental results on both synthetic and real-world\ndatasets confirm the effectiveness of the proposed method in terms of model\nparsimony and generalization ability on unseen test data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 04:07:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Qiao", "Maoying", ""], ["Liu", "Tongliang", ""], ["Yu", "Jun", ""], ["Bian", "Wei", ""], ["Tao", "Dacheng", ""]]}, {"id": "2004.03133", "submitter": "Seungjae Shin", "authors": "Seungjae Shin, Kyungwoo Song, JoonHo Jang, Hyemi Kim, Weonyoung Joo,\n  Il-Chul Moon", "title": "Neutralizing Gender Bias in Word Embedding with Latent Disentanglement\n  and Counterfactual Generation", "comments": "Findings of EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research demonstrates that word embeddings, trained on the\nhuman-generated corpus, have strong gender biases in embedding spaces, and\nthese biases can result in the discriminative results from the various\ndownstream tasks. Whereas the previous methods project word embeddings into a\nlinear subspace for debiasing, we introduce a \\textit{Latent Disentanglement}\nmethod with a siamese auto-encoder structure with an adapted gradient reversal\nlayer. Our structure enables the separation of the semantic latent information\nand gender latent information of given word into the disjoint latent\ndimensions. Afterwards, we introduce a \\textit{Counterfactual Generation} to\nconvert the gender information of words, so the original and the modified\nembeddings can produce a gender-neutralized word embedding after geometric\nalignment regularization, without loss of semantic information. From the\nvarious quantitative and qualitative debiasing experiments, our method shows to\nbe better than existing debiasing methods in debiasing word embeddings. In\naddition, Our method shows the ability to preserve semantic information during\ndebiasing by minimizing the semantic information losses for extrinsic NLP\ndownstream tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 05:16:48 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 05:06:41 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Jang", "JoonHo", ""], ["Kim", "Hyemi", ""], ["Joo", "Weonyoung", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2004.03139", "submitter": "Yeganeh Marghi", "authors": "Yeganeh M. Marghi, Aziz Kocanaogullari, Murat Akcakaya, Deniz Erdogmus", "title": "Active recursive Bayesian inference using R\\'enyi information measures", "comments": "13 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Bayesian inference (RBI) provides optimal Bayesian latent variable\nestimates in real-time settings with streaming noisy observations. Active RBI\nattempts to effectively select queries that lead to more informative\nobservations to rapidly reduce uncertainty until a confident decision is made.\nHowever, typically the optimality objectives of inference and query mechanisms\nare not jointly selected. Furthermore, conventional active querying methods\nstagger due to misleading prior information. Motivated by information theoretic\napproaches, we propose an active RBI framework with unified inference and query\nselection steps through Renyi entropy and $\\alpha$-divergence. We also propose\na new objective based on Renyi entropy and its changes called Momentum that\nencourages exploration for misleading prior cases. The proposed active RBI\nframework is applied to the trajectory of the posterior changes in the\nprobability simplex that provides a coordinated active querying and decision\nmaking with specified confidence. Under certain assumptions, we analytically\ndemonstrate that the proposed approach outperforms conventional methods such as\nmutual information by allowing the selections of unlikely events. We present\nempirical and experimental performance evaluations on two applications:\nrestaurant recommendation and brain-computer interface (BCI) typing systems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 05:52:58 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 16:35:34 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Marghi", "Yeganeh M.", ""], ["Kocanaogullari", "Aziz", ""], ["Akcakaya", "Murat", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2004.03147", "submitter": "Sourish Das", "authors": "Sourish Das", "title": "Prediction of COVID-19 Disease Progression in India : Under the Effect\n  of National Lockdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this policy paper, we implement the epidemiological SIR to estimate the\nbasic reproduction number $\\mathcal{R}_0$ at national and state level. We also\ndeveloped the statistical machine learning model to predict the cases ahead of\ntime. Our analysis indicates that the situation of Punjab\n($\\mathcal{R}_0\\approx 16$) is not good. It requires immediate aggressive\nattention. We see the $\\mathcal{R}_0$ for Madhya Pradesh (3.37) , Maharastra\n(3.25) and Tamil Nadu (3.09) are more than 3. The $\\mathcal{R}_0$ of Andhra\nPradesh (2.96), Delhi (2.82) and West Bengal (2.77) is more than the India's\n$\\mathcal{R}_0=2.75$, as of 04 March, 2020. India's $\\mathcal{R}_0=2.75$ (as of\n04 March, 2020) is very much comparable to Hubei/China at the early disease\nprogression stage. Our analysis indicates that the early disease progression of\nIndia is that of similar to China. Therefore, with lockdown in place, India\nshould expect as many as cases if not more like China. If lockdown works, we\nshould expect less than 66,224 cases by May 01,2020. All data and \\texttt{R}\ncode for this paper is available from\n\\url{https://github.com/sourish-cmi/Covid19}\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 06:35:41 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Das", "Sourish", ""]]}, {"id": "2004.03168", "submitter": "R\\'emy Portelas", "authors": "R\\'emy Portelas and Katja Hofmann and Pierre-Yves Oudeyer", "title": "Trying AGAIN instead of Trying Longer: Prior Learning for Automatic\n  Curriculum Learning", "comments": "Accepted to the ICLR 2020 workshop Beyond tabula rasa in RL (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in the Deep RL (DRL) community is to train agents able to\ngeneralize over unseen situations, which is often approached by training them\non a diversity of tasks (or environments). A powerful method to foster\ndiversity is to procedurally generate tasks by sampling their parameters from a\nmulti-dimensional distribution, enabling in particular to propose a different\ntask for each training episode. In practice, to get the high diversity of\ntraining tasks necessary for generalization, one has to use complex procedural\ngeneration systems. With such generators, it is hard to get prior knowledge on\nthe subset of tasks that are actually learnable at all (many generated tasks\nmay be unlearnable), what is their relative difficulty and what is the most\nefficient task distribution ordering for training. A typical solution in such\ncases is to rely on some form of Automated Curriculum Learning (ACL) to adapt\nthe sampling distribution. One limit of current approaches is their need to\nexplore the task space to detect progress niches over time, which leads to a\nloss of time. Additionally, we hypothesize that the induced noise in the\ntraining data may impair the performances of brittle DRL learners. We address\nthis problem by proposing a two stage ACL approach where 1) a teacher algorithm\nfirst learns to train a DRL agent with a high-exploration curriculum, and then\n2) distills learned priors from the first run to generate an \"expert\ncurriculum\" to re-train the same agent from scratch. Besides demonstrating 50%\nimprovements on average over the current state of the art, the objective of\nthis work is to give a first example of a new research direction oriented\ntowards refining ACL techniques over multiple learners, which we call Classroom\nTeaching.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:30:27 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Portelas", "R\u00e9my", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2004.03169", "submitter": "Quoc Hoan Tran", "authors": "Quoc Hoan Tran, Mark Chen, and Yoshihiko Hasegawa", "title": "Topological Persistence Machine of Phase Transitions", "comments": "12 pages, 8 figures", "journal-ref": "Phys. Rev. E 103, 052127 (2021)", "doi": "10.1103/PhysRevE.103.052127", "report-no": null, "categories": "cond-mat.stat-mech cs.LG math.AT quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of phase transitions using data-driven approaches is challenging,\nespecially when little prior knowledge of the system is available. Topological\ndata analysis is an emerging framework for characterizing the shape of data and\nhas recently achieved success in detecting structural transitions in material\nscience, such as the glass--liquid transition. However, data obtained from\nphysical states may not have explicit shapes as structural materials. We thus\npropose a general framework, termed \"topological persistence machine,\" to\nconstruct the shape of data from correlations in states, so that we can\nsubsequently decipher phase transitions via qualitative changes in the shape.\nOur framework enables an effective and unified approach in phase transition\nanalysis. We demonstrate the efficacy of the approach in detecting the\nBerezinskii--Kosterlitz--Thouless phase transition in the classical XY model\nand quantum phase transitions in the transverse Ising and Bose--Hubbard models.\nInterestingly, while these phase transitions have proven to be notoriously\ndifficult to analyze using traditional methods, they can be characterized\nthrough our framework without requiring prior knowledge of the phases. Our\napproach is thus expected to be widely applicable and will provide practical\ninsights for exploring the phases of experimental physical systems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 07:31:42 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 09:09:53 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 07:41:12 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Tran", "Quoc Hoan", ""], ["Chen", "Mark", ""], ["Hasegawa", "Yoshihiko", ""]]}, {"id": "2004.03188", "submitter": "Saeed Rahimi Gorji", "authors": "Saeed Rahimi Gorji, Ole-Christoffer Granmo, Sondre Glimsdal, Jonathan\n  Edwards, Morten Goodwin", "title": "Increasing the Inference and Learning Speed of Tsetlin Machines with\n  Clause Indexing", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Tsetlin Machine (TM) is a machine learning algorithm founded on the\nclassical Tsetlin Automaton (TA) and game theory. It further leverages frequent\npattern mining and resource allocation principles to extract common patterns in\nthe data, rather than relying on minimizing output error, which is prone to\noverfitting. Unlike the intertwined nature of pattern representation in neural\nnetworks, a TM decomposes problems into self-contained patterns, represented as\nconjunctive clauses. The clause outputs, in turn, are combined into a\nclassification decision through summation and thresholding, akin to a logistic\nregression function, however, with binary weights and a unit step output\nfunction. In this paper, we exploit this hierarchical structure by introducing\na novel algorithm that avoids evaluating the clauses exhaustively. Instead we\nuse a simple look-up table that indexes the clauses on the features that\nfalsify them. In this manner, we can quickly evaluate a large number of clauses\nthrough falsification, simply by iterating through the features and using the\nlook-up table to eliminate those clauses that are falsified. The look-up table\nis further structured so that it facilitates constant time updating, thus\nsupporting use also during learning. We report up to 15 times faster\nclassification and three times faster learning on MNIST and Fashion-MNIST image\nclassification, and IMDb sentiment analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 08:16:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Gorji", "Saeed Rahimi", ""], ["Granmo", "Ole-Christoffer", ""], ["Glimsdal", "Sondre", ""], ["Edwards", "Jonathan", ""], ["Goodwin", "Morten", ""]]}, {"id": "2004.03194", "submitter": "Youngmoon Jung", "authors": "Youngmoon Jung, Seong Min Kye, Yeunju Choi, Myunghun Jung, Hoirin Kim", "title": "Improving Multi-Scale Aggregation Using Feature Pyramid Module for\n  Robust Speaker Verification of Variable-Duration Utterances", "comments": "Accepted to Interspeech 2020", "journal-ref": "Proc. Interspeech 2020, pp. 1501-1505", "doi": "10.21437/Interspeech.2020-1025", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, the most widely used approach for speaker verification is the deep\nspeaker embedding learning. In this approach, we obtain a speaker embedding\nvector by pooling single-scale features that are extracted from the last layer\nof a speaker feature extractor. Multi-scale aggregation (MSA), which utilizes\nmulti-scale features from different layers of the feature extractor, has\nrecently been introduced and shows superior performance for variable-duration\nutterances. To increase the robustness dealing with utterances of arbitrary\nduration, this paper improves the MSA by using a feature pyramid module. The\nmodule enhances speaker-discriminative information of features from multiple\nlayers via a top-down pathway and lateral connections. We extract speaker\nembeddings using the enhanced features that contain rich speaker information\nwith different time scales. Experiments on the VoxCeleb dataset show that the\nproposed module improves previous MSA methods with a smaller number of\nparameters. It also achieves better performance than state-of-the-art\napproaches for both short and long utterances.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 08:35:05 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 04:28:40 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 09:39:43 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 06:09:29 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Jung", "Youngmoon", ""], ["Kye", "Seong Min", ""], ["Choi", "Yeunju", ""], ["Jung", "Myunghun", ""], ["Kim", "Hoirin", ""]]}, {"id": "2004.03237", "submitter": "Richard Meyes", "authors": "Richard Meyes, Moritz Schneider, Tobias Meisen", "title": "How Do You Act? An Empirical Study to Understand Behavior of Deep\n  Reinforcement Learning Agents", "comments": "16 pages, currently under review for publication for the ECMLPKDD\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for more transparency of decision-making processes of deep\nreinforcement learning agents is greater than ever, due to their increased use\nin safety critical and ethically challenging domains such as autonomous\ndriving. In this empirical study, we address this lack of transparency\nfollowing an idea that is inspired by research in the field of neuroscience. We\ncharacterize the learned representations of an agent's policy network through\nits activation space and perform partial network ablations to compare the\nrepresentations of the healthy and the intentionally damaged networks. We show\nthat the healthy agent's behavior is characterized by a distinct correlation\npattern between the network's layer activation and the performed actions during\nan episode and that network ablations, which cause a strong change of this\npattern, lead to the agent failing its trained control task. Furthermore, the\nlearned representation of the healthy agent is characterized by a distinct\npattern in its activation space reflecting its different behavioral stages\nduring an episode, which again, when distorted by network ablations, leads to\nthe agent failing its trained control task. Concludingly, we argue in favor of\na new perspective on artificial neural networks as objects of empirical\ninvestigations, just as biological neural systems in neuroscientific studies,\npaving the way towards a new standard of scientific falsifiability with respect\nto research on transparency and interpretability of artificial neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:08:55 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Meyes", "Richard", ""], ["Schneider", "Moritz", ""], ["Meisen", "Tobias", ""]]}, {"id": "2004.03238", "submitter": "Kazutoshi Shinoda", "authors": "Kazutoshi Shinoda, Saku Sugawara, Akiko Aizawa", "title": "Improving the Robustness of QA Models to Challenge Sets with Variational\n  Question-Answer Pair Generation", "comments": "ACL-IJCNLP 2021 SRW", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) models for reading comprehension have achieved\nhuman-level accuracy on in-distribution test sets. However, they have been\ndemonstrated to lack robustness to challenge sets, whose distribution is\ndifferent from that of training sets. Existing data augmentation methods\nmitigate this problem by simply augmenting training sets with synthetic\nexamples sampled from the same distribution as the challenge sets. However,\nthese methods assume that the distribution of a challenge set is known a\npriori, making them less applicable to unseen challenge sets. In this study, we\nfocus on question-answer pair generation (QAG) to mitigate this problem. While\nmost existing QAG methods aim to improve the quality of synthetic examples, we\nconjecture that diversity-promoting QAG can mitigate the sparsity of training\nsets and lead to better robustness. We present a variational QAG model that\ngenerates multiple diverse QA pairs from a paragraph. Our experiments show that\nour method can improve the accuracy of 12 challenge sets, as well as the\nin-distribution accuracy. Our code and data are available at\nhttps://github.com/KazutoshiShinoda/VQAG.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:15:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 01:21:14 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Shinoda", "Kazutoshi", ""], ["Sugawara", "Saku", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2004.03254", "submitter": "Marco Corneli", "authors": "Laurent Vanni, Marco Corneli, Damon Mayaffre, Fr\\'ed\\'eric Precioso", "title": "From text saliency to linguistic objects: learning linguistic\n  interpretable markers with a multi-channels convolutional architecture", "comments": "7 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of effort is currently made to provide methods to analyze and\nunderstand deep neural network impressive performances for tasks such as image\nor text classification. These methods are mainly based on visualizing the\nimportant input features taken into account by the network to build a decision.\nHowever these techniques, let us cite LIME, SHAP, Grad-CAM, or TDS, require\nextra effort to interpret the visualization with respect to expert knowledge.\nIn this paper, we propose a novel approach to inspect the hidden layers of a\nfitted CNN in order to extract interpretable linguistic objects from texts\nexploiting classification process. In particular, we detail a weighted\nextension of the Text Deconvolution Saliency (wTDS) measure which can be used\nto highlight the relevant features used by the CNN to perform the\nclassification task. We empirically demonstrate the efficiency of our approach\non corpora from two different languages: English and French. On all datasets,\nwTDS automatically encodes complex linguistic objects based on co-occurrences\nand possibly on grammatical and syntax analysis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:46:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Vanni", "Laurent", ""], ["Corneli", "Marco", ""], ["Mayaffre", "Damon", ""], ["Precioso", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2004.03260", "submitter": "Danyang Huang", "authors": "Yingqiu Zhu, Yu Chen, Danyang Huang, Bo Zhang and Hansheng Wang", "title": "Automatic, Dynamic, and Nearly Optimal Learning Rate Specification by\n  Local Quadratic Approximation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning tasks, the learning rate determines the update step size in\neach iteration, which plays a critical role in gradient-based optimization.\nHowever, the determination of the appropriate learning rate in practice\ntypically replies on subjective judgement. In this work, we propose a novel\noptimization method based on local quadratic approximation (LQA). In each\nupdate step, given the gradient direction, we locally approximate the loss\nfunction by a standard quadratic function of the learning rate. Then, we\npropose an approximation step to obtain a nearly optimal learning rate in a\ncomputationally efficient way. The proposed LQA method has three important\nfeatures. First, the learning rate is automatically determined in each update\nstep. Second, it is dynamically adjusted according to the current loss function\nvalue and the parameter estimates. Third, with the gradient direction fixed,\nthe proposed method leads to nearly the greatest reduction in terms of the loss\nfunction. Extensive experiments have been conducted to prove the strengths of\nthe proposed LQA method.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:55:12 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zhu", "Yingqiu", ""], ["Chen", "Yu", ""], ["Huang", "Danyang", ""], ["Zhang", "Bo", ""], ["Wang", "Hansheng", ""]]}, {"id": "2004.03264", "submitter": "Geon Heo", "authors": "Geon Heo, Yuji Roh, Seonghyeon Hwang, Dayun Lee, Steven Euijong Whang", "title": "Inspector Gadget: A Data Programming-based Labeling System for\n  Industrial Images", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning for images becomes democratized in the Software 2.0 era,\none of the serious bottlenecks is securing enough labeled data for training.\nThis problem is especially critical in a manufacturing setting where smart\nfactories rely on machine learning for product quality control by analyzing\nindustrial images. Such images are typically large and may only need to be\npartially analyzed where only a small portion is problematic (e.g., identifying\ndefects on a surface). Since manual labeling these images is expensive, weak\nsupervision is an attractive alternative where the idea is to generate weak\nlabels that are not perfect, but can be produced at scale. Data programming is\na recent paradigm in this category where it uses human knowledge in the form of\nlabeling functions and combines them into a generative model. Data programming\nhas been successful in applications based on text or structured data and can\nalso be applied to images usually if one can find a way to convert them into\nstructured data. In this work, we expand the horizon of data programming by\ndirectly applying it to images without this conversion, which is a common\nscenario for industrial applications. We propose Inspector Gadget, an image\nlabeling system that combines crowdsourcing, data augmentation, and data\nprogramming to produce weak labels at scale for image classification. We\nperform experiments on real industrial image datasets and show that Inspector\nGadget obtains better performance than other weak-labeling techniques: Snuba,\nGOGGLES, and self-learning baselines using convolutional neural networks (CNNs)\nwithout pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:00:29 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 05:45:21 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 04:12:15 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Heo", "Geon", ""], ["Roh", "Yuji", ""], ["Hwang", "Seonghyeon", ""], ["Lee", "Dayun", ""], ["Whang", "Steven Euijong", ""]]}, {"id": "2004.03267", "submitter": "Ziming Li", "authors": "Ziming Li, Sungjin Lee, Baolin Peng, Jinchao Li, Julia Kiseleva,\n  Maarten de Rijke, Shahin Shayandeh, Jianfeng Gao", "title": "Guided Dialog Policy Learning without Adversarial Learning in the Loop", "comments": "10 pages", "journal-ref": "Findings of EMNLP 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) methods have emerged as a popular choice for\ntraining an efficient and effective dialogue policy. However, these methods\nsuffer from sparse and unstable reward signals returned by a user simulator\nonly when a dialogue finishes. Besides, the reward signal is manually designed\nby human experts, which requires domain knowledge. Recently, a number of\nadversarial learning methods have been proposed to learn the reward function\ntogether with the dialogue policy. However, to alternatively update the\ndialogue policy and the reward model on the fly, we are limited to\npolicy-gradient-based algorithms, such as REINFORCE and PPO. Moreover, the\nalternating training of a dialogue agent and the reward model can easily get\nstuck in local optima or result in mode collapse. To overcome the listed\nissues, we propose to decompose the adversarial training into two steps. First,\nwe train the discriminator with an auxiliary dialogue generator and then\nincorporate a derived reward model into a common RL method to guide the\ndialogue policy learning. This approach is applicable to both on-policy and\noff-policy RL methods. Based on our extensive experimentation, we can conclude\nthe proposed method: (1) achieves a remarkable task success rate using both\non-policy and off-policy RL methods; and (2) has the potential to transfer\nknowledge from existing domains to a new domain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:03:17 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 20:26:31 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Li", "Ziming", ""], ["Lee", "Sungjin", ""], ["Peng", "Baolin", ""], ["Li", "Jinchao", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""], ["Shayandeh", "Shahin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.03271", "submitter": "Christoph Baur", "authors": "Christoph Baur, Stefan Denner, Benedikt Wiestler, Shadi Albarqouni and\n  Nassir Navab", "title": "Autoencoders for Unsupervised Anomaly Segmentation in Brain MR Images: A\n  Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep unsupervised representation learning has recently led to new approaches\nin the field of Unsupervised Anomaly Detection (UAD) in brain MRI. The main\nprinciple behind these works is to learn a model of normal anatomy by learning\nto compress and recover healthy data. This allows to spot abnormal structures\nfrom erroneous recoveries of compressed, potentially anomalous samples. The\nconcept is of great interest to the medical image analysis community as it i)\nrelieves from the need of vast amounts of manually segmented training data---a\nnecessity for and pitfall of current supervised Deep Learning---and ii)\ntheoretically allows to detect arbitrary, even rare pathologies which\nsupervised approaches might fail to find. To date, the experimental design of\nmost works hinders a valid comparison, because i) they are evaluated against\ndifferent datasets and different pathologies, ii) use different image\nresolutions and iii) different model architectures with varying complexity. The\nintent of this work is to establish comparability among recent methods by\nutilizing a single architecture, a single resolution and the same dataset(s).\nBesides providing a ranking of the methods, we also try to answer questions\nlike i) how many healthy training subjects are needed to model normality and\nii) if the reviewed approaches are also sensitive to domain shift. Further, we\nidentify open challenges and provide suggestions for future community efforts\nand research directions.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:12:07 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:04:04 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Baur", "Christoph", ""], ["Denner", "Stefan", ""], ["Wiestler", "Benedikt", ""], ["Albarqouni", "Shadi", ""], ["Navab", "Nassir", ""]]}, {"id": "2004.03281", "submitter": "Shaiq Munir Malik", "authors": "Shaiq Munir Malik, Mohbat Tharani, and Murtaza Taj", "title": "Teacher-Class Network: A Neural Network Compression Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the problem of the overwhelming size of Deep Neural Networks (DNN)\nseveral compression schemes have been proposed, one of them is teacher-student.\nTeacher-student tries to transfer knowledge from a complex teacher network to a\nsimple student network. In this paper, we propose a novel method called a\nteacher-class network consisting of a single teacher and multiple student\nnetworks (i.e. class of students). Instead of transferring knowledge to one\nstudent only, the proposed method transfers a chunk of knowledge about the\nentire solution to each student. Our students are not trained for\nproblem-specific logits, they are trained to mimic knowledge (dense\nrepresentation) learned by the teacher network. Thus unlike the logits-based\nsingle student approach, the combined knowledge learned by the class of\nstudents can be used to solve other problems as well. These students can be\ndesigned to satisfy a given budget, e.g. for comparative purposes we kept the\ncollective parameters of all the students less than or equivalent to that of a\nsingle student in the teacher-student approach . These small student networks\nare trained independently, making it possible to train and deploy models on\nmemory deficient devices as well as on parallel processing systems such as data\ncenters. The proposed teacher-class architecture is evaluated on several\nbenchmark datasets including MNIST, FashionMNIST, IMDB Movie Reviews and CAMVid\non multiple tasks including classification, sentiment classification and\nsegmentation. Our approach outperforms the state-of-the-art single student\napproach in terms of accuracy as well as computational cost and in many cases\nit achieves an accuracy equivalent to the teacher network while having 10-30\ntimes fewer parameters.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 11:31:20 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 14:50:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Malik", "Shaiq Munir", ""], ["Tharani", "Mohbat", ""], ["Taj", "Murtaza", ""]]}, {"id": "2004.03295", "submitter": "Claudio Lucchese", "authors": "Stefano Calzavara, Claudio Lucchese, Federico Marcuzzi, Salvatore\n  Orlando", "title": "Feature Partitioning for Robust Tree Ensembles and their Certification\n  in Adversarial Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms, however effective, are known to be vulnerable in\nadversarial scenarios where a malicious user may inject manipulated instances.\nIn this work we focus on evasion attacks, where a model is trained in a safe\nenvironment and exposed to attacks at test time. The attacker aims at finding a\nminimal perturbation of a test instance that changes the model outcome.\n  We propose a model-agnostic strategy that builds a robust ensemble by\ntraining its basic models on feature-based partitions of the given dataset. Our\nalgorithm guarantees that the majority of the models in the ensemble cannot be\naffected by the attacker. We experimented the proposed strategy on decision\ntree ensembles, and we also propose an approximate certification method for\ntree ensembles that efficiently assess the minimal accuracy of a forest on a\ngiven dataset avoiding the costly computation of evasion attacks.\n  Experimental evaluation on publicly available datasets shows that proposed\nstrategy outperforms state-of-the-art adversarial learning algorithms against\nevasion attacks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 12:00:40 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Calzavara", "Stefano", ""], ["Lucchese", "Claudio", ""], ["Marcuzzi", "Federico", ""], ["Orlando", "Salvatore", ""]]}, {"id": "2004.03315", "submitter": "Alexander Robey", "authors": "Alexander Robey, Haimin Hu, Lars Lindemann, Hanwen Zhang, Dimos V.\n  Dimarogonas, Stephen Tu, Nikolai Matni", "title": "Learning Control Barrier Functions from Expert Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of imitation and inverse reinforcement learning in\nreplicating expert behavior through optimal control, we propose a learning\nbased approach to safe controller synthesis based on control barrier functions\n(CBFs). We consider the setting of a known nonlinear control affine dynamical\nsystem and assume that we have access to safe trajectories generated by an\nexpert - a practical example of such a setting would be a kinematic model of a\nself-driving vehicle with safe trajectories (e.g., trajectories that avoid\ncollisions with obstacles in the environment) generated by a human driver. We\nthen propose and analyze an optimization-based approach to learning a CBF that\nenjoys provable safety guarantees under suitable Lipschitz smoothness\nassumptions on the underlying dynamical system. A strength of our approach is\nthat it is agnostic to the parameterization used to represent the CBF, assuming\nonly that the Lipschitz constant of such functions can be efficiently bounded.\nFurthermore, if the CBF parameterization is convex, then under mild\nassumptions, so is our learning process. We end with extensive numerical\nevaluations of our results on both planar and realistic examples, using both\nrandom feature and deep neural network parameterizations of the CBF. To the\nbest of our knowledge, these are the first results that learn provably safe\ncontrol barrier functions from data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 12:29:06 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 18:42:44 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 00:02:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Robey", "Alexander", ""], ["Hu", "Haimin", ""], ["Lindemann", "Lars", ""], ["Zhang", "Hanwen", ""], ["Dimarogonas", "Dimos V.", ""], ["Tu", "Stephen", ""], ["Matni", "Nikolai", ""]]}, {"id": "2004.03323", "submitter": "Niklas K\\\"uhl", "authors": "Svenja Laing, Niklas K\\\"uhl", "title": "Comfort-as-a-Service: Designing a User-Oriented Thermal Comfort Artifact\n  for Office Buildings", "comments": null, "journal-ref": "Thirty Ninth International Conference on Information Systems 2018", "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most people spend up to 90 % of their time indoors. However, literature in\nthe field of facility management and related disciplines mostly focus on energy\nand cost saving aspects of buildings. Especially in the area of commercial\nbuildings, only few articles take a user-centric perspective and none of them\nconsiders the subjectivity of thermal comfort. This work addresses this\nresearch gap and aims to optimize individual environmental comfort in open\noffice environments, taking advantage of changes in modern office\ninfrastructure and considering actual user feedback without interfering with\nexisting systems. Based on a Design Science Research approach, we first perform\na user experience testing in an exemplary corporate office building.\nFurthermore, we build a mechanism to gather user feedback on environmental\ncomfort. Based on this, we build a machine learning model including different\nIoT data sources (e.g. building data and weather data) with an average\ncoefficient of determination of 41.5%. Using these insights, we are able to\nsuggest current individual comfort zones within the building and help employees\nto make better informed decisions on where to sit or what to wear, to feel\ncomfortable and work productively. Therefore, we contribute to the body of\nknowledge by proposing a user-centric design within a cross-disciplinary\ncontext on the basis of analytical processes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:06:38 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Laing", "Svenja", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2004.03329", "submitter": "Pengtao Xie", "authors": "Xuehai He, Shu Chen, Zeqian Ju, Xiangyu Dong, Hongchao Fang, Sicheng\n  Wang, Yue Yang, Jiaqi Zeng, Ruisi Zhang, Ruoyu Zhang, Meng Zhou, Penghui Zhu,\n  Pengtao Xie", "title": "MedDialog: Two Large-scale Medical Dialogue Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical dialogue systems are promising in assisting in telemedicine to\nincrease access to healthcare services, improve the quality of patient care,\nand reduce medical costs. To facilitate the research and development of medical\ndialogue systems, we build two large-scale medical dialogue datasets:\nMedDialog-EN and MedDialog-CN. MedDialog-EN is an English dataset containing\n0.3 million conversations between patients and doctors and 0.5 million\nutterances. MedDialog-CN is an Chinese dataset containing 1.1 million\nconversations and 4 million utterances. To our best knowledge,\nMedDialog-(EN,CN) are the largest medical dialogue datasets to date. The\ndataset is available at https://github.com/UCSD-AI4H/Medical-Dialogue-System\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:07:09 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 22:15:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["He", "Xuehai", ""], ["Chen", "Shu", ""], ["Ju", "Zeqian", ""], ["Dong", "Xiangyu", ""], ["Fang", "Hongchao", ""], ["Wang", "Sicheng", ""], ["Yang", "Yue", ""], ["Zeng", "Jiaqi", ""], ["Zhang", "Ruisi", ""], ["Zhang", "Ruoyu", ""], ["Zhou", "Meng", ""], ["Zhu", "Penghui", ""], ["Xie", "Pengtao", ""]]}, {"id": "2004.03332", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "Two-Stage Resampling for Convolutional Neural Network Training in the\n  Imbalanced Colorectal Cancer Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data imbalance remains one of the open challenges in the contemporary machine\nlearning. It is especially prevalent in case of medical data, such as\nhistopathological images. Traditional data-level approaches for dealing with\ndata imbalance are ill-suited for image data: oversampling methods such as\nSMOTE and its derivatives lead to creation of unrealistic synthetic\nobservations, whereas undersampling reduces the amount of available data,\ncritical for successful training of convolutional neural networks. To alleviate\nthe problems associated with over- and undersampling we propose a novel\ntwo-stage resampling methodology, in which we initially use the oversampling\ntechniques in the image space to leverage a large amount of data for training\nof a convolutional neural network, and afterwards apply undersampling in the\nfeature space to fine-tune the last layers of the network. Experiments\nconducted on a colorectal cancer image dataset indicate the usefulness of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:11:17 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 13:44:04 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "2004.03333", "submitter": "Haotong Qin", "authors": "Haotong Qin, Ruihao Gong, Xianglong Liu, Xiao Bai, Jingkuan Song, Nicu\n  Sebe", "title": "Binary Neural Networks: A Survey", "comments": null, "journal-ref": "Pattern Recognition (2020) 107281", "doi": "10.1016/j.patcog.2020.107281", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary neural network, largely saving the storage and computation, serves\nas a promising technique for deploying deep models on resource-limited devices.\nHowever, the binarization inevitably causes severe information loss, and even\nworse, its discontinuity brings difficulty to the optimization of the deep\nnetwork. To address these issues, a variety of algorithms have been proposed,\nand achieved satisfying progress in recent years. In this paper, we present a\ncomprehensive survey of these algorithms, mainly categorized into the native\nsolutions directly conducting binarization, and the optimized ones using\ntechniques like minimizing the quantization error, improving the network loss\nfunction, and reducing the gradient error. We also investigate other practical\naspects of binary neural networks such as the hardware-friendly design and the\ntraining tricks. Then, we give the evaluation and discussions on different\ntasks, including image classification, object detection and semantic\nsegmentation. Finally, the challenges that may be faced in future research are\nprospected.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 16:47:20 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Qin", "Haotong", ""], ["Gong", "Ruihao", ""], ["Liu", "Xianglong", ""], ["Bai", "Xiao", ""], ["Song", "Jingkuan", ""], ["Sebe", "Nicu", ""]]}, {"id": "2004.03335", "submitter": "Chuan-Yung Tsai", "authors": "Zachary Polizzi, Chuan-Yung Tsai", "title": "FusedProp: Towards Efficient Training of Generative Adversarial Networks", "comments": "source code available at https://github.com/zplizzi/fusedprop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are capable of generating strikingly\nrealistic samples but state-of-the-art GANs can be extremely computationally\nexpensive to train. In this paper, we propose the fused propagation (FusedProp)\nalgorithm which can be used to efficiently train the discriminator and the\ngenerator of common GANs simultaneously using only one forward and one backward\npropagation. We show that FusedProp achieves 1.49 times the training speed\ncompared to the conventional training of GANs, although further studies are\nrequired to improve its stability. By reporting our preliminary results and\nopen-sourcing our implementation, we hope to accelerate future research on the\ntraining of GANs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 06:46:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Polizzi", "Zachary", ""], ["Tsai", "Chuan-Yung", ""]]}, {"id": "2004.03336", "submitter": "Ciro Javier Diaz Penedo", "authors": "Ciro Javier Diaz Penedo", "title": "Predict the model of a camera", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we address the problem of predicting the model of a camera based\non the content of their photographs. We use two set of features, one set\nconsist in properties extracted from a Discrete Wavelet Domain (DWD) obtained\nby applying a 4 level Fast Wavelet Decomposition of the images, and a second\nset are Local Binary Patterns (LBP) features from the after filter noise of\nimages. The algorithms used for classification were Logistic regression, K-NN\nand Artificial Neural Networks\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:08:11 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Penedo", "Ciro Javier Diaz", ""]]}, {"id": "2004.03337", "submitter": "Andre G Hochuli", "authors": "Andre G. Hochuli, Alceu S. Britto Jr., Jean P. Barddal, Luiz E. S.\n  Oliveira, Robert Sabourin", "title": "An End-to-End Approach for Recognition of Modern and Historical\n  Handwritten Numeral Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An end-to-end solution for handwritten numeral string recognition is\nproposed, in which the numeral string is considered as composed of objects\nautomatically detected and recognized by a YoLo-based model. The main\ncontribution of this paper is to avoid heuristic-based methods for string\npreprocessing and segmentation, the need for task-oriented classifiers, and\nalso the use of specific constraints related to the string length. A robust\nexperimental protocol based on several numeral string datasets, including one\ncomposed of historical documents, has shown that the proposed method is a\nfeasible end-to-end solution for numeral string recognition. Besides, it\nreduces the complexity of the string recognition task considerably since it\ndrops out classical steps, in special preprocessing, segmentation, and a set of\nclassifiers devoted to strings with a specific length.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 16:51:00 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Hochuli", "Andre G.", ""], ["Britto", "Alceu S.", "Jr."], ["Barddal", "Jean P.", ""], ["Oliveira", "Luiz E. S.", ""], ["Sabourin", "Robert", ""]]}, {"id": "2004.03338", "submitter": "Bo Huang", "authors": "Fenxi Xiao, Jie Zhang, Bo Huang, Xia Wu", "title": "Multiform Fonts-to-Fonts Translation via Style and Content Disentangled\n  Representations of Chinese Character", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper mainly discusses the generation of personalized fonts as the\nproblem of image style transfer. The main purpose of this paper is to design a\nnetwork framework that can extract and recombine the content and style of the\ncharacters. These attempts can be used to synthesize the entire set of fonts\nwith only a small amount of characters. The paper combines various depth\nnetworks such as Convolutional Neural Network, Multi-layer Perceptron and\nResidual Network to find the optimal model to extract the features of the fonts\ncharacter. The result shows that those characters we have generated is very\nclose to real characters, using Structural Similarity index and Peak\nSignal-to-Noise Ratio evaluation criterions.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 04:30:00 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xiao", "Fenxi", ""], ["Zhang", "Jie", ""], ["Huang", "Bo", ""], ["Wu", "Xia", ""]]}, {"id": "2004.03339", "submitter": "Bo Huang", "authors": "Fenxi Xiao, Bo Huang, Xia Wu", "title": "Automatic Generation of Chinese Handwriting via Fonts Style\n  Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and end-to-end deep Chinese font generation system.\nThis system can generate new style fonts by interpolation of latent\nstyle-related embeding variables that could achieve smooth transition between\ndifferent style. Our method is simpler and more effective than other methods,\nwhich will help to improve the font design efficiency\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 23:34:01 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Xiao", "Fenxi", ""], ["Huang", "Bo", ""], ["Wu", "Xia", ""]]}, {"id": "2004.03340", "submitter": "Germ\\'an Kruszewski", "authors": "Germ\\'an Kruszewski, Ionut-Teodor Sorodoc, Tomas Mikolov", "title": "Evaluating Online Continual Learning with CALM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Continual Learning (OCL) studies learning over a continuous data\nstream without observing any single example more than once, a setting that is\ncloser to the experience of humans and systems that must learn \"on-the-wild\".\nYet, commonly available benchmarks are far from these real-world conditions,\nbecause they explicitly signal different tasks, lack latent similarity\nstructure or assume temporal independence between different examples. Here, we\npropose a new benchmark for OCL based on language modelling in which input\nalternates between different languages and domains without any explicit\ndelimitation. Additionally, we propose new metrics to study catastrophic\nforgetting in this setting and evaluate multiple baseline models based on\ncompositions of experts. Finally, we introduce a simple gating technique that\nlearns the latent similarities between different inputs, improving the\nperformance of a Products of Experts model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:17:05 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 12:20:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kruszewski", "Germ\u00e1n", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Mikolov", "Tomas", ""]]}, {"id": "2004.03343", "submitter": "Loick Bonniot", "authors": "Lo\\\"ick Bonniot (WIDE), Christoph Neumann, Fran\\c{c}ois Ta\\\"iani\n  (WIDE)", "title": "DiagNet: towards a generic, Internet-scale root cause analysis solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing problems in Internet-scale services remains particularly difficult\nand costly for both content providers and ISPs. Because the Internet is\ndecentralized, the cause of such problems might lie anywhere between an\nend-user's device and the service datacenters. Further, the set of possible\nproblems and causes is not known in advance, making it impossible in practice\nto train a classifier with all combinations of problems, causes and locations.\nIn this paper, we explore how different machine learning techniques can be used\nfor Internet-scale root cause analysis using measurements taken from end-user\ndevices. We show how to build generic models that (i) are agnostic to the\nunderlying network topology, (ii) do not require to define the full set of\npossible causes during training, and (iii) can be quickly adapted to diagnose\nnew services. Our solution, DiagNet, adapts concepts from image processing\nresearch to handle network and system metrics. We evaluate DiagNet with a\nmulti-cloud deployment of online services with injected faults and emulated\nclients with automated browsers. We demonstrate promising root cause analysis\ncapabilities, with a recall of 73.9% including causes only being introduced at\ninference time.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:21:32 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Bonniot", "Lo\u00efck", "", "WIDE"], ["Neumann", "Christoph", "", "WIDE"], ["Ta\u00efani", "Fran\u00e7ois", "", "WIDE"]]}, {"id": "2004.03357", "submitter": "Chairi Kiourt", "authors": "Chairi Kiourt, George Pavlidis, Stella Markantonatou", "title": "Deep learning approaches in food recognition", "comments": "26 pages, 10 figures, book chapter for Machine Learning Paradigms -\n  Advances in Theory and Applications of Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic image-based food recognition is a particularly challenging task.\nTraditional image analysis approaches have achieved low classification accuracy\nin the past, whereas deep learning approaches enabled the identification of\nfood types and their ingredients. The contents of food dishes are typically\ndeformable objects, usually including complex semantics, which makes the task\nof defining their structure very difficult. Deep learning methods have already\nshown very promising results in such challenges, so this chapter focuses on the\npresentation of some popular approaches and techniques applied in image-based\nfood recognition. The three main lines of solutions, namely the design from\nscratch, the transfer learning and the platform-based approaches, are outlined,\nparticularly for the task at hand, and are tested and compared to reveal the\ninherent strengths and weaknesses. The chapter is complemented with basic\nbackground material, a section devoted to the relevant datasets that are\ncrucial in light of the empirical approaches adopted, and some concluding\nremarks that underline the future directions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 20:22:16 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 08:44:48 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kiourt", "Chairi", ""], ["Pavlidis", "George", ""], ["Markantonatou", "Stella", ""]]}, {"id": "2004.03360", "submitter": "Tan Le", "authors": "Abrar Zahin, Le Thanh Tan, and Rose Qingyang Hu", "title": "A Machine Learning Based Framework for the Smart Healthcare Monitoring", "comments": null, "journal-ref": "2020 Intermountain Engineering, Technology and Computing (IETC)", "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel framework for the smart healthcare system,\nwhere we employ the compressed sensing (CS) and the combination of the\nstate-of-the-art machine learning based denoiser as well as the alternating\ndirection of method of multipliers (ADMM) structure. This integration\nsignificantly simplifies the software implementation for the lowcomplexity\nencoder, thanks to the modular structure of ADMM. Furthermore, we focus on\ndetecting fall down actions from image streams. Thus, teh primary purpose of\nthus study is to reconstruct the image as visibly clear as possible and hence\nit helps the detection step at the trained classifier. For this efficient smart\nhealth monitoring framework, we employ the trained binary convolutional neural\nnetwork (CNN) classifier for the fall-action classifier, because this scheme is\na part of surveillance scenario. In this scenario, we deal with the fallimages,\nthus, we compress, transmit and reconstruct the fallimages. Experimental\nresults demonstrate the impacts of network parameters and the significant\nperformance gain of the proposal compared to traditional methods.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 17:41:28 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zahin", "Abrar", ""], ["Tan", "Le Thanh", ""], ["Hu", "Rose Qingyang", ""]]}, {"id": "2004.03364", "submitter": "S\\'andor K\\'onya Dr.", "authors": "Sandor Konya, Sai Natarajan T R, Hassan Allouch, Kais Abu Nahleh,\n  Omneya Yakout Dogheim, Heinrich Boehm", "title": "Convolutional Neural Networks based automated segmentation and labelling\n  of the lumbar spine X-ray", "comments": "Submitted to Medical & Biological Engineering & Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to investigate the segmentation accuracies of\ndifferent segmentation networks trained on 730 manually annotated lateral\nlumbar spine X-rays. Instance segmentation networks were compared to semantic\nsegmentation networks. The study cohort comprised diseased spines and\npostoperative images with metallic implants. The average mean accuracy and mean\nintersection over union (IoU) was up to 3 percent better for the best\nperforming instance segmentation model, the average pixel accuracy and weighted\nIoU were slightly better for the best performing semantic segmentation model.\nMoreover, the inferences of the instance segmentation models are easier to\nimplement for further processing pipelines in clinical decision support.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 20:15:03 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Konya", "Sandor", ""], ["R", "Sai Natarajan T", ""], ["Allouch", "Hassan", ""], ["Nahleh", "Kais Abu", ""], ["Dogheim", "Omneya Yakout", ""], ["Boehm", "Heinrich", ""]]}, {"id": "2004.03366", "submitter": "David Noever", "authors": "David A. Noever, Sam E. Miller Noever", "title": "Knife and Threat Detectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Despite rapid advances in image-based machine learning, the threat\nidentification of a knife wielding attacker has not garnered substantial\nacademic attention. This relative research gap appears less understandable\ngiven the high knife assault rate (>100,000 annually) and the increasing\navailability of public video surveillance to analyze and forensically document.\nWe present three complementary methods for scoring automated threat\nidentification using multiple knife image datasets, each with the goal of\nnarrowing down possible assault intentions while minimizing misidentifying\nfalse positives and risky false negatives. To alert an observer to the\nknife-wielding threat, we test and deploy classification built around MobileNet\nin a sparse and pruned neural network with a small memory requirement (< 2.2\nmegabytes) and 95% test accuracy. We secondly train a detection algorithm\n(MaskRCNN) to segment the hand from the knife in a single image and assign\nprobable certainty to their relative location. This segmentation accomplishes\nboth localization with bounding boxes but also relative positions to infer\noverhand threats. A final model built on the PoseNet architecture assigns\nanatomical waypoints or skeletal features to narrow the threat characteristics\nand reduce misunderstood intentions. We further identify and supplement\nexisting data gaps that might blind a deployed knife threat detector such as\ncollecting innocuous hand and fist images as important negative training sets.\nWhen automated on commodity hardware and software solutions one original\nresearch contribution is this systematic survey of timely and readily available\nimage-based alerts to task and prioritize crime prevention countermeasures\nprior to a tragic outcome.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 12:41:28 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 14:36:29 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Noever", "David A.", ""], ["Noever", "Sam E. Miller", ""]]}, {"id": "2004.03373", "submitter": "Victor Lorena de Farias Souza", "authors": "Victor L. F. Souza, Adriano L. I. Oliveira, Rafael M. O. Cruz, Robert\n  Sabourin", "title": "Improving BPSO-based feature selection applied to offline WI handwritten\n  signature verification through overfitting control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the presence of overfitting when using Binary\nParticle Swarm Optimization (BPSO) to perform the feature selection in a\ncontext of Handwritten Signature Verification (HSV). SigNet is a state of the\nart Deep CNN model for feature representation in the HSV context and contains\n2048 dimensions. Some of these dimensions may include redundant information in\nthe dissimilarity representation space generated by the dichotomy\ntransformation (DT) used by the writer-independent (WI) approach. The analysis\nis carried out on the GPDS-960 dataset. Experiments demonstrate that the\nproposed method is able to control overfitting during the search for the most\ndiscriminant representation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:42:29 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 11:18:02 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Souza", "Victor L. F.", ""], ["Oliveira", "Adriano L. I.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "2004.03374", "submitter": "Gal Oren", "authors": "Re'em Harel, Matan Rusanovsky, Yehonatan Fridman, Assaf Shimony, Gal\n  Oren", "title": "Complete CVDL Methodology for Investigating Hydrodynamic Instabilities", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.CV cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In fluid dynamics, one of the most important research fields is hydrodynamic\ninstabilities and their evolution in different flow regimes. The investigation\nof said instabilities is concerned with the highly non-linear dynamics.\nCurrently, three main methods are used for understanding of such phenomenon -\nnamely analytical models, experiments and simulations - and all of them are\nprimarily investigated and correlated using human expertise. In this work we\nclaim and demonstrate that a major portion of this research effort could and\nshould be analysed using recent breakthrough advancements in the field of\nComputer Vision with Deep Learning (CVDL, or Deep Computer-Vision).\nSpecifically, we target and evaluate specific state-of-the-art techniques -\nsuch as Image Retrieval, Template Matching, Parameters Regression and\nSpatiotemporal Prediction - for the quantitative and qualitative benefits they\nprovide. In order to do so we focus in this research on one of the most\nrepresentative instabilities, the Rayleigh-Taylor one, simulate its behaviour\nand create an open-sourced state-of-the-art annotated database (RayleAI).\nFinally, we use adjusted experimental results and novel physical loss\nmethodologies to validate the correspondence of the predicted results to actual\nphysical reality to prove the models efficiency. The techniques which were\ndeveloped and proved in this work can be served as essential tools for\nphysicists in the field of hydrodynamics for investigating a variety of\nphysical systems, and also could be used via Transfer Learning to other\ninstabilities research. A part of the techniques can be easily applied on\nalready exist simulation results. All models as well as the data-set that was\ncreated for this work, are publicly available at:\nhttps://github.com/scientific-computing-nrcn/SimulAI.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 13:52:04 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 06:52:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Harel", "Re'em", ""], ["Rusanovsky", "Matan", ""], ["Fridman", "Yehonatan", ""], ["Shimony", "Assaf", ""], ["Oren", "Gal", ""]]}, {"id": "2004.03375", "submitter": "Dario Sitnik", "authors": "Dario Sitnik and Ivica Kopriva", "title": "Robust Self-Supervised Convolutional Neural Network for Subspace\n  Clustering and Classification", "comments": "15 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insufficient capability of existing subspace clustering methods to handle\ndata coming from nonlinear manifolds, data corruptions, and out-of-sample data\nhinders their applicability to address real-world clustering and classification\nproblems. This paper proposes the robust formulation of the self-supervised\nconvolutional subspace clustering network ($S^2$ConvSCN) that incorporates the\nfully connected (FC) layer and, thus, it is capable for handling out-of-sample\ndata by classifying them using a softmax classifier. $S^2$ConvSCN clusters data\ncoming from nonlinear manifolds by learning the linear self-representation\nmodel in the feature space. Robustness to data corruptions is achieved by using\nthe correntropy induced metric (CIM) of the error. Furthermore, the\nblock-diagonal (BD) structure of the representation matrix is enforced\nexplicitly through BD regularization. In a truly unsupervised training\nenvironment, Robust $S^2$ConvSCN outperforms its baseline version by a\nsignificant amount for both seen and unseen data on four well-known datasets.\nArguably, such an ablation study has not been reported before.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:07:58 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Sitnik", "Dario", ""], ["Kopriva", "Ivica", ""]]}, {"id": "2004.03376", "submitter": "Kaveena Persand", "authors": "Kaveena Persand, Andrew Anderson, David Gregg", "title": "Composition of Saliency Metrics for Channel Pruning with a Myopic Oracle", "comments": null, "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)", "doi": "10.1109/SSCI47803.2020.9308157", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation and memory needed for Convolutional Neural Network (CNN)\ninference can be reduced by pruning weights from the trained network. Pruning\nis guided by a pruning saliency, which heuristically approximates the change in\nthe loss function associated with the removal of specific weights. Many pruning\nsignals have been proposed, but the performance of each heuristic depends on\nthe particular trained network. This leaves the data scientist with a difficult\nchoice. When using any one saliency metric for the entire pruning process, we\nrun the risk of the metric assumptions being invalidated, leading to poor\ndecisions being made by the metric. Ideally we could combine the best aspects\nof different saliency metrics. However, despite an extensive literature review,\nwe are unable to find any prior work on composing different saliency metrics.\nThe chief difficulty lies in combining the numerical output of different\nsaliency metrics, which are not directly comparable.\n  We propose a method to compose several primitive pruning saliencies, to\nexploit the cases where each saliency measure does well. Our experiments show\nthat the composition of saliencies avoids many poor pruning choices identified\nby individual saliencies. In most cases our method finds better selections than\neven the best individual pruning saliency.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 11:29:41 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 12:56:50 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Persand", "Kaveena", ""], ["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "2004.03379", "submitter": "Kaijie Xu", "authors": "Kaijie Xu, Witold Pedrycz, Zhiwu Li, and Mengdao Xing", "title": "Granular Computing: An Augmented Scheme of Degranulation Through a\n  Modified Partition Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": "No. CYB-E-2018-06-1082", "categories": "cs.LG cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an important technology in artificial intelligence Granular Computing\n(GrC) has emerged as a new multi-disciplinary paradigm and received much\nattention in recent years. Information granules forming an abstract and\nefficient characterization of large volumes of numeric data have been\nconsidered as the fundamental constructs of GrC. By generating prototypes and\npartition matrix, fuzzy clustering is a commonly encountered way of information\ngranulation. Degranulation involves data reconstruction completed on a basis of\nthe granular representatives. Previous studies have shown that there is a\nrelationship between the reconstruction error and the performance of the\ngranulation process. Typically, the lower the degranulation error is, the\nbetter performance of granulation is. However, the existing methods of\ndegranulation usually cannot restore the original numeric data, which is one of\nthe important reasons behind the occurrence of the reconstruction error. To\nenhance the quality of degranulation, in this study, we develop an augmented\nscheme through modifying the partition matrix. By proposing the augmented\nscheme, we dwell on a novel collection of granulation-degranulation mechanisms.\nIn the constructed approach, the prototypes can be expressed as the product of\nthe dataset matrix and the partition matrix. Then, in the degranulation\nprocess, the reconstructed numeric data can be decomposed into the product of\nthe partition matrix and the matrix of prototypes. Both the granulation and\ndegranulation are regarded as generalized rotation between the data subspace\nand the prototype subspace with the partition matrix and the fuzzification\nfactor. By modifying the partition matrix, the new partition matrix is\nconstructed through a series of matrix operations. We offer a thorough analysis\nof the developed scheme. The experimental results are in agreement with the\nunderlying conceptual framework\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 03:20:09 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xu", "Kaijie", ""], ["Pedrycz", "Witold", ""], ["Li", "Zhiwu", ""], ["Xing", "Mengdao", ""]]}, {"id": "2004.03383", "submitter": "Subhashini Venugopalan", "authors": "Shawn Xu, Subhashini Venugopalan, Mukund Sundararajan", "title": "Attribution in Scale and Space", "comments": "CVPR 2020 camera-ready. Code is available at\n  https://github.com/PAIR-code/saliency", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the attribution problem [28] for deep networks applied to perception\ntasks. For vision tasks, attribution techniques attribute the prediction of a\nnetwork to the pixels of the input image. We propose a new technique called\n\\emph{Blur Integrated Gradients}. This technique has several advantages over\nother methods. First, it can tell at what scale a network recognizes an object.\nIt produces scores in the scale/frequency dimension, that we find captures\ninteresting phenomena. Second, it satisfies the scale-space axioms [14], which\nimply that it employs perturbations that are free of artifact. We therefore\nproduce explanations that are cleaner and consistent with the operation of deep\nnetworks. Third, it eliminates the need for a 'baseline' parameter for\nIntegrated Gradients [31] for perception tasks. This is desirable because the\nchoice of baseline has a significant effect on the explanations. We compare the\nproposed technique against previous techniques and demonstrate application on\nthree tasks: ImageNet object recognition, Diabetic Retinopathy prediction, and\nAudioSet audio event identification.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 17:04:16 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 16:41:12 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Xu", "Shawn", ""], ["Venugopalan", "Subhashini", ""], ["Sundararajan", "Mukund", ""]]}, {"id": "2004.03385", "submitter": "Mat\\'ias  Di Martino", "authors": "J. Matias Di Martino, Fernando Suzacq, Mauricio Delbracio, Qiang Qiu,\n  and Guillermo Sapiro", "title": "Differential 3D Facial Recognition: Adding 3D to Your State-of-the-Art\n  2D Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Active illumination is a prominent complement to enhance 2D face recognition\nand make it more robust, e.g., to spoofing attacks and low-light conditions. In\nthe present work we show that it is possible to adopt active illumination to\nenhance state-of-the-art 2D face recognition approaches with 3D features, while\nbypassing the complicated task of 3D reconstruction. The key idea is to project\nover the test face a high spatial frequency pattern, which allows us to\nsimultaneously recover real 3D information plus a standard 2D facial image.\nTherefore, state-of-the-art 2D face recognition solution can be transparently\napplied, while from the high frequency component of the input image,\ncomplementary 3D facial features are extracted. Experimental results on ND-2006\ndataset show that the proposed ideas can significantly boost face recognition\nperformance and dramatically improve the robustness to spoofing attacks.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:17:14 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Di Martino", "J. Matias", ""], ["Suzacq", "Fernando", ""], ["Delbracio", "Mauricio", ""], ["Qiu", "Qiang", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "2004.03391", "submitter": "Jarek Duda Dr", "authors": "Jarek Duda", "title": "Exploiting context dependence for image compression with upsampling", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image compression with upsampling encodes information to succeedingly\nincrease image resolution, for example by encoding differences in FUIF and JPEG\nXL. It is useful for progressive decoding, also often can improve compression\nratio - both for lossless compression and e.g. DC coefficients of lossy.\nHowever, the currently used solutions rather do not exploit context dependence\nfor encoding of such upscaling information. This article discusses simple\ninexpensive general techniques for this purpose, which allowed to save on\naverage $0.645$ bits/difference (between $0.138$ and $1.489$) for the last\nupscaling for 48 standard $512\\times 512$ grayscale 8 bit images - compared to\nassumption of fixed Laplace distribution. Using least squares linear regression\nof context to predict center of Laplace distribution gave on average $0.393$\nbits/difference savings. The remaining savings were obtained by additionally\npredicting width of this Laplace distribution, also using just the least\nsquares linear regression.\n  For RGB images, optimization of color transform alone gave mean $\\approx\n4.6\\%$ size reduction comparing to standard YCrCb if using fixed transform,\n$\\approx 6.3\\%$ if optimizing transform individually for each image. Then\nfurther mean $\\approx 10\\%$ reduction was obtained if predicting Laplace\nparameters based on context. The presented simple inexpensive general\nmethodology can be also used for different types of data like DCT coefficients\nin lossy image compression.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:37:04 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 12:51:20 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 07:56:31 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "2004.03398", "submitter": "Berthold Reinwald", "authors": "Shivam Srivastava, Prithviraj Sen, Berthold Reinwald", "title": "Forecasting in multivariate irregularly sampled time series with missing\n  values", "comments": "arXiv admin note: text overlap with arXiv:1905.12374 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse and irregularly sampled multivariate time series are common in\nclinical, climate, financial and many other domains. Most recent approaches\nfocus on classification, regression or forecasting tasks on such data. In\nforecasting, it is necessary to not only forecast the right value but also to\nforecast when that value will occur in the irregular time series. In this work,\nwe present an approach to forecast not only the values but also the time at\nwhich they are expected to occur.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 01:49:46 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Srivastava", "Shivam", ""], ["Sen", "Prithviraj", ""], ["Reinwald", "Berthold", ""]]}, {"id": "2004.03399", "submitter": "Karim Hammoudi", "authors": "Karim Hammoudi and Halim Benhabiles and Mahmoud Melkemi and Fadi\n  Dornaika and Ignacio Arganda-Carreras and Dominique Collard and Arnaud\n  Scherpereel", "title": "Deep Learning on Chest X-ray Images to Detect and Evaluate Pneumonia\n  Cases at the Era of COVID-19", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease 2019 (COVID-19) is an infectious disease with first\nsymptoms similar to the flu. COVID-19 appeared first in China and very quickly\nspreads to the rest of the world, causing then the 2019-20 coronavirus\npandemic. In many cases, this disease causes pneumonia. Since pulmonary\ninfections can be observed through radiography images, this paper investigates\ndeep learning methods for automatically analyzing query chest X-ray images with\nthe hope to bring precision tools to health professionals towards screening the\nCOVID-19 and diagnosing confirmed patients. In this context, training datasets,\ndeep learning architectures and analysis strategies have been experimented from\npublicly open sets of chest X-ray images. Tailored deep learning models are\nproposed to detect pneumonia infection cases, notably viral cases. It is\nassumed that viral pneumonia cases detected during an epidemic COVID-19 context\nhave a high probability to presume COVID-19 infections. Moreover, easy-to-apply\nhealth indicators are proposed for estimating infection status and predicting\npatient status from the detected pneumonia cases. Experimental results show\npossibilities of training deep learning models over publicly open sets of chest\nX-ray images towards screening viral pneumonia. Chest X-ray test images of\nCOVID-19 infected patients are successfully diagnosed through detection models\nretained for their performances. The efficiency of proposed health indicators\nis highlighted through simulated scenarios of patients presenting infections\nand health problems by combining real and synthetic health data.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:30:54 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Hammoudi", "Karim", ""], ["Benhabiles", "Halim", ""], ["Melkemi", "Mahmoud", ""], ["Dornaika", "Fadi", ""], ["Arganda-Carreras", "Ignacio", ""], ["Collard", "Dominique", ""], ["Scherpereel", "Arnaud", ""]]}, {"id": "2004.03401", "submitter": "Yang Zheng", "authors": "Yang Zheng, Izzat H. Izzat, Sanling Song", "title": "MNEW: Multi-domain Neighborhood Embedding and Weighting for Sparse Point\n  Clouds Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds have been widely adopted in 3D semantic scene understanding.\nHowever, point clouds for typical tasks such as 3D shape segmentation or indoor\nscenario parsing are much denser than outdoor LiDAR sweeps for the application\nof autonomous driving perception. Due to the spatial property disparity, many\nsuccessful methods designed for dense point clouds behave depreciated\neffectiveness on the sparse data. In this paper, we focus on the semantic\nsegmentation task of sparse outdoor point clouds. We propose a new method\ncalled MNEW, including multi-domain neighborhood embedding, and attention\nweighting based on their geometry distance, feature similarity, and\nneighborhood sparsity. The network architecture inherits PointNet which\ndirectly process point clouds to capture pointwise details and global\nsemantics, and is improved by involving multi-scale local neighborhoods in\nstatic geometry domain and dynamic feature space. The distance/similarity\nattention and sparsity-adapted weighting mechanism of MNEW enable its\ncapability for a wide range of data sparsity distribution. With experiments\nconducted on virtual and real KITTI semantic datasets, MNEW achieves the top\nperformance for sparse point clouds, which is important to the application of\nLiDAR-based automated driving perception.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 18:02:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zheng", "Yang", ""], ["Izzat", "Izzat H.", ""], ["Song", "Sanling", ""]]}, {"id": "2004.03406", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski, Micha{\\l} Wo\\'zniak, Bartosz Krawczyk", "title": "Combined Cleaning and Resampling Algorithm for Multi-Class Imbalanced\n  Data with Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The imbalanced data classification is one of the most crucial tasks facing\nmodern data analysis. Especially when combined with other difficulty factors,\nsuch as the presence of noise, overlapping class distributions, and small\ndisjuncts, data imbalance can significantly impact the classification\nperformance. Furthermore, some of the data difficulty factors are known to\naffect the performance of the existing oversampling strategies, in particular\nSMOTE and its derivatives. This effect is especially pronounced in the\nmulti-class setting, in which the mutual imbalance relationships between the\nclasses complicate even further. Despite that, most of the contemporary\nresearch in the area of data imbalance focuses on the binary classification\nproblems, while their more difficult multi-class counterparts are relatively\nunexplored. In this paper, we propose a novel oversampling technique, a\nMulti-Class Combined Cleaning and Resampling (MC-CCR) algorithm. The proposed\nmethod utilizes an energy-based approach to modeling the regions suitable for\noversampling, less affected by small disjuncts and outliers than SMOTE. It\ncombines it with a simultaneous cleaning operation, the aim of which is to\nreduce the effect of overlapping class distributions on the performance of the\nlearning algorithms. Finally, by incorporating a dedicated strategy of handling\nthe multi-class problems, MC-CCR is less affected by the loss of information\nabout the inter-class relationships than the traditional multi-class\ndecomposition strategies. Based on the results of experimental research carried\nout for many multi-class imbalanced benchmark datasets, the high robust of the\nproposed approach to noise was shown, as well as its high quality compared to\nthe state-of-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:59:35 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Koziarski", "Micha\u0142", ""], ["Wo\u017aniak", "Micha\u0142", ""], ["Krawczyk", "Bartosz", ""]]}, {"id": "2004.03409", "submitter": "Micha{\\l} Koziarski", "authors": "Micha{\\l} Koziarski", "title": "CSMOUTE: Combined Synthetic Oversampling and Undersampling Technique for\n  Imbalanced Data Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel data-level algorithm for handling data\nimbalance in the classification task, Synthetic Majority Undersampling\nTechnique (SMUTE). SMUTE leverages the concept of interpolation of nearby\ninstances, previously introduced in the oversampling setting in SMOTE.\nFurthermore, we combine both in the Combined Synthetic Oversampling and\nUndersampling Technique (CSMOUTE), which integrates SMOTE oversampling with\nSMUTE undersampling. The results of the conducted experimental study\ndemonstrate the usefulness of both the SMUTE and the CSMOUTE algorithms,\nespecially when combined with more complex classifiers, namely MLP and SVM, and\nwhen applied on datasets consisting of a large number of outliers. This leads\nus to a conclusion that the proposed approach shows promise for further\nextensions accommodating local data characteristics, a direction discussed in\nmore detail in the paper.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:03:43 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 13:39:09 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Koziarski", "Micha\u0142", ""]]}, {"id": "2004.03420", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Marco Baroni", "title": "Emergent Language Generalization and Acquisition Speed are not tied to\n  Compositionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies of discrete languages emerging when neural agents communicate to\nsolve a joint task often look for evidence of compositional structure. This\nstems for the expectation that such a structure would allow languages to be\nacquired faster by the agents and enable them to generalize better. We argue\nthat these beneficial properties are only loosely connected to\ncompositionality. In two experiments, we demonstrate that, depending on the\ntask, non-compositional languages might show equal, or better, generalization\nperformance and acquisition speed than compositional ones. Further research in\nthe area should be clearer about what benefits are expected from\ncompositionality, and how the latter would lead to them.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:10:27 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 14:46:24 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Baroni", "Marco", ""]]}, {"id": "2004.03424", "submitter": "Joon Sik Kim", "authors": "Joon Sik Kim, Jiahao Chen, Ameet Talwalkar", "title": "FACT: A Diagnostic for Group Fairness Trade-offs", "comments": "Accepted to International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness, a class of fairness notions that measure how different groups\nof individuals are treated differently according to their protected attributes,\nhas been shown to conflict with one another, often with a necessary cost in\nloss of model's predictive performance. We propose a general diagnostic that\nenables systematic characterization of these trade-offs in group fairness. We\nobserve that the majority of group fairness notions can be expressed via the\nfairness-confusion tensor, which is the confusion matrix split according to the\nprotected attribute values. We frame several optimization problems that\ndirectly optimize both accuracy and fairness objectives over the elements of\nthis tensor, which yield a general perspective for understanding multiple\ntrade-offs including group fairness incompatibilities. It also suggests an\nalternate post-processing method for designing fair classifiers. On synthetic\nand real datasets, we demonstrate the use cases of our diagnostic, particularly\non understanding the trade-off landscape between accuracy and fairness.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:15:51 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 17:55:32 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 17:34:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kim", "Joon Sik", ""], ["Chen", "Jiahao", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2004.03436", "submitter": "Shaoxu Song", "authors": "Aoqian Zhang, Shaoxu Song, Yu Sun, Jianmin Wang", "title": "Learning Individual Models for Imputation (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing numerical values are prevalent, e.g., owing to unreliable sensor\nreading, collection and transmission among heterogeneous sources. Unlike\ncategorized data imputation over a limited domain, the numerical values suffer\nfrom two issues: (1) sparsity problem, the incomplete tuple may not have\nsufficient complete neighbors sharing the same/similar values for imputation,\nowing to the (almost) infinite domain; (2) heterogeneity problem, different\ntuples may not fit the same (regression) model. In this study, enlightened by\nthe conditional dependencies that hold conditionally over certain tuples rather\nthan the whole relation, we propose to learn a regression model individually\nfor each complete tuple together with its neighbors. Our IIM, Imputation via\nIndividual Models, thus no longer relies on sharing similar values among the k\ncomplete neighbors for imputation, but utilizes their regression results by the\naforesaid learned individual (not necessary the same) models. Remarkably, we\nshow that some existing methods are indeed special cases of our IIM, under the\nextreme settings of the number l of learning neighbors considered in individual\nlearning. In this sense, a proper number l of neighbors is essential to learn\nthe individual models (avoid over-fitting or under-fitting). We propose to\nadaptively learn individual models over various number l of neighbors for\ndifferent complete tuples. By devising efficient incremental computation, the\ntime complexity of learning a model reduces from linear to constant.\nExperiments on real data demonstrate that our IIM with adaptive learning\nachieves higher imputation accuracy than the existing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:36:54 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Zhang", "Aoqian", ""], ["Song", "Shaoxu", ""], ["Sun", "Yu", ""], ["Wang", "Jianmin", ""]]}, {"id": "2004.03445", "submitter": "Adriano Koshiyama", "authors": "Adriano Koshiyama, Sebastian Flennerhag, Stefano B. Blumberg, Nick\n  Firoozye and Philip Treleaven", "title": "QuantNet: Transferring Learning Across Systematic Trading Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP q-fin.PM q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic financial trading strategies account for over 80% of trade volume\nin equities and a large chunk of the foreign exchange market. In spite of the\navailability of data from multiple markets, current approaches in trading rely\nmainly on learning trading strategies per individual market. In this paper, we\ntake a step towards developing fully end-to-end global trading strategies that\nleverage systematic trends to produce superior market-specific trading\nstrategies. We introduce QuantNet: an architecture that learns market-agnostic\ntrends and use these to learn superior market-specific trading strategies. Each\nmarket-specific model is composed of an encoder-decoder pair. The encoder\ntransforms market-specific data into an abstract latent representation that is\nprocessed by a global model shared by all markets, while the decoder learns a\nmarket-specific trading strategy based on both local and global information\nfrom the market-specific encoder and the global model. QuantNet uses recent\nadvances in transfer and meta-learning, where market-specific parameters are\nfree to specialize on the problem at hand, whilst market-agnostic parameters\nare driven to capture signals from all markets. By integrating over\nidiosyncratic market data we can learn general transferable dynamics, avoiding\nthe problem of overfitting to produce strategies with superior returns. We\nevaluate QuantNet on historical data across 3103 assets in 58 global equity\nmarkets. Against the top performing baseline, QuantNet yielded 51% higher\nSharpe and 69% Calmar ratios. In addition we show the benefits of our approach\nover the non-transfer learning variant, with improvements of 15% and 41% in\nSharpe and Calmar ratios. Code available in appendix.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:48:20 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:46:25 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Koshiyama", "Adriano", ""], ["Flennerhag", "Sebastian", ""], ["Blumberg", "Stefano B.", ""], ["Firoozye", "Nick", ""], ["Treleaven", "Philip", ""]]}, {"id": "2004.03449", "submitter": "Farzan Erlik Nowruzi", "authors": "Farzan Erlik Nowruzi, Dhanvin Kolhatkar, Prince Kapoor, Fahed Al\n  Hassanat, Elnaz Jahani Heravi, Robert Laganiere, Julien Rebut, Waqas Malik", "title": "Deep Open Space Segmentation using Automotive Radar", "comments": "IEEE MTT-S International Conference on Microwaves for Intelligent\n  Mobility (ICMIM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose the use of radar with advanced deep segmentation\nmodels to identify open space in parking scenarios. A publically available\ndataset of radar observations called SCORP was collected. Deep models are\nevaluated with various radar input representations. Our proposed approach\nachieves low memory usage and real-time processing speeds, and is thus very\nwell suited for embedded deployment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 14:49:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Nowruzi", "Farzan Erlik", ""], ["Kolhatkar", "Dhanvin", ""], ["Kapoor", "Prince", ""], ["Hassanat", "Fahed Al", ""], ["Heravi", "Elnaz Jahani", ""], ["Laganiere", "Robert", ""], ["Rebut", "Julien", ""], ["Malik", "Waqas", ""]]}, {"id": "2004.03452", "submitter": "Jason Stock", "authors": "Jason Stock, Andy Dolan, and Tom Cavey", "title": "Strategies for Robust Image Classification", "comments": "15 pages, and 39 figure (with Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we evaluate the impact of digitally altered images on the\nperformance of artificial neural networks. We explore factors that negatively\naffect the ability of an image classification model to produce consistent and\naccurate results. A model's ability to classify is negatively influenced by\nalterations to images as a result of digital abnormalities or changes in the\nphysical environment. The focus of this paper is to discover and replicate\nscenarios that modify the appearance of an image and evaluate them on\nstate-of-the-art machine learning models. Our contributions present various\ntraining techniques that enhance a model's ability to generalize and improve\nrobustness against these alterations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 21:22:39 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 16:50:35 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Stock", "Jason", ""], ["Dolan", "Andy", ""], ["Cavey", "Tom", ""]]}, {"id": "2004.03455", "submitter": "Francesco Sovrano", "authors": "Francesco Sovrano, Monica Palmirani, Fabio Vitali", "title": "Deep Learning Based Multi-Label Text Classification of UNGA Resolutions", "comments": "10 pages, 10 figures, accepted paper at ICEGOV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this research is to produce a useful software for United\nNations (UN), that could help to speed up the process of qualifying the UN\ndocuments following the Sustainable Development Goals (SDGs) in order to\nmonitor the progresses at the world level to fight poverty, discrimination,\nclimate changes. In fact human labeling of UN documents would be a daunting\ntask given the size of the impacted corpus. Thus, automatic labeling must be\nadopted at least as a first step of a multi-phase process to reduce the overall\neffort of cataloguing and classifying. Deep Learning (DL) is nowadays one of\nthe most powerful tools for state-of-the-art (SOTA) AI for this task, but very\noften it comes with the cost of an expensive and error-prone preparation of a\ntraining-set. In the case of multi-label text classification of domain-specific\ntext it seems that we cannot effectively adopt DL without a big-enough\ndomain-specific training-set. In this paper, we show that this is not always\ntrue. In fact we propose a novel method that is able, through statistics like\nTF-IDF, to exploit pre-trained SOTA DL models (such as the Universal Sentence\nEncoder) without any need for traditional transfer learning or any other\nexpensive training procedure. We show the effectiveness of our method in a\nlegal context, by classifying UN Resolutions according to their most related\nSDGs.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:54:38 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Sovrano", "Francesco", ""], ["Palmirani", "Monica", ""], ["Vitali", "Fabio", ""]]}, {"id": "2004.03456", "submitter": "Jefferson Oliva PhD", "authors": "Jefferson Tales Oliva and Jo\\~ao Lu\\'is Garcia Rosa", "title": "Binary and Multiclass Classifiers based on Multitaper Spectral Features\n  for Epilepsy Detection", "comments": "19 pages, 6 figures, 10 tables. Obs.: in the text, English editing is\n  required. A new version of this text will be available once we have completed\n  their review", "journal-ref": null, "doi": "10.1016/j.bspc.2021.102469", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is one of the most common neurological disorders that can be\ndiagnosed through electroencephalogram (EEG), in which the following epileptic\nevents can be observed: pre-ictal, ictal, post-ictal, and interictal. In this\npaper, we present a novel method for epilepsy detection into two\ndifferentiation contexts: binary and multiclass classification. For feature\nextraction, a total of 105 measures were extracted from power spectrum,\nspectrogram, and bispectrogram. For classifier building, eight different\nmachine learning algorithms were used. Our method was applied in a widely used\nEEG database. As a result, random forest and backpropagation based on\nmultilayer perceptron algorithms reached the highest accuracy for binary\n(98.75%) and multiclass (96.25%) classification problems, respectively.\nSubsequently, the statistical tests did not find a model that would achieve a\nbetter performance than the other classifiers. In the evaluation based on\nconfusion matrices, it was also not possible to identify a classifier that\nstands out in relation to other models for EEG classification. Even so, our\nresults are promising and competitive with the findings in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:12:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Oliva", "Jefferson Tales", ""], ["Rosa", "Jo\u00e3o Lu\u00eds Garcia", ""]]}, {"id": "2004.03459", "submitter": "Ankit Dhall", "authors": "Ankit Dhall, Anastasia Makarova, Octavian Ganea, Dario Pavllo, Michael\n  Greeff, Andreas Krause", "title": "Hierarchical Image Classification using Entailment Cone Embeddings", "comments": "Accepted in the CVPR 2020 Workshop on Differential Geometry in\n  Computer Vision and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has been studied extensively, but there has been limited\nwork in using unconventional, external guidance other than traditional\nimage-label pairs for training. We present a set of methods for leveraging\ninformation about the semantic hierarchy embedded in class labels. We first\ninject label-hierarchy knowledge into an arbitrary CNN-based classifier and\nempirically show that availability of such external semantic information in\nconjunction with the visual semantics from images boosts overall performance.\nTaking a step further in this direction, we model more explicitly the\nlabel-label and label-image interactions using order-preserving embeddings\ngoverned by both Euclidean and hyperbolic geometries, prevalent in natural\nlanguage, and tailor them to hierarchical image classification and\nrepresentation learning. We empirically validate all the models on the\nhierarchical ETHEC dataset.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:22:02 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 12:56:07 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dhall", "Ankit", ""], ["Makarova", "Anastasia", ""], ["Ganea", "Octavian", ""], ["Pavllo", "Dario", ""], ["Greeff", "Michael", ""], ["Krause", "Andreas", ""]]}, {"id": "2004.03461", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Lukas Stankevi\\v{c}ius and Mantas Luko\\v{s}evi\\v{c}ius", "title": "Testing pre-trained Transformer models for Lithuanian news clustering", "comments": "Submission accepted at https://ivus.ktu.edu/", "journal-ref": "Proceedings of the Information Society and University Studies\n  2020, pp. 46-53, vol. 2698, CEUR, Kaunas, 2020, ISSN: 1613-0073", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent introduction of Transformer deep learning architecture made\nbreakthroughs in various natural language processing tasks. However,\nnon-English languages could not leverage such new opportunities with the\nEnglish text pre-trained models. This changed with research focusing on\nmultilingual models, where less-spoken languages are the main beneficiaries. We\ncompare pre-trained multilingual BERT, XLM-R, and older learned text\nrepresentation methods as encodings for the task of Lithuanian news clustering.\nOur results indicate that publicly available pre-trained multilingual\nTransformer models can be fine-tuned to surpass word vectors but still score\nmuch lower than specially trained doc2vec embeddings.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 14:41:54 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Stankevi\u010dius", "Lukas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""]]}, {"id": "2004.03466", "submitter": "Shuhang Wang", "authors": "Shuhang Wang, Szu-Yeu Hu, Eugene Cheah, Xiaohong Wang, Jingchao Wang,\n  Lei Chen, Masoud Baikpour, Arinc Ozturk, Qian Li, Shinn-Huey Chou, Constance\n  D. Lehman, Viksit Kumar, Anthony Samir", "title": "U-Net Using Stacked Dilated Convolutions for Medical Image Segmentation", "comments": "8 pages MICCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel U-Net variant using stacked dilated convolutions\nfor medical image segmentation (SDU-Net). SDU-Net adopts the architecture of\nvanilla U-Net with modifications in the encoder and decoder operations (an\noperation indicates all the processing for feature maps of the same\nresolution). Unlike vanilla U-Net which incorporates two standard convolutions\nin each encoder/decoder operation, SDU-Net uses one standard convolution\nfollowed by multiple dilated convolutions and concatenates all dilated\nconvolution outputs as input to the next operation. Experiments showed that\nSDU-Net outperformed vanilla U-Net, attention U-Net (AttU-Net), and recurrent\nresidual U-Net (R2U-Net) in all four tested segmentation tasks while using\nparameters around 40% of vanilla U-Net's, 17% of AttU-Net's, and 15% of\nR2U-Net's.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:06:20 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 13:27:16 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Wang", "Shuhang", ""], ["Hu", "Szu-Yeu", ""], ["Cheah", "Eugene", ""], ["Wang", "Xiaohong", ""], ["Wang", "Jingchao", ""], ["Chen", "Lei", ""], ["Baikpour", "Masoud", ""], ["Ozturk", "Arinc", ""], ["Li", "Qian", ""], ["Chou", "Shinn-Huey", ""], ["Lehman", "Constance D.", ""], ["Kumar", "Viksit", ""], ["Samir", "Anthony", ""]]}, {"id": "2004.03468", "submitter": "Ivan Matvienko", "authors": "Ivan Matvienko, Mikhail Gasanov, Anna Petrovskaia, Raghavendra Belur\n  Jana, Maria Pukalchik, Ivan Oseledets", "title": "Bayesian aggregation improves traditional single image crop\n  classification approaches", "comments": "Paper presented at the ICLR 2020 Workshop on Computer Vision for\n  Agriculture (CV4A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) methods and neural networks (NN) are widely implemented\nfor crop types recognition and classification based on satellite images.\nHowever, most of these studies use several multi-temporal images which could be\ninapplicable for cloudy regions. We present a comparison between the classical\nML approaches and U-Net NN for classifying crops with a single satellite image.\nThe results show the advantages of using field-wise classification over\npixel-wise approach. We first used a Bayesian aggregation for field-wise\nclassification and improved on 1.5% results between majority voting\naggregation. The best result for single satellite image crop classification is\nachieved for gradient boosting with an overall accuracy of 77.4% and macro\nF1-score 0.66.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:14:03 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Matvienko", "Ivan", ""], ["Gasanov", "Mikhail", ""], ["Petrovskaia", "Anna", ""], ["Jana", "Raghavendra Belur", ""], ["Pukalchik", "Maria", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2004.03473", "submitter": "Emmanouil Antonios Platanios", "authors": "Emmanouil Antonios Platanios and Maruan Al-Shedivat and Eric Xing and\n  Tom Mitchell", "title": "Learning from Imperfect Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning systems today are trained on large amounts of\nhuman-annotated data. Data annotation tasks that require a high level of\ncompetency make data acquisition expensive, while the resulting labels are\noften subjective, inconsistent, and may contain a variety of human biases. To\nimprove the data quality, practitioners often need to collect multiple\nannotations per example and aggregate them before training models. Such a\nmulti-stage approach results in redundant annotations and may often produce\nimperfect \"ground truth\" that may limit the potential of training accurate\nmachine learning models. We propose a new end-to-end framework that enables us\nto: (i) merge the aggregation step with model training, thus allowing deep\nlearning systems to learn to predict ground truth estimates directly from the\navailable data, and (ii) model difficulties of examples and learn\nrepresentations of the annotators that allow us to estimate and take into\naccount their competencies. Our approach is general and has many applications,\nincluding training more accurate models on crowdsourced data, ensemble\nlearning, as well as classifier accuracy estimation from unlabeled data. We\nconduct an extensive experimental evaluation of our method on 5 crowdsourcing\ndatasets of varied difficulty and show accuracy gains of up to 25% over the\ncurrent state-of-the-art approaches for aggregating annotations, as well as\nsignificant reductions in the required annotation redundancy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:21:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Platanios", "Emmanouil Antonios", ""], ["Al-Shedivat", "Maruan", ""], ["Xing", "Eric", ""], ["Mitchell", "Tom", ""]]}, {"id": "2004.03484", "submitter": "Soham Parikh", "authors": "Soham Parikh, Quaizar Vohra, Mitul Tiwari", "title": "Automated Utterance Generation", "comments": "AAAI/IAAI-20, Emerging Application Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational AI assistants are becoming popular and question-answering is\nan important part of any conversational assistant. Using relevant utterances as\nfeatures in question-answering has shown to improve both the precision and\nrecall for retrieving the right answer by a conversational assistant. Hence,\nutterance generation has become an important problem with the goal of\ngenerating relevant utterances (sentences or phrases) from a knowledge base\narticle that consists of a title and a description. However, generating good\nutterances usually requires a lot of manual effort, creating the need for an\nautomated utterance generation. In this paper, we propose an utterance\ngeneration system which 1) uses extractive summarization to extract important\nsentences from the description, 2) uses multiple paraphrasing techniques to\ngenerate a diverse set of paraphrases of the title and summary sentences, and\n3) selects good candidate paraphrases with the help of a novel candidate\nselection algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:35:54 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 01:27:09 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Parikh", "Soham", ""], ["Vohra", "Quaizar", ""], ["Tiwari", "Mitul", ""]]}, {"id": "2004.03497", "submitter": "Ali Madani", "authors": "Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata\n  Anand, Raphael R. Eguchi, Po-Ssu Huang, Richard Socher", "title": "ProGen: Language Modeling for Protein Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative modeling for protein engineering is key to solving fundamental\nproblems in synthetic biology, medicine, and material science. We pose protein\nengineering as an unsupervised sequence generation problem in order to leverage\nthe exponentially growing set of proteins that lack costly, structural\nannotations. We train a 1.2B-parameter language model, ProGen, on ~280M protein\nsequences conditioned on taxonomic and keyword tags such as molecular function\nand cellular component. This provides ProGen with an unprecedented range of\nevolutionary sequence diversity and allows it to generate with fine-grained\ncontrol as demonstrated by metrics based on primary sequence similarity,\nsecondary structure accuracy, and conformational energy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 04:27:16 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Madani", "Ali", ""], ["McCann", "Bryan", ""], ["Naik", "Nikhil", ""], ["Keskar", "Nitish Shirish", ""], ["Anand", "Namrata", ""], ["Eguchi", "Raphael R.", ""], ["Huang", "Po-Ssu", ""], ["Socher", "Richard", ""]]}, {"id": "2004.03499", "submitter": "Benjamin Van NIekerk", "authors": "Benjamin van Niekerk, Andreas Damianou, Benjamin Rosman", "title": "Online Constrained Model-based Reinforcement Learning", "comments": "Conf. Uncertainty in Artificial Intelligence (UAI). 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying reinforcement learning to robotic systems poses a number of\nchallenging problems. A key requirement is the ability to handle continuous\nstate and action spaces while remaining within a limited time and resource\nbudget. Additionally, for safe operation, the system must make robust decisions\nunder hard constraints. To address these challenges, we propose a model based\napproach that combines Gaussian Process regression and Receding Horizon\nControl. Using sparse spectrum Gaussian Processes, we extend previous work by\nupdating the dynamics model incrementally from a stream of sensory data. This\nresults in an agent that can learn and plan in real-time under non-linear\nconstraints. We test our approach on a cart pole swing-up environment and\ndemonstrate the benefits of online learning on an autonomous racing task. The\nenvironment's dynamics are learned from limited training data and can be reused\nin new task instances without retraining.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:51:34 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["van Niekerk", "Benjamin", ""], ["Damianou", "Andreas", ""], ["Rosman", "Benjamin", ""]]}, {"id": "2004.03500", "submitter": "Francisco Maria Calisto", "authors": "Francisco Maria Calisto, Nuno Jardim Nunes, Jacinto Carlos Nascimento", "title": "BreastScreening: On the Use of Multi-Modality in Medical Imaging\n  Diagnosis", "comments": "AVI 2020 Short Papers, 5 pages, 2 figures, for associated files, see\n  https://github.com/MIMBCD-UI/avi-2020-short-paper", "journal-ref": null, "doi": "10.1145/3399715.3399744", "report-no": null, "categories": "cs.HC cs.LG cs.SE eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper describes the field research, design and comparative deployment of\na multimodal medical imaging user interface for breast screening. The main\ncontributions described here are threefold: 1) The design of an advanced visual\ninterface for multimodal diagnosis of breast cancer (BreastScreening); 2)\nInsights from the field comparison of single vs multimodality screening of\nbreast cancer diagnosis with 31 clinicians and 566 images, and 3) The\nvisualization of the two main types of breast lesions in the following image\nmodalities: (i) MammoGraphy (MG) in both Craniocaudal (CC) and Mediolateral\noblique (MLO) views; (ii) UltraSound (US); and (iii) Magnetic Resonance Imaging\n(MRI). We summarize our work with recommendations from the radiologists for\nguiding the future design of medical imaging interfaces.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 15:53:26 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 14:38:48 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Calisto", "Francisco Maria", ""], ["Nunes", "Nuno Jardim", ""], ["Nascimento", "Jacinto Carlos", ""]]}, {"id": "2004.03512", "submitter": "Robert Rehr", "authors": "Robert Rehr, Timo Gerkmann", "title": "SNR-Based Features and Diverse Training Data for Robust DNN-Based Speech\n  Enhancement", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing,\n  Vol. 29, 2021. (c) 2021 IEEE", "doi": "10.1109/TASLP.2021.3082702", "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the generalization of deep neural network (DNN)\nbased speech enhancement to unseen noise conditions for the case that training\ndata is limited in size and diversity. To gain more insights, we analyze the\ngeneralization with respect to (1) the size and diversity of the training data,\n(2) different network architectures, and (3) the chosen features. To address\n(1), we train networks on the Hu noise corpus (limited size), the CHiME 3 noise\ncorpus (limited diversity) and also propose a large and diverse dataset\ncollected based on freely available sounds. To address (2), we compare a\nfully-connected feed-forward and a long short-term memory (LSTM) architecture.\nTo address (3), we compare three input features, namely logarithmized noisy\nperiodograms, noise aware training (NAT) and the proposed signal-to-noise ratio\n(SNR) based noise aware training (SNR-NAT). We confirm that rich training data\nand improved network architectures help DNNs to generalize. Furthermore, we\nshow via experimental results and an analysis using t-distributed stochastic\nneighbor embedding (t-SNE) that the proposed SNR-NAT features yield robust and\nlevel independent results in unseen noise even with simple network\narchitectures and when trained on only small datasets, which is the key\ncontribution of this paper.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 16:09:54 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 14:04:40 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Rehr", "Robert", ""], ["Gerkmann", "Timo", ""]]}, {"id": "2004.03515", "submitter": "Lev Reyzin", "authors": "Benjamin Fish, Lev Reyzin", "title": "On the Complexity of Learning from Label Proportions", "comments": "this is an extended and corrected version of an IJCAI 2017 paper, 13\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of learning with label proportions, which we call LLP\nlearning, the training data is unlabeled, and only the proportions of examples\nreceiving each label are given. The goal is to learn a hypothesis that predicts\nthe proportions of labels on the distribution underlying the sample. This model\nof learning is applicable to a wide variety of settings, including predicting\nthe number of votes for candidates in political elections from polls.\n  In this paper, we formally define this class and resolve foundational\nquestions regarding the computational complexity of LLP and characterize its\nrelationship to PAC learning. Among our results, we show, perhaps surprisingly,\nthat for finite VC classes what can be efficiently LLP learned is a strict\nsubset of what can be leaned efficiently in PAC, under standard complexity\nassumptions. We also show that there exist classes of functions whose\nlearnability in LLP is independent of ZFC, the standard set theoretic axioms.\nThis implies that LLP learning cannot be easily characterized (like PAC by VC\ndimension).\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 16:15:22 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Fish", "Benjamin", ""], ["Reyzin", "Lev", ""]]}, {"id": "2004.03519", "submitter": "Lavender Yao Jiang", "authors": "Mark Cheung, John Shi, Lavender Yao Jiang, Oren Wright, Jos\\'e M.F.\n  Moura", "title": "Pooling in Graph Convolutional Neural Networks", "comments": "5 pages, 2 figures, 2019 Asilomar Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional neural networks (GCNNs) are a powerful extension of deep\nlearning techniques to graph-structured data problems. We empirically evaluate\nseveral pooling methods for GCNNs, and combinations of those graph pooling\nmethods with three different architectures: GCN, TAGCN, and GraphSAGE. We\nconfirm that graph pooling, especially DiffPool, improves classification\naccuracy on popular graph classification datasets and find that, on average,\nTAGCN achieves comparable or better accuracy than GCN and GraphSAGE,\nparticularly for datasets with larger and sparser graph structures.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 16:19:52 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Cheung", "Mark", ""], ["Shi", "John", ""], ["Jiang", "Lavender Yao", ""], ["Wright", "Oren", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2004.03553", "submitter": "Lewis Smith", "authors": "Lewis Smith and Lisa Schut and Yarin Gal and Mark van der Wilk", "title": "Capsule Networks -- A Probabilistic Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Capsule' models try to explicitly represent the poses of objects, enforcing\na linear relationship between an object's pose and that of its constituent\nparts. This modelling assumption should lead to robustness to viewpoint changes\nsince the sub-object/super-object relationships are invariant to the poses of\nthe object. We describe a probabilistic generative model which encodes such\ncapsule assumptions, clearly separating the generative parts of the model from\nthe inference mechanisms. With a variational bound we explore the properties of\nthe generative model independently of the approximate inference scheme, and\ngain insights into failures of the capsule assumptions and inference\namortisation. We experimentally demonstrate the applicability of our unified\nobjective, and demonstrate the use of test time optimisation to solve problems\ninherent to amortised inference in our model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:26:11 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 15:00:04 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 10:04:41 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Smith", "Lewis", ""], ["Schut", "Lisa", ""], ["Gal", "Yarin", ""], ["van der Wilk", "Mark", ""]]}, {"id": "2004.03561", "submitter": "Changmao Li", "authors": "Changmao Li, Jinho D. Choi", "title": "Transformers to Learn Hierarchical Contexts in Multiparty Dialogue for\n  Span-based Question Answering", "comments": "Accepted by the Annual Conference of the Association for\n  Computational Linguistics, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to transformers that learns hierarchical\nrepresentations in multiparty dialogue. First, three language modeling tasks\nare used to pre-train the transformers, token- and utterance-level language\nmodeling and utterance order prediction, that learn both token and utterance\nembeddings for better understanding in dialogue contexts. Then, multi-task\nlearning between the utterance prediction and the token span prediction is\napplied to fine-tune for span-based question answering (QA). Our approach is\nevaluated on the FriendsQA dataset and shows improvements of 3.8% and 1.4% over\nthe two state-of-the-art transformer models, BERT and RoBERTa, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:36:33 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 04:35:45 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Li", "Changmao", ""], ["Choi", "Jinho D.", ""]]}, {"id": "2004.03586", "submitter": "Jean-Pierre Briot", "authors": "Jean-Pierre Briot", "title": "From Artificial Neural Networks to Deep Learning for Music Generation --\n  History, Concepts and Trends", "comments": "To appear in the Special Issue on Art, Sound and Design in the Neural\n  Computing and Applications Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.MM cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current wave of deep learning (the hyper-vitamined return of artificial\nneural networks) applies not only to traditional statistical machine learning\ntasks: prediction and classification (e.g., for weather prediction and pattern\nrecognition), but has already conquered other areas, such as translation. A\ngrowing area of application is the generation of creative content, notably the\ncase of music, the topic of this paper. The motivation is in using the capacity\nof modern deep learning techniques to automatically learn musical styles from\narbitrary musical corpora and then to generate musical samples from the\nestimated distribution, with some degree of control over the generation. This\npaper provides a tutorial on music generation based on deep learning\ntechniques. After a short introduction to the topic illustrated by a recent\nexemple, the paper analyzes some early works from the late 1980s using\nartificial neural networks for music generation and how their pioneering\ncontributions have prefigured current techniques. Then, we introduce some\nconceptual framework to analyze the various concepts and dimensions involved.\nVarious examples of recent systems are introduced and analyzed to illustrate\nthe variety of concerns and of techniques.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:33:56 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 22:33:16 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Briot", "Jean-Pierre", ""]]}, {"id": "2004.03589", "submitter": "Piji Li", "authors": "Piji Li, Lidong Bing, Zhongyu Wei, Wai Lam", "title": "Salience Estimation with Multi-Attention Learning for Abstractive Text\n  Summarization", "comments": "11 pages, @CUHK. arXiv admin note: text overlap with\n  arXiv:1803.11070, arXiv:1708.00625", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism plays a dominant role in the sequence generation models\nand has been used to improve the performance of machine translation and\nabstractive text summarization. Different from neural machine translation, in\nthe task of text summarization, salience estimation for words, phrases or\nsentences is a critical component, since the output summary is a distillation\nof the input text. Although the typical attention mechanism can conduct text\nfragment selection from the input text conditioned on the decoder states, there\nis still a gap to conduct direct and effective salience detection. To bring\nback direct salience estimation for summarization with neural networks, we\npropose a Multi-Attention Learning framework which contains two new attention\nlearning components for salience estimation: supervised attention learning and\nunsupervised attention learning. We regard the attention weights as the\nsalience information, which means that the semantic units with large attention\nvalue will be more important. The context information obtained based on the\nestimated salience is incorporated with the typical attention mechanism in the\ndecoder to conduct summary generation. Extensive experiments on some benchmark\ndatasets in different languages demonstrate the effectiveness of the proposed\nframework for the task of abstractive summarization.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 02:38:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Piji", ""], ["Bing", "Lidong", ""], ["Wei", "Zhongyu", ""], ["Lam", "Wai", ""]]}, {"id": "2004.03590", "submitter": "Ke Li", "authors": "Ke Li, Shichong Peng, Tianhao Zhang, Jitendra Malik", "title": "Multimodal Image Synthesis with Conditional Implicit Maximum Likelihood\n  Estimation", "comments": "To appear in International Journal of Computer Vision (IJCV). arXiv\n  admin note: text overlap with arXiv:1811.12373", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in computer vision and graphics fall within the framework of\nconditional image synthesis. In recent years, generative adversarial nets\n(GANs) have delivered impressive advances in quality of synthesized images.\nHowever, it remains a challenge to generate both diverse and plausible images\nfor the same input, due to the problem of mode collapse. In this paper, we\ndevelop a new generic multimodal conditional image synthesis method based on\nImplicit Maximum Likelihood Estimation (IMLE) and demonstrate improved\nmultimodal image synthesis performance on two tasks, single image\nsuper-resolution and image synthesis from scene layouts. We make our\nimplementation publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 03:06:55 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Ke", ""], ["Peng", "Shichong", ""], ["Zhang", "Tianhao", ""], ["Malik", "Jitendra", ""]]}, {"id": "2004.03623", "submitter": "Kamal Gupta", "authors": "Kamal Gupta, Saurabh Singh, Abhinav Shrivastava", "title": "PatchVAE: Learning Local Latent Codes for Recognition", "comments": "To appear at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised representation learning holds the promise of exploiting large\namounts of unlabeled data to learn general representations. A promising\ntechnique for unsupervised learning is the framework of Variational\nAuto-encoders (VAEs). However, unsupervised representations learned by VAEs are\nsignificantly outperformed by those learned by supervised learning for\nrecognition. Our hypothesis is that to learn useful representations for\nrecognition the model needs to be encouraged to learn about repeating and\nconsistent patterns in data. Drawing inspiration from the mid-level\nrepresentation discovery work, we propose PatchVAE, that reasons about images\nat patch level. Our key contribution is a bottleneck formulation that\nencourages mid-level style representations in the VAE framework. Our\nexperiments demonstrate that representations learned by our method perform much\nbetter on the recognition tasks compared to those learned by vanilla VAEs.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:01:26 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Gupta", "Kamal", ""], ["Singh", "Saurabh", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2004.03624", "submitter": "Ajna Ram", "authors": "Ajna Ram, Constantino Carlos Reyes-Aldasoro", "title": "The relationship between Fully Connected Layers and number of classes\n  for the analysis of retinal images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper experiments with the number of fully-connected layers in a deep\nconvolutional neural network as applied to the classification of fundus retinal\nimages. The images analysed corresponded to the ODIR 2019 (Peking University\nInternational Competition on Ocular Disease Intelligent Recognition) [9], which\nincluded images of various eye diseases (cataract, glaucoma, myopia, diabetic\nretinopathy, age-related macular degeneration (AMD), hypertension) as well as\nnormal cases. This work focused on the classification of Normal, Cataract, AMD\nand Myopia. The feature extraction (convolutional) part of the neural network\nis kept the same while the feature mapping (linear) part of the network is\nchanged. Different data sets are also explored on these neural nets. Each data\nset differs from another by the number of classes it has. This paper hence aims\nto find the relationship between number of classes and number of\nfully-connected layers. It was found out that the effect of increasing the\nnumber of fully-connected layers of a neural networks depends on the type of\ndata set being used. For simple, linearly separable data sets, addition of\nfully-connected layer is something that should be explored and that could\nresult in better training accuracy, but a direct correlation was not found.\nHowever as complexity of the data set goes up(more overlapping classes),\nincreasing the number of fully-connected layers causes the neural network to\nstop learning. This phenomenon happens quicker the more complex the data set\nis.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:03:02 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 15:50:05 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ram", "Ajna", ""], ["Reyes-Aldasoro", "Constantino Carlos", ""]]}, {"id": "2004.03636", "submitter": "Jun Chen", "authors": "Jun Chen, Robert Hoehndorf, Mohamed Elhoseiny and Xiangliang Zhang", "title": "Efficient long-distance relation extraction with DG-SpanBERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In natural language processing, relation extraction seeks to rationally\nunderstand unstructured text. Here, we propose a novel SpanBERT-based graph\nconvolutional network (DG-SpanBERT) that extracts semantic features from a raw\nsentence using the pre-trained language model SpanBERT and a graph\nconvolutional network to pool latent features. Our DG-SpanBERT model inherits\nthe advantage of SpanBERT on learning rich lexical features from large-scale\ncorpus. It also has the ability to capture long-range relations between\nentities due to the usage of GCN on dependency tree. The experimental results\nshow that our model outperforms other existing dependency-based and\nsequence-based models and achieves a state-of-the-art performance on the TACRED\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:21:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Chen", "Jun", ""], ["Hoehndorf", "Robert", ""], ["Elhoseiny", "Mohamed", ""], ["Zhang", "Xiangliang", ""]]}, {"id": "2004.03637", "submitter": "Pola Schw\\\"obel", "authors": "Pola Schw\\\"obel, Frederik Warburg, Martin J{\\o}rgensen, Kristoffer H.\n  Madsen, S{\\o}ren Hauberg", "title": "Probabilistic Spatial Transformers for Bayesian Data Augmentation", "comments": "Submitted to the International Conference on Machine Learning (ICML),\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-capacity models require vast amounts of data, and data augmentation is a\ncommon remedy when this resource is limited. Standard augmentation techniques\napply small hand-tuned transformations to existing data, which is a brittle\nprocess that realistically only allows for simple transformations. We propose a\nBayesian interpretation of data augmentation where the transformations are\nmodelled as latent variables to be marginalized, and show how these can be\ninferred variationally in an end-to-end fashion. This allows for significantly\nmore complex transformations than manual tuning, and the marginalization\nimplies a form of test-time data augmentation. The resulting model can be\ninterpreted as a probabilistic extension of spatial transformer networks.\nExperimentally, we demonstrate improvements in accuracy and uncertainty\nquantification in image and time series classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:22:02 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Schw\u00f6bel", "Pola", ""], ["Warburg", "Frederik", ""], ["J\u00f8rgensen", "Martin", ""], ["Madsen", "Kristoffer H.", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "2004.03639", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Tianyu Ding, Bo Ji, Guanyi Wang, Jing Tian, Yixin Shi,\n  Sheng Yi, Xiao Tu, Zhihui Zhu", "title": "Orthant Based Proximal Stochastic Gradient Method for\n  $\\ell_1$-Regularized Optimization", "comments": "Accepted by ECML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity-inducing regularization problems are ubiquitous in machine learning\napplications, ranging from feature selection to model compression. In this\npaper, we present a novel stochastic method -- Orthant Based Proximal\nStochastic Gradient Method (OBProx-SG) -- to solve perhaps the most popular\ninstance, i.e., the l1-regularized problem. The OBProx-SG method contains two\nsteps: (i) a proximal stochastic gradient step to predict a support cover of\nthe solution; and (ii) an orthant step to aggressively enhance the sparsity\nlevel via orthant face projection. Compared to the state-of-the-art methods,\ne.g., Prox-SG, RDA and Prox-SVRG, the OBProx-SG not only converges to the\nglobal optimal solutions (in convex scenario) or the stationary points (in\nnon-convex scenario), but also promotes the sparsity of the solutions\nsubstantially. Particularly, on a large number of convex problems, OBProx-SG\noutperforms the existing methods comprehensively in the aspect of sparsity\nexploration and objective values. Moreover, the experiments on non-convex deep\nneural networks, e.g., MobileNetV1 and ResNet18, further demonstrate its\nsuperiority by achieving the solutions of much higher sparsity without\nsacrificing generalization accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:23:39 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 04:54:42 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Chen", "Tianyi", ""], ["Ding", "Tianyu", ""], ["Ji", "Bo", ""], ["Wang", "Guanyi", ""], ["Tian", "Jing", ""], ["Shi", "Yixin", ""], ["Yi", "Sheng", ""], ["Tu", "Xiao", ""], ["Zhu", "Zhihui", ""]]}, {"id": "2004.03644", "submitter": "Babak Salimi", "authors": "Babak Salimi, Harsh Parikh, Moe Kayali, Sudeepa Roy, Lise Getoor, and\n  Dan Suciu", "title": "Causal Relational Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference is at the heart of empirical research in natural and social\nsciences and is critical for scientific discovery and informed decision making.\nThe gold standard in causal inference is performing randomized controlled\ntrials; unfortunately these are not always feasible due to ethical, legal, or\ncost constraints. As an alternative, methodologies for causal inference from\nobservational data have been developed in statistical studies and social\nsciences. However, existing methods critically rely on restrictive assumptions\nsuch as the study population consisting of homogeneous elements that can be\nrepresented in a single flat table, where each row is referred to as a unit. In\ncontrast, in many real-world settings, the study domain naturally consists of\nheterogeneous elements with complex relational structure, where the data is\nnaturally represented in multiple related tables. In this paper, we present a\nformal framework for causal inference from such relational data. We propose a\ndeclarative language called CaRL for capturing causal background knowledge and\nassumptions and specifying causal queries using simple Datalog-like rules.CaRL\nprovides a foundation for inferring causality and reasoning about the effect of\ncomplex interventions in relational domains. We present an extensive\nexperimental evaluation on real relational data to illustrate the applicability\nof CaRL in social sciences and healthcare.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 18:33:05 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Salimi", "Babak", ""], ["Parikh", "Harsh", ""], ["Kayali", "Moe", ""], ["Roy", "Sudeepa", ""], ["Getoor", "Lise", ""], ["Suciu", "Dan", ""]]}, {"id": "2004.03657", "submitter": "Wei Chen", "authors": "Wei Chen, Kartikeya Bhardwaj, Radu Marculescu", "title": "FedMAX: Mitigating Activation Divergence for Accurate and\n  Communication-Efficient Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we identify a new phenomenon called activation-divergence\nwhich occurs in Federated Learning (FL) due to data heterogeneity (i.e., data\nbeing non-IID) across multiple users. Specifically, we argue that the\nactivation vectors in FL can diverge, even if subsets of users share a few\ncommon classes with data residing on different devices. To address the\nactivation-divergence issue, we introduce a prior based on the principle of\nmaximum entropy; this prior assumes minimal information about the per-device\nactivation vectors and aims at making the activation vectors of same classes as\nsimilar as possible across multiple devices. Our results show that, for both\nIID and non-IID settings, our proposed approach results in better accuracy (due\nto the significantly more similar activation vectors across multiple devices),\nand is more communication-efficient than state-of-the-art approaches in FL.\nFinally, we illustrate the effectiveness of our approach on a few common\nbenchmarks and two large medical datasets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:22:58 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 19:57:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Wei", ""], ["Bhardwaj", "Kartikeya", ""], ["Marculescu", "Radu", ""]]}, {"id": "2004.03658", "submitter": "Haitian Sun", "authors": "Haitian Sun, Andrew O. Arnold, Tania Bedrax-Weiss, Fernando Pereira,\n  William W. Cohen", "title": "Faithful Embeddings for Knowledge Base Queries", "comments": "Published at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deductive closure of an ideal knowledge base (KB) contains exactly the\nlogical queries that the KB can answer. However, in practice KBs are both\nincomplete and over-specified, failing to answer some queries that have\nreal-world answers. \\emph{Query embedding} (QE) techniques have been recently\nproposed where KB entities and KB queries are represented jointly in an\nembedding space, supporting relaxation and generalization in KB inference.\nHowever, experiments in this paper show that QE systems may disagree with\ndeductive reasoning on answers that do not require generalization or\nrelaxation. We address this problem with a novel QE method that is more\nfaithful to deductive reasoning, and show that this leads to better performance\non complex queries to incomplete KBs. Finally we show that inserting this new\nQE module into a neural question-answering system leads to substantial\nimprovements over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:25:16 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 21:19:36 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 03:46:25 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Sun", "Haitian", ""], ["Arnold", "Andrew O.", ""], ["Bedrax-Weiss", "Tania", ""], ["Pereira", "Fernando", ""], ["Cohen", "William W.", ""]]}, {"id": "2004.03669", "submitter": "Mohammad Shifat-E-Rabbi", "authors": "Mohammad Shifat-E-Rabbi, Xuwang Yin, Abu Hasnat Mohammad Rubaiyat,\n  Shiying Li, Soheil Kolouri, Akram Aldroubi, Jonathan M. Nichols, and Gustavo\n  K. Rohde", "title": "Radon cumulative distribution transform subspace modeling for image\n  classification", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new supervised image classification method applicable to a broad\nclass of image deformation models. The method makes use of the previously\ndescribed Radon Cumulative Distribution Transform (R-CDT) for image data, whose\nmathematical properties are exploited to express the image data in a form that\nis more suitable for machine learning. While certain operations such as\ntranslation, scaling, and higher-order transformations are challenging to model\nin native image space, we show the R-CDT can capture some of these variations\nand thus render the associated image classification problems easier to solve.\nThe method -- utilizing a nearest-subspace algorithm in R-CDT space -- is\nsimple to implement, non-iterative, has no hyper-parameters to tune, is\ncomputationally efficient, label efficient, and provides competitive accuracies\nto state-of-the-art neural networks for many types of classification problems.\nIn addition to the test accuracy performances, we show improvements (with\nrespect to neural network-based methods) in terms of computational efficiency\n(it can be implemented without the use of GPUs), number of training samples\nneeded for training, as well as out-of-distribution generalization. The Python\ncode for reproducing our results is available at\nhttps://github.com/rohdelab/rcdt_ns_classifier.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:47:26 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2020 18:35:30 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Shifat-E-Rabbi", "Mohammad", ""], ["Yin", "Xuwang", ""], ["Rubaiyat", "Abu Hasnat Mohammad", ""], ["Li", "Shiying", ""], ["Kolouri", "Soheil", ""], ["Aldroubi", "Akram", ""], ["Nichols", "Jonathan M.", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "2004.03670", "submitter": "Antonio Libri", "authors": "Antonio Libri, Andrea Bartolini, Luca Benini", "title": "pAElla: Edge-AI based Real-Time Malware Detection in Data Centers", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2020.2986702", "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of Internet-of-Things (IoT) devices for monitoring a wide\nspectrum of applications, along with the challenges of \"big data\" streaming\nsupport they often require for data analysis, is nowadays pushing for an\nincreased attention to the emerging edge computing paradigm. In particular,\nsmart approaches to manage and analyze data directly on the network edge, are\nmore and more investigated, and Artificial Intelligence (AI) powered edge\ncomputing is envisaged to be a promising direction. In this paper, we focus on\nData Centers (DCs) and Supercomputers (SCs), where a new generation of\nhigh-resolution monitoring systems is being deployed, opening new opportunities\nfor analysis like anomaly detection and security, but introducing new\nchallenges for handling the vast amount of data it produces. In detail, we\nreport on a novel lightweight and scalable approach to increase the security of\nDCs/SCs, that involves AI-powered edge computing on high-resolution power\nconsumption. The method -- called pAElla -- targets real-time Malware Detection\n(MD), it runs on an out-of-band IoT-based monitoring system for DCs/SCs, and\ninvolves Power Spectral Density of power measurements, along with AutoEncoders.\nResults are promising, with an F1-score close to 1, and a False Alarm and\nMalware Miss rate close to 0%. We compare our method with State-of-the-Art MD\ntechniques and show that, in the context of DCs/SCs, pAElla can cover a wider\nrange of malware, significantly outperforming SoA approaches in terms of\naccuracy. Moreover, we propose a methodology for online training suitable for\nDCs/SCs in production, and release open dataset and code.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:48:57 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Libri", "Antonio", ""], ["Bartolini", "Andrea", ""], ["Benini", "Luca", ""]]}, {"id": "2004.03685", "submitter": "Alon Jacovi", "authors": "Alon Jacovi, Yoav Goldberg", "title": "Towards Faithfully Interpretable NLP Systems: How should we define and\n  evaluate faithfulness?", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing popularity of deep-learning based NLP models, comes a need\nfor interpretable systems. But what is interpretability, and what constitutes a\nhigh-quality interpretation? In this opinion piece we reflect on the current\nstate of interpretability evaluation research. We call for more clearly\ndifferentiating between different desired criteria an interpretation should\nsatisfy, and focus on the faithfulness criteria. We survey the literature with\nrespect to faithfulness evaluation, and arrange the current approaches around\nthree assumptions, providing an explicit form to how faithfulness is \"defined\"\nby the community. We provide concrete guidelines on how evaluation of\ninterpretation methods should and should not be conducted. Finally, we claim\nthat the current binary definition for faithfulness sets a potentially\nunrealistic bar for being considered faithful. We call for discarding the\nbinary notion of faithfulness in favor of a more graded one, which we believe\nwill be of greater practical utility.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:15:28 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 01:18:49 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 20:44:37 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jacovi", "Alon", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2004.03698", "submitter": "Umut \\\"Ozkaya", "authors": "Umut Ozkaya, Saban Ozturk, Mucahid Barstugan", "title": "Coronavirus (COVID-19) Classification using Deep Features Fusion and\n  Ranking Technique", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus (COVID-19) emerged towards the end of 2019. World Health\nOrganization (WHO) was identified it as a global epidemic. Consensus occurred\nin the opinion that using Computerized Tomography (CT) techniques for early\ndiagnosis of pandemic disease gives both fast and accurate results. It was\nstated by expert radiologists that COVID-19 displays different behaviours in CT\nimages. In this study, a novel method was proposed as fusing and ranking deep\nfeatures to detect COVID-19 in early phase. 16x16 (Subset-1) and 32x32\n(Subset-2) patches were obtained from 150 CT images to generate sub-datasets.\nWithin the scope of the proposed method, 3000 patch images have been labelled\nas CoVID-19 and No finding for using in training and testing phase. Feature\nfusion and ranking method have been applied in order to increase the\nperformance of the proposed method. Then, the processed data was classified\nwith a Support Vector Machine (SVM). According to other pre-trained\nConvolutional Neural Network (CNN) models used in transfer learning, the\nproposed method shows high performance on Subset-2 with 98.27% accuracy, 98.93%\nsensitivity, 97.60% specificity, 97.63% precision, 98.28% F1-score and 96.54%\nMatthews Correlation Coefficient (MCC) metrics.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:43:44 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ozkaya", "Umut", ""], ["Ozturk", "Saban", ""], ["Barstugan", "Mucahid", ""]]}, {"id": "2004.03705", "submitter": "Shervin Minaee", "authors": "Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam\n  Chenaghlu, Jianfeng Gao", "title": "Deep Learning Based Text Classification: A Comprehensive Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based models have surpassed classical machine learning based\napproaches in various text classification tasks, including sentiment analysis,\nnews categorization, question answering, and natural language inference. In\nthis paper, we provide a comprehensive review of more than 150 deep learning\nbased models for text classification developed in recent years, and discuss\ntheir technical contributions, similarities, and strengths. We also provide a\nsummary of more than 40 popular datasets widely used for text classification.\nFinally, we provide a quantitative analysis of the performance of different\ndeep learning models on popular benchmarks, and discuss future research\ndirections.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 02:00:30 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 20:53:58 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 07:41:46 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Minaee", "Shervin", ""], ["Kalchbrenner", "Nal", ""], ["Cambria", "Erik", ""], ["Nikzad", "Narjes", ""], ["Chenaghlu", "Meysam", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.03706", "submitter": "Saurabh Sharma", "authors": "Saurabh Sharma, Ning Yu, Mario Fritz, Bernt Schiele", "title": "Long-Tailed Recognition Using Class-Balanced Experts", "comments": "Accepted and presented at 42nd German Conference on Pattern\n  Recognition (DAGM-GCPR 2020), T\\\"ubingen, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning enables impressive performance in image recognition using\nlarge-scale artificially-balanced datasets. However, real-world datasets\nexhibit highly class-imbalanced distributions, yielding two main challenges:\nrelative imbalance amongst the classes and data scarcity for mediumshot or\nfewshot classes. In this work, we address the problem of long-tailed\nrecognition wherein the training set is highly imbalanced and the test set is\nkept balanced. Differently from existing paradigms relying on data-resampling,\ncost-sensitive learning, online hard example mining, loss objective reshaping,\nand/or memory-based modeling, we propose an ensemble of class-balanced experts\nthat combines the strength of diverse classifiers. Our ensemble of\nclass-balanced experts reaches results close to state-of-the-art and an\nextended ensemble establishes a new state-of-the-art on two benchmarks for\nlong-tailed recognition. We conduct extensive experiments to analyse the\nperformance of the ensembles, and discover that in modern large-scale datasets,\nrelative imbalance is a harder problem than data scarcity. The training and\nevaluation code is available at\nhttps://github.com/ssfootball04/class-balanced-experts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:57:44 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 11:22:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Sharma", "Saurabh", ""], ["Yu", "Ning", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "2004.03712", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Houman Ghaemmaghami, Simon Denman, Sridha\n  Sridharan, Nayyar Hussain, Clinton Fookes", "title": "Heart Sound Segmentation using Bidirectional LSTMs with Attention", "comments": "IEEE Journal of Biomedical and Health Informatics, 25 October 2019", "journal-ref": null, "doi": "10.1109/JBHI.2019.2949516", "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel framework for the segmentation of phonocardiogram\n(PCG) signals into heart states, exploiting the temporal evolution of the PCG\nas well as considering the salient information that it provides for the\ndetection of the heart state. We propose the use of recurrent neural networks\nand exploit recent advancements in attention based learning to segment the PCG\nsignal. This allows the network to identify the most salient aspects of the\nsignal and disregard uninformative information. The proposed method attains\nstate-of-the-art performance on multiple benchmarks including both human and\nanimal heart recordings. Furthermore, we empirically analyse different feature\ncombinations including envelop features, wavelet and Mel Frequency Cepstral\nCoefficients (MFCC), and provide quantitative measurements that explore the\nimportance of different features in the proposed approach. We demonstrate that\na recurrent neural network coupled with attention mechanisms can effectively\nlearn from irregular and noisy PCG recordings. Our analysis of different\nfeature combinations shows that MFCC features and their derivatives offer the\nbest performance compared to classical wavelet and envelop features. Heart\nsound segmentation is a crucial pre-processing step for many diagnostic\napplications. The proposed method provides a cost effective alternative to\nlabour extensive manual segmentation, and provides a more accurate segmentation\nthan existing methods. As such, it can improve the performance of further\nanalysis including the detection of murmurs and ejection clicks. The proposed\nmethod is also applicable for detection and segmentation of other one\ndimensional biomedical signals.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 02:09:11 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Fernando", "Tharindu", ""], ["Ghaemmaghami", "Houman", ""], ["Denman", "Simon", ""], ["Sridharan", "Sridha", ""], ["Hussain", "Nayyar", ""], ["Fookes", "Clinton", ""]]}, {"id": "2004.03722", "submitter": "Lucas May Petry", "authors": "Lucas May Petry, Amilcar Soares, Vania Bogorny, Bruno Brandoli, Stan\n  Matwin", "title": "Challenges in Vessel Behavior and Anomaly Detection: From Classical\n  Machine Learning to Deep Learning", "comments": "This is an extended version of the article Challenges in Vessel\n  Behavior and Anomaly Detection: From Classical Machine Learning to Deep\n  Learning, to be published by Springer in the proceedings of the 33rd Canadian\n  Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global expansion of maritime activities and the development of the\nAutomatic Identification System (AIS) have driven the advances in maritime\nmonitoring systems in the last decade. Monitoring vessel behavior is\nfundamental to safeguard maritime operations, protecting other vessels sailing\nthe ocean and the marine fauna and flora. Given the enormous volume of vessel\ndata continually being generated, real-time analysis of vessel behaviors is\nonly possible because of decision support systems provided with event and\nanomaly detection methods. However, current works on vessel event detection are\nad-hoc methods able to handle only a single or a few predefined types of vessel\nbehavior. Most of the existing approaches do not learn from the data and\nrequire the definition of queries and rules for describing each behavior. In\nthis paper, we discuss challenges and opportunities in classical machine\nlearning and deep learning for vessel event and anomaly detection. We hope to\nmotivate the research of novel methods and tools, since addressing these\nchallenges is an essential step towards actual intelligent maritime monitoring\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 21:25:12 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Brandoli", "Bruno", ""], ["Matwin", "Stan", ""]]}, {"id": "2004.03734", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Francis Ferraro, Tim Oates", "title": "Locality Preserving Loss: Neighbors that Live together, Align together", "comments": null, "journal-ref": "Adapt-NLP 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a locality preserving loss (LPL) that improves the alignment\nbetween vector space embeddings while separating uncorrelated representations.\nGiven two pretrained embedding manifolds, LPL optimizes a model to project an\nembedding and maintain its local neighborhood while aligning one manifold to\nanother. This reduces the overall size of the dataset required to align the two\nin tasks such as cross-lingual word alignment. We show that the LPL-based\nalignment between input vector spaces acts as a regularizer, leading to better\nand consistent accuracy than the baseline, especially when the size of the\ntraining set is small. We demonstrate the effectiveness of LPL optimized\nalignment on semantic text similarity (STS), natural language inference (SNLI),\nmulti-genre language inference (MNLI) and cross-lingual word alignment(CLA)\nshowing consistent improvements, finding up to 16% improvement over our\nbaseline in lower resource settings.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 22:26:09 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 04:56:20 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Ferraro", "Francis", ""], ["Oates", "Tim", ""]]}, {"id": "2004.03737", "submitter": "Zhecan Wang", "authors": "Zhecan Wang, Jian Zhao, Cheng Lu, Han Huang, Fan Yang, Lianji Li,\n  Yandong Guo", "title": "Learning to Detect Head Movement in Unconstrained Remote Gaze Estimation\n  in the Wild", "comments": "2020 Winter Conference on Applications of Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unconstrained remote gaze estimation remains challenging mostly due to its\nvulnerability to the large variability in head-pose. Prior solutions struggle\nto maintain reliable accuracy in unconstrained remote gaze tracking. Among\nthem, appearance-based solutions demonstrate tremendous potential in improving\ngaze accuracy. However, existing works still suffer from head movement and are\nnot robust enough to handle real-world scenarios. Especially most of them study\ngaze estimation under controlled scenarios where the collected datasets often\ncover limited ranges of both head-pose and gaze which introduces further bias.\nIn this paper, we propose novel end-to-end appearance-based gaze estimation\nmethods that could more robustly incorporate different levels of head-pose\nrepresentations into gaze estimation. Our method could generalize to real-world\nscenarios with low image quality, different lightings and scenarios where\ndirect head-pose information is not available. To better demonstrate the\nadvantage of our methods, we further propose a new benchmark dataset with the\nmost rich distribution of head-gaze combination reflecting real-world\nscenarios. Extensive evaluations on several public datasets and our own dataset\ndemonstrate that our method consistently outperforms the state-of-the-art by a\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 22:38:49 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Wang", "Zhecan", ""], ["Zhao", "Jian", ""], ["Lu", "Cheng", ""], ["Huang", "Han", ""], ["Yang", "Fan", ""], ["Li", "Lianji", ""], ["Guo", "Yandong", ""]]}, {"id": "2004.03742", "submitter": "Boxin Wang", "authors": "Boxin Wang, Boyuan Pan, Xin Li, Bo Li", "title": "Towards Evaluating the Robustness of Chinese BERT Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in large-scale language representation models such as BERT\nhave improved the state-of-the-art performances in many NLP tasks. Meanwhile,\ncharacter-level Chinese NLP models, including BERT for Chinese, have also\ndemonstrated that they can outperform the existing models. In this paper, we\nshow that, however, such BERT-based models are vulnerable under character-level\nadversarial attacks. We propose a novel Chinese char-level attack method\nagainst BERT-based classifiers. Essentially, we generate \"small\" perturbation\non the character level in the embedding space and guide the character\nsubstitution procedure. Extensive experiments show that the classification\naccuracy on a Chinese news dataset drops from 91.8% to 0% by manipulating less\nthan 2 characters on average based on the proposed attack. Human evaluations\nalso confirm that our generated Chinese adversarial examples barely affect\nhuman performance on these NLP tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 23:02:37 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Wang", "Boxin", ""], ["Pan", "Boyuan", ""], ["Li", "Xin", ""], ["Li", "Bo", ""]]}, {"id": "2004.03747", "submitter": "Md Zahangir Alom", "authors": "Md Zahangir Alom, M M Shaifur Rahman, Mst Shamima Nasrin, Tarek M.\n  Taha, and Vijayan K. Asari", "title": "COVID_MTNet: COVID-19 Detection with Multi-Task Deep Learning Approaches", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 is currently one the most life-threatening problems around the\nworld. The fast and accurate detection of the COVID-19 infection is essential\nto identify, take better decisions and ensure treatment for the patients which\nwill help save their lives. In this paper, we propose a fast and efficient way\nto identify COVID-19 patients with multi-task deep learning (DL) methods. Both\nX-ray and CT scan images are considered to evaluate the proposed technique. We\nemploy our Inception Residual Recurrent Convolutional Neural Network with\nTransfer Learning (TL) approach for COVID-19 detection and our NABLA-N network\nmodel for segmenting the regions infected by COVID-19. The detection model\nshows around 84.67% testing accuracy from X-ray images and 98.78% accuracy in\nCT-images. A novel quantitative analysis strategy is also proposed in this\npaper to determine the percentage of infected regions in X-ray and CT images.\nThe qualitative and quantitative results demonstrate promising results for\nCOVID-19 detection and infected region localization.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 23:19:59 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 02:26:05 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 19:01:10 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Alom", "Md Zahangir", ""], ["Rahman", "M M Shaifur", ""], ["Nasrin", "Mst Shamima", ""], ["Taha", "Tarek M.", ""], ["Asari", "Vijayan K.", ""]]}, {"id": "2004.03749", "submitter": "Pengzhan Guo", "authors": "Pengzhan Guo, Zeyang Ye, Keli Xiao, Wei Zhu", "title": "Weighted Aggregating Stochastic Gradient Descent for Parallel Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the stochastic optimization problem with a focus on\ndeveloping scalable parallel algorithms for deep learning tasks. Our solution\ninvolves a reformation of the objective function for stochastic optimization in\nneural network models, along with a novel parallel strategy, coined weighted\naggregating stochastic gradient descent (WASGD). Following a theoretical\nanalysis on the characteristics of the new objective function, WASGD introduces\na decentralized weighted aggregating scheme based on the performance of local\nworkers. Without any center variable, the new method automatically assesses the\nimportance of local workers and accepts them according to their contributions.\nFurthermore, we have developed an enhanced version of the method, WASGD+, by\n(1) considering a designed sample order and (2) applying a more advanced weight\nevaluating function. To validate the new method, we benchmark our schemes\nagainst several popular algorithms including the state-of-the-art techniques\n(e.g., elastic averaging SGD) in training deep neural networks for\nclassification tasks. Comprehensive experiments have been conducted on four\nclassic datasets, including the CIFAR-100, CIFAR-10, Fashion-MNIST, and MNIST.\nThe subsequent results suggest the superiority of the WASGD scheme in\naccelerating the training of deep architecture. Better still, the enhanced\nversion, WASGD+, has been shown to be a significant improvement over its basic\nversion.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 23:38:29 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Guo", "Pengzhan", ""], ["Ye", "Zeyang", ""], ["Xiao", "Keli", ""], ["Zhu", "Wei", ""]]}, {"id": "2004.03761", "submitter": "Shakti Kumar", "authors": "Shakti Kumar, Jerrod Parker, Panteha Naderian", "title": "Adaptive Transformers in RL", "comments": "10 pages with 9 figures and 4 tables. Main text is 6 pages, appendix\n  is 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Transformers have opened new interesting areas of\nresearch in partially observable reinforcement learning tasks. Results from\nlate 2019 showed that Transformers are able to outperform LSTMs on both memory\nintense and reactive tasks. In this work we first partially replicate the\nresults shown in Stabilizing Transformers in RL on both reactive and memory\nbased environments. We then show performance improvement coupled with reduced\ncomputation when adding adaptive attention span to this Stable Transformer on a\nchallenging DMLab30 environment. The code for all our experiments and models is\navailable at https://github.com/jerrodparker20/adaptive-transformers-in-rl.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 01:03:10 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Kumar", "Shakti", ""], ["Parker", "Jerrod", ""], ["Naderian", "Panteha", ""]]}, {"id": "2004.03774", "submitter": "Manqing Dong", "authors": "Manqing Dong, Feng Yuan, Lina Yao, Xianzhi Wang, Xiwei Xu and Liming\n  Zhu", "title": "Survey for Trust-aware Recommender Systems: A Deep Learning Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A significant remaining challenge for existing recommender systems is that\nusers may not trust the recommender systems for either lack of explanation or\ninaccurate recommendation results. Thus, it becomes critical to embrace a\ntrustworthy recommender system. This survey provides a systemic summary of\nthree categories of trust-aware recommender systems: social-aware recommender\nsystems that leverage users' social relationships; robust recommender systems\nthat filter untruthful noises (e.g., spammers and fake information) or enhance\nattack resistance; explainable recommender systems that provide explanations of\nrecommended items. We focus on the work based on deep learning techniques, an\nemerging area in the recommendation research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 02:11:55 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 00:45:13 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dong", "Manqing", ""], ["Yuan", "Feng", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Xu", "Xiwei", ""], ["Zhu", "Liming", ""]]}, {"id": "2004.03786", "submitter": "Ye Tian", "authors": "Cheng Li, Ye Tian", "title": "Downstream Model Design of Pre-trained Language Model for Relation\n  Extraction Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised relation extraction methods based on deep neural network play an\nimportant role in the recent information extraction field. However, at present,\ntheir performance still fails to reach a good level due to the existence of\ncomplicated relations. On the other hand, recently proposed pre-trained\nlanguage models (PLMs) have achieved great success in multiple tasks of natural\nlanguage processing through fine-tuning when combined with the model of\ndownstream tasks. However, original standard tasks of PLM do not include the\nrelation extraction task yet. We believe that PLMs can also be used to solve\nthe relation extraction problem, but it is necessary to establish a specially\ndesigned downstream task model or even loss function for dealing with\ncomplicated relations. In this paper, a new network architecture with a special\nloss function is designed to serve as a downstream model of PLMs for supervised\nrelation extraction. Experiments have shown that our method significantly\nexceeded the current optimal baseline models across multiple public datasets of\nrelation extraction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 03:16:06 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Cheng", ""], ["Tian", "Ye", ""]]}, {"id": "2004.03793", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "A Dynamic Observation Strategy for Multi-agent Multi-armed Bandit\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and analyze a multi-agent multi-armed bandit problem in which\ndecision-making agents can observe the choices and rewards of their neighbors\nunder a linear observation cost. Neighbors are defined by a network graph that\nencodes the inherent observation constraints of the system. We define a cost\nassociated with observations such that at every instance an agent makes an\nobservation it receives a constant observation regret. We design a sampling\nalgorithm and an observation protocol for each agent to maximize its own\nexpected cumulative reward through minimizing expected cumulative sampling\nregret and expected cumulative observation regret. For our proposed protocol,\nwe prove that total cumulative regret is logarithmically bounded. We verify the\naccuracy of analytical bounds using numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 03:45:48 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2004.03797", "submitter": "Jaleh Zand", "authors": "Jaleh Zand and Stephen Roberts", "title": "Mixture Density Conditional Generative Adversarial Network Models\n  (MD-CGAN)", "comments": "Revision includes further expansion of analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have gained significant attention in\nrecent years, with impressive applications highlighted in computer vision in\nparticular. Compared to such examples, however, there have been more limited\napplications of GANs to time series modelling, including forecasting. In this\nwork, we present the Mixture Density Conditional Generative Adversarial Model\n(MD-CGAN), with a focus on time series forecasting. We show that our model is\ncapable of estimating a probabilistic posterior distribution over forecasts and\nthat, in comparison to a set of benchmark methods, the MD-CGAN model performs\nwell, particularly in situations where noise is a significant component of the\nobserved time series. Further, by using a Gaussian mixture model as the output\ndistribution, MD-CGAN offers posterior predictions that are non-Gaussian.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 03:55:30 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:09:17 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 03:52:08 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Zand", "Jaleh", ""], ["Roberts", "Stephen", ""]]}, {"id": "2004.03808", "submitter": "Xiaoyu Kou", "authors": "Xiaoyu Kou, Yaming Yang, Yujing Wang, Ce Zhang, Yiren Chen, Yunhai\n  Tong, Yan Zhang, and Jing Bai", "title": "Improving BERT with Self-Supervised Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most popular paradigms of applying large, pre-trained NLP models\nsuch as BERT is to fine-tune it on a smaller dataset. However, one challenge\nremains as the fine-tuned model often overfits on smaller datasets. A symptom\nof this phenomenon is that irrelevant words in the sentences, even when they\nare obvious to humans, can substantially degrade the performance of these\nfine-tuned BERT models. In this paper, we propose a novel technique, called\nSelf-Supervised Attention (SSA) to help facilitate this generalization\nchallenge. Specifically, SSA automatically generates weak, token-level\nattention labels iteratively by \"probing\" the fine-tuned model from the\nprevious iteration. We investigate two different ways of integrating SSA into\nBERT and propose a hybrid approach to combine their benefits. Empirically, on a\nvariety of public datasets, we illustrate significant performance improvement\nusing our SSA-enhanced BERT model.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 04:48:44 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:17:12 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 03:49:47 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kou", "Xiaoyu", ""], ["Yang", "Yaming", ""], ["Wang", "Yujing", ""], ["Zhang", "Ce", ""], ["Chen", "Yiren", ""], ["Tong", "Yunhai", ""], ["Zhang", "Yan", ""], ["Bai", "Jing", ""]]}, {"id": "2004.03809", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Runze Liang, Minlie Huang", "title": "Multi-Agent Task-Oriented Dialog Policy Learning with Role-Aware Reward\n  Decomposition", "comments": "ACL 2020 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have applied reinforcement learning to train a dialog policy and\nshow great promise these years. One common approach is to employ a user\nsimulator to obtain a large number of simulated user experiences for\nreinforcement learning algorithms. However, modeling a realistic user simulator\nis challenging. A rule-based simulator requires heavy domain expertise for\ncomplex tasks, and a data-driven simulator requires considerable data and it is\neven unclear how to evaluate a simulator. To avoid explicitly building a user\nsimulator beforehand, we propose Multi-Agent Dialog Policy Learning, which\nregards both the system and the user as the dialog agents. Two agents interact\nwith each other and are jointly learned simultaneously. The method uses the\nactor-critic framework to facilitate pretraining and improve scalability. We\nalso propose Hybrid Value Network for the role-aware reward decomposition to\nintegrate role-specific domain knowledge of each agent in the task-oriented\ndialog. Results show that our method can successfully build a system policy and\na user policy simultaneously, and two agents can achieve a high task success\nrate through conversational interaction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 04:51:40 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 02:34:16 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Liang", "Runze", ""], ["Huang", "Minlie", ""]]}, {"id": "2004.03818", "submitter": "Kehai Chen", "authors": "Kehai Chen, Rui Wang, Masao Utiyama, and Eiichiro Sumita", "title": "Explicit Reordering for Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Transformer-based neural machine translation (NMT), the positional\nencoding mechanism helps the self-attention networks to learn the source\nrepresentation with order dependency, which makes the Transformer-based NMT\nachieve state-of-the-art results for various translation tasks. However,\nTransformer-based NMT only adds representations of positions sequentially to\nword vectors in the input sentence and does not explicitly consider reordering\ninformation in this sentence. In this paper, we first empirically investigate\nthe relationship between source reordering information and translation\nperformance. The empirical findings show that the source input with the target\norder learned from the bilingual parallel dataset can substantially improve\ntranslation performance. Thus, we propose a novel reordering method to\nexplicitly model this reordering information for the Transformer-based NMT. The\nempirical results on the WMT14 English-to-German, WAT ASPEC\nJapanese-to-English, and WMT17 Chinese-to-English translation tasks show the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 05:28:46 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Chen", "Kehai", ""], ["Wang", "Rui", ""], ["Utiyama", "Masao", ""], ["Sumita", "Eiichiro", ""]]}, {"id": "2004.03839", "submitter": "Zhi-Hua Zhou", "authors": "Shao-Qun Zhang and Zhi-Hua Zhou", "title": "Flexible Transmitter Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural networks are mostly built upon the MP model, which usually\nformulates the neuron as executing an activation function on the real-valued\nweighted aggregation of signals received from other neurons. In this paper, we\npropose the Flexible Transmitter (FT) model, a novel bio-plausible neuron model\nwith flexible synaptic plasticity. The FT model employs a pair of parameters to\nmodel the transmitters between neurons and puts up a neuron-exclusive variable\nto record the regulated neurotrophin density, which leads to the formulation of\nthe FT model as a two-variable two-valued function, taking the commonly-used MP\nneuron model as its special case. This modeling manner makes the FT model not\nonly biologically more realistic, but also capable of handling complicated\ndata, even time series. To exhibit its power and potential, we present the\nFlexible Transmitter Network (FTNet), which is built on the most common\nfully-connected feed-forward architecture taking the FT model as the basic\nbuilding block. FTNet allows gradient calculation and can be implemented by an\nimproved back-propagation algorithm in the complex-valued domain. Experiments\non a board range of tasks show the superiority of the proposed FTNet. This\nstudy provides an alternative basic building block in neural networks and\nexhibits the feasibility of developing artificial neural networks with neuronal\nplasticity.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 06:55:12 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 17:36:21 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 14:18:18 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Zhang", "Shao-Qun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "2004.03841", "submitter": "Shantanu Sharma", "authors": "Nisha Panwar, Shantanu Sharma, Guoxi Wang, Sharad Mehrotra, and Nalini\n  Venkatasubramanian", "title": "Canopy: A Verifiable Privacy-Preserving Token Ring based Communication\n  Protocol for Smart Homes", "comments": "This version has been accepted in ACM Transactions on Cyber-Physical\n  Systems (TCPS). A preliminary version of this paper was accepted in ACM\n  Conference on Data and Application Security and Privacy (CODASPY) 2019. arXiv\n  admin note: substantial text overlap with arXiv:1901.08618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the new privacy challenges that arise in smart homes.\nSpecifically, the paper focuses on inferring the user's activities -- which\nmay, in turn, lead to the user's privacy -- via inferences through device\nactivities and network traffic analysis. We develop techniques that are based\non a cryptographically secure token circulation in a ring network consisting of\nsmart home devices to prevent inferences from device activities, via device\nworkflow, i.e., inferences from a coordinated sequence of devices' actuation.\nThe solution hides the device activity and corresponding channel activities,\nand thus, preserve the individual's activities. We also extend our solution to\ndeal with a large number of devices and devices that produce large-sized data\nby implementing parallel rings. Our experiments also evaluate the performance\nin terms of communication overheads of the proposed approach and the obtained\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 06:57:01 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""], ["Wang", "Guoxi", ""], ["Mehrotra", "Sharad", ""], ["Venkatasubramanian", "Nalini", ""]]}, {"id": "2004.03842", "submitter": "Hayoung Kim", "authors": "Hayoung Kim, Dongchan Kim, Gihoon Kim, Jeongmin Cho and Kunsoo Huh", "title": "Multi-Head Attention based Probabilistic Vehicle Trajectory Prediction", "comments": "6 pages, 5 figures, 2020 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents online-capable deep learning model for probabilistic\nvehicle trajectory prediction. We propose a simple encoder-decoder architecture\nbased on multi-head attention. The proposed model generates the distribution of\nthe predicted trajectories for multiple vehicles in parallel. Our approach to\nmodel the interactions can learn to attend to a few influential vehicles in an\nunsupervised manner, which can improve the interpretability of the network. The\nexperiments using naturalistic trajectories at highway show the clear\nimprovement in terms of positional error on both longitudinal and lateral\ndirection.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 06:58:51 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 07:53:56 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 09:47:35 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Kim", "Hayoung", ""], ["Kim", "Dongchan", ""], ["Kim", "Gihoon", ""], ["Cho", "Jeongmin", ""], ["Huh", "Kunsoo", ""]]}, {"id": "2004.03844", "submitter": "Hassan Sajjad", "authors": "Hassan Sajjad, Fahim Dalvi, Nadir Durrani, and Preslav Nakov", "title": "On the Effect of Dropping Layers of Pre-trained Transformer Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based NLP models are trained using hundreds of millions or even\nbillions of parameters, limiting their applicability in computationally\nconstrained environments. While the number of parameters generally correlates\nwith performance, it is not clear whether the entire network is required for a\ndownstream task. Motivated by the recent work on pruning and distilling\npre-trained models, we explore strategies to drop layers in pre-trained models,\nand observe the effect of pruning on downstream GLUE tasks. We were able to\nprune BERT, RoBERTa and XLNet models up to 40%, while maintaining up to 98% of\ntheir original performance. Additionally we show that our pruned models are on\npar with those built using knowledge distillation, both in terms of size and\nperformance. Our experiments yield interesting observations such as, (i) the\nlower layers are most critical to maintain downstream task performance, (ii)\nsome tasks such as paraphrase detection and sentence similarity are more robust\nto the dropping of layers, and (iii) models trained using a different objective\nfunction exhibit different learning patterns and w.r.t the layer dropping.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:09:59 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 11:05:23 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Sajjad", "Hassan", ""], ["Dalvi", "Fahim", ""], ["Durrani", "Nadir", ""], ["Nakov", "Preslav", ""]]}, {"id": "2004.03845", "submitter": "Camille Champion", "authors": "Camille Champion (IMT), Blaz\\`ere M\\'elanie (IMT), Burcelin R\\'emy\n  (I2MC), Loubes Jean-Michel (IMT), Risser Laurent (IMT)", "title": "Robust spectral clustering using LASSO regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster structure detection is a fundamental task for the analysis of graphs,\nin order to understand and to visualize their functional characteristics. Among\nthe different cluster structure detection methods, spectral clustering is\ncurrently one of the most widely used due to its speed and simplicity. Yet,\nthere are few theoretical guarantee to recover the underlying partitions of the\ngraph for general models. This paper therefore presents a variant of spectral\nclustering, called 1-spectral clustering, performed on a new random model\nclosely related to stochastic block model. Its goal is to promote a sparse\neigenbasis solution of a 1 minimization problem revealing the natural structure\nof the graph. The effectiveness and the robustness to small noise perturbations\nof our technique is confirmed through a collection of simulated and real data\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:12:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Champion", "Camille", "", "IMT"], ["M\u00e9lanie", "Blaz\u00e8re", "", "IMT"], ["R\u00e9my", "Burcelin", "", "I2MC"], ["Jean-Michel", "Loubes", "", "IMT"], ["Laurent", "Risser", "", "IMT"]]}, {"id": "2004.03846", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Fei Huang, Kewei Tu", "title": "Structure-Level Knowledge Distillation For Multilingual Sequence\n  Labeling", "comments": "Accepted to ACL 2020, camera-ready. 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual sequence labeling is a task of predicting label sequences using\na single unified model for multiple languages. Compared with relying on\nmultiple monolingual models, using a multilingual model has the benefit of a\nsmaller model size, easier in online serving, and generalizability to\nlow-resource languages. However, current multilingual models still underperform\nindividual monolingual models significantly due to model capacity limitations.\nIn this paper, we propose to reduce the gap between monolingual models and the\nunified multilingual model by distilling the structural knowledge of several\nmonolingual models (teachers) to the unified multilingual model (student). We\npropose two novel KD methods based on structure-level information: (1)\napproximately minimizes the distance between the student's and the teachers'\nstructure level probability distributions, (2) aggregates the structure-level\nknowledge to local distributions and minimizes the distance between two local\nprobability distributions. Our experiments on 4 multilingual tasks with 25\ndatasets show that our approaches outperform several strong baselines and have\nstronger zero-shot generalizability than both the baseline model and teacher\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:14:01 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:10:38 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 09:28:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2004.03848", "submitter": "Weiwei Jiang", "authors": "Weiwei Jiang", "title": "MNIST-MIX: A Multi-language Handwritten Digit Recognition Dataset", "comments": "3 pages, 1 figure, 2 tables", "journal-ref": "IOP SciNotes, 2020", "doi": "10.1088/2633-1357/abad0e", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we contribute a multi-language handwritten digit recognition\ndataset named MNIST-MIX, which is the largest dataset of the same type in terms\nof both languages and data samples. With the same data format with MNIST,\nMNIST-MIX can be seamlessly applied in existing studies for handwritten digit\nrecognition. By introducing digits from 10 different languages, MNIST-MIX\nbecomes a more challenging dataset and its imbalanced classification requires a\nbetter design of models. We also present the results of applying a LeNet model\nwhich is pre-trained on MNIST as the baseline.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:17:32 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Jiang", "Weiwei", ""]]}, {"id": "2004.03865", "submitter": "Joshua Blumenstock", "authors": "Daniel Bj\\\"orkegren, Joshua E. Blumenstock, Samsun Knight", "title": "Manipulation-Proof Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of decisions are guided by machine learning algorithms.\nIn many settings, from consumer credit to criminal justice, those decisions are\nmade by applying an estimator to data on an individual's observed behavior. But\nwhen consequential decisions are encoded in rules, individuals may\nstrategically alter their behavior to achieve desired outcomes. This paper\ndevelops a new class of estimator that is stable under manipulation, even when\nthe decision rule is fully transparent. We explicitly model the costs of\nmanipulating different behaviors, and identify decision rules that are stable\nin equilibrium. Through a large field experiment in Kenya, we show that\ndecision rules estimated with our strategy-robust method outperform those based\non standard supervised learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 08:04:01 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Bj\u00f6rkegren", "Daniel", ""], ["Blumenstock", "Joshua E.", ""], ["Knight", "Samsun", ""]]}, {"id": "2004.03891", "submitter": "Apratim Bhattacharyya", "authors": "Shweta Mahajan, Apratim Bhattacharyya, Mario Fritz, Bernt Schiele,\n  Stefan Roth", "title": "Normalizing Flows with Multi-Scale Autoregressive Priors", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-based generative models are an important class of exact inference models\nthat admit efficient inference and sampling for image synthesis. Owing to the\nefficiency constraints on the design of the flow layers, e.g. split coupling\nflow layers in which approximately half the pixels do not undergo further\ntransformations, they have limited expressiveness for modeling long-range data\ndependencies compared to autoregressive models that rely on conditional\npixel-wise generation. In this work, we improve the representational power of\nflow-based models by introducing channel-wise dependencies in their latent\nspace through multi-scale autoregressive priors (mAR). Our mAR prior for models\nwith split coupling flow layers (mAR-SCF) can better capture dependencies in\ncomplex multimodal data. The resulting model achieves state-of-the-art density\nestimation results on MNIST, CIFAR-10, and ImageNet. Furthermore, we show that\nmAR-SCF allows for improved image generation quality, with gains in FID and\nInception scores compared to state-of-the-art flow-based models.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 09:07:11 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Mahajan", "Shweta", ""], ["Bhattacharyya", "Apratim", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""], ["Roth", "Stefan", ""]]}, {"id": "2004.03898", "submitter": "Michael Gygli", "authors": "Michael Gygli, Jasper Uijlings, Vittorio Ferrari", "title": "Towards Reusable Network Components by Learning Compatible\n  Representations", "comments": "Preprint; To be presented at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes to make a first step towards compatible and hence\nreusable network components. Rather than training networks for different tasks\nindependently, we adapt the training process to produce network components that\nare compatible across tasks. In particular, we split a network into two\ncomponents, a features extractor and a target task head, and propose various\napproaches to accomplish compatibility between them. We systematically analyse\nthese approaches on the task of image classification on standard datasets. We\ndemonstrate that we can produce components which are directly compatible\nwithout any fine-tuning or compromising accuracy on the original tasks.\nAfterwards, we demonstrate the use of compatible components on three\napplications: Unsupervised domain adaptation, transferring classifiers across\nfeature extractors with different architectures, and increasing the\ncomputational efficiency of transfer learning.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 09:21:37 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 16:40:59 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 13:31:27 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Gygli", "Michael", ""], ["Uijlings", "Jasper", ""], ["Ferrari", "Vittorio", ""]]}, {"id": "2004.03922", "submitter": "Suchismita Das", "authors": "Suchismita Das and Nikhil R. Pal", "title": "Nonlinear Dimensionality Reduction for Data Visualization: An\n  Unsupervised Fuzzy Rule-based Approach", "comments": null, "journal-ref": "IEEE Transactions on Fuzzy Systems ( Early Access ) 2021", "doi": "10.1109/TFUZZ.2021.3076583", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we propose an unsupervised fuzzy rule-based dimensionality reduction\nmethod primarily for data visualization. It considers the following important\nissues relevant to dimensionality reduction-based data visualization: (i)\npreservation of neighborhood relationships, (ii) handling data on a non-linear\nmanifold, (iii) the capability of predicting projections for new test data\npoints, (iv) interpretability of the system, and (v) the ability to reject test\npoints if required. For this, we use a first-order Takagi-Sugeno type model. We\ngenerate rule antecedents using clusters in the input data. In this context, we\nalso propose a new variant of the Geodesic c-means clustering algorithm. We\nestimate the rule parameters by minimizing an error function that preserves the\ninter-point geodesic distances (distances over the manifold) as Euclidean\ndistances on the projected space. We apply the proposed method on three\nsynthetic and three real-world data sets and visually compare the results with\nfour other standard data visualization methods. The obtained results show that\nthe proposed method behaves desirably and performs better than or comparable to\nthe methods compared with. The proposed method is found to be robust to the\ninitial conditions. The predictability of the proposed method for test points\nis validated by experiments. We also assess the ability of our method to reject\noutput points when it should. Then, we extend this concept to provide a general\nframework for learning an unsupervised fuzzy model for data projection with\ndifferent objective functions. To the best of our knowledge, this is the first\nattempt to manifold learning using unsupervised fuzzy modeling.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 10:33:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Das", "Suchismita", ""], ["Pal", "Nikhil R.", ""]]}, {"id": "2004.03924", "submitter": "Dominik Wagner", "authors": "Carol Mak, C.-H. Luke Ong, Hugo Paquet and Dominik Wagner", "title": "Densities of Almost Surely Terminating Probabilistic Programs are\n  Differentiable Almost Everywhere", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-72019-3_16", "report-no": null, "categories": "cs.LO cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the differential properties of higher-order statistical\nprobabilistic programs with recursion and conditioning. Our starting point is\nan open problem posed by Hongseok Yang: what class of statistical probabilistic\nprograms have densities that are differentiable almost everywhere? To formalise\nthe problem, we consider Statistical PCF (SPCF), an extension of call-by-value\nPCF with real numbers, and constructs for sampling and conditioning. We give\nSPCF a sampling-style operational semantics a la Borgstrom et al., and study\nthe associated weight (commonly referred to as the density) function and value\nfunction on the set of possible execution traces. Our main result is that\nalmost-surely terminating SPCF programs, generated from a set of primitive\nfunctions (e.g. the set of analytic functions) satisfying mild closure\nproperties, have weight and value functions that are almost-everywhere\ndifferentiable. We use a stochastic form of symbolic execution to reason about\nalmost-everywhere differentiability. A by-product of this work is that\nalmost-surely terminating deterministic (S)PCF programs with real parameters\ndenote functions that are almost-everywhere differentiable. Our result is of\npractical interest, as almost-everywhere differentiability of the density\nfunction is required to hold for the correctness of major gradient-based\ninference algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 10:40:14 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 16:00:29 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mak", "Carol", ""], ["Ong", "C. -H. Luke", ""], ["Paquet", "Hugo", ""], ["Wagner", "Dominik", ""]]}, {"id": "2004.03951", "submitter": "Zhongchen Ma", "authors": "Zhongchen Ma and Songcan Chen", "title": "Global Expanding, Local Shrinking: Discriminant Multi-label Learning\n  with Missing Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label learning, the issue of missing labels brings a major\nchallenge. Many methods attempt to recovery missing labels by exploiting\nlow-rank structure of label matrix. However, these methods just utilize global\nlow-rank label structure, ignore both local low-rank label structures and label\ndiscriminant information to some extent, leaving room for further performance\nimprovement. In this paper, we develop a simple yet effective discriminant\nmulti-label learning (DM2L) method for multi-label learning with missing\nlabels. Specifically, we impose the low-rank structures on all the predictions\nof instances from the same labels (local shrinking of rank), and a maximally\nseparated structure (high-rank structure) on the predictions of instances from\ndifferent labels (global expanding of rank). In this way, these imposed\nlow-rank structures can help modeling both local and global low-rank label\nstructures, while the imposed high-rank structure can help providing more\nunderlying discriminability. Our subsequent theoretical analysis also supports\nthese intuitions. In addition, we provide a nonlinear extension via using\nkernel trick to enhance DM2L and establish a concave-convex objective to learn\nthese models. Compared to the other methods, our method involves the fewest\nassumptions and only one hyper-parameter. Even so, extensive experiments show\nthat our method still outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 11:49:58 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ma", "Zhongchen", ""], ["Chen", "Songcan", ""]]}, {"id": "2004.03955", "submitter": "Gang Liu", "authors": "Gang Liu and Jing Wang", "title": "Dendrite Net: A White-Box Module for Classification, Regression, and\n  System Identification", "comments": "Dendrite (DD)---A new \"block\" since decades. Renamed DD for avoiding\n  confusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a basic machine learning algorithm, named Dendrite Net or\nDD, just like Support Vector Machine (SVM) or Multilayer Perceptron (MLP). DD's\nmain concept is that the algorithm can recognize this class after learning, if\nthe output's logical expression contains the corresponding class's logical\nrelationship among inputs ($ and \\backslash or \\backslash not $). Experiments\nand results: DD, the first white-box machine learning algorithm, showed\nexcellent system identification performance for the black-box system. Secondly,\nit was verified by nine real-world applications that DD brought better\ngeneralization capability relative to MLP architecture that imitated neurons'\ncell body (Cell body Net) for regression. Thirdly, by MNIST and FASHION-MNIST\ndatasets, it was verified that DD showed higher testing accuracy under greater\ntraining loss than Cell body Net for classification. The number of modules can\neffectively adjust DD's logical expression capacity, which avoids over-fitting\nand makes it easy to get a model with outstanding generalization capability.\nFinally, repeated experiments in $ MATLAB $ and $ PyTorch $ ($ Python $)\ndemonstrated that DD was faster than Cell body Net both in epoch and\nforward-propagation. We highlight DD's white-box attribute, controllable\nprecision for better generalization capability, and lower computational\ncomplexity. Not only can DD be used for generalized engineering, but DD has\nvast development potential as a module for deep learning. DD code is available\nat https://github.com/liugang1234567/Gang-neuron.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 12:02:16 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 10:22:57 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 18:46:11 GMT"}, {"version": "v4", "created": "Mon, 28 Sep 2020 08:09:26 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 07:54:57 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Liu", "Gang", ""], ["Wang", "Jing", ""]]}, {"id": "2004.03959", "submitter": "Nicholas Baskerville", "authors": "Nicholas P. Baskerville, Jonathan P. Keating, Francesco Mezzadri,\n  Joseph Najnudel", "title": "The Loss Surfaces of Neural Networks with General Activation Functions", "comments": "50 pages, 11 figures; references added for Kac-Rice reduction to RMT\n  method; updates following JSTAT review and publication", "journal-ref": null, "doi": "10.1088/1742-5468/abfa1e", "report-no": null, "categories": "math.PR cond-mat.stat-mech cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The loss surfaces of deep neural networks have been the subject of several\nstudies, theoretical and experimental, over the last few years. One strand of\nwork considers the complexity, in the sense of local optima, of high\ndimensional random functions with the aim of informing how local optimisation\nmethods may perform in such complicated settings. Prior work of Choromanska et\nal (2015) established a direct link between the training loss surfaces of deep\nmulti-layer perceptron networks and spherical multi-spin glass models under\nsome very strong assumptions on the network and its data. In this work, we test\nthe validity of this approach by removing the undesirable restriction to ReLU\nactivation functions. In doing so, we chart a new path through the spin glass\ncomplexity calculations using supersymmetric methods in Random Matrix Theory\nwhich may prove useful in other contexts. Our results shed new light on both\nthe strengths and the weaknesses of spin glass models in this context.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 12:19:25 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 17:11:55 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 07:08:49 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Baskerville", "Nicholas P.", ""], ["Keating", "Jonathan P.", ""], ["Mezzadri", "Francesco", ""], ["Najnudel", "Joseph", ""]]}, {"id": "2004.03960", "submitter": "Mohammed K Alzaylaee Dr", "authors": "Suleiman Y. Yerima and Mohammed K. Alzaylaee", "title": "High Accuracy Phishing Detection Based on Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The persistent growth in phishing and the rising volume of phishing websites\nhas led to individuals and organizations worldwide becoming increasingly\nexposed to various cyber-attacks. Consequently, more effective phishing\ndetection is required for improved cyber defence. Hence, in this paper we\npresent a deep learning-based approach to enable high accuracy detection of\nphishing sites. The proposed approach utilizes convolutional neural networks\n(CNN) for high accuracy classification to distinguish genuine sites from\nphishing sites. We evaluate the models using a dataset obtained from 6,157\ngenuine and 4,898 phishing websites. Based on the results of extensive\nexperiments, our CNN based models proved to be highly effective in detecting\nunknown phishing sites. Furthermore, the CNN based approach performed better\nthan traditional machine learning classifiers evaluated on the same dataset,\nreaching 98.2% phishing detection rate with an F1-score of 0.976. The method\npresented in this paper compares favourably to the state-of-the art in deep\nlearning based phishing website detection.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 12:20:14 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Yerima", "Suleiman Y.", ""], ["Alzaylaee", "Mohammed K.", ""]]}, {"id": "2004.03961", "submitter": "Jianwei Liu", "authors": "Jianwei Liu, Jinsong Han, Feng Lin, Kui Ren", "title": "Adversary Helps: Gradient-based Device-Free Domain-Independent Gesture\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless signal-based gesture recognition has promoted the developments of VR\ngame, smart home, etc. However, traditional approaches suffer from the\ninfluence of the domain gap. Low recognition accuracy occurs when the\nrecognition model is trained in one domain but is used in another domain.\nThough some solutions, such as adversarial learning, transfer learning and\nbody-coordinate velocity profile, have been proposed to achieve cross-domain\nrecognition, these solutions more or less have flaws. In this paper, we define\nthe concept of domain gap and then propose a more promising solution, namely\nDI, to eliminate domain gap and further achieve domain-independent gesture\nrecognition. DI leverages the sign map of the gradient map as the domain gap\neliminator to improve the recognition accuracy. We conduct experiments with ten\ndomains and ten gestures. The experiment results show that DI can achieve the\nrecognition accuracies of 87.13%, 90.12% and 94.45% on KNN, SVM and CNN, which\noutperforms existing solutions.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 12:20:44 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Liu", "Jianwei", ""], ["Han", "Jinsong", ""], ["Lin", "Feng", ""], ["Ren", "Kui", ""]]}, {"id": "2004.03985", "submitter": "Xavier Favory", "authors": "Xavier Favory, Frederic Font and Xavier Serra", "title": "Search Result Clustering in Collaborative Sound Collections", "comments": "8 pages, 4 figures, Proceedings of the 2020 International Conference\n  on Multimedia Retrieval (ICMR 20), June 8-11, 2020, Dublin, Ireland. ACM,\n  NewYork, NY, USA, 8 pages", "journal-ref": null, "doi": "10.1145/3372278.3390691", "report-no": null, "categories": "cs.IR cs.HC cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large size of nowadays' online multimedia databases makes retrieving\ntheir content a difficult and time-consuming task. Users of online sound\ncollections typically submit search queries that express a broad intent, often\nmaking the system return large and unmanageable result sets. Search Result\nClustering is a technique that organises search-result content into coherent\ngroups, which allows users to identify useful subsets in their results.\nObtaining coherent and distinctive clusters that can be explored with a\nsuitable interface is crucial for making this technique a useful complement of\ntraditional search engines. In our work, we propose a graph-based approach\nusing audio features for clustering diverse sound collections obtained when\nquerying large online databases. We propose an approach to assess the\nperformance of different features at scale, by taking advantage of the metadata\nassociated with each sound. This analysis is complemented with an evaluation\nusing ground-truth labels from manually annotated datasets. We show that using\na confidence measure for discarding inconsistent clusters improves the quality\nof the partitions. After identifying the most appropriate features for\nclustering, we conduct an experiment with users performing a sound design task,\nin order to evaluate our approach and its user interface. A qualitative\nanalysis is carried out including usability questionnaires and semi-structured\ninterviews. This provides us with valuable new insights regarding the features\nthat promote efficient interaction with the clusters.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:08:17 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Favory", "Xavier", ""], ["Font", "Frederic", ""], ["Serra", "Xavier", ""]]}, {"id": "2004.03990", "submitter": "Erik Thiede", "authors": "Erik Henning Thiede, Truong Son Hy, and Risi Kondor", "title": "The general theory of permutation equivarant neural networks and higher\n  order graph variational encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on symmetric group equivariant neural networks generally only\nconsidered the case where the group acts by permuting the elements of a single\nvector. In this paper we derive formulae for general permutation equivariant\nlayers, including the case where the layer acts on matrices by permuting their\nrows and columns simultaneously. This case arises naturally in graph learning\nand relation learning applications. As a specific case of higher order\npermutation equivariant networks, we present a second order graph variational\nencoder, and show that the latent distribution of equivariant generative models\nmust be exchangeable. We demonstrate the efficacy of this architecture on the\ntasks of link prediction in citation graphs and molecular graph generation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:29:56 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Thiede", "Erik Henning", ""], ["Hy", "Truong Son", ""], ["Kondor", "Risi", ""]]}, {"id": "2004.03991", "submitter": "Karl Stratos", "authors": "Karl Stratos, Sam Wiseman", "title": "Learning Discrete Structured Representations by Adversarially Maximizing\n  Mutual Information", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose learning discrete structured representations from unlabeled data\nby maximizing the mutual information between a structured latent variable and a\ntarget variable. Calculating mutual information is intractable in this setting.\nOur key technical contribution is an adversarial objective that can be used to\ntractably estimate mutual information assuming only the feasibility of cross\nentropy calculation. We develop a concrete realization of this general\nformulation with Markov distributions over binary encodings. We report critical\nand unexpected findings on practical aspects of the objective such as the\nchoice of variational priors. We apply our model on document hashing and show\nthat it outperforms current best baselines based on discrete and vector\nquantized variational autoencoders. It also yields highly compressed\ninterpretable representations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:31:53 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 18:03:23 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Stratos", "Karl", ""], ["Wiseman", "Sam", ""]]}, {"id": "2004.03994", "submitter": "Rahul Ragesh", "authors": "Rahul Ragesh, Sundararajan Sellamanickam, Vijay Lingam and Arun Iyer", "title": "A Graph Convolutional Network Composition Framework for Semi-supervised\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks (GCNs) have gained popularity due to high\nperformance achievable on several downstream tasks including node\nclassification. Several architectural variants of these networks have been\nproposed and investigated with experimental studies in the literature.\nMotivated by a recent work on simplifying GCNs, we study the problem of\ndesigning other variants and propose a framework to compose networks using\nbuilding blocks of GCN. The framework offers flexibility to compose and\nevaluate different networks using feature and/or label propagation networks,\nlinear or non-linear networks, with each composition having different\ncomputational complexity. We conduct a detailed experimental study on several\nbenchmark datasets with many variants and present observations from our\nevaluation. Our empirical experimental results suggest that several newly\ncomposed variants are useful alternatives to consider because they are as\ncompetitive as, or better than the original GCN.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 13:52:09 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ragesh", "Rahul", ""], ["Sellamanickam", "Sundararajan", ""], ["Lingam", "Vijay", ""], ["Iyer", "Arun", ""]]}, {"id": "2004.04006", "submitter": "Yue Wu", "authors": "Yue Wu, Hao Ni, Terence J. Lyons, and Robin L. Hudson", "title": "Signature features with the visibility transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we put the visibility transformation on a clear theoretical\nfooting and show that this transform is able to embed the effect of the\nabsolute position of the data stream into signature features in a unified and\nefficient way. The generated feature set is particularly useful in pattern\nrecognition tasks, for its simplifying role in allowing the signature feature\nset to accommodate nonlinear functions of absolute and relative values.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:24:13 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 11:18:19 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 09:25:50 GMT"}, {"version": "v4", "created": "Thu, 8 Oct 2020 23:26:58 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Wu", "Yue", ""], ["Ni", "Hao", ""], ["Lyons", "Terence J.", ""], ["Hudson", "Robin L.", ""]]}, {"id": "2004.04010", "submitter": "Fahim Dalvi", "authors": "Fahim Dalvi, Hassan Sajjad, Nadir Durrani and Yonatan Belinkov", "title": "Analyzing Redundancy in Pretrained Transformer Models", "comments": "19 Pages, 14 figures, EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based deep NLP models are trained using hundreds of millions of\nparameters, limiting their applicability in computationally constrained\nenvironments. In this paper, we study the cause of these limitations by\ndefining a notion of Redundancy, which we categorize into two classes: General\nRedundancy and Task-specific Redundancy. We dissect two popular pretrained\nmodels, BERT and XLNet, studying how much redundancy they exhibit at a\nrepresentation-level and at a more fine-grained neuron-level. Our analysis\nreveals interesting insights, such as: i) 85% of the neurons across the network\nare redundant and ii) at least 92% of them can be removed when optimizing\ntowards a downstream task. Based on our analysis, we present an efficient\nfeature-based transfer learning procedure, which maintains 97% performance\nwhile using at-most 10% of the original neurons.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:29:23 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:45:07 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dalvi", "Fahim", ""], ["Sajjad", "Hassan", ""], ["Durrani", "Nadir", ""], ["Belinkov", "Yonatan", ""]]}, {"id": "2004.04014", "submitter": "Xu Li", "authors": "Xu Li, Jinghua Zhong, Jianwei Yu, Shoukang Hu, Xixin Wu, Xunying Liu,\n  Helen Meng", "title": "Bayesian x-vector: Bayesian Neural Network based x-vector System for\n  Speaker Verification", "comments": "Accepted by Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker verification systems usually suffer from the mismatch problem between\ntraining and evaluation data, such as speaker population mismatch, the channel\nand environment variations. In order to address this issue, it requires the\nsystem to have good generalization ability on unseen data. In this work, we\nincorporate Bayesian neural networks (BNNs) into the deep neural network (DNN)\nx-vector speaker verification system to improve the system's generalization\nability. With the weight uncertainty modeling provided by BNNs, we expect the\nsystem could generalize better on the evaluation data and make verification\ndecisions more accurately. Our experiment results indicate that the DNN\nx-vector system could benefit from BNNs especially when the mismatch problem is\nsevere for evaluations using out-of-domain data. Specifically, results show\nthat the system could benefit from BNNs by a relative EER decrease of 2.66% and\n2.32% respectively for short- and long-utterance in-domain evaluations.\nAdditionally, the fusion of DNN x-vector and Bayesian x-vector systems could\nachieve further improvement. Moreover, experiments conducted by out-of-domain\nevaluations, e.g. models trained on Voxceleb1 while evaluated on NIST SRE10\ncore test, suggest that BNNs could bring a larger relative EER decrease of\naround 4.69%.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:35:12 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Li", "Xu", ""], ["Zhong", "Jinghua", ""], ["Yu", "Jianwei", ""], ["Hu", "Shoukang", ""], ["Wu", "Xixin", ""], ["Liu", "Xunying", ""], ["Meng", "Helen", ""]]}, {"id": "2004.04019", "submitter": "Mauricio Santillana", "authors": "Dianbo Liu, Leonardo Clemente, Canelle Poirier, Xiyu Ding, Matteo\n  Chinazzi, Jessica T Davis, Alessandro Vespignani, Mauricio Santillana", "title": "A machine learning methodology for real-time forecasting of the\n  2019-2020 COVID-19 outbreak using Internet searches, news alerts, and\n  estimates from mechanistic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a timely and novel methodology that combines disease estimates\nfrom mechanistic models with digital traces, via interpretable machine-learning\nmethodologies, to reliably forecast COVID-19 activity in Chinese provinces in\nreal-time. Specifically, our method is able to produce stable and accurate\nforecasts 2 days ahead of current time, and uses as inputs (a) official health\nreports from Chinese Center Disease for Control and Prevention (China CDC), (b)\nCOVID-19-related internet search activity from Baidu, (c) news media activity\nreported by Media Cloud, and (d) daily forecasts of COVID-19 activity from\nGLEAM, an agent-based mechanistic model. Our machine-learning methodology uses\na clustering technique that enables the exploitation of geo-spatial\nsynchronicities of COVID-19 activity across Chinese provinces, and a data\naugmentation technique to deal with the small number of historical disease\nactivity observations, characteristic of emerging outbreaks. Our model's\npredictive power outperforms a collection of baseline models in 27 out of the\n32 Chinese provinces, and could be easily extended to other geographies\ncurrently affected by the COVID-19 outbreak to help decision makers.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:39:32 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Liu", "Dianbo", ""], ["Clemente", "Leonardo", ""], ["Poirier", "Canelle", ""], ["Ding", "Xiyu", ""], ["Chinazzi", "Matteo", ""], ["Davis", "Jessica T", ""], ["Vespignani", "Alessandro", ""], ["Santillana", "Mauricio", ""]]}, {"id": "2004.04026", "submitter": "Jochen Stiasny", "authors": "Jochen Stiasny, George S. Misyris, Spyros Chatzivasileiadis", "title": "Physics-Informed Neural Networks for Non-linear System Identification\n  for Power System Dynamics", "comments": "6 pages, 8 figures, accepted at IEEE PES PowerTech 2021 Madrid", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Varying power-infeed from converter-based generation units introduces great\nuncertainty on system parameters such as inertia and damping. As a consequence,\nsystem operators face increasing challenges in performing dynamic security\nassessment and taking real-time control actions. Exploiting the widespread\ndeployment of phasor measurement units (PMUs) and aiming at developing a fast\ndynamic state and parameter estimation tool, this paper investigates the\nperformance of Physics-Informed Neural Networks (PINN) for discovering the\nfrequency dynamics of future power systems. PINNs have the potential to address\nchallenges such as the stronger non-linearities of low-inertia systems,\nincreased measurement noise, and limited availability of data. The estimator is\ndemonstrated in several test cases using a 4-bus system, and compared with\nstate of the art algorithms, such as the Unscented Kalman Filter (UKF), to\nassess its performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:50:13 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 17:00:08 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Stiasny", "Jochen", ""], ["Misyris", "George S.", ""], ["Chatzivasileiadis", "Spyros", ""]]}, {"id": "2004.04030", "submitter": "Ayobami Adewale Mr", "authors": "Ayobami E. Adewale and Amnir Hadachi", "title": "Neural Networks Model for Travel Time Prediction Based on ODTravel Time\n  Matrix", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public transportation system commuters are often interested in getting\naccurate travel time information to plan their daily activities. However, this\ninformation is often difficult to predict accurately due to the irregularities\nof road traffic, caused by factors such as weather conditions, road accidents,\nand traffic jams. In this study, two neural network models namely\nmulti-layer(MLP) perceptron and long short-term model(LSTM) are developed for\npredicting link travel time of a busy route with input generated using\nOrigin-Destination travel time matrix derived from a historical GPS dataset.\nThe experiment result showed that both models can make near-accurate\npredictions however, LSTM is more susceptible to noise as time step increases.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 15:01:13 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Adewale", "Ayobami E.", ""], ["Hadachi", "Amnir", ""]]}, {"id": "2004.04037", "submitter": "Lu Hou", "authors": "Lu Hou, Zhiqi Huang, Lifeng Shang, Xin Jiang, Xiao Chen, Qun Liu", "title": "DynaBERT: Dynamic BERT with Adaptive Width and Depth", "comments": "NeurIPS-2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pre-trained language models like BERT, though powerful in many natural\nlanguage processing tasks, are both computation and memory expensive. To\nalleviate this problem, one approach is to compress them for specific tasks\nbefore deployment. However, recent works on BERT compression usually compress\nthe large BERT model to a fixed smaller size. They can not fully satisfy the\nrequirements of different edge devices with various hardware performances. In\nthis paper, we propose a novel dynamic BERT model (abbreviated as DynaBERT),\nwhich can flexibly adjust the size and latency by selecting adaptive width and\ndepth. The training process of DynaBERT includes first training a\nwidth-adaptive BERT and then allowing both adaptive width and depth, by\ndistilling knowledge from the full-sized model to small sub-networks. Network\nrewiring is also used to keep the more important attention heads and neurons\nshared by more sub-networks. Comprehensive experiments under various efficiency\nconstraints demonstrate that our proposed dynamic BERT (or RoBERTa) at its\nlargest size has comparable performance as BERT-base (or RoBERTa-base), while\nat smaller widths and depths consistently outperforms existing BERT compression\nmethods. Code is available at\nhttps://github.com/huawei-noah/Pretrained-Language-Model/tree/master/DynaBERT.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 15:06:28 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 08:51:37 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Hou", "Lu", ""], ["Huang", "Zhiqi", ""], ["Shang", "Lifeng", ""], ["Jiang", "Xin", ""], ["Chen", "Xiao", ""], ["Liu", "Qun", ""]]}, {"id": "2004.04054", "submitter": "Astik Biswas", "authors": "A. Biswas, F. de Wet, E. van der Westhuizen, T.R. Niesler", "title": "Semi-supervised acoustic and language model training for English-isiZulu\n  code-switched speech recognition", "comments": "4th Code-Switch workshop, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of semi-supervised acoustic and language model\ntraining for English-isiZulu code-switched ASR using soap opera speech.\nApproximately 11 hours of untranscribed multilingual speech was transcribed\nautomatically using four bilingual code-switching transcription systems\noperating in English-isiZulu, English-isiXhosa, English-Setswana and\nEnglish-Sesotho. These transcriptions were incorporated into the acoustic and\nlanguage model training sets. Results showed that the TDNN-F acoustic models\nbenefit from the additional semi-supervised data and that even better\nperformance could be achieved by including additional CNN layers. Using these\nCNN-TDNN-F acoustic models, a first iteration of semi-supervised training\nachieved an absolute mixed-language WER reduction of 3.4%, and a further 2.2%\nafter a second iteration. Although the languages in the untranscribed data were\nunknown, the best results were obtained when all automatically transcribed data\nwas used for training and not just the utterances classified as\nEnglish-isiZulu. Despite reducing perplexity, the semi-supervised language\nmodel was not able to improve the ASR performance.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:27:29 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Biswas", "A.", ""], ["de Wet", "F.", ""], ["van der Westhuizen", "E.", ""], ["Niesler", "T. R.", ""]]}, {"id": "2004.04072", "submitter": "Lam Pham", "authors": "Lam Pham, Huy Phan, Ramaswamy Palaniappan, Alfred Mertins, Ian\n  McLoughlin", "title": "CNN-MoE based framework for classification of respiratory anomalies and\n  lung disease detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents and explores a robust deep learning framework for\nauscultation analysis. This aims to classify anomalies in respiratory cycles\nand detect disease, from respiratory sound recordings. The framework begins\nwith front-end feature extraction that transforms input sound into a\nspectrogram representation. Then, a back-end deep learning network is used to\nclassify the spectrogram features into categories of respiratory anomaly cycles\nor diseases. Experiments, conducted over the ICBHI benchmark dataset of\nrespiratory sounds, confirm three main contributions towards respiratory-sound\nanalysis. Firstly, we carry out an extensive exploration of the effect of\nspectrogram type, spectral-time resolution, overlapped/non-overlapped windows,\nand data augmentation on final prediction accuracy. This leads us to propose a\nnovel deep learning system, built on the proposed framework, which outperforms\ncurrent state-of-the-art methods. Finally, we apply a Teacher-Student scheme to\nachieve a trade-off between model performance and model complexity which\nadditionally helps to increase the potential of the proposed framework for\nbuilding real-time applications.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 21:45:06 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:55:28 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Pham", "Lam", ""], ["Phan", "Huy", ""], ["Palaniappan", "Ramaswamy", ""], ["Mertins", "Alfred", ""], ["McLoughlin", "Ian", ""]]}, {"id": "2004.04077", "submitter": "Andrea Cossu", "authors": "Andrea Cossu, Antonio Carta, Davide Bacciu", "title": "Continual Learning with Gated Incremental Memories for sequential data\n  processing", "comments": "Accepted as a conference paper at 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020). Part of 2020 IEEE World Congress on\n  Computational Intelligence (IEEE WCCI 2020)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207550", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn in dynamic, nonstationary environments without\nforgetting previous knowledge, also known as Continual Learning (CL), is a key\nenabler for scalable and trustworthy deployments of adaptive solutions. While\nthe importance of continual learning is largely acknowledged in machine vision\nand reinforcement learning problems, this is mostly under-documented for\nsequence processing tasks. This work proposes a Recurrent Neural Network (RNN)\nmodel for CL that is able to deal with concept drift in input distribution\nwithout forgetting previously acquired knowledge. We also implement and test a\npopular CL approach, Elastic Weight Consolidation (EWC), on top of two\ndifferent types of RNNs. Finally, we compare the performances of our enhanced\narchitecture against EWC and RNNs on a set of standard CL benchmarks, adapted\nto the sequential data processing scenario. Results show the superior\nperformance of our architecture and highlight the need for special solutions\ndesigned to address CL in RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:00:20 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Cossu", "Andrea", ""], ["Carta", "Antonio", ""], ["Bacciu", "Davide", ""]]}, {"id": "2004.04092", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Xiang Gao, Yuan Li, Baolin Peng, Xiujun Li, Yizhe Zhang,\n  Jianfeng Gao", "title": "Optimus: Organizing Sentences via Pre-trained Modeling of a Latent Space", "comments": "Accepted in EMNLP 2020; Code: https://github.com/ChunyuanLI/Optimus\n  Demo: http://aka.ms/optimus", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained effectively, the Variational Autoencoder (VAE) can be both a\npowerful generative model and an effective representation learning framework\nfor natural language. In this paper, we propose the first large-scale language\nVAE model, Optimus. A universal latent embedding space for sentences is first\npre-trained on large text corpus, and then fine-tuned for various language\ngeneration and understanding tasks. Compared with GPT-2, Optimus enables guided\nlanguage generation from an abstract level using the latent vectors. Compared\nwith BERT, Optimus can generalize better on low-resource language understanding\ntasks due to the smooth latent space structure. Extensive experimental results\non a wide range of language tasks demonstrate the effectiveness of Optimus. It\nachieves new state-of-the-art on VAE language modeling benchmarks. We hope that\nour first pre-trained big VAE language model itself and results can help the\nNLP community renew the interests of deep generative models in the era of\nlarge-scale pre-training, and make these principled methods more practical.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:20:18 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 19:11:42 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 00:41:43 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 23:33:10 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Li", "Chunyuan", ""], ["Gao", "Xiang", ""], ["Li", "Yuan", ""], ["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Zhang", "Yizhe", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.04093", "submitter": "Manel Mart\\'inez-Ram\\'on", "authors": "Meenu Ajith, Aswathy Rajendra Kurup, and Manel Mart\\'inez-Ram\\'on", "title": "Time accelerated image super-resolution using shallow residual feature\n  representative network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advances in deep learning indicate significant progress in the\nfield of single image super-resolution. With the advent of these techniques,\nhigh-resolution image with high peak signal to noise ratio (PSNR) and excellent\nperceptual quality can be reconstructed. The major challenges associated with\nexisting deep convolutional neural networks are their computational complexity\nand time; the increasing depth of the networks, often result in high space\ncomplexity. To alleviate these issues, we developed an innovative shallow\nresidual feature representative network (SRFRN) that uses a bicubic\ninterpolated low-resolution image as input and residual representative units\n(RFR) which include serially stacked residual non-linear convolutions.\nFurthermore, the reconstruction of the high-resolution image is done by\ncombining the output of the RFR units and the residual output from the bicubic\ninterpolated LR image. Finally, multiple experiments have been performed on the\nbenchmark datasets and the proposed model illustrates superior performance for\nhigher scales. Besides, this model also exhibits faster execution time compared\nto all the existing approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:17:42 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ajith", "Meenu", ""], ["Kurup", "Aswathy Rajendra", ""], ["Mart\u00ednez-Ram\u00f3n", "Manel", ""]]}, {"id": "2004.04095", "submitter": "Yunqi Cai", "authors": "Yunqi Cai, Lantian Li, Dong Wang and Andrew Abel", "title": "Deep Normalization for Speaker Vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep speaker embedding has demonstrated state-of-the-art performance in\nspeaker recognition tasks. However, one potential issue with this approach is\nthat the speaker vectors derived from deep embedding models tend to be\nnon-Gaussian for each individual speaker, and non-homogeneous for distributions\nof different speakers. These irregular distributions can seriously impact\nspeaker recognition performance, especially with the popular PLDA scoring\nmethod, which assumes homogeneous Gaussian distribution. In this paper, we\nargue that deep speaker vectors require deep normalization, and propose a deep\nnormalization approach based on a novel discriminative normalization flow (DNF)\nmodel. We demonstrate the effectiveness of the proposed approach with\nexperiments using the widely used SITW and CNCeleb corpora. In these\nexperiments, the DNF-based normalization delivered substantial performance\ngains and also showed strong generalization capability in out-of-domain tests.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 09:20:48 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 02:27:10 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Yunqi", ""], ["Li", "Lantian", ""], ["Wang", "Dong", ""], ["Abel", "Andrew", ""]]}, {"id": "2004.04096", "submitter": "Niko Br\\\"ummer", "authors": "Anna Silnova, Niko Br\\\"ummer, Johan Rohdin, Themos Stafylakis,\n  Luk\\'a\\v{s} Burget", "title": "Probabilistic embeddings for speaker diarization", "comments": "Awarded: Jack Godfrey Best Student Paper Award, at Odyssey 2020: The\n  Speaker and Language Recognition Workshop, Tokio", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speaker embeddings (x-vectors) extracted from very short segments of speech\nhave recently been shown to give competitive performance in speaker\ndiarization. We generalize this recipe by extracting from each speech segment,\nin parallel with the x-vector, also a diagonal precision matrix, thus providing\na path for the propagation of information about the quality of the speech\nsegment into a PLDA scoring backend. These precisions quantify the uncertainty\nabout what the values of the embeddings might have been if they had been\nextracted from high quality speech segments. The proposed probabilistic\nembeddings (x-vectors with precisions) are interfaced with the PLDA model by\ntreating the x-vectors as hidden variables and marginalizing them out. We apply\nthe proposed probabilistic embeddings as input to an agglomerative hierarchical\nclustering (AHC) algorithm to do diarization in the DIHARD'19 evaluation set.\nWe compute the full PLDA likelihood 'by the book' for each clustering\nhypothesis that is considered by AHC. We do joint discriminative training of\nthe PLDA parameters and of the probabilistic x-vector extractor. We demonstrate\naccuracy gains relative to a baseline AHC algorithm, applied to traditional\nxvectors (without uncertainty), and which uses averaging of binary\nlog-likelihood-ratios, rather than by-the-book scoring.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:51:01 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 09:25:25 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 06:16:16 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Silnova", "Anna", ""], ["Br\u00fcmmer", "Niko", ""], ["Rohdin", "Johan", ""], ["Stafylakis", "Themos", ""], ["Burget", "Luk\u00e1\u0161", ""]]}, {"id": "2004.04098", "submitter": "Tsun-An Hsieh", "authors": "Tsun-An Hsieh, Hsin-Min Wang, Xugang Lu, and Yu Tsao", "title": "WaveCRN: An Efficient Convolutional Recurrent Neural Network for\n  End-to-end Speech Enhancement", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3040693", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the simple design pipeline, end-to-end (E2E) neural models for speech\nenhancement (SE) have attracted great interest. In order to improve the\nperformance of the E2E model, the locality and temporal sequential properties\nof speech should be efficiently taken into account when modelling. However, in\nmost current E2E models for SE, these properties are either not fully\nconsidered or are too complex to be realized. In this paper, we propose an\nefficient E2E SE model, termed WaveCRN. In WaveCRN, the speech locality feature\nis captured by a convolutional neural network (CNN), while the temporal\nsequential property of the locality feature is modeled by stacked simple\nrecurrent units (SRU). Unlike a conventional temporal sequential model that\nuses a long short-term memory (LSTM) network, which is difficult to\nparallelize, SRU can be efficiently parallelized in calculation with even fewer\nmodel parameters. In addition, in order to more effectively suppress the noise\ncomponents in the input noisy speech, we derive a novel restricted feature\nmasking (RFM) approach that performs enhancement on the feature maps in the\nhidden layers; this is different from the approach that applies the estimated\nratio mask on the noisy spectral features, which is commonly used in speech\nseparation methods. Experimental results on speech denoising and compressed\nspeech restoration tasks confirm that with the lightweight architecture of SRU\nand the feature-mapping-based RFM, WaveCRN performs comparably with other\nstate-of-the-art approaches with notably reduced model complexity and inference\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:48:05 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 15:40:42 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 07:28:32 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Hsieh", "Tsun-An", ""], ["Wang", "Hsin-Min", ""], ["Lu", "Xugang", ""], ["Tsao", "Yu", ""]]}, {"id": "2004.04104", "submitter": "Hieu Nguyen", "authors": "Nguyen Quang Hieu, Tran The Anh, Nguyen Cong Luong, Dusit Niyato, Dong\n  In Kim, Erik Elmroth", "title": "Resource Management for Blockchain-enabled Federated Learning: A Deep\n  Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-enabled Federated Learning (BFL) enables mobile devices to\ncollaboratively train neural network models required by a Machine Learning\nModel Owner (MLMO) while keeping data on the mobile devices. Then, the model\nupdates are stored in the blockchain in a decentralized and reliable manner.\nHowever, the issue of BFL is that the mobile devices have energy and CPU\nconstraints that may reduce the system lifetime and training efficiency. The\nother issue is that the training latency may increase due to the blockchain\nmining process. To address these issues, the MLMO needs to (i) decide how much\ndata and energy that the mobile devices use for the training and (ii) determine\nthe block generation rate to minimize the system latency, energy consumption,\nand incentive cost while achieving the target accuracy for the model. Under the\nuncertainty of the BFL environment, it is challenging for the MLMO to determine\nthe optimal decisions. We propose to use the Deep Reinforcement Learning (DRL)\nto derive the optimal decisions for the MLMO.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:29:19 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 05:51:28 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Hieu", "Nguyen Quang", ""], ["Anh", "Tran The", ""], ["Luong", "Nguyen Cong", ""], ["Niyato", "Dusit", ""], ["Kim", "Dong In", ""], ["Elmroth", "Erik", ""]]}, {"id": "2004.04116", "submitter": "Lorraine Chambers", "authors": "Lorraine Chambers, Mohamed Medhat Gaber, Zahraa S. Abdallah", "title": "DeepStreamCE: A Streaming Approach to Concept Evolution Detection in\n  Deep Neural Networks", "comments": "Submitted to Journal of Machine Learning, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have experimentally demonstrated superior performance\nover other machine learning approaches in decision-making predictions. However,\none major concern is the closed set nature of the classification decision on\nthe trained classes, which can have serious consequences in safety critical\nsystems. When the deep neural network is in a streaming environment, fast\ninterpretation of this classification is required to determine if the\nclassification result is trusted. Un-trusted classifications can occur when the\ninput data to the deep neural network changes over time. One type of change\nthat can occur is concept evolution, where a new class is introduced that the\ndeep neural network was not trained on. In the majority of deep neural network\narchitectures, the only option is to assign this instance to one of the classes\nit was trained on, which would be incorrect. The aim of this research is to\ndetect the arrival of a new class in the stream. Existing work on interpreting\ndeep neural networks often focuses on neuron activations to provide visual\ninterpretation and feature extraction. Our novel approach, coined DeepStreamCE,\nuses streaming approaches for real-time concept evolution detection in deep\nneural networks. DeepStreamCE applies neuron activation reduction using an\nautoencoder and MCOD stream-based clustering in the offline phase. Both outputs\nare used in the online phase to analyse the neuron activations in the evolving\nstream in order to detect concept evolution occurrence in real time. We\nevaluate DeepStreamCE by training VGG16 convolutional neural networks on\ncombinations of data from the CIFAR-10 dataset, holding out some classes to be\nused as concept evolution. For comparison, we apply the data and VGG16 networks\nto an open-set deep network solution - OpenMax. DeepStreamCE outperforms\nOpenMax when identifying concept evolution for our datasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:53:26 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Chambers", "Lorraine", ""], ["Gaber", "Mohamed Medhat", ""], ["Abdallah", "Zahraa S.", ""]]}, {"id": "2004.04120", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Solving the scalarization issues of Advantage-based Reinforcement\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": "10.1016/j.compeleceng.2021.107117", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, some of the issues that arise from the scalarization of the\nmulti-objective optimization problem in the Advantage Actor Critic (A2C)\nreinforcement learning algorithm are investigated. The paper shows how a naive\nscalarization can lead to gradients overlapping. Furthermore, the possibility\nthat the entropy regularization term can be a source of uncontrolled noise is\ndiscussed. With respect to the above issues, a technique to avoid gradient\noverlapping is proposed, while keeping the same loss formulation. Moreover, a\nmethod to avoid the uncontrolled noise, by sampling the actions from\ndistributions with a desired minimum entropy, is investigated. Pilot\nexperiments have been carried out to show how the proposed method speeds up the\ntraining. The proposed approach can be applied to any Advantage-based\nReinforcement Learning algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:03:21 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:58:25 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 14:30:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "2004.04124", "submitter": "Yihuan Mao", "authors": "Yihuan Mao, Yujing Wang, Chufan Wu, Chen Zhang, Yang Wang, Yaming\n  Yang, Quanlu Zhang, Yunhai Tong, Jing Bai", "title": "LadaBERT: Lightweight Adaptation of BERT through Hybrid Model\n  Compression", "comments": "COLING2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT is a cutting-edge language representation model pre-trained by a large\ncorpus, which achieves superior performances on various natural language\nunderstanding tasks. However, a major blocking issue of applying BERT to online\nservices is that it is memory-intensive and leads to unsatisfactory latency of\nuser requests, raising the necessity of model compression. Existing solutions\nleverage the knowledge distillation framework to learn a smaller model that\nimitates the behaviors of BERT. However, the training procedure of knowledge\ndistillation is expensive itself as it requires sufficient training data to\nimitate the teacher model. In this paper, we address this issue by proposing a\nhybrid solution named LadaBERT (Lightweight adaptation of BERT through hybrid\nmodel compression), which combines the advantages of different model\ncompression methods, including weight pruning, matrix factorization and\nknowledge distillation. LadaBERT achieves state-of-the-art accuracy on various\npublic datasets while the training overheads can be reduced by an order of\nmagnitude.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:18:56 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 15:15:11 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Mao", "Yihuan", ""], ["Wang", "Yujing", ""], ["Wu", "Chufan", ""], ["Zhang", "Chen", ""], ["Wang", "Yang", ""], ["Yang", "Yaming", ""], ["Zhang", "Quanlu", ""], ["Tong", "Yunhai", ""], ["Bai", "Jing", ""]]}, {"id": "2004.04136", "submitter": "Michael Laskin", "authors": "Aravind Srinivas, Michael Laskin, Pieter Abbeel", "title": "CURL: Contrastive Unsupervised Representations for Reinforcement\n  Learning", "comments": "First two authors contributed equally, website:\n  https://mishalaskin.github.io/curl code: https://github.com/MishaLaskin/curl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CURL: Contrastive Unsupervised Representations for Reinforcement\nLearning. CURL extracts high-level features from raw pixels using contrastive\nlearning and performs off-policy control on top of the extracted features. CURL\noutperforms prior pixel-based methods, both model-based and model-free, on\ncomplex tasks in the DeepMind Control Suite and Atari Games showing 1.9x and\n1.2x performance gains at the 100K environment and interaction steps benchmarks\nrespectively. On the DeepMind Control Suite, CURL is the first image-based\nalgorithm to nearly match the sample-efficiency of methods that use state-based\nfeatures. Our code is open-sourced and available at\nhttps://github.com/MishaLaskin/curl.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:40:43 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:54:47 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 16:37:04 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 15:34:30 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Srinivas", "Aravind", ""], ["Laskin", "Michael", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2004.04141", "submitter": "Leslie Smith", "authors": "Leslie N. Smith, Adam Conovaloff", "title": "Empirical Perspectives on One-Shot Semi-supervised Learning", "comments": "Short paper with interesting results pointing to further\n  investigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the greatest obstacles in the adoption of deep neural networks for new\napplications is that training the network typically requires a large number of\nmanually labeled training samples. We empirically investigate the scenario\nwhere one has access to large amounts of unlabeled data but require labeling\nonly a single prototypical sample per class in order to train a deep network\n(i.e., one-shot semi-supervised learning). Specifically, we investigate the\nrecent results reported in FixMatch for one-shot semi-supervised learning to\nunderstand the factors that affect and impede high accuracies and reliability\nfor one-shot semi-supervised learning of Cifar-10. For example, we discover\nthat one barrier to one-shot semi-supervised learning for high-performance\nimage classification is the unevenness of class accuracy during the training.\nThese results point to solutions that might enable more widespread adoption of\none-shot semi-supervised training methods for new applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:51:06 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Smith", "Leslie N.", ""], ["Conovaloff", "Adam", ""]]}, {"id": "2004.04143", "submitter": "Junhwa Hur", "authors": "Junhwa Hur, Stefan Roth", "title": "Self-Supervised Monocular Scene Flow Estimation", "comments": "To appear at CVPR 2020 (Oral); a typo corrected in the reference\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene flow estimation has been receiving increasing attention for 3D\nenvironment perception. Monocular scene flow estimation -- obtaining 3D\nstructure and 3D motion from two temporally consecutive images -- is a highly\nill-posed problem, and practical solutions are lacking to date. We propose a\nnovel monocular scene flow method that yields competitive accuracy and\nreal-time performance. By taking an inverse problem view, we design a single\nconvolutional neural network (CNN) that successfully estimates depth and 3D\nmotion simultaneously from a classical optical flow cost volume. We adopt\nself-supervised learning with 3D loss functions and occlusion reasoning to\nleverage unlabeled data. We validate our design choices, including the proxy\nloss and augmentation setup. Our model achieves state-of-the-art accuracy among\nunsupervised/self-supervised learning approaches to monocular scene flow, and\nyields competitive results for the optical flow and monocular depth estimation\nsub-tasks. Semi-supervised fine-tuning further improves the accuracy and yields\npromising results in real-time.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:55:54 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 22:17:10 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Hur", "Junhwa", ""], ["Roth", "Stefan", ""]]}, {"id": "2004.04157", "submitter": "Theerawit Wilaiprasitporn", "authors": "Nannapas Banluesombatkul, Pichayoot Ouppaphan, Pitshaporn Leelaarporn,\n  Payongkit Lakhan, Busarakum Chaitusaney, Nattapong Jaimchariyatam, Ekapol\n  Chuangsuwanich, Wei Chen, Huy Phan, Nat Dilokthanakul and Theerawit\n  Wilaiprasitporn", "title": "MetaSleepLearner: A Pilot Study on Fast Adaptation of Bio-signals-Based\n  Sleep Stage Classifier to New Individual Subject Using Meta-Learning", "comments": "IEEE Journal of Biomedical and Health Informatics (Accepted) (source\n  code is available at https://github.com/IoBT-VISTEC/MetaSleepLearner)", "journal-ref": "IEEE Journal of Biomedical and Health Informatics (2020)", "doi": "10.1109/JBHI.2020.3037693", "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying bio-signals based-sleep stages requires time-consuming and\ntedious labor of skilled clinicians. Deep learning approaches have been\nintroduced in order to challenge the automatic sleep stage classification\nconundrum. However, the difficulties can be posed in replacing the clinicians\nwith the automatic system due to the differences in many aspects found in\nindividual bio-signals, causing the inconsistency in the performance of the\nmodel on every incoming individual. Thus, we aim to explore the feasibility of\nusing a novel approach, capable of assisting the clinicians and lessening the\nworkload. We propose the transfer learning framework, entitled\nMetaSleepLearner, based on Model Agnostic Meta-Learning (MAML), in order to\ntransfer the acquired sleep staging knowledge from a large dataset to new\nindividual subjects. The framework was demonstrated to require the labelling of\nonly a few sleep epochs by the clinicians and allow the remainder to be handled\nby the system. Layer-wise Relevance Propagation (LRP) was also applied to\nunderstand the learning course of our approach. In all acquired datasets, in\ncomparison to the conventional approach, MetaSleepLearner achieved a range of\n5.4\\% to 17.7\\% improvement with statistical difference in the mean of both\napproaches. The illustration of the model interpretation after the adaptation\nto each subject also confirmed that the performance was directed towards\nreasonable learning. MetaSleepLearner outperformed the conventional approaches\nas a result from the fine-tuning using the recordings of both healthy subjects\nand patients. This is the first work that investigated a non-conventional\npre-training method, MAML, resulting in a possibility for human-machine\ncollaboration in sleep stage classification and easing the burden of the\nclinicians in labelling the sleep stages through only several epochs rather\nthan an entire recording.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:31:03 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 15:58:42 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 16:14:44 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 17:08:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Banluesombatkul", "Nannapas", ""], ["Ouppaphan", "Pichayoot", ""], ["Leelaarporn", "Pitshaporn", ""], ["Lakhan", "Payongkit", ""], ["Chaitusaney", "Busarakum", ""], ["Jaimchariyatam", "Nattapong", ""], ["Chuangsuwanich", "Ekapol", ""], ["Chen", "Wei", ""], ["Phan", "Huy", ""], ["Dilokthanakul", "Nat", ""], ["Wilaiprasitporn", "Theerawit", ""]]}, {"id": "2004.04177", "submitter": "Alireza Vafaei Sadr", "authors": "Alireza Vafaei Sadr, Farida Farsian", "title": "Inpainting via Generative Adversarial Networks for CMB data analysis", "comments": "19 pages, 21 figures. Prepared for submission to JCAP. All codes will\n  be published after acceptance", "journal-ref": null, "doi": "10.1088/1475-7516/2021/03/012", "report-no": null, "categories": "astro-ph.CO cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new method to inpaint the CMB signal in regions\nmasked out following a point source extraction process. We adopt a modified\nGenerative Adversarial Network (GAN) and compare different combinations of\ninternal (hyper-)parameters and training strategies. We study the performance\nusing a suitable $\\mathcal{C}_r$ variable in order to estimate the performance\nregarding the CMB power spectrum recovery. We consider a test set where one\npoint source is masked out in each sky patch with a 1.83 $\\times$ 1.83 squared\ndegree extension, which, in our gridding, corresponds to 64 $\\times$ 64 pixels.\nThe GAN is optimized for estimating performance on Planck 2018 total intensity\nsimulations. The training makes the GAN effective in reconstructing a masking\ncorresponding to about 1500 pixels with $1\\%$ error down to angular scales\ncorresponding to about 5 arcminutes.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:00:10 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 07:38:15 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Sadr", "Alireza Vafaei", ""], ["Farsian", "Farida", ""]]}, {"id": "2004.04180", "submitter": "Paul Henderson", "authors": "Paul Henderson, Vagia Tsiminaki, Christoph H. Lampert", "title": "Leveraging 2D Data to Learn Textured 3D Mesh Generation", "comments": "CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous methods have been proposed for probabilistic generative modelling of\n3D objects. However, none of these is able to produce textured objects, which\nrenders them of limited use for practical tasks. In this work, we present the\nfirst generative model of textured 3D meshes. Training such a model would\ntraditionally require a large dataset of textured meshes, but unfortunately,\nexisting datasets of meshes lack detailed textures. We instead propose a new\ntraining methodology that allows learning from collections of 2D images without\nany 3D information. To do so, we train our model to explain a distribution of\nimages by modelling each image as a 3D foreground object placed in front of a\n2D background. Thus, it learns to generate meshes that when rendered, produce\nimages similar to those in its training set.\n  A well-known problem when generating meshes with deep networks is the\nemergence of self-intersections, which are problematic for many use-cases. As a\nsecond contribution we therefore introduce a new generation process for 3D\nmeshes that guarantees no self-intersections arise, based on the physical\nintuition that faces should push one another out of the way as they move.\n  We conduct extensive experiments on our approach, reporting quantitative and\nqualitative results on both synthetic data and natural images. These show our\nmethod successfully learns to generate plausible and diverse textured 3D\nsamples for five challenging object classes.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:00:37 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Henderson", "Paul", ""], ["Tsiminaki", "Vagia", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2004.04192", "submitter": "Elijah Cole", "authors": "Elijah Cole, Benjamin Deneu, Titouan Lorieul, Maximilien Servajean,\n  Christophe Botella, Dan Morris, Nebojsa Jojic, Pierre Bonnet, Alexis Joly", "title": "The GeoLifeCLEF 2020 Dataset", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the geographic distribution of species is a key concern in\nconservation. By pairing species occurrences with environmental features,\nresearchers can model the relationship between an environment and the species\nwhich may be found there. To facilitate research in this area, we present the\nGeoLifeCLEF 2020 dataset, which consists of 1.9 million species observations\npaired with high-resolution remote sensing imagery, land cover data, and\naltitude, in addition to traditional low-resolution climate and soil variables.\nWe also discuss the GeoLifeCLEF 2020 competition, which aims to use this\ndataset to advance the state-of-the-art in location-based species\nrecommendation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:30:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Cole", "Elijah", ""], ["Deneu", "Benjamin", ""], ["Lorieul", "Titouan", ""], ["Servajean", "Maximilien", ""], ["Botella", "Christophe", ""], ["Morris", "Dan", ""], ["Jojic", "Nebojsa", ""], ["Bonnet", "Pierre", ""], ["Joly", "Alexis", ""]]}, {"id": "2004.04198", "submitter": "Kenneth McMIllan", "authors": "Kenneth L. McMillan", "title": "Bayesian Interpolants as Explanations for Neural Inferences", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of Craig interpolant, used as a form of explanation in automated\nreasoning, is adapted from logical inference to statistical inference and used\nto explain inferences made by neural networks. The method produces explanations\nthat are at the same time concise, understandable and precise.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:45:06 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["McMillan", "Kenneth L.", ""]]}, {"id": "2004.04209", "submitter": "Anna Petrovskaia", "authors": "Anna Petrovskaia, Raghavendra B. Jana, Ivan V. Oseledets", "title": "A single image deep learning approach to restoration of corrupted remote\n  sensing products", "comments": "Paper presented at the ICLR 2020 Workshop on Computer Vision for\n  Agriculture (CV4A)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensing images are used for a variety of analyses, from agricultural\nmonitoring, to disaster relief, to resource planning, among others. The images\ncan be corrupted due to a number of reasons, including instrument errors and\nnatural obstacles such as clouds. We present here a novel approach for\nreconstruction of missing information in such cases using only the corrupted\nimage as the input. The Deep Image Prior methodology eliminates the need for a\npre-trained network or an image database. It is shown that the approach easily\nbeats the performance of traditional single-image methods.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:11:32 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Petrovskaia", "Anna", ""], ["Jana", "Raghavendra B.", ""], ["Oseledets", "Ivan V.", ""]]}, {"id": "2004.04221", "submitter": "Lei Xu", "authors": "Lei Xu, Jenni Raitoharju, Alexandros Iosifidis, Moncef Gabbouj", "title": "Saliency-based Weighted Multi-label Linear Discriminant Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new variant of Linear Discriminant Analysis (LDA)\nto solve multi-label classification tasks. The proposed method is based on a\nprobabilistic model for defining the weights of individual samples in a\nweighted multi-label LDA approach. Linear Discriminant Analysis is a classical\nstatistical machine learning method, which aims to find a linear data\ntransformation increasing class discrimination in an optimal discriminant\nsubspace. Traditional LDA sets assumptions related to Gaussian class\ndistributions and single-label data annotations. To employ the LDA technique in\nmulti-label classification problems, we exploit intuitions coming from a\nprobabilistic interpretation of class saliency to redefine the between-class\nand within-class scatter matrices. The saliency-based weights obtained based on\nvarious kinds of affinity encoding prior information are used to reveal the\nprobability of each instance to be salient for each of its classes in the\nmulti-label problem at hand. The proposed Saliency-based weighted Multi-label\nLDA approach is shown to lead to performance improvements in various\nmulti-label classification problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:40:53 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xu", "Lei", ""], ["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2004.04244", "submitter": "Aishwarya Jadhav", "authors": "Aishwarya Jadhav", "title": "Variable Rate Video Compression using a Hybrid Recurrent Convolutional\n  Learning Framework", "comments": null, "journal-ref": "2020 International Conference on Computer Communication and\n  Informatics (ICCCI)", "doi": "10.1109/ICCCI48352.2020.9104085", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural network-based image compression techniques have been\nable to outperform traditional codecs and have opened the gates for the\ndevelopment of learning-based video codecs. However, to take advantage of the\nhigh temporal correlation in videos, more sophisticated architectures need to\nbe employed. This paper presents PredEncoder, a hybrid video compression\nframework based on the concept of predictive auto-encoding that models the\ntemporal correlations between consecutive video frames using a prediction\nnetwork which is then combined with a progressive encoder network to exploit\nthe spatial redundancies. A variable-rate block encoding scheme has been\nproposed in the paper that leads to remarkably high quality to bit-rate ratios.\nBy joint training and fine-tuning of this hybrid architecture, PredEncoder has\nbeen able to gain significant improvement over the MPEG-4 codec and has\nachieved bit-rate savings over the H.264 codec in the low to medium bit-rate\nrange for HD videos and comparable results over most bit-rates for non-HD\nvideos. This paper serves to demonstrate how neural architectures can be\nleveraged to perform at par with the highly optimized traditional methodologies\nin the video compression domain.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 20:49:25 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 20:21:24 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Jadhav", "Aishwarya", ""]]}, {"id": "2004.04249", "submitter": "Mojan Javaheripi", "authors": "Mojan Javaheripi, Mohammad Samragh, Tara Javidi, Farinaz Koushanfar", "title": "GeneCAI: Genetic Evolution for Acquiring Compact AI", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390226", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contemporary big data realm, Deep Neural Networks (DNNs) are evolving\ntowards more complex architectures to achieve higher inference accuracy. Model\ncompression techniques can be leveraged to efficiently deploy such\ncompute-intensive architectures on resource-limited mobile devices. Such\nmethods comprise various hyper-parameters that require per-layer customization\nto ensure high accuracy. Choosing such hyper-parameters is cumbersome as the\npertinent search space grows exponentially with model layers. This paper\nintroduces GeneCAI, a novel optimization method that automatically learns how\nto tune per-layer compression hyper-parameters. We devise a bijective\ntranslation scheme that encodes compressed DNNs to the genotype space. The\noptimality of each genotype is measured using a multi-objective score based on\naccuracy and number of floating point operations. We develop customized genetic\noperations to iteratively evolve the non-dominated solutions towards the\noptimal Pareto front, thus, capturing the optimal trade-off between model\naccuracy and complexity. GeneCAI optimization method is highly scalable and can\nachieve a near-linear performance boost on distributed multi-GPU platforms. Our\nextensive evaluations demonstrate that GeneCAI outperforms existing rule-based\nand reinforcement learning methods in DNN compression by finding models that\nlie on a better accuracy-complexity Pareto curve.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 20:56:37 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 04:35:42 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Javaheripi", "Mojan", ""], ["Samragh", "Mohammad", ""], ["Javidi", "Tara", ""], ["Koushanfar", "Farinaz", ""]]}, {"id": "2004.04250", "submitter": "Zhao Song", "authors": "Haotian Jiang, Yin Tat Lee, Zhao Song, Sam Chiu-wai Wong", "title": "An Improved Cutting Plane Method for Convex Optimization, Convex-Concave\n  Games and its Applications", "comments": "STOC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Given a separation oracle for a convex set $K \\subset \\mathbb{R}^n$ that is\ncontained in a box of radius $R$, the goal is to either compute a point in $K$\nor prove that $K$ does not contain a ball of radius $\\epsilon$. We propose a\nnew cutting plane algorithm that uses an optimal $O(n \\log (\\kappa))$\nevaluations of the oracle and an additional $O(n^2)$ time per evaluation, where\n$\\kappa = nR/\\epsilon$.\n  $\\bullet$ This improves upon Vaidya's $O( \\text{SO} \\cdot n \\log (\\kappa) +\nn^{\\omega+1} \\log (\\kappa))$ time algorithm [Vaidya, FOCS 1989a] in terms of\npolynomial dependence on $n$, where $\\omega < 2.373$ is the exponent of matrix\nmultiplication and $\\text{SO}$ is the time for oracle evaluation.\n  $\\bullet$ This improves upon Lee-Sidford-Wong's $O( \\text{SO} \\cdot n \\log\n(\\kappa) + n^3 \\log^{O(1)} (\\kappa))$ time algorithm [Lee, Sidford and Wong,\nFOCS 2015] in terms of dependence on $\\kappa$.\n  For many important applications in economics, $\\kappa = \\Omega(\\exp(n))$ and\nthis leads to a significant difference between $\\log(\\kappa)$ and\n$\\mathrm{poly}(\\log (\\kappa))$. We also provide evidence that the $n^2$ time\nper evaluation cannot be improved and thus our running time is optimal.\n  A bottleneck of previous cutting plane methods is to compute leverage scores,\na measure of the relative importance of past constraints. Our result is\nachieved by a novel multi-layered data structure for leverage score\nmaintenance, which is a sophisticated combination of diverse techniques such as\nrandom projection, batched low-rank update, inverse maintenance, polynomial\ninterpolation, and fast rectangular matrix multiplication. Interestingly, our\nmethod requires a combination of different fast rectangular matrix\nmultiplication algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 20:56:40 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jiang", "Haotian", ""], ["Lee", "Yin Tat", ""], ["Song", "Zhao", ""], ["Wong", "Sam Chiu-wai", ""]]}, {"id": "2004.04256", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Adrian Flanagan, Were Oyomno, Alexander Grigorievskiy, Kuan Eeik Tan,\n  Suleiman A. Khan, and Muhammad Ammad-Ud-Din", "title": "Federated Multi-view Matrix Factorization for Personalized\n  Recommendations", "comments": "16 pages, 3 figures, 5 tables, submitted to a conference", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2020. Lecture Notes in Computer Science, Springer, Cham", "doi": "10.1007/978-3-030-67661-2_20", "report-no": "12458", "categories": "cs.LG cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the federated multi-view matrix factorization method that\nextends the federated learning framework to matrix factorization with multiple\ndata sources. Our method is able to learn the multi-view model without\ntransferring the user's personal data to a central server. As far as we are\naware this is the first federated model to provide recommendations using\nmulti-view matrix factorization. The model is rigorously evaluated on three\ndatasets on production settings. Empirical validation confirms that federated\nmulti-view matrix factorization outperforms simpler methods that do not take\ninto account the multi-view structure of the data, in addition, it demonstrates\nthe usefulness of the proposed method for the challenging prediction tasks of\ncold-start federated recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:07:50 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Flanagan", "Adrian", ""], ["Oyomno", "Were", ""], ["Grigorievskiy", "Alexander", ""], ["Tan", "Kuan Eeik", ""], ["Khan", "Suleiman A.", ""], ["Ammad-Ud-Din", "Muhammad", ""]]}, {"id": "2004.04272", "submitter": "Jingyun Jia", "authors": "Jingyun Jia", "title": "Deep Learning and Open Set Malware Classification: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Internet is growing rapidly these years, the variant of malicious\nsoftware, which often referred to as malware, has become one of the major and\nserious threats to Internet users. The dramatic increase of malware has led to\na research area of not only using cutting edge machine learning techniques\nclassify malware into their known families, moreover, recognize the unknown\nones, which can be related to Open Set Recognition (OSR) problem in machine\nlearning. Recent machine learning works have shed light on Open Set Recognition\n(OSR) from different scenarios. Under the situation of missing unknown training\nsamples, the OSR system should not only correctly classify the known classes,\nbut also recognize the unknown class. This survey provides an overview of\ndifferent deep learning techniques, a discussion of OSR and graph\nrepresentation solutions and an introduction of malware classification systems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:36:21 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Jia", "Jingyun", ""]]}, {"id": "2004.04276", "submitter": "Marta D'Elia", "authors": "Guofei Pang, Marta D'Elia, Michael Parks, George E. Karniadakis", "title": "nPINNs: nonlocal Physics-Informed Neural Networks for a parametrized\n  nonlocal universal Laplacian operator. Algorithms and Applications", "comments": "31 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": "SAND2020-3980", "categories": "math.AP cs.LG math.OC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-informed neural networks (PINNs) are effective in solving inverse\nproblems based on differential and integral equations with sparse, noisy,\nunstructured, and multi-fidelity data. PINNs incorporate all available\ninformation into a loss function, thus recasting the original problem into an\noptimization problem. In this paper, we extend PINNs to parameter and function\ninference for integral equations such as nonlocal Poisson and nonlocal\nturbulence models, and we refer to them as nonlocal PINNs (nPINNs). The\ncontribution of the paper is three-fold. First, we propose a unified nonlocal\noperator, which converges to the classical Laplacian as one of the operator\nparameters, the nonlocal interaction radius $\\delta$ goes to zero, and to the\nfractional Laplacian as $\\delta$ goes to infinity. This universal operator\nforms a super-set of classical Laplacian and fractional Laplacian operators\nand, thus, has the potential to fit a broad spectrum of data sets. We provide\ntheoretical convergence rates with respect to $\\delta$ and verify them via\nnumerical experiments. Second, we use nPINNs to estimate the two parameters,\n$\\delta$ and $\\alpha$. The strong non-convexity of the loss function yielding\nmultiple (good) local minima reveals the occurrence of the operator mimicking\nphenomenon: different pairs of estimated parameters could produce multiple\nsolutions of comparable accuracy. Third, we propose another nonlocal operator\nwith spatially variable order $\\alpha(y)$, which is more suitable for modeling\nturbulent Couette flow. Our results show that nPINNs can jointly infer this\nfunction as well as $\\delta$. Also, these parameters exhibit a universal\nbehavior with respect to the Reynolds number, a finding that contributes to our\nunderstanding of nonlocal interactions in wall-bounded turbulence.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:48:30 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Pang", "Guofei", ""], ["D'Elia", "Marta", ""], ["Parks", "Michael", ""], ["Karniadakis", "George E.", ""]]}, {"id": "2004.04292", "submitter": "Mark Koren", "authors": "Mark Koren and Mykel J. Kochenderfer", "title": "Adaptive Stress Testing without Domain Heuristics using Go-Explore", "comments": "Accepted to ITSC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning (RL) has been used as a tool for finding\nfailures in autonomous systems. During execution, the RL agents often rely on\nsome domain-specific heuristic reward to guide them towards finding failures,\nbut constructing such a heuristic may be difficult or infeasible. Without a\nheuristic, the agent may only receive rewards at the time of failure, or even\nrewards that guide it away from failures. For example, some approaches give\nrewards for taking more-likely actions, because we want to find more-likely\nfailures. However, the agent may then learn to only take likely actions, and\nmay not be able to find a failure at all. Consequently, the problem becomes a\nhard-exploration problem, where rewards do not aid exploration. A new\nalgorithm, go-explore (GE), has recently set new records on benchmarks from the\nhard-exploration field. We apply GE to adaptive stress testing (AST), one\nexample of an RL-based falsification approach that provides a way to search for\nthe most-likely failure scenario. We simulate a scenario where an autonomous\nvehicle drives while a pedestrian is crossing the road. We demonstrate that GE\nis able to find failures without domain-specific heuristics, such as the\ndistance between the car and the pedestrian, on scenarios that other RL\ntechniques are unable to solve. Furthermore, inspired by the robustification\nphase of GE, we demonstrate that the backwards algorithm (BA) improves the\nfailures found by other RL techniques.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 22:56:59 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:49:28 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Koren", "Mark", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.04293", "submitter": "Mark Koren", "authors": "Mark Koren, Anthony Corso, and Mykel J. Kochenderfer", "title": "The Adaptive Stress Testing Formulation", "comments": "Presented at the Workshop on Robust Autonomy at RSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Validation is a key challenge in the search for safe autonomy. Simulations\nare often either too simple to provide robust validation, or too complex to\ntractably compute. Therefore, approximate validation methods are needed to\ntractably find failures without unsafe simplifications. This paper presents the\ntheory behind one such black-box approach: adaptive stress testing (AST). We\nalso provide three examples of validation problems formulated to work with AST.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 23:04:42 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Koren", "Mark", ""], ["Corso", "Anthony", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.04300", "submitter": "Rahul Chauhan", "authors": "Rahul Kr Chauhan, Ravinder Saharan, Siddhartha Singh, Priti Sharma", "title": "Automated Content Grading Using Machine Learning", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": "10.5281/zenodo.3756789", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grading of examination papers is a hectic, time-labor intensive task and is\noften subjected to inefficiency and bias in checking. This research project is\na primitive experiment in the automation of grading of theoretical answers\nwritten in exams by students in technical courses which yet had continued to be\nhuman graded. In this paper, we show how the algorithmic approach in machine\nlearning can be used to automatically examine and grade theoretical content in\nexam answer papers. Bag of words, their vectors & centroids, and a few semantic\nand lexical text features have been used overall. Machine learning models have\nbeen implemented on datasets manually built from exams given by graduating\nstudents enrolled in technical courses. These models have been compared to show\nthe effectiveness of each model.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 23:46:24 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Chauhan", "Rahul Kr", ""], ["Saharan", "Ravinder", ""], ["Singh", "Siddhartha", ""], ["Sharma", "Priti", ""]]}, {"id": "2004.04306", "submitter": "Colin Cooke", "authors": "Colin L. Cooke, Fanjie Kong, Amey Chaware, Kevin C. Zhou, Kanghyun\n  Kim, Rong Xu, D. Michael Ando, Samuel J. Yang, Pavan Chandra Konda, Roarke\n  Horstmeyer", "title": "Physics-enhanced machine learning for virtual fluorescence microscopy", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method of data-driven microscope design for\nvirtual fluorescence microscopy. Our results show that by including a model of\nillumination within the first layers of a deep convolutional neural network, it\nis possible to learn task-specific LED patterns that substantially improve the\nability to infer fluorescence image information from unstained transmission\nmicroscopy images. We validated our method on two different experimental\nsetups, with different magnifications and different sample types, to show a\nconsistent improvement in performance as compared to conventional illumination\nmethods. Additionally, to understand the importance of learned illumination on\ninference task, we varied the dynamic range of the fluorescent image targets\n(from one to seven bits), and showed that the margin of improvement for learned\npatterns increased with the information content of the target. This work\ndemonstrates the power of programmable optical elements at enabling better\nmachine learning algorithm performance and at providing physical insight into\nnext generation of machine-controlled imaging systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 00:17:00 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 22:19:15 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cooke", "Colin L.", ""], ["Kong", "Fanjie", ""], ["Chaware", "Amey", ""], ["Zhou", "Kevin C.", ""], ["Kim", "Kanghyun", ""], ["Xu", "Rong", ""], ["Ando", "D. Michael", ""], ["Yang", "Samuel J.", ""], ["Konda", "Pavan Chandra", ""], ["Horstmeyer", "Roarke", ""]]}, {"id": "2004.04314", "submitter": "Jie Xu", "authors": "Jie Xu, Heqiang Wang", "title": "Client Selection and Bandwidth Allocation in Wireless Federated Learning\n  Networks: A Long-Term Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies federated learning (FL) in a classic wireless network,\nwhere learning clients share a common wireless link to a coordinating server to\nperform federated model training using their local data. In such wireless\nfederated learning networks (WFLNs), optimizing the learning performance\ndepends crucially on how clients are selected and how bandwidth is allocated\namong the selected clients in every learning round, as both radio and client\nenergy resources are limited. While existing works have made some attempts to\nallocate the limited wireless resources to optimize FL, they focus on the\nproblem in individual learning rounds, overlooking an inherent yet critical\nfeature of federated learning. This paper brings a new long-term perspective to\nresource allocation in WFLNs, realizing that learning rounds are not only\ntemporally interdependent but also have varying significance towards the final\nlearning outcome. To this end, we first design data-driven experiments to show\nthat different temporal client selection patterns lead to considerably\ndifferent learning performance. With the obtained insights, we formulate a\nstochastic optimization problem for joint client selection and bandwidth\nallocation under long-term client energy constraints, and develop a new\nalgorithm that utilizes only currently available wireless channel information\nbut can achieve long-term performance guarantee. Further experiments show that\nour algorithm results in the desired temporal client selection pattern, is\nadaptive to changing network environments and far outperforms benchmarks that\nignore the long-term effect of FL.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 01:06:41 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xu", "Jie", ""], ["Wang", "Heqiang", ""]]}, {"id": "2004.04320", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Ling Liu, Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei,\n  Yanzhao Wu", "title": "TOG: Targeted Adversarial Objectness Gradient Attacks on Real-time\n  Object Detection Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of real-time huge data capturing has pushed the deep\nlearning and data analytic computing to the edge systems. Real-time object\nrecognition on the edge is one of the representative deep neural network (DNN)\npowered edge systems for real-world mission-critical applications, such as\nautonomous driving and augmented reality. While DNN powered object detection\nedge systems celebrate many life-enriching opportunities, they also open doors\nfor misuse and abuse. This paper presents three Targeted adversarial Objectness\nGradient attacks, coined as TOG, which can cause the state-of-the-art deep\nobject detection networks to suffer from object-vanishing, object-fabrication,\nand object-mislabeling attacks. We also present a universal objectness gradient\nattack to use adversarial transferability for black-box attacks, which is\neffective on any inputs with negligible attack time cost, low human\nperceptibility, and particularly detrimental to object detection edge systems.\nWe report our experimental measurements using two benchmark datasets (PASCAL\nVOC and MS COCO) on two state-of-the-art detection algorithms (YOLO and SSD).\nThe results demonstrate serious adversarial vulnerabilities and the compelling\nneed for developing robust object detection systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 01:36:23 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Liu", "Ling", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""], ["Wei", "Wenqi", ""], ["Wu", "Yanzhao", ""]]}, {"id": "2004.04328", "submitter": "Marco Loog", "authors": "Marco Loog, Tom Viering, Alexander Mey, Jesse H. Krijthe, David M.J.\n  Tax", "title": "A Brief Prehistory of Double Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their thought-provoking paper [1], Belkin et al. illustrate and discuss\nthe shape of risk curves in the context of modern high-complexity learners.\nGiven a fixed training sample size $n$, such curves show the risk of a learner\nas a function of some (approximate) measure of its complexity $N$. With $N$ the\nnumber of features, these curves are also referred to as feature curves. A\nsalient observation in [1] is that these curves can display, what they call,\ndouble descent: with increasing $N$, the risk initially decreases, attains a\nminimum, and then increases until $N$ equals $n$, where the training data is\nfitted perfectly. Increasing $N$ even further, the risk decreases a second and\nfinal time, creating a peak at $N=n$. This twofold descent may come as a\nsurprise, but as opposed to what [1] reports, it has not been overlooked\nhistorically. Our letter draws attention to some original, earlier findings, of\ninterest to contemporary machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 09:41:24 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Loog", "Marco", ""], ["Viering", "Tom", ""], ["Mey", "Alexander", ""], ["Krijthe", "Jesse H.", ""], ["Tax", "David M. J.", ""]]}, {"id": "2004.04333", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Ruxin Wang, Rongxiang Zhu, Yunpeng Cai, Hongyan Wu", "title": "HopGAT: Hop-aware Supervision Graph Attention Networks for Sparsely\n  Labeled Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the cost of labeling nodes, classifying a node in a sparsely labeled\ngraph while maintaining the prediction accuracy deserves attention. The key\npoint is how the algorithm learns sufficient information from more neighbors\nwith different hop distances. This study first proposes a hop-aware attention\nsupervision mechanism for the node classification task. A simulated annealing\nlearning strategy is then adopted to balance two learning tasks, node\nclassification and the hop-aware attention coefficients, along the training\ntimeline. Compared with state-of-the-art models, the experimental results\nproved the superior effectiveness of the proposed Hop-aware Supervision Graph\nAttention Networks (HopGAT) model. Especially, for the protein-protein\ninteraction network, in a 40% labeled graph, the performance loss is only 3.9%,\nfrom 98.5% to 94.6%, compared to the fully labeled graph. Extensive experiments\nalso demonstrate the effectiveness of supervised attention coefficient and\nlearning strategies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 02:27:15 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ji", "Chaojie", ""], ["Wang", "Ruxin", ""], ["Zhu", "Rongxiang", ""], ["Cai", "Yunpeng", ""], ["Wu", "Hongyan", ""]]}, {"id": "2004.04342", "submitter": "Yang Yang", "authors": "Adam Golinski, Reza Pourreza, Yang Yang, Guillaume Sautiere, Taco S\n  Cohen", "title": "Feedback Recurrent Autoencoder for Video Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep generative modeling have enabled efficient modeling\nof high dimensional data distributions and opened up a new horizon for solving\ndata compression problems. Specifically, autoencoder based learned image or\nvideo compression solutions are emerging as strong competitors to traditional\napproaches. In this work, We propose a new network architecture, based on\ncommon and well studied components, for learned video compression operating in\nlow latency mode. Our method yields state of the art MS-SSIM/rate performance\non the high-resolution UVG dataset, among both learned video compression\napproaches and classical video compression methods (H.265 and H.264) in the\nrate range of interest for streaming applications. Additionally, we provide an\nanalysis of existing approaches through the lens of their underlying\nprobabilistic graphical models. Finally, we point out issues with temporal\nconsistency and color shift observed in empirical evaluation, and suggest\ndirections forward to alleviate those.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 02:58:07 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Golinski", "Adam", ""], ["Pourreza", "Reza", ""], ["Yang", "Yang", ""], ["Sautiere", "Guillaume", ""], ["Cohen", "Taco S", ""]]}, {"id": "2004.04343", "submitter": "Jo\\~ao Ribeiro", "authors": "Jo\\~ao G. Ribeiro, Frederico S. Felisberto and Isabel C. Neto", "title": "Pruning and Sparsemax Methods for Hierarchical Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces and evaluates two novel Hierarchical Attention Network\nmodels [Yang et al., 2016] - i) Hierarchical Pruned Attention Networks, which\nremove the irrelevant words and sentences from the classification process in\norder to reduce potential noise in the document classification accuracy and ii)\nHierarchical Sparsemax Attention Networks, which replace the Softmax function\nused in the attention mechanism with the Sparsemax [Martins and Astudillo,\n2016], capable of better handling importance distributions where a lot of words\nor sentences have very low probabilities. Our empirical evaluation on the IMDB\nReview for sentiment analysis datasets shows both approaches to be able to\nmatch the results obtained by the current state-of-the-art (without, however,\nany significant benefits). All our source code is made available\nathttps://github.com/jmribeiro/dsl-project.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:56:58 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ribeiro", "Jo\u00e3o G.", ""], ["Felisberto", "Frederico S.", ""], ["Neto", "Isabel C.", ""]]}, {"id": "2004.04361", "submitter": "Abhyuday Jagannatha", "authors": "Abhyuday Jagannatha, Hong Yu", "title": "Calibrating Structured Output Predictors for Natural Language Processing", "comments": "ACL 2020; 9 pages + 4 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of calibrating prediction confidence for output\nentities of interest in natural language processing (NLP) applications. It is\nimportant that NLP applications such as named entity recognition and question\nanswering produce calibrated confidence scores for their predictions,\nespecially if the system is to be deployed in a safety-critical domain such as\nhealthcare. However, the output space of such structured prediction models is\noften too large to adapt binary or multi-class calibration methods directly. In\nthis study, we propose a general calibration scheme for output entities of\ninterest in neural-network based structured prediction models. Our proposed\nmethod can be used with any binary class calibration scheme and a neural\nnetwork model. Additionally, we show that our calibration method can also be\nused as an uncertainty-aware, entity-specific decoding step to improve the\nperformance of the underlying model at no additional training cost or data\nrequirements. We show that our method outperforms current calibration\ntechniques for named-entity-recognition, part-of-speech and question answering.\nWe also improve our model's performance from our decoding step across several\ntasks and benchmark datasets. Our method improves the calibration and model\nperformance on out-of-domain test scenarios as well.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 04:14:46 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 21:28:08 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Jagannatha", "Abhyuday", ""], ["Yu", "Hong", ""]]}, {"id": "2004.04362", "submitter": "Chee-Ming Ting PhD", "authors": "Chee-Ming Ting, S. Balqis Samdin, Meini Tang, Hernando Ombao", "title": "Detecting Dynamic Community Structure in Functional Brain Networks\n  Across Individuals: A Multilayer Approach", "comments": "Main paper: 12 pages, 13 figures. Supplemental file: 16 pages.\n  Accepted for IEEE Trans Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.3030047", "report-no": null, "categories": "cs.LG eess.SP physics.soc-ph q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified statistical framework for characterizing community\nstructure of brain functional networks that captures variation across\nindividuals and evolution over time. Existing methods for community detection\nfocus only on single-subject analysis of dynamic networks; while recent\nextensions to multiple-subjects analysis are limited to static networks. To\novercome these limitations, we propose a multi-subject, Markov-switching\nstochastic block model (MSS-SBM) to identify state-related changes in brain\ncommunity organization over a group of individuals. We first formulate a\nmultilayer extension of SBM to describe the time-dependent, multi-subject brain\nnetworks. We develop a novel procedure for fitting the multilayer SBM that\nbuilds on multislice modularity maximization which can uncover a common\ncommunity partition of all layers (subjects) simultaneously. By augmenting with\na dynamic Markov switching process, our proposed method is able to capture a\nset of distinct, recurring temporal states with respect to inter-community\ninteractions over subjects and the change points between them. Simulation shows\naccurate community recovery and tracking of dynamic community regimes over\nmultilayer networks by the MSS-SBM. Application to task fMRI reveals meaningful\nnon-assortative brain community motifs, e.g., core-periphery structure at the\ngroup level, that are associated with language comprehension and motor\nfunctions suggesting their putative role in complex information integration.\nOur approach detected dynamic reconfiguration of modular connectivity elicited\nby varying task demands and identified unique profiles of intra and\ninter-community connectivity across different task conditions. The proposed\nmultilayer network representation provides a principled way of detecting\nsynchronous, dynamic modularity in brain networks across subjects.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 04:23:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 06:38:07 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 04:53:23 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 07:59:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ting", "Chee-Ming", ""], ["Samdin", "S. Balqis", ""], ["Tang", "Meini", ""], ["Ombao", "Hernando", ""]]}, {"id": "2004.04373", "submitter": "Onur Avci", "authors": "Onur Avci, Osama Abdeljaber, Serkan Kiranyaz, Mohammed Hussein, Moncef\n  Gabbouj, Daniel J. Inman", "title": "A Review of Vibration-Based Damage Detection in Civil Structures: From\n  Traditional Methods to Machine Learning and Deep Learning Applications", "comments": "51 pages, 45 figures, MSSP (Elsevier) submission", "journal-ref": null, "doi": "10.1016/j.ymssp.2020.107077", "report-no": null, "categories": "eess.SP cs.LG stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring structural damage is extremely important for sustaining and\npreserving the service life of civil structures. While successful monitoring\nprovides resolute and staunch information on the health, serviceability,\nintegrity and safety of structures; maintaining continuous performance of a\nstructure depends highly on monitoring the occurrence, formation and\npropagation of damage. Damage may accumulate on structures due to different\nenvironmental and human-induced factors. Numerous monitoring and detection\napproaches have been developed to provide practical means for early warning\nagainst structural damage or any type of anomaly. Considerable effort has been\nput into vibration-based methods, which utilize the vibration response of the\nmonitored structure to assess its condition and identify structural damage.\nMeanwhile, with emerging computing power and sensing technology in the last\ndecade, Machine Learning (ML) and especially Deep Learning (DL) algorithms have\nbecome more feasible and extensively used in vibration-based structural damage\ndetection with elegant performance and often with rigorous accuracy. While\nthere have been multiple review studies published on vibration-based structural\ndamage detection, there has not been a study where the transition from\ntraditional methods to ML and DL methods are described and discussed. This\npaper aims to fulfill this gap by presenting the highlights of the traditional\nmethods and provide a comprehensive review of the most recent applications of\nML and DL algorithms utilized for vibration-based structural damage detection\nin civil structures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 05:39:21 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Avci", "Onur", ""], ["Abdeljaber", "Osama", ""], ["Kiranyaz", "Serkan", ""], ["Hussein", "Mohammed", ""], ["Gabbouj", "Moncef", ""], ["Inman", "Daniel J.", ""]]}, {"id": "2004.04386", "submitter": "Felix Dietrich", "authors": "Felix Dietrich, Or Yair, Rotem Mulayoff, Ronen Talmon, and Ioannis G.\n  Kevrekidis", "title": "Spectral Discovery of Jointly Smooth Features for Multimodal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a spectral method for deriving functions that are\njointly smooth on multiple observed manifolds. This allows us to register\nmeasurements of the same phenomenon by heterogeneous sensors, and to reject\nsensor-specific noise. Our method is unsupervised and primarily consists of two\nsteps. First, using kernels, we obtain a subspace spanning smooth functions on\neach separate manifold. Then, we apply a spectral method to the obtained\nsubspaces and discover functions that are jointly smooth on all manifolds. We\nshow analytically that our method is guaranteed to provide a set of orthogonal\nfunctions that are as jointly smooth as possible, ordered by increasing\nDirichlet energy from the smoothest to the least smooth. In addition, we show\nthat the extracted functions can be efficiently extended to unseen data using\nthe Nystr\\\"{o}m method. We demonstrate the proposed method on both simulated\nand real measured data and compare the results to nonlinear variants of the\nseminal Canonical Correlation Analysis (CCA). Particularly, we show superior\nresults for sleep stage identification. In addition, we show how the proposed\nmethod can be leveraged for finding minimal realizations of parameter spaces of\nnonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:04:02 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 16:24:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Dietrich", "Felix", ""], ["Yair", "Or", ""], ["Mulayoff", "Rotem", ""], ["Talmon", "Ronen", ""], ["Kevrekidis", "Ioannis G.", ""]]}, {"id": "2004.04388", "submitter": "Jogendra Nath Kundu", "authors": "Jogendra Nath Kundu, Naveen Venkat, Ambareesh Revanur, Rahul M V, R.\n  Venkatesh Babu", "title": "Towards Inheritable Models for Open-Set Domain Adaptation", "comments": "CVPR 2020 (Oral). Code available at\n  https://github.com/val-iisc/inheritune", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a tremendous progress in Domain Adaptation (DA) for visual\nrecognition tasks. Particularly, open-set DA has gained considerable attention\nwherein the target domain contains additional unseen categories. Existing\nopen-set DA approaches demand access to a labeled source dataset along with\nunlabeled target instances. However, this reliance on co-existing source and\ntarget data is highly impractical in scenarios where data-sharing is restricted\ndue to its proprietary nature or privacy concerns. Addressing this, we\nintroduce a practical DA paradigm where a source-trained model is used to\nfacilitate adaptation in the absence of the source dataset in future. To this\nend, we formalize knowledge inheritability as a novel concept and propose a\nsimple yet effective solution to realize inheritable models suitable for the\nabove practical paradigm. Further, we present an objective way to quantify\ninheritability to enable the selection of the most suitable source model for a\ngiven target domain, even in the absence of the source data. We provide\ntheoretical insights followed by a thorough empirical evaluation demonstrating\nstate-of-the-art open-set domain adaptation performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:16:30 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kundu", "Jogendra Nath", ""], ["Venkat", "Naveen", ""], ["Revanur", "Ambareesh", ""], ["M", "Rahul", "V"], ["Babu", "R. Venkatesh", ""]]}, {"id": "2004.04391", "submitter": "Benjamin Smith", "authors": "Benjamin Smith, Kevin Cant, Gloria Wang", "title": "Anomaly Detection with SDAE", "comments": "9 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a prominent data preprocessing step in learning\napplications for correction and/or removal of faulty data. Automating this data\ntype with the use of autoencoders could increase the quality of the dataset by\nisolating anomalies that were missed through manual or basic statistical\nanalysis. A Simple, Deep, and Supervised Deep Autoencoder were trained and\ncompared for anomaly detection over the ASHRAE building energy dataset. Given\nthe restricted parameters under which the models were trained, the Deep\nAutoencoder perfoms the best, however, the Supervised Deep Autoencoder\noutperforms the other models in total anomalies detected when considerations\nfor the test datasets are given.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:22:08 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Smith", "Benjamin", ""], ["Cant", "Kevin", ""], ["Wang", "Gloria", ""]]}, {"id": "2004.04393", "submitter": "Jogendra Nath Kundu", "authors": "Jogendra Nath Kundu, Naveen Venkat, Rahul M V, R. Venkatesh Babu", "title": "Universal Source-Free Domain Adaptation", "comments": "CVPR 2020. Code available at https://github.com/val-iisc/usfda", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a strong incentive to develop versatile learning techniques that can\ntransfer the knowledge of class-separability from a labeled source domain to an\nunlabeled target domain in the presence of a domain-shift. Existing domain\nadaptation (DA) approaches are not equipped for practical DA scenarios as a\nresult of their reliance on the knowledge of source-target label-set\nrelationship (e.g. Closed-set, Open-set or Partial DA). Furthermore, almost all\nprior unsupervised DA works require coexistence of source and target samples\neven during deployment, making them unsuitable for real-time adaptation. Devoid\nof such impractical assumptions, we propose a novel two-stage learning process.\n1) In the Procurement stage, we aim to equip the model for future source-free\ndeployment, assuming no prior knowledge of the upcoming category-gap and\ndomain-shift. To achieve this, we enhance the model's ability to reject\nout-of-source distribution samples by leveraging the available source data, in\na novel generative classifier framework. 2) In the Deployment stage, the goal\nis to design a unified adaptation algorithm capable of operating across a wide\nrange of category-gaps, with no access to the previously seen source samples.\nTo this end, in contrast to the usage of complex adversarial training regimes,\nwe define a simple yet effective source-free adaptation objective by utilizing\na novel instance-level weighting mechanism, named as Source Similarity Metric\n(SSM). A thorough evaluation shows the practical usability of the proposed\nlearning framework with superior DA performance even over state-of-the-art\nsource-dependent approaches.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:26:20 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kundu", "Jogendra Nath", ""], ["Venkat", "Naveen", ""], ["M", "Rahul", "V"], ["Babu", "R. Venkatesh", ""]]}, {"id": "2004.04394", "submitter": "Kakeru Mitsuno", "authors": "Kakeru Mitsuno, Junichi Miyao and Takio Kurita", "title": "Hierarchical Group Sparse Regularization for Deep Convolutional Neural\n  Networks", "comments": "Accepted to IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a deep neural network (DNN), the number of the parameters is usually huge\nto get high learning performances. For that reason, it costs a lot of memory\nand substantial computational resources, and also causes overfitting. It is\nknown that some parameters are redundant and can be removed from the network\nwithout decreasing performance. Many sparse regularization criteria have been\nproposed to solve this problem. In a convolutional neural network (CNN), group\nsparse regularizations are often used to remove unnecessary subsets of the\nweights, such as filters or channels. When we apply a group sparse\nregularization for the weights connected to a neuron as a group, each\nconvolution filter is not treated as a target group in the regularization. In\nthis paper, we introduce the concept of hierarchical grouping to solve this\nproblem, and we propose several hierarchical group sparse regularization\ncriteria for CNNs. Our proposed the hierarchical group sparse regularization\ncan treat the weight for the input-neuron or the output-neuron as a group and\nconvolutional filter as a group in the same group to prune the unnecessary\nsubsets of weights. As a result, we can prune the weights more adequately\ndepending on the structure of the network and the number of channels keeping\nhigh performance. In the experiment, we investigate the effectiveness of the\nproposed sparse regularizations through intensive comparison experiments on\npublic datasets with several network architectures. Code is available on\nGitHub: \"https://github.com/K-Mitsuno/hierarchical-group-sparse-regularization\"\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:27:06 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Mitsuno", "Kakeru", ""], ["Miyao", "Junichi", ""], ["Kurita", "Takio", ""]]}, {"id": "2004.04396", "submitter": "Minhyeok Lee", "authors": "Minhyeok Lee and Junhee Seok", "title": "Score-Guided Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Generative Adversarial Network (GAN) that introduces an\nevaluator module using pre-trained networks. The proposed model, called\nscore-guided GAN (ScoreGAN), is trained with an evaluation metric for GANs,\ni.e., the Inception score, as a rough guide for the training of the generator.\nBy using another pre-trained network instead of the Inception network, ScoreGAN\ncircumvents the overfitting of the Inception network in order that generated\nsamples do not correspond to adversarial examples of the Inception network.\nAlso, to prevent the overfitting, the evaluation metrics are employed only as\nan auxiliary role, while the conventional target of GANs is mainly used.\nEvaluated with the CIFAR-10 dataset, ScoreGAN demonstrated an Inception score\nof 10.36$\\pm$0.15, which corresponds to state-of-the-art performance.\nFurthermore, to generalize the effectiveness of ScoreGAN, the model was further\nevaluated with another dataset, i.e., the CIFAR-100; as a result, ScoreGAN\noutperformed the other existing methods, where the Fr\\'echet Inception Distance\n(FID) was 13.98.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:32:43 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 04:27:26 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Lee", "Minhyeok", ""], ["Seok", "Junhee", ""]]}, {"id": "2004.04398", "submitter": "Da Li", "authors": "Da Li, Timothy Hospedales", "title": "Online Meta-Learning for Multi-Source and Semi-Supervised Domain\n  Adaptation", "comments": "ECCV 2020 CR version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) is the topical problem of adapting models from\nlabelled source datasets so that they perform well on target datasets where\nonly unlabelled or partially labelled data is available. Many methods have been\nproposed to address this problem through different ways to minimise the domain\nshift between source and target datasets. In this paper we take an orthogonal\nperspective and propose a framework to further enhance performance by\nmeta-learning the initial conditions of existing DA algorithms. This is\nchallenging compared to the more widely considered setting of few-shot\nmeta-learning, due to the length of the computation graph involved. Therefore\nwe propose an online shortest-path meta-learning framework that is both\ncomputationally tractable and practically effective for improving DA\nperformance. We present variants for both multi-source unsupervised domain\nadaptation (MSDA), and semi-supervised domain adaptation (SSDA). Importantly,\nour approach is agnostic to the base adaptation algorithm, and can be applied\nto improve many techniques. Experimentally, we demonstrate improvements on\nclassic (DANN) and recent (MCD and MME) techniques for MSDA and SSDA, and\nultimately achieve state of the art results on several DA benchmarks including\nthe largest scale DomainNet.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 07:48:22 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 12:55:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Li", "Da", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2004.04412", "submitter": "Christian Meilicke", "authors": "Christian Meilicke, Melisachew Wudage Chekol, Manuel Fink, Heiner\n  Stuckenschmidt", "title": "Reinforced Anytime Bottom Up Rule Learning for Knowledge Graph\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of todays work on knowledge graph completion is concerned with\nsub-symbolic approaches that focus on the concept of embedding a given graph in\na low dimensional vector space. Against this trend, we propose an approach\ncalled AnyBURL that is rooted in the symbolic space. Its core algorithm is\nbased on sampling paths, which are generalized into Horn rules. Previously\npublished results show that the prediction quality of AnyBURL is on the same\nlevel as current state of the art with the additional benefit of offering an\nexplanation for the predicted fact. In this paper, we are concerned with two\nextensions of AnyBURL. Firstly, we change AnyBURLs interpretation of rules from\n$\\Theta$-subsumption into $\\Theta$-subsumption under Object Identity. Secondly,\nwe introduce reinforcement learning to better guide the sampling process. We\nfound out that reinforcement learning helps finding more valuable rules earlier\nin the search process. We measure the impact of both extensions and compare the\nresulting approach with current state of the art approaches. Our results show\nthat AnyBURL outperforms most sub-symbolic methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 08:15:39 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Meilicke", "Christian", ""], ["Chekol", "Melisachew Wudage", ""], ["Fink", "Manuel", ""], ["Stuckenschmidt", "Heiner", ""]]}, {"id": "2004.04418", "submitter": "Elan van Biljon", "authors": "Elan van Biljon, Arnu Pretorius and Julia Kreutzer", "title": "On Optimal Transformer Depth for Low-Resource Language Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have shown great promise as an approach to Neural Machine\nTranslation (NMT) for low-resource languages. However, at the same time,\ntransformer models remain difficult to optimize and require careful tuning of\nhyper-parameters to be useful in this setting. Many NMT toolkits come with a\nset of default hyper-parameters, which researchers and practitioners often\nadopt for the sake of convenience and avoiding tuning. These configurations,\nhowever, have been optimized for large-scale machine translation data sets with\nseveral millions of parallel sentences for European languages like English and\nFrench. In this work, we find that the current trend in the field to use very\nlarge models is detrimental for low-resource languages, since it makes training\nmore difficult and hurts overall performance, confirming previous observations.\nWe see our work as complementary to the Masakhane project (\"Masakhane\" means\n\"We Build Together\" in isiZulu.) In this spirit, low-resource NMT systems are\nnow being built by the community who needs them the most. However, many in the\ncommunity still have very limited access to the type of computational resources\nrequired for building extremely large models promoted by industrial research.\nTherefore, by showing that transformer models perform well (and often best) at\nlow-to-moderate depth, we hope to convince fellow researchers to devote less\ncomputational resources, as well as time, to exploring overly large models\nduring the development of these systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 08:25:02 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 19:42:41 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["van Biljon", "Elan", ""], ["Pretorius", "Arnu", ""], ["Kreutzer", "Julia", ""]]}, {"id": "2004.04423", "submitter": "Heiko Paulheim", "authors": "Ahmad Al Taweel and Heiko Paulheim", "title": "Towards Exploiting Implicit Human Feedback for Improving RDF2vec\n  Embeddings", "comments": "Workshop paper accepted at Deep Learning for Knowledge Graphs\n  Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RDF2vec is a technique for creating vector space embeddings from an RDF\nknowledge graph, i.e., representing each entity in the graph as a vector. It\nfirst creates sequences of nodes by performing random walks on the graph. In a\nsecond step, those sequences are processed by the word2vec algorithm for\ncreating the actual embeddings. In this paper, we explore the use of external\nedge weights for guiding the random walks. As edge weights, transition\nprobabilities between pages in Wikipedia are used as a proxy for the human\nfeedback for the importance of an edge. We show that in some scenarios, RDF2vec\nutilizing those transition probabilities can outperform both RDF2vec based on\nrandom walks as well as the usage of graph internal edge weights.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 08:39:19 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Taweel", "Ahmad Al", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2004.04432", "submitter": "Mizuho Nishio", "authors": "Mizuho Nishio, Sho Koyasu, Shunjiro Noguchi, Takao Kiguchi, Kanako\n  Nakatsu, Thai Akasaka, Hiroki Yamada, Kyo Itoh", "title": "Automatic detection of acute ischemic stroke using non-contrast computed\n  tomography and two-stage deep learning model", "comments": null, "journal-ref": "Computer Methods and Programs in Biomedicine 196 (2020) 105711", "doi": "10.1016/j.cmpb.2020.105711", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Purpose: We aimed to develop and evaluate an automatic acute\nischemic stroke-related (AIS) detection system involving a two-stage deep\nlearning model.\n  Methods: We included 238 cases from two different institutions. AIS-related\nfindings were annotated on each of the 238 sets of head CT images by referring\nto head magnetic resonance imaging (MRI) images in which an MRI examination was\nperformed within 24 h following the CT scan. These 238 annotated cases were\ndivided into a training set including 189 cases and test set including 49\ncases. Subsequently, a two-stage deep learning detection model was constructed\nfrom the training set using the You Only Look Once v3 model and Visual Geometry\nGroup 16 classification model. Then, the two-stage model performed the AIS\ndetection process in the test set. To assess the detection model's results, a\nboard-certified radiologist also evaluated the test set head CT images with and\nwithout the aid of the detection model. The sensitivity of AIS detection and\nnumber of false positives were calculated for the evaluation of the test set\ndetection results. The sensitivity of the radiologist with and without the\nsoftware detection results was compared using the McNemar test. A p-value of\nless than 0.05 was considered statistically significant.\n  Results: For the two-stage model and radiologist without and with the use of\nthe software results, the sensitivity was 37.3%, 33.3%, and 41.3%,\nrespectively, and the number of false positives per one case was 1.265, 0.327,\nand 0.388, respectively. On using the two-stage detection model's results, the\nboard-certified radiologist's detection sensitivity significantly improved\n(p-value = 0.0313).\n  Conclusions: Our detection system involving the two-stage deep learning model\nsignificantly improved the radiologist's sensitivity in AIS detection.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:14:24 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 08:56:01 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nishio", "Mizuho", ""], ["Koyasu", "Sho", ""], ["Noguchi", "Shunjiro", ""], ["Kiguchi", "Takao", ""], ["Nakatsu", "Kanako", ""], ["Akasaka", "Thai", ""], ["Yamada", "Hiroki", ""], ["Itoh", "Kyo", ""]]}, {"id": "2004.04433", "submitter": "Marcel B\\\"uhler", "authors": "Marcel C. B\\\"uhler, Andr\\'es Romero, Radu Timofte", "title": "DeepSEE: Deep Disentangled Semantic Explorative Extreme Super-Resolution", "comments": "19 pages. Supplementary material is available on the project page.\n  Accepted for oral presentation at the 15th Asian Conference on Computer\n  Vision (ACCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Super-resolution (SR) is by definition ill-posed. There are infinitely many\nplausible high-resolution variants for a given low-resolution natural image.\nMost of the current literature aims at a single deterministic solution of\neither high reconstruction fidelity or photo-realistic perceptual quality. In\nthis work, we propose an explorative facial super-resolution framework,\nDeepSEE, for Deep disentangled Semantic Explorative Extreme super-resolution.\nTo the best of our knowledge, DeepSEE is the first method to leverage semantic\nmaps for explorative super-resolution. In particular, it provides control of\nthe semantic regions, their disentangled appearance and it allows a broad range\nof image manipulations. We validate DeepSEE on faces, for up to 32x\nmagnification and exploration of the space of super-resolution. Our code and\nmodels are available at: https://mcbuehler.github.io/DeepSEE/\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:14:42 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 12:55:35 GMT"}, {"version": "v3", "created": "Fri, 2 Oct 2020 08:48:07 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["B\u00fchler", "Marcel C.", ""], ["Romero", "Andr\u00e9s", ""], ["Timofte", "Radu", ""]]}, {"id": "2004.04450", "submitter": "Danial Kamran", "authors": "Danial Kamran, Carlos Fernandez Lopez, Martin Lauer, Christoph Stiller", "title": "Risk-Aware High-level Decisions for Automated Driving at Occluded\n  Intersections with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is nowadays a popular framework for solving different\ndecision making problems in automated driving. However, there are still some\nremaining crucial challenges that need to be addressed for providing more\nreliable policies. In this paper, we propose a generic risk-aware DQN approach\nin order to learn high level actions for driving through unsignalized occluded\nintersections. The proposed state representation provides lane based\ninformation which allows to be used for multi-lane scenarios. Moreover, we\npropose a risk based reward function which punishes risky situations instead of\nonly collision failures. Such rewarding approach helps to incorporate risk\nprediction into our deep Q network and learn more reliable policies which are\nsafer in challenging situations. The efficiency of the proposed approach is\ncompared with a DQN learned with conventional collision based rewarding scheme\nand also with a rule-based intersection navigation policy. Evaluation results\nshow that the proposed approach outperforms both of these methods. It provides\nsafer actions than collision-aware DQN approach and is less overcautious than\nthe rule-based policy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:44:41 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kamran", "Danial", ""], ["Lopez", "Carlos Fernandez", ""], ["Lauer", "Martin", ""], ["Stiller", "Christoph", ""]]}, {"id": "2004.04454", "submitter": "Toshinari Morimoto", "authors": "Toshinari Morimoto, Su-Yun Huang", "title": "TensorProjection Layer: A Tensor-Based Dimensionality Reduction Method\n  in CNN", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dimensionality reduction method applied to\ntensor-structured data as a hidden layer (we call it TensorProjection Layer) in\na convolutional neural network. Our proposed method transforms input tensors\ninto ones with a smaller dimension by projection. The directions of projection\nare viewed as training parameters associated with our proposed layer and\ntrained via a supervised learning criterion such as minimization of the\ncross-entropy loss function. We discuss the gradients of the loss function with\nrespect to the parameters associated with our proposed layer. We also implement\nsimple numerical experiments to evaluate the performance of the\nTensorProjection Layer.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:52:49 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Morimoto", "Toshinari", ""], ["Huang", "Su-Yun", ""]]}, {"id": "2004.04459", "submitter": "Kang-Hun Ahn", "authors": "Woo Seok Lee, Hyunjae Kim, Andrew N. Cleland, and Kang-Hun Ahn", "title": "Fast frequency discrimination and phoneme recognition using a biomimetic\n  membrane coupled to a neural network", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the human ear, the basilar membrane plays a central role in sound\nrecognition. When excited by sound, this membrane responds with a\nfrequency-dependent displacement pattern that is detected and identified by the\nauditory hair cells combined with the human neural system. Inspired by this\nstructure, we designed and fabricated an artificial membrane that produces a\nspatial displacement pattern in response to an audible signal, which we used to\ntrain a convolutional neural network (CNN). When trained with single frequency\ntones, this system can unambiguously distinguish tones closely spaced in\nfrequency. When instead trained to recognize spoken vowels, this system\noutperforms existing methods for phoneme recognition, including the discrete\nFourier transform (DFT), zoom FFT and chirp z-transform, especially when tested\nin short time windows. This sound recognition scheme therefore promises\nsignificant benefits in fast and accurate sound identification compared to\nexisting methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:07:12 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Lee", "Woo Seok", ""], ["Kim", "Hyunjae", ""], ["Cleland", "Andrew N.", ""], ["Ahn", "Kang-Hun", ""]]}, {"id": "2004.04462", "submitter": "Alexandre Boulch", "authors": "Alexandre Boulch, Gilles Puy, and Renaud Marlet", "title": "FKAConv: Feature-Kernel Alignment for Point Cloud Convolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art methods for point cloud processing are based on the\nnotion of point convolution, for which several approaches have been proposed.\nIn this paper, inspired by discrete convolution in image processing, we provide\na formulation to relate and analyze a number of point convolution methods. We\nalso propose our own convolution variant, that separates the estimation of\ngeometry-less kernel weights and their alignment to the spatial support of\nfeatures. Additionally, we define a point sampling strategy for convolution\nthat is both effective and fast. Finally, using our convolution and sampling\nstrategy, we show competitive results on classification and semantic\nsegmentation benchmarks while being time and memory efficient.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:12:45 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 14:48:15 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 10:32:36 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Boulch", "Alexandre", ""], ["Puy", "Gilles", ""], ["Marlet", "Renaud", ""]]}, {"id": "2004.04464", "submitter": "Naoya Takeishi", "authors": "Naoya Takeishi and Yoshinobu Kawahara", "title": "On Anomaly Interpretation via Shapley Values", "comments": "23 pages, 5 figures and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly localization is an essential problem as anomaly detection is. Because\na rigorous localization requires a causal model of a target system, practically\nwe often resort to a relaxed problem of anomaly interpretation, for which we\nare to obtain meaningful attribution of anomaly scores to input features. In\nthis paper, we investigate the use of the Shapley value for anomaly\ninterpretation. We focus on the semi-supervised anomaly detection and newly\npropose a characteristic function, on which the Shapley value is computed,\nspecifically for anomaly scores. The idea of the proposed method is\napproximating the absence of some features by minimizing an anomaly score with\nregard to them. We examine the performance of the proposed method as well as\nother general approaches to computing the Shapley value in interpreting anomaly\nscores. We show the results of experiments on multiple datasets and anomaly\ndetection methods, which indicate the usefulness of the Shapley-based anomaly\ninterpretation toward anomaly localization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:27:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Takeishi", "Naoya", ""], ["Kawahara", "Yoshinobu", ""]]}, {"id": "2004.04467", "submitter": "Stanislav Pidhorskyi", "authors": "Stanislav Pidhorskyi, Donald Adjeroh, Gianfranco Doretto", "title": "Adversarial Latent Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder networks are unsupervised approaches aiming at combining\ngenerative and representational properties by learning simultaneously an\nencoder-generator map. Although studied extensively, the issues of whether they\nhave the same generative power of GANs, or learn disentangled representations,\nhave not been fully addressed. We introduce an autoencoder that tackles these\nissues jointly, which we call Adversarial Latent Autoencoder (ALAE). It is a\ngeneral architecture that can leverage recent improvements on GAN training\nprocedures. We designed two autoencoders: one based on a MLP encoder, and\nanother based on a StyleGAN generator, which we call StyleALAE. We verify the\ndisentanglement properties of both architectures. We show that StyleALAE can\nnot only generate 1024x1024 face images with comparable quality of StyleGAN,\nbut at the same resolution can also produce face reconstructions and\nmanipulations based on real images. This makes ALAE the first autoencoder able\nto compare with, and go beyond the capabilities of a generator-only type of\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:33:44 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Pidhorskyi", "Stanislav", ""], ["Adjeroh", "Donald", ""], ["Doretto", "Gianfranco", ""]]}, {"id": "2004.04479", "submitter": "Ivan Y. Tyukin", "authors": "Ivan Y. Tyukin, Desmond J. Higham, and Alexander N. Gorban", "title": "On Adversarial Examples and Stealth Attacks in Artificial Intelligence\n  Systems", "comments": null, "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020", "doi": "10.1109/IJCNN48605.2020.9207472", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a formal theoretical framework for assessing and\nanalyzing two classes of malevolent action towards generic Artificial\nIntelligence (AI) systems. Our results apply to general multi-class classifiers\nthat map from an input space into a decision space, including artificial neural\nnetworks used in deep learning applications. Two classes of attacks are\nconsidered. The first class involves adversarial examples and concerns the\nintroduction of small perturbations of the input data that cause\nmisclassification. The second class, introduced here for the first time and\nnamed stealth attacks, involves small perturbations to the AI system itself.\nHere the perturbed system produces whatever output is desired by the attacker\non a specific small data set, perhaps even a single input, but performs as\nnormal on a validation set (which is unknown to the attacker). We show that in\nboth cases, i.e., in the case of an attack based on adversarial examples and in\nthe case of a stealth attack, the dimensionality of the AI's decision-making\nspace is a major contributor to the AI's susceptibility. For attacks based on\nadversarial examples, a second crucial parameter is the absence of local\nconcentrations in the data probability distribution, a property known as\nSmeared Absolute Continuity. According to our findings, robustness to\nadversarial examples requires either (a) the data distributions in the AI's\nfeature space to have concentrated probability density functions or (b) the\ndimensionality of the AI's decision variables to be sufficiently small. We also\nshow how to construct stealth attacks on high-dimensional AI systems that are\nhard to spot unless the validation set is made exponentially large.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:56:53 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tyukin", "Ivan Y.", ""], ["Higham", "Desmond J.", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2004.04491", "submitter": "Shidong Wang", "authors": "S. Wang, Y. Guan, L. Shao", "title": "Multi-Granularity Canonical Appearance Pooling for Remote Sensing Scene\n  Classification", "comments": "This paper is going to be published by IEEE Transactions on Image\n  Processing", "journal-ref": "IEEE Transactions on Image Processing 29, 5396--5407 (2020)", "doi": "10.1109/TIP.2020.2983560", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognising remote sensing scene images remains challenging due to large\nvisual-semantic discrepancies. These mainly arise due to the lack of detailed\nannotations that can be employed to align pixel-level representations with\nhigh-level semantic labels. As the tagging process is labour-intensive and\nsubjective, we hereby propose a novel Multi-Granularity Canonical Appearance\nPooling (MG-CAP) to automatically capture the latent ontological structure of\nremote sensing datasets. We design a granular framework that allows\nprogressively cropping the input image to learn multi-grained features. For\neach specific granularity, we discover the canonical appearance from a set of\npre-defined transformations and learn the corresponding CNN features through a\nmaxout-based Siamese style architecture. Then, we replace the standard CNN\nfeatures with Gaussian covariance matrices and adopt the proper matrix\nnormalisations for improving the discriminative power of features. Besides, we\nprovide a stable solution for training the eigenvalue-decomposition function\n(EIG) in a GPU and demonstrate the corresponding back-propagation using matrix\ncalculus. Extensive experiments have shown that our framework can achieve\npromising results in public remote sensing scene datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 11:24:00 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Wang", "S.", ""], ["Guan", "Y.", ""], ["Shao", "L.", ""]]}, {"id": "2004.04520", "submitter": "Jun Li", "authors": "Jun Li, Hongfu Liu, Zhiqiang Tao, Handong Zhao, and Yun Fu", "title": "Learnable Subspace Clustering", "comments": "IEEE Transactions on Neural Networks and Learning Systems (accepted\n  with minor revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the large-scale subspace clustering (LSSC) problem with\nmillion data points. Many popular subspace clustering methods cannot directly\nhandle the LSSC problem although they have been considered as state-of-the-art\nmethods for small-scale data points. A basic reason is that these methods often\nchoose all data points as a big dictionary to build huge coding models, which\nresults in a high time and space complexity. In this paper, we develop a\nlearnable subspace clustering paradigm to efficiently solve the LSSC problem.\nThe key idea is to learn a parametric function to partition the\nhigh-dimensional subspaces into their underlying low-dimensional subspaces\ninstead of the expensive costs of the classical coding models. Moreover, we\npropose a unified robust predictive coding machine (RPCM) to learn the\nparametric function, which can be solved by an alternating minimization\nalgorithm. In addition, we provide a bounded contraction analysis of the\nparametric function. To the best of our knowledge, this paper is the first work\nto efficiently cluster millions of data points among the subspace clustering\nmethods. Experiments on million-scale datasets verify that our paradigm\noutperforms the related state-of-the-art methods in both efficiency and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 12:53:28 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Li", "Jun", ""], ["Liu", "Hongfu", ""], ["Tao", "Zhiqiang", ""], ["Zhao", "Handong", ""], ["Fu", "Yun", ""]]}, {"id": "2004.04523", "submitter": "P\\'adraig Cunningham", "authors": "Padraig Cunningham, Sarah Jane Delany", "title": "k-Nearest Neighbour Classifiers: 2nd Edition (with Python examples)", "comments": "22 pages, 15 figures: An updated edition of an older tutorial on kNN", "journal-ref": null, "doi": "10.1145/3459665", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps the most straightforward classifier in the arsenal or machine\nlearning techniques is the Nearest Neighbour Classifier -- classification is\nachieved by identifying the nearest neighbours to a query example and using\nthose neighbours to determine the class of the query. This approach to\nclassification is of particular importance because issues of poor run-time\nperformance is not such a problem these days with the computational power that\nis available. This paper presents an overview of techniques for Nearest\nNeighbour classification focusing on; mechanisms for assessing similarity\n(distance), computational issues in identifying nearest neighbours and\nmechanisms for reducing the dimension of the data.\n  This paper is the second edition of a paper previously published as a\ntechnical report. Sections on similarity measures for time-series, retrieval\nspeed-up and intrinsic dimensionality have been added. An Appendix is included\nproviding access to Python code for the key methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 13:00:05 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 11:07:06 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cunningham", "Padraig", ""], ["Delany", "Sarah Jane", ""]]}, {"id": "2004.04546", "submitter": "Laetitia Teodorescu", "authors": "Laetitia Teodorescu, Katja Hofmann, and Pierre-Yves Oudeyer", "title": "SpatialSim: Recognizing Spatial Configurations of Objects with Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing precise geometrical configurations of groups of objects is a key\ncapability of human spatial cognition, yet little studied in the deep learning\nliterature so far. In particular, a fundamental problem is how a machine can\nlearn and compare classes of geometric spatial configurations that are\ninvariant to the point of view of an external observer. In this paper we make\ntwo key contributions. First, we propose SpatialSim (Spatial Similarity), a\nnovel geometrical reasoning benchmark, and argue that progress on this\nbenchmark would pave the way towards a general solution to address this\nchallenge in the real world. This benchmark is composed of two tasks:\nIdentification and Comparison, each one instantiated in increasing levels of\ndifficulty. Secondly, we study how relational inductive biases exhibited by\nfully-connected message-passing Graph Neural Networks (MPGNNs) are useful to\nsolve those tasks, and show their advantages over less relational baselines\nsuch as Deep Sets and unstructured models such as Multi-Layer Perceptrons.\nFinally, we highlight the current limits of GNNs in these tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:13:20 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 18:16:31 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Teodorescu", "Laetitia", ""], ["Hofmann", "Katja", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "2004.04548", "submitter": "Phong Nguyen-Ha", "authors": "Phong Nguyen-Ha, Lam Huynh, Esa Rahtu, Janne Heikkila", "title": "Sequential View Synthesis with Transformer", "comments": "Code is available at: https://github.com/phongnhhn92/TransformerGQN;\n  Supplementary material: https://bit.ly/3kEgnzU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of novel view synthesis by means of neural\nrendering, where we are interested in predicting the novel view at an arbitrary\ncamera pose based on a given set of input images from other viewpoints. Using\nthe known query pose and input poses, we create an ordered set of observations\nthat leads to the target view. Thus, the problem of single novel view synthesis\nis reformulated as a sequential view prediction task. In this paper, the\nproposed Transformer-based Generative Query Network (T-GQN) extends the\nneural-rendering methods by adding two new concepts. First, we use multi-view\nattention learning between context images to obtain multiple implicit scene\nrepresentations. Second, we introduce a sequential rendering decoder to predict\nan image sequence, including the target view, based on the learned\nrepresentations. Finally, we evaluate our model on various challenging datasets\nand demonstrate that our model not only gives consistent predictions but also\ndoesn't require any retraining for finetuning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:15:27 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 08:53:28 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Nguyen-Ha", "Phong", ""], ["Huynh", "Lam", ""], ["Rahtu", "Esa", ""], ["Heikkila", "Janne", ""]]}, {"id": "2004.04552", "submitter": "Ga\\\"el Poux-M\\'edard", "authors": "Ga\\\"el Poux-M\\'edard, Julien Velcin, Sabine Loudcher", "title": "Interactions in information spread: quantification and interpretation\n  using stochastic block models", "comments": "17 pages, 3 figures, submitted to ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most real-world applications, it is seldom the case that a given\nobservable evolves independently of its environment. In social networks, users'\nbehavior results from the people they interact with, news in their feed, or\ntrending topics. In natural language, the meaning of phrases emerges from the\ncombination of words. In general medicine, a diagnosis is established on the\nbasis of the interaction of symptoms. Here, we propose a new model, the\nInteractive Mixed Membership Stochastic Block Model (IMMSBM), which\ninvestigates the role of interactions between entities (hashtags, words, memes,\netc.) and quantifies their importance within the aforementioned corpora. We\nfind that interactions play an important role in those corpora. In inference\ntasks, taking them into account leads to average relative changes with respect\nto non-interactive models of up to 150\\% in the probability of an outcome.\nFurthermore, their role greatly improves the predictive power of the model. Our\nfindings suggest that neglecting interactions when modeling real-world\nphenomena might lead to incorrect conclusions being drawn.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:22:10 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:33:48 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Poux-M\u00e9dard", "Ga\u00ebl", ""], ["Velcin", "Julien", ""], ["Loudcher", "Sabine", ""]]}, {"id": "2004.04555", "submitter": "Lexing Ying", "authors": "Lexing Ying", "title": "Mirror Descent Algorithms for Minimizing Interacting Free Energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note considers the problem of minimizing interacting free energy.\nMotivated by the mirror descent algorithm, for a given interacting free energy,\nwe propose a descent dynamics with a novel metric that takes into consideration\nthe reference measure and the interacting term. This metric naturally suggests\na monotone reparameterization of the probability measure. By discretizing the\nreparameterized descent dynamics with the explicit Euler method, we arrive at a\nnew mirror-descent-type algorithm for minimizing interacting free energy.\nNumerical results are included to demonstrate the efficiency of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 07:52:14 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ying", "Lexing", ""]]}, {"id": "2004.04571", "submitter": "Anthony Constantinou", "authors": "Anthony Constantinou", "title": "Learning Bayesian Networks that enable full propagation of evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds on recent developments in Bayesian network (BN) structure\nlearning under the controversial assumption that the input variables are\ndependent. This assumption can be viewed as a learning constraint geared\ntowards cases where the input variables are known or assumed to be dependent.\nIt addresses the problem of learning multiple disjoint subgraphs that do not\nenable full propagation of evidence. This problem is highly prevalent in cases\nwhere the sample size of the input data is low with respect to the\ndimensionality of the model, which is often the case when working with real\ndata. The paper presents a novel hybrid structure learning algorithm, called\nSaiyanH, that addresses this issue. The results show that this constraint helps\nthe algorithm to estimate the number of true edges with higher accuracy\ncompared to the state-of-the-art. Out of the 13 algorithms investigated, the\nresults rank SaiyanH 4th in reconstructing the true DAG, with accuracy scores\nlower by 8.1% (F1), 10.2% (BSF), and 19.5% (SHD) compared to the top ranked\nalgorithm, and higher by 75.5% (F1), 118% (BSF), and 4.3% (SHD) compared to the\nbottom ranked algorithm. Overall, the results suggest that the proposed\nalgorithm discovers satisfactorily accurate connected DAGs in cases where other\nalgorithms produce multiple disjoint subgraphs that often underfit the true\ngraph.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 14:44:11 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 14:16:49 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Constantinou", "Anthony", ""]]}, {"id": "2004.04572", "submitter": "Tony Tung", "authors": "Zeng Huang, Yuanlu Xu, Christoph Lassner, Hao Li, Tony Tung", "title": "ARCH: Animatable Reconstruction of Clothed Humans", "comments": "10 pages, 10 figures, CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose ARCH (Animatable Reconstruction of Clothed Humans),\na novel end-to-end framework for accurate reconstruction of animation-ready 3D\nclothed humans from a monocular image. Existing approaches to digitize 3D\nhumans struggle to handle pose variations and recover details. Also, they do\nnot produce models that are animation ready. In contrast, ARCH is a learned\npose-aware model that produces detailed 3D rigged full-body human avatars from\na single unconstrained RGB image. A Semantic Space and a Semantic Deformation\nField are created using a parametric 3D body estimator. They allow the\ntransformation of 2D/3D clothed humans into a canonical space, reducing\nambiguities in geometry caused by pose variations and occlusions in training\ndata. Detailed surface geometry and appearance are learned using an implicit\nfunction representation with spatial local features. Furthermore, we propose\nadditional per-pixel supervision on the 3D reconstruction using opacity-aware\ndifferentiable rendering. Our experiments indicate that ARCH increases the\nfidelity of the reconstructed humans. We obtain more than 50% lower\nreconstruction errors for standard metrics compared to state-of-the-art methods\non public datasets. We also show numerous qualitative examples of animated,\nhigh-quality reconstructed avatars unseen in the literature so far.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:23:08 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 19:14:39 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Huang", "Zeng", ""], ["Xu", "Yuanlu", ""], ["Lassner", "Christoph", ""], ["Li", "Hao", ""], ["Tung", "Tony", ""]]}, {"id": "2004.04573", "submitter": "Mark Crowley", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Backprojection for Training Feedforward Neural Networks in the Input and\n  Feature Spaces", "comments": "Accepted (to appear) in International Conference on Image Analysis\n  and Recognition (ICIAR) 2020, Springer", "journal-ref": "International Conference on Image Analysis and Recognition, vol 2,\n  pp. 16-24. Springer, Cham, 2020", "doi": "10.1007/978-3-030-50516-5_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the tremendous development of neural networks trained by\nbackpropagation, it is a good time to develop other algorithms for training\nneural networks to gain more insights into networks. In this paper, we propose\na new algorithm for training feedforward neural networks which is fairly faster\nthan backpropagation. This method is based on projection and reconstruction\nwhere, at every layer, the projected data and reconstructed labels are forced\nto be similar and the weights are tuned accordingly layer by layer. The\nproposed algorithm can be used for both input and feature spaces, named as\nbackprojection and kernel backprojection, respectively. This algorithm gives an\ninsight to networks with a projection-based perspective. The experiments on\nsynthetic datasets show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 20:53:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.04574", "submitter": "Aras Dargazany", "authors": "Aras Dargazany", "title": "Model-based actor-critic: GAN (model generator) + DRL (actor-critic) =>\n  AGI", "comments": "arXiv admin note: text overlap with arXiv:1610.01945,\n  arXiv:1903.04411, arXiv:1910.01007 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our effort is toward unifying GAN and DRL algorithms into a unifying AI model\n(AGI or general-purpose AI or artificial general intelligence which has\ngeneral-purpose applications to: (A) offline learning (of stored data) like GAN\nin (un/semi-/fully-)SL setting such as big data analytics (mining) and\nvisualization; (B) online learning (of real or simulated devices) like DRL in\nRL setting (with/out environment reward) such as (real or simulated) robotics\nand control; Our core proposal is adding an (generative/predictive) environment\nmodel to the actor-critic (model-free) architecture which results in a\nmodel-based actor-critic architecture with temporal-differencing (TD) error and\nan episodic memory. The proposed AI model is similar to (model-free) DDPG and\ntherefore it's called model-based DDPG. To evaluate it, we compare it with\n(model-free) DDPG by applying them both to a variety (wide range) of\nindependent simulated robotic and control task environments in OpenAI Gym and\nUnity Agents. Our initial limited experiments show that DRL and GAN in\nmodel-based actor-critic results in an incremental goal-driven intellignce\nrequired to solve each task with similar performance to (model-free) DDPG. Our\nfuture focus is to investigate the proposed AI model potential to: (A) unify\nDRL field inside AI by producing competitive performance compared to the best\nof model-based (PlaNet) and model-free (D4PG) approaches; (B) bridge the gap\nbetween AI and robotics communities by solving the important problem of reward\nengineering with learning the reward function by demonstration.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 02:05:54 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 19:36:09 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 00:54:41 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 17:14:19 GMT"}, {"version": "v5", "created": "Mon, 28 Dec 2020 20:19:56 GMT"}, {"version": "v6", "created": "Fri, 22 Jan 2021 16:56:39 GMT"}, {"version": "v7", "created": "Mon, 1 Mar 2021 21:35:45 GMT"}, {"version": "v8", "created": "Fri, 16 Apr 2021 23:03:35 GMT"}, {"version": "v9", "created": "Tue, 20 Apr 2021 22:09:26 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Dargazany", "Aras", ""]]}, {"id": "2004.04582", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim, Till D\\\"ohmen, Dietrich Rebholz-Schuhmann, Stefan\n  Decker, Michael Cochez, and Oya Beyan", "title": "DeepCOVIDExplainer: Explainable COVID-19 Diagnosis Based on Chest X-ray\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Amid the coronavirus disease(COVID-19) pandemic, humanity experiences a rapid\nincrease in infection numbers across the world. Challenge hospitals are faced\nwith, in the fight against the virus, is the effective screening of incoming\npatients. One methodology is the assessment of chest radiography(CXR) images,\nwhich usually requires expert radiologist's knowledge. In this paper, we\npropose an explainable deep neural networks(DNN)-based method for automatic\ndetection of COVID-19 symptoms from CXR images, which we call\nDeepCOVIDExplainer. We used 15,959 CXR images of 15,854 patients, covering\nnormal, pneumonia, and COVID-19 cases. CXR images are first comprehensively\npreprocessed, before being augmented and classified with a neural ensemble\nmethod, followed by highlighting class-discriminating regions using\ngradient-guided class activation maps(Grad-CAM++) and layer-wise relevance\npropagation(LRP). Further, we provide human-interpretable explanations of the\npredictions. Evaluation results based on hold-out data show that our approach\ncan identify COVID-19 confidently with a positive predictive value(PPV) of\n91.6%, 92.45%, and 96.12%; precision, recall, and F1 score of 94.6%, 94.3%, and\n94.6%, respectively for normal, pneumonia, and COVID-19 cases, respectively,\nmaking it comparable or improved results over recent approaches. We hope that\nour findings will be a useful contribution to the fight against COVID-19 and,\nin more general, towards an increasing acceptance and adoption of AI-assisted\napplications in the clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 15:03:58 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 10:25:47 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 20:31:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["D\u00f6hmen", "Till", ""], ["Rebholz-Schuhmann", "Dietrich", ""], ["Decker", "Stefan", ""], ["Cochez", "Michael", ""], ["Beyan", "Oya", ""]]}, {"id": "2004.04593", "submitter": "Pawel Kalczynski", "authors": "Pawel Kalczynski, Jack Brimberg and Zvi Drezner", "title": "The Importance of Good Starting Solutions in the Minimum Sum of Squares\n  Clustering Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering problem has many applications in Machine Learning, Operations\nResearch, and Statistics. We propose three algorithms to create starting\nsolutions for improvement algorithms for this problem. We test the algorithms\non 72 instances that were investigated in the literature. Forty eight of them\nare relatively easy to solve and we found the best known solution many times\nfor all of them. Twenty four medium and large size instances are more\nchallenging. We found five new best known solutions and matched the best known\nsolution for 18 of the remaining 19 instances.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:13:41 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Kalczynski", "Pawel", ""], ["Brimberg", "Jack", ""], ["Drezner", "Zvi", ""]]}, {"id": "2004.04597", "submitter": "Andres Abeliuk", "authors": "Nazgol Tavabi, Andr\\'es Abeliuk, Negar Mokhberian, Jeremy Abramson,\n  Kristina Lerman", "title": "Challenges in Forecasting Malicious Events from Incomplete Data", "comments": "Accepted in The Fifth Workshop on Computational Methods in Online\n  Misbehavior, Companion Proceedings of The 2020 World Wide Web Conference (WWW\n  '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict cyber-attacks would enable organizations to\nmitigate their growing threat and avert the financial losses and disruptions\nthey cause. But how predictable are cyber-attacks? Researchers have attempted\nto combine external data -- ranging from vulnerability disclosures to\ndiscussions on Twitter and the darkweb -- with machine learning algorithms to\nlearn indicators of impending cyber-attacks. However, successful cyber-attacks\nrepresent a tiny fraction of all attempted attacks: the vast majority are\nstopped, or filtered by the security appliances deployed at the target. As we\nshow in this paper, the process of filtering reduces the predictability of\ncyber-attacks. The small number of attacks that do penetrate the target's\ndefenses follow a different generative process compared to the whole data which\nis much harder to learn for predictive models. This could be caused by the fact\nthat the resulting time series also depends on the filtering process in\naddition to all the different factors that the original time series depended\non. We empirically quantify the loss of predictability due to filtering using\nreal-world data from two organizations. Our work identifies the limits to\nforecasting cyber-attacks from highly filtered data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 22:57:23 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Mokhberian", "Negar", ""], ["Abramson", "Jeremy", ""], ["Lerman", "Kristina", ""]]}, {"id": "2004.04603", "submitter": "Ivan Vishniakou", "authors": "Ivan Vishniakou, Johannes D. Seelig", "title": "Adaptive optics with reflected light and deep neural networks", "comments": null, "journal-ref": "Opt. Express 28 (2020) 15459-15471", "doi": "10.1364/OE.392794", "report-no": null, "categories": "physics.optics cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Light scattering and aberrations limit optical microscopy in biological\ntissue, which motivates the development of adaptive optics techniques. Here, we\ndevelop a method for adaptive optics with reflected light and deep neural\nnetworks compatible with an epi-detection configuration. Large datasets of\nsample aberrations which consist of excitation and detection path aberrations\nas well as the corresponding reflected focus images are generated. These\ndatasets are used for training deep neural networks. After training, these\nnetworks can disentangle and independently correct excitation and detection\naberrations based on reflected light images recorded from scattering samples. A\nsimilar deep learning approach is also demonstrated with scattering guide\nstars. The predicted aberration corrections are validated using two photon\nimaging.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 15:39:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Vishniakou", "Ivan", ""], ["Seelig", "Johannes D.", ""]]}, {"id": "2004.04618", "submitter": "You Li", "authors": "You Li, Xin Hu, Yuan Zhuang, Zhouzheng Gao, Peng Zhang, Naser\n  El-Sheimy", "title": "Deep Reinforcement Learning (DRL): Another Perspective for Unsupervised\n  Wireless Localization", "comments": null, "journal-ref": null, "doi": "10.1109/JIOT.2019.2957778", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Location is key to spatialize internet-of-things (IoT) data. However, it is\nchallenging to use low-cost IoT devices for robust unsupervised localization\n(i.e., localization without training data that have known location labels).\nThus, this paper proposes a deep reinforcement learning (DRL) based\nunsupervised wireless-localization method. The main contributions are as\nfollows. (1) This paper proposes an approach to model a continuous\nwireless-localization process as a Markov decision process (MDP) and process it\nwithin a DRL framework. (2) To alleviate the challenge of obtaining rewards\nwhen using unlabeled data (e.g., daily-life crowdsourced data), this paper\npresents a reward-setting mechanism, which extracts robust landmark data from\nunlabeled wireless received signal strengths (RSS). (3) To ease requirements\nfor model re-training when using DRL for localization, this paper uses RSS\nmeasurements together with agent location to construct DRL inputs. The proposed\nmethod was tested by using field testing data from multiple Bluetooth 5 smart\near tags in a pasture. Meanwhile, the experimental verification process\nreflected the advantages and challenges for using DRL in wireless localization.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:03:56 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Li", "You", ""], ["Hu", "Xin", ""], ["Zhuang", "Yuan", ""], ["Gao", "Zhouzheng", ""], ["Zhang", "Peng", ""], ["El-Sheimy", "Naser", ""]]}, {"id": "2004.04631", "submitter": "Di Gao", "authors": "Di Gao and Cheng Zhuo", "title": "Private Knowledge Transfer via Model Distillation with Generative\n  Adversarial Networks", "comments": "9 pages, 4 figures, ECAI 2020, the 24th European Conference on\n  Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deployment of deep learning applications has to address the growing\nprivacy concerns when using private and sensitive data for training. A\nconventional deep learning model is prone to privacy attacks that can recover\nthe sensitive information of individuals from either model parameters or\naccesses to the target model. Recently, differential privacy that offers\nprovable privacy guarantees has been proposed to train neural networks in a\nprivacy-preserving manner to protect training data. However, many approaches\ntend to provide the worst case privacy guarantees for model publishing,\ninevitably impairing the accuracy of the trained models. In this paper, we\npresent a novel private knowledge transfer strategy, where the private teacher\ntrained on sensitive data is not publicly accessible but teaches a student to\nbe publicly released. In particular, a three-player\n(teacher-student-discriminator) learning framework is proposed to achieve\ntrade-off between utility and privacy, where the student acquires the distilled\nknowledge from the teacher and is trained with the discriminator to generate\nsimilar outputs as the teacher. We then integrate a differential privacy\nprotection mechanism into the learning procedure, which enables a rigorous\nprivacy budget for the training. The framework eventually allows student to be\ntrained with only unlabelled public data and very few epochs, and hence\nprevents the exposure of sensitive training data, while ensuring model utility\nwith a modest privacy budget. The experiments on MNIST, SVHN and CIFAR-10\ndatasets show that our students obtain the accuracy losses w.r.t teachers of\n0.89%, 2.29%, 5.16%, respectively with the privacy bounds of (1.93, 10^-5),\n(5.02, 10^-6), (8.81, 10^-6). When compared with the existing works\n\\cite{papernot2016semi,wang2019private}, the proposed work can achieve 5-82%\naccuracy loss improvement.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 12:55:01 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Gao", "Di", ""], ["Zhuo", "Cheng", ""]]}, {"id": "2004.04632", "submitter": "Xueyu Zhu", "authors": "Andrew Pensoneault and Xiu Yang and Xueyu Zhu", "title": "Nonnegativity-Enforced Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GP) regression is a flexible non-parametric approach to\napproximate complex models. In many cases, these models correspond to processes\nwith bounded physical properties. Standard GP regression typically results in a\nproxy model which is unbounded for all temporal or spacial points, and thus\nleaves the possibility of taking on infeasible values. We propose an approach\nto enforce the physical constraints in a probabilistic way under the GP\nregression framework. In addition, this new approach reduces the variance in\nthe resulting GP model.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:43:46 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Pensoneault", "Andrew", ""], ["Yang", "Xiu", ""], ["Zhu", "Xueyu", ""]]}, {"id": "2004.04634", "submitter": "Jianxin Lin", "authors": "Jianxin Lin, Yingxue Pang, Yingce Xia, Zhibo Chen, Jiebo Luo", "title": "TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired\n  Images", "comments": "ECCV 2020 Spotlight", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unsupervised image-to-image translation (UI2I) task deals with learning a\nmapping between two domains without paired images. While existing UI2I methods\nusually require numerous unpaired images from different domains for training,\nthere are many scenarios where training data is quite limited. In this paper,\nwe argue that even if each domain contains a single image, UI2I can still be\nachieved. To this end, we propose TuiGAN, a generative model that is trained on\nonly two unpaired images and amounts to one-shot unsupervised learning. With\nTuiGAN, an image is translated in a coarse-to-fine manner where the generated\nimage is gradually refined from global structures to local details. We conduct\nextensive experiments to verify that our versatile method can outperform strong\nbaselines on a wide variety of UI2I tasks. Moreover, TuiGAN is capable of\nachieving comparable performance with the state-of-the-art UI2I models trained\nwith sufficient data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:23:59 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 02:23:03 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Lin", "Jianxin", ""], ["Pang", "Yingxue", ""], ["Xia", "Yingce", ""], ["Chen", "Zhibo", ""], ["Luo", "Jiebo", ""]]}, {"id": "2004.04635", "submitter": "Xin Xin", "authors": "Xin Xin, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M.Jose", "title": "Graph Highway Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Networks (GCN) are widely used in learning graph\nrepresentations due to their effectiveness and efficiency. However, they suffer\nfrom the notorious over-smoothing problem, in which the learned representations\nof densely connected nodes converge to alike vectors when many (>3) graph\nconvolutional layers are stacked. In this paper, we argue that\nthere-normalization trick used in GCN leads to overly homogeneous information\npropagation, which is the source of over-smoothing. To address this problem, we\npropose Graph Highway Networks(GHNet) which utilize gating units to\nautomatically balance the trade-off between homogeneity and heterogeneity in\nthe GCN learning process. The gating units serve as direct highways to maintain\nheterogeneous information from the node itself after feature propagation. This\ndesign enables GHNet to achieve much larger receptive fields per node without\nover-smoothing and thus access to more of the graph connectivity information.\nExperimental results on benchmark datasets demonstrate the superior performance\nof GHNet over GCN and related models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:26:43 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Xin", "Xin", ""], ["Karatzoglou", "Alexandros", ""], ["Arapakis", "Ioannis", ""], ["Jose", "Joemon M.", ""]]}, {"id": "2004.04641", "submitter": "Alireza Ghaffari", "authors": "Alireza Ghaffari, Yvon Savaria", "title": "CNN2Gate: Toward Designing a General Framework for Implementation of\n  Convolutional Neural Networks on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have a major impact on our society\nbecause of the numerous services they provide. On the other hand, they require\nconsiderable computing power. To satisfy these requirements, it is possible to\nuse graphic processing units (GPUs). However, high power consumption and\nlimited external IOs constrain their usability and suitability in industrial\nand mission-critical scenarios. Recently, the number of researches that utilize\nFPGAs to implement CNNs are increasing rapidly. This is due to the lower power\nconsumption and easy reconfigurability offered by these platforms. Because of\nthe research efforts put into topics such as architecture, synthesis and\noptimization, some new challenges are arising to integrate such hardware\nsolutions to high-level machine learning software libraries. This paper\nintroduces an integrated framework (CNN2Gate) that supports compilation of a\nCNN model for an FPGA target. CNN2Gate exploits the OpenCL synthesis workflow\nfor FPGAs offered by commercial vendors. CNN2Gate is capable of parsing CNN\nmodels from several popular high-level machine learning libraries such as\nKeras, Pytorch, Caffe2 etc. CNN2Gate extracts computation flow of layers, in\naddition to weights and biases and applies a \"given\" fixed-point quantization.\nFurthermore, it writes this information in the proper format for OpenCL\nsynthesis tools that are then used to build and run the project on FPGA.\nCNN2Gate performs design-space exploration using a reinforcement learning agent\nand fits the design on different FPGAs with limited logic resources\nautomatically. This paper reports results of automatic synthesis and\ndesign-space exploration of AlexNet and VGG-16 on various Intel FPGA platforms.\nCNN2Gate achieves a latency of 205 ms for VGG-16 and 18 ms for AlexNet on the\nFPGA.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 01:57:53 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 00:59:40 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Ghaffari", "Alireza", ""], ["Savaria", "Yvon", ""]]}, {"id": "2004.04642", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Una-May O'Reilly, Erik Hemberg", "title": "Data Dieting in GAN Training", "comments": "Chapter 14 of the Book \"Deep Neural Evolution - Deep Learning with\n  Evolutionary Computation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate training Generative Adversarial Networks, GANs, with less\ndata. Subsets of the training dataset can express empirical sample diversity\nwhile reducing training resource requirements, e.g. time and memory. We ask how\nmuch data reduction impacts generator performance and gauge the additive value\nof generator ensembles. In addition to considering stand-alone GAN training and\nensembles of generator models, we also consider reduced data training on an\nevolutionary GAN training framework named Redux-Lipizzaner. Redux-Lipizzaner\nmakes GAN training more robust and accurate by exploiting overlapping\nneighborhood-based training on a spatial 2D grid. We conduct empirical\nexperiments on Redux-Lipizzaner using the MNIST and CelebA data sets.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:39:42 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Toutouh", "Jamal", ""], ["O'Reilly", "Una-May", ""], ["Hemberg", "Erik", ""]]}, {"id": "2004.04644", "submitter": "Shai Shalev-Shwartz", "authors": "Shai Shalev-Shwartz, Shaked Shammah, Amnon Shashua", "title": "On the Ethics of Building AI in a Responsible Manner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI-alignment problem arises when there is a discrepancy between the goals\nthat a human designer specifies to an AI learner and a potential catastrophic\noutcome that does not reflect what the human designer really wants. We argue\nthat a formalism of AI alignment that does not distinguish between strategic\nand agnostic misalignments is not useful, as it deems all technology as\nun-safe. We propose a definition of a strategic-AI-alignment and prove that\nmost machine learning algorithms that are being used in practice today do not\nsuffer from the strategic-AI-alignment problem. However, without being careful,\ntoday's technology might lead to strategic misalignment.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 04:11:08 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shammah", "Shaked", ""], ["Shashua", "Amnon", ""]]}, {"id": "2004.04645", "submitter": "Denis McInerney", "authors": "Denis Jered McInerney, Borna Dabiri, Anne-Sophie Touret, Geoffrey\n  Young, Jan-Willem van de Meent, Byron C. Wallace", "title": "Query-Focused EHR Summarization to Aid Imaging Diagnosis", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 126 (2020) 632-659", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHRs) provide vital contextual information to\nradiologists and other physicians when making a diagnosis. Unfortunately,\nbecause a given patient's record may contain hundreds of notes and reports,\nidentifying relevant information within these in the short time typically\nallotted to a case is very difficult. We propose and evaluate models that\nextract relevant text snippets from patient records to provide a rough case\nsummary intended to aid physicians considering one or more diagnoses. This is\nhard because direct supervision (i.e., physician annotations of snippets\nrelevant to specific diagnoses in medical records) is prohibitively expensive\nto collect at scale. We propose a distantly supervised strategy in which we use\ngroups of International Classification of Diseases (ICD) codes observed in\n'future' records as noisy proxies for 'downstream' diagnoses. Using this we\ntrain a transformer-based neural model to perform extractive summarization\nconditioned on potential diagnoses. This model defines an attention mechanism\nthat is conditioned on potential diagnoses (queries) provided by the diagnosing\nphysician. We train (via distant supervision) and evaluate variants of this\nmodel on EHR data from Brigham and Women's Hospital in Boston and MIMIC-III\n(the latter to facilitate reproducibility). Evaluations performed by\nradiologists demonstrate that these distantly supervised models yield better\nextractive summaries than do unsupervised approaches. Such models may aid\ndiagnosis by identifying sentences in past patient reports that are clinically\nrelevant to a potential diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:32:39 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 04:25:30 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["McInerney", "Denis Jered", ""], ["Dabiri", "Borna", ""], ["Touret", "Anne-Sophie", ""], ["Young", "Geoffrey", ""], ["van de Meent", "Jan-Willem", ""], ["Wallace", "Byron C.", ""]]}, {"id": "2004.04647", "submitter": "Jamal Toutouh", "authors": "Una-May O'Reilly and Jamal Toutouh and Marcos Pertierra and Daniel\n  Prado Sanchez and Dennis Garcia and Anthony Erb Luogo and Jonathan Kelly and\n  Erik Hemberg", "title": "Adversarial Genetic Programming for Cyber Security: A Rising Application\n  Domain Where GP Matters", "comments": null, "journal-ref": null, "doi": "10.1007/s10710-020-09389-y", "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber security adversaries and engagements are ubiquitous and ceaseless. We\ndelineate Adversarial Genetic Programming for Cyber Security, a research topic\nthat, by means of genetic programming (GP), replicates and studies the behavior\nof cyber adversaries and the dynamics of their engagements. Adversarial Genetic\nProgramming for Cyber Security encompasses extant and immediate research\nefforts in a vital problem domain, arguably occupying a position at the\nfrontier where GP matters. Additionally, it prompts research questions around\nevolving complex behavior by expressing different abstractions with GP and\nopportunities to reconnect to the Machine Learning, Artificial Life,\nAgent-Based Modeling and Cyber Security communities. We present a framework\ncalled RIVALS which supports the study of network security arms races. Its goal\nis to elucidate the dynamics of cyber networks under attack by computationally\nmodeling and simulating them.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:13:14 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["O'Reilly", "Una-May", ""], ["Toutouh", "Jamal", ""], ["Pertierra", "Marcos", ""], ["Sanchez", "Daniel Prado", ""], ["Garcia", "Dennis", ""], ["Luogo", "Anthony Erb", ""], ["Kelly", "Jonathan", ""], ["Hemberg", "Erik", ""]]}, {"id": "2004.04650", "submitter": "Ilija Radosavovic", "authors": "Ilija Radosavovic, Xiaolong Wang, Lerrel Pinto, Jitendra Malik", "title": "State-Only Imitation Learning for Dexterous Manipulation", "comments": "Videos available at https://people.eecs.berkeley.edu/~ilija/soil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dexterous manipulation has been a long-standing challenge in robotics.\nRecently, modern model-free RL has demonstrated impressive results on a number\nof problems. However, complex domains like dexterous manipulation remain a\nchallenge for RL due to the poor sample complexity. To address this, current\napproaches employ expert demonstrations in the form of state-action pairs,\nwhich are difficult to obtain for real-world settings such as learning from\nvideos. In this work, we move toward a more realistic setting and explore\nstate-only imitation learning. To tackle this setting, we train an inverse\ndynamics model and use it to predict actions for state-only demonstrations. The\ninverse dynamics model and the policy are trained jointly. Our method performs\non par with state-action approaches and considerably outperforms RL alone. By\nnot relying on expert actions, we are able to learn from demonstrations with\ndifferent dynamics, morphologies, and objects.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:57:20 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Radosavovic", "Ilija", ""], ["Wang", "Xiaolong", ""], ["Pinto", "Lerrel", ""], ["Malik", "Jitendra", ""]]}, {"id": "2004.04653", "submitter": "Quercus Hernandez Lain", "authors": "Quercus Hern\\'andez, Alberto Badias, David Gonzalez, Francisco\n  Chinesta, and Elias Cueto", "title": "Structure-preserving neural networks", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2020.109950", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to learn physical systems from data that employs\nfeedforward neural networks and whose predictions comply with the first and\nsecond principles of thermodynamics. The method employs a minimum amount of\ndata by enforcing the metriplectic structure of dissipative Hamiltonian systems\nin the form of the so-called General Equation for the Non-Equilibrium\nReversible-Irreversible Coupling, GENERIC [M. Grmela and H.C Oettinger (1997).\nDynamics and thermodynamics of complex fluids. I. Development of a general\nformalism. Phys. Rev. E. 56 (6): 6620-6632]. The method does not need to\nenforce any kind of balance equation, and thus no previous knowledge on the\nnature of the system is needed. Conservation of energy and dissipation of\nentropy in the prediction of previously unseen situations arise as a natural\nby-product of the structure of the method. Examples of the performance of the\nmethod are shown that include conservative as well as dissipative systems,\ndiscrete as well as continuous ones.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:41:20 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 15:07:50 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Hern\u00e1ndez", "Quercus", ""], ["Badias", "Alberto", ""], ["Gonzalez", "David", ""], ["Chinesta", "Francisco", ""], ["Cueto", "Elias", ""]]}, {"id": "2004.04662", "submitter": "Andis Draguns", "authors": "Andis Draguns, Em\\=ils Ozoli\\c{n}\\v{s}, Agris \\v{S}ostaks, Mat\\=iss\n  Apinis, K\\=arlis Freivalds", "title": "Residual Shuffle-Exchange Networks for Fast Processing of Long Sequences", "comments": "35th AAAI Conference on Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention is a commonly used mechanism in sequence processing, but it is of\nO(n^2) complexity which prevents its application to long sequences. The\nrecently introduced neural Shuffle-Exchange network offers a\ncomputation-efficient alternative, enabling the modelling of long-range\ndependencies in O(n log n) time. The model, however, is quite complex,\ninvolving a sophisticated gating mechanism derived from the Gated Recurrent\nUnit. In this paper, we present a simple and lightweight variant of the\nShuffle-Exchange network, which is based on a residual network employing GELU\nand Layer Normalization. The proposed architecture not only scales to longer\nsequences but also converges faster and provides better accuracy. It surpasses\nthe Shuffle-Exchange network on the LAMBADA language modelling task and\nachieves state-of-the-art performance on the MusicNet dataset for music\ntranscription while being efficient in the number of parameters. We show how to\ncombine the improved Shuffle-Exchange network with convolutional layers,\nestablishing it as a useful building block in long sequence processing\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 12:44:22 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 14:51:56 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 11:14:31 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 00:33:19 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Draguns", "Andis", ""], ["Ozoli\u0146\u0161", "Em\u012bls", ""], ["\u0160ostaks", "Agris", ""], ["Apinis", "Mat\u012bss", ""], ["Freivalds", "K\u0101rlis", ""]]}, {"id": "2004.04666", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi, Chen Wang", "title": "Exploration with Limited Memory: Streaming Algorithms for Coin Tossing,\n  Noisy Comparisons, and Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following abstract coin tossing problem: Given a set of $n$\ncoins with unknown biases, find the most biased coin using a minimal number of\ncoin tosses. This is a common abstraction of various exploration problems in\ntheoretical computer science and machine learning and has been studied\nextensively over the years. In particular, algorithms with optimal sample\ncomplexity (number of coin tosses) have been known for this problem for quite\nsome time.\n  Motivated by applications to processing massive datasets, we study the space\ncomplexity of solving this problem with optimal number of coin tosses in the\nstreaming model. In this model, the coins are arriving one by one and the\nalgorithm is only allowed to store a limited number of coins at any point --\nany coin not present in the memory is lost and can no longer be tossed or\ncompared to arriving coins. Prior algorithms for the coin tossing problem with\noptimal sample complexity are based on iterative elimination of coins which\ninherently require storing all the coins, leading to memory-inefficient\nstreaming algorithms.\n  We remedy this state-of-affairs by presenting a series of improved streaming\nalgorithms for this problem: we start with a simple algorithm which require\nstoring only $O(\\log{n})$ coins and then iteratively refine it further and\nfurther, leading to algorithms with $O(\\log\\log{(n)})$ memory, $O(\\log^*{(n)})$\nmemory, and finally a one that only stores a single extra coin in memory -- the\nsame exact space needed to just store the best coin throughout the stream.\n  Furthermore, we extend our algorithms to the problem of finding the $k$ most\nbiased coins as well as other exploration problems such as finding top-$k$\nelements using noisy comparisons or finding an $\\epsilon$-best arm in\nstochastic multi-armed bandits, and obtain efficient streaming algorithms for\nthese problems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:54:43 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Assadi", "Sepehr", ""], ["Wang", "Chen", ""]]}, {"id": "2004.04667", "submitter": "Nina Miolane", "authors": "Nina Miolane, Alice Le Brigant, Johan Mathe, Benjamin Hou, Nicolas\n  Guigui, Yann Thanwerdas, Stefan Heyder, Olivier Peltre, Niklas Koep, Hadi\n  Zaatiti, Hatem Hajri, Yann Cabanes, Thomas Gerald, Paul Chauchat, Christian\n  Shewmake, Bernhard Kainz, Claire Donnat, Susan Holmes, Xavier Pennec", "title": "Geomstats: A Python Package for Riemannian Geometry in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Geomstats, an open-source Python toolbox for computations and\nstatistics on nonlinear manifolds, such as hyperbolic spaces, spaces of\nsymmetric positive definite matrices, Lie groups of transformations, and many\nmore. We provide object-oriented and extensively unit-tested implementations.\nAmong others, manifolds come equipped with families of Riemannian metrics, with\nassociated exponential and logarithmic maps, geodesics and parallel transport.\nStatistics and learning algorithms provide methods for estimation, clustering\nand dimension reduction on manifolds. All associated operations are vectorized\nfor batch computation and provide support for different execution backends,\nnamely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper\npresents the package, compares it with related libraries and provides relevant\ncode examples. We show that Geomstats provides reliable building blocks to\nfoster research in differential geometry and statistics, and to democratize the\nuse of Riemannian geometry in machine learning applications. The source code is\nfreely available under the MIT license at \\url{geomstats.ai}.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:41:50 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Miolane", "Nina", ""], ["Brigant", "Alice Le", ""], ["Mathe", "Johan", ""], ["Hou", "Benjamin", ""], ["Guigui", "Nicolas", ""], ["Thanwerdas", "Yann", ""], ["Heyder", "Stefan", ""], ["Peltre", "Olivier", ""], ["Koep", "Niklas", ""], ["Zaatiti", "Hadi", ""], ["Hajri", "Hatem", ""], ["Cabanes", "Yann", ""], ["Gerald", "Thomas", ""], ["Chauchat", "Paul", ""], ["Shewmake", "Christian", ""], ["Kainz", "Bernhard", ""], ["Donnat", "Claire", ""], ["Holmes", "Susan", ""], ["Pennec", "Xavier", ""]]}, {"id": "2004.04668", "submitter": "Neerav Karani", "authors": "Neerav Karani, Ertunc Erdil, Krishna Chaitanya, and Ender Konukoglu", "title": "Test-Time Adaptable Neural Networks for Robust Medical Image\n  Segmentation", "comments": "Published in Medical Image Analysis journal:\n  https://doi.org/10.1016/j.media.2020.101907", "journal-ref": "Medical Image Analysis, Volume 68, 2021, 101907, ISSN 1361-8415.\n  http://www.sciencedirect.com/science/article/pii/S1361841520302711", "doi": "10.1016/j.media.2020.101907", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) work very well for supervised learning\nproblems when the training dataset is representative of the variations expected\nto be encountered at test time. In medical image segmentation, this premise is\nviolated when there is a mismatch between training and test images in terms of\ntheir acquisition details, such as the scanner model or the protocol.\nRemarkable performance degradation of CNNs in this scenario is well documented\nin the literature. To address this problem, we design the segmentation CNN as a\nconcatenation of two sub-networks: a relatively shallow image normalization\nCNN, followed by a deep CNN that segments the normalized image. We train both\nthese sub-networks using a training dataset, consisting of annotated images\nfrom a particular scanner and protocol setting. Now, at test time, we adapt the\nimage normalization sub-network for \\emph{each test image}, guided by an\nimplicit prior on the predicted segmentation labels. We employ an independently\ntrained denoising autoencoder (DAE) in order to model such an implicit prior on\nplausible anatomical segmentation labels. We validate the proposed idea on\nmulti-center Magnetic Resonance imaging datasets of three anatomies: brain,\nheart and prostate. The proposed test-time adaptation consistently provides\nperformance improvement, demonstrating the promise and generality of the\napproach. Being agnostic to the architecture of the deep CNN, the second\nsub-network, the proposed design can be utilized with any segmentation network\nto increase robustness to variations in imaging scanners and protocols. Our\ncode is available at:\n\\url{https://github.com/neerakara/test-time-adaptable-neural-networks-for-domain-generalization}.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:57:27 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 11:01:39 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 12:07:31 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2021 16:14:08 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Karani", "Neerav", ""], ["Erdil", "Ertunc", ""], ["Chaitanya", "Krishna", ""], ["Konukoglu", "Ender", ""]]}, {"id": "2004.04671", "submitter": "Alex Bocharov", "authors": "Alex Bocharov, Michael Freedman, Eshan Kemp, Martin Roetteler, and\n  Krysta M.Svore", "title": "Predicting human-generated bitstreams using classical and quantum models", "comments": "10 pages, 2 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A school of thought contends that human decision making exhibits quantum-like\nlogic. While it is not known whether the brain may indeed be driven by actual\nquantum mechanisms, some researchers suggest that the decision logic is\nphenomenologically non-classical. This paper develops and implements an\nempirical framework to explore this view. We emulate binary decision-making\nusing low width, low depth, parameterized quantum circuits. Here, entanglement\nserves as a resource for pattern analysis in the context of a simple\nbit-prediction game. We evaluate a hybrid quantum-assisted machine learning\nstrategy where quantum processing is used to detect correlations in the\nbitstreams while parameter updates and class inference are performed by\nclassical post-processing of measurement results. Simulation results indicate\nthat a family of two-qubit variational circuits is sufficient to achieve the\nsame bit-prediction accuracy as the best traditional classical solution such as\nneural nets or logistic autoregression. Thus, short of establishing a provable\n\"quantum advantage\" in this simple scenario, we give evidence that the\nclassical predictability analysis of a human-generated bitstream can be\nachieved by small quantum models.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:59:49 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Bocharov", "Alex", ""], ["Freedman", "Michael", ""], ["Kemp", "Eshan", ""], ["Roetteler", "Martin", ""], ["Svore", "Krysta M.", ""]]}, {"id": "2004.04674", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Milad Sikaroudi, Sobhan Shafiei, H.R. Tizhoosh,\n  Fakhri Karray, Mark Crowley", "title": "Fisher Discriminant Triplet and Contrastive Losses for Training Siamese\n  Networks", "comments": "Accepted (to appear) in International Joint Conference on Neural\n  Networks (IJCNN) 2020, IEEE, in IEEE World Congress on Computational\n  Intelligence (WCCI) 2020", "journal-ref": "International Joint Conference on Neural Networks (IJCNN), IEEE,\n  2020", "doi": "10.1109/IJCNN48605.2020.9206833", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Siamese neural network is a very powerful architecture for both feature\nextraction and metric learning. It usually consists of several networks that\nshare weights. The Siamese concept is topology-agnostic and can use any neural\nnetwork as its backbone. The two most popular loss functions for training these\nnetworks are the triplet and contrastive loss functions. In this paper, we\npropose two novel loss functions, named Fisher Discriminant Triplet (FDT) and\nFisher Discriminant Contrastive (FDC). The former uses anchor-neighbor-distant\ntriplets while the latter utilizes pairs of anchor-neighbor and anchor-distant\nsamples. The FDT and FDC loss functions are designed based on the statistical\nformulation of the Fisher Discriminant Analysis (FDA), which is a linear\nsubspace learning method. Our experiments on the MNIST and two challenging and\npublicly available histopathology datasets show the effectiveness of the\nproposed loss functions.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 09:27:05 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Sikaroudi", "Milad", ""], ["Shafiei", "Sobhan", ""], ["Tizhoosh", "H. R.", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2004.04676", "submitter": "David Enthoven", "authors": "David Enthoven and Zaid Al-Ars", "title": "An Overview of Federated Deep Learning Privacy Attacks and Defensive\n  Strategies", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased attention and legislation for data-privacy, collaborative\nmachine learning (ML) algorithms are being developed to ensure the protection\nof private data used for processing. Federated learning (FL) is the most\npopular of these methods, which provides privacy preservation by facilitating\ncollaborative training of a shared model without the need to exchange any\nprivate data with a centralized server. Rather, an abstraction of the data in\nthe form of a machine learning model update is sent. Recent studies showed that\nsuch model updates may still very well leak private information and thus more\nstructured risk assessment is needed. In this paper, we analyze existing\nvulnerabilities of FL and subsequently perform a literature review of the\npossible attack methods targetingFL privacy protection capabilities. These\nattack methods are then categorized by a basic taxonomy. Additionally, we\nprovide a literature study of the most recent defensive strategies and\nalgorithms for FL aimed to overcome these attacks. These defensive strategies\nare categorized by their respective underlying defence principle. The paper\nconcludes that the application of a single defensive strategy is not enough to\nprovide adequate protection to all available attack methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 12:41:45 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Enthoven", "David", ""], ["Al-Ars", "Zaid", ""]]}, {"id": "2004.04677", "submitter": "Ronny Hug", "authors": "Ronny Hug, Stefan Becker, Wolfgang H\\\"ubner and Michael Arens", "title": "A Short Note on Analyzing Sequence Complexity in Trajectory Prediction\n  Benchmarks", "comments": "Accepted at LHMP2020 Workshop (ICRA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis and quantification of sequence complexity is an open problem\nfrequently encountered when defining trajectory prediction benchmarks. In order\nto enable a more informative assembly of a data basis, an approach for\ndetermining a dataset representation in terms of a small set of distinguishable\nprototypical sub-sequences is proposed. The approach employs a sequence\nalignment followed by a learning vector quantization (LVQ) stage. A first proof\nof concept on synthetically generated and real-world datasets shows the\nviability of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 11:44:11 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:04:54 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hug", "Ronny", ""], ["Becker", "Stefan", ""], ["H\u00fcbner", "Wolfgang", ""], ["Arens", "Michael", ""]]}, {"id": "2004.04686", "submitter": "Niklas K\\\"uhl", "authors": "Niklas K\\\"uhl, Marc Goutier, Robin Hirt, Gerhard Satzger", "title": "Machine Learning in Artificial Intelligence: Towards a Common\n  Understanding", "comments": "Hawaii International Conference on System Sciences (HICSS-52) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The application of \"machine learning\" and \"artificial intelligence\" has\nbecome popular within the last decade. Both terms are frequently used in\nscience and media, sometimes interchangeably, sometimes with different\nmeanings. In this work, we aim to clarify the relationship between these terms\nand, in particular, to specify the contribution of machine learning to\nartificial intelligence. We review relevant literature and present a conceptual\nframework which clarifies the role of machine learning to build (artificial)\nintelligent agents. Hence, we seek to provide more terminological clarity and a\nstarting point for (interdisciplinary) discussions and future research.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 19:09:57 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["K\u00fchl", "Niklas", ""], ["Goutier", "Marc", ""], ["Hirt", "Robin", ""], ["Satzger", "Gerhard", ""]]}, {"id": "2004.04690", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Rongmei Lin, Zhen Liu, James M. Rehg, Liam Paull, Li\n  Xiong, Le Song, Adrian Weller", "title": "Orthogonal Over-Parameterized Training", "comments": "CVPR 2021 Oral (43 Pages, Substantial Update from v3, Typos Fixed\n  from v5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inductive bias of a neural network is largely determined by the\narchitecture and the training algorithm. To achieve good generalization, how to\neffectively train a neural network is of great importance. We propose a novel\northogonal over-parameterized training (OPT) framework that can provably\nminimize the hyperspherical energy which characterizes the diversity of neurons\non a hypersphere. By maintaining the minimum hyperspherical energy during\ntraining, OPT can greatly improve the empirical generalization. Specifically,\nOPT fixes the randomly initialized weights of the neurons and learns an\northogonal transformation that applies to these neurons. We consider multiple\nways to learn such an orthogonal transformation, including unrolling\northogonalization algorithms, applying orthogonal parameterization, and\ndesigning orthogonality-preserving gradient descent. For better scalability, we\npropose the stochastic OPT which performs orthogonal transformation\nstochastically for partial dimensions of neurons. Interestingly, OPT reveals\nthat learning a proper coordinate system for neurons is crucial to\ngeneralization. We provide some insights on why OPT yields better\ngeneralization. Extensive experiments validate the superiority of OPT over the\nstandard training.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:16:38 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:22:30 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 06:18:55 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 11:31:31 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 01:07:38 GMT"}, {"version": "v6", "created": "Sat, 5 Jun 2021 00:31:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Liu", "Weiyang", ""], ["Lin", "Rongmei", ""], ["Liu", "Zhen", ""], ["Rehg", "James M.", ""], ["Paull", "Liam", ""], ["Xiong", "Li", ""], ["Song", "Le", ""], ["Weller", "Adrian", ""]]}, {"id": "2004.04692", "submitter": "Yiming Li", "authors": "Yiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shutao\n  Xia", "title": "Rethinking the Trigger of Backdoor Attack", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attack intends to inject hidden backdoor into the deep neural\nnetworks (DNNs), such that the prediction of the infected model will be\nmaliciously changed if the hidden backdoor is activated by the attacker-defined\ntrigger, while it performs well on benign samples. Currently, most of existing\nbackdoor attacks adopted the setting of \\emph{static} trigger, $i.e.,$ triggers\nacross the training and testing images follow the same appearance and are\nlocated in the same area. In this paper, we revisit this attack paradigm by\nanalyzing the characteristics of the static trigger. We demonstrate that such\nan attack paradigm is vulnerable when the trigger in testing images is not\nconsistent with the one used for training. We further explore how to utilize\nthis property for backdoor defense, and discuss how to alleviate such\nvulnerability of existing attacks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:19:37 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 10:22:58 GMT"}, {"version": "v3", "created": "Sun, 31 Jan 2021 17:25:49 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Yiming", ""], ["Zhai", "Tongqing", ""], ["Wu", "Baoyuan", ""], ["Jiang", "Yong", ""], ["Li", "Zhifeng", ""], ["Xia", "Shutao", ""]]}, {"id": "2004.04697", "submitter": "Travis Manderson", "authors": "Travis Manderson, Stefan Wapnick, David Meger, and Gregory Dudek", "title": "Learning to Drive Off Road on Smooth Terrain in Unstructured\n  Environments Using an On-Board Camera and Sparse Aerial Images", "comments": "ICRA 2020. Video and project details can be found at\n  http://www.cim.mcgill.ca/mrl/offroad_driving/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for learning to drive on smooth terrain while\nsimultaneously avoiding collisions in challenging off-road and unstructured\noutdoor environments using only visual inputs. Our approach applies a hybrid\nmodel-based and model-free reinforcement learning method that is entirely\nself-supervised in labeling terrain roughness and collisions using on-board\nsensors. Notably, we provide both first-person and overhead aerial image inputs\nto our model. We find that the fusion of these complementary inputs improves\nplanning foresight and makes the model robust to visual obstructions. Our\nresults show the ability to generalize to environments with plentiful\nvegetation, various types of rock, and sandy trails. During evaluation, our\npolicy attained 90% smooth terrain traversal and reduced the proportion of\nrough terrain driven over by 6.1 times compared to a model using only\nfirst-person imagery.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:27:09 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Manderson", "Travis", ""], ["Wapnick", "Stefan", ""], ["Meger", "David", ""], ["Dudek", "Gregory", ""]]}, {"id": "2004.04704", "submitter": "Robert Tillman", "authors": "Robert E. Tillman, Vamsi K. Potluru, Jiahao Chen, Prashant Reddy,\n  Manuela Veloso", "title": "Heuristics for Link Prediction in Multiplex Networks", "comments": null, "journal-ref": "Proceedings of the 24th European Conference on Artificial\n  Intelligence (ECAI 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction, or the inference of future or missing connections between\nentities, is a well-studied problem in network analysis. A multitude of\nheuristics exist for link prediction in ordinary networks with a single type of\nconnection. However, link prediction in multiplex networks, or networks with\nmultiple types of connections, is not a well understood problem. We propose a\nnovel general framework and three families of heuristics for multiplex network\nlink prediction that are simple, interpretable, and take advantage of the rich\nconnection type correlation structure that exists in many real world networks.\nWe further derive a theoretical threshold for determining when to use a\ndifferent connection type based on the number of links that overlap with an\nErdos-Renyi random graph. Through experiments with simulated and real world\nscientific collaboration, transportation and global trade networks, we\ndemonstrate that the proposed heuristics show increased performance with the\nrichness of connection type correlation structure and significantly outperform\ntheir baseline heuristics for ordinary networks with a single connection type.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:36:18 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tillman", "Robert E.", ""], ["Potluru", "Vamsi K.", ""], ["Chen", "Jiahao", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.04710", "submitter": "Besher Alhalabi", "authors": "Besher Alhalabi, Mohamed Gaber, Shadi Basurra", "title": "Prune2Edge: A Multi-Phase Pruning Pipelines to Deep Ensemble Learning in\n  IIoT", "comments": "a revised version is going to be submitted to a journal soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recently, with the proliferation of IoT devices, computational nodes in\nmanufacturing systems IIoT(Industrial-Internet-of-things) and the lunch of 5G\nnetworks, there will be millions of connected devices generating a massive\namount of data. In such an environment, the controlling systems need to be\nintelligent enough to deal with a vast amount of data to detect defects in a\nreal-time process. Driven by such a need, artificial intelligence models such\nas deep learning have to be deployed into IIoT systems. However, learning and\nusing deep learning models are computationally expensive, so an IoT device with\nlimited computational power could not run such models. To tackle this issue,\nedge intelligence had emerged as a new paradigm towards running Artificial\nIntelligence models on edge devices. Although a considerable amount of studies\nhave been proposed in this area, the research is still in the early stages. In\nthis paper, we propose a novel edge-based multi-phase pruning pipelines to\nensemble learning on IIoT devices. In the first phase, we generate a diverse\nensemble of pruned models, then we apply integer quantisation, next we prune\nthe generated ensemble using a clustering-based technique. Finally, we choose\nthe best representative from each generated cluster to be deployed to a\ndistributed IoT environment. On CIFAR-100 and CIFAR-10, our proposed approach\nwas able to outperform the predictability levels of a baseline model (up to\n7%), more importantly, the generated learners have small sizes (up to 90%\nreduction in the model size) that minimise the required computational\ncapabilities to make an inference on the resource-constraint devices.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:44:34 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 16:05:23 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Alhalabi", "Besher", ""], ["Gaber", "Mohamed", ""], ["Basurra", "Shadi", ""]]}, {"id": "2004.04715", "submitter": "Justin Khim", "authors": "Justin Khim, Ziyu Xu and Shashank Singh", "title": "Multiclass Classification via Class-Weighted Nearest Neighbors", "comments": "62 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study statistical properties of the k-nearest neighbors algorithm for\nmulticlass classification, with a focus on settings where the number of classes\nmay be large and/or classes may be highly imbalanced. In particular, we\nconsider a variant of the k-nearest neighbor classifier with non-uniform\nclass-weightings, for which we derive upper and minimax lower bounds on\naccuracy, class-weighted risk, and uniform error. Additionally, we show that\nuniform error bounds lead to bounds on the difference between empirical\nconfusion matrix quantities and their population counterparts across a set of\nweights. As a result, we may adjust the class weights to optimize\nclassification metrics such as F1 score or Matthew's Correlation Coefficient\nthat are commonly used in practice, particularly in settings with imbalanced\nclasses. We additionally provide a simple example to instantiate our bounds and\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:50:16 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 00:40:57 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Khim", "Justin", ""], ["Xu", "Ziyu", ""], ["Singh", "Shashank", ""]]}, {"id": "2004.04717", "submitter": "Matthew Dixon", "authors": "Matthew F Dixon", "title": "Industrial Forecasting with Exponentially Smoothed Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series modeling has entered an era of unprecedented growth in the size\nand complexity of data which require new modeling approaches. While many new\ngeneral purpose machine learning approaches have emerged, they remain poorly\nunderstand and irreconcilable with more traditional statistical modeling\napproaches. We present a general class of exponential smoothed recurrent neural\nnetworks (RNNs) which are well suited to modeling non-stationary dynamical\nsystems arising in industrial applications. In particular, we analyze their\ncapacity to characterize the non-linear partial autocorrelation structure of\ntime series and directly capture dynamic effects such as seasonality and\ntrends. Application of exponentially smoothed RNNs to forecasting electricity\nload, weather data, and stock prices highlight the efficacy of exponential\nsmoothing of the hidden state for multi-step time series forecasting. The\nresults also suggest that popular, but more complicated neural network\narchitectures originally designed for speech processing, such as LSTMs and\nGRUs, are likely over-engineered for industrial forecasting and light-weight\nexponentially smoothed architectures, trained in a fraction of the time,\ncapture the salient features while being superior and more robust than simple\nRNNs and ARIMA models. Additionally uncertainty quantification of the\nexponential smoothed recurrent neural networks, provided by Bayesian\nestimation, is shown to provide improved coverage.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:53:49 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 16:54:40 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Dixon", "Matthew F", ""]]}, {"id": "2004.04719", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Chris Junchi Li, Martin J. Wainwright, Peter L. Bartlett,\n  Michael I. Jordan", "title": "On Linear Stochastic Approximation: Fine-grained Polyak-Ruppert and\n  Non-Asymptotic Concentration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We undertake a precise study of the asymptotic and non-asymptotic properties\nof stochastic approximation procedures with Polyak-Ruppert averaging for\nsolving a linear system $\\bar{A} \\theta = \\bar{b}$. When the matrix $\\bar{A}$\nis Hurwitz, we prove a central limit theorem (CLT) for the averaged iterates\nwith fixed step size and number of iterations going to infinity. The CLT\ncharacterizes the exact asymptotic covariance matrix, which is the sum of the\nclassical Polyak-Ruppert covariance and a correction term that scales with the\nstep size. Under assumptions on the tail of the noise distribution, we prove a\nnon-asymptotic concentration inequality whose main term matches the covariance\nin CLT in any direction, up to universal constants. When the matrix $\\bar{A}$\nis not Hurwitz but only has non-negative real parts in its eigenvalues, we\nprove that the averaged LSA procedure actually achieves an $O(1/T)$ rate in\nmean-squared error. Our results provide a more refined understanding of linear\nstochastic approximation in both the asymptotic and non-asymptotic settings. We\nalso show various applications of the main results, including the study of\nmomentum-based stochastic gradient methods as well as temporal difference\nalgorithms in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:54:18 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Mou", "Wenlong", ""], ["Li", "Chris Junchi", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2004.04721", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "Translation Artifacts in Cross-lingual Transfer Learning", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both human and machine translation play a central role in cross-lingual\ntransfer learning: many multilingual datasets have been created through\nprofessional translation services, and using machine translation to translate\neither the test set or the training set is a widely used transfer technique. In\nthis paper, we show that such translation process can introduce subtle\nartifacts that have a notable impact in existing cross-lingual models. For\ninstance, in natural language inference, translating the premise and the\nhypothesis independently can reduce the lexical overlap between them, which\ncurrent models are highly sensitive to. We show that some previous findings in\ncross-lingual transfer learning need to be reconsidered in the light of this\nphenomenon. Based on the gained insights, we also improve the state-of-the-art\nin XNLI for the translate-test and zero-shot approaches by 4.3 and 2.8 points,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:54:30 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 16:06:53 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 00:42:41 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 22:26:49 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2004.04722", "submitter": "Paul Van Eecke", "authors": "Paul Van Eecke (1 and 2), Katrien Beuls (1) ((1) Artificial\n  Intelligence Laboratory, Vrije Universiteit Brussel, Brussels, Belgium, (2)\n  ITEC, imec research group at KU Leuven, Kortrijk, Belgium)", "title": "Re-conceptualising the Language Game Paradigm in the Framework of\n  Multi-Agent Reinforcement Learning", "comments": "This paper was accepted for presentation at the 2020 AAAI Spring\n  Symposium `Challenges and Opportunities for Multi-Agent Reinforcement\n  Learning' after a double-blind reviewing process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the challenge of re-conceptualising the language\ngame experimental paradigm in the framework of multi-agent reinforcement\nlearning (MARL). If successful, future language game experiments will benefit\nfrom the rapid and promising methodological advances in the MARL community,\nwhile future MARL experiments on learning emergent communication will benefit\nfrom the insights and results gained from language game experiments. We\nstrongly believe that this cross-pollination has the potential to lead to major\nbreakthroughs in the modelling of how human-like languages can emerge and\nevolve in multi-agent systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:55:15 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Van Eecke", "Paul", "", "1 and 2"], ["Beuls", "Katrien", ""]]}, {"id": "2004.04725", "submitter": "Zhongzheng Ren", "authors": "Zhongzheng Ren, Zhiding Yu, Xiaodong Yang, Ming-Yu Liu, Yong Jae Lee,\n  Alexander G. Schwing, Jan Kautz", "title": "Instance-aware, Context-focused, and Memory-efficient Weakly Supervised\n  Object Detection", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised learning has emerged as a compelling tool for object\ndetection by reducing the need for strong supervision during training. However,\nmajor challenges remain: (1) differentiation of object instances can be\nambiguous; (2) detectors tend to focus on discriminative parts rather than\nentire objects; (3) without ground truth, object proposals have to be redundant\nfor high recalls, causing significant memory consumption. Addressing these\nchallenges is difficult, as it often requires to eliminate uncertainties and\ntrivial solutions. To target these issues we develop an instance-aware and\ncontext-focused unified framework. It employs an instance-aware self-training\nalgorithm and a learnable Concrete DropBlock while devising a memory-efficient\nsequential batch back-propagation. Our proposed method achieves\nstate-of-the-art results on COCO ($12.1\\% ~AP$, $24.8\\% ~AP_{50}$), VOC 2007\n($54.9\\% ~AP$), and VOC 2012 ($52.1\\% ~AP$), improving baselines by great\nmargins. In addition, the proposed method is the first to benchmark ResNet\nbased models and weakly supervised video object detection. Code, models, and\nmore details will be made available at: https://github.com/NVlabs/wetectron.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:57:09 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 16:26:07 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 07:32:04 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Ren", "Zhongzheng", ""], ["Yu", "Zhiding", ""], ["Yang", "Xiaodong", ""], ["Liu", "Ming-Yu", ""], ["Lee", "Yong Jae", ""], ["Schwing", "Alexander G.", ""], ["Kautz", "Jan", ""]]}, {"id": "2004.04729", "submitter": "Temesgen Mehari", "authors": "Simon Wiedemann, Temesgen Mehari, Kevin Kepp, Wojciech Samek", "title": "Dithered backprop: A sparse and quantized backpropagation algorithm for\n  more efficient deep neural network training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are successful but highly computationally expensive\nlearning systems. One of the main sources of time and energy drains is the well\nknown backpropagation (backprop) algorithm, which roughly accounts for 2/3 of\nthe computational complexity of training. In this work we propose a method for\nreducing the computational cost of backprop, which we named dithered backprop.\nIt consists in applying a stochastic quantization scheme to intermediate\nresults of the method. The particular quantisation scheme, called\nnon-subtractive dither (NSD), induces sparsity which can be exploited by\ncomputing efficient sparse matrix multiplications. Experiments on popular image\nclassification tasks show that it induces 92% sparsity on average across a wide\nset of models at no or negligible accuracy drop in comparison to\nstate-of-the-art approaches, thus significantly reducing the computational\ncomplexity of the backward pass. Moreover, we show that our method is fully\ncompatible to state-of-the-art training methods that reduce the bit-precision\nof training down to 8-bits, as such being able to further reduce the\ncomputational requirements. Finally we discuss and show potential benefits of\napplying dithered backprop in a distributed training setting, where both\ncommunication as well as compute efficiency may increase simultaneously with\nthe number of participant nodes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 17:59:26 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 16:59:09 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Wiedemann", "Simon", ""], ["Mehari", "Temesgen", ""], ["Kepp", "Kevin", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.04731", "submitter": "Gautam Krishna", "authors": "Gautam Krishna, Co Tran, Mason Carnahan, Ahmed Tewfik", "title": "Advancing Speech Synthesis using EEG", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce attention-regression model to demonstrate\npredicting acoustic features from electroencephalography (EEG) features\nrecorded in parallel with spoken sentences. First we demonstrate predicting\nacoustic features directly from EEG features using our attention model and then\nwe demonstrate predicting acoustic features from EEG features using a two-step\napproach where in the first step we use our attention model to predict\narticulatory features from EEG features and then in second step another\nattention-regression model is trained to transform the predicted articulatory\nfeatures to acoustic features. Our proposed attention-regression model\ndemonstrates superior performance compared to the regression model introduced\nby authors in [1] when tested using their data set for majority of the subjects\nduring test time. The results presented in this paper further advances the work\ndescribed by authors in [1].\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:58:40 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:33:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Krishna", "Gautam", ""], ["Tran", "Co", ""], ["Carnahan", "Mason", ""], ["Tewfik", "Ahmed", ""]]}, {"id": "2004.04736", "submitter": "Rodney LaLonde III", "authors": "Rodney LaLonde, Ziyue Xu, Ismail Irmakci, Sanjay Jain, Ulas Bagci", "title": "Capsules for Biomedical Image Segmentation", "comments": "Extension of the non-archival Capsules of Object Segmentation with\n  experiments on both clinical and pre-clinical pathological lung segmentation\n  from CT scans and muscular and adipose tissue segmentation from MR images.\n  Accepted for publication in Medical Image Analysis. DOI:\n  https://doi.org/10.1016/j.media.2020.101889. arXiv admin note: text overlap\n  with arXiv:1804.04241", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. This is made possible via\nthe introduction of locally-constrained routing and transformation matrix\nsharing, which reduces the parameter/memory burden and allows for the\nsegmentation of objects at large resolutions. To compensate for the loss of\nglobal information in constraining the routing, we propose the concept of\n\"deconvolutional\" capsules to create a deep encoder-decoder style network,\ncalled SegCaps. We extend the masked reconstruction regularization to the task\nof segmentation and perform thorough ablation experiments on each component of\nour method. The proposed convolutional-deconvolutional capsule network,\nSegCaps, shows state-of-the-art results while using a fraction of the\nparameters of popular segmentation networks. To validate our proposed method,\nwe perform experiments segmenting pathological lungs from clinical and\npre-clinical thoracic computed tomography (CT) scans and segmenting muscle and\nadipose (fat) tissue from magnetic resonance imaging (MRI) scans of human\nsubjects' thighs. Notably, our experiments in lung segmentation represent the\nlargest-scale study in pathological lung segmentation in the literature, where\nwe conduct experiments across five extremely challenging datasets, containing\nboth clinical and pre-clinical subjects, and nearly 2000 computed-tomography\nscans. Our newly developed segmentation platform outperforms other methods\nacross all datasets while utilizing less than 5% of the parameters in the\npopular U-Net for biomedical image segmentation. Further, we demonstrate\ncapsules' ability to generalize to unseen rotations/reflections on natural\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 03:01:31 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 21:53:16 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["LaLonde", "Rodney", ""], ["Xu", "Ziyue", ""], ["Irmakci", "Ismail", ""], ["Jain", "Sanjay", ""], ["Bagci", "Ulas", ""]]}, {"id": "2004.04743", "submitter": "Yi Zhang", "authors": "Yuan-Hang Zhang, Pei-Lin Zheng, Yi Zhang and Dong-Ling Deng", "title": "Topological Quantum Compiling with Reinforcement Learning", "comments": "6 pages, 5 figures; Supplementary Material: 4 pages, 7 figures", "journal-ref": "Phys. Rev. Lett. 125, 170501 (2020)", "doi": "10.1103/PhysRevLett.125.170501", "report-no": null, "categories": "quant-ph cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum compiling, a process that decomposes the quantum algorithm into a\nseries of hardware-compatible commands or elementary gates, is of fundamental\nimportance for quantum computing. We introduce an efficient algorithm based on\ndeep reinforcement learning that compiles an arbitrary single-qubit gate into a\nsequence of elementary gates from a finite universal set. It generates\nnear-optimal gate sequences with given accuracy and is generally applicable to\nvarious scenarios, independent of the hardware-feasible universal set and free\nfrom using ancillary qubits. For concreteness, we apply this algorithm to the\ncase of topological compiling of Fibonacci anyons and obtain near-optimal\nbraiding sequences for arbitrary single-qubit unitaries. Our algorithm may\ncarry over to other challenging quantum discrete problems, thus opening up a\nnew avenue for intriguing applications of deep learning in quantum physics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 18:00:01 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 05:46:38 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhang", "Yuan-Hang", ""], ["Zheng", "Pei-Lin", ""], ["Zhang", "Yi", ""], ["Deng", "Dong-Ling", ""]]}, {"id": "2004.04767", "submitter": "Hai Tran-Bach", "authors": "Tengyuan Liang and Hai Tran-Bach", "title": "Mehler's Formula, Branching Process, and Compositional Kernels of Deep\n  Neural Networks", "comments": null, "journal-ref": "Journal of the American Statistical Association (2020)", "doi": "10.1080/01621459.2020.1853547", "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize a connection between compositional kernels and branching processes\nvia Mehler's formula to study deep neural networks. This new probabilistic\ninsight provides us a novel perspective on the mathematical role of activation\nfunctions in compositional neural networks. We study the unscaled and rescaled\nlimits of the compositional kernels and explore the different phases of the\nlimiting behavior, as the compositional depth increases. We investigate the\nmemorization capacity of the compositional kernels and neural networks by\ncharacterizing the interplay among compositional depth, sample size,\ndimensionality, and non-linearity of the activation. Explicit formulas on the\neigenvalues of the compositional kernel are provided, which quantify the\ncomplexity of the corresponding reproducing kernel Hilbert space. On the\nmethodological front, we propose a new random features algorithm, which\ncompresses the compositional layers by devising a new activation function.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 18:46:13 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 17:29:34 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Liang", "Tengyuan", ""], ["Tran-Bach", "Hai", ""]]}, {"id": "2004.04768", "submitter": "Zhibo Yang", "authors": "Jianyuan Deng, Zhibo Yang, Yao Li, Dimitris Samaras, Fusheng Wang", "title": "Towards Better Opioid Antagonists Using Deep Reinforcement Learning", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Naloxone, an opioid antagonist, has been widely used to save lives from\nopioid overdose, a leading cause for death in the opioid epidemic. However,\nnaloxone has short brain retention ability, which limits its therapeutic\nefficacy. Developing better opioid antagonists is critical in combating the\nopioid epidemic.Instead of exhaustively searching in a huge chemical space for\nbetter opioid antagonists, we adopt reinforcement learning which allows\nefficient gradient-based search towards molecules with desired physicochemical\nand/or biological properties. Specifically, we implement a deep reinforcement\nlearning framework to discover potential lead compounds as better opioid\nantagonists with enhanced brain retention ability. A customized multi-objective\nreward function is designed to bias the generation towards molecules with both\nsufficient opioid antagonistic effect and enhanced brain retention ability.\nThorough evaluation demonstrates that with this framework, we are able to\nidentify valid, novel and feasible molecules with multiple desired properties,\nwhich has high potential in drug discovery.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 15:28:50 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Deng", "Jianyuan", ""], ["Yang", "Zhibo", ""], ["Li", "Yao", ""], ["Samaras", "Dimitris", ""], ["Wang", "Fusheng", ""]]}, {"id": "2004.04778", "submitter": "Lucas N. Alegre", "authors": "Lucas N. Alegre, Ana L. C. Bazzan, Bruno C. da Silva", "title": "Quantifying the Impact of Non-Stationarity in Reinforcement\n  Learning-Based Traffic Signal Control", "comments": "13 pages", "journal-ref": "PeerJ Computer Science 2021", "doi": "10.7717/peerj-cs.575", "report-no": "7:e575", "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning (RL), dealing with non-stationarity is a\nchallenging issue. However, some domains such as traffic optimization are\ninherently non-stationary. Causes for and effects of this are manifold. In\nparticular, when dealing with traffic signal controls, addressing\nnon-stationarity is key since traffic conditions change over time and as a\nfunction of traffic control decisions taken in other parts of a network. In\nthis paper we analyze the effects that different sources of non-stationarity\nhave in a network of traffic signals, in which each signal is modeled as a\nlearning agent. More precisely, we study both the effects of changing the\n\\textit{context} in which an agent learns (e.g., a change in flow rates\nexperienced by it), as well as the effects of reducing agent observability of\nthe true environment state. Partial observability may cause distinct states (in\nwhich distinct actions are optimal) to be seen as the same by the traffic\nsignal agents. This, in turn, may lead to sub-optimal performance. We show that\nthe lack of suitable sensors to provide a representative observation of the\nreal state seems to affect the performance more drastically than the changes to\nthe underlying traffic patterns.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:20:43 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Alegre", "Lucas N.", ""], ["Bazzan", "Ana L. C.", ""], ["da Silva", "Bruno C.", ""]]}, {"id": "2004.04787", "submitter": "Ha Q. Ngo", "authors": "Ha Q. Ngo, Christoph Henke, Frank Hees", "title": "An End-to-End Learning Approach for Trajectory Prediction in Pedestrian\n  Zones", "comments": "Submitted 23 March 2020", "journal-ref": "2020 ACM/IEEE International Conference on Human-Robot Interaction.\n  Workshop on The Forgotten in HRI: Incidental Encounters with Robots in Public\n  Spaces", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to explore the problem of trajectory prediction in\nheterogeneous pedestrian zones, where social dynamics representation is a big\nchallenge. Proposed is an end-to-end learning framework for prediction accuracy\nimprovement based on an attention mechanism to learn social interaction from\nmulti-factor inputs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:56:45 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 22:43:17 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Ngo", "Ha Q.", ""], ["Henke", "Christoph", ""], ["Hees", "Frank", ""]]}, {"id": "2004.04788", "submitter": "Bekir Z Demiray", "authors": "Bekir Z Demiray, Muhammed Sit, Ibrahim Demir", "title": "D-SRGAN: DEM Super-Resolution with Generative Adversarial Networks", "comments": "8 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LIDAR (light detection and ranging) is an optical remote-sensing technique\nthat measures the distance between sensor and object, and the reflected energy\nfrom the object. Over the years, LIDAR data has been used as the primary source\nof Digital Elevation Models (DEMs). DEMs have been used in a variety of\napplications like road extraction, hydrological modeling, flood mapping, and\nsurface analysis. A number of studies in flooding suggest the usage of\nhigh-resolution DEMs as inputs in the applications improve the overall\nreliability and accuracy. Despite the importance of high-resolution DEM, many\nareas in the United States and the world do not have access to high-resolution\nDEM due to technological limitations or the cost of the data collection. With\nrecent development in Graphical Processing Units (GPU) and novel algorithms,\ndeep learning techniques have become attractive to researchers for their\nperformance in learning features from high-resolution datasets. Numerous new\nmethods have been proposed such as Generative Adversarial Networks (GANs) to\ncreate intelligent models that correct and augment large-scale datasets. In\nthis paper, a GAN based model is developed and evaluated, inspired by single\nimage super-resolution methods, to increase the spatial resolution of a given\nDEM dataset up to 4 times without additional information related to data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 19:57:49 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 17:42:46 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Demiray", "Bekir Z", ""], ["Sit", "Muhammed", ""], ["Demir", "Ibrahim", ""]]}, {"id": "2004.04795", "submitter": "Sajad Norouzi", "authors": "Sajad Norouzi, David J. Fleet, Mohammad Norouzi", "title": "Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and\n  Data Augmentation", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Exemplar VAEs, a family of generative models that bridge the gap\nbetween parametric and non-parametric, exemplar based generative models.\nExemplar VAE is a variant of VAE with a non-parametric prior in the latent\nspace based on a Parzen window estimator. To sample from it, one first draws a\nrandom exemplar from a training set, then stochastically transforms that\nexemplar into a latent code and a new observation. We propose retrieval\naugmented training (RAT) as a way to speed up Exemplar VAE training by using\napproximate nearest neighbor search in the latent space to define a lower bound\non log marginal likelihood. To enhance generalization, model parameters are\nlearned using exemplar leave-one-out and subsampling. Experiments demonstrate\nthe effectiveness of Exemplar VAEs on density estimation and representation\nlearning. Importantly, generative data augmentation using Exemplar VAEs on\npermutation invariant MNIST and Fashion MNIST reduces classification error from\n1.17% to 0.69% and from 8.56% to 8.16%.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 20:21:45 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 21:06:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 18:51:11 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Norouzi", "Sajad", ""], ["Fleet", "David J.", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2004.04807", "submitter": "Tolga Birdal", "authors": "Mai Bui and Tolga Birdal and Haowen Deng and Shadi Albarqouni and\n  Leonidas Guibas and Slobodan Ilic and Nassir Navab", "title": "6D Camera Relocalization in Ambiguous Scenes via Continuous Multimodal\n  Inference", "comments": "Accepted for publication at ECCV 2020. Project page under\n  https://multimodal3dvision.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multimodal camera relocalization framework that captures\nambiguities and uncertainties with continuous mixture models defined on the\nmanifold of camera poses. In highly ambiguous environments, which can easily\narise due to symmetries and repetitive structures in the scene, computing one\nplausible solution (what most state-of-the-art methods currently regress) may\nnot be sufficient. Instead we predict multiple camera pose hypotheses as well\nas the respective uncertainty for each prediction. Towards this aim, we use\nBingham distributions, to model the orientation of the camera pose, and a\nmultivariate Gaussian to model the position, with an end-to-end deep neural\nnetwork. By incorporating a Winner-Takes-All training scheme, we finally obtain\na mixture model that is well suited for explaining ambiguities in the scene,\nyet does not suffer from mode collapse, a common problem with mixture density\nnetworks. We introduce a new dataset specifically designed to foster camera\nlocalization research in ambiguous environments and exhaustively evaluate our\nmethod on synthetic as well as real data on both ambiguous scenes and on\nnon-ambiguous benchmark datasets. We plan to release our code and dataset under\n$\\href{https://multimodal3dvision.github.io}{multimodal3dvision.github.io}$.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 20:55:06 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 07:06:27 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bui", "Mai", ""], ["Birdal", "Tolga", ""], ["Deng", "Haowen", ""], ["Albarqouni", "Shadi", ""], ["Guibas", "Leonidas", ""], ["Ilic", "Slobodan", ""], ["Navab", "Nassir", ""]]}, {"id": "2004.04812", "submitter": "Vinayakumar R", "authors": "Simran K, Prathiksha Balakrishna, Vinayakumar Ravi, Soman KP", "title": "Deep Learning based Frameworks for Handling Imbalance in DGA, Email, and\n  URL Data Analysis", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE cs.SI eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is a state of the art method for a lot of applications. The\nmain issue is that most of the real-time data is highly imbalanced in nature.\nIn order to avoid bias in training, cost-sensitive approach can be used. In\nthis paper, we propose cost-sensitive deep learning based frameworks and the\nperformance of the frameworks is evaluated on three different Cyber Security\nuse cases which are Domain Generation Algorithm (DGA), Electronic mail (Email),\nand Uniform Resource Locator (URL). Various experiments were performed using\ncost-insensitive as well as cost-sensitive methods and parameters for both of\nthese methods are set based on hyperparameter tuning. In all experiments, the\ncost-sensitive deep learning methods performed better than the cost-insensitive\napproaches. This is mainly due to the reason that cost-sensitive approach gives\nimportance to the classes which have a very less number of samples during\ntraining and this helps to learn all the classes in a more efficient manner.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:22:25 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 08:12:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["K", "Simran", ""], ["Balakrishna", "Prathiksha", ""], ["Ravi", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "2004.04814", "submitter": "Stephen Baek", "authors": "Sehyun Chun, Sidhartha Roy, Yen Thi Nguyen, Joseph B. Choi, H.S.\n  Udaykumar, Stephen S. Baek", "title": "Deep learning for synthetic microstructure generation in a\n  materials-by-design framework for heterogeneous energetic materials", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-020-70149-0", "report-no": null, "categories": "cond-mat.mtrl-sci cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sensitivity of heterogeneous energetic (HE) materials (propellants,\nexplosives, and pyrotechnics) is critically dependent on their microstructure.\nInitiation of chemical reactions occurs at hot spots due to energy localization\nat sites of porosities and other defects. Emerging multi-scale predictive\nmodels of HE response to loads account for the physics at the meso-scale, i.e.\nat the scale of statistically representative clusters of particles and other\nfeatures in the microstructure. Meso-scale physics is infused in\nmachine-learned closure models informed by resolved meso-scale simulations.\nSince microstructures are stochastic, ensembles of meso-scale simulations are\nrequired to quantify hot spot ignition and growth and to develop models for\nmicrostructure-dependent energy deposition rates. We propose utilizing\ngenerative adversarial networks (GAN) to spawn ensembles of synthetic\nheterogeneous energetic material microstructures. The method generates\nqualitatively and quantitatively realistic microstructures by learning from\nimages of HE microstructures. We show that the proposed GAN method also permits\nthe generation of new morphologies, where the porosity distribution can be\ncontrolled and spatially manipulated. Such control paves the way for the design\nof novel microstructures to engineer HE materials for targeted performance in a\nmaterials-by-design framework.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 16:58:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chun", "Sehyun", ""], ["Roy", "Sidhartha", ""], ["Nguyen", "Yen Thi", ""], ["Choi", "Joseph B.", ""], ["Udaykumar", "H. S.", ""], ["Baek", "Stephen S.", ""]]}, {"id": "2004.04815", "submitter": "Yingshi Chen", "authors": "Yingshi Chen, Naixing Feng", "title": "Learning Unsplit-field-based PML for the FDTD Method by Deep\n  Differentiable Forest", "comments": "4 pages,2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2003.00223", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternative unsplit-filed-based absorbing boundary condition (ABC)\ncomputation approach for the finite-difference time-domain (FDTD) is\nefficiently proposed based on the deep differentiable forest. The deep\ndifferentiable forest (DDF) model is introduced to replace the conventional\nperfectly matched layer (PML) ABC during the computation process of FDTD. The\nfield component data on the interface of traditional PML are adopted to train\nthe DDF-based PML model. DDF has the advantages of both trees and neural\nnetworks. Its tree structure is easy to use and explain for the numerical PML\ndata. It has full differentiability like neural networks. DDF could be trained\nby powerful techniques from deep learning. So compared to the traditional PML\nimplementation, the proposed method can greatly reduce the size of FDTD\nphysical domain and the calculation complexity of FDTD due to the novel model\nwhich only involves the one-cell thickness of boundary layer. Numerical\nsimulations have been carried out to benchmark the performance of the proposed\napproach. Numerical results illustrate that the proposed method can not only\neasily replace the traditional PML, but also be integrated into the FDTD\ncomputation process with satisfactory numerical accuracy and compatibility to\nthe FDTD.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:05:49 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chen", "Yingshi", ""], ["Feng", "Naixing", ""]]}, {"id": "2004.04816", "submitter": "Guanhua Zhang", "authors": "Bing Bai, Guanhua Zhang, Ye Lin, Hao Li, Kun Bai, Bo Luo", "title": "CSRN: Collaborative Sequential Recommendation Networks for News\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, news apps have taken over the popularity of paper-based media,\nproviding a great opportunity for personalization. Recurrent Neural Network\n(RNN)-based sequential recommendation is a popular approach that utilizes\nusers' recent browsing history to predict future items. This approach is\nlimited that it does not consider the societal influences of news consumption,\ni.e., users may follow popular topics that are constantly changing, while\ncertain hot topics might be spreading only among specific groups of people.\nSuch societal impact is difficult to predict given only users' own reading\nhistories. On the other hand, the traditional User-based Collaborative\nFiltering (UserCF) makes recommendations based on the interests of the\n\"neighbors\", which provides the possibility to supplement the weaknesses of\nRNN-based methods. However, conventional UserCF only uses a single similarity\nmetric to model the relationships between users, which is too coarse-grained\nand thus limits the performance. In this paper, we propose a framework of deep\nneural networks to integrate the RNN-based sequential recommendations and the\nkey ideas from UserCF, to develop Collaborative Sequential Recommendation\nNetworks (CSRNs). Firstly, we build a directed co-reading network of users, to\ncapture the fine-grained topic-specific similarities between users in a vector\nspace. Then, the CSRN model encodes users with RNNs, and learns to attend to\nneighbors and summarize what news they are reading at the moment. Finally, news\narticles are recommended according to both the user's own state and the\nsummarized state of the neighbors. Experiments on two public datasets show that\nthe proposed model outperforms the state-of-the-art approaches significantly.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 13:25:21 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bai", "Bing", ""], ["Zhang", "Guanhua", ""], ["Lin", "Ye", ""], ["Li", "Hao", ""], ["Bai", "Kun", ""], ["Luo", "Bo", ""]]}, {"id": "2004.04834", "submitter": "Adam Breuer", "authors": "Adam Breuer, Roee Eilat, and Udi Weinsberg", "title": "Friend or Faux: Graph-Based Early Detection of Fake Accounts on Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the problem of early detection of fake user accounts\non social networks based solely on their network connectivity with other users.\nRemoving such accounts is a core task for maintaining the integrity of social\nnetworks, and early detection helps to reduce the harm that such accounts\ninflict. However, new fake accounts are notoriously difficult to detect via\ngraph-based algorithms, as their small number of connections are unlikely to\nreflect a significant structural difference from those of new real accounts. We\npresent the SybilEdge algorithm, which determines whether a new user is a fake\naccount (`sybil') by aggregating over (I) her choices of friend request targets\nand (II) these targets' respective responses. SybilEdge performs this\naggregation giving more weight to a user's choices of targets to the extent\nthat these targets are preferred by other fakes versus real users, and also to\nthe extent that these targets respond differently to fakes versus real users.\nWe show that SybilEdge rapidly detects new fake users at scale on the Facebook\nnetwork and outperforms state-of-the-art algorithms. We also show that\nSybilEdge is robust to label noise in the training data, to different\nprevalences of fake accounts in the network, and to several different ways\nfakes can select targets for their friend requests. To our knowledge, this is\nthe first time a graph-based algorithm has been shown to achieve high\nperformance (AUC>0.9) on new users who have only sent a small number of friend\nrequests.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 22:03:28 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Breuer", "Adam", ""], ["Eilat", "Roee", ""], ["Weinsberg", "Udi", ""]]}, {"id": "2004.04841", "submitter": "Andrey Kupavskii", "authors": "Andrey Kupavskii", "title": "The VC-dimension of k-vertex d-polytopes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DM cs.LG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we show that the VC-dimension of the class of $k$-vertex\npolytopes in $\\mathbb R^d$ is at most $8d^2k\\log_2k$, answering an old question\nof Long and Warmuth.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:00:08 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 21:44:18 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kupavskii", "Andrey", ""]]}, {"id": "2004.04843", "submitter": "Sujay Bhatt", "authors": "Sujay Bhatt, Alec Koppel, Vikram Krishnamurthy", "title": "Policy Gradient using Weak Derivatives for Reinforcement Learning", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers policy search in continuous state-action reinforcement\nlearning problems. Typically, one computes search directions using a classic\nexpression for the policy gradient called the Policy Gradient Theorem, which\ndecomposes the gradient of the value function into two factors: the score\nfunction and the Q-function. This paper presents four results:(i) an\nalternative policy gradient theorem using weak (measure-valued) derivatives\ninstead of score-function is established; (ii) the stochastic gradient\nestimates thus derived are shown to be unbiased and to yield algorithms that\nconverge almost surely to stationary points of the non-convex value function of\nthe reinforcement learning problem; (iii) the sample complexity of the\nalgorithm is derived and is shown to be $O(1/\\sqrt(k))$; (iv) finally, the\nexpected variance of the gradient estimates obtained using weak derivatives is\nshown to be lower than those obtained using the popular score-function\napproach. Experiments on OpenAI gym pendulum environment show superior\nperformance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:05:18 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bhatt", "Sujay", ""], ["Koppel", "Alec", ""], ["Krishnamurthy", "Vikram", ""]]}, {"id": "2004.04849", "submitter": "Daniel Khashabi Mr.", "authors": "Daniel Khashabi, Tushar Khot, Ashish Sabharwal", "title": "More Bang for Your Buck: Natural Perturbation for Robust Question\n  Answering", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent models have achieved human-level scores on many NLP datasets, we\nobserve that they are considerably sensitive to small changes in input. As an\nalternative to the standard approach of addressing this issue by constructing\ntraining sets of completely new examples, we propose doing so via minimal\nperturbation of examples. Specifically, our approach involves first collecting\na set of seed examples and then applying human-driven natural perturbations (as\nopposed to rule-based machine perturbations), which often change the gold label\nas well. Local perturbations have the advantage of being relatively easier (and\nhence cheaper) to create than writing out completely new examples. To evaluate\nthe impact of this phenomenon, we consider a recent question-answering dataset\n(BoolQ) and study the benefit of our approach as a function of the perturbation\ncost ratio, the relative cost of perturbing an existing question vs. creating a\nnew one from scratch. We find that when natural perturbations are moderately\ncheaper to create, it is more effective to train models using them: such models\nexhibit higher robustness and better generalization, while retaining\nperformance on the original BoolQ dataset.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:12:39 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 07:10:00 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Khashabi", "Daniel", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""]]}, {"id": "2004.04851", "submitter": "Ankan Bansal", "authors": "Ankan Bansal, Sai Saketh Rambhatla, Abhinav Shrivastava, Rama\n  Chellappa", "title": "Spatial Priming for Detecting Human-Object Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relative spatial layout of a human and an object is an important cue for\ndetermining how they interact. However, until now, spatial layout has been used\njust as side-information for detecting human-object interactions (HOIs). In\nthis paper, we present a method for exploiting this spatial layout information\nfor detecting HOIs in images. The proposed method consists of a layout module\nwhich primes a visual module to predict the type of interaction between a human\nand an object. The visual and layout modules share information through lateral\nconnections at several stages. The model uses predictions from the layout\nmodule as a prior to the visual module and the prediction from the visual\nmodule is given as the final output. It also incorporates semantic information\nabout the object using word2vec vectors. The proposed model reaches an mAP of\n24.79% for HICO-Det dataset which is about 2.8% absolute points higher than the\ncurrent state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 23:20:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bansal", "Ankan", ""], ["Rambhatla", "Sai Saketh", ""], ["Shrivastava", "Abhinav", ""], ["Chellappa", "Rama", ""]]}, {"id": "2004.04866", "submitter": "Mart\\'in Palazzo", "authors": "Martin Palazzo, Patricio Yankilevich, Pierre Beauseroy", "title": "Latent regularization for feature selection using kernel methods in\n  tumor classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transcriptomics of cancer tumors are characterized with tens of thousands\nof gene expression features. Patient prognosis or tumor stage can be assessed\nby machine learning techniques like supervised classification tasks given a\ngene expression profile. Feature selection is a useful approach to select the\nkey genes which helps to classify tumors. In this work we propose a feature\nselection method based on Multiple Kernel Learning that results in a reduced\nsubset of genes and a custom kernel that improves the classification\nperformance when used in support vector classification. During the feature\nselection process this method performs a novel latent regularisation by\nrelaxing the supervised target problem by introducing unsupervised structure\nobtained from the latent space learned by a non linear dimensionality reduction\nmodel. An improvement of the generalization capacity is obtained and assessed\nby the tumor classification performance on new unseen test samples when the\nclassifier is trained with the features selected by the proposed method in\ncomparison with other supervised feature selection approaches.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 00:46:02 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Palazzo", "Martin", ""], ["Yankilevich", "Patricio", ""], ["Beauseroy", "Pierre", ""]]}, {"id": "2004.04871", "submitter": "Satish Viswanath", "authors": "Amir Reza Sadri, Andrew Janowczyk, Ren Zou, Ruchika Verma, Niha Beig,\n  Jacob Antunes, Anant Madabhushi, Pallavi Tiwari, Satish E. Viswanath", "title": "MRQy: An Open-Source Tool for Quality Control of MR Imaging Data", "comments": "28 pages, 7 figures. Submitted to Medical Physics", "journal-ref": null, "doi": "10.1002/mp.14593", "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We sought to develop a quantitative tool to quickly determine relative\ndifferences in MRI volumes both within and between large MR imaging cohorts\n(such as available in The Cancer Imaging Archive (TCIA)), in order to help\ndetermine the generalizability of radiomics and machine learning schemes to\nunseen datasets. The tool is intended to help quantify presence of (a) site- or\nscanner-specific variations in image resolution, field-of-view, or image\ncontrast, or (b) imaging artifacts such as noise, motion, inhomogeneity,\nringing, or aliasing; which can adversely affect relative image quality between\ndata cohorts. We present MRQy, a new open-source quality control tool to (a)\ninterrogate MRI cohorts for site- or equipment-based differences, and (b)\nquantify the impact of MRI artifacts on relative image quality; to help\ndetermine how to correct for these variations prior to model development. MRQy\nextracts a series of quality measures (e.g. noise ratios, variation metrics,\nentropy and energy criteria) and MR image metadata (e.g. voxel resolution,\nimage dimensions) for subsequent interrogation via a specialized HTML5 based\nfront-end designed for real-time filtering and trend visualization. MRQy was\nused to evaluate (a) n=133 brain MRIs from TCIA (7 sites), and (b) n=104 rectal\nMRIs (3 local sites). MRQy measures revealed significant site-specific\nvariations in both cohorts, indicating potential batch effects. Marked\ndifferences in specific MRQy measures were also able to identify outlier MRI\ndatasets that needed to be corrected for common MR imaging artifacts. MRQy is\ndesigned to be a standalone, unsupervised tool that can be efficiently run on a\nstandard desktop computer. It has been made freely accessible at\n\\url{http://github.com/ccipd/MRQy} for wider community use and feedback.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 01:30:51 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 17:42:08 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 14:04:25 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sadri", "Amir Reza", ""], ["Janowczyk", "Andrew", ""], ["Zou", "Ren", ""], ["Verma", "Ruchika", ""], ["Beig", "Niha", ""], ["Antunes", "Jacob", ""], ["Madabhushi", "Anant", ""], ["Tiwari", "Pallavi", ""], ["Viswanath", "Satish E.", ""]]}, {"id": "2004.04872", "submitter": "Razieh Nabi", "authors": "Razieh Nabi, Rohit Bhattacharya, Ilya Shpitser", "title": "Full Law Identification In Graphical Models Of Missing Data:\n  Completeness Results", "comments": "Camera ready version published at ICML 2020", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119, 2020", "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data has the potential to affect analyses conducted in all fields of\nscientific study, including healthcare, economics, and the social sciences.\nSeveral approaches to unbiased inference in the presence of non-ignorable\nmissingness rely on the specification of the target distribution and its\nmissingness process as a probability distribution that factorizes with respect\nto a directed acyclic graph. In this paper, we address the longstanding\nquestion of the characterization of models that are identifiable within this\nclass of missing data distributions. We provide the first completeness result\nin this field of study -- necessary and sufficient graphical conditions under\nwhich, the full data distribution can be recovered from the observed data\ndistribution. We then simultaneously address issues that may arise due to the\npresence of both missing data and unmeasured confounding, by extending these\ngraphical conditions and proofs of completeness, to settings where some\nvariables are not just missing, but completely unobserved.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 01:31:10 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 02:33:55 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 14:28:45 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Nabi", "Razieh", ""], ["Bhattacharya", "Rohit", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2004.04892", "submitter": "Yihong Dong", "authors": "Yihong Dong, Xiaohan Jiang, Huaji Zhou, Yun Lin and Qingjiang Shi", "title": "SR2CNN: Zero-Shot Learning for Signal Recognition", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2021.3070186", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal recognition is one of significant and challenging tasks in the signal\nprocessing and communications field. It is often a common situation that\nthere's no training data accessible for some signal classes to perform a\nrecognition task. Hence, as widely-used in image processing field, zero-shot\nlearning (ZSL) is also very important for signal recognition. Unfortunately,\nZSL regarding this field has hardly been studied due to inexplicable signal\nsemantics. This paper proposes a ZSL framework, signal recognition and\nreconstruction convolutional neural networks (SR2CNN), to address relevant\nproblems in this situation. The key idea behind SR2CNN is to learn the\nrepresentation of signal semantic feature space by introducing a proper\ncombination of cross entropy loss, center loss and autoencoder loss, as well as\nadopting a suitable distance metric space such that semantic features have\ngreater minimal inter-class distance than maximal intra-class distance. The\nproposed SR2CNN can discriminate signals even if no training data is available\nfor some signal class. Moreover, SR2CNN can gradually improve itself in the aid\nof signal detection, because of constantly refined class center vectors in\nsemantic feature space. These merits are all verified by extensive experiments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:24:10 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 12:07:59 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 06:38:31 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 09:59:50 GMT"}, {"version": "v5", "created": "Sat, 13 Jun 2020 02:34:35 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 02:35:18 GMT"}, {"version": "v7", "created": "Wed, 7 Apr 2021 06:55:11 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Dong", "Yihong", ""], ["Jiang", "Xiaohan", ""], ["Zhou", "Huaji", ""], ["Lin", "Yun", ""], ["Shi", "Qingjiang", ""]]}, {"id": "2004.04894", "submitter": "Zhanhong Zhou", "authors": "Zhanhong Zhou, Xiaolong Zhai, Chung Tin", "title": "Fully Automatic Electrocardiogram Classification System based on\n  Generative Adversarial Network with Auxiliary Classifier", "comments": "Accepted for publication in Expert Systems with Applications", "journal-ref": "Expert Systems with Applications, Volume 174, 2021, 114809, ISSN\n  0957-4174", "doi": "10.1016/j.eswa.2021.114809", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A generative adversarial network (GAN) based fully automatic\nelectrocardiogram (ECG) arrhythmia classification system with high performance\nis presented in this paper. The generator (G) in our GAN is designed to\ngenerate various coupling matrix inputs conditioned on different arrhythmia\nclasses for data augmentation. Our designed discriminator (D) is trained on\nboth real and generated ECG coupling matrix inputs, and is extracted as an\narrhythmia classifier upon completion of training for our GAN. After\nfine-tuning the D by including patient-specific normal beats estimated using an\nunsupervised algorithm, and generated abnormal beats by G that are usually rare\nto obtain, our fully automatic system showed superior overall classification\nperformance for both supraventricular ectopic beats (SVEB or S beats) and\nventricular ectopic beats (VEB or V beats) on the MIT-BIH arrhythmia database.\nIt surpassed several state-of-art automatic classifiers and can perform on\nsimilar levels as some expert-assisted methods. In particular, the F1 score of\nSVEB has been improved by up to 13% over the top-performing automatic systems.\nMoreover, high sensitivity for both SVEB (87%) and VEB (93%) detection has been\nachieved, which is of great value for practical diagnosis. We, therefore,\nsuggest our ACE-GAN (Generative Adversarial Network with Auxiliary Classifier\nfor Electrocardiogram) based automatic system can be a promising and reliable\ntool for high throughput clinical screening practice, without any need of\nmanual intervene or expert assisted labeling.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:33:10 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:08:11 GMT"}, {"version": "v3", "created": "Thu, 4 Mar 2021 06:09:24 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Zhou", "Zhanhong", ""], ["Zhai", "Xiaolong", ""], ["Tin", "Chung", ""]]}, {"id": "2004.04898", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Liang Li, Wenjing Fang, Jun Zhou, Li Wang, Lei Wang,\n  Shuang Yang, Alex Liu, and Hao Wang", "title": "Secret Sharing based Secure Regressions with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the utilization of the ever expanding amount of data has made a\nhuge impact on web technologies while also causing various types of security\nconcerns. On one hand, potential gains are highly anticipated if different\norganizations could somehow collaboratively share their data for technological\nimprovements. On the other hand, data security concerns may arise for both data\nholders and data providers due to commercial or sociological concerns. To make\na balance between technical improvements and security limitations, we implement\nsecure and scalable protocols for multiple data holders to train linear\nregression and logistic regression models. We build our protocols based on the\nsecret sharing scheme, which is scalable and efficient in applications.\nMoreover, our proposed paradigm can be generalized to any secure multiparty\ntraining scenarios where only matrix summation and matrix multiplications are\nused. We demonstrate our approach by experiments which shows the scalability\nand efficiency of our proposed protocols, and finally present its real-world\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 04:04:06 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chen", "Chaochao", ""], ["Li", "Liang", ""], ["Fang", "Wenjing", ""], ["Zhou", "Jun", ""], ["Wang", "Li", ""], ["Wang", "Lei", ""], ["Yang", "Shuang", ""], ["Liu", "Alex", ""], ["Wang", "Hao", ""]]}, {"id": "2004.04902", "submitter": "Rohan Jagtap", "authors": "Rohan Jagtap, Dr. Sudhir N. Dhage", "title": "An In-depth Walkthrough on Evolution of Neural Machine Translation", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) methodologies have burgeoned from using\nsimple feed-forward architectures to the state of the art; viz. BERT model. The\nuse cases of NMT models have been broadened from just language translations to\nconversational agents (chatbots), abstractive text summarization, image\ncaptioning, etc. which have proved to be a gem in their respective\napplications. This paper aims to study the major trends in Neural Machine\nTranslation, the state of the art models in the domain and a high level\ncomparison between them.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 04:21:05 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Jagtap", "Rohan", ""], ["Dhage", "Dr. Sudhir N.", ""]]}, {"id": "2004.04907", "submitter": "M\\'arton Karsai", "authors": "Jacob Levy Abitbol and M\\'arton Karsai", "title": "Socioeconomic correlations of urban patterns inferred from aerial\n  images: interpreting activation maps of Convolutional Neural Networks", "comments": "19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urbanisation is a great challenge for modern societies, promising better\naccess to economic opportunities while widening socioeconomic inequalities.\nAccurately tracking how this process unfolds has been challenging for\ntraditional data collection methods, while remote sensing information offers an\nalternative to gather a more complete view on these societal changes. By\nfeeding a neural network with satellite images one may recover the\nsocioeconomic information associated to that area, however these models lack to\nexplain how visual features contained in a sample, trigger a given prediction.\nHere we close this gap by predicting socioeconomic status across France from\naerial images and interpreting class activation mappings in terms of urban\ntopology. We show that the model disregards the spatial correlations existing\nbetween urban class and socioeconomic status to derive its predictions. These\nresults pave the way to build interpretable models, which may help to better\ntrack and understand urbanisation and its consequences.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 04:57:20 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Abitbol", "Jacob Levy", ""], ["Karsai", "M\u00e1rton", ""]]}, {"id": "2004.04917", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani and Liwei Wu and Shengli Hu and Joel Tetreault and\n  Alejandro Jaimes", "title": "Multimodal Categorization of Crisis Events in Social Media", "comments": "Conference on Computer Vision and Pattern Recognition (CVPR 2020)", "journal-ref": "Conference on Computer Vision and Pattern Recognition (CVPR 2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent developments in image classification and natural language processing,\ncoupled with the rapid growth in social media usage, have enabled fundamental\nadvances in detecting breaking events around the world in real-time. Emergency\nresponse is one such area that stands to gain from these advances. By\nprocessing billions of texts and images a minute, events can be automatically\ndetected to enable emergency response workers to better assess rapidly evolving\nsituations and deploy resources accordingly. To date, most event detection\ntechniques in this area have focused on image-only or text-only approaches,\nlimiting detection performance and impacting the quality of information\ndelivered to crisis response teams. In this paper, we present a new multimodal\nfusion method that leverages both images and texts as input. In particular, we\nintroduce a cross-attention module that can filter uninformative and misleading\ncomponents from weak modalities on a sample by sample basis. In addition, we\nemploy a multimodal graph-based approach to stochastically transition between\nembeddings of different multimodal pairs during training to better regularize\nthe learning process as well as dealing with limited training data by\nconstructing new matched pairs from different samples. We show that our method\noutperforms the unimodal approaches and strong multimodal baselines by a large\nmargin on three crisis-related tasks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 06:31:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Wu", "Liwei", ""], ["Hu", "Shengli", ""], ["Tetreault", "Joel", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "2004.04919", "submitter": "R\\'emi Bernhard", "authors": "R\\'emi Bernhard, Pierre-Alain Moellic, Jean-Max Dutertre", "title": "Luring of transferable adversarial perturbations in the black-box\n  paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest for adversarial examples, i.e. maliciously modified\nexamples which fool a classifier, has resulted in many defenses intended to\ndetect them, render them inoffensive or make the model more robust against\nthem. In this paper, we pave the way towards a new approach to improve the\nrobustness of a model against black-box transfer attacks. A removable\nadditional neural network is included in the target model, and is designed to\ninduce the \\textit{luring effect}, which tricks the adversary into choosing\nfalse directions to fool the target model. Training the additional model is\nachieved thanks to a loss function acting on the logits sequence order. Our\ndeception-based method only needs to have access to the predictions of the\ntarget model and does not require a labeled data set. We explain the luring\neffect thanks to the notion of robust and non-robust useful features and\nperform experiments on MNIST, SVHN and CIFAR10 to characterize and evaluate\nthis phenomenon. Additionally, we discuss two simple prediction schemes, and\nverify experimentally that our approach can be used as a defense to efficiently\nthwart an adversary using state-of-the-art attacks and allowed to perform large\nperturbations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 06:48:36 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 08:46:39 GMT"}, {"version": "v3", "created": "Wed, 3 Mar 2021 15:52:41 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Bernhard", "R\u00e9mi", ""], ["Moellic", "Pierre-Alain", ""], ["Dutertre", "Jean-Max", ""]]}, {"id": "2004.04926", "submitter": "TImothee Lacroix", "authors": "Timoth\\'ee Lacroix, Guillaume Obozinski and Nicolas Usunier", "title": "Tensor Decompositions for temporal knowledge base completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most algorithms for representation learning and link prediction in relational\ndata have been designed for static data. However, the data they are applied to\nusually evolves with time, such as friend graphs in social networks or user\ninteractions with items in recommender systems. This is also the case for\nknowledge bases, which contain facts such as (US, has president, B. Obama,\n[2009-2017]) that are valid only at certain points in time. For the problem of\nlink prediction under temporal constraints, i.e., answering queries such as\n(US, has president, ?, 2012), we propose a solution inspired by the canonical\ndecomposition of tensors of order 4. We introduce new regularization schemes\nand present an extension of ComplEx (Trouillon et al., 2016) that achieves\nstate-of-the-art performance. Additionally, we propose a new dataset for\nknowledge base completion constructed from Wikidata, larger than previous\nbenchmarks by an order of magnitude, as a new reference for evaluating temporal\nand non-temporal link prediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 07:09:30 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Lacroix", "Timoth\u00e9e", ""], ["Obozinski", "Guillaume", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2004.04931", "submitter": "Asif Iqbal Khan", "authors": "Asif Iqbal Khan, Junaid Latief Shah, Mudasir Bhat", "title": "CoroNet: A deep neural network for detection and diagnosis of COVID-19\n  from chest x-ray images", "comments": "9 pages, 8 Figures and 8 Tables", "journal-ref": "Computer Methods and Programs in Biomedicine 196C (2020) 105581", "doi": "10.1016/j.cmpb.2020.105581", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Objective\n  The novel Coronavirus also called COVID-19 originated in Wuhan, China in\nDecember 2019 and has now spread across the world. It has so far infected\naround 1.8 million people and claimed approximately 114,698 lives overall. As\nthe number of cases are rapidly increasing, most of the countries are facing\nshortage of testing kits and resources. The limited quantity of testing kits\nand increasing number of daily cases encouraged us to come up with a Deep\nLearning model that can aid radiologists and clinicians in detecting COVID-19\ncases using chest X-rays.\n  Methods\n  In this study, we propose CoroNet, a Deep Convolutional Neural Network model\nto automatically detect COVID-19 infection from chest X-ray images. The\nproposed model is based on Xception architecture pre-trained on ImageNet\ndataset and trained end-to-end on a dataset prepared by collecting COVID-19 and\nother chest pneumonia X-ray images from two different publically available\ndatabases.\n  Results and Conclusion\n  CoroNet has been trained and tested on the prepared dataset and the\nexperimental results show that our proposed model achieved an overall accuracy\nof 89.6%, and more importantly the precision and recall rate for COVID-19 cases\nare 93% and 98.2% for 4-class cases (COVID vs Pneumonia bacterial vs pneumonia\nviral vs normal). For 3-class classification (COVID vs Pneumonia vs normal),\nthe proposed model produced a classification accuracy of 95%. The preliminary\nresults of this study look promising which can be further improved as more\ntraining data becomes available. Overall, the proposed model substantially\nadvances the current radiology based methodology and during COVID-19 pandemic,\nit can be very helpful tool for clinical practitioners and radiologists to aid\nthem in diagnosis, quantification and follow-up of COVID-19 cases.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 07:46:07 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 13:48:04 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 07:04:19 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Khan", "Asif Iqbal", ""], ["Shah", "Junaid Latief", ""], ["Bhat", "Mudasir", ""]]}, {"id": "2004.04943", "submitter": "Beichen Zhang", "authors": "Beichen Zhang (1), Liang Li (2), Shijie Yang (1, 2), Shuhui Wang (2),\n  Zheng-Jun Zha (3), Qingming Huang (1, 2, 4) ((1) University of Chinese\n  Academy of Sciences. (2) Key Lab of Intell. Info. Process., Inst. of Comput.\n  Tech., Chinese Academy of Sciences. (3) University of Science and Technology\n  of China. (4) Peng Cheng Laboratory.)", "title": "State-Relabeling Adversarial Active Learning", "comments": "Accepted as Oral at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning is to design label-efficient algorithms by sampling the most\nrepresentative samples to be labeled by an oracle. In this paper, we propose a\nstate relabeling adversarial active learning model (SRAAL), that leverages both\nthe annotation and the labeled/unlabeled state information for deriving the\nmost informative unlabeled samples. The SRAAL consists of a representation\ngenerator and a state discriminator. The generator uses the complementary\nannotation information with traditional reconstruction information to generate\nthe unified representation of samples, which embeds the semantic into the whole\ndata representation. Then, we design an online uncertainty indicator in the\ndiscriminator, which endues unlabeled samples with different importance. As a\nresult, we can select the most informative samples based on the discriminator's\npredicted state. We also design an algorithm to initialize the labeled pool,\nwhich makes subsequent sampling more efficient. The experiments conducted on\nvarious datasets show that our model outperforms the previous state-of-art\nactive learning methods and our initially sampling algorithm achieves better\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:23:59 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Zhang", "Beichen", ""], ["Li", "Liang", ""], ["Yang", "Shijie", ""], ["Wang", "Shuhui", ""], ["Zha", "Zheng-Jun", ""], ["Huang", "Qingming", ""]]}, {"id": "2004.04946", "submitter": "Yuying Liu", "authors": "Yuying Liu, Colin Ponce, Steven L. Brunton, J. Nathan Kutz", "title": "Multiresolution Convolutional Autoencoders", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-resolution convolutional autoencoder (MrCAE) architecture\nthat integrates and leverages three highly successful mathematical\narchitectures: (i) multigrid methods, (ii) convolutional autoencoders and (iii)\ntransfer learning. The method provides an adaptive, hierarchical architecture\nthat capitalizes on a progressive training approach for multiscale\nspatio-temporal data. This framework allows for inputs across multiple scales:\nstarting from a compact (small number of weights) network architecture and\nlow-resolution data, our network progressively deepens and widens itself in a\nprincipled manner to encode new information in the higher resolution data based\non its current performance of reconstruction. Basic transfer learning\ntechniques are applied to ensure information learned from previous training\nsteps can be rapidly transferred to the larger network. As a result, the\nnetwork can dynamically capture different scaled features at different depths\nof the network. The performance gains of this adaptive multiscale architecture\nare illustrated through a sequence of numerical experiments on synthetic\nexamples and real-world spatial-temporal data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:31:59 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Liu", "Yuying", ""], ["Ponce", "Colin", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2004.04948", "submitter": "Mehmet Emre Ozfatura", "authors": "Emre Ozfatura, Sennur Ulukus, Deniz Gunduz", "title": "Straggler-aware Distributed Learning: Communication Computation Latency\n  Trade-off", "comments": "This paper was presented in part at the 2019 IEEE International\n  Symposium on Information Theory (ISIT) in Paris, France, and at the 2019 IEEE\n  Data Science Workshop in Minneapolis, USA", "journal-ref": null, "doi": "10.3390/e22050544", "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When gradient descent (GD) is scaled to many parallel workers for large scale\nmachine learning problems, its per-iteration computation time is limited by the\nstraggling workers. Straggling workers can be tolerated by assigning redundant\ncomputations and coding across data and computations, but in most existing\nschemes, each non-straggling worker transmits one message per iteration to the\nparameter server (PS) after completing all its computations. Imposing such a\nlimitation results in two main drawbacks; over-computation due to inaccurate\nprediction of the straggling behaviour, and under-utilization due to treating\nworkers as straggler/non-straggler and discarding partial computations carried\nout by stragglers. In this paper, to overcome these drawbacks, we consider\nmulti-message communication (MMC) by allowing multiple computations to be\nconveyed from each worker per iteration, and design straggler avoidance\ntechniques accordingly. Then, we analyze how the proposed designs can be\nemployed efficiently to seek a balance between the computation and\ncommunication latency to minimize the overall latency. Furthermore, through\nextensive simulations, both model-based and real implementation on Amazon EC2\nservers, we identify the advantages and disadvantages of these designs in\ndifferent settings, and demonstrate that MMC can help improve upon existing\nstraggler avoidance schemes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:39:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ozfatura", "Emre", ""], ["Ulukus", "Sennur", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2004.04954", "submitter": "Piotr Bojanowski", "authors": "Lina Mezghani, Sainbayar Sukhbaatar, Arthur Szlam, Armand Joulin,\n  Piotr Bojanowski", "title": "Learning to Visually Navigate in Photorealistic Environments Without any\n  Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to navigate in a realistic setting where an agent must rely solely\non visual inputs is a challenging task, in part because the lack of position\ninformation makes it difficult to provide supervision during training. In this\npaper, we introduce a novel approach for learning to navigate from image inputs\nwithout external supervision or reward. Our approach consists of three stages:\nlearning a good representation of first-person views, then learning to explore\nusing memory, and finally learning to navigate by setting its own goals. The\nmodel is trained with intrinsic rewards only so that it can be applied to any\nenvironment with image observations. We show the benefits of our approach by\ntraining an agent to navigate challenging photo-realistic environments from the\nGibson dataset with RGB inputs only.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 08:59:32 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Mezghani", "Lina", ""], ["Sukhbaatar", "Sainbayar", ""], ["Szlam", "Arthur", ""], ["Joulin", "Armand", ""], ["Bojanowski", "Piotr", ""]]}, {"id": "2004.04955", "submitter": "Jinlin Liu", "authors": "Jinlin Liu, Yuan Yao, Wendi Hou, Miaomiao Cui, Xuansong Xie, Changshui\n  Zhang, Xian-sheng Hua", "title": "Boosting Semantic Human Matting with Coarse Annotations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic human matting aims to estimate the per-pixel opacity of the\nforeground human regions. It is quite challenging and usually requires user\ninteractive trimaps and plenty of high quality annotated data. Annotating such\nkind of data is labor intensive and requires great skills beyond normal users,\nespecially considering the very detailed hair part of humans. In contrast,\ncoarse annotated human dataset is much easier to acquire and collect from the\npublic dataset. In this paper, we propose to use coarse annotated data coupled\nwith fine annotated data to boost end-to-end semantic human matting without\ntrimaps as extra input. Specifically, we train a mask prediction network to\nestimate the coarse semantic mask using the hybrid data, and then propose a\nquality unification network to unify the quality of the previous coarse mask\noutputs. A matting refinement network takes in the unified mask and the input\nimage to predict the final alpha matte. The collected coarse annotated dataset\nenriches our dataset significantly, allows generating high quality alpha matte\nfor real images. Experimental results show that the proposed method performs\ncomparably against state-of-the-art methods. Moreover, the proposed method can\nbe used for refining coarse annotated public dataset, as well as semantic\nsegmentation methods, which reduces the cost of annotating high quality human\ndata to a great extent.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 09:11:02 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Liu", "Jinlin", ""], ["Yao", "Yuan", ""], ["Hou", "Wendi", ""], ["Cui", "Miaomiao", ""], ["Xie", "Xuansong", ""], ["Zhang", "Changshui", ""], ["Hua", "Xian-sheng", ""]]}, {"id": "2004.04972", "submitter": "Alistair Conkie", "authors": "Soumi Maiti, Erik Marchi, Alistair Conkie", "title": "Generating Multilingual Voices Using Speaker Space Translation Based on\n  Bilingual Speaker Data", "comments": "Accepted to IEEE ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present progress towards bilingual Text-to-Speech which is able to\ntransform a monolingual voice to speak a second language while preserving\nspeaker voice quality. We demonstrate that a bilingual speaker embedding space\ncontains a separate distribution for each language and that a simple transform\nin speaker space generated by the speaker embedding can be used to control the\ndegree of accent of a synthetic voice in a language. The same transform can be\napplied even to monolingual speakers.\n  In our experiments speaker data from an English-Spanish (Mexican) bilingual\nspeaker was used, and the goal was to enable English speakers to speak Spanish\nand Spanish speakers to speak English. We found that the simple transform was\nsufficient to convert a voice from one language to the other with a high degree\nof naturalness. In one case the transformed voice outperformed a native\nlanguage voice in listening tests. Experiments further indicated that the\ntransform preserved many of the characteristics of the original voice. The\ndegree of accent present can be controlled and naturalness is relatively\nconsistent across a range of accent values.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:01:53 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Maiti", "Soumi", ""], ["Marchi", "Erik", ""], ["Conkie", "Alistair", ""]]}, {"id": "2004.04977", "submitter": "Evangelos Ntavelis", "authors": "Evangelos Ntavelis, Andr\\'es Romero, Iason Kastanis, Luc Van Gool and\n  Radu Timofte", "title": "SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing\n  Objects", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58542-6_24", "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in image generation gave rise to powerful tools for semantic\nimage editing. However, existing approaches can either operate on a single\nimage or require an abundance of additional information. They are not capable\nof handling the complete set of editing operations, that is addition,\nmanipulation or removal of semantic concepts. To address these limitations, we\npropose SESAME, a novel generator-discriminator pair for Semantic Editing of\nScenes by Adding, Manipulating or Erasing objects. In our setup, the user\nprovides the semantic labels of the areas to be edited and the generator\nsynthesizes the corresponding pixels. In contrast to previous methods that\nemploy a discriminator that trivially concatenates semantics and image as an\ninput, the SESAME discriminator is composed of two input streams that\nindependently process the image and its semantics, using the latter to\nmanipulate the results of the former. We evaluate our model on a diverse set of\ndatasets and report state-of-the-art performance on two tasks: (a) image\nmanipulation and (b) image generation conditioned on semantic labels.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:19:19 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 14:52:01 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ntavelis", "Evangelos", ""], ["Romero", "Andr\u00e9s", ""], ["Kastanis", "Iason", ""], ["Van Gool", "Luc", ""], ["Timofte", "Radu", ""]]}, {"id": "2004.04978", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr, Martin Krejca", "title": "A Simplified Run Time Analysis of the Univariate Marginal Distribution\n  Algorithm on LeadingOnes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With elementary means, we prove a stronger run time guarantee for the\nunivariate marginal distribution algorithm (UMDA) optimizing the LeadingOnes\nbenchmark function in the desirable regime with low genetic drift. If the\npopulation size is at least quasilinear, then, with high probability, the UMDA\nsamples the optimum within a number of iterations that is linear in the problem\nsize divided by the logarithm of the UMDA's selection rate. This improves over\nthe previous guarantee, obtained by Dang and Lehre (2015) via the deep\nlevel-based population method, both in terms of the run time and by\ndemonstrating further run time gains from small selection rates. With similar\narguments as in our upper-bound analysis, we also obtain the first lower bound\nfor this problem. Under similar assumptions, we prove that a bound that matches\nour upper bound up to constant factors holds with high probability.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:20:05 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Doerr", "Benjamin", ""], ["Krejca", "Martin", ""]]}, {"id": "2004.04979", "submitter": "Jiawei Liu", "authors": "Jiawei Liu, Zheng-Jun Zha, Xierong Zhu, Na Jiang", "title": "Co-Saliency Spatio-Temporal Interaction Network for Person\n  Re-Identification in Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification aims at identifying a certain pedestrian across\nnon-overlapping camera networks. Video-based re-identification approaches have\ngained significant attention recently, expanding image-based approaches by\nlearning features from multiple frames. In this work, we propose a novel\nCo-Saliency Spatio-Temporal Interaction Network (CSTNet) for person\nre-identification in videos. It captures the common salient foreground regions\namong video frames and explores the spatial-temporal long-range context\ninterdependency from such regions, towards learning discriminative pedestrian\nrepresentation. Specifically, multiple co-saliency learning modules within\nCSTNet are designed to utilize the correlated information across video frames\nto extract the salient features from the task-relevant regions and suppress\nbackground interference. Moreover, multiple spatialtemporal interaction modules\nwithin CSTNet are proposed, which exploit the spatial and temporal long-range\ncontext interdependencies on such features and spatial-temporal information\ncorrelation, to enhance feature representation. Extensive experiments on two\nbenchmarks have demonstrated the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:23:58 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 10:04:19 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Jiawei", ""], ["Zha", "Zheng-Jun", ""], ["Zhu", "Xierong", ""], ["Jiang", "Na", ""]]}, {"id": "2004.04980", "submitter": "Anastasia Funkner", "authors": "Anastasia Funkner, Ksenia Balabaeva, Sergey Kovalchuk", "title": "Negation Detection for Clinical Text Mining in Russian", "comments": "5 pages, 1 figure, 3 tables, accepted for the conference MIE 2020", "journal-ref": null, "doi": "10.3233/SHTI200179", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing predictive modeling in medicine requires additional features from\nunstructured clinical texts. In Russia, there are no instruments for natural\nlanguage processing to cope with problems of medical records. This paper is\ndevoted to a module of negation detection. The corpus-free machine learning\nmethod is based on gradient boosting classifier is used to detect whether a\ndisease is denied, not mentioned or presented in the text. The detector\nclassifies negations for five diseases and shows average F-score from 0.81 to\n0.93. The benefits of negation detection have been demonstrated by predicting\nthe presence of surgery for patients with the acute coronary syndrome.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:38:33 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Funkner", "Anastasia", ""], ["Balabaeva", "Ksenia", ""], ["Kovalchuk", "Sergey", ""]]}, {"id": "2004.04986", "submitter": "Amit Portnoy", "authors": "Amit Portnoy, Yoav Tirosh, and Danny Hendler", "title": "Towards Federated Learning With Byzantine-Robust Client Weighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) is a distributed machine learning paradigm where data\nis distributed among clients who collaboratively train a model in a computation\nprocess coordinated by a central server. By assigning a weight to each client\nbased on the proportion of data instances it possesses, the rate of convergence\nto an accurate joint model can be greatly accelerated. Some previous works\nstudied FL in a Byzantine setting, in which a fraction of the clients may send\narbitrary or even malicious information regarding their model. However, these\nworks either ignore the issue of data unbalancedness altogether or assume that\nclient weights are apriori known to the server, whereas, in practice, it is\nlikely that weights will be reported to the server by the clients themselves\nand therefore cannot be relied upon. We address this issue for the first time\nby proposing a practical weight-truncation-based preprocessing method and\ndemonstrating empirically that it is able to strike a good balance between\nmodel quality and Byzantine robustness. We also establish analytically that our\nmethod can be applied to a randomly selected sample of client weights.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 10:59:16 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 08:10:10 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Portnoy", "Amit", ""], ["Tirosh", "Yoav", ""], ["Hendler", "Danny", ""]]}, {"id": "2004.05001", "submitter": "Ivan P Yamshchikov", "authors": "Ivan P. Yamshchikov, Viacheslav Shibaev, Nikolay Khlebnikov, Alexey\n  Tikhonov", "title": "Style-transfer and Paraphrase: Looking for a Sensible Semantic\n  Similarity Metric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of such natural language processing tasks as style\ntransfer, paraphrase, and machine translation often calls for the use of\nsemantic similarity metrics. In recent years a lot of methods to measure the\nsemantic similarity of two short texts were developed. This paper provides a\ncomprehensive analysis for more than a dozen of such methods. Using a new\ndataset of fourteen thousand sentence pairs human-labeled according to their\nsemantic similarity, we demonstrate that none of the metrics widely used in the\nliterature is close enough to human judgment in these tasks. A number of\nrecently proposed metrics provide comparable results, yet Word Mover Distance\nis shown to be the most reasonable solution to measure semantic similarity in\nreformulated texts at the moment.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 11:52:06 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 14:10:24 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 21:58:57 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yamshchikov", "Ivan P.", ""], ["Shibaev", "Viacheslav", ""], ["Khlebnikov", "Nikolay", ""], ["Tikhonov", "Alexey", ""]]}, {"id": "2004.05002", "submitter": "Reza Bonyadi", "authors": "Mohammad Reza Bonyadi, Rui Wang, Maryam Ziaei", "title": "Self Punishment and Reward Backfill for Deep Q-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents learn by encouraging behaviours which maximize\ntheir total reward, usually provided by the environment. In many environments,\nhowever, the reward is provided after a series of actions rather than each\nsingle action, causing the agent to experience ambiguity in terms of whether\nthose actions are effective, an issue called the credit assignment problem. In\nthis paper, we propose two strategies, inspired by behavioural psychology, to\nestimate a more informative reward value for actions with no reward. The first\nstrategy, called self-punishment, discourages the agent to avoid making\nmistakes, i.e., actions which lead to a terminal state. The second strategy,\ncalled the rewards backfill, backpropagates the rewards between two rewarded\nactions. We prove that, under certain assumptions, these two strategies\nmaintain the order of the policies in the space of all possible policies in\nterms of their total reward, and, by extension, maintain the optimal policy. We\nincorporated these two strategies into three popular deep reinforcement\nlearning approaches and evaluated the results on thirty Atari games. After\nparameter tuning, our results indicate that the proposed strategies improve the\ntested methods in over 65 percent of tested games by up to over 25 times\nperformance improvement.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 11:53:11 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Wang", "Rui", ""], ["Ziaei", "Maryam", ""]]}, {"id": "2004.05005", "submitter": "Eirini Anthi", "authors": "Eirini Anthi, Lowri Williams, Matilda Rhode, Pete Burnap, Adam\n  Wedgbury", "title": "Adversarial Attacks on Machine Learning Cybersecurity Defences in\n  Industrial Control Systems", "comments": "9 pages. 7 figures. 7 tables. 46 references. Submitted to a special\n  issue Journal of Information Security and Applications, Machine Learning\n  Techniques for Cyber Security: Challenges and Future Trends, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation and application of machine learning based Intrusion\nDetection Systems (IDS) have allowed for more flexibility and efficiency in the\nautomated detection of cyber attacks in Industrial Control Systems (ICS).\nHowever, the introduction of such IDSs has also created an additional attack\nvector; the learning models may also be subject to cyber attacks, otherwise\nreferred to as Adversarial Machine Learning (AML). Such attacks may have severe\nconsequences in ICS systems, as adversaries could potentially bypass the IDS.\nThis could lead to delayed attack detection which may result in infrastructure\ndamages, financial loss, and even loss of life. This paper explores how\nadversarial learning can be used to target supervised models by generating\nadversarial samples using the Jacobian-based Saliency Map attack and exploring\nclassification behaviours. The analysis also includes the exploration of how\nsuch samples can support the robustness of supervised models using adversarial\ntraining. An authentic power system dataset was used to support the experiments\npresented herein. Overall, the classification performance of two widely used\nclassifiers, Random Forest and J48, decreased by 16 and 20 percentage points\nwhen adversarial samples were present. Their performances improved following\nadversarial training, demonstrating their robustness towards such attacks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:05:33 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Anthi", "Eirini", ""], ["Williams", "Lowri", ""], ["Rhode", "Matilda", ""], ["Burnap", "Pete", ""], ["Wedgbury", "Adam", ""]]}, {"id": "2004.05007", "submitter": "Yo Joong Choe", "authors": "Yo Joong Choe, Jiyeon Ham, Kyubyong Park", "title": "An Empirical Study of Invariant Risk Minimization", "comments": "Presented at the ICML 2020 Workshop on Uncertainty and Robustness in\n  Deep Learning. Code at https://github.com/kakaobrain/irm-empirical-study", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Invariant risk minimization (IRM) (Arjovsky et al., 2019) is a recently\nproposed framework designed for learning predictors that are invariant to\nspurious correlations across different training environments. Yet, despite its\ntheoretical justifications, IRM has not been extensively tested across various\nsettings. In an attempt to gain a better understanding of the framework, we\nempirically investigate several research questions using IRMv1, which is the\nfirst practical algorithm proposed to approximately solve IRM. By extending the\nColoredMNIST experiment in different ways, we find that IRMv1 (i) performs\nbetter as the spurious correlation varies more widely between training\nenvironments, (ii) learns an approximately invariant predictor when the\nunderlying relationship is approximately invariant, and (iii) can be extended\nto an analogous setting for text classification.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:23:29 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 09:10:51 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Choe", "Yo Joong", ""], ["Ham", "Jiyeon", ""], ["Park", "Kyubyong", ""]]}, {"id": "2004.05013", "submitter": "Celine Beji", "authors": "C\\'eline Beji, Micha\\\"el Bon, Florian Yger, Jamal Atif", "title": "Estimating Individual Treatment Effects through Causal Populations\n  Identification", "comments": "Accepted (to appear) in ESANN 2020 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium), 2-4 October 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the Individual Treatment Effect from observational data, defined\nas the difference between outcomes with and without treatment or intervention,\nwhile observing just one of both, is a challenging problems in causal learning.\nIn this paper, we formulate this problem as an inference from hidden variables\nand enforce causal constraints based on a model of four exclusive causal\npopulations. We propose a new version of the EM algorithm, coined as\nExpected-Causality-Maximization (ECM) algorithm and provide hints on its\nconvergence under mild conditions. We compare our algorithm to baseline methods\non synthetic and real-world data and discuss its performances.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 12:51:19 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 12:59:34 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 11:12:37 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Beji", "C\u00e9line", ""], ["Bon", "Micha\u00ebl", ""], ["Yger", "Florian", ""], ["Atif", "Jamal", ""]]}, {"id": "2004.05024", "submitter": "Marvin Lerousseau", "authors": "Marvin Lerousseau, Maria Vakalopoulou, Marion Classe, Julien Adam,\n  Enzo Battistella, Alexandre Carr\\'e, Th\\'eo Estienne, Th\\'eophraste Henry,\n  Eric Deutsch, Nikos Paragios", "title": "Weakly supervised multiple instance learning histopathological tumor\n  segmentation", "comments": "Accepted MICCAI 2020; added code + results url; 10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Histopathological image segmentation is a challenging and important topic in\nmedical imaging with tremendous potential impact in clinical practice. State of\nthe art methods rely on hand-crafted annotations which hinder clinical\ntranslation since histology suffers from significant variations between cancer\nphenotypes. In this paper, we propose a weakly supervised framework for whole\nslide imaging segmentation that relies on standard clinical annotations,\navailable in most medical systems. In particular, we exploit a multiple\ninstance learning scheme for training models. The proposed framework has been\nevaluated on multi-locations and multi-centric public data from The Cancer\nGenome Atlas and the PatchCamelyon dataset. Promising results when compared\nwith experts' annotations demonstrate the potentials of the presented approach.\nThe complete framework, including $6481$ generated tumor maps and data\nprocessing, is available at https://github.com/marvinler/tcga_segmentation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 13:12:47 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 15:53:24 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 16:47:54 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 12:26:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lerousseau", "Marvin", ""], ["Vakalopoulou", "Maria", ""], ["Classe", "Marion", ""], ["Adam", "Julien", ""], ["Battistella", "Enzo", ""], ["Carr\u00e9", "Alexandre", ""], ["Estienne", "Th\u00e9o", ""], ["Henry", "Th\u00e9ophraste", ""], ["Deutsch", "Eric", ""], ["Paragios", "Nikos", ""]]}, {"id": "2004.05041", "submitter": "Sayan Putatunda PhD", "authors": "Sayan Putatunda and Kiran Rama", "title": "A Modified Bayesian Optimization based Hyper-Parameter Tuning Approach\n  for Extreme Gradient Boosting", "comments": "Pre-review version of the paper submitted to IEEE 2019 Fifteenth\n  International Conference on Information Processing (ICINPRO). The paper is\n  accepted for publication", "journal-ref": null, "doi": "10.1109/ICInPro47689.2019.9092025", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is already reported in the literature that the performance of a machine\nlearning algorithm is greatly impacted by performing proper Hyper-Parameter\noptimization. One of the ways to perform Hyper-Parameter optimization is by\nmanual search but that is time consuming. Some of the common approaches for\nperforming Hyper-Parameter optimization are Grid search Random search and\nBayesian optimization using Hyperopt. In this paper, we propose a brand new\napproach for hyperparameter improvement i.e. Randomized-Hyperopt and then tune\nthe hyperparameters of the XGBoost i.e. the Extreme Gradient Boosting algorithm\non ten datasets by applying Random search, Randomized-Hyperopt, Hyperopt and\nGrid Search. The performances of each of these four techniques were compared by\ntaking both the prediction accuracy and the execution time into consideration.\nWe find that the Randomized-Hyperopt performs better than the other three\nconventional methods for hyper-paramter optimization of XGBoost.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:09:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Putatunda", "Sayan", ""], ["Rama", "Kiran", ""]]}, {"id": "2004.05048", "submitter": "James Murphy", "authors": "Shukun Zhang and James M. Murphy", "title": "Hyperspectral Image Clustering with Spatially-Regularized Ultrametrics", "comments": "5 pages, 2 columns, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for the unsupervised clustering of hyperspectral images\nbased on spatially regularized spectral clustering with ultrametric path\ndistances. The proposed method efficiently combines data density and geometry\nto distinguish between material classes in the data, without the need for\ntraining labels. The proposed method is efficient, with quasilinear scaling in\nthe number of data points, and enjoys robust theoretical performance\nguarantees. Extensive experiments on synthetic and real HSI data demonstrate\nits strong performance compared to benchmark and state-of-the-art methods. In\nparticular, the proposed method achieves not only excellent labeling accuracy,\nbut also efficiently estimates the number of clusters.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:27:41 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Zhang", "Shukun", ""], ["Murphy", "James M.", ""]]}, {"id": "2004.05082", "submitter": "Xinyue Liang", "authors": "Xinyue Liang, Alireza M. Javid, Mikael Skoglund, Saikat Chatterjee", "title": "Asynchronous Decentralized Learning of a Neural Network", "comments": null, "journal-ref": "2020 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we exploit an asynchronous computing framework namely ARock to\nlearn a deep neural network called self-size estimating feedforward neural\nnetwork (SSFN) in a decentralized scenario. Using this algorithm namely\nasynchronous decentralized SSFN (dSSFN), we provide the centralized equivalent\nsolution under certain technical assumptions. Asynchronous dSSFN relaxes the\ncommunication bottleneck by allowing one node activation and one side\ncommunication, which reduces the communication overhead significantly,\nconsequently increasing the learning speed. We compare asynchronous dSSFN with\ntraditional synchronous dSSFN in the experimental results, which shows the\ncompetitive performance of asynchronous dSSFN, especially when the\ncommunication network is sparse.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 15:53:37 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Liang", "Xinyue", ""], ["Javid", "Alireza M.", ""], ["Skoglund", "Mikael", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "2004.05089", "submitter": "Navid Khoshavi", "authors": "Navid Khoshavi, Saman Sargolzaei, Arman Roohi, Connor Broyles, Yu Bi", "title": "Entropy-Based Modeling for Estimating Soft Errors Impact on Binarized\n  Neural Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past years, the easy accessibility to the large scale datasets has\nsignificantly shifted the paradigm for developing highly accurate prediction\nmodels that are driven from Neural Network (NN). These models can be\npotentially impacted by the radiation-induced transient faults that might lead\nto the gradual downgrade of the long-running expected NN inference accelerator.\nThe crucial observation from our rigorous vulnerability assessment on the NN\ninference accelerator demonstrates that the weights and activation functions\nare unevenly susceptible to both single-event upset (SEU) and multi-bit upset\n(MBU), especially in the first five layers of our selected convolution neural\nnetwork. In this paper, we present the relatively-accurate statistical models\nto delineate the impact of both undertaken SEU and MBU across layers and per\neach layer of the selected NN. These models can be used for evaluating the\nerror-resiliency magnitude of NN topology before adopting them in the\nsafety-critical applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:10:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:01:53 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Khoshavi", "Navid", ""], ["Sargolzaei", "Saman", ""], ["Roohi", "Arman", ""], ["Broyles", "Connor", ""], ["Bi", "Yu", ""]]}, {"id": "2004.05094", "submitter": "Michael Murray", "authors": "Michael Murray, Jared Tanner", "title": "Encoder blind combinatorial compressed sensing", "comments": "41 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In its most elementary form, compressed sensing studies the design of\ndecoding algorithms to recover a sufficiently sparse vector or code from a\nlower dimensional linear measurement vector. Typically it is assumed that the\ndecoder has access to the encoder matrix, which in the combinatorial case is\nsparse and binary. In this paper we consider the problem of designing a decoder\nto recover a set of sparse codes from their linear measurements alone, that is\nwithout access to encoder matrix. To this end we study the matrix factorisation\ntask of recovering both the encoder and sparse coding matrices from the\nassociated linear measurement matrix. The contribution of this paper is a\ncomputationally efficient decoding algorithm, Decoder-Expander Based\nFactorisation, with strong performance guarantees. In particular, under mild\nassumptions on the sparse coding matrix and by deploying a novel random encoder\nmatrix, we prove that Decoder-Expander Based Factorisation recovers both the\nencoder and sparse coding matrix at the optimal measurement rate with high\nprobability and from a near optimal number of measurement vectors. In addition,\nour experiments demonstrate the efficacy and computational efficiency of our\nalgorithm in practice. Beyond compressed sensing our results may be of interest\nfor researchers working in areas such as linear sketching, coding theory and\nmatrix compression.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:26:11 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 08:30:29 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Murray", "Michael", ""], ["Tanner", "Jared", ""]]}, {"id": "2004.05100", "submitter": "Rohit Jena", "authors": "Rohit Jena, Shirsendu Sukanta Halder, Katia Sycara", "title": "MA 3 : Model Agnostic Adversarial Augmentation for Few Shot learning", "comments": "Accepted at CVPR Workshop on Visual Learning with Limited Labels 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent developments in vision-related problems using deep neural\nnetworks, there still remains a wide scope in the improvement of generalizing\nthese models to unseen examples. In this paper, we explore the domain of\nfew-shot learning with a novel augmentation technique. In contrast to other\ngenerative augmentation techniques, where the distribution over input images\nare learnt, we propose to learn the probability distribution over the image\ntransformation parameters which are easier and quicker to learn. Our technique\nis fully differentiable which enables its extension to versatile data-sets and\nbase models. We evaluate our proposed method on multiple base-networks and 2\ndata-sets to establish the robustness and efficiency of this method. We obtain\nan improvement of nearly 4% by adding our augmentation module without making\nany change in network architectures. We also make the code readily available\nfor usage by the community.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:35:49 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Jena", "Rohit", ""], ["Halder", "Shirsendu Sukanta", ""], ["Sycara", "Katia", ""]]}, {"id": "2004.05107", "submitter": "Jessica Hamrick", "authors": "Jessica Hamrick and Shakir Mohamed", "title": "Levels of Analysis for Machine Learning", "comments": "Accepted to the workshop on \"Bridging AI and Cognitive Science\" at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is currently involved in some of the most vigorous debates\nit has ever seen. Such debates often seem to go around in circles, reaching no\nconclusion or resolution. This is perhaps unsurprising given that researchers\nin machine learning come to these discussions with very different frames of\nreference, making it challenging for them to align perspectives and find common\nground. As a remedy for this dilemma, we advocate for the adoption of a common\nconceptual framework which can be used to understand, analyze, and discuss\nresearch. We present one such framework which is popular in cognitive science\nand neuroscience and which we believe has great utility in machine learning as\nwell: Marr's levels of analysis. Through a series of case studies, we\ndemonstrate how the levels facilitate an understanding and dissection of\nseveral methods from machine learning. By adopting the levels of analysis in\none's own work, we argue that researchers can be better equipped to engage in\nthe debates necessary to drive forward progress in our field.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 15:58:44 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Hamrick", "Jessica", ""], ["Mohamed", "Shakir", ""]]}, {"id": "2004.05113", "submitter": "Naeemul Hassan", "authors": "Fariha Afsana, Muhammad Ashad Kabir, Naeemul Hassan, Manoranjan Paul", "title": "Automatically Assessing Quality of Online Health Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 02:57:35 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Afsana", "Fariha", ""], ["Kabir", "Muhammad Ashad", ""], ["Hassan", "Naeemul", ""], ["Paul", "Manoranjan", ""]]}, {"id": "2004.05137", "submitter": "Crefeda Rodrigues", "authors": "Crefeda Faviola Rodrigues, Graham Riley, Mikel Lujan", "title": "Energy Predictive Models for Convolutional Neural Networks on Mobile\n  Platforms", "comments": "9 pages, 4 Figures", "journal-ref": null, "doi": "10.13140/RG.2.2.15224.80644", "report-no": null, "categories": "cs.PF cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Energy use is a key concern when deploying deep learning models on mobile and\nembedded platforms. Current studies develop energy predictive models based on\napplication-level features to provide researchers a way to estimate the energy\nconsumption of their deep learning models. This information is useful for\nbuilding resource-aware models that can make efficient use of the hard-ware\nresources. However, previous works on predictive modelling provide little\ninsight into the trade-offs involved in the choice of features on the final\npredictive model accuracy and model complexity. To address this issue, we\nprovide a comprehensive analysis of building regression-based predictive models\nfor deep learning on mobile devices, based on empirical measurements gathered\nfrom the SyNERGY framework.Our predictive modelling strategy is based on two\ntypes of predictive models used in the literature:individual layers and\nlayer-type. Our analysis of predictive models show that simple layer-type\nfeatures achieve a model complexity of 4 to 32 times less for convolutional\nlayer predictions for a similar accuracy compared to predictive models using\nmore complex features adopted by previous approaches. To obtain an overall\nenergy estimate of the inference phase, we build layer-type predictive models\nfor the fully-connected and pooling layers using 12 representative\nConvolutional NeuralNetworks (ConvNets) on the Jetson TX1 and the Snapdragon\n820using software backends such as OpenBLAS, Eigen and CuDNN. We obtain an\naccuracy between 76% to 85% and a model complexity of 1 for the overall energy\nprediction of the test ConvNets across different hardware-software\ncombinations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:35:40 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Rodrigues", "Crefeda Faviola", ""], ["Riley", "Graham", ""], ["Lujan", "Mikel", ""]]}, {"id": "2004.05154", "submitter": "Carlos Esteves", "authors": "Carlos Esteves", "title": "Theoretical Aspects of Group Equivariant Neural Networks", "comments": "Corrected 3D steerable CNNs kernel characterization and other minor\n  fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group equivariant neural networks have been explored in the past few years\nand are interesting from theoretical and practical standpoints. They leverage\nconcepts from group representation theory, non-commutative harmonic analysis\nand differential geometry that do not often appear in machine learning. In\npractice, they have been shown to reduce sample and model complexity, notably\nin challenging tasks where input transformations such as arbitrary rotations\nare present. We begin this work with an exposition of group representation\ntheory and the machinery necessary to define and evaluate integrals and\nconvolutions on groups. Then, we show applications to recent SO(3) and SE(3)\nequivariant networks, namely the Spherical CNNs, Clebsch-Gordan Networks, and\n3D Steerable CNNs. We proceed to discuss two recent theoretical results. The\nfirst, by Kondor and Trivedi (ICML'18), shows that a neural network is group\nequivariant if and only if it has a convolutional structure. The second, by\nCohen et al. (NeurIPS'19), generalizes the first to a larger class of networks,\nwith feature maps as fields on homogeneous spaces.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:57:27 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 02:10:51 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Esteves", "Carlos", ""]]}, {"id": "2004.05155", "submitter": "Devendra Singh Chaplot", "authors": "Devendra Singh Chaplot, Dhiraj Gandhi, Saurabh Gupta, Abhinav Gupta,\n  Ruslan Salakhutdinov", "title": "Learning to Explore using Active Neural SLAM", "comments": "Published in ICLR-2020. See the project webpage at\n  https://devendrachaplot.github.io/projects/Neural-SLAM for supplementary\n  videos. The code is available at\n  https://github.com/devendrachaplot/Neural-SLAM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a modular and hierarchical approach to learn policies for\nexploring 3D environments, called `Active Neural SLAM'. Our approach leverages\nthe strengths of both classical and learning-based methods, by using analytical\npath planners with learned SLAM module, and global and local policies. The use\nof learning provides flexibility with respect to input modalities (in the SLAM\nmodule), leverages structural regularities of the world (in global policies),\nand provides robustness to errors in state estimation (in local policies). Such\nuse of learning within each module retains its benefits, while at the same\ntime, hierarchical decomposition and modular training allow us to sidestep the\nhigh sample complexities associated with training end-to-end policies. Our\nexperiments in visually and physically realistic simulated 3D environments\ndemonstrate the effectiveness of our approach over past learning and\ngeometry-based approaches. The proposed model can also be easily transferred to\nthe PointGoal task and was the winning entry of the CVPR 2019 Habitat PointGoal\nNavigation Challenge.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 17:57:29 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Chaplot", "Devendra Singh", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Saurabh", ""], ["Gupta", "Abhinav", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "2004.05167", "submitter": "Meena Jagadeesan", "authors": "Cynthia Dwork, Christina Ilvento, Meena Jagadeesan", "title": "Individual Fairness in Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well understood that a system built from individually fair components\nmay not itself be individually fair. In this work, we investigate individual\nfairness under pipeline composition. Pipelines differ from ordinary sequential\nor repeated composition in that individuals may drop out at any stage, and\nclassification in subsequent stages may depend on the remaining \"cohort\" of\nindividuals. As an example, a company might hire a team for a new project and\nat a later point promote the highest performer on the team. Unlike other\nrepeated classification settings, where the degree of unfairness degrades\ngracefully over multiple fair steps, the degree of unfairness in pipelines can\nbe arbitrary, even in a pipeline with just two stages.\n  Guided by a panoply of real-world examples, we provide a rigorous framework\nfor evaluating different types of fairness guarantees for pipelines. We show\nthat na\\\"{i}ve auditing is unable to uncover systematic unfairness and that, in\norder to ensure fairness, some form of dependence must exist between the design\nof algorithms at different stages in the pipeline. Finally, we provide\nconstructions that permit flexibility at later stages, meaning that there is no\nneed to lock in the entire pipeline at the time that the early stage is\nconstructed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:31:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dwork", "Cynthia", ""], ["Ilvento", "Christina", ""], ["Jagadeesan", "Meena", ""]]}, {"id": "2004.05184", "submitter": "Christian Reilly", "authors": "Oleksandr Ivanov (1), Lisa Wolf (2), Deena Brecher (1), Kevin Masek\n  (3), Erica Lewis (4), Stephen Liu (5), Robert B Dunne (6), Kevin Klauer (7),\n  Kyla Montgomery (1), Yurii Andrieiev (1), Moss McLaughlin (1), and Christian\n  Reilly (1) ((1) Mednition Inc., (2) Emergency Nurses Association, (3) San\n  Mateo Medical Center, (4) El Camino Hospital, (5) Adventist Health, (6)\n  Ascension Health, (7) American Osteopathic Association)", "title": "Improving Emergency Department ESI Acuity Assignment Using Machine\n  Learning and Clinical Natural Language Processing", "comments": "18 pages, 6 tables, 12 supplemental tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective triage is critical to mitigating the effect of increased volume by\naccurately determining patient acuity, need for resources, and establishing\neffective acuity-based patient prioritization. The purpose of this\nretrospective study was to determine whether historical EHR data can be\nextracted and synthesized with clinical natural language processing (C-NLP) and\nthe latest ML algorithms (KATE) to produce highly accurate ESI predictive\nmodels. An ML model (KATE) for the triage process was developed using 166,175\npatient encounters from two participating hospitals. The model was then tested\nagainst a gold set that was derived from a random sample of triage encounters\nat the study sites and correct acuity assignments were recorded by study\nclinicians using the Emergency Severity Index (ESI) standard as a guide. At the\ntwo study sites, KATE predicted accurate ESI acuity assignments 75.9% of the\ntime, compared to nurses (59.8%) and average individual study clinicians\n(75.3%). KATE accuracy was 26.9% higher than the average nurse accuracy\n(p-value < 0.0001). On the boundary between ESI 2 and ESI 3 acuity assignments,\nwhich relates to the risk of decompensation, KATE was 93.2% higher with 80%\naccuracy, compared to triage nurses with 41.4% accuracy (p-value < 0.0001).\nKATE provides a triage acuity assignment substantially more accurate than the\ntriage nurses in this study sample. KATE operates independently of contextual\nfactors, unaffected by the external pressures that can cause under triage and\nmay mitigate the racial and social biases that can negatively affect the\naccuracy of triage assignment. Future research should focus on the impact of\nKATE providing feedback to triage nurses in real time, KATEs impact on\nmortality and morbidity, ED throughput, resource optimization, and nursing\noutcomes.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:18:22 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 15:38:40 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Ivanov", "Oleksandr", ""], ["Wolf", "Lisa", ""], ["Brecher", "Deena", ""], ["Masek", "Kevin", ""], ["Lewis", "Erica", ""], ["Liu", "Stephen", ""], ["Dunne", "Robert B", ""], ["Klauer", "Kevin", ""], ["Montgomery", "Kyla", ""], ["Andrieiev", "Yurii", ""], ["McLaughlin", "Moss", ""], ["Reilly", "Christian", ""]]}, {"id": "2004.05198", "submitter": "Michael Schneider", "authors": "Im\\`ene R. Goumiri, Benjamin W. Priest, Michael D. Schneider", "title": "Reinforcement Learning via Gaussian Processes with Neural Network Dual\n  Kernels", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-808440", "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks (DNNs) and Gaussian Processes (GPs) are both\npopularly utilized to solve problems in reinforcement learning, both approaches\nfeature undesirable drawbacks for challenging problems. DNNs learn complex\nnonlinear embeddings, but do not naturally quantify uncertainty and are often\ndata-inefficient to train. GPs infer posterior distributions over functions,\nbut popular kernels exhibit limited expressivity on complex and\nhigh-dimensional data. Fortunately, recently discovered conjugate and neural\ntangent kernel functions encode the behavior of overparameterized neural\nnetworks in the kernel domain. We demonstrate that these kernels can be\nefficiently applied to regression and reinforcement learning problems by\nanalyzing a baseline case study. We apply GPs with neural network dual kernels\nto solve reinforcement learning tasks for the first time. We demonstrate, using\nthe well-understood mountain-car problem, that GPs empowered with dual kernels\nperform at least as well as those using the conventional radial basis function\nkernel. We conjecture that by inheriting the probabilistic rigor of GPs and the\npowerful embedding properties of DNNs, GPs using NN dual kernels will empower\nfuture reinforcement learning models on difficult domains.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 18:36:21 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Goumiri", "Im\u00e8ne R.", ""], ["Priest", "Benjamin W.", ""], ["Schneider", "Michael D.", ""]]}, {"id": "2004.05209", "submitter": "David Carlson", "authors": "Austin Talbot, David Dunson, Kafui Dzirasa, David Carlson", "title": "Supervised Autoencoders Learn Robust Joint Factor Models of Neural\n  Activity", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor models are routinely used for dimensionality reduction in modeling of\ncorrelated, high-dimensional data. We are particularly motivated by\nneuroscience applications collecting high-dimensional `predictors'\ncorresponding to brain activity in different regions along with behavioral\noutcomes. Joint factor models for the predictors and outcomes are natural, but\nmaximum likelihood estimates of these models can struggle in practice when\nthere is model misspecification. We propose an alternative inference strategy\nbased on supervised autoencoders; rather than placing a probability\ndistribution on the latent factors, we define them as an unknown function of\nthe high-dimensional predictors. This mapping function, along with the\nloadings, can be optimized to explain variance in brain activity while\nsimultaneously being predictive of behavior. In practice, the mapping function\ncan range in complexity from linear to more complex forms, such as splines or\nneural networks, with the usual tradeoff between bias and variance. This\napproach yields distinct solutions from a maximum likelihood inference\nstrategy, as we demonstrate by deriving analytic solutions for a linear\nGaussian factor model. Using synthetic data, we show that this function-based\napproach is robust against multiple types of misspecification. We then apply\nthis technique to a neuroscience application resulting in substantial gains in\npredicting behavioral tasks from electrophysiological measurements in multiple\nfactor models.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:31:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Talbot", "Austin", ""], ["Dunson", "David", ""], ["Dzirasa", "Kafui", ""], ["Carlson", "David", ""]]}, {"id": "2004.05214", "submitter": "Sergiu Oprea", "authors": "Sergiu Oprea, Pablo Martinez-Gonzalez, Alberto Garcia-Garcia, John\n  Alejandro Castro-Vargas, Sergio Orts-Escolano, Jose Garcia-Rodriguez and\n  Antonis Argyros", "title": "A Review on Deep Learning Techniques for Video Prediction", "comments": "Submitted to TPAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2020.3045007", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to predict, anticipate and reason about future outcomes is a key\ncomponent of intelligent decision-making systems. In light of the success of\ndeep learning in computer vision, deep-learning-based video prediction emerged\nas a promising research direction. Defined as a self-supervised learning task,\nvideo prediction represents a suitable framework for representation learning,\nas it demonstrated potential capabilities for extracting meaningful\nrepresentations of the underlying patterns in natural videos. Motivated by the\nincreasing interest in this task, we provide a review on the deep learning\nmethods for prediction in video sequences. We firstly define the video\nprediction fundamentals, as well as mandatory background concepts and the most\nused datasets. Next, we carefully analyze existing video prediction models\norganized according to a proposed taxonomy, highlighting their contributions\nand their significance in the field. The summary of the datasets and methods is\naccompanied with experimental results that facilitate the assessment of the\nstate of the art on a quantitative basis. The paper is summarized by drawing\nsome general conclusions, identifying open research challenges and by pointing\nout future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:58:44 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 00:24:31 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Oprea", "Sergiu", ""], ["Martinez-Gonzalez", "Pablo", ""], ["Garcia-Garcia", "Alberto", ""], ["Castro-Vargas", "John Alejandro", ""], ["Orts-Escolano", "Sergio", ""], ["Garcia-Rodriguez", "Jose", ""], ["Argyros", "Antonis", ""]]}, {"id": "2004.05219", "submitter": "Georgiana Dinu", "authors": "Georgiana Dinu, Prashant Mathur, Marcello Federico, Stanislas Lauly,\n  Yaser Al-Onaizan", "title": "Joint translation and unit conversion for end-to-end localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of natural language tasks require processing of textual data which\ncontains a mix of natural language and formal languages such as mathematical\nexpressions. In this paper, we take unit conversions as an example and propose\na data augmentation technique which leads to models learning both translation\nand conversion tasks as well as how to adequately switch between them for\nend-to-end localization.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 20:18:43 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dinu", "Georgiana", ""], ["Mathur", "Prashant", ""], ["Federico", "Marcello", ""], ["Lauly", "Stanislas", ""], ["Al-Onaizan", "Yaser", ""]]}, {"id": "2004.05224", "submitter": "Yaodong Cui", "authors": "Yaodong Cui, Ren Chen, Wenbo Chu, Long Chen, Daxin Tian, Ying Li,\n  Dongpu Cao", "title": "Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A\n  Review", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Transportation Systems.(2021)", "doi": "10.1109/TITS.2020.3023541", "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles were experiencing rapid development in the past few\nyears. However, achieving full autonomy is not a trivial task, due to the\nnature of the complex and dynamic driving environment. Therefore, autonomous\nvehicles are equipped with a suite of different sensors to ensure robust,\naccurate environmental perception. In particular, the camera-LiDAR fusion is\nbecoming an emerging research theme. However, so far there has been no critical\nreview that focuses on deep-learning-based camera-LiDAR fusion methods. To\nbridge this gap and motivate future research, this paper devotes to review\nrecent deep-learning-based data fusion approaches that leverage both image and\npoint cloud. This review gives a brief overview of deep learning on image and\npoint cloud data processing. Followed by in-depth reviews of camera-LiDAR\nfusion methods in depth completion, object detection, semantic segmentation,\ntracking and online cross-sensor calibration, which are organized based on\ntheir respective fusion levels. Furthermore, we compare these methods on\npublicly available datasets. Finally, we identified gaps and over-looked\nchallenges between current academic researches and real-world applications.\nBased on these observations, we provide our insights and point out promising\nresearch directions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 20:43:14 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 14:12:13 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Cui", "Yaodong", ""], ["Chen", "Ren", ""], ["Chu", "Wenbo", ""], ["Chen", "Long", ""], ["Tian", "Daxin", ""], ["Li", "Ying", ""], ["Cao", "Dongpu", ""]]}, {"id": "2004.05243", "submitter": "Frank Cichos", "authors": "Martin Fr\\\"anzl, Frank Cichos", "title": "Convolutional Neural Networks for Real-Time Localization and\n  Classification in Feedback Digital Microscopy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cs.LG eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adapted single-shot convolutional neural network (YOLOv2) for\nthe real-time localization and classification of particles in optical\nmicroscopy. As compared to previous works, we focus on the real-time detection\ncapabilities of the system to allow for manipulation of microscopic objects in\nlarge heterogeneous ensembles with the help of feedback control. The network is\ncapable of localizing and classifying several hundreds of microscopic objects\neven at very low signal-to-noise ratios for images as large as 416x416 pixels\nwith an inference time of about 10 ms. We demonstrate the real-time detection\nperformance by manipulating active particles propelled by laser-induced\nself-thermophoresis. In order to make our framework readily available for\nothers, we provide all scripts and source code. The network is implemented in\nPython/Keras using the TensorFlow backend. A C library supporting GPUs is\nprovided for the real-time inference.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 22:09:32 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Fr\u00e4nzl", "Martin", ""], ["Cichos", "Frank", ""]]}, {"id": "2004.05244", "submitter": "Maciej Skorski", "authors": "Maciej Skorski", "title": "Efficient Sampled Softmax for Tensorflow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper discusses an efficient implementation of \\emph{sampled\nsoftmax loss} for Tensorflow. The speedup over the default implementation is\nachieved due to simplification of the graph for the forward and backward\npasses.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 22:14:52 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Skorski", "Maciej", ""]]}, {"id": "2004.05249", "submitter": "Gareth Ari Aye", "authors": "Gareth Ari Aye and Gail E. Kaiser", "title": "Sequence Model Design for Code Completion in the Modern IDE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code completion plays a prominent role in modern integrated development\nenvironments (IDEs). Machine learning has become ubiquitous in analogous\nnatural language writing and search software, surfacing more relevant\nautocompletions and search suggestions in fewer keystrokes. Prior research has\nreported training high-accuracy, deep neural networks for modeling source code,\nbut little attention has been given to the practical constraints imposed by\ninteractive developer tools. In particular, neural language models for source\ncode modeling like the one described in Maybe Deep Neural Networks are the Best\nChoice for Modeling Source Code are framed around code completion, but only\nreport accuracy of next-token prediction. However, in order for a language\nmodel (LM) to work well within real-world code completion systems, it must also\nalways make suggestions that produce valid code that typechecks to support code\ncompletion's role in correctness-checking; return instantaneous results to help\nprogrammers code more efficiently in fewer keystrokes; and be small enough to\nfit comfortably on disk and in memory on developer workstations, since\nvirtually all modern IDEs run locally and support offline usage. To meet these\nadditional requirements, we propose a novel design for predicting top-k next\ntokens that combines static analysis' ability to enumerate all valid keywords\nand in-scope identifiers with the ability of a language model to place a\nprobability distribution over them. Our model mixes character-level input\nrepresentation with token output to represent out-of-vocabulary (OOV) tokens\nmeaningfully and minimize prediction latency. OOV tokens can be predicted\nthrough detection of local repetition common in software. This design achieves\nstate-of-art accuracy in source code modeling and fits the constraints imposed\nby real-world code completion implementations in modern IDEs.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 22:40:49 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Aye", "Gareth Ari", ""], ["Kaiser", "Gail E.", ""]]}, {"id": "2004.05258", "submitter": "Rikima Mitsuhashi", "authors": "Rikima Mitsuhashi and Takahiro Shinagawa", "title": "High-Accuracy Malware Classification with a Malware-Optimized Deep\n  Learning Model", "comments": "11 pages with 10figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware threats are a serious problem for computer security, and the ability\nto detect and classify malware is critical for maintaining the security level\nof a computer. Recently, a number of researchers are investigating techniques\nfor classifying malware families using malware visualization, which convert the\nbinary structure of malware into grayscale images. Although there have been\nmany reports that applied CNN to malware visualization image classification, it\nhas not been revealed how to pick out a model that fits a given malware dataset\nand achieves higher classification accuracy. We propose a strategy to select a\nDeep learning model that fits the malware visualization images. Our strategy\nuses the fine-tuning method for the pre-trained CNN model and a dataset that\nsolves the imbalance problem. We chose the VGG19 model based on the proposed\nstrategy to classify the Malimg dataset. Experimental results show that the\nclassification accuracy is 99.72 %, which is higher than other previously\nproposed malware classification methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 23:45:54 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mitsuhashi", "Rikima", ""], ["Shinagawa", "Takahiro", ""]]}, {"id": "2004.05265", "submitter": "Nic Herndon", "authors": "Mark Sokolov, Kehinde Olufowobi and Nic Herndon", "title": "Visual Spoofing in content based spam detection", "comments": null, "journal-ref": null, "doi": "10.1145/3433174.3433605", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although the problem of spam classification seems to be solved, there are\nstill vulnerabilities in the current spam filters that could be easily\nexploited. We present one such vulnerability, in which one could replace some\ncharacters with corresponding characters from a different alphabet. These\ncharacters are visually similar, yet have a different Unicode encoding. With\nthis approach spammers can create messages that bypass existing spam filters.\nMoreover, we show that this approach can be used to avoid plagiarism detection,\nand in other applications that use natural language processing for automatic\nanalysis of text documents.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:16:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 01:44:32 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Sokolov", "Mark", ""], ["Olufowobi", "Kehinde", ""], ["Herndon", "Nic", ""]]}, {"id": "2004.05273", "submitter": "Mohammad Javad Khojasteh", "authors": "Richard Cheng, Mohammad Javad Khojasteh, Aaron D. Ames, and Joel W.\n  Burdick", "title": "Safe Multi-Agent Interaction through Robust Control Barrier Functions\n  with Learned Uncertainties", "comments": null, "journal-ref": "59th IEEE Conference on Decision and Control (CDC 2020)", "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.MA cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots operating in real world settings must navigate and maintain safety\nwhile interacting with many heterogeneous agents and obstacles. Multi-Agent\nControl Barrier Functions (CBF) have emerged as a computationally efficient\ntool to guarantee safety in multi-agent environments, but they assume perfect\nknowledge of both the robot dynamics and other agents' dynamics. While\nknowledge of the robot's dynamics might be reasonably well known, the\nheterogeneity of agents in real-world environments means there will always be\nconsiderable uncertainty in our prediction of other agents' dynamics. This work\naims to learn high-confidence bounds for these dynamic uncertainties using\nMatrix-Variate Gaussian Process models, and incorporates them into a robust\nmulti-agent CBF framework. We transform the resulting min-max robust CBF into a\nquadratic program, which can be efficiently solved in real time. We verify via\nsimulation results that the nominal multi-agent CBF is often violated during\nagent interactions, whereas our robust formulation maintains safety with a much\nhigher probability and adapts to learned uncertainties\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 00:56:36 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 18:37:44 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Cheng", "Richard", ""], ["Khojasteh", "Mohammad Javad", ""], ["Ames", "Aaron D.", ""], ["Burdick", "Joel W.", ""]]}, {"id": "2004.05274", "submitter": "Yu-An Chung", "authors": "Yu-An Chung, James Glass", "title": "Improved Speech Representations with Multi-Target Autoregressive\n  Predictive Coding", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training objectives based on predictive coding have recently been shown to be\nvery effective at learning meaningful representations from unlabeled speech.\nOne example is Autoregressive Predictive Coding (Chung et al., 2019), which\ntrains an autoregressive RNN to generate an unseen future frame given a context\nsuch as recent past frames. The basic hypothesis of these approaches is that\nhidden states that can accurately predict future frames are a useful\nrepresentation for many downstream tasks. In this paper we extend this\nhypothesis and aim to enrich the information encoded in the hidden states by\ntraining the model to make more accurate future predictions. We propose an\nauxiliary objective that serves as a regularization to improve generalization\nof the future frame prediction task. Experimental results on phonetic\nclassification, speech recognition, and speech translation not only support the\nhypothesis, but also demonstrate the effectiveness of our approach in learning\nrepresentations that contain richer phonetic content.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 01:09:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Chung", "Yu-An", ""], ["Glass", "James", ""]]}, {"id": "2004.05277", "submitter": "Bubacarr Bah", "authors": "Mhlasakululeka Mvubu, Emmanuel Kabuga, Christian Plitz, Bubacarr Bah,\n  Ronnie Becker, Hans Georg Zimmermann", "title": "On Error Correction Neural Networks for Economic Forecasting", "comments": "13 pages, 4 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are more suitable for learning non-linear\ndependencies in dynamical systems from observed time series data. In practice\nall the external variables driving such systems are not known a priori,\nespecially in economical forecasting. A class of RNNs called Error Correction\nNeural Networks (ECNNs) was designed to compensate for missing input variables.\nIt does this by feeding back in the current step the error made in the previous\nstep. The ECNN is implemented in Python by the computation of the appropriate\ngradients and it is tested on stock market predictions. As expected it out\nperformed the simple RNN and LSTM and other hybrid models which involve a\nde-noising pre-processing step. The intuition for the latter is that de-noising\nmay lead to loss of information.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 01:23:39 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:21:32 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Mvubu", "Mhlasakululeka", ""], ["Kabuga", "Emmanuel", ""], ["Plitz", "Christian", ""], ["Bah", "Bubacarr", ""], ["Becker", "Ronnie", ""], ["Zimmermann", "Hans Georg", ""]]}, {"id": "2004.05285", "submitter": "Said Varlioglu", "authors": "Mustafa Sagir and Said Varlioglu", "title": "Explaining the Relationship between Internet and Democracy in Partly\n  Free Countries Using Machine Learning Models", "comments": "\"University of Cincinnati, School of Information Technology, IT EXPO\n  Research Symposium '20, April 14, 2020, Cincinnati, OH, USA\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have offered a variety of explanations on the relationship\nbetween democracy and the internet. However, most of these studies concentrate\non regions, specific states or authoritarian regimes. No study has investigated\nthe influence of the internet in partly free countries defined by the Freedom\nHouse. Moreover, very little is known about the effects of online censorship on\nthe development, stagnation, or decline of democracy. Drawing upon the\nInternational Telecommunication Union, Freedom House, and World Bank databases\nand using machine learning methods, this study sheds new light on the effects\nof the internet on democratization in partly free countries. The findings\nsuggest that internet penetration and online censorship both have a negative\nimpact on democracy scores and the internet's effect on democracy scores is\nconditioned by online censorship. Moreover, results from random forest suggest\nthat online censorship is the most important variable followed by governance\nindex and education on democracy scores. The comparison of the various machine\nlearning models reveals that the best predicting model is the 175-tree random\nforest model which has 92% accuracy. Also, this study might help \"IT\nprofessionals\" to see their important role not only in the technical fields but\nalso in society in terms of democratization and how close IT is to social\nsciences.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 02:26:37 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sagir", "Mustafa", ""], ["Varlioglu", "Said", ""]]}, {"id": "2004.05289", "submitter": "Petros Spachos", "authors": "Syeda Manjia Tahsien, Hadis Karimipour, Petros Spachos", "title": "Machine Learning Based Solutions for Security of Internet of Things\n  (IoT): A Survey", "comments": null, "journal-ref": null, "doi": "10.1016/j.jnca.2020.102630", "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, IoT platforms have been developed into a global giant\nthat grabs every aspect of our daily lives by advancing human life with its\nunaccountable smart services. Because of easy accessibility and fast-growing\ndemand for smart devices and network, IoT is now facing more security\nchallenges than ever before. There are existing security measures that can be\napplied to protect IoT. However, traditional techniques are not as efficient\nwith the advancement booms as well as different attack types and their\nsevereness. Thus, a strong-dynamically enhanced and up to date security system\nis required for next-generation IoT system. A huge technological advancement\nhas been noticed in Machine Learning (ML) which has opened many possible\nresearch windows to address ongoing and future challenges in IoT. In order to\ndetect attacks and identify abnormal behaviors of smart devices and networks,\nML is being utilized as a powerful technology to fulfill this purpose. In this\nsurvey paper, the architecture of IoT is discussed, following a comprehensive\nliterature review on ML approaches the importance of security of IoT in terms\nof different types of possible attacks. Moreover, ML-based potential solutions\nfor IoT security has been presented and future challenges are discussed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:08:24 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Tahsien", "Syeda Manjia", ""], ["Karimipour", "Hadis", ""], ["Spachos", "Petros", ""]]}, {"id": "2004.05290", "submitter": "Ian Manchester", "authors": "Max Revay, Ruigang Wang, Ian R. Manchester", "title": "A Convex Parameterization of Robust Recurrent Neural Networks", "comments": "conference submission, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a class of nonlinear dynamical systems\noften used to model sequence-to-sequence maps. RNNs have excellent expressive\npower but lack the stability or robustness guarantees that are necessary for\nmany applications. In this paper, we formulate convex sets of RNNs with\nstability and robustness guarantees. The guarantees are derived using\nincremental quadratic constraints and can ensure global exponential stability\nof all solutions, and bounds on incremental $ \\ell_2 $ gain (the Lipschitz\nconstant of the learned sequence-to-sequence mapping). Using an implicit model\nstructure, we construct a parametrization of RNNs that is jointly convex in the\nmodel parameters and stability certificate. We prove that this model structure\nincludes all previously-proposed convex sets of stable RNNs as special cases,\nand also includes all stable linear dynamical systems. We illustrate the\nutility of the proposed model class in the context of non-linear system\nidentification.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:12:42 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 08:48:04 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Revay", "Max", ""], ["Wang", "Ruigang", ""], ["Manchester", "Ian R.", ""]]}, {"id": "2004.05298", "submitter": "An Xu", "authors": "An Xu, Zhouyuan Huo, Heng Huang", "title": "Exploit Where Optimizer Explores via Residuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to train the neural networks faster, many efforts have been devoted\nto exploring a better solution trajectory, but few have been put into\nexploiting the existing solution trajectory. To exploit the trajectory of\n(momentum) stochastic gradient descent (SGD(m)) method, we propose a novel\nmethod named SGD(m) with residuals (RSGD(m)), which leads to a performance\nboost of both the convergence and generalization. Our new method can also be\napplied to other optimizers such as ASGD and Adam. We provide theoretical\nanalysis to show that RSGD achieves a smaller growth rate of the generalization\nerror and the same (but empirically better) convergence rate compared with SGD.\nExtensive deep learning experiments on image classification, language modeling\nand graph convolutional neural networks show that the proposed algorithm is\nfaster than SGD(m)/Adam at the initial training stage, and similar to or better\nthan SGD(m) at the end of training with better generalization error.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 03:50:59 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 12:13:54 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Xu", "An", ""], ["Huo", "Zhouyuan", ""], ["Huang", "Heng", ""]]}, {"id": "2004.05316", "submitter": "Zhaobin Kuang", "authors": "Zhaobin Kuang, Frederic Sala, Nimit Sohoni, Sen Wu, Aldo\n  C\\'ordova-Palomera, Jared Dunnmon, James Priest, Christopher R\\'e", "title": "Ivy: Instrumental Variable Synthesis for Causal Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular way to estimate the causal effect of a variable x on y from\nobservational data is to use an instrumental variable (IV): a third variable z\nthat affects y only through x. The more strongly z is associated with x, the\nmore reliable the estimate is, but such strong IVs are difficult to find.\nInstead, practitioners combine more commonly available IV candidates---which\nare not necessarily strong, or even valid, IVs---into a single \"summary\" that\nis plugged into causal effect estimators in place of an IV. In genetic\nepidemiology, such approaches are known as allele scores. Allele scores require\nstrong assumptions---independence and validity of all IV candidates---for the\nresulting estimate to be reliable. To relax these assumptions, we propose Ivy,\na new method to combine IV candidates that can handle correlated and invalid IV\ncandidates in a robust manner. Theoretically, we characterize this robustness,\nits limits, and its impact on the resulting causal estimates. Empirically, Ivy\ncan correctly identify the directionality of known relationships and is robust\nagainst false discovery (median effect size <= 0.025) on three real-world\ndatasets with no causal effects, while allele scores return more biased\nestimates (median effect size >= 0.118).\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:11:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Kuang", "Zhaobin", ""], ["Sala", "Frederic", ""], ["Sohoni", "Nimit", ""], ["Wu", "Sen", ""], ["C\u00f3rdova-Palomera", "Aldo", ""], ["Dunnmon", "Jared", ""], ["Priest", "James", ""], ["R\u00e9", "Christopher", ""]]}, {"id": "2004.05318", "submitter": "Luchen Liu", "authors": "Luchen Liu, Zequn Liu, Haoxian Wu, Zichang Wang, Jianhao Shen, Yiping\n  Song, and Ming Zhang", "title": "Multi-task Learning via Adaptation to Similar Tasks for Mortality\n  Prediction of Diverse Rare Diseases", "comments": "10 pages, 3 Figures, submitted to AMIA Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mortality prediction of diverse rare diseases using electronic health record\n(EHR) data is a crucial task for intelligent healthcare. However, data\ninsufficiency and the clinical diversity of rare diseases make it hard for\ndirectly training deep learning models on individual disease data or all the\ndata from different diseases. Mortality prediction for these patients with\ndifferent diseases can be viewed as a multi-task learning problem with\ninsufficient data and large task number. But the tasks with little training\ndata also make it hard to train task-specific modules in multi-task learning\nmodels. To address the challenges of data insufficiency and task diversity, we\npropose an initialization-sharing multi-task learning method (Ada-Sit) which\nlearns the parameter initialization for fast adaptation to dynamically measured\nsimilar tasks. We use Ada-Sit to train long short-term memory networks (LSTM)\nbased prediction models on longitudinal EHR data. And experimental results\ndemonstrate that the proposed model is effective for mortality prediction of\ndiverse rare diseases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:15:23 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:58:27 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Luchen", ""], ["Liu", "Zequn", ""], ["Wu", "Haoxian", ""], ["Wang", "Zichang", ""], ["Shen", "Jianhao", ""], ["Song", "Yiping", ""], ["Zhang", "Ming", ""]]}, {"id": "2004.05319", "submitter": "Balamurali Murugesan", "authors": "Balamurali Murugesan, Sricharan Vijayarangan, Kaushik Sarveswaran,\n  Keerthi Ram and Mohanasankar Sivaprakasam", "title": "KD-MRI: A knowledge distillation framework for image reconstruction and\n  image restoration in MRI workflow", "comments": "Accepted in MIDL 2020. Code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning networks are being developed in every stage of the MRI workflow\nand have provided state-of-the-art results. However, this has come at the cost\nof increased computation requirement and storage. Hence, replacing the networks\nwith compact models at various stages in the MRI workflow can significantly\nreduce the required storage space and provide considerable speedup. In computer\nvision, knowledge distillation is a commonly used method for model compression.\nIn our work, we propose a knowledge distillation (KD) framework for the image\nto image problems in the MRI workflow in order to develop compact,\nlow-parameter models without a significant drop in performance. We propose a\ncombination of the attention-based feature distillation method and imitation\nloss and demonstrate its effectiveness on the popular MRI reconstruction\narchitecture, DC-CNN. We conduct extensive experiments using Cardiac, Brain,\nand Knee MRI datasets for 4x, 5x and 8x accelerations. We observed that the\nstudent network trained with the assistance of the teacher using our proposed\nKD framework provided significant improvement over the student network trained\nwithout assistance across all the datasets and acceleration factors.\nSpecifically, for the Knee dataset, the student network achieves $65\\%$\nparameter reduction, 2x faster CPU running time, and 1.5x faster GPU running\ntime compared to the teacher. Furthermore, we compare our attention-based\nfeature distillation method with other feature distillation methods. We also\nconduct an ablative study to understand the significance of attention-based\ndistillation and imitation loss. We also extend our KD framework for MRI\nsuper-resolution and show encouraging results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:21:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Murugesan", "Balamurali", ""], ["Vijayarangan", "Sricharan", ""], ["Sarveswaran", "Kaushik", ""], ["Ram", "Keerthi", ""], ["Sivaprakasam", "Mohanasankar", ""]]}, {"id": "2004.05328", "submitter": "Javad PourMostafa Roshan Sharami", "authors": "Javad PourMostafa Roshan Sharami, Parsa Abbasi Sarabestani, Seyed\n  Abolghasem Mirroshandel", "title": "DeepSentiPers: Novel Deep Learning Models Trained Over Proposed\n  Augmented Persian Sentiment Corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on how to extract opinions over each Persian\nsentence-level text. Deep learning models provided a new way to boost the\nquality of the output. However, these architectures need to feed on big\nannotated data as well as an accurate design. To best of our knowledge, we do\nnot merely suffer from lack of well-annotated Persian sentiment corpus, but\nalso a novel model to classify the Persian opinions in terms of both multiple\nand binary classification. So in this work, first we propose two novel deep\nlearning architectures comprises of bidirectional LSTM and CNN. They are a part\nof a deep hierarchy designed precisely and also able to classify sentences in\nboth cases. Second, we suggested three data augmentation techniques for the\nlow-resources Persian sentiment corpus. Our comprehensive experiments on three\nbaselines and two different neural word embedding methods show that our data\naugmentation methods and intended models successfully address the aims of the\nresearch.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 07:45:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sharami", "Javad PourMostafa Roshan", ""], ["Sarabestani", "Parsa Abbasi", ""], ["Mirroshandel", "Seyed Abolghasem", ""]]}, {"id": "2004.05333", "submitter": "Soroush Ghodrati", "authors": "Soroush Ghodrati, Hardik Sharma, Cliff Young, Nam Sung Kim, Hadi\n  Esmaeilzadeh", "title": "Bit-Parallel Vector Composability for Neural Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional neural accelerators rely on isolated self-sufficient functional\nunits that perform an atomic operation while communicating the results through\nan operand delivery-aggregation logic. Each single unit processes all the bits\nof their operands atomically and produce all the bits of the results in\nisolation. This paper explores a different design style, where each unit is\nonly responsible for a slice of the bit-level operations to interleave and\ncombine the benefits of bit-level parallelism with the abundant data-level\nparallelism in deep neural networks. A dynamic collection of these units\ncooperate at runtime to generate bits of the results, collectively. Such\ncooperation requires extracting new grouping between the bits, which is only\npossible if the operands and operations are vectorizable. The abundance of Data\nLevel Parallelism and mostly repeated execution patterns, provides a unique\nopportunity to define and leverage this new dimension of Bit-Parallel Vector\nComposability. This design intersperses bit parallelism within data-level\nparallelism and dynamically interweaves the two together. As such, the building\nblock of our neural accelerator is a Composable Vector Unit that is a\ncollection of Narrower-Bitwidth Vector Engines, which are dynamically composed\nor decomposed at the bit granularity. Using six diverse CNN and LSTM deep\nnetworks, we evaluate this design style across four design points: with and\nwithout algorithmic bitwidth heterogeneity and with and without availability of\na high-bandwidth off-chip memory. Across these four design points, Bit-Parallel\nVector Composability brings (1.4x to 3.5x) speedup and (1.1x to 2.7x) energy\nreduction. We also comprehensively compare our design style to the Nvidia RTX\n2080 TI GPU, which also supports INT-4 execution. The benefits range between\n28.0x and 33.7x improvement in Performance-per-Watt.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 08:09:59 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ghodrati", "Soroush", ""], ["Sharma", "Hardik", ""], ["Young", "Cliff", ""], ["Kim", "Nam Sung", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2004.05340", "submitter": "Cheng Wang", "authors": "Cheng Wang, Kang Wei, Lingjun Kong, Long Shi, Zhen Mei, Jun Li, and\n  Kui Cai", "title": "DNN-aided Read-voltage Threshold Optimization for MLC Flash Memory with\n  Finite Block Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The error correcting performance of multi-level-cell (MLC) NAND flash memory\nis closely related to the block length of error correcting codes (ECCs) and\nlog-likelihood-ratios (LLRs) of the read-voltage thresholds. Driven by this\nissue, this paper optimizes the read-voltage thresholds for MLC flash memory to\nimprove the decoding performance of ECCs with finite block length. First,\nthrough the analysis of channel coding rate (CCR) and decoding error\nprobability under finite block length, we formulate the optimization problem of\nread-voltage thresholds to minimize the maximum decoding error probability.\nSecond, we develop a cross iterative search (CIS) algorithm to optimize\nread-voltage thresholds under the perfect knowledge of flash memory channel.\nHowever, it is challenging to analytically characterize the voltage\ndistribution under the effect of data retention noise (DRN), since the data\nretention time (DRT) is hard to be recorded for flash memory in reality. To\naddress this problem, we develop a deep neural network (DNN) aided optimization\nstrategy to optimize the read-voltage thresholds, where a multi-layer\nperception (MLP) network is employed to learn the relationship between voltage\ndistribution and read-voltage thresholds. Simulation results show that,\ncompared with the existing schemes, the proposed DNN-aided read-voltage\nthreshold optimization strategy with a well-designed LDPC code can not only\nimprove the program-and-erase (PE) endurance but also reduce the read latency.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 09:03:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wang", "Cheng", ""], ["Wei", "Kang", ""], ["Kong", "Lingjun", ""], ["Shi", "Long", ""], ["Mei", "Zhen", ""], ["Li", "Jun", ""], ["Cai", "Kui", ""]]}, {"id": "2004.05352", "submitter": "Hyunjae Kim", "authors": "Hyunjae Kim, Yookyung Koh, Jinheon Baek, Jaewoo Kang", "title": "Exploring The Spatial Reasoning Ability of Neural Models in Human IQ\n  Tests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural models have performed impressively well on various tasks such\nas image recognition and question answering, their reasoning ability has been\nmeasured in only few studies. In this work, we focus on spatial reasoning and\nexplore the spatial understanding of neural models. First, we describe the\nfollowing two spatial reasoning IQ tests: rotation and shape composition. Using\nwell-defined rules, we constructed datasets that consist of various complexity\nlevels. We designed a variety of experiments in terms of generalization, and\nevaluated six different baseline models on the newly generated datasets. We\nprovide an analysis of the results and factors that affect the generalization\nabilities of models. Also, we analyze how neural models solve spatial reasoning\ntests with visual aids. Our findings would provide valuable insights into\nunderstanding a machine and the difference between a machine and human.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 09:41:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Kim", "Hyunjae", ""], ["Koh", "Yookyung", ""], ["Baek", "Jinheon", ""], ["Kang", "Jaewoo", ""]]}, {"id": "2004.05363", "submitter": "Ralf L\\\"ammel", "authors": "John Ahlgren, Maria Eugenia Berezin, Kinga Bojarczuk, Elena Dulskyte,\n  Inna Dvortsova, Johann George, Natalija Gucevska, Mark Harman, Ralf L\\\"ammel,\n  Erik Meijer, Silvia Sapora, Justin Spahr-Summers", "title": "WES: Agent-based User Interaction Simulation on Real Infrastructure", "comments": "Author order is alphabetical. Correspondence to Mark Harman\n  (markharman@fb.com). This paper appears in GI 2020: 8th International\n  Workshop on Genetic Improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Web-Enabled Simulation (WES) research agenda, and describe\nFACEBOOK's WW system. We describe the application of WW to reliability,\nintegrity and privacy at FACEBOOK , where it is used to simulate social media\ninteractions on an infrastructure consisting of hundreds of millions of lines\nof code. The WES agenda draws on research from many areas of study, including\nSearch Based Software Engineering, Machine Learning, Programming Languages,\nMulti Agent Systems, Graph Theory, Game AI, and AI Assisted Game Play. We\nconclude with a set of open problems and research challenges to motivate wider\ninvestigation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 10:50:34 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ahlgren", "John", ""], ["Berezin", "Maria Eugenia", ""], ["Bojarczuk", "Kinga", ""], ["Dulskyte", "Elena", ""], ["Dvortsova", "Inna", ""], ["George", "Johann", ""], ["Gucevska", "Natalija", ""], ["Harman", "Mark", ""], ["L\u00e4mmel", "Ralf", ""], ["Meijer", "Erik", ""], ["Sapora", "Silvia", ""], ["Spahr-Summers", "Justin", ""]]}, {"id": "2004.05366", "submitter": "Len Du", "authors": "Len Du", "title": "In-Machine-Learning Database: Reimagining Deep Learning with Old-School\n  SQL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-database machine learning has been very popular, almost being a cliche.\nHowever, can we do it the other way around? In this work, we say \"yes\" by\napplying plain old SQL to deep learning, in a sense implementing deep learning\nalgorithms with SQL. Most deep learning frameworks, as well as generic machine\nlearning ones, share a de facto standard of multidimensional array operations,\nunderneath fancier infrastructure such as automatic differentiation. As SQL\ntables can be regarded as generalisations of (multi-dimensional) arrays, we\nhave found a way to express common deep learning operations in SQL, encouraging\na different way of thinking and thus potentially novel models. In particular,\none of the latest trend in deep learning was the introduction of sparsity in\nthe name of graph convolutional networks, whereas we take sparsity almost for\ngranted in the database world. As both databases and machine learning involve\ntransformation of datasets, we hope this work can inspire further works\nutilizing the large body of existing wisdom, algorithms and technologies in the\ndatabase field to advance the state of the art in machine learning, rather than\nmerely integerating machine learning into databases.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 11:00:26 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 18:08:28 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Du", "Len", ""]]}, {"id": "2004.05380", "submitter": "Fabio Caraffini PhD", "authors": "Johana Florez-Lozano, Fabio Caraffini, Carlos Parra and Mario Gongora", "title": "Training Data Set Assessment for Decision-Making in a Multiagent\n  Landmine Detection Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems such as landmine detection require multiple sources of\ninformation to reduce the uncertainty of decision-making. A novel approach to\nsolve these problems includes distributed systems, as presented in this work\nbased on hardware and software multi-agent systems. To achieve a high rate of\nlandmine detection, we evaluate the performance of a trained system over the\ndistribution of samples between training and validation sets. Additionally, a\ngeneral explanation of the data set is provided, presenting the samples\ngathered by a cooperative multi-agent system developed for detecting improvised\nexplosive devices. The results show that input samples affect the performance\nof the output decisions, and a decision-making system can be less sensitive to\nsensor noise with intelligent systems obtained from a diverse and suitably\norganised training set.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:05:30 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Florez-Lozano", "Johana", ""], ["Caraffini", "Fabio", ""], ["Parra", "Carlos", ""], ["Gongora", "Mario", ""]]}, {"id": "2004.05381", "submitter": "Sebastian Feld", "authors": "Sebastian Feld (1), Andreas Sedlmeier (1), Markus Friedrich (1), Jan\n  Franz (1), Lenz Belzner (2) ((1) Mobile and Distributed Systems Group LMU\n  Munich, (2) MaibornWolff Munich)", "title": "Bayesian Surprise in Indoor Environments", "comments": "10 pages, 16 figures", "journal-ref": "Proceedings of the 27th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '19), 2019, p. 129-138", "doi": "10.1145/3347146.3359358", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel method to identify unexpected structures in 2D\nfloor plans using the concept of Bayesian Surprise. Taking into account that a\nperson's expectation is an important aspect of the perception of space, we\nexploit the theory of Bayesian Surprise to robustly model expectation and thus\nsurprise in the context of building structures. We use Isovist Analysis, which\nis a popular space syntax technique, to turn qualitative object attributes into\nquantitative environmental information. Since isovists are location-specific\npatterns of visibility, a sequence of isovists describes the spatial perception\nduring a movement along multiple points in space. We then use Bayesian Surprise\nin a feature space consisting of these isovist readings. To demonstrate the\nsuitability of our approach, we take \"snapshots\" of an agent's local\nenvironment to provide a short list of images that characterize a traversed\ntrajectory through a 2D indoor environment. Those fingerprints represent\nsurprising regions of a tour, characterize the traversed map and enable indoor\nLBS to focus more on important regions. Given this idea, we propose to use\n\"surprise\" as a new dimension of context in indoor location-based services\n(LBS). Agents of LBS, such as mobile robots or non-player characters in\ncomputer games, may use the context surprise to focus more on important regions\nof a map for a better use or understanding of the floor plan.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:09:51 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Feld", "Sebastian", ""], ["Sedlmeier", "Andreas", ""], ["Friedrich", "Markus", ""], ["Franz", "Jan", ""], ["Belzner", "Lenz", ""]]}, {"id": "2004.05383", "submitter": "Sebastian Feld", "authors": "Sebastian Feld (1), Steffen Illium (1), Andreas Sedlmeier (1), Lenz\n  Belzner (2) ((1) Mobile and Distributed Systems Group LMU Munich, (2)\n  MaibornWolff Munich)", "title": "Trajectory annotation using sequences of spatial perception", "comments": "10 pages, 17 figures", "journal-ref": "Proceedings of the 26th ACM SIGSPATIAL International Conference on\n  Advances in Geographic Information Systems (SIGSPATIAL '18), 2018, p. 329-338", "doi": "10.1145/3274895.3274968", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the near future, more and more machines will perform tasks in the vicinity\nof human spaces or support them directly in their spatially bound activities.\nIn order to simplify the verbal communication and the interaction between\nrobotic units and/or humans, reliable and robust systems w.r.t. noise and\nprocessing results are needed. This work builds a foundation to address this\ntask. By using a continuous representation of spatial perception in interiors\nlearned from trajectory data, our approach clusters movement in dependency to\nits spatial context. We propose an unsupervised learning approach based on a\nneural autoencoding that learns semantically meaningful continuous encodings of\nspatio-temporal trajectory data. This learned encoding can be used to form\nprototypical representations. We present promising results that clear the path\nfor future applications.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 12:22:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Feld", "Sebastian", ""], ["Illium", "Steffen", ""], ["Sedlmeier", "Andreas", ""], ["Belzner", "Lenz", ""]]}, {"id": "2004.05399", "submitter": "Sricharan Vijayarangan", "authors": "Sricharan Vijayarangan, Balamurali Murugesan, Vignesh R, Preejith SP,\n  Jayaraj Joseph and Mohansankar Sivaprakasam", "title": "Interpreting Deep Neural Networks for Single-Lead ECG Arrhythmia\n  Classification", "comments": "Accepted in EMBC 2020(EMBS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Cardiac arrhythmia is a prevalent and significant cause of morbidity and\nmortality among cardiac ailments. Early diagnosis is crucial in providing\nintervention for patients suffering from cardiac arrhythmia. Traditionally,\ndiagnosis is performed by examination of the Electrocardiogram (ECG) by a\ncardiologist. This method of diagnosis is hampered by the lack of accessibility\nto expert cardiologists. For quite some time, signal processing methods had\nbeen used to automate arrhythmia diagnosis. However, these traditional methods\nrequire expert knowledge and are unable to model a wide range of arrhythmia.\nRecently, Deep Learning methods have provided solutions to performing\narrhythmia diagnosis at scale. However, the black-box nature of these models\nprohibit clinical interpretation of cardiac arrhythmia. There is a dire need to\ncorrelate the obtained model outputs to the corresponding segments of the ECG.\nTo this end, two methods are proposed to provide interpretability to the\nmodels. The first method is a novel application of Gradient-weighted Class\nActivation Map (Grad-CAM) for visualizing the saliency of the CNN model. In the\nsecond approach, saliency is derived by learning the input deletion mask for\nthe LSTM model. The visualizations are provided on a model whose competence is\nestablished by comparisons against baselines. The results of model saliency not\nonly provide insight into the prediction capability of the model but also\naligns with the medical literature for the classification of cardiac\narrhythmia.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 13:24:17 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Vijayarangan", "Sricharan", ""], ["Murugesan", "Balamurali", ""], ["R", "Vignesh", ""], ["SP", "Preejith", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohansankar", ""]]}, {"id": "2004.05405", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Carlo Alberto Barbano, Claudio Berzovini, Marco\n  Calandri and Marco Grangetto", "title": "Unveiling COVID-19 from Chest X-ray with deep learning: a hurdles race\n  with small data", "comments": null, "journal-ref": "Int. J. Environ. Res. Public Health 2020, 17(18), 6933", "doi": "10.3390/ijerph17186933", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility to use widespread and simple chest X-ray (CXR) imaging for\nearly screening of COVID-19 patients is attracting much interest from both the\nclinical and the AI community. In this study we provide insights and also raise\nwarnings on what is reasonable to expect by applying deep-learning to COVID\nclassification of CXR images. We provide a methodological guide and critical\nreading of an extensive set of statistical results that can be obtained using\ncurrently available datasets. In particular, we take the challenge posed by\ncurrent small size COVID data and show how significant can be the bias\nintroduced by transfer-learning using larger public non-COVID CXR datasets. We\nalso contribute by providing results on a medium size COVID CXR dataset, just\ncollected by one of the major emergency hospitals in Northern Italy during the\npeak of the COVID pandemic. These novel data allow us to contribute to validate\nthe generalization capacity of preliminary results circulating in the\nscientific community. Our conclusions shed some light into the possibility to\neffectively discriminate COVID using CXR.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 13:58:17 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Barbano", "Carlo Alberto", ""], ["Berzovini", "Claudio", ""], ["Calandri", "Marco", ""], ["Grangetto", "Marco", ""]]}, {"id": "2004.05417", "submitter": "Warren Powell", "authors": "Kristopher Reyes and Warren B Powell", "title": "Optimal Learning for Sequential Decisions in Laboratory Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of discovery in the physical, biological and medical sciences can\nbe painstakingly slow. Most experiments fail, and the time from initiation of\nresearch until a new advance reaches commercial production can span 20 years.\nThis tutorial is aimed to provide experimental scientists with a foundation in\nthe science of making decisions. Using numerical examples drawn from the\nexperiences of the authors, the article describes the fundamental elements of\nany experimental learning problem. It emphasizes the important role of belief\nmodels, which include not only the best estimate of relationships provided by\nprior research, previous experiments and scientific expertise, but also the\nuncertainty in these relationships. We introduce the concept of a learning\npolicy, and review the major categories of policies. We then introduce a\npolicy, known as the knowledge gradient, that maximizes the value of\ninformation from each experiment. We bring out the importance of reducing\nuncertainty, and illustrate this process for different belief models.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 14:53:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 00:54:16 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Reyes", "Kristopher", ""], ["Powell", "Warren B", ""]]}, {"id": "2004.05426", "submitter": "Filipe Rodrigues", "authors": "Filipe Rodrigues", "title": "Scaling Bayesian inference of mixed multinomial logit models to very\n  large datasets", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference methods have been shown to lead to significant\nimprovements in the computational efficiency of approximate Bayesian inference\nin mixed multinomial logit models when compared to standard Markov-chain Monte\nCarlo (MCMC) methods without compromising accuracy. However, despite their\ndemonstrated efficiency gains, existing methods still suffer from important\nlimitations that prevent them to scale to very large datasets, while providing\nthe flexibility to allow for rich prior distributions and to capture complex\nposterior distributions. In this paper, we propose an Amortized Variational\nInference approach that leverages stochastic backpropagation, automatic\ndifferentiation and GPU-accelerated computation, for effectively scaling\nBayesian inference in Mixed Multinomial Logit models to very large datasets.\nMoreover, we show how normalizing flows can be used to increase the flexibility\nof the variational posterior approximations. Through an extensive simulation\nstudy, we empirically show that the proposed approach is able to achieve\ncomputational speedups of multiple orders of magnitude over traditional MSLE\nand MCMC approaches for large datasets without compromising estimation\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 15:30:47 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Rodrigues", "Filipe", ""]]}, {"id": "2004.05436", "submitter": "Muhammad Ilyas Dr.", "authors": "Muhammad Ilyas, Hina Rehman and Amine Nait-ali", "title": "Detection of Covid-19 From Chest X-ray Images Using Artificial\n  Intelligence: An Early Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In 2019, the entire world is facing a situation of health emergency due to a\nnewly emerged coronavirus (COVID-19). Almost 196 countries are affected by\ncovid-19, while USA, Italy, China, Spain, Iran, and France have the maximum\nactive cases of COVID-19. The issues, medical and healthcare departments are\nfacing in delay of detecting the COVID-19. Several artificial intelligence\nbased system are designed for the automatic detection of COVID-19 using chest\nx-rays. In this article we will discuss the different approaches used for the\ndetection of COVID-19 and the challenges we are facing. It is mandatory to\ndevelop an automatic detection system to prevent the transfer of the virus\nthrough contact. Several deep learning architecture are deployed for the\ndetection of COVID-19 such as ResNet, Inception, Googlenet etc. All these\napproaches are detecting the subjects suffering with pneumonia while its hard\nto decide whether the pneumonia is caused by COVID-19 or due to any other\nbacterial or fungal attack.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:15:53 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ilyas", "Muhammad", ""], ["Rehman", "Hina", ""], ["Nait-ali", "Amine", ""]]}, {"id": "2004.05438", "submitter": "Kevin Lybarger", "authors": "Kevin Lybarger, Mari Ostendorf, Meliha Yetisgen", "title": "Annotating Social Determinants of Health Using Active Learning, and\n  Characterizing Determinants Using Neural Event Extraction", "comments": null, "journal-ref": "Journal of Biomedical Informatics 113 (2021) 103631", "doi": "10.1016/j.jbi.2020.103631", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social determinants of health (SDOH) affect health outcomes, and knowledge of\nSDOH can inform clinical decision-making. Automatically extracting SDOH\ninformation from clinical text requires data-driven information extraction\nmodels trained on annotated corpora that are heterogeneous and frequently\ninclude critical SDOH. This work presents a new corpus with SDOH annotations, a\nnovel active learning framework, and the first extraction results on the new\ncorpus. The Social History Annotation Corpus (SHAC) includes 4,480 social\nhistory sections with detailed annotation for 12 SDOH characterizing the\nstatus, extent, and temporal information of 18K distinct events. We introduce a\nnovel active learning framework that selects samples for annotation using a\nsurrogate text classification task as a proxy for a more complex event\nextraction task. The active learning framework successfully increases the\nfrequency of health risk factors and improves automatic extraction of these\nevents over undirected annotation. An event extraction model trained on SHAC\nachieves high extraction performance for substance use status (0.82-0.93 F1),\nemployment status (0.81-0.86 F1), and living status type (0.81-0.93 F1) on data\nfrom three institutions.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:19:02 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 05:54:50 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Lybarger", "Kevin", ""], ["Ostendorf", "Mari", ""], ["Yetisgen", "Meliha", ""]]}, {"id": "2004.05439", "submitter": "Timothy Hospedales", "authors": "Timothy Hospedales, Antreas Antoniou, Paul Micaelli, Amos Storkey", "title": "Meta-Learning in Neural Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of meta-learning, or learning-to-learn, has seen a dramatic rise in\ninterest in recent years. Contrary to conventional approaches to AI where tasks\nare solved from scratch using a fixed learning algorithm, meta-learning aims to\nimprove the learning algorithm itself, given the experience of multiple\nlearning episodes. This paradigm provides an opportunity to tackle many\nconventional challenges of deep learning, including data and computation\nbottlenecks, as well as generalization. This survey describes the contemporary\nmeta-learning landscape. We first discuss definitions of meta-learning and\nposition it with respect to related fields, such as transfer learning and\nhyperparameter optimization. We then propose a new taxonomy that provides a\nmore comprehensive breakdown of the space of meta-learning methods today. We\nsurvey promising applications and successes of meta-learning such as few-shot\nlearning and reinforcement learning. Finally, we discuss outstanding challenges\nand promising areas for future research.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:34:24 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 20:22:57 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hospedales", "Timothy", ""], ["Antoniou", "Antreas", ""], ["Micaelli", "Paul", ""], ["Storkey", "Amos", ""]]}, {"id": "2004.05442", "submitter": "Sandeep Juneja", "authors": "Achal Bassamboo, Vikas Deep, Sandeep Juneja and Assaf Zeevi", "title": "Discriminative Learning via Adaptive Questioning", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing an adaptive sequence of questions that\noptimally classify a candidate's ability into one of several categories or\ndiscriminative grades. A candidate's ability is modeled as an unknown\nparameter, which, together with the difficulty of the question asked,\ndetermines the likelihood with which s/he is able to answer a question\ncorrectly. The learning algorithm is only able to observe these noisy responses\nto its queries. We consider this problem from a fixed confidence-based\n$\\delta$-correct framework, that in our setting seeks to arrive at the correct\nability discrimination at the fastest possible rate while guaranteeing that the\nprobability of error is less than a pre-specified and small $\\delta$. In this\nsetting we develop lower bounds on any sequential questioning strategy and\ndevelop geometrical insights into the problem structure both from primal and\ndual formulation. In addition, we arrive at algorithms that essentially match\nthese lower bounds. Our key conclusions are that, asymptotically, any candidate\nneeds to be asked questions at most at two (candidate ability-specific) levels,\nalthough, in a reasonably general framework, questions need to be asked only at\na single level. Further, and interestingly, the problem structure facilitates\nendogenous exploration, so there is no need for a separately designed\nexploration stage in the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 16:50:00 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bassamboo", "Achal", ""], ["Deep", "Vikas", ""], ["Juneja", "Sandeep", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2004.05461", "submitter": "Keigo Nakamura", "authors": "Keigo Nakamura and Yoshiro Suzuki", "title": "Deep learning-based topological optimization for representing a\n  user-specified design area", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presently, topology optimization requires multiple iterations to create an\noptimized structure for given conditions. Among the conditions for topology\noptimization,the design area is one of the most important for structural\ndesign. In this study, we propose a new deep learning model to generate an\noptimized structure for a given design domain and other boundary conditions\nwithout iteration. For this purpose, we used open-source topology optimization\nMATLAB code to generate a pair of optimized structures under various design\nconditions. The resolution of the optimized structure is 32 * 32 pixels, and\nthe design conditions are design area, volume fraction, distribution of\nexternal forces, and load value. Our deep learning model is primarily composed\nof a convolutional neural network (CNN)-based encoder and decoder, trained with\ndatasets generated with MATLAB code. In the encoder, we use batch normalization\n(BN) to increase the stability of the CNN model. In the decoder, we use SPADE\n(spatially adaptive denormalization) to reinforce the design area information.\nComparing the performance of our proposed model with a CNN model that does not\nuse BN and SPADE, values for mean absolute error (MAE), mean compliance error,\nand volume error with the optimized topology structure generated in MAT-LAB\ncode were smaller, and the proposed model was able to represent the design area\nmore precisely. The proposed method generates near-optimal structures\nreflecting the design area in less computational time, compared with the\nopen-source topology optimization MATLAB code.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:54:07 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 13:44:20 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Nakamura", "Keigo", ""], ["Suzuki", "Yoshiro", ""]]}, {"id": "2004.05462", "submitter": "Iordanis Fostiropoulos", "authors": "Iordanis Fostiropoulos", "title": "Depthwise Discrete Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in learning Discrete Representations as opposed to\ncontinuous ones have led to state of art results in tasks that involve\nLanguage, Audio and Vision. Some latent factors such as words, phonemes and\nshapes are better represented by discrete latent variables as opposed to\ncontinuous. Vector Quantized Variational Autoencoders (VQVAE) have produced\nremarkable results in multiple domains. VQVAE learns a prior distribution $z_e$\nalong with its mapping to a discrete number of $K$ vectors (Vector\nQuantization). We propose applying VQ along the feature axis. We hypothesize\nthat by doing so, we are learning a mapping between the codebook vectors and\nthe marginal distribution of the prior feature space. Our approach leads to\n33\\% improvement as compared to prevous discrete models and has similar\nperformance to state of the art auto-regressive models (e.g. PixelSNAIL). We\nevaluate our approach on a static prior using an artificial toy dataset\n(blobs). We further evaluate our approach on benchmarks for CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:57:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Fostiropoulos", "Iordanis", ""]]}, {"id": "2004.05465", "submitter": "Melanie Weber", "authors": "Melanie Weber, Manzil Zaheer, Ankit Singh Rawat, Aditya Menon and\n  Sanjiv Kumar", "title": "Robust Large-Margin Learning in Hyperbolic Space", "comments": "Accepted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been a surge of interest in representation learning in\nhyperbolic spaces, driven by their ability to represent hierarchical data with\nsignificantly fewer dimensions than standard Euclidean spaces. However, the\nviability and benefits of hyperbolic spaces for downstream machine learning\ntasks have received less attention. In this paper, we present, to our\nknowledge, the first theoretical guarantees for learning a classifier in\nhyperbolic rather than Euclidean space. Specifically, we consider the problem\nof learning a large-margin classifier for data possessing a hierarchical\nstructure. Our first contribution is a hyperbolic perceptron algorithm, which\nprovably converges to a separating hyperplane. We then provide an algorithm to\nefficiently learn a large-margin hyperplane, relying on the careful injection\nof adversarial examples. Finally, we prove that for hierarchical data that\nembeds well into hyperbolic space, the low embedding dimension ensures superior\nguarantees when learning the classifier directly in hyperbolic space.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 19:11:30 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 17:25:50 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Weber", "Melanie", ""], ["Zaheer", "Manzil", ""], ["Rawat", "Ankit Singh", ""], ["Menon", "Aditya", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.05472", "submitter": "Conor Lazarou", "authors": "Conor Lazarou", "title": "Autoencoding Generative Adversarial Networks", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the years since Goodfellow et al. introduced Generative Adversarial\nNetworks (GANs), there has been an explosion in the breadth and quality of\ngenerative model applications. Despite this work, GANs still have a long way to\ngo before they see mainstream adoption, owing largely to their infamous\ntraining instability. Here I propose the Autoencoding Generative Adversarial\nNetwork (AEGAN), a four-network model which learns a bijective mapping between\na specified latent space and a given sample space by applying an adversarial\nloss and a reconstruction loss to both the generated images and the generated\nlatent vectors. The AEGAN technique offers several improvements to typical GAN\ntraining, including training stabilization, mode-collapse prevention, and\npermitting the direct interpolation between real samples. The effectiveness of\nthe technique is illustrated using an anime face dataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 19:51:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lazarou", "Conor", ""]]}, {"id": "2004.05476", "submitter": "Maite Taboada", "authors": "Varada Kolhatkar, Nithum Thain, Jeffrey Sorensen, Lucas Dixon and\n  Maite Taboada", "title": "Classifying Constructive Comments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the Constructive Comments Corpus (C3), comprised of 12,000\nannotated news comments, intended to help build new tools for online\ncommunities to improve the quality of their discussions. We define constructive\ncomments as high-quality comments that make a contribution to the conversation.\nWe explain the crowd worker annotation scheme and define a taxonomy of\nsub-characteristics of constructiveness. The quality of the annotation scheme\nand the resulting dataset is evaluated using measurements of inter-annotator\nagreement, expert assessment of a sample, and by the constructiveness\nsub-characteristics, which we show provide a proxy for the general\nconstructiveness concept. We provide models for constructiveness trained on C3\nusing both feature-based and a variety of deep learning approaches and\ndemonstrate that these models capture general rather than topic- or\ndomain-specific characteristics of constructiveness, through domain adaptation\nexperiments. We examine the role that length plays in our models, as comment\nlength could be easily gamed if models depend heavily upon this feature. By\nexamining the errors made by each model and their distribution by length, we\nshow that the best performing models are less correlated with comment\nlength.The constructiveness corpus and our experiments pave the way for a\nmoderation tool focused on promoting comments that make a contribution, rather\nthan only filtering out undesirable content.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 20:05:52 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 22:23:15 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 04:28:42 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 03:14:04 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Kolhatkar", "Varada", ""], ["Thain", "Nithum", ""], ["Sorensen", "Jeffrey", ""], ["Dixon", "Lucas", ""], ["Taboada", "Maite", ""]]}, {"id": "2004.05484", "submitter": "Rami Al-Rfou", "authors": "Uma Roy, Noah Constant, Rami Al-Rfou, Aditya Barua, Aaron Phillips,\n  Yinfei Yang", "title": "LAReQA: Language-agnostic answer retrieval from a multilingual pool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LAReQA, a challenging new benchmark for language-agnostic answer\nretrieval from a multilingual candidate pool. Unlike previous cross-lingual\ntasks, LAReQA tests for \"strong\" cross-lingual alignment, requiring\nsemantically related cross-language pairs to be closer in representation space\nthan unrelated same-language pairs. Building on multilingual BERT (mBERT), we\nstudy different strategies for achieving strong alignment. We find that\naugmenting training data via machine translation is effective, and improves\nsignificantly over using mBERT out-of-the-box. Interestingly, the embedding\nbaseline that performs the best on LAReQA falls short of competing baselines on\nzero-shot variants of our task that only target \"weak\" alignment. This finding\nunderscores our claim that languageagnostic retrieval is a substantively new\nkind of cross-lingual evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 20:51:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Roy", "Uma", ""], ["Constant", "Noah", ""], ["Al-Rfou", "Rami", ""], ["Barua", "Aditya", ""], ["Phillips", "Aaron", ""], ["Yang", "Yinfei", ""]]}, {"id": "2004.05485", "submitter": "Ashis Pati", "authors": "Ashis Pati, Alexander Lerch", "title": "Attribute-based Regularization of Latent Spaces for Variational\n  Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Selective manipulation of data attributes using deep generative models is an\nactive area of research. In this paper, we present a novel method to structure\nthe latent space of a Variational Auto-Encoder (VAE) to encode different\ncontinuous-valued attributes explicitly. This is accomplished by using an\nattribute regularization loss which enforces a monotonic relationship between\nthe attribute values and the latent code of the dimension along which the\nattribute is to be encoded. Consequently, post-training, the model can be used\nto manipulate the attribute by simply changing the latent code of the\ncorresponding regularized dimension. The results obtained from several\nquantitative and qualitative experiments show that the proposed method leads to\ndisentangled and interpretable latent spaces that can be used to effectively\nmanipulate a wide range of data attributes spanning image and symbolic music\ndomains.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 20:53:13 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 03:38:16 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 01:16:24 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Pati", "Ashis", ""], ["Lerch", "Alexander", ""]]}, {"id": "2004.05488", "submitter": "Lyes Khacef", "authors": "Lyes Khacef, Laurent Rodriguez, Benoit Miramond", "title": "Brain-inspired self-organization with cellular neuromorphic computing\n  for multimodal unsupervised learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical plasticity is one of the main features that enable our ability to\nlearn and adapt in our environment. Indeed, the cerebral cortex self-organizes\nitself through structural and synaptic plasticity mechanisms that are very\nlikely at the basis of an extremely interesting characteristic of the human\nbrain development: the multimodal association. In spite of the diversity of the\nsensory modalities, like sight, sound and touch, the brain arrives at the same\nconcepts (convergence). Moreover, biological observations show that one\nmodality can activate the internal representation of another modality when both\nare correlated (divergence). In this work, we propose the Reentrant\nSelf-Organizing Map (ReSOM), a brain-inspired neural system based on the\nreentry theory using Self-Organizing Maps and Hebbian-like learning. We propose\nand compare different computational methods for unsupervised learning and\ninference, then quantify the gain of the ReSOM in a multimodal classification\ntask. The divergence mechanism is used to label one modality based on the\nother, while the convergence mechanism is used to improve the overall accuracy\nof the system. We perform our experiments on a constructed written/spoken\ndigits database and a DVS/EMG hand gestures database. The proposed model is\nimplemented on a cellular neuromorphic architecture that enables distributed\ncomputing with local connectivity. We show the gain of the so-called hardware\nplasticity induced by the ReSOM, where the system's topology is not fixed by\nthe user but learned along the system's experience through self-organization.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 21:02:45 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 15:36:46 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 17:10:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Khacef", "Lyes", ""], ["Rodriguez", "Laurent", ""], ["Miramond", "Benoit", ""]]}, {"id": "2004.05511", "submitter": "Dung Tran Hoang", "authors": "Hoang-Dung Tran, Stanley Bak, Weiming Xiang and Taylor T.Johnson", "title": "Verification of Deep Convolutional Neural Networks Using ImageStars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have redefined the state-of-the-art in\nmany real-world applications, such as facial recognition, image classification,\nhuman pose estimation, and semantic segmentation. Despite their success, CNNs\nare vulnerable to adversarial attacks, where slight changes to their inputs may\nlead to sharp changes in their output in even well-trained networks. Set-based\nanalysis methods can detect or prove the absence of bounded adversarial\nattacks, which can then be used to evaluate the effectiveness of neural network\ntraining methodology. Unfortunately, existing verification approaches have\nlimited scalability in terms of the size of networks that can be analyzed.\n  In this paper, we describe a set-based framework that successfully deals with\nreal-world CNNs, such as VGG16 and VGG19, that have high accuracy on ImageNet.\nOur approach is based on a new set representation called the ImageStar, which\nenables efficient exact and over-approximative analysis of CNNs. ImageStars\nperform efficient set-based analysis by combining operations on concrete images\nwith linear programming (LP). Our approach is implemented in a tool called NNV,\nand can verify the robustness of VGG networks with respect to a small set of\ninput states, derived from adversarial attacks, such as the DeepFool attack.\nThe experimental results show that our approach is less conservative and faster\nthan existing zonotope methods, such as those used in DeepZ, and the polytope\nmethod used in DeepPoly.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:37:21 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 20:02:06 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Tran", "Hoang-Dung", ""], ["Bak", "Stanley", ""], ["Xiang", "Weiming", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "2004.05512", "submitter": "Lisa Torrey", "authors": "Lisa Torrey", "title": "Reinforcement Learning via Reasoning from Demonstration", "comments": "Adaptive and Learning Agents Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonstration is an appealing way for humans to provide assistance to\nreinforcement-learning agents. Most approaches in this area view demonstrations\nprimarily as sources of behavioral bias. But in sparse-reward tasks, humans\nseem to treat demonstrations more as sources of causal knowledge. This paper\nproposes a framework for agents that benefit from demonstration in this\nhuman-inspired way. In this framework, agents develop causal models through\nobservation, and reason from this knowledge to decompose tasks for effective\nreinforcement learning. Experimental results show that a basic implementation\nof Reasoning from Demonstration (RfD) is effective in a range of sparse-reward\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 00:41:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Torrey", "Lisa", ""]]}, {"id": "2004.05519", "submitter": "Dung Tran Hoang", "authors": "Hoang-Dung Tran, Xiaodong Yang, Diego Manzanas Lopez, Patrick Musau,\n  Luan Viet Nguyen, Weiming Xiang, Stanley Bak and Taylor T. Johnson", "title": "NNV: The Neural Network Verification Tool for Deep Neural Networks and\n  Learning-Enabled Cyber-Physical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper presents the Neural Network Verification (NNV) software tool, a\nset-based verification framework for deep neural networks (DNNs) and\nlearning-enabled cyber-physical systems (CPS). The crux of NNV is a collection\nof reachability algorithms that make use of a variety of set representations,\nsuch as polyhedra, star sets, zonotopes, and abstract-domain representations.\nNNV supports both exact (sound and complete) and over-approximate (sound)\nreachability algorithms for verifying safety and robustness properties of\nfeed-forward neural networks (FFNNs) with various activation functions. For\nlearning-enabled CPS, such as closed-loop control systems incorporating neural\nnetworks, NNV provides exact and over-approximate reachability analysis schemes\nfor linear plant models and FFNN controllers with piecewise-linear activation\nfunctions, such as ReLUs. For similar neural network control systems (NNCS)\nthat instead have nonlinear plant models, NNV supports over-approximate\nanalysis by combining the star set analysis used for FFNN controllers with\nzonotope-based analysis for nonlinear plant dynamics building on CORA. We\nevaluate NNV using two real-world case studies: the first is safety\nverification of ACAS Xu networks and the second deals with the safety\nverification of a deep learning-based adaptive cruise control system.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 01:29:58 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Tran", "Hoang-Dung", ""], ["Yang", "Xiaodong", ""], ["Lopez", "Diego Manzanas", ""], ["Musau", "Patrick", ""], ["Nguyen", "Luan Viet", ""], ["Xiang", "Weiming", ""], ["Bak", "Stanley", ""], ["Johnson", "Taylor T.", ""]]}, {"id": "2004.05529", "submitter": "Fangzhou Mu", "authors": "Fangzhou Mu, Yingyu Liang, Yin Li", "title": "Gradients as Features for Deep Representation Learning", "comments": "ICLR 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the challenging problem of deep representation learning--the\nefficient adaption of a pre-trained deep network to different tasks.\nSpecifically, we propose to explore gradient-based features. These features are\ngradients of the model parameters with respect to a task-specific loss given an\ninput sample. Our key innovation is the design of a linear model that\nincorporates both gradient and activation of the pre-trained network. We show\nthat our model provides a local linear approximation to an underlying deep\nmodel, and discuss important theoretical insights. Moreover, we present an\nefficient algorithm for the training and inference of our model without\ncomputing the actual gradient. Our method is evaluated across a number of\nrepresentation-learning tasks on several datasets and using different network\narchitectures. Strong results are obtained in all settings, and are\nwell-aligned with our theoretical insights.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 02:57:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mu", "Fangzhou", ""], ["Liang", "Yingyu", ""], ["Li", "Yin", ""]]}, {"id": "2004.05531", "submitter": "Tianyun Zhang", "authors": "Tianyun Zhang, Xiaolong Ma, Zheng Zhan, Shanglin Zhou, Minghai Qin,\n  Fei Sun, Yen-Kuang Chen, Caiwen Ding, Makan Fardad and Yanzhi Wang", "title": "A Unified DNN Weight Compression Framework Using Reweighted Optimization\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the large model size and intensive computation requirement of deep\nneural networks (DNNs), weight pruning techniques have been proposed and\ngenerally fall into two categories, i.e., static regularization-based pruning\nand dynamic regularization-based pruning. However, the former method currently\nsuffers either complex workloads or accuracy degradation, while the latter one\ntakes a long time to tune the parameters to achieve the desired pruning rate\nwithout accuracy loss. In this paper, we propose a unified DNN weight pruning\nframework with dynamically updated regularization terms bounded by the\ndesignated constraint, which can generate both non-structured sparsity and\ndifferent kinds of structured sparsity. We also extend our method to an\nintegrated framework for the combination of different DNN compression tasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 02:59:06 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhang", "Tianyun", ""], ["Ma", "Xiaolong", ""], ["Zhan", "Zheng", ""], ["Zhou", "Shanglin", ""], ["Qin", "Minghai", ""], ["Sun", "Fei", ""], ["Chen", "Yen-Kuang", ""], ["Ding", "Caiwen", ""], ["Fardad", "Makan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2004.05549", "submitter": "Jianxiong Guo", "authors": "Jianxiong Guo, Weili Wu", "title": "Continuous Profit Maximization: A Study of Unconstrained Dr-submodular\n  Maximization", "comments": "in IEEE Transactions on Computational Social Systems", "journal-ref": null, "doi": "10.1109/TCSS.2021.3061452", "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Profit maximization (PM) is to select a subset of users as seeds for viral\nmarketing in online social networks, which balances between the cost and the\nprofit from influence spread. We extend PM to that under the general marketing\nstrategy, and form continuous profit maximization (CPM-MS) problem, whose\ndomain is on integer lattices. The objective function of our CPM-MS is\ndr-submodular, but non-monotone. It is a typical case of unconstrained\ndr-submodular maximization (UDSM) problem, and take it as a starting point, we\nstudy UDSM systematically in this paper, which is very different from those\nexisting researcher. First, we introduce the lattice-based double greedy\nalgorithm, which can obtain a constant approximation guarantee. However, there\nis a strict and unrealistic condition that requiring the objective value is\nnon-negative on the whole domain, or else no theoretical bounds. Thus, we\npropose a technique, called lattice-based iterative pruning. It can shrink the\nsearch space effectively, thereby greatly increasing the possibility of\nsatisfying the non-negative objective function on this smaller domain without\nlosing approximation ratio. Then, to overcome the difficulty to estimate the\nobjective value of CPM-MS, we adopt reverse sampling strategies, and combine it\nwith lattice-based double greedy, including pruning, without losing its\nperformance but reducing its running time. The entire process can be considered\nas a general framework to solve the UDSM problem, especially for applying to\nsocial networks. Finally, we conduct experiments on several real datasets to\nevaluate the effectiveness and efficiency of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 05:35:19 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Guo", "Jianxiong", ""], ["Wu", "Weili", ""]]}, {"id": "2004.05553", "submitter": "Bishal Santra", "authors": "Bishal Santra, Prakhar Sharma, Sumegh Roychowdhury, Pawan Goyal", "title": "Exploring Effects of Random Walk Based Minibatch Selection Policy on\n  Knowledge Graph Completion", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have explored the effects of different minibatch sampling\ntechniques in Knowledge Graph Completion. Knowledge Graph Completion (KGC) or\nLink Prediction is the task of predicting missing facts in a knowledge graph.\nKGC models are usually trained using margin, soft-margin or cross-entropy loss\nfunction that promotes assigning a higher score or probability for true fact\ntriplets. Minibatch gradient descent is used to optimize these loss functions\nfor training the KGC models. But, as each minibatch consists of only a few\nrandomly sampled triplets from a large knowledge graph, any entity that occurs\nin a minibatch, occurs only once in most cases. Because of this, these loss\nfunctions ignore all other neighbors of any entity, whose embedding is being\nupdated at some minibatch step. In this paper, we propose a new random-walk\nbased minibatch sampling technique for training KGC models that optimizes the\nloss incurred by a minibatch of closely connected subgraph of triplets instead\nof randomly selected ones. We have shown results of experiments for different\nmodels and datasets with our sampling technique and found that the proposed\nsampling algorithm has varying effects on these datasets/models. Specifically,\nwe find that our proposed method achieves state-of-the-art performance on the\nDB100K dataset.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 06:16:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Santra", "Bishal", ""], ["Sharma", "Prakhar", ""], ["Roychowdhury", "Sumegh", ""], ["Goyal", "Pawan", ""]]}, {"id": "2004.05565", "submitter": "Alvin Wan", "authors": "Alvin Wan, Xiaoliang Dai, Peizhao Zhang, Zijian He, Yuandong Tian,\n  Saining Xie, Bichen Wu, Matthew Yu, Tao Xu, Kan Chen, Peter Vajda, Joseph E.\n  Gonzalez", "title": "FBNetV2: Differentiable Neural Architecture Search for Spatial and\n  Channel Dimensions", "comments": "8 pages, 10 figures, accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentiable Neural Architecture Search (DNAS) has demonstrated great\nsuccess in designing state-of-the-art, efficient neural networks. However,\nDARTS-based DNAS's search space is small when compared to other search\nmethods', since all candidate network layers must be explicitly instantiated in\nmemory. To address this bottleneck, we propose a memory and computationally\nefficient DNAS variant: DMaskingNAS. This algorithm expands the search space by\nup to $10^{14}\\times$ over conventional DNAS, supporting searches over spatial\nand channel dimensions that are otherwise prohibitively expensive: input\nresolution and number of filters. We propose a masking mechanism for feature\nmap reuse, so that memory and computational costs stay nearly constant as the\nsearch space expands. Furthermore, we employ effective shape propagation to\nmaximize per-FLOP or per-parameter accuracy. The searched FBNetV2s yield\nstate-of-the-art performance when compared with all previous architectures.\nWith up to 421$\\times$ less search cost, DMaskingNAS finds models with 0.9%\nhigher accuracy, 15% fewer FLOPs than MobileNetV3-Small; and with similar\naccuracy but 20% fewer FLOPs than Efficient-B0. Furthermore, our FBNetV2\noutperforms MobileNetV3 by 2.6% in accuracy, with equivalent model size.\nFBNetV2 models are open-sourced at\nhttps://github.com/facebookresearch/mobile-vision.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 08:52:15 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wan", "Alvin", ""], ["Dai", "Xiaoliang", ""], ["Zhang", "Peizhao", ""], ["He", "Zijian", ""], ["Tian", "Yuandong", ""], ["Xie", "Saining", ""], ["Wu", "Bichen", ""], ["Yu", "Matthew", ""], ["Xu", "Tao", ""], ["Chen", "Kan", ""], ["Vajda", "Peter", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2004.05569", "submitter": "Veronica Latcinnik", "authors": "Veronica Latcinnik, Jonathan Berant", "title": "Explaining Question Answering Models through Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large pre-trained language models (LMs) have been shown to perform\nsurprisingly well when fine-tuned on tasks that require commonsense and world\nknowledge. However, in end-to-end architectures, it is difficult to explain\nwhat is the knowledge in the LM that allows it to make a correct prediction. In\nthis work, we propose a model for multi-choice question answering, where a\nLM-based generator generates a textual hypothesis that is later used by a\nclassifier to answer the question. The hypothesis provides a window into the\ninformation used by the fine-tuned LM that can be inspected by humans. A key\nchallenge in this setup is how to constrain the model to generate hypotheses\nthat are meaningful to humans. We tackle this by (a) joint training with a\nsimple similarity classifier that encourages meaningful hypotheses, and (b) by\nadding loss functions that encourage natural text without repetitions. We show\non several tasks that our model reaches performance that is comparable to\nend-to-end architectures, while producing hypotheses that elucidate the\nknowledge used by the LM for answering the question.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 09:06:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Latcinnik", "Veronica", ""], ["Berant", "Jonathan", ""]]}, {"id": "2004.05572", "submitter": "Deng Cai", "authors": "Deng Cai and Wai Lam", "title": "AMR Parsing via Graph-Sequence Iterative Inference", "comments": "ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new end-to-end model that treats AMR parsing as a series of dual\ndecisions on the input sequence and the incrementally constructed graph. At\neach time step, our model performs multiple rounds of attention, reasoning, and\ncomposition that aim to answer two critical questions: (1) which part of the\ninput \\textit{sequence} to abstract; and (2) where in the output \\textit{graph}\nto construct the new concept. We show that the answers to these two questions\nare mutually causalities. We design a model based on iterative inference that\nhelps achieve better answers in both perspectives, leading to greatly improved\nparsing accuracy. Our experimental results significantly outperform all\npreviously reported \\textsc{Smatch} scores by large margins. Remarkably,\nwithout the help of any large-scale pre-trained language model (e.g., BERT),\nour model already surpasses previous state-of-the-art using BERT. With the help\nof BERT, we can push the state-of-the-art results to 80.2\\% on LDC2017T10 (AMR\n2.0) and 75.4\\% on LDC2014T12 (AMR 1.0).\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 09:15:21 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 04:01:44 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Cai", "Deng", ""], ["Lam", "Wai", ""]]}, {"id": "2004.05573", "submitter": "Shizhe Chen", "authors": "Shizhe Chen, Weiying Wang, Ludan Ruan, Linli Yao, Qin Jin", "title": "YouMakeup VQA Challenge: Towards Fine-grained Action Understanding in\n  Domain-Specific Videos", "comments": "CVPR LVVU Workshop 2020 YouMakeup VQA Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the YouMakeup VQA Challenge 2020 is to provide a common benchmark\nfor fine-grained action understanding in domain-specific videos e.g. makeup\ninstructional videos. We propose two novel question-answering tasks to evaluate\nmodels' fine-grained action understanding abilities. The first task is\n\\textbf{Facial Image Ordering}, which aims to understand visual effects of\ndifferent actions expressed in natural language to the facial object. The\nsecond task is \\textbf{Step Ordering}, which aims to measure cross-modal\nsemantic alignments between untrimmed videos and multi-sentence texts. In this\npaper, we present the challenge guidelines, the dataset used, and performances\nof baseline models on the two proposed tasks. The baseline codes and models are\nreleased at \\url{https://github.com/AIM3-RUC/YouMakeup_Baseline}.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 09:25:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Chen", "Shizhe", ""], ["Wang", "Weiying", ""], ["Ruan", "Ludan", ""], ["Yao", "Linli", ""], ["Jin", "Qin", ""]]}, {"id": "2004.05574", "submitter": "Ali Shahin Shamsabadi", "authors": "Ali Shahin Shamsabadi, Adria Gascon, Hamed Haddadi and Andrea\n  Cavallaro", "title": "PrivEdge: From Local to Distributed Private Training and Prediction", "comments": "IEEE Transactions on Information Forensics and Security (TIFS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) operators provide model training and\nprediction on the cloud. MLaaS applications often rely on centralised\ncollection and aggregation of user data, which could lead to significant\nprivacy concerns when dealing with sensitive personal data. To address this\nproblem, we propose PrivEdge, a technique for privacy-preserving MLaaS that\nsafeguards the privacy of users who provide their data for training, as well as\nusers who use the prediction service. With PrivEdge, each user independently\nuses their private data to locally train a one-class reconstructive adversarial\nnetwork that succinctly represents their training data. As sending the model\nparameters to the service provider in the clear would reveal private\ninformation, PrivEdge secret-shares the parameters among two non-colluding\nMLaaS providers, to then provide cryptographically private prediction services\nthrough secure multi-party computation techniques. We quantify the benefits of\nPrivEdge and compare its performance with state-of-the-art centralised\narchitectures on three privacy-sensitive image-based tasks: individual\nidentification, writer identification, and handwritten letter recognition.\nExperimental results show that PrivEdge has high precision and recall in\npreserving privacy, as well as in distinguishing between private and\nnon-private images. Moreover, we show the robustness of PrivEdge to image\ncompression and biased training data. The source code is available at\nhttps://github.com/smartcameras/PrivEdge.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 09:26:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Shamsabadi", "Ali Shahin", ""], ["Gascon", "Adria", ""], ["Haddadi", "Hamed", ""], ["Cavallaro", "Andrea", ""]]}, {"id": "2004.05599", "submitter": "Omar Darwiche Domingues", "authors": "Omar Darwiche Domingues, Pierre M\\'enard, Matteo Pirotta, Emilie\n  Kaufmann, Michal Valko", "title": "Regret Bounds for Kernel-Based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the exploration-exploitation dilemma in finite-horizon\nreinforcement learning problems whose state-action space is endowed with a\nmetric. We introduce Kernel-UCBVI, a model-based optimistic algorithm that\nleverages the smoothness of the MDP and a non-parametric kernel estimator of\nthe rewards and transitions to efficiently balance exploration and\nexploitation. Unlike existing approaches with regret guarantees, it does not\nuse any kind of partitioning of the state-action space. For problems with $K$\nepisodes and horizon $H$, we provide a regret bound of $O\\left( H^3\nK^{\\max\\left(\\frac{1}{2}, \\frac{2d}{2d+1}\\right)}\\right)$, where $d$ is the\ncovering dimension of the joint state-action space. We empirically validate\nKernel-UCBVI on discrete and continuous MDPs.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 12:23:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:19:40 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Domingues", "Omar Darwiche", ""], ["M\u00e9nard", "Pierre", ""], ["Pirotta", "Matteo", ""], ["Kaufmann", "Emilie", ""], ["Valko", "Michal", ""]]}, {"id": "2004.05607", "submitter": "Aleksandr Cariow", "authors": "Aleksandr Cariow and Galina Cariowa", "title": "Minimal Filtering Algorithms for Convolutional Neural Networks", "comments": "11 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present several resource-efficient algorithmic solutions\nregarding the fully parallel hardware implementation of the basic filtering\noperation performed in the convolutional layers of convolution neural networks.\nIn fact, these basic operations calculate two inner products of neighboring\nvectors formed by a sliding time window from the current data stream with an\nimpulse response of the M-tap finite impulse response filter. We used Winograd\nminimal filtering trick and applied it to develop fully parallel\nhardware-oriented algorithms for implementing the basic filtering operation for\nM=3,5,7,9, and 11. A fully parallel hardware implementation of the proposed\nalgorithms in each case gives approximately 30 percent savings in the number of\nembedded multipliers compared to a fully parallel hardware implementation of\nthe naive calculation methods.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 13:18:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cariow", "Aleksandr", ""], ["Cariowa", "Galina", ""]]}, {"id": "2004.05617", "submitter": "Rogan Morrow", "authors": "Rogan Morrow, Wei-Chen Chiu", "title": "Variational Autoencoders with Normalizing Flow Decoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed normalizing flow models such as Glow have been shown to be\nable to generate high quality, high dimensional images with relatively fast\nsampling speed. Due to their inherently restrictive architecture, however, it\nis necessary that they are excessively deep in order to train effectively. In\nthis paper we propose to combine Glow with an underlying variational\nautoencoder in order to counteract this issue. We demonstrate that our proposed\nmodel is competitive with Glow in terms of image quality and test likelihood\nwhile requiring far less time for training.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 14:11:15 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Morrow", "Rogan", ""], ["Chiu", "Wei-Chen", ""]]}, {"id": "2004.05629", "submitter": "Martin Huber", "authors": "Hannes Wallimann and David Imhof and Martin Huber", "title": "A Machine Learning Approach for Flagging Incomplete Bid-rigging Cartels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for flagging bid rigging, which is particularly\nuseful for detecting incomplete bid-rigging cartels. Our approach combines\nscreens, i.e. statistics derived from the distribution of bids in a tender,\nwith machine learning to predict the probability of collusion. As a\nmethodological innovation, we calculate such screens for all possible subgroups\nof three or four bids within a tender and use summary statistics like the mean,\nmedian, maximum, and minimum of each screen as predictors in the machine\nlearning algorithm. This approach tackles the issue that competitive bids in\nincomplete cartels distort the statistical signals produced by bid rigging. We\ndemonstrate that our algorithm outperforms previously suggested methods in\napplications to incomplete cartels based on empirical data from Switzerland.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 15:04:35 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wallimann", "Hannes", ""], ["Imhof", "David", ""], ["Huber", "Martin", ""]]}, {"id": "2004.05631", "submitter": "Tai-Danae Bradley", "authors": "Tai-Danae Bradley", "title": "At the Interface of Algebra and Statistics", "comments": "135 pages, PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG math.CT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis takes inspiration from quantum physics to investigate\nmathematical structure that lies at the interface of algebra and statistics.\nThe starting point is a passage from classical probability theory to quantum\nprobability theory. The quantum version of a probability distribution is a\ndensity operator, the quantum version of marginalizing is an operation called\nthe partial trace, and the quantum version of a marginal probability\ndistribution is a reduced density operator. Every joint probability\ndistribution on a finite set can be modeled as a rank one density operator. By\napplying the partial trace, we obtain reduced density operators whose diagonals\nrecover classical marginal probabilities. In general, these reduced densities\nwill have rank higher than one, and their eigenvalues and eigenvectors will\ncontain extra information that encodes subsystem interactions governed by\nstatistics. We decode this information, and show it is akin to conditional\nprobability, and then investigate the extent to which the eigenvectors capture\n\"concepts\" inherent in the original joint distribution. The theory is then\nillustrated with an experiment that exploits these ideas. Turning to a more\ntheoretical application, we also discuss a preliminary framework for modeling\nentailment and concept hierarchy in natural language, namely, by representing\nexpressions in the language as densities. Finally, initial inspiration for this\nthesis comes from formal concept analysis, which finds many striking parallels\nwith the linear algebra. The parallels are not coincidental, and a common\nblueprint is found in category theory. We close with an exposition on free\n(co)completions and how the free-forgetful adjunctions in which they arise\nstrongly suggest that in certain categorical contexts, the \"fixed points\" of a\nmorphism with its adjoint encode interesting information.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 15:22:07 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bradley", "Tai-Danae", ""]]}, {"id": "2004.05640", "submitter": "Jiancheng Yang", "authors": "Jiancheng Yang, Haoran Deng, Xiaoyang Huang, Bingbing Ni, Yi Xu", "title": "Relational Learning between Multiple Pulmonary Nodules via Deep Set\n  Attention Transformers", "comments": "2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI\n  2020)", "journal-ref": null, "doi": "10.1109/ISBI45749.2020.9098722", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosis and treatment of multiple pulmonary nodules are clinically\nimportant but challenging. Prior studies on nodule characterization use\nsolitary-nodule approaches on multiple nodular patients, which ignores the\nrelations between nodules. In this study, we propose a multiple instance\nlearning (MIL) approach and empirically prove the benefit to learn the\nrelations between multiple nodules. By treating the multiple nodules from a\nsame patient as a whole, critical relational information between\nsolitary-nodule voxels is extracted. To our knowledge, it is the first study to\nlearn the relations between multiple pulmonary nodules. Inspired by recent\nadvances in natural language processing (NLP) domain, we introduce a\nself-attention transformer equipped with 3D CNN, named {NoduleSAT}, to replace\ntypical pooling-based aggregation in multiple instance learning. Extensive\nexperiments on lung nodule false positive reduction on LUNA16 database, and\nmalignancy classification on LIDC-IDRI database, validate the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 16:05:08 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Yang", "Jiancheng", ""], ["Deng", "Haoran", ""], ["Huang", "Xiaoyang", ""], ["Ni", "Bingbing", ""], ["Xu", "Yi", ""]]}, {"id": "2004.05645", "submitter": "Xiaocong Chen", "authors": "Xiaocong Chen, Lina Yao, Yu Zhang", "title": "Residual Attention U-Net for Automated Multi-Class Segmentation of\n  COVID-19 Chest CT Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus disease 2019 (COVID-19) has been spreading rapidly\naround the world and caused significant impact on the public health and\neconomy. However, there is still lack of studies on effectively quantifying the\nlung infection caused by COVID-19. As a basic but challenging task of the\ndiagnostic framework, segmentation plays a crucial role in accurate\nquantification of COVID-19 infection measured by computed tomography (CT)\nimages. To this end, we proposed a novel deep learning algorithm for automated\nsegmentation of multiple COVID-19 infection regions. Specifically, we use the\nAggregated Residual Transformations to learn a robust and expressive feature\nrepresentation and apply the soft attention mechanism to improve the capability\nof the model to distinguish a variety of symptoms of the COVID-19. With a\npublic CT image dataset, we validate the efficacy of the proposed algorithm in\ncomparison with other competing methods. Experimental results demonstrate the\noutstanding performance of our algorithm for automated segmentation of COVID-19\nChest CT images. Our study provides a promising deep leaning-based segmentation\ntool to lay a foundation to quantitative diagnosis of COVID-19 lung infection\nin CT images.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 16:24:59 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Zhang", "Yu", ""]]}, {"id": "2004.05665", "submitter": "Biswajit Paria", "authors": "Biswajit Paria, Chih-Kuan Yeh, Ian E.H. Yen, Ning Xu, Pradeep\n  Ravikumar, Barnab\\'as P\\'oczos", "title": "Minimizing FLOPs to Learn Efficient Sparse Representations", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep representation learning has become one of the most widely adopted\napproaches for visual search, recommendation, and identification. Retrieval of\nsuch representations from a large database is however computationally\nchallenging. Approximate methods based on learning compact representations,\nhave been widely explored for this problem, such as locality sensitive hashing,\nproduct quantization, and PCA. In this work, in contrast to learning compact\nrepresentations, we propose to learn high dimensional and sparse\nrepresentations that have similar representational capacity as dense embeddings\nwhile being more efficient due to sparse matrix multiplication operations which\ncan be much faster than dense multiplication. Following the key insight that\nthe number of operations decreases quadratically with the sparsity of\nembeddings provided the non-zero entries are distributed uniformly across\ndimensions, we propose a novel approach to learn such distributed sparse\nembeddings via the use of a carefully constructed regularization function that\ndirectly minimizes a continuous relaxation of the number of floating-point\noperations (FLOPs) incurred during retrieval. Our experiments show that our\napproach is competitive to the other baselines and yields a similar or better\nspeed-vs-accuracy tradeoff on practical datasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 18:09:02 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Paria", "Biswajit", ""], ["Yeh", "Chih-Kuan", ""], ["Yen", "Ian E. H.", ""], ["Xu", "Ning", ""], ["Ravikumar", "Pradeep", ""], ["P\u00f3czos", "Barnab\u00e1s", ""]]}, {"id": "2004.05671", "submitter": "Jianyuan Yu", "authors": "Jianyuan Yu, William W. Howard, Daniel Tait and R. Michael Buehrer", "title": "Direction of Arrival Estimation for a Vector Sensor Using Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vector sensor, a type of sensor array with six collocated antennas to\nmeasure all electromagnetic field components of incident waves, has been shown\nto be advantageous in estimating the angle of arrival and polarization of the\nincident sources. While angle estimation with machine learning for linear\narrays has been well studied, there has not been a similar solution for the\nvector sensor. In this paper, we propose neural networks to determine the\nnumber of the sources and estimate the angle of arrival of each source, based\non the covariance matrix extracted from received data. Also, we provide a\nsolution for matching output angles to corresponding sources and examine the\nerror distributions with this method. The results show that neural networks can\nachieve reasonably accurate estimation with up to 5 sources, especially if the\nfield-of-view is limited.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 18:37:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Yu", "Jianyuan", ""], ["Howard", "William W.", ""], ["Tait", "Daniel", ""], ["Buehrer", "R. Michael", ""]]}, {"id": "2004.05675", "submitter": "Casey Meehan", "authors": "Casey Meehan, Kamalika Chaudhuri, Sanjoy Dasgupta", "title": "A Non-Parametric Test to Detect Data-Copying in Generative Models", "comments": "To be published in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting overfitting in generative models is an important challenge in\nmachine learning. In this work, we formalize a form of overfitting that we call\n{\\em{data-copying}} -- where the generative model memorizes and outputs\ntraining samples or small variations thereof. We provide a three sample\nnon-parametric test for detecting data-copying that uses the training set, a\nseparate sample from the target distribution, and a generated sample from the\nmodel, and study the performance of our test on several canonical models and\ndatasets.\n  For code \\& examples, visit https://github.com/casey-meehan/data-copying\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 18:59:29 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Meehan", "Casey", ""], ["Chaudhuri", "Kamalika", ""], ["Dasgupta", "Sanjoy", ""]]}, {"id": "2004.05686", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee, Ahmed Awadallah", "title": "XtremeDistil: Multi-stage Distillation for Massive Multilingual Models", "comments": "To appear in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep and large pre-trained language models are the state-of-the-art for\nvarious natural language processing tasks. However, the huge size of these\nmodels could be a deterrent to use them in practice. Some recent and concurrent\nworks use knowledge distillation to compress these huge models into shallow\nones. In this work we study knowledge distillation with a focus on\nmulti-lingual Named Entity Recognition (NER). In particular, we study several\ndistillation strategies and propose a stage-wise optimization scheme leveraging\nteacher internal representations that is agnostic of teacher architecture and\nshow that it outperforms strategies employed in prior works. Additionally, we\ninvestigate the role of several factors like the amount of unlabeled data,\nannotation resources, model architecture and inference latency to name a few.\nWe show that our approach leads to massive compression of MBERT-like teacher\nmodels by upto 35x in terms of parameters and 51x in terms of latency for batch\ninference while retaining 95% of its F1-score for NER over 41 languages.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 19:49:27 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 00:20:48 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Mukherjee", "Subhabrata", ""], ["Awadallah", "Ahmed", ""]]}, {"id": "2004.05691", "submitter": "Aliaksei Mikhailiuk", "authors": "Aliaksei Mikhailiuk, Clifford Wilmot, Maria Perez-Ortiz, Dingcheng\n  Yue, Rafal Mantiuk", "title": "Active Sampling for Pairwise Comparisons via Approximate Message Passing\n  and Information Gain Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise comparison data arise in many domains with subjective assessment\nexperiments, for example in image and video quality assessment. In these\nexperiments observers are asked to express a preference between two conditions.\nHowever, many pairwise comparison protocols require a large number of\ncomparisons to infer accurate scores, which may be unfeasible when each\ncomparison is time-consuming (e.g. videos) or expensive (e.g. medical imaging).\nThis motivates the use of an active sampling algorithm that chooses only the\nmost informative pairs for comparison. In this paper we propose ASAP, an active\nsampling algorithm based on approximate message passing and expected\ninformation gain maximization. Unlike most existing methods, which rely on\npartial updates of the posterior distribution, we are able to perform full\nupdates and therefore much improve the accuracy of the inferred scores. The\nalgorithm relies on three techniques for reducing computational cost: inference\nbased on approximate message passing, selective evaluations of the information\ngain, and selecting pairs in a batch that forms a minimum spanning tree of the\ninverse of information gain. We demonstrate, with real and synthetic data, that\nASAP offers the highest accuracy of inferred scores compared to the existing\nmethods. We also provide an open-source GPU implementation of ASAP for\nlarge-scale experiments.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 20:48:10 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mikhailiuk", "Aliaksei", ""], ["Wilmot", "Clifford", ""], ["Perez-Ortiz", "Maria", ""], ["Yue", "Dingcheng", ""], ["Mantiuk", "Rafal", ""]]}, {"id": "2004.05692", "submitter": "Panagiotis Sidiropoulos", "authors": "Panagiotis Sidiropoulos", "title": "Measuring spatial uniformity with the hypersphere chord length\n  distribution", "comments": "18 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data uniformity is a concept associated with several semantic data\ncharacteristics such as lack of features, correlation and sample bias. This\narticle introduces a novel measure to assess data uniformity and detect uniform\npointsets on high-dimensional Euclidean spaces. Spatial uniformity measure\nbuilds upon the isomorphism between hyperspherical chords and L2-normalised\ndata Euclidean distances, which is implied by the fact that, in Euclidean\nspaces, L2-normalised data can be geometrically defined as points on a\nhypersphere. The imposed connection between the distance distribution of\nuniformly selected points and the hyperspherical chord length distribution is\nemployed to quantify uniformity. More specifically,, the closed-form expression\nof hypersphere chord length distribution is revisited extended, before\nexamining a few qualitative and quantitative characteristics of this\ndistribution that can be rather straightforwardly linked to data uniformity.\nThe experimental section includes validation in four distinct setups, thus\nsubstantiating the potential of the new uniformity measure on practical\ndata-science applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 20:48:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Sidiropoulos", "Panagiotis", ""]]}, {"id": "2004.05693", "submitter": "Ao Liu", "authors": "Ao Liu, Yunpeng Wang, Tao Li", "title": "SFE-GACN: A Novel Unknown Attack Detection Method Using Intra Categories\n  Generation in Embedding Space", "comments": "19 pages, 9 figures, submitted to Computers & Security, accepted", "journal-ref": null, "doi": "10.1016/j.cose.2021.102262", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the encrypted network traffic intrusion detection, deep learning based\nschemes have attracted lots of attention. However, in real-world scenarios,\ndata is often insufficient (few-shot), which leads to various deviations\nbetween the models prediction and the ground truth. Consequently, downstream\ntasks such as unknown attack detection based on few-shot will be limited by\ninsufficient data. In this paper, we propose a novel unknown attack detection\nmethod based on Intra Categories Generation in Embedding Space, namely\nSFE-GACN, which might be the solution of few-shot problem. Concretely, we first\nproposed Session Feature Embedding (SFE) to summarize the context of sessions\n(session is the basic granularity of network traffic), bring the insufficient\ndata to the pre-trained embedding space. In this way, we achieve the goal of\npreliminary information extension in the few-shot case. Second, we further\npropose the Generative Adversarial Cooperative Network (GACN), which improves\nthe conventional Generative Adversarial Network by supervising the generated\nsample to avoid falling into similar categories, and thus enables samples to\ngenerate intra categories. Our proposed SFE-GACN can accurately generate\nsession samples in the case of few-shot, and ensure the difference between\ncategories during data augmentation. The detection results show that, compared\nto the state-of-the-art method, the average TPR is 8.38% higher, and the\naverage FPR is 12.77% lower. In addition, we evaluated the graphics generation\ncapabilities of GACN on the graphics dataset, the result shows our proposed\nGACN can be popularized for generating easy-confused multi-categories graphics.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 20:51:00 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:54:00 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Liu", "Ao", ""], ["Wang", "Yunpeng", ""], ["Li", "Tao", ""]]}, {"id": "2004.05698", "submitter": "Sharmin Pathan", "authors": "Sharmin Pathan, Anant Tripathi", "title": "Y-net: Biomedical Image Segmentation and Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep clustering architecture alongside image segmentation for\nmedical image analysis. The main idea is based on unsupervised learning to\ncluster images on severity of the disease in the subject's sample, and this\nimage is then segmented to highlight and outline regions of interest. We start\nwith training an autoencoder on the images for segmentation. The encoder part\nfrom the autoencoder branches out to a clustering node and segmentation node.\nDeep clustering using Kmeans clustering is performed at the clustering branch\nand a lightweight model is used for segmentation. Each of the branches use\nextracted features from the autoencoder. We demonstrate our results on ISIC\n2018 Skin Lesion Analysis Towards Melanoma Detection and Cityscapes datasets\nfor segmentation and clustering. The proposed architecture beats UNet and\nDeepLab results on the two datasets, and has less than half the number of\nparameters. We use the deep clustering branch for clustering images into four\nclusters. Our approach can be applied to work with high complexity datasets of\nmedical imaging for analyzing survival prediction for severe diseases or\ncustomizing treatment based on how far the disease has propagated. Clustering\npatients can help understand how binning should be done on real valued features\nto reduce feature sparsity and improve accuracy on classification tasks. The\nproposed architecture can provide an early diagnosis and reduce human\nintervention on labeling as it can become quite costly as the datasets grow\nlarger. The main idea is to propose a one shot approach to segmentation with\ndeep clustering.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 21:08:31 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 02:08:16 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Pathan", "Sharmin", ""], ["Tripathi", "Anant", ""]]}, {"id": "2004.05703", "submitter": "Fan Mo", "authors": "Fan Mo, Ali Shahin Shamsabadi, Kleomenis Katevas, Soteris Demetriou,\n  Ilias Leontiadis, Andrea Cavallaro, Hamed Haddadi", "title": "DarkneTZ: Towards Model Privacy at the Edge using Trusted Execution\n  Environments", "comments": "13 pages, 8 figures, accepted to ACM MobiSys 2020", "journal-ref": null, "doi": "10.1145/3386901.3388946", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DarkneTZ, a framework that uses an edge device's Trusted Execution\nEnvironment (TEE) in conjunction with model partitioning to limit the attack\nsurface against Deep Neural Networks (DNNs). Increasingly, edge devices\n(smartphones and consumer IoT devices) are equipped with pre-trained DNNs for a\nvariety of applications. This trend comes with privacy risks as models can leak\ninformation about their training data through effective membership inference\nattacks (MIAs). We evaluate the performance of DarkneTZ, including CPU\nexecution time, memory usage, and accurate power consumption, using two small\nand six large image classification models. Due to the limited memory of the\nedge device's TEE, we partition model layers into more sensitive layers (to be\nexecuted inside the device TEE), and a set of layers to be executed in the\nuntrusted part of the operating system. Our results show that even if a single\nlayer is hidden, we can provide reliable model privacy and defend against state\nof the art MIAs, with only 3% performance overhead. When fully utilizing the\nTEE, DarkneTZ provides model protections with up to 10% overhead.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 21:42:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mo", "Fan", ""], ["Shamsabadi", "Ali Shahin", ""], ["Katevas", "Kleomenis", ""], ["Demetriou", "Soteris", ""], ["Leontiadis", "Ilias", ""], ["Cavallaro", "Andrea", ""], ["Haddadi", "Hamed", ""]]}, {"id": "2004.05707", "submitter": "Zhibin Lu", "authors": "Zhibin Lu, Pan Du, Jian-Yun Nie", "title": "VGCN-BERT: Augmenting BERT with Graph Embedding for Text Classification", "comments": "12 pages, 2 figures", "journal-ref": "in J. M. Jose et al. (Eds.): ECIR 2020, LNCS 12035, pp.369-382,\n  2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much progress has been made recently on text classification with methods\nbased on neural networks. In particular, models using attention mechanism such\nas BERT have shown to have the capability of capturing the contextual\ninformation within a sentence or document. However, their ability of capturing\nthe global information about the vocabulary of a language is more limited. This\nlatter is the strength of Graph Convolutional Networks (GCN). In this paper, we\npropose VGCN-BERT model which combines the capability of BERT with a Vocabulary\nGraph Convolutional Network (VGCN). Local information and global information\ninteract through different layers of BERT, allowing them to influence mutually\nand to build together a final representation for classification. In our\nexperiments on several text classification datasets, our approach outperforms\nBERT and GCN alone, and achieve higher effectiveness than that reported in\nprevious studies.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 22:02:33 GMT"}], "update_date": "2020-06-14", "authors_parsed": [["Lu", "Zhibin", ""], ["Du", "Pan", ""], ["Nie", "Jian-Yun", ""]]}, {"id": "2004.05716", "submitter": "Zhi Liu", "authors": "Zhi Liu, Yan Huang, Jing Gao, Li Chen, Dong Li", "title": "Large-scale Real-time Personalized Similar Product Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar product recommendation is one of the most common scenes in\ne-commerce. Many recommendation algorithms such as item-to-item Collaborative\nFiltering are working on measuring item similarities. In this paper, we\nintroduce our real-time personalized algorithm to model product similarity and\nreal-time user interests. We also introduce several other baseline algorithms\nincluding an image-similarity-based method, item-to-item collaborative\nfiltering, and item2vec, and compare them on our large-scale real-world\ne-commerce dataset. The algorithms which achieve good offline results are also\ntested on the online e-commerce website. Our personalized method achieves a 10%\nimprovement on the add-cart number in the real-world e-commerce scenario.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:16:14 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Zhi", ""], ["Huang", "Yan", ""], ["Gao", "Jing", ""], ["Chen", "Li", ""], ["Li", "Dong", ""]]}, {"id": "2004.05717", "submitter": "Eduardo Jos\\'e Da Silva Luz", "authors": "Eduardo Luz, Pedro Lopes Silva, Rodrigo Silva, Ludmila Silva, Gladston\n  Moreira and David Menotti", "title": "Towards an Effective and Efficient Deep Learning Model for COVID-19\n  Patterns Detection in X-ray Images", "comments": "This is a preprint of an article published in Research on Biomedical\n  Engineering. The final authenticated version is available online at\n  https://doi.org/10.1007/s42600-021-00151-6", "journal-ref": null, "doi": "10.1007/s42600-021-00151-6", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Confronting the pandemic of COVID-19, is nowadays one of the most prominent\nchallenges of the human species. A key factor in slowing down the virus\npropagation is the rapid diagnosis and isolation of infected patients. The\nstandard method for COVID-19 identification, the Reverse transcription\npolymerase chain reaction method, is time-consuming and in short supply due to\nthe pandemic. Thus, researchers have been looking for alternative screening\nmethods and deep learning applied to chest X-rays of patients has been showing\npromising results. Despite their success, the computational cost of these\nmethods remains high, which imposes difficulties to their accessibility and\navailability. Thus, the main goal of this work is to propose an accurate yet\nefficient method in terms of memory and processing time for the problem of\nCOVID-19 screening in chest X-rays. Methods: To achieve the defined objective\nwe exploit and extend the EfficientNet family of deep artificial neural\nnetworks which are known for their high accuracy and low footprints in other\napplications. We also exploit the underlying taxonomy of the problem with a\nhierarchical classifier. A dataset of 13,569 X-ray images divided into healthy,\nnon-COVID-19 pneumonia, and COVID-19 patients is used to train the proposed\napproaches and other 5 competing architectures. Finally, 231 images of the\nthree classes were used to assess the quality of the methods. Results: The\nresults show that the proposed approach was able to produce a high-quality\nmodel, with an overall accuracy of 93.9%, COVID-19, sensitivity of 96.8% and\npositive prediction of 100%, while having from 5 to 30 times fewer parameters\nthan other than the other tested architectures. Larger and more heterogeneous\ndatabases are still needed for validation before claiming that deep learning\ncan assist physicians in the task of detecting COVID-19 in X-ray images.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:26:56 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 03:32:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 19:03:46 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 15:43:10 GMT"}, {"version": "v5", "created": "Sat, 24 Apr 2021 12:36:57 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Luz", "Eduardo", ""], ["Silva", "Pedro Lopes", ""], ["Silva", "Rodrigo", ""], ["Silva", "Ludmila", ""], ["Moreira", "Gladston", ""], ["Menotti", "David", ""]]}, {"id": "2004.05718", "submitter": "Gabriele Corso", "authors": "Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\\`o, Petar\n  Veli\\v{c}kovi\\'c", "title": "Principal Neighbourhood Aggregation for Graph Nets", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been shown to be effective models for\ndifferent predictive tasks on graph-structured data. Recent work on their\nexpressive power has focused on isomorphism tasks and countable feature spaces.\nWe extend this theoretical framework to include continuous features - which\noccur regularly in real-world input domains and within the hidden layers of\nGNNs - and we demonstrate the requirement for multiple aggregation functions in\nthis context. Accordingly, we propose Principal Neighbourhood Aggregation\n(PNA), a novel architecture combining multiple aggregators with degree-scalers\n(which generalize the sum aggregator). Finally, we compare the capacity of\ndifferent models to capture and exploit the graph structure via a novel\nbenchmark containing multiple tasks taken from classical graph theory,\nalongside existing benchmarks from real-world domains, all of which demonstrate\nthe strength of our model. With this work, we hope to steer some of the GNN\nresearch towards new aggregation methods which we believe are essential in the\nsearch for powerful and robust models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:30:00 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 16:33:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 15:40:07 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2020 16:36:18 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2020 08:23:06 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Corso", "Gabriele", ""], ["Cavalleri", "Luca", ""], ["Beaini", "Dominique", ""], ["Li\u00f2", "Pietro", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2004.05722", "submitter": "Weiyuan Wu", "authors": "Weiyuan Wu, Lampros Flokas, Eugene Wu, Jiannan Wang", "title": "Complaint-driven Training Data Debugging for Query 2.0", "comments": "Proceedings of the 2020 ACM SIGMOD International Conference on\n  Management of Data", "journal-ref": null, "doi": "10.1145/3318464.3389696", "report-no": null, "categories": "cs.DB cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the need for machine learning (ML) increases rapidly across all industry\nsectors, there is a significant interest among commercial database providers to\nsupport \"Query 2.0\", which integrates model inference into SQL queries.\nDebugging Query 2.0 is very challenging since an unexpected query result may be\ncaused by the bugs in training data (e.g., wrong labels, corrupted features).\nIn response, we propose Rain, a complaint-driven training data debugging\nsystem. Rain allows users to specify complaints over the query's intermediate\nor final output, and aims to return a minimum set of training examples so that\nif they were removed, the complaints would be resolved. To the best of our\nknowledge, we are the first to study this problem. A naive solution requires\nretraining an exponential number of ML models. We propose two novel heuristic\napproaches based on influence functions which both require linear retraining\nsteps. We provide an in-depth analytical and empirical analysis of the two\napproaches and conduct extensive experiments to evaluate their effectiveness\nusing four real-world datasets. Results show that Rain achieves the highest\nrecall@k among all the baselines while still returns results interactively.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:56:06 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wu", "Weiyuan", ""], ["Flokas", "Lampros", ""], ["Wu", "Eugene", ""], ["Wang", "Jiannan", ""]]}, {"id": "2004.05731", "submitter": "Lavanya Umapathy", "authors": "Lavanya Umapathy (1 and 2), Mahesh Bharath Keerthivasan (1 and 2),\n  Jean-Phillipe Galons (2), Wyatt Unger (2), Diego Martin (2), Maria I Altbach\n  (2) and Ali Bilgin (1 and 2 and 3) ((1) Department of Electrical and Computer\n  Engineering, University of Arizona, Tucson, Arizona, (2) Department of\n  Medical Imaging, University of Arizona, Tucson, Arizona, (3) Department of\n  Biomedical Engineering, University of Arizona, Tucson, Arizona)", "title": "A Comparison of Deep Learning Convolution Neural Networks for Liver\n  Segmentation in Radial Turbo Spin Echo Images", "comments": "3 pages, 4 figures, 1 table. Published in Proceedings of\n  International Society for Magnetic Resonance in Medicine 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion-robust 2D Radial Turbo Spin Echo (RADTSE) pulse sequence can provide a\nhigh-resolution composite image, T2-weighted images at multiple echo times\n(TEs), and a quantitative T2 map, all from a single k-space acquisition. In\nthis work, we use a deep-learning convolutional neural network (CNN) for the\nsegmentation of liver in abdominal RADTSE images. A modified UNET architecture\nwith generalized dice loss objective function was implemented. Three 2D CNNs\nwere trained, one for each image type obtained from the RADTSE sequence. On\nevaluating the performance of the CNNs on the validation set, we found that\nCNNs trained on TE images or the T2 maps had higher average dice scores than\nthe composite images. This, in turn, implies that the information regarding T2\nvariation in tissues aids in improving the segmentation performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 00:19:02 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Umapathy", "Lavanya", "", "1 and 2"], ["Keerthivasan", "Mahesh Bharath", "", "1 and 2"], ["Galons", "Jean-Phillipe", "", "1 and 2 and 3"], ["Unger", "Wyatt", "", "1 and 2 and 3"], ["Martin", "Diego", "", "1 and 2 and 3"], ["Altbach", "Maria I", "", "1 and 2 and 3"], ["Bilgin", "Ali", "", "1 and 2 and 3"]]}, {"id": "2004.05741", "submitter": "Ahmed S. Zamzam", "authors": "Ahmed S. Zamzam and Yajing Liu and Andrey Bernstein", "title": "Model-Free State Estimation Using Low-Rank Canonical Polyadic\n  Decomposition", "comments": "8 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As electric grids experience high penetration levels of renewable generation,\nfundamental changes are required to address real-time situational awareness.\nThis paper uses unique traits of tensors to devise a model-free situational\nawareness and energy forecasting framework for distribution networks. This work\nformulates the state of the network at multiple time instants as a three-way\ntensor; hence, recovering full state information of the network is tantamount\nto estimating all the values of the tensor. Given measurements received from\n$\\mu$phasor measurement units and/or smart meters, the recovery of unobserved\nquantities is carried out using the low-rank canonical polyadic decomposition\nof the state tensor---that is, the state estimation task is posed as a tensor\nimputation problem utilizing observed patterns in measured quantities. Two\nstructured sampling schemes are considered: slab sampling and fiber sampling.\nFor both schemes, we present sufficient conditions on the number of sampled\nslabs and fibers that guarantee identifiability of the factors of the state\ntensor. Numerical results demonstrate the ability of the proposed framework to\nachieve high estimation accuracy in multiple sampling scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 01:50:51 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zamzam", "Ahmed S.", ""], ["Liu", "Yajing", ""], ["Bernstein", "Andrey", ""]]}, {"id": "2004.05755", "submitter": "Yufei Tian", "authors": "Yufei Tian, Jianfei Yu, Jing Jiang", "title": "Aspect and Opinion Aware Abstractive Review Summarization with\n  Reinforced Hard Typed Decoder", "comments": null, "journal-ref": null, "doi": "10.1145/3357384.3358142", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study abstractive review summarization.Observing that\nreview summaries often consist of aspect words, opinion words and context\nwords, we propose a two-stage reinforcement learning approach, which first\npredicts the output word type from the three types, and then leverages the\npredicted word type to generate the final word distribution.Experimental\nresults on two Amazon product review datasets demonstrate that our method can\nconsistently outperform several strong baseline approaches based on ROUGE\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 03:35:29 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Tian", "Yufei", ""], ["Yu", "Jianfei", ""], ["Jiang", "Jing", ""]]}, {"id": "2004.05757", "submitter": "Mingjun Zhao", "authors": "Mingjun Zhao, Haijiang Wu, Di Niu and Xiaoli Wang", "title": "Reinforced Curriculum Learning on Pre-trained Neural Machine Translation\n  Models", "comments": "Accepted as full paper by AAAI-2020 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competitive performance of neural machine translation (NMT) critically\nrelies on large amounts of training data. However, acquiring high-quality\ntranslation pairs requires expert knowledge and is costly. Therefore, how to\nbest utilize a given dataset of samples with diverse quality and\ncharacteristics becomes an important yet understudied question in NMT.\nCurriculum learning methods have been introduced to NMT to optimize a model's\nperformance by prescribing the data input order, based on heuristics such as\nthe assessment of noise and difficulty levels. However, existing methods\nrequire training from scratch, while in practice most NMT models are\npre-trained on big data already. Moreover, as heuristics, they do not\ngeneralize well. In this paper, we aim to learn a curriculum for improving a\npre-trained NMT model by re-selecting influential data samples from the\noriginal training set and formulate this task as a reinforcement learning\nproblem. Specifically, we propose a data selection framework based on\nDeterministic Actor-Critic, in which a critic network predicts the expected\nchange of model performance due to a certain sample, while an actor network\nlearns to select the best sample out of a random batch of samples presented to\nit. Experiments on several translation datasets show that our method can\nfurther improve the performance of NMT when original batch training reaches its\nceiling, without using additional new training data, and significantly\noutperforms several strong baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 03:40:44 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhao", "Mingjun", ""], ["Wu", "Haijiang", ""], ["Niu", "Di", ""], ["Wang", "Xiaoli", ""]]}, {"id": "2004.05758", "submitter": "Jong Chul Ye", "authors": "Yujin Oh, Sangjoon Park, Jong Chul Ye", "title": "Deep Learning COVID-19 Features on CXR using Limited Training Data Sets", "comments": "Accepted for IEEE Trans. on Medical Imaging Special Issue on\n  Imaging-based Diagnosis of COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the global pandemic of COVID-19, the use of artificial intelligence to\nanalyze chest X-ray (CXR) image for COVID-19 diagnosis and patient triage is\nbecoming important. Unfortunately, due to the emergent nature of the COVID-19\npandemic, a systematic collection of the CXR data set for deep neural network\ntraining is difficult. To address this problem, here we propose a patch-based\nconvolutional neural network approach with a relatively small number of\ntrainable parameters for COVID-19 diagnosis. The proposed method is inspired by\nour statistical analysis of the potential imaging biomarkers of the CXR\nradiographs. Experimental results show that our method achieves\nstate-of-the-art performance and provides clinically interpretable saliency\nmaps, which are useful for COVID-19 diagnosis and patient triage.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 03:44:42 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 16:07:25 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Oh", "Yujin", ""], ["Park", "Sangjoon", ""], ["Ye", "Jong Chul", ""]]}, {"id": "2004.05768", "submitter": "Kun Wang", "authors": "Kun Wang, Jun He, Lei Zhang", "title": "Sequential Weakly Labeled Multi-Activity Localization and Recognition on\n  Wearable Sensors using Recurrent Attention Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity and development of the wearable devices such as\nsmartphones, human activity recognition (HAR) based on sensors has become as a\nkey research area in human computer interaction and ubiquitous computing. The\nemergence of deep learning leads to a recent shift in the research of HAR,\nwhich requires massive strictly labeled data. In comparison with video data,\nactivity data recorded from accelerometer or gyroscope is often more difficult\nto interpret and segment. Recently, several attention mechanisms are proposed\nto handle the weakly labeled human activity data, which do not require accurate\ndata annotation. However, these attention-based models can only handle the\nweakly labeled dataset whose sample includes one target activity, as a result\nit limits efficiency and practicality. In the paper, we propose a recurrent\nattention networks (RAN) to handle sequential weakly labeled multi-activity\nrecognition and location tasks. The model can repeatedly perform steps of\nattention on multiple activities of one sample and each step is corresponding\nto the current focused activity. The effectiveness of the RAN model is\nvalidated on a collected sequential weakly labeled multi-activity dataset and\nthe other two public datasets. The experiment results show that our RAN model\ncan simultaneously infer multi-activity types from the coarse-grained\nsequential weak labels and determine specific locations of every target\nactivity with only knowledge of which types of activities contained in the long\nsequence. It will greatly reduce the burden of manual labeling.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 04:57:09 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 13:37:59 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Kun", ""], ["He", "Jun", ""], ["Zhang", "Lei", ""]]}, {"id": "2004.05773", "submitter": "Isabelle Augenstein", "authors": "Pepa Atanasova and Jakob Grue Simonsen and Christina Lioma and\n  Isabelle Augenstein", "title": "Generating Fact Checking Explanations", "comments": "In Proceedings of the 2020 Annual Conference of the Association for\n  Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing work on automated fact checking is concerned with predicting\nthe veracity of claims based on metadata, social network spread, language used\nin claims, and, more recently, evidence supporting or denying claims. A crucial\npiece of the puzzle that is still missing is to understand how to automate the\nmost elaborate part of the process -- generating justifications for verdicts on\nclaims. This paper provides the first study of how these explanations can be\ngenerated automatically based on available claim context, and how this task can\nbe modelled jointly with veracity prediction. Our results indicate that\noptimising both objectives at the same time, rather than training them\nseparately, improves the performance of a fact checking system. The results of\na manual evaluation further suggest that the informativeness, coverage and\noverall quality of the generated explanations are also improved in the\nmulti-task model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 05:23:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Atanasova", "Pepa", ""], ["Simonsen", "Jakob Grue", ""], ["Lioma", "Christina", ""], ["Augenstein", "Isabelle", ""]]}, {"id": "2004.05774", "submitter": "Qiang Zhou", "authors": "Jingjing Gu, Qiang Zhou, Jingyuan Yang, Yanchi Liu, Fuzhen Zhuang,\n  Yanchao Zhao, and Hui Xiong", "title": "Exploiting Interpretable Patterns for Flow Prediction in Dockless Bike\n  Sharing Systems", "comments": "14 pages, 37 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the traditional dock-based systems, dockless bike-sharing systems are\nmore convenient for users in terms of flexibility. However, the flexibility of\nthese dockless systems comes at the cost of management and operation\ncomplexity. Indeed, the imbalanced and dynamic use of bikes leads to mandatory\nrebalancing operations, which impose a critical need for effective bike traffic\nflow prediction. While efforts have been made in developing traffic flow\nprediction models, existing approaches lack interpretability, and thus have\nlimited value in practical deployment. To this end, we propose an Interpretable\nBike Flow Prediction (IBFP) framework, which can provide effective bike flow\nprediction with interpretable traffic patterns. Specifically, by dividing the\nurban area into regions according to flow density, we first model the\nspatio-temporal bike flows between regions with graph regularized sparse\nrepresentation, where graph Laplacian is used as a smooth operator to preserve\nthe commonalities of the periodic data structure. Then, we extract traffic\npatterns from bike flows using subspace clustering with sparse representation\nto construct interpretable base matrices. Moreover, the bike flows can be\npredicted with the interpretable base matrices and learned parameters. Finally,\nexperimental results on real-world data show the advantages of the IBFP method\nfor flow prediction in dockless bike sharing systems. In addition, the\ninterpretability of our flow pattern exploitation is further illustrated\nthrough a case study where IBFP provides valuable insights into bike flow\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 05:31:50 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gu", "Jingjing", ""], ["Zhou", "Qiang", ""], ["Yang", "Jingyuan", ""], ["Liu", "Yanchi", ""], ["Zhuang", "Fuzhen", ""], ["Zhao", "Yanchao", ""], ["Xiong", "Hui", ""]]}, {"id": "2004.05785", "submitter": "Anjin Liu", "authors": "Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, Guangquan Zhang", "title": "Learning under Concept Drift: A Review", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering 31, no. 12\n  (2018): 2346-2363", "doi": "10.1109/TKDE.2018.2876857", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift describes unforeseeable changes in the underlying distribution\nof streaming data over time. Concept drift research involves the development of\nmethodologies and techniques for drift detection, understanding and adaptation.\nData analysis has revealed that machine learning in a concept drift environment\nwill result in poor learning results if the drift is not addressed. To help\nresearchers identify which research topics are significant and how to apply\nrelated techniques in data analysis tasks, it is necessary that a high quality,\ninstructive review of current research developments and trends in the concept\ndrift field is conducted. In addition, due to the rapid development of concept\ndrift in recent years, the methodologies of learning under concept drift have\nbecome noticeably systematic, unveiling a framework which has not been\nmentioned in literature. This paper reviews over 130 high quality publications\nin concept drift related research areas, analyzes up-to-date developments in\nmethodologies and techniques, and establishes a framework of learning under\nconcept drift including three main components: concept drift detection, concept\ndrift understanding, and concept drift adaptation. This paper lists and\ndiscusses 10 popular synthetic datasets and 14 publicly available benchmark\ndatasets used for evaluating the performance of learning algorithms aiming at\nhandling concept drift. Also, concept drift related research directions are\ncovered and discussed. By providing state-of-the-art knowledge, this survey\nwill directly support researchers in their understanding of research\ndevelopments in the field of learning under concept drift.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 06:29:56 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lu", "Jie", ""], ["Liu", "Anjin", ""], ["Dong", "Fan", ""], ["Gu", "Feng", ""], ["Gama", "Joao", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.05793", "submitter": "Yiqun Liu", "authors": "Yiqun Liu, Shouzhen Chen, Lei Chen, Hai Chu, Xiaoyang Xu, Junping\n  Zhang, Leiming Ma", "title": "STAS: Adaptive Selecting Spatio-Temporal Deep Features for Improving\n  Bias Correction on Precipitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical Weather Prediction (NWP) can reduce human suffering by predicting\ndisastrous precipitation in time. A commonly-used NWP in the world is the\nEuropean Centre for medium-range weather forecasts (EC). However, it is\nnecessary to correct EC forecast through Bias Correcting on Precipitation\n(BCoP) since we still have not fully understood the mechanism of precipitation,\nmaking EC often have some biases. The existing BCoPs suffers from limited prior\ndata and the fixed Spatio-Temporal (ST) scale. We thus propose an end-to-end\ndeep-learning BCoP model named Spatio-Temporal feature Auto-Selective (STAS)\nmodel to select optimal ST regularity from EC via the ST Feature-selective\nMechanisms (SFM/TFM). Given different input features, these two mechanisms can\nautomatically adjust the spatial and temporal scales for correcting.\nExperiments on an EC public dataset indicate that compared with 8 published\nBCoP methods, STAS shows state-of-the-art performance on several criteria of\nBCoP, named threat scores (TS). Further, ablation studies justify that the\nSFM/TFM indeed work well in boosting the performance of BCoP, especially on the\nheavy precipitation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:00:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Yiqun", ""], ["Chen", "Shouzhen", ""], ["Chen", "Lei", ""], ["Chu", "Hai", ""], ["Xu", "Xiaoyang", ""], ["Zhang", "Junping", ""], ["Ma", "Leiming", ""]]}, {"id": "2004.05795", "submitter": "Zhaowei Cai", "authors": "Zhaowei Cai and Nuno Vasconcelos", "title": "Rethinking Differentiable Search for Mixed-Precision Neural Networks", "comments": "accepted by CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision networks, with weights and activations quantized to low\nbit-width, are widely used to accelerate inference on edge devices. However,\ncurrent solutions are uniform, using identical bit-width for all filters. This\nfails to account for the different sensitivities of different filters and is\nsuboptimal. Mixed-precision networks address this problem, by tuning the\nbit-width to individual filter requirements. In this work, the problem of\noptimal mixed-precision network search (MPS) is considered. To circumvent its\ndifficulties of discrete search space and combinatorial optimization, a new\ndifferentiable search architecture is proposed, with several novel\ncontributions to advance the efficiency by leveraging the unique properties of\nthe MPS problem. The resulting Efficient differentiable MIxed-Precision network\nSearch (EdMIPS) method is effective at finding the optimal bit allocation for\nmultiple popular networks, and can search a large model, e.g. Inception-V3,\ndirectly on ImageNet without proxy task in a reasonable amount of time. The\nlearned mixed-precision networks significantly outperform their uniform\ncounterparts.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:02:23 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cai", "Zhaowei", ""], ["Vasconcelos", "Nuno", ""]]}, {"id": "2004.05801", "submitter": "Chinnadhurai Sankar", "authors": "Chinnadhurai Sankar, Sujith Ravi, Zornitsa Kozareva", "title": "ProFormer: Towards On-Device LSH Projection Based Transformers", "comments": "EACL 2021 - BEST PAPER AWARD, Honorable Mention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the heart of text based neural models lay word representations, which are\npowerful but occupy a lot of memory making it challenging to deploy to devices\nwith memory constraints such as mobile phones, watches and IoT. To surmount\nthese challenges, we introduce ProFormer -- a projection based transformer\narchitecture that is faster and lighter making it suitable to deploy to memory\nconstraint devices and preserve user privacy. We use LSH projection layer to\ndynamically generate word representations on-the-fly without embedding lookup\ntables leading to significant memory footprint reduction from O(V.d) to O(T),\nwhere V is the vocabulary size, d is the embedding dimension size and T is the\ndimension of the LSH projection representation.\n  We also propose a local projection attention (LPA) layer, which uses\nself-attention to transform the input sequence of N LSH word projections into a\nsequence of N/K representations reducing the computations quadratically by\nO(K^2). We evaluate ProFormer on multiple text classification tasks and\nobserved improvements over prior state-of-the-art on-device approaches for\nshort text classification and comparable performance for long text\nclassification tasks. In comparison with a 2-layer BERT model, ProFormer\nreduced the embedding memory footprint from 92.16 MB to 1.3 KB and requires 16\ntimes less computation overhead, which is very impressive making it the fastest\nand smallest on-device model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:31:31 GMT"}, {"version": "v2", "created": "Sat, 24 Apr 2021 00:27:50 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Sankar", "Chinnadhurai", ""], ["Ravi", "Sujith", ""], ["Kozareva", "Zornitsa", ""]]}, {"id": "2004.05803", "submitter": "Dongjun Kim", "authors": "Dongjun Kim, Weonyoung Joo, Seungjae Shin, Kyungwoo Song, Il-Chul Moon", "title": "Adversarial Likelihood-Free Inference on Black-Box Generator", "comments": "10 pages for the main paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) can be viewed as an implicit estimator\nof a data distribution, and this perspective motivates using the adversarial\nconcept in the true input parameter estimation of black-box generators. While\nprevious works on likelihood-free inference introduces an implicit proposal\ndistribution on the generator input, this paper analyzes theoretic limitations\nof the proposal distribution approach. On top of that, we introduce a new\nalgorithm, Adversarial Likelihood-Free Inference (ALFI), to mitigate the\nanalyzed limitations, so ALFI is able to find the posterior distribution on the\ninput parameter for black-box generative models. We experimented ALFI with\ndiverse simulation models as well as pre-trained statistical models, and we\nidentified that ALFI achieves the best parameter estimation accuracy with a\nlimited simulation budget.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:37:56 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:50:27 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kim", "Dongjun", ""], ["Joo", "Weonyoung", ""], ["Shin", "Seungjae", ""], ["Song", "Kyungwoo", ""], ["Moon", "Il-Chul", ""]]}, {"id": "2004.05810", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Diverse Instances-Weighting Ensemble based on Region Drift Disagreement\n  for Concept Drift Adaptation", "comments": "in IEEE Transactions on Neural Networks and Learning Systems, 2020", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2978523", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept drift refers to changes in the distribution of underlying data and is\nan inherent property of evolving data streams. Ensemble learning, with dynamic\nclassifiers, has proved to be an efficient method of handling concept drift.\nHowever, the best way to create and maintain ensemble diversity with evolving\nstreams is still a challenging problem. In contrast to estimating diversity via\ninputs, outputs, or classifier parameters, we propose a diversity measurement\nbased on whether the ensemble members agree on the probability of a regional\ndistribution change. In our method, estimations over regional distribution\nchanges are used as instance weights. Constructing different region sets\nthrough different schemes will lead to different drift estimation results,\nthereby creating diversity. The classifiers that disagree the most are selected\nto maximize diversity. Accordingly, an instance-based ensemble learning\nalgorithm, called the diverse instance weighting ensemble (DiwE), is developed\nto address concept drift for data stream classification problems. Evaluations\nof various synthetic and real-world data stream benchmarks show the\neffectiveness and advantages of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:59:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.05811", "submitter": "Prithvi Suresh", "authors": "Gokul H., Prithvi Suresh, Hari Vignesh B, Pravin Kumaar R, Vineeth\n  Vijayaraghavan", "title": "Gait Recovery System for Parkinson's Disease using Machine Learning on\n  Embedded Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Freezing of Gait (FoG) is a common gait deficit among patients diagnosed with\nParkinson's Disease (PD). In order to help these patients recover from FoG\nepisodes, Rhythmic Auditory Stimulation (RAS) is needed. The authors propose a\nubiquitous embedded system that detects FOG events with a Machine Learning (ML)\nsubsystem from accelerometer signals . By making inferences on-device, we avoid\nissues prevalent in cloud-based systems such as latency and network connection\ndependency. The resource-efficient classifier used, reduces the model size\nrequirements by approximately 400 times compared to the best performing\nstandard ML systems, with a trade-off of a mere 1.3% in best classification\naccuracy. The aforementioned trade-off facilitates deployability in a wide\nrange of embedded devices including microcontroller based systems. The research\nalso explores the optimization procedure to deploy the model on an ATMega2560\nmicrocontroller with a minimum system latency of 44.5 ms. The smallest model\nsize of the proposed resource efficient ML model was 1.4 KB with an average\nrecall score of 93.58%.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:03:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["H.", "Gokul", ""], ["Suresh", "Prithvi", ""], ["B", "Hari Vignesh", ""], ["R", "Pravin Kumaar", ""], ["Vijayaraghavan", "Vineeth", ""]]}, {"id": "2004.05812", "submitter": "Shuangyong Song", "authors": "Shuangyong Song, Chao Wang, Qianqian Xie, Xinxing Zu, Huan Chen,\n  Haiqing Chen", "title": "MLR: A Two-stage Conversational Query Rewriting Model with Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational context understanding aims to recognize the real intention of\nuser from the conversation history, which is critical for building the dialogue\nsystem. However, the multi-turn conversation understanding in open domain is\nstill quite challenging, which requires the system extracting the important\ninformation and resolving the dependencies in contexts among a variety of open\ntopics. In this paper, we propose the conversational query rewriting model -\nMLR, which is a Multi-task model on sequence Labeling and query Rewriting. MLR\nreformulates the multi-turn conversational queries into a single turn query,\nwhich conveys the true intention of users concisely and alleviates the\ndifficulty of the multi-turn dialogue modeling. In the model, we formulate the\nquery rewriting as a sequence generation problem and introduce word category\ninformation via the auxiliary word category label predicting task. To train our\nmodel, we construct a new Chinese query rewriting dataset and conduct\nexperiments on it. The experimental results show that our model outperforms\ncompared models, and prove the effectiveness of the word category information\nin improving the rewriting performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:04:49 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Song", "Shuangyong", ""], ["Wang", "Chao", ""], ["Xie", "Qianqian", ""], ["Zu", "Xinxing", ""], ["Chen", "Huan", ""], ["Chen", "Haiqing", ""]]}, {"id": "2004.05813", "submitter": "Somnath Chakraborty", "authors": "Somnath Chakraborty, Hariharan Narayanan", "title": "Learning Mixtures of Spherical Gaussians via Fourier Analysis", "comments": "A few omissions are taken care of, and some more references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that we are given independent, identically distributed samples $x_l$\nfrom a mixture $\\mu$ of no more than $k$ of $d$-dimensional spherical gaussian\ndistributions $\\mu_i$ with variance $1$, such that the minimum $\\ell_2$\ndistance between two distinct centers $y_l$ and $y_j$ is greater than $\\sqrt{d}\n\\Delta$ for some $c \\leq \\Delta $, where $c\\in (0,1)$ is a small positive\nuniversal constant. We develop a randomized algorithm that learns the centers\n$y_l$ of the gaussians, to within an $\\ell_2$ distance of $\\delta <\n\\frac{\\Delta\\sqrt{d}}{2}$ and the weights $w_l$ to within $cw_{min}$ with\nprobability greater than $1 - \\exp(-k/c)$. The number of samples and the\ncomputational time is bounded above by $poly(k, d, \\frac{1}{\\delta})$. Such a\nbound on the sample and computational complexity was previously unknown when\n$\\omega(1) \\leq d \\leq O(\\log k)$. When $d = O(1)$, this follows from work of\nRegev and Vijayaraghavan. These authors also show that the sample complexity of\nlearning a random mixture of gaussians in a ball of radius $\\Theta(\\sqrt{d})$\nin $d$ dimensions, when $d$ is $\\Theta( \\log k)$ is at least $poly(k,\n\\frac{1}{\\delta})$, showing that our result is tight in this case.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:06:29 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 09:08:11 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Chakraborty", "Somnath", ""], ["Narayanan", "Hariharan", ""]]}, {"id": "2004.05821", "submitter": "Robert McCraith", "authors": "Robert McCraith, Lukas Neumann, Andrew Zisserman, Andrea Vedaldi", "title": "Monocular Depth Estimation with Self-supervised Instance Adaptation", "comments": "IROS submission, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in self-supervised learning havedemonstrated that it is\npossible to learn accurate monoculardepth reconstruction from raw video data,\nwithout using any 3Dground truth for supervision. However, in robotics\napplications,multiple views of a scene may or may not be available, depend-ing\non the actions of the robot, switching between monocularand multi-view\nreconstruction. To address this mixed setting,we proposed a new approach that\nextends any off-the-shelfself-supervised monocular depth reconstruction system\nto usemore than one image at test time. Our method builds on astandard prior\nlearned to perform monocular reconstruction,but uses self-supervision at test\ntime to further improve thereconstruction accuracy when multiple images are\navailable.When used to update the correct components of the model, thisapproach\nis highly-effective. On the standard KITTI bench-mark, our self-supervised\nmethod consistently outperformsall the previous methods with an average 25%\nreduction inabsolute error for the three common setups (monocular, stereoand\nmonocular+stereo), and comes very close in accuracy whencompared to the\nfully-supervised state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:32:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["McCraith", "Robert", ""], ["Neumann", "Lukas", ""], ["Zisserman", "Andrew", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "2004.05824", "submitter": "Lotta Meijerink", "authors": "Lotta Meijerink, Giovanni Cin\\`a, Michele Tonutti (Pacmed)", "title": "Uncertainty estimation for classification and risk prediction on medical\n  tabular data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a data-scarce field such as healthcare, where models often deliver\npredictions on patients with rare conditions, the ability to measure the\nuncertainty of a model's prediction could potentially lead to improved\neffectiveness of decision support tools and increased user trust. This work\nadvances the understanding of uncertainty estimation for classification and\nrisk prediction on medical tabular data, in a two-fold way. First, we expand\nand refine the set of heuristics to select an uncertainty estimation technique,\nintroducing tests for clinically-relevant scenarios such as generalization to\nuncommon pathologies, changes in clinical protocol and simulations of corrupted\ndata. We furthermore differentiate these heuristics depending on the clinical\nuse-case. Second, we observe that ensembles and related techniques perform\npoorly when it comes to detecting out-of-domain examples, a critical task which\nis carried out more successfully by auto-encoders. These remarks are enriched\nby considerations of the interplay of uncertainty estimation with class\nimbalance, post-modeling calibration and other modeling procedures. Our\nfindings are supported by an array of experiments on toy and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 08:46:41 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 08:25:08 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Meijerink", "Lotta", "", "Pacmed"], ["Cin\u00e0", "Giovanni", "", "Pacmed"], ["Tonutti", "Michele", "", "Pacmed"]]}, {"id": "2004.05827", "submitter": "Shuyang Gao", "authors": "Shuyang Gao, Sanchit Agarwal, Tagyoung Chung, Di Jin, Dilek\n  Hakkani-Tur", "title": "From Machine Reading Comprehension to Dialogue State Tracking: Bridging\n  the Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking (DST) is at the heart of task-oriented dialogue\nsystems. However, the scarcity of labeled data is an obstacle to building\naccurate and robust state tracking systems that work across a variety of\ndomains. Existing approaches generally require some dialogue data with state\ninformation and their ability to generalize to unknown domains is limited. In\nthis paper, we propose using machine reading comprehension (RC) in state\ntracking from two perspectives: model architectures and datasets. We divide the\nslot types in dialogue state into categorical or extractive to borrow the\nadvantages from both multiple-choice and span-based reading comprehension\nmodels. Our method achieves near the current state-of-the-art in joint goal\naccuracy on MultiWOZ 2.1 given full training data. More importantly, by\nleveraging machine reading comprehension datasets, our method outperforms the\nexisting approaches by many a large margin in few-shot scenarios when the\navailability of in-domain data is limited. Lastly, even without any state\ntracking data, i.e., zero-shot scenario, our proposed approach achieves greater\nthan 90% average slot accuracy in 12 out of 30 slots in MultiWOZ 2.1.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:00:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gao", "Shuyang", ""], ["Agarwal", "Sanchit", ""], ["Chung", "Tagyoung", ""], ["Jin", "Di", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "2004.05828", "submitter": "Ziqing Ma", "authors": "Ziqing Ma and Shuming Liu and Guancheng Guo and Xipeng Yu", "title": "Hybrid Attention Networks for Flow and Pressure Forecasting in Water\n  Distribution Systems", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate geo-sensory time series prediction is challenging because of the\ncomplex spatial and temporal correlation. In urban water distribution systems\n(WDS), numerous spatial-correlated sensors have been deployed to continuously\ncollect hydraulic data. Forecasts of monitored flow and pressure time series\nare of vital importance for operational decision making, alerts and anomaly\ndetection. To address this issue, we proposed a hybrid dual-stage\nspatial-temporal attention-based recurrent neural networks (hDS-RNN). Our model\nconsists of two stages: a spatial attention-based encoder and a temporal\nattention-based decoder. Specifically, a hybrid spatial attention mechanism\nthat employs inputs along temporal and spatial axes is proposed. Experiments on\na real-world dataset are conducted and demonstrate that our model outperformed\n9 baseline models in flow and pressure series prediction in WDS.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:00:26 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 03:48:28 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ma", "Ziqing", ""], ["Liu", "Shuming", ""], ["Guo", "Guancheng", ""], ["Yu", "Xipeng", ""]]}, {"id": "2004.05830", "submitter": "Hyeong-Seok Choi", "authors": "Hyeong-Seok Choi, Changdae Park, Kyogu Lee", "title": "From Inference to Generation: End-to-end Fully Self-supervised\n  Generation of Human Face from Speech", "comments": "18 pages, 12 figures, Published as a conference paper at\n  International Conference on Learning Representations (ICLR) 2020.\n  (camera-ready version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work seeks the possibility of generating the human face from voice\nsolely based on the audio-visual data without any human-labeled annotations. To\nthis end, we propose a multi-modal learning framework that links the inference\nstage and generation stage. First, the inference networks are trained to match\nthe speaker identity between the two different modalities. Then the trained\ninference networks cooperate with the generation network by giving conditional\ninformation about the voice. The proposed method exploits the recent\ndevelopment of GANs techniques and generates the human face directly from the\nspeech waveform making our system fully end-to-end. We analyze the extent to\nwhich the network can naturally disentangle two latent factors that contribute\nto the generation of a face image - one that comes directly from a speech\nsignal and the other that is not related to it - and explore whether the\nnetwork can learn to generate natural human face image distribution by modeling\nthese factors. Experimental results show that the proposed network can not only\nmatch the relationship between the human face and speech, but can also generate\nthe high-quality human face sample conditioned on its speech. Finally, the\ncorrelation between the generated face and the corresponding speech is\nquantitatively measured to analyze the relationship between the two modalities.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:01:49 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Choi", "Hyeong-Seok", ""], ["Park", "Changdae", ""], ["Lee", "Kyogu", ""]]}, {"id": "2004.05835", "submitter": "Rodolfo Miranda  Pereira", "authors": "Rodolfo M. Pereira, Diego Bertolini, Lucas O. Teixeira, Carlos N.\n  Silla Jr., and Yandre M. G. Costa", "title": "COVID-19 identification in chest X-ray images on flat and hierarchical\n  classification scenarios", "comments": "Accepted for publication in the Computer Methods and Programs in\n  Biomedicine Journal", "journal-ref": null, "doi": "10.1016/j.cmpb.2020.105532", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 can cause severe pneumonia and is estimated to have a high\nimpact on the healthcare system. The standard image diagnosis tests for\npneumonia are chest X-ray (CXR) and computed tomography (CT) scan. CXR are\nuseful in because it is cheaper, faster and more widespread than CT. This study\naims to identify pneumonia caused by COVID-19 from other types and also healthy\nlungs using only CXR images. In order to achieve the objectives, we have\nproposed a classification schema considering the multi-class and hierarchical\nperspectives, since pneumonia can be structured as a hierarchy. Given the\nnatural data imbalance in this domain, we also proposed the use of resampling\nalgorithms in order to re-balance the classes distribution. Our classification\nschema extract features using some well-known texture descriptors and also\nusing a pre-trained CNN model. We also explored early and late fusion\ntechniques in order to leverage the strength of multiple texture descriptors\nand base classifiers at once. To evaluate the approach, we composed a database,\nnamed RYDLS-20, containing CXR images of pneumonia caused by different\npathogens as well as CXR images of healthy lungs. The classes distribution\nfollows a real-world scenario in which some pathogens are more common than\nothers. The proposed approach achieved a macro-avg F1-Score of 0.65 using a\nmulti-class approach and a F1-Score of 0.89 for the COVID-19 identification in\nthe hierarchical classification scenario. As far as we know, we achieved the\nbest nominal rate obtained for COVID-19 identification in an unbalanced\nenvironment with more than three classes. We must also highlight the novel\nproposed hierarchical classification approach for this task, which considers\nthe types of pneumonia caused by the different pathogens and lead us to the\nbest COVID-19 recognition rate obtained here.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:22:32 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 21:46:17 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 14:15:00 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Pereira", "Rodolfo M.", ""], ["Bertolini", "Diego", ""], ["Teixeira", "Lucas O.", ""], ["Silla", "Carlos N.", "Jr."], ["Costa", "Yandre M. G.", ""]]}, {"id": "2004.05839", "submitter": "Simone Garatti", "authors": "Marco C. Campi and Simone Garatti", "title": "Scenario optimization with relaxation: a new tool for design and\n  application to machine learning problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario optimization is by now a well established technique to perform\ndesigns in the presence of uncertainty. It relies on domain knowledge\nintegrated with first-hand information that comes from data and generates\nsolutions that are also accompanied by precise statements of reliability. In\nthis paper, following recent developments in (Garatti and Campi, 2019), we\nventure beyond the traditional set-up of scenario optimization by analyzing the\nconcept of constraints relaxation. By a solid theoretical underpinning, this\nnew paradigm furnishes fundamental tools to perform designs that meet a proper\ncompromise between robustness and performance. After suitably expanding the\nscope of constraints relaxation as proposed in (Garatti and Campi, 2019), we\nfocus on various classical Support Vector methods in machine learning -\nincluding SVM (Support Vector Machine), SVR (Support Vector Regression) and\nSVDD (Support Vector Data Description) - and derive new results for the ability\nof these methods to generalize.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:38:25 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 10:34:10 GMT"}, {"version": "v3", "created": "Tue, 20 Oct 2020 19:26:04 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Campi", "Marco C.", ""], ["Garatti", "Simone", ""]]}, {"id": "2004.05843", "submitter": "Zhanpeng Yang", "authors": "Kai Yang, Yuanming Shi, Yong Zhou, Zhanpeng Yang, Liqun Fu, and Wei\n  Chen", "title": "Federated Machine Learning for Intelligent IoT via Reconfigurable\n  Intelligent Surface", "comments": "This work has been accepted by the IEEE Network Magazine for\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent Internet-of-Things (IoT) will be transformative with the\nadvancement of artificial intelligence and high-dimensional data analysis,\nshifting from \"connected things\" to \"connected intelligence\". This shall\nunleash the full potential of intelligent IoT in a plethora of exciting\napplications, such as self-driving cars, unmanned aerial vehicles, healthcare,\nrobotics, and supply chain finance. These applications drive the need of\ndeveloping revolutionary computation, communication and artificial intelligence\ntechnologies that can make low-latency decisions with massive real-time data.\nTo this end, federated machine learning, as a disruptive technology, is emerged\nto distill intelligence from the data at network edge, while guaranteeing\ndevice privacy and data security. However, the limited communication bandwidth\nis a key bottleneck of model aggregation for federated machine learning over\nradio channels. In this article, we shall develop an over-the-air computation\nbased communication-efficient federated machine learning framework for\nintelligent IoT networks via exploiting the waveform superposition property of\na multi-access channel. Reconfigurable intelligent surface is further leveraged\nto reduce the model aggregation error via enhancing the signal strength by\nreconfiguring the wireless propagation environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:48:04 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Yang", "Kai", ""], ["Shi", "Yuanming", ""], ["Zhou", "Yong", ""], ["Yang", "Zhanpeng", ""], ["Fu", "Liqun", ""], ["Chen", "Wei", ""]]}, {"id": "2004.05846", "submitter": "Isht Dwivedi", "authors": "Isht Dwivedi, Srikanth Malla, Behzad Dariush, Chiho Choi", "title": "SSP: Single Shot Future Trajectory Prediction", "comments": "Accepted at IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a robust solution to future trajectory forecast, which can be\npractically applicable to autonomous agents in highly crowded environments. For\nthis, three aspects are particularly addressed in this paper. First, we use\ncomposite fields to predict future locations of all road agents in a\nsingle-shot, which results in a constant time complexity, regardless of the\nnumber of agents in the scene. Second, interactions between agents are modeled\nas a non-local response, enabling spatial relationships between different\nlocations to be captured temporally as well (i.e., in spatio-temporal\ninteractions). Third, the semantic context of the scene are modeled and take\ninto account the environmental constraints that potentially influence the\nfuture motion. To this end, we validate the robustness of the proposed approach\nusing the ETH, UCY, and SDD datasets and highlight its practical functionality\ncompared to the current state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:56:38 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 01:37:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Dwivedi", "Isht", ""], ["Malla", "Srikanth", ""], ["Dariush", "Behzad", ""], ["Choi", "Chiho", ""]]}, {"id": "2004.05849", "submitter": "Yanghong Liu", "authors": "Yanghong Liu and Jia Lu and Tingting Li", "title": "MLPSVM:A new parallel support vector machine to multi-label learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning has attracted the attention of the machine learning\ncommunity. The problem conversion method Binary Relevance converts a familiar\nsingle label into a multi-label algorithm. The binary relevance method is\nwidely used because of its simple structure and efficient algorithm. But binary\nrelevance does not consider the links between labels, making it cumbersome to\nhandle some tasks. This paper proposes a multi-label learning algorithm that\ncan also be used for single-label classification. It is based on standard\nsupport vector machines and changes the original single decision hyperplane\ninto two parallel decision hyper-planes, which call multi-label parallel\nsupport vector machine (MLPSVM). At the end of the article, MLPSVM is compared\nwith other multi-label learning algorithms. The experimental results show that\nthe algorithm performs well on data sets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 10:04:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Liu", "Yanghong", ""], ["Lu", "Jia", ""], ["Li", "Tingting", ""]]}, {"id": "2004.05859", "submitter": "Hung-Yu Tseng", "authors": "Hung-Yu Tseng, Yi-Wen Chen, Yi-Hsuan Tsai, Sifei Liu, Yen-Yu Lin,\n  Ming-Hsuan Yang", "title": "Regularizing Meta-Learning via Gradient Dropout", "comments": "Code: https://github.com/hytseng0509/DropGrad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing attention on learning-to-learn new tasks using only a few\nexamples, meta-learning has been widely used in numerous problems such as\nfew-shot classification, reinforcement learning, and domain generalization.\nHowever, meta-learning models are prone to overfitting when there are no\nsufficient training tasks for the meta-learners to generalize. Although\nexisting approaches such as Dropout are widely used to address the overfitting\nproblem, these methods are typically designed for regularizing models of a\nsingle task in supervised training. In this paper, we introduce a simple yet\neffective method to alleviate the risk of overfitting for gradient-based\nmeta-learning. Specifically, during the gradient-based adaptation stage, we\nrandomly drop the gradient in the inner-loop optimization of each parameter in\ndeep neural networks, such that the augmented gradients improve generalization\nto new tasks. We present a general form of the proposed gradient dropout\nregularization and show that this term can be sampled from either the Bernoulli\nor Gaussian distribution. To validate the proposed method, we conduct extensive\nexperiments and analysis on numerous computer vision tasks, demonstrating that\nthe gradient dropout regularization mitigates the overfitting problem and\nimproves the performance upon various gradient-based meta-learning frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 10:47:02 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Tseng", "Hung-Yu", ""], ["Chen", "Yi-Wen", ""], ["Tsai", "Yi-Hsuan", ""], ["Liu", "Sifei", ""], ["Lin", "Yen-Yu", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2004.05865", "submitter": "Tanmoy Chakraborty", "authors": "Viresh Gupta, Aayush Aggarwal, Tanmoy Chakraborty", "title": "Detecting and Characterizing Extremist Reviewer Groups in Online Product\n  Reviews", "comments": "6 figures, 5 tables, Accepted in IEEE Transactions on Computational\n  Social Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online marketplaces often witness opinion spam in the form of reviews. People\nare often hired to target specific brands for promoting or impeding them by\nwriting highly positive or negative reviews. This often is done collectively in\ngroups. Although some previous studies attempted to identify and analyze such\nopinion spam groups, little has been explored to spot those groups who target a\nbrand as a whole, instead of just products.\n  In this paper, we collected reviews from the Amazon product review site and\nmanually labelled a set of 923 candidate reviewer groups. The groups are\nextracted using frequent itemset mining over brand similarities such that users\nare clustered together if they have mutually reviewed (products of) a lot of\nbrands. We hypothesize that the nature of the reviewer groups is dependent on 8\nfeatures specific to a (group, brand) pair. We develop a feature-based\nsupervised model to classify candidate groups as extremist entities. We run\nmultiple classifiers for the task of classifying a group based on the reviews\nwritten by the users of that group, to determine if the group shows signs of\nextremity. A 3-layer Perceptron based classifier turns out to be the best\nclassifier. We further study the behaviours of such groups in detail to\nunderstand the dynamics of brand-level opinion fraud better. These behaviours\ninclude consistency in ratings, review sentiment, verified purchase, review\ndates and helpful votes received on reviews. Surprisingly, we observe that\nthere are a lot of verified reviewers showing extreme sentiment, which on\nfurther investigation leads to ways to circumvent existing mechanisms in place\nto prevent unofficial incentives on Amazon.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 10:59:21 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gupta", "Viresh", ""], ["Aggarwal", "Aayush", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2004.05867", "submitter": "Wei Huang", "authors": "Wei Huang and Weitao Du and Richard Yi Da Xu", "title": "On the Neural Tangent Kernel of Deep Networks with Orthogonal\n  Initialization", "comments": "revised theorems and completed proofs", "journal-ref": "IJCAI 2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevailing thinking is that orthogonal weights are crucial to enforcing\ndynamical isometry and speeding up training. The increase in learning speed\nthat results from orthogonal initialization in linear networks has been\nwell-proven. However, while the same is believed to also hold for nonlinear\nnetworks when the dynamical isometry condition is satisfied, the training\ndynamics behind this contention have not been thoroughly explored. In this\nwork, we study the dynamics of ultra-wide networks across a range of\narchitectures, including Fully Connected Networks (FCNs) and Convolutional\nNeural Networks (CNNs) with orthogonal initialization via neural tangent kernel\n(NTK). Through a series of propositions and lemmas, we prove that two NTKs, one\ncorresponding to Gaussian weights and one to orthogonal weights, are equal when\nthe network width is infinite. Further, during training, the NTK of an\northogonally-initialized infinite-width network should theoretically remain\nconstant. This suggests that the orthogonal initialization cannot speed up\ntraining in the NTK (lazy training) regime, contrary to the prevailing\nthoughts. In order to explore under what circumstances can orthogonality\naccelerate training, we conduct a thorough empirical investigation outside the\nNTK regime. We find that when the hyper-parameters are set to achieve a linear\nregime in nonlinear activation, orthogonal initialization can improve the\nlearning speed with a large learning rate or large depth.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 11:12:53 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:10:55 GMT"}, {"version": "v3", "created": "Sun, 11 Oct 2020 06:06:05 GMT"}, {"version": "v4", "created": "Wed, 21 Jul 2021 08:08:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Huang", "Wei", ""], ["Du", "Weitao", ""], ["Da Xu", "Richard Yi", ""]]}, {"id": "2004.05884", "submitter": "Dongxian Wu", "authors": "Dongxian Wu, Shu-tao Xia, Yisen Wang", "title": "Adversarial Weight Perturbation Helps Robust Generalization", "comments": "To appear in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study on improving the robustness of deep neural networks against\nadversarial examples grows rapidly in recent years. Among them, adversarial\ntraining is the most promising one, which flattens the input loss landscape\n(loss change with respect to input) via training on adversarially perturbed\nexamples. However, how the widely used weight loss landscape (loss change with\nrespect to weight) performs in adversarial training is rarely explored. In this\npaper, we investigate the weight loss landscape from a new perspective, and\nidentify a clear correlation between the flatness of weight loss landscape and\nrobust generalization gap. Several well-recognized adversarial training\nimprovements, such as early stopping, designing new objective functions, or\nleveraging unlabeled data, all implicitly flatten the weight loss landscape.\nBased on these observations, we propose a simple yet effective Adversarial\nWeight Perturbation (AWP) to explicitly regularize the flatness of weight loss\nlandscape, forming a double-perturbation mechanism in the adversarial training\nframework that adversarially perturbs both inputs and weights. Extensive\nexperiments demonstrate that AWP indeed brings flatter weight loss landscape\nand can be easily incorporated into various existing adversarial training\nmethods to further boost their adversarial robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 12:05:01 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 13:46:09 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Wu", "Dongxian", ""], ["Xia", "Shu-tao", ""], ["Wang", "Yisen", ""]]}, {"id": "2004.05898", "submitter": "Yash Akhauri", "authors": "Yash Akhauri", "title": "Exposing Hardware Building Blocks to Machine Learning Frameworks", "comments": "62 pages, 22 figures, 14 tables", "journal-ref": null, "doi": "10.13140/RG.2.2.31661.23527", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are a plethora of applications that demand high throughput and low\nlatency algorithms leveraging machine learning methods. This need for real time\nprocessing can be seen in industries ranging from developing neural network\nbased pre-distortors for enhanced mobile broadband to designing FPGA-based\ntriggers in major scientific efforts by CERN for particle physics. In this\nthesis, we explore how niche domains can benefit vastly if we look at neurons\nas a unique boolean function of the form $f:B^{I} \\rightarrow B^{O}$, where $B\n= \\{0,1\\}$. We focus on how to design topologies that complement such a view of\nneurons, how to automate such a strategy of neural network design, and\ninference of such networks on Xilinx FPGAs. Major hardware borne constraints\narise when designing topologies that view neurons as unique boolean functions.\nFundamentally, realizing such topologies on hardware asserts a strict limit on\nthe 'fan-in' bits of a neuron due to the doubling of permutations possible with\nevery increment in input bit-length. We address this limit by exploring\ndifferent methods of implementing sparsity and explore activation quantization.\nFurther, we develop a library that supports training a neural network with\ncustom sparsity and quantization. This library also supports conversion of\ntrained Sparse Quantized networks from PyTorch to VERILOG code which is then\nsynthesized using Vivado, all of which is part of the LogicNet tool-flow. To\naid faster prototyping, we also support calculation of the worst-case hardware\ncost of any given topology. We hope that our insights into the behavior of\nextremely sparse quantized neural networks are of use to the research community\nand by extension allow people to use the LogicNet design flow to deploy highly\nefficient neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 14:26:00 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Akhauri", "Yash", ""]]}, {"id": "2004.05909", "submitter": "Tao Zhang", "authors": "Tao Zhang, Wei Li", "title": "k-decay: A New Method For Learning Rate Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that optimizing the learning rate (LR) schedule can be\na very accurate and efficient way to train the deep neural networks. In this\npaper, we propose the k-decay method, in which the rate of change (ROC) of the\nLR is changed by its k-th order derivative, to obtain the new LR schedule. In\nthe new LR schedule, a new hyper-parameter $k$ controls the change degree of\nLR, whereas the original method of $k$ at 1. By repeatedly using the k-decay\nmethod, one can identify the best LR schedule. We evaluate the k-decay method\non CIFAR And ImageNet datasets with different neural networks (ResNet, Wide\nResNet, and DenseNet). Our experiments show that the k-decay method can achieve\nimprovements over the state-of-the-art results on most of them. The accuracy\nimproved by 1.08% on the CIFAR-10 dataset, and by 2.07% on the CIFAR-100\ndataset. On the ImageNet, accuracy improved by 1.25%. Our method is not only\nefficient but also easy to use.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 12:58:45 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 06:47:54 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 13:03:36 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 10:17:13 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Zhang", "Tao", ""], ["Li", "Wei", ""]]}, {"id": "2004.05910", "submitter": "Xueshuang Xiang", "authors": "Meiyu Huang, Xueshuang Xiang, Yao Xu", "title": "Training few-shot classification via the perspective of minibatch and\n  pretraining", "comments": "arXiv admin note: text overlap with arXiv:1803.00676 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot classification is a challenging task which aims to formulate the\nability of humans to learn concepts from limited prior data and has drawn\nconsiderable attention in machine learning. Recent progress in few-shot\nclassification has featured meta-learning, in which a parameterized model for a\nlearning algorithm is defined and trained to learn the ability of handling\nclassification tasks on extremely large or infinite episodes representing\ndifferent classification task, each with a small labeled support set and its\ncorresponding query set. In this work, we advance this few-shot classification\nparadigm by formulating it as a supervised classification learning problem. We\nfurther propose multi-episode and cross-way training techniques, which\nrespectively correspond to the minibatch and pretraining in classification\nproblems. Experimental results on a state-of-the-art few-shot classification\nmethod (prototypical networks) demonstrate that both the proposed training\nstrategies can highly accelerate the training process without accuracy loss for\nvarying few-shot classification problems on Omniglot and miniImageNet.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 03:14:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Huang", "Meiyu", ""], ["Xiang", "Xueshuang", ""], ["Xu", "Yao", ""]]}, {"id": "2004.05912", "submitter": "Xueshuang Xiang", "authors": "Xuejiao Liu, Yao Xu, Xueshuang Xiang", "title": "Towards GANs' Approximation Ability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have attracted intense interest in the\nfield of generative models. However, few investigations focusing either on the\ntheoretical analysis or on algorithm design for the approximation ability of\nthe generator of GANs have been reported. This paper will first theoretically\nanalyze GANs' approximation property. Similar to the universal approximation\nproperty of the fully connected neural networks with one hidden layer, we prove\nthat the generator with the input latent variable in GANs can universally\napproximate the potential data distribution given the increasing hidden\nneurons. Furthermore, we propose an approach named stochastic data generation\n(SDG) to enhance GANs'approximation ability. Our approach is based on the\nsimple idea of imposing randomness through data generation in GANs by a prior\ndistribution on the conditional probability between the layers. SDG approach\ncan be easily implemented by using the reparameterization trick. The\nexperimental results on synthetic dataset verify the improved approximation\nability obtained by this SDG approach. In the practical dataset, four GANs\nusing SDG can also outperform the corresponding traditional GANs when the model\narchitectures are smaller.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:40:16 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 06:00:08 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Liu", "Xuejiao", ""], ["Xu", "Yao", ""], ["Xiang", "Xueshuang", ""]]}, {"id": "2004.05913", "submitter": "Xueshuang Xiang", "authors": "Haidong Xie, Lixin Qian, Xueshuang Xiang, Naijin Liu", "title": "Blind Adversarial Pruning: Balance Accuracy, Efficiency and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growth of interest in the attack and defense of deep neural\nnetworks, researchers are focusing more on the robustness of applying them to\ndevices with limited memory. Thus, unlike adversarial training, which only\nconsiders the balance between accuracy and robustness, we come to a more\nmeaningful and critical issue, i.e., the balance among accuracy, efficiency and\nrobustness (AER). Recently, some related works focused on this issue, but with\ndifferent observations, and the relations among AER remain unclear. This paper\nfirst investigates the robustness of pruned models with different compression\nratios under the gradual pruning process and concludes that the robustness of\nthe pruned model drastically varies with different pruning processes,\nespecially in response to attacks with large strength. Second, we test the\nperformance of mixing the clean data and adversarial examples (generated with a\nprescribed uniform budget) into the gradual pruning process, called adversarial\npruning, and find the following: the pruned model's robustness exhibits high\nsensitivity to the budget. Furthermore, to better balance the AER, we propose\nan approach called blind adversarial pruning (BAP), which introduces the idea\nof blind adversarial training into the gradual pruning process. The main idea\nis to use a cutoff-scale strategy to adaptively estimate a nonuniform budget to\nmodify the AEs used during pruning, thus ensuring that the strengths of AEs are\ndynamically located within a reasonable range at each pruning step and\nultimately improving the overall AER of the pruned model. The experimental\nresults obtained using BAP for pruning classification models based on several\nbenchmarks demonstrate the competitive performance of this method: the\nrobustness of the model pruned by BAP is more stable among varying pruning\nprocesses, and BAP exhibits better overall AER than adversarial pruning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:27:48 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xie", "Haidong", ""], ["Qian", "Lixin", ""], ["Xiang", "Xueshuang", ""], ["Liu", "Naijin", ""]]}, {"id": "2004.05914", "submitter": "Xueshuang Xiang", "authors": "Haidong Xie, Xueshuang Xiang, Naijin Liu, Bin Dong", "title": "Blind Adversarial Training: Balance Accuracy and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training (AT) aims to improve the robustness of deep learning\nmodels by mixing clean data and adversarial examples (AEs). Most existing AT\napproaches can be grouped into restricted and unrestricted approaches.\nRestricted AT requires a prescribed uniform budget to constrain the magnitude\nof the AE perturbations during training, with the obtained results showing high\nsensitivity to the budget. On the other hand, unrestricted AT uses\nunconstrained AEs, resulting in the use of AEs located beyond the decision\nboundary; these overestimated AEs significantly lower the accuracy on clean\ndata. These limitations mean that the existing AT approaches have difficulty in\nobtaining a comprehensively robust model with high accuracy and robustness when\nconfronting attacks with varying strengths. Considering this problem, this\npaper proposes a novel AT approach named blind adversarial training (BAT) to\nbetter balance the accuracy and robustness. The main idea of this approach is\nto use a cutoff-scale strategy to adaptively estimate a nonuniform budget to\nmodify the AEs used in the training, ensuring that the strengths of the AEs are\ndynamically located in a reasonable range and ultimately improving the overall\nrobustness of the AT model. The experimental results obtained using BAT for\ntraining classification models on several benchmarks demonstrate the\ncompetitive performance of this method.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:16:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xie", "Haidong", ""], ["Xiang", "Xueshuang", ""], ["Liu", "Naijin", ""], ["Dong", "Bin", ""]]}, {"id": "2004.05915", "submitter": "Navid Khoshavi", "authors": "Navid Khoshavi, Connor Broyles, and Yu Bi", "title": "A Survey on Impact of Transient Faults on BNN Inference Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over past years, the philosophy for designing the artificial intelligence\nalgorithms has significantly shifted towards automatically extracting the\ncomposable systems from massive data volumes. This paradigm shift has been\nexpedited by the big data booming which enables us to easily access and analyze\nthe highly large data sets. The most well-known class of big data analysis\ntechniques is called deep learning. These models require significant\ncomputation power and extremely high memory accesses which necessitate the\ndesign of novel approaches to reduce the memory access and improve power\nefficiency while taking into account the development of domain-specific\nhardware accelerators to support the current and future data sizes and model\nstructures.The current trends for designing application-specific integrated\ncircuits barely consider the essential requirement for maintaining the complex\nneural network computation to be resilient in the presence of soft errors. The\nsoft errors might strike either memory storage or combinational logic in the\nhardware accelerator that can affect the architectural behavior such that the\nprecision of the results fall behind the minimum allowable correctness. In this\nstudy, we demonstrate that the impact of soft errors on a customized deep\nlearning algorithm called Binarized Neural Network might cause drastic image\nmisclassification. Our experimental results show that the accuracy of image\nclassifier can drastically drop by 76.70% and 19.25% in lfcW1A1 and cnvW1A1\nnetworks,respectively across CIFAR-10 and MNIST datasets during the fault\ninjection for the worst-case scenarios\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:15:55 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Khoshavi", "Navid", ""], ["Broyles", "Connor", ""], ["Bi", "Yu", ""]]}, {"id": "2004.05916", "submitter": "Damian Pascual", "authors": "Damian Pascual, Gino Brunner and Roger Wattenhofer", "title": "Telling BERT's full story: from Local Attention to Global Aggregation", "comments": "Accepted at EACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take a deep look into the behavior of self-attention heads in the\ntransformer architecture. In light of recent work discouraging the use of\nattention distributions for explaining a model's behavior, we show that\nattention distributions can nevertheless provide insights into the local\nbehavior of attention heads. This way, we propose a distinction between local\npatterns revealed by attention and global patterns that refer back to the\ninput, and analyze BERT from both angles. We use gradient attribution to\nanalyze how the output of an attention attention head depends on the input\ntokens, effectively extending the local attention-based analysis to account for\nthe mixing of information throughout the transformer layers. We find that there\nis a significant discrepancy between attention and attribution distributions,\ncaused by the mixing of context inside the model. We quantify this discrepancy\nand observe that interestingly, there are some patterns that persist across all\nlayers despite the mixing.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 01:36:41 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 21:48:04 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Pascual", "Damian", ""], ["Brunner", "Gino", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2004.05923", "submitter": "Giacomo De Palma", "authors": "Giacomo De Palma, Bobak T. Kiani and Seth Lloyd", "title": "Adversarial Robustness Guarantees for Random Deep Neural Networks", "comments": null, "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139:2522-2534, 2021", "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG math-ph math.MP quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliability of deep learning algorithms is fundamentally challenged by\nthe existence of adversarial examples, which are incorrectly classified inputs\nthat are extremely close to a correctly classified input. We explore the\nproperties of adversarial examples for deep neural networks with random weights\nand biases, and prove that for any $p\\ge1$, the $\\ell^p$ distance of any given\ninput from the classification boundary scales as one over the square root of\nthe dimension of the input times the $\\ell^p$ norm of the input. The results\nare based on the recently proved equivalence between Gaussian processes and\ndeep neural networks in the limit of infinite width of the hidden layers, and\nare validated with experiments on both random deep neural networks and deep\nneural networks trained on the MNIST and CIFAR10 datasets. The results\nconstitute a fundamental advance in the theoretical understanding of\nadversarial examples, and open the way to a thorough theoretical\ncharacterization of the relation between network architecture and robustness to\nadversarial perturbations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:07:26 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 13:53:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["De Palma", "Giacomo", ""], ["Kiani", "Bobak T.", ""], ["Lloyd", "Seth", ""]]}, {"id": "2004.05930", "submitter": "Francesco Conti", "authors": "Francesco Conti", "title": "Technical Report: NEMO DNN Quantization for Deployment Model", "comments": "12 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report aims at defining a formal framework for Deep Neural\nNetwork (DNN) layer-wise quantization, focusing in particular on the problems\nrelated to the final deployment. It also acts as a documentation for the NEMO\n(NEural Minimization for pytOrch) framework. It describes the four DNN\nrepresentations used in NEMO (FullPrecision, FakeQuantized, QuantizedDeployable\nand IntegerDeployable), focusing in particular on a formal definition of the\nlatter two. An important feature of this model, and in particular the\nIntegerDeployable representation, is that it enables DNN inference using purely\nintegers - without resorting to real-valued numbers in any part of the\ncomputation and without relying on an explicit fixed-point numerical\nrepresentation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:23:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Conti", "Francesco", ""]]}, {"id": "2004.05937", "submitter": "Lin Wang", "authors": "Lin Wang and Kuk-Jin Yoon", "title": "Knowledge Distillation and Student-Teacher Learning for Visual\n  Intelligence: A Review and New Outlooks", "comments": "Accepted to IEEE Transactions on Pattern Analysis and Machine\n  Intelligence(TPAMI),2021. Some references are updated in this version", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3055564", "report-no": "https://ieeexplore.ieee.org/document/9340578", "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural models in recent years have been successful in almost every\nfield, including extremely complex problem statements. However, these models\nare huge in size, with millions (and even billions) of parameters, thus\ndemanding more heavy computation power and failing to be deployed on edge\ndevices. Besides, the performance boost is highly dependent on redundant\nlabeled data. To achieve faster speeds and to handle the problems caused by the\nlack of data, knowledge distillation (KD) has been proposed to transfer\ninformation learned from one model to another. KD is often characterized by the\nso-called `Student-Teacher' (S-T) learning framework and has been broadly\napplied in model compression and knowledge transfer. This paper is about KD and\nS-T learning, which are being actively studied in recent years. First, we aim\nto provide explanations of what KD is and how/why it works. Then, we provide a\ncomprehensive survey on the recent progress of KD methods together with S-T\nframeworks typically for vision tasks. In general, we consider some fundamental\nquestions that have been driving this research area and thoroughly generalize\nthe research progress and technical details. Additionally, we systematically\nanalyze the research status of KD in vision applications. Finally, we discuss\nthe potentials and open challenges of existing methods and prospect the future\ndirections of KD and S-T learning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:45:38 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 06:53:08 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 01:27:02 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 13:33:33 GMT"}, {"version": "v5", "created": "Wed, 6 Jan 2021 08:16:08 GMT"}, {"version": "v6", "created": "Mon, 25 Jan 2021 12:37:46 GMT"}, {"version": "v7", "created": "Thu, 17 Jun 2021 07:17:50 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Wang", "Lin", ""], ["Yoon", "Kuk-Jin", ""]]}, {"id": "2004.05940", "submitter": "Ioannis Boukas", "authors": "Ioannis Boukas, Damien Ernst, Thibaut Th\\'eate, Adrien Bolland,\n  Alexandre Huynen, Martin Buchwald, Christelle Wynants, Bertrand Corn\\'elusse", "title": "A Deep Reinforcement Learning Framework for Continuous Intraday Market\n  Bidding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large integration of variable energy resources is expected to shift a\nlarge part of the energy exchanges closer to real-time, where more accurate\nforecasts are available. In this context, the short-term electricity markets\nand in particular the intraday market are considered a suitable trading floor\nfor these exchanges to occur. A key component for the successful renewable\nenergy sources integration is the usage of energy storage. In this paper, we\npropose a novel modelling framework for the strategic participation of energy\nstorage in the European continuous intraday market where exchanges occur\nthrough a centralized order book. The goal of the storage device operator is\nthe maximization of the profits received over the entire trading horizon, while\ntaking into account the operational constraints of the unit. The sequential\ndecision-making problem of trading in the intraday market is modelled as a\nMarkov Decision Process. An asynchronous distributed version of the fitted Q\niteration algorithm is chosen for solving this problem due to its sample\nefficiency. The large and variable number of the existing orders in the order\nbook motivates the use of high-level actions and an alternative state\nrepresentation. Historical data are used for the generation of a large number\nof artificial trajectories in order to address exploration issues during the\nlearning process. The resulting policy is back-tested and compared against a\nbenchmark strategy that is the current industrial standard. Results indicate\nthat the agent converges to a policy that achieves in average higher total\nrevenues than the benchmark strategy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 13:50:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Boukas", "Ioannis", ""], ["Ernst", "Damien", ""], ["Th\u00e9ate", "Thibaut", ""], ["Bolland", "Adrien", ""], ["Huynen", "Alexandre", ""], ["Buchwald", "Martin", ""], ["Wynants", "Christelle", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2004.05958", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Madson L. D. Dias, C\\'esar Lincoln C. Mattos, Ticiana L. C. da Silva,\n  Jos\\'e Ant\\^onio F. de Macedo, Wellington C. P. Silva", "title": "Anomaly Detection in Trajectory Data with Normalizing Flows", "comments": "Accepted as a conference paper at 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020), part of 2020 IEEE World Congress on\n  Computational Intelligence (IEEE WCCI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of detecting anomalous data patterns is as important in practical\napplications as challenging. In the context of spatial data, recognition of\nunexpected trajectories brings additional difficulties, such as high\ndimensionality and varying pattern lengths. We aim to tackle such a problem\nfrom a probability density estimation point of view, since it provides an\nunsupervised procedure to identify out of distribution samples. More\nspecifically, we pursue an approach based on normalizing flows, a recent\nframework that enables complex density estimation from data with neural\nnetworks. Our proposal computes exact model likelihood values, an important\nfeature of normalizing flows, for each segment of the trajectory. Then, we\naggregate the segments' likelihoods into a single coherent trajectory anomaly\nscore. Such a strategy enables handling possibly large sequences with different\nlengths. We evaluate our methodology, named aggregated anomaly detection with\nnormalizing flows (GRADINGS), using real world trajectory data and compare it\nwith more traditional anomaly detection techniques. The promising results\nobtained in the performed computational experiments indicate the feasibility of\nthe GRADINGS, specially the variant that considers autoregressive normalizing\nflows.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 14:16:40 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Dias", "Madson L. D.", ""], ["Mattos", "C\u00e9sar Lincoln C.", ""], ["da Silva", "Ticiana L. C.", ""], ["de Macedo", "Jos\u00e9 Ant\u00f4nio F.", ""], ["Silva", "Wellington C. P.", ""]]}, {"id": "2004.05975", "submitter": "Uri Stemmer", "authors": "Avinatan Hassidim, Haim Kaplan, Yishay Mansour, Yossi Matias, Uri\n  Stemmer", "title": "Adversarially Robust Streaming Algorithms via Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A streaming algorithm is said to be adversarially robust if its accuracy\nguarantees are maintained even when the data stream is chosen maliciously, by\nan adaptive adversary. We establish a connection between adversarial robustness\nof streaming algorithms and the notion of differential privacy. This connection\nallows us to design new adversarially robust streaming algorithms that\noutperform the current state-of-the-art constructions for many interesting\nregimes of parameters.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 14:49:38 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Hassidim", "Avinatan", ""], ["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Matias", "Yossi", ""], ["Stemmer", "Uri", ""]]}, {"id": "2004.05980", "submitter": "Timothy Jeruzalski", "authors": "Timothy Jeruzalski, David I.W. Levin, Alec Jacobson, Paul Lalonde,\n  Mohammad Norouzi, Andrea Tagliasacchi", "title": "NiLBS: Neural Inverse Linear Blend Skinning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we investigate efficient representations of\narticulated objects (e.g. human bodies), which is an important problem in\ncomputer vision and graphics. To deform articulated geometry, existing\napproaches represent objects as meshes and deform them using \"skinning\"\ntechniques. The skinning operation allows a wide range of deformations to be\nachieved with a small number of control parameters. This paper introduces a\nmethod to invert the deformations undergone via traditional skinning techniques\nvia a neural network parameterized by pose. The ability to invert these\ndeformations allows values (e.g., distance function, signed distance function,\noccupancy) to be pre-computed at rest pose, and then efficiently queried when\nthe character is deformed. We leave empirical evaluation of our approach to\nfuture work.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 20:46:37 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Jeruzalski", "Timothy", ""], ["Levin", "David I. W.", ""], ["Jacobson", "Alec", ""], ["Lalonde", "Paul", ""], ["Norouzi", "Mohammad", ""], ["Tagliasacchi", "Andrea", ""]]}, {"id": "2004.05985", "submitter": "Lukasz Augustyniak", "authors": "{\\L}ukasz Augustyniak, Piotr Szymanski, Miko{\\l}aj Morzy, Piotr\n  Zelasko, Adrian Szymczak, Jan Mizgajski, Yishay Carmiel, Najim Dehak", "title": "Punctuation Prediction in Spontaneous Conversations: Can We Mitigate ASR\n  Errors with Retrofitted Word Embeddings?", "comments": "submitted to INTERSPEECH'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Speech Recognition (ASR) systems introduce word errors, which often\nconfuse punctuation prediction models, turning punctuation restoration into a\nchallenging task. These errors usually take the form of homonyms. We show how\nretrofitting of the word embeddings on the domain-specific data can mitigate\nASR errors. Our main contribution is a method for better alignment of homonym\nembeddings and the validation of the presented method on the punctuation\nprediction task. We record the absolute improvement in punctuation prediction\naccuracy between 6.2% (for question marks) to 9% (for periods) when compared\nwith the state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:02:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Augustyniak", "\u0141ukasz", ""], ["Szymanski", "Piotr", ""], ["Morzy", "Miko\u0142aj", ""], ["Zelasko", "Piotr", ""], ["Szymczak", "Adrian", ""], ["Mizgajski", "Jan", ""], ["Carmiel", "Yishay", ""], ["Dehak", "Najim", ""]]}, {"id": "2004.05986", "submitter": "Liang  Xu", "authors": "Liang Xu, Hai Hu, Xuanwei Zhang, Lu Li, Chenjie Cao, Yudong Li, Yechen\n  Xu, Kai Sun, Dian Yu, Cong Yu, Yin Tian, Qianqian Dong, Weitang Liu, Bo Shi,\n  Yiming Cui, Junyi Li, Jun Zeng, Rongzhao Wang, Weijian Xie, Yanting Li, Yina\n  Patterson, Zuoyu Tian, Yiwen Zhang, He Zhou, Shaoweihua Liu, Zhe Zhao, Qipeng\n  Zhao, Cong Yue, Xinrui Zhang, Zhengliang Yang, Kyle Richardson and Zhenzhong\n  Lan", "title": "CLUE: A Chinese Language Understanding Evaluation Benchmark", "comments": "Accepted by COLING2020; 10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The advent of natural language understanding (NLU) benchmarks for English,\nsuch as GLUE and SuperGLUE allows new NLU models to be evaluated across a\ndiverse set of tasks. These comprehensive benchmarks have facilitated a broad\nrange of research and applications in natural language processing (NLP). The\nproblem, however, is that most such benchmarks are limited to English, which\nhas made it difficult to replicate many of the successes in English NLU for\nother languages. To help remedy this issue, we introduce the first large-scale\nChinese Language Understanding Evaluation (CLUE) benchmark. CLUE is an\nopen-ended, community-driven project that brings together 9 tasks spanning\nseveral well-established single-sentence/sentence-pair classification tasks, as\nwell as machine reading comprehension, all on original Chinese text. To\nestablish results on these tasks, we report scores using an exhaustive set of\ncurrent state-of-the-art pre-trained Chinese models (9 in total). We also\nintroduce a number of supplementary datasets and additional tools to help\nfacilitate further progress on Chinese NLU. Our benchmark is released at\nhttps://www.CLUEbenchmarks.com\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:02:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 11:41:07 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 14:46:45 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Xu", "Liang", ""], ["Hu", "Hai", ""], ["Zhang", "Xuanwei", ""], ["Li", "Lu", ""], ["Cao", "Chenjie", ""], ["Li", "Yudong", ""], ["Xu", "Yechen", ""], ["Sun", "Kai", ""], ["Yu", "Dian", ""], ["Yu", "Cong", ""], ["Tian", "Yin", ""], ["Dong", "Qianqian", ""], ["Liu", "Weitang", ""], ["Shi", "Bo", ""], ["Cui", "Yiming", ""], ["Li", "Junyi", ""], ["Zeng", "Jun", ""], ["Wang", "Rongzhao", ""], ["Xie", "Weijian", ""], ["Li", "Yanting", ""], ["Patterson", "Yina", ""], ["Tian", "Zuoyu", ""], ["Zhang", "Yiwen", ""], ["Zhou", "He", ""], ["Liu", "Shaoweihua", ""], ["Zhao", "Zhe", ""], ["Zhao", "Qipeng", ""], ["Yue", "Cong", ""], ["Zhang", "Xinrui", ""], ["Yang", "Zhengliang", ""], ["Richardson", "Kyle", ""], ["Lan", "Zhenzhong", ""]]}, {"id": "2004.05988", "submitter": "Huajie Shao", "authors": "Huajie Shao, Shuochao Yao, Dachun Sun, Aston Zhang, Shengzhong Liu,\n  Dongxin Liu, Jun Wang, Tarek Abdelzaher", "title": "ControlVAE: Controllable Variational Autoencoder", "comments": "accepted by ICML2020", "journal-ref": "37th proceedings of ICML, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoders (VAE) and their variants have been widely used in a\nvariety of applications, such as dialog generation, image generation and\ndisentangled representation learning. However, the existing VAE models have\nsome limitations in different applications. For example, a VAE easily suffers\nfrom KL vanishing in language modeling and low reconstruction quality for\ndisentangling. To address these issues, we propose a novel controllable\nvariational autoencoder framework, ControlVAE, that combines a controller,\ninspired by automatic control theory, with the basic VAE to improve the\nperformance of resulting generative models. Specifically, we design a new\nnon-linear PI controller, a variant of the proportional-integral-derivative\n(PID) control, to automatically tune the hyperparameter (weight) added in the\nVAE objective using the output KL-divergence as feedback during model training.\nThe framework is evaluated using three applications; namely, language modeling,\ndisentangled representation learning, and image generation. The results show\nthat ControlVAE can achieve better disentangling and reconstruction quality\nthan the existing methods. For language modelling, it not only averts the\nKL-vanishing, but also improves the diversity of generated text. Finally, we\nalso demonstrate that ControlVAE improves the reconstruction quality of\ngenerated images compared to the original VAE.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:04:56 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:07:55 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 12:56:11 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 15:59:27 GMT"}, {"version": "v5", "created": "Sat, 20 Jun 2020 20:21:48 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shao", "Huajie", ""], ["Yao", "Shuochao", ""], ["Sun", "Dachun", ""], ["Zhang", "Aston", ""], ["Liu", "Shengzhong", ""], ["Liu", "Dongxin", ""], ["Wang", "Jun", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2004.05989", "submitter": "Bahman Mirheidari", "authors": "Bahman Mirheidari, Yilin Pan, Daniel Blackburn, Ronan O'Malley, Traci\n  Walker, Annalena Venneri, Markus Reuber, Heidi Christensen", "title": "Data augmentation using generative networks to identify dementia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data limitation is one of the most common issues in training machine learning\nclassifiers for medical applications. Due to ethical concerns and data privacy,\nthe number of people that can be recruited to such experiments is generally\nsmaller than the number of participants contributing to non-healthcare\ndatasets. Recent research showed that generative models can be used as an\neffective approach for data augmentation, which can ultimately help to train\nmore robust classifiers sparse data domains. A number of studies proved that\nthis data augmentation technique works for image and audio data sets. In this\npaper, we investigate the application of a similar approach to different types\nof speech and audio-based features extracted from interactions recorded with\nour automatic dementia detection system. Using two generative models we show\nhow the generated synthesized samples can improve the performance of a DNN\nbased classifier. The variational autoencoder increased the F-score of a\nfour-way classifier distinguishing the typical patient groups seen in memory\nclinics from 58% to around 74%, a 16% improvement\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:05:24 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Mirheidari", "Bahman", ""], ["Pan", "Yilin", ""], ["Blackburn", "Daniel", ""], ["O'Malley", "Ronan", ""], ["Walker", "Traci", ""], ["Venneri", "Annalena", ""], ["Reuber", "Markus", ""], ["Christensen", "Heidi", ""]]}, {"id": "2004.05990", "submitter": "Takeyuki Sasai", "authors": "Takeyuki Sasai and Hironori Fujisawa", "title": "Robust estimation with Lasso when outputs are adversarially contaminated", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust estimation when outputs are adversarially contaminated.\nNguyen and Tran (2012) proposed an extended Lasso for robust parameter\nestimation and then they showed the convergence rate of the estimation error.\nRecently, Dalalyan and Thompson (2019) gave some useful inequalities and then\nthey showed a faster convergence rate than Nguyen and Tran (2012). They focused\non the fact that the minimization problem of the extended Lasso can become that\nof the penalized Huber loss function with $L_1$ penalty. The distinguishing\npoint is that the Huber loss function includes an extra tuning parameter, which\nis different from the conventional method. We give the proof, which is\ndifferent from Dalalyan and Thompson (2019) and then we give the same\nconvergence rate as Dalalyan and Thompson (2019). The significance of our proof\nis to use some specific properties of the Huber function. Such techniques have\nnot been used in the past proofs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:06:45 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 17:13:44 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 16:01:45 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 06:22:28 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Sasai", "Takeyuki", ""], ["Fujisawa", "Hironori", ""]]}, {"id": "2004.05991", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, Bamdev Mishra", "title": "A Simple Approach to Learning Unsupervised Multilingual Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress on unsupervised learning of cross-lingual embeddings in\nbilingual setting has given impetus to learning a shared embedding space for\nseveral languages without any supervision. A popular framework to solve the\nlatter problem is to jointly solve the following two sub-problems: 1) learning\nunsupervised word alignment between several pairs of languages, and 2) learning\nhow to map the monolingual embeddings of every language to a shared\nmultilingual space. In contrast, we propose a simple, two-stage framework in\nwhich we decouple the above two sub-problems and solve them separately using\nexisting techniques. The proposed approach obtains surprisingly good\nperformance in various tasks such as bilingual lexicon induction, cross-lingual\nword similarity, multilingual document classification, and multilingual\ndependency parsing. When distant languages are involved, the proposed solution\nillustrates robustness and outperforms existing unsupervised multilingual word\nembedding approaches. Overall, our experimental results encourage development\nof multi-stage models for such challenging problems.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 05:54:10 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 15:17:01 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.05994", "submitter": "Stanis{\\l}aw Purga{\\l}", "authors": "Stanis{\\l}aw Purga{\\l}", "title": "Improving Expressivity of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Graph Neural Network with greater expressive power than commonly\nused GNNs - not constrained to only differentiate between graphs that\nWeisfeiler-Lehman test recognizes to be non-isomorphic. We use a graph\nattention network with expanding attention window that aggregates information\nfrom nodes exponentially far away. We also use partially random initial\nembeddings, allowing differentiation between nodes that would otherwise look\nthe same. This could cause problem with a traditional dropout mechanism,\ntherefore we use a \"head dropout\", randomly ignoring some attention heads\nrather than some dimensions of the embedding.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:24:58 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Purga\u0142", "Stanis\u0142aw", ""]]}, {"id": "2004.06014", "submitter": "Yedid Hoshen", "authors": "Yael Vinker and Nir Zabari and Yedid Hoshen", "title": "Training End-to-end Single Image Generators without GANs", "comments": "Project page: http://www.vision.huji.ac.il/augurone", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AugurOne, a novel approach for training single image generative\nmodels. Our approach trains an upscaling neural network using non-affine\naugmentations of the (single) input image, particularly including non-rigid\nthin plate spline image warps. The extensive augmentations significantly\nincrease the in-sample distribution for the upsampling network enabling the\nupscaling of highly variable inputs. A compact latent space is jointly learned\nallowing for controlled image synthesis. Differently from Single Image GAN, our\napproach does not require GAN training and takes place in an end-to-end fashion\nallowing fast and stable training. We experimentally evaluate our method and\nshow that it obtains compelling novel animations of single-image, as well as,\nstate-of-the-art performance on conditional generation tasks e.g.\npaint-to-image and edges-to-image.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:58:03 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Vinker", "Yael", ""], ["Zabari", "Nir", ""], ["Hoshen", "Yedid", ""]]}, {"id": "2004.06025", "submitter": "Abhijeet Awasthi", "authors": "Abhijeet Awasthi, Sabyasachi Ghosh, Rasna Goyal, Sunita Sarawagi", "title": "Learning from Rules Generalizing Labeled Exemplars", "comments": "ICLR 2020 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications labeled data is not readily available, and needs to be\ncollected via pain-staking human supervision. We propose a rule-exemplar method\nfor collecting human supervision to combine the efficiency of rules with the\nquality of instance labels. The supervision is coupled such that it is both\nnatural for humans and synergistic for learning. We propose a training\nalgorithm that jointly denoises rules via latent coverage variables, and trains\nthe model through a soft implication loss over the coverage and label\nvariables. The denoised rules and trained model are used jointly for inference.\nEmpirical evaluation on five different tasks shows that (1) our algorithm is\nmore accurate than several existing methods of learning from a mix of clean and\nnoisy supervision, and (2) the coupled rule-exemplar supervision is effective\nin denoising rules.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:57:54 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:56:59 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Awasthi", "Abhijeet", ""], ["Ghosh", "Sabyasachi", ""], ["Goyal", "Rasna", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "2004.06030", "submitter": "Yilun Du", "authors": "Yilun Du, Shuang Li, Igor Mordatch", "title": "Compositional Visual Generation and Inference with Energy Based Models", "comments": "NeurIPS 2020 Spotlight; Website at\n  https://energy-based-model.github.io/compositional-generation-inference/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A vital aspect of human intelligence is the ability to compose increasingly\ncomplex concepts out of simpler ideas, enabling both rapid learning and\nadaptation of knowledge. In this paper we show that energy-based models can\nexhibit this ability by directly combining probability distributions. Samples\nfrom the combined distribution correspond to compositions of concepts. For\nexample, given a distribution for smiling faces, and another for male faces, we\ncan combine them to generate smiling male faces. This allows us to generate\nnatural images that simultaneously satisfy conjunctions, disjunctions, and\nnegations of concepts. We evaluate compositional generation abilities of our\nmodel on the CelebA dataset of natural faces and synthetic 3D scene images. We\nalso demonstrate other unique advantages of our model, such as the ability to\ncontinually learn and incorporate new concepts, or infer compositions of\nconcept properties underlying an image.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:01:40 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 22:50:40 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 09:26:00 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Du", "Yilun", ""], ["Li", "Shuang", ""], ["Mordatch", "Igor", ""]]}, {"id": "2004.06037", "submitter": "Ciro Javier Diaz Penedo", "authors": "Ciro Javier Diaz Penedo and Lucas Leonardo Silveira Costa", "title": "Prediction of properties of steel alloys", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study of possible predictors based on four supervised machine\nlearning models for the prediction of four mechanical properties of the main\nindustrially used steels. The results were obtained from an experimental\ndatabase available in the literature which were used as input to train and\nevaluate the models.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 00:45:01 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Penedo", "Ciro Javier Diaz", ""], ["Costa", "Lucas Leonardo Silveira", ""]]}, {"id": "2004.06042", "submitter": "Yawei Luo", "authors": "Yawei Luo, Ping Liu, Tao Guan, Junqing Yu, Yi Yang", "title": "Adversarial Style Mining for One-Shot Unsupervised Domain Adaptation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We aim at the problem named One-Shot Unsupervised Domain Adaptation. Unlike\ntraditional Unsupervised Domain Adaptation, it assumes that only one unlabeled\ntarget sample can be available when learning to adapt. This setting is\nrealistic but more challenging, in which conventional adaptation approaches are\nprone to failure due to the scarce of unlabeled target data. To this end, we\npropose a novel Adversarial Style Mining approach, which combines the style\ntransfer module and task-specific module into an adversarial manner.\nSpecifically, the style transfer module iteratively searches for harder\nstylized images around the one-shot target sample according to the current\nlearning state, leading the task model to explore the potential styles that are\ndifficult to solve in the almost unseen target domain, thus boosting the\nadaptation performance in a data-scarce scenario. The adversarial learning\nframework makes the style transfer module and task-specific module benefit each\nother during the competition. Extensive experiments on both cross-domain\nclassification and segmentation benchmarks verify that ASM achieves\nstate-of-the-art adaptation performance under the challenging one-shot setting.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:18:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Luo", "Yawei", ""], ["Liu", "Ping", ""], ["Guan", "Tao", ""], ["Yu", "Junqing", ""], ["Yang", "Yi", ""]]}, {"id": "2004.06043", "submitter": "Aron Laszka", "authors": "Afiya Ayman, Michael Wilbur, Amutheezan Sivagnanam, Philip Pugliese,\n  Abhishek Dubey, Aron Laszka", "title": "Data-Driven Prediction of Route-Level Energy Use for Mixed-Vehicle\n  Transit Fleets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing concerns about environmental impact, operating costs, and\nenergy security, public transit agencies are seeking to reduce their fuel use\nby employing electric vehicles (EVs). However, because of the high upfront cost\nof EVs, most agencies can afford only mixed fleets of internal-combustion and\nelectric vehicles. Making the best use of these mixed fleets presents a\nchallenge for agencies since optimizing the assignment of vehicles to transit\nroutes, scheduling charging, etc. require accurate predictions of electricity\nand fuel use. Recent advances in sensor-based technologies, data analytics, and\nmachine learning enable remedying this situation; however, to the best of our\nknowledge, there exists no framework that would integrate all relevant data\ninto a route-level prediction model for public transit. In this paper, we\npresent a novel framework for the data-driven prediction of route-level energy\nuse for mixed-vehicle transit fleets, which we evaluate using data collected\nfrom the bus fleet of CARTA, the public transit authority of Chattanooga, TN.\nWe present a data collection and storage framework, which we use to capture\nsystem-level data, including traffic and weather conditions, and high-frequency\nvehicle-level data, including location traces, fuel or electricity use, etc. We\npresent domain-specific methods and algorithms for integrating and cleansing\ndata from various sources, including street and elevation maps. Finally, we\ntrain and evaluate machine learning models, including deep neural networks,\ndecision trees, and linear regression, on our integrated dataset. Our results\nshow that neural networks provide accurate estimates, while other models can\nhelp us discover relations between energy use and factors such as road and\nweather conditions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 16:31:10 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 16:31:34 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ayman", "Afiya", ""], ["Wilbur", "Michael", ""], ["Sivagnanam", "Amutheezan", ""], ["Pugliese", "Philip", ""], ["Dubey", "Abhishek", ""], ["Laszka", "Aron", ""]]}, {"id": "2004.06044", "submitter": "Saeed Khorram", "authors": "Mohamadreza Jafaryani, Saeed Khorram, Vahid Pourahmadi, Minoo Shahbazi", "title": "Sleep Stage Scoring Using Joint Frequency-Temporal and Unsupervised\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with sleep disorders can better manage their lifestyle if they know\nabout their special situations. Detection of such sleep disorders is usually\npossible by analyzing a number of vital signals that have been collected from\nthe patients. To simplify this task, a number of Automatic Sleep Stage\nRecognition (ASSR) methods have been proposed. Most of these methods use\ntemporal-frequency features that have been extracted from the vital signals.\nHowever, due to the non-stationary nature of sleep signals, such schemes are\nnot leading an acceptable accuracy. Recently, some ASSR methods have been\nproposed which use deep neural networks for unsupervised feature extraction. In\nthis paper, we proposed to combine the two ideas and use both\ntemporal-frequency and unsupervised features at the same time. To augment the\ntime resolution, each standard epoch is segmented into 5 sub-epochs.\nAdditionally, to enhance the accuracy, we employ three classifiers with\ndifferent properties and then use an ensemble method as the ultimate\nclassifier. The simulation results show that the proposed method enhances the\naccuracy of conventional ASSR methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 02:00:29 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Jafaryani", "Mohamadreza", ""], ["Khorram", "Saeed", ""], ["Pourahmadi", "Vahid", ""], ["Shahbazi", "Minoo", ""]]}, {"id": "2004.06046", "submitter": "Hamad Ahmed", "authors": "Hamad Ahmed, Ronnie B Wilbur, Hari M Bharadwaj, and Jeffrey Mark\n  Siskind", "title": "Object classification from randomized EEG trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New results suggest strong limits to the feasibility of classifying human\nbrain activity evoked from image stimuli, as measured through EEG. Considerable\nprior work suffers from a confound between the stimulus class and the time\nsince the start of the experiment. A prior attempt to avoid this confound using\nrandomized trials was unable to achieve results above chance in a statistically\nsignificant fashion when the data sets were of the same size as the original\nexperiments. Here, we again attempt to replicate these experiments with\nrandomized trials on a far larger (20x) dataset of 1,000 stimulus presentations\nof each of forty classes, all from a single subject. To our knowledge, this is\nthe largest such EEG data collection effort from a single subject and is at the\nbounds of feasibility. We obtain classification accuracy that is marginally\nabove chance and above chance in a statistically significant fashion, and\nfurther assess how accuracy depends on the classifier used, the amount of\ntraining data used, and the number of classes. Reaching the limits of data\ncollection without substantial improvement in classification accuracy suggests\nlimits to the feasibility of this enterprise.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 22:06:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Ahmed", "Hamad", ""], ["Wilbur", "Ronnie B", ""], ["Bharadwaj", "Hari M", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "2004.06063", "submitter": "Markus Freitag", "authors": "Markus Freitag, David Grangier, Isaac Caswell", "title": "BLEU might be Guilty but References are not Innocent", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of automatic metrics for machine translation has been\nincreasingly called into question, especially for high-quality systems. This\npaper demonstrates that, while choice of metric is important, the nature of the\nreferences is also critical. We study different methods to collect references\nand compare their value in automated evaluation by reporting correlation with\nhuman evaluation for a variety of systems and metrics. Motivated by the finding\nthat typical references exhibit poor diversity, concentrating around\ntranslationese language, we develop a paraphrasing task for linguists to\nperform on existing reference translations, which counteracts this bias. Our\nmethod yields higher correlation with human judgment not only for the\nsubmissions of WMT 2019 English to German, but also for Back-translation and\nAPE augmented MT output, which have been shown to have low correlation with\nautomatic metrics using standard references. We demonstrate that our\nmethodology improves correlation with all modern evaluation metrics we look at,\nincluding embedding-based methods. To complete this picture, we reveal that\nmulti-reference BLEU does not improve the correlation for high quality output,\nand present an alternative multi-reference formulation that is more effective.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:49:09 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 13:02:12 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Freitag", "Markus", ""], ["Grangier", "David", ""], ["Caswell", "Isaac", ""]]}, {"id": "2004.06069", "submitter": "Anthony Bagnall Dr", "authors": "Anthony Bagnall, Michael Flynn, James Large, Jason Lines and Matthew\n  Middlehurst", "title": "A tale of two toolkits, report the third: on the usage and performance\n  of HIVE-COTE v1.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hierarchical Vote Collective of Transformation-based Ensembles\n(HIVE-COTE) is a heterogeneous meta ensemble for time series classification.\nSince it was first proposed in 2016, the algorithm has undergone some minor\nchanges and there is now a configurable, scalable and easy to use version\navailable in two open source repositories. We present an overview of the latest\nstable HIVE-COTE, version 1.0, and describe how it differs to the original. We\nprovide a walkthrough guide of how to use the classifier, and conduct extensive\nexperimental evaluation of its predictive performance and resource usage. We\ncompare the performance of HIVE-COTE to three recently proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:09:48 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 11:17:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bagnall", "Anthony", ""], ["Flynn", "Michael", ""], ["Large", "James", ""], ["Lines", "Jason", ""], ["Middlehurst", "Matthew", ""]]}, {"id": "2004.06076", "submitter": "Adyasha Maharana", "authors": "Adyasha Maharana, Mohit Bansal", "title": "Adversarial Augmentation Policy Search for Domain and Cross-Lingual\n  Generalization in Reading Comprehension", "comments": "Findings of EMNLP, 2020 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension models often overfit to nuances of training datasets\nand fail at adversarial evaluation. Training with adversarially augmented\ndataset improves robustness against those adversarial attacks but hurts\ngeneralization of the models. In this work, we present several effective\nadversaries and automated data augmentation policy search methods with the goal\nof making reading comprehension models more robust to adversarial evaluation,\nbut also improving generalization to the source domain as well as new domains\nand languages. We first propose three new methods for generating QA\nadversaries, that introduce multiple points of confusion within the context,\nshow dependence on insertion location of the distractor, and reveal the\ncompounding effect of mixing adversarial strategies with syntactic and semantic\nparaphrasing methods. Next, we find that augmenting the training datasets with\nuniformly sampled adversaries improves robustness to the adversarial attacks\nbut leads to decline in performance on the original unaugmented dataset. We\naddress this issue via RL and more efficient Bayesian policy search methods for\nautomatically learning the best augmentation policy combinations of the\ntransformation probability for each adversary in a large search space. Using\nthese learned policies, we show that adversarial training can lead to\nsignificant improvements in in-domain, out-of-domain, and cross-lingual\n(German, Russian, Turkish) generalization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:20:08 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 15:30:48 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 01:38:28 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 16:43:56 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Maharana", "Adyasha", ""], ["Bansal", "Mohit", ""]]}, {"id": "2004.06077", "submitter": "Marouane Hachimi", "authors": "Marouane Hachimi, Georges Kaddoum, Ghyslain Gagnon, Poulmanogo Illy", "title": "Multi-stage Jamming Attacks Detection using Deep Learning Combined with\n  Kernelized Support Vector Machine in 5G Cloud Radio Access Networks", "comments": "6 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In 5G networks, the Cloud Radio Access Network (C-RAN) is considered a\npromising future architecture in terms of minimizing energy consumption and\nallocating resources efficiently by providing real-time cloud infrastructures,\ncooperative radio, and centralized data processing. Recently, given their\nvulnerability to malicious attacks, the security of C-RAN networks has\nattracted significant attention. Among various anomaly-based intrusion\ndetection techniques, the most promising one is the machine learning-based\nintrusion detection as it learns without human assistance and adjusts actions\naccordingly. In this direction, many solutions have been proposed, but they\nshow either low accuracy in terms of attack classification or they offer just a\nsingle layer of attack detection. This research focuses on deploying a\nmulti-stage machine learning-based intrusion detection (ML-IDS) in 5G C-RAN\nthat can detect and classify four types of jamming attacks: constant jamming,\nrandom jamming, deceptive jamming, and reactive jamming. This deployment\nenhances security by minimizing the false negatives in C-RAN architectures. The\nexperimental evaluation of the proposed solution is carried out using WSN-DS\n(Wireless Sensor Networks DataSet), which is a dedicated wireless dataset for\nintrusion detection. The final classification accuracy of attacks is 94.51\\%\nwith a 7.84\\% false negative rate.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:21:45 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 13:11:53 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Hachimi", "Marouane", ""], ["Kaddoum", "Georges", ""], ["Gagnon", "Ghyslain", ""], ["Illy", "Poulmanogo", ""]]}, {"id": "2004.06089", "submitter": "Ted Xiao", "authors": "Ted Xiao, Eric Jang, Dmitry Kalashnikov, Sergey Levine, Julian Ibarz,\n  Karol Hausman, Alexander Herzog", "title": "Thinking While Moving: Deep Reinforcement Learning with Concurrent\n  Control", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study reinforcement learning in settings where sampling an action from the\npolicy must be done concurrently with the time evolution of the controlled\nsystem, such as when a robot must decide on the next action while still\nperforming the previous action. Much like a person or an animal, the robot must\nthink and move at the same time, deciding on its next action before the\nprevious one has completed. In order to develop an algorithmic framework for\nsuch concurrent control problems, we start with a continuous-time formulation\nof the Bellman equations, and then discretize them in a way that is aware of\nsystem delays. We instantiate this new class of approximate dynamic programming\nmethods via a simple architectural extension to existing value-based deep\nreinforcement learning algorithms. We evaluate our methods on simulated\nbenchmark tasks and a large-scale robotic grasping task where the robot must\n\"think while moving\".\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:49:29 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 08:31:07 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 23:22:39 GMT"}, {"version": "v4", "created": "Sat, 25 Apr 2020 21:19:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xiao", "Ted", ""], ["Jang", "Eric", ""], ["Kalashnikov", "Dmitry", ""], ["Levine", "Sergey", ""], ["Ibarz", "Julian", ""], ["Hausman", "Karol", ""], ["Herzog", "Alexander", ""]]}, {"id": "2004.06093", "submitter": "Lek-Heng Lim", "authors": "Gregory Naitzat, Andrey Zhitnikov, and Lek-Heng Lim", "title": "Topology of deep neural networks", "comments": "34 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the topology of a data set $M = M_a \\cup M_b \\subseteq\n\\mathbb{R}^d$, representing two classes $a$ and $b$ in a binary classification\nproblem, changes as it passes through the layers of a well-trained neural\nnetwork, i.e., with perfect accuracy on training set and near-zero\ngeneralization error ($\\approx 0.01\\%$). The goal is to shed light on two\nmysteries in deep neural networks: (i) a nonsmooth activation function like\nReLU outperforms a smooth one like hyperbolic tangent; (ii) successful neural\nnetwork architectures rely on having many layers, even though a shallow network\ncan approximate any function arbitrary well. We performed extensive experiments\non the persistent homology of a wide range of point cloud data sets, both real\nand simulated. The results consistently demonstrate the following: (1) Neural\nnetworks operate by changing topology, transforming a topologically complicated\ndata set into a topologically simple one as it passes through the layers. No\nmatter how complicated the topology of $M$ we begin with, when passed through a\nwell-trained neural network $f : \\mathbb{R}^d \\to \\mathbb{R}^p$, there is a\nvast reduction in the Betti numbers of both components $M_a$ and $M_b$; in fact\nthey nearly always reduce to their lowest possible values:\n$\\beta_k\\bigl(f(M_i)\\bigr) = 0$ for $k \\ge 1$ and $\\beta_0\\bigl(f(M_i)\\bigr) =\n1$, $i =a, b$. Furthermore, (2) the reduction in Betti numbers is significantly\nfaster for ReLU activation than hyperbolic tangent activation as the former\ndefines nonhomeomorphic maps that change topology, whereas the latter defines\nhomeomorphic maps that preserve topology. Lastly, (3) shallow and deep networks\ntransform data sets differently -- a shallow network operates mainly through\nchanging geometry and changes topology only in its final layers, a deep one\nspreads topological changes more evenly across all layers.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:53:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Naitzat", "Gregory", ""], ["Zhitnikov", "Andrey", ""], ["Lim", "Lek-Heng", ""]]}, {"id": "2004.06100", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam Dziedzic, Rishabh\n  Krishnan, and Dawn Song", "title": "Pretrained Transformers Improve Out-of-Distribution Robustness", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although pretrained Transformers such as BERT achieve high accuracy on\nin-distribution examples, do they generalize to new distributions? We\nsystematically measure out-of-distribution (OOD) generalization for seven NLP\ndatasets by constructing a new robustness benchmark with realistic distribution\nshifts. We measure the generalization of previous models including bag-of-words\nmodels, ConvNets, and LSTMs, and we show that pretrained Transformers'\nperformance declines are substantially smaller. Pretrained transformers are\nalso more effective at detecting anomalous or OOD examples, while many previous\nmodels are frequently worse than chance. We examine which factors affect\nrobustness, finding that larger models are not necessarily more robust,\ndistillation can be harmful, and more diverse pretraining data can enhance\nrobustness. Finally, we show where future work can improve OOD robustness.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 17:58:56 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 05:01:33 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Hendrycks", "Dan", ""], ["Liu", "Xiaoyuan", ""], ["Wallace", "Eric", ""], ["Dziedzic", "Adam", ""], ["Krishnan", "Rishabh", ""], ["Song", "Dawn", ""]]}, {"id": "2004.06149", "submitter": "Cscott Brown", "authors": "CScott Brown", "title": "Local Model Feature Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local learning methods are a popular class of machine learning algorithms.\nThe basic idea for the entire cadre is to choose some non-local model family,\nto train many of them on small sections of neighboring data, and then to\n`stitch' the resulting models together in some way. Due to the limits of\nconstraining a training dataset to a small neighborhood, research on\nlocally-learned models has largely been restricted to simple model families.\nAlso, since simple model families have no complex structure by design, this has\nlimited use of the individual local models to predictive tasks. We hypothesize\nthat, using a sufficiently complex local model family, various properties of\nthe individual local models, such as their learned parameters, can be used as\nfeatures for further learning. This dissertation improves upon the current\nstate of research and works toward establishing this hypothesis by\ninvestigating algorithms for localization of more complex model families and by\nstudying their applications beyond predictions as a feature extraction\nmechanism. We summarize this generic technique of using local models as a\nfeature extraction step with the term ``local model feature transformations.''\nIn this document, we extend the local modeling paradigm to Gaussian processes,\northogonal quadric models and word embedding models, and extend the existing\ntheory for localized linear classifiers. We then demonstrate applications of\nlocal model feature transformations to epileptic event classification from EEG\nreadings, activity monitoring via chest accelerometry, 3D surface\nreconstruction, 3D point cloud segmentation, handwritten digit classification\nand event detection from Twitter feeds.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:41:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Brown", "CScott", ""]]}, {"id": "2004.06152", "submitter": "Hussein Hazimeh", "authors": "Hussein Hazimeh, Rahul Mazumder, Ali Saab", "title": "Sparse Regression at Scale: Branch-and-Bound rooted in First-Order\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the least squares regression problem, penalized with a\ncombination of the $\\ell_{0}$ and squared $\\ell_{2}$ penalty functions (a.k.a.\n$\\ell_0 \\ell_2$ regularization). Recent work shows that the resulting\nestimators are of key importance in many high-dimensional statistical settings.\nHowever, exact computation of these estimators remains a major challenge.\nIndeed, modern exact methods, based on mixed integer programming (MIP), face\ndifficulties when the number of features $p \\sim 10^4$. In this work, we\npresent a new exact MIP framework for $\\ell_0\\ell_2$-regularized regression\nthat can scale to $p \\sim 10^7$, achieving speedups of at least $5000$x,\ncompared to state-of-the-art exact methods. Unlike recent work, which relies on\nmodern commercial MIP solvers, we design a specialized nonlinear\nbranch-and-bound (BnB) framework, by critically exploiting the problem\nstructure. A key distinguishing component in our framework lies in efficiently\nsolving the node relaxations using a specialized first-order method, based on\ncoordinate descent (CD). Our CD-based method effectively leverages information\nacross the BnB nodes, through using warm starts, active sets, and gradient\nscreening. In addition, we design a novel method for obtaining dual bounds from\nprimal CD solutions, which certifiably works in high dimensions. Experiments on\nsynthetic and real high-dimensional datasets demonstrate that our framework is\nnot only significantly faster than the state of the art, but can also deliver\ncertifiably optimal solutions to statistically challenging instances that\ncannot be handled with existing methods. We open source the implementation\nthrough our toolkit L0BnB.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:45:29 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 20:18:21 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hazimeh", "Hussein", ""], ["Mazumder", "Rahul", ""], ["Saab", "Ali", ""]]}, {"id": "2004.06165", "submitter": "Xiujun Li", "authors": "Xiujun Li, Xi Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei\n  Zhang, Lijuan Wang, Houdong Hu, Li Dong, Furu Wei, Yejin Choi, Jianfeng Gao", "title": "Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks", "comments": "ECCV 2020, Code and pre-trained models are released:\n  https://github.com/microsoft/Oscar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-training methods of learning cross-modal representations on\nimage-text pairs are becoming popular for vision-language tasks. While existing\nmethods simply concatenate image region features and text features as input to\nthe model to be pre-trained and use self-attention to learn image-text semantic\nalignments in a brute force manner, in this paper, we propose a new learning\nmethod Oscar (Object-Semantics Aligned Pre-training), which uses object tags\ndetected in images as anchor points to significantly ease the learning of\nalignments. Our method is motivated by the observation that the salient objects\nin an image can be accurately detected, and are often mentioned in the paired\ntext. We pre-train an Oscar model on the public corpus of 6.5 million\ntext-image pairs, and fine-tune it on downstream tasks, creating new\nstate-of-the-arts on six well-established vision-language understanding and\ngeneration tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 19:18:10 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 03:29:46 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 04:57:31 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 01:18:25 GMT"}, {"version": "v5", "created": "Sun, 26 Jul 2020 00:46:46 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Li", "Xiujun", ""], ["Yin", "Xi", ""], ["Li", "Chunyuan", ""], ["Zhang", "Pengchuan", ""], ["Hu", "Xiaowei", ""], ["Zhang", "Lei", ""], ["Wang", "Lijuan", ""], ["Hu", "Houdong", ""], ["Dong", "Li", ""], ["Wei", "Furu", ""], ["Choi", "Yejin", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2004.06171", "submitter": "Udari Madhushani", "authors": "Udari Madhushani and Naomi Ehrich Leonard", "title": "Distributed Learning: Sequential Decision Making in Resource-Constrained\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study cost-effective communication strategies that can be used to improve\nthe performance of distributed learning systems in resource-constrained\nenvironments. For distributed learning in sequential decision making, we\npropose a new cost-effective partial communication protocol. We illustrate that\nwith this protocol the group obtains the same order of performance that it\nobtains with full communication. Moreover, we prove that under the proposed\npartial communication protocol the communication cost is $O(\\log T)$, where $T$\nis the time horizon of the decision-making process. This improves significantly\non protocols with full communication, which incur a communication cost that is\n$O(T)$. We validate our theoretical results using numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 19:46:35 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Madhushani", "Udari", ""], ["Leonard", "Naomi Ehrich", ""]]}, {"id": "2004.06174", "submitter": "Ralf L\\\"ammel", "authors": "Ralf L\\\"ammel, Alvin Kerber, and Liane Praza", "title": "Understanding What Software Engineers Are Working on -- The Work-Item\n  Prediction Challenge", "comments": "This paper appears in Proceedings of 28th International Conference on\n  Program Comprehension, ICPC 2020. The subject of the paper is covered by the\n  first author's keynote at the same conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding what a software engineer (a developer, an incident responder, a\nproduction engineer, etc.) is working on is a challenging problem -- especially\nwhen considering the more complex software engineering workflows in\nsoftware-intensive organizations: i) engineers rely on a multitude (perhaps\nhundreds) of loosely integrated tools; ii) engineers engage in concurrent and\nrelatively long running workflows; ii) infrastructure (such as logging) is not\nfully aware of work items; iv) engineering processes (e.g., for incident\nresponse) are not explicitly modeled. In this paper, we explain the\ncorresponding 'work-item prediction challenge' on the grounds of representative\nscenarios, report on related efforts at Facebook, discuss some lessons learned,\nand review related work to call to arms to leverage, advance, and combine\ntechniques from program comprehension, mining software repositories, process\nmining, and machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 19:59:36 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["L\u00e4mmel", "Ralf", ""], ["Kerber", "Alvin", ""], ["Praza", "Liane", ""]]}, {"id": "2004.06196", "submitter": "Alena Kopanicakova", "authors": "Lisa Gaedke-Merzh\\\"auser and Alena Kopani\\v{c}\\'akov\\'a and Rolf\n  Krause", "title": "Multilevel Minimization for Deep Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new multilevel minimization framework for the training of deep\nresidual networks (ResNets), which has the potential to significantly reduce\ntraining time and effort. Our framework is based on the dynamical system's\nviewpoint, which formulates a ResNet as the discretization of an initial value\nproblem. The training process is then formulated as a time-dependent optimal\ncontrol problem, which we discretize using different time-discretization\nparameters, eventually generating multilevel-hierarchy of auxiliary networks\nwith different resolutions. The training of the original ResNet is then\nenhanced by training the auxiliary networks with reduced resolutions. By\ndesign, our framework is conveniently independent of the choice of the training\nstrategy chosen on each level of the multilevel hierarchy. By means of\nnumerical examples, we analyze the convergence behavior of the proposed method\nand demonstrate its robustness. For our examples we employ a multilevel\ngradient-based methods. Comparisons with standard single level methods show a\nspeedup of more than factor three while achieving the same validation accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 20:52:26 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gaedke-Merzh\u00e4user", "Lisa", ""], ["Kopani\u010d\u00e1kov\u00e1", "Alena", ""], ["Krause", "Rolf", ""]]}, {"id": "2004.06201", "submitter": "Yi Tay", "authors": "Yi Tay, Dara Bahri, Che Zheng, Clifford Brunk, Donald Metzler, Andrew\n  Tomkins", "title": "Reverse Engineering Configurations of Neural Text Generation Models", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to develop a deeper understanding of the fundamental\nproperties of neural text generations models. The study of artifacts that\nemerge in machine generated text as a result of modeling choices is a nascent\nresearch area. Previously, the extent and degree to which these artifacts\nsurface in generated text has not been well studied. In the spirit of better\nunderstanding generative text models and their artifacts, we propose the new\ntask of distinguishing which of several variants of a given model generated a\npiece of text, and we conduct an extensive suite of diagnostic tests to observe\nwhether modeling choices (e.g., sampling methods, top-$k$ probabilities, model\narchitectures, etc.) leave detectable artifacts in the text they generate. Our\nkey finding, which is backed by a rigorous set of experiments, is that such\nartifacts are present and that different modeling choices can be inferred by\nobserving the generated text alone. This suggests that neural text generators\nmay be more sensitive to various modeling choices than previously thought.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 21:02:44 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Tay", "Yi", ""], ["Bahri", "Dara", ""], ["Zheng", "Che", ""], ["Brunk", "Clifford", ""], ["Metzler", "Donald", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2004.06216", "submitter": "Murthy Devarakonda", "authors": "Hong Guan, Jianfu Li, Hua Xu, Murthy Devarakonda", "title": "Robustly Pre-trained Neural Model for Direct Temporal Relation\n  Extraction", "comments": "10 pages, 1 Figure, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Identifying relationships between clinical events and temporal\nexpressions is a key challenge in meaningfully analyzing clinical text for use\nin advanced AI applications. While previous studies exist, the state-of-the-art\nperformance has significant room for improvement.\n  Methods: We studied several variants of BERT (Bidirectional Encoder\nRepresentations using Transformers) some involving clinical domain\ncustomization and the others involving improved architecture and/or training\nstrategies. We evaluated these methods using a direct temporal relations\ndataset which is a semantically focused subset of the 2012 i2b2 temporal\nrelations challenge dataset.\n  Results: Our results show that RoBERTa, which employs better pre-training\nstrategies including using 10x larger corpus, has improved overall F measure by\n0.0864 absolute score (on the 1.00 scale) and thus reducing the error rate by\n24% relative to the previous state-of-the-art performance achieved with an SVM\n(support vector machine) model.\n  Conclusion: Modern contextual language modeling neural networks, pre-trained\non a large corpus, achieve impressive performance even on highly-nuanced\nclinical temporal relation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 22:01:38 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Guan", "Hong", ""], ["Li", "Jianfu", ""], ["Xu", "Hua", ""], ["Devarakonda", "Murthy", ""]]}, {"id": "2004.06222", "submitter": "Murthy Devarakonda", "authors": "Ashwin Karthik Ambalavanan, Murthy Devarakonda", "title": "Cascade Neural Ensemble for Identifying Scientifically Sound Articles", "comments": "11 pages, 4 figures, and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: A significant barrier to conducting systematic reviews and\nmeta-analysis is efficiently finding scientifically sound relevant articles.\nTypically, less than 1% of articles match this requirement which leads to a\nhighly imbalanced task. Although feature-engineered and early neural networks\nmodels were studied for this task, there is an opportunity to improve the\nresults.\n  Methods: We framed the problem of filtering articles as a classification\ntask, and trained and tested several ensemble architectures of SciBERT, a\nvariant of BERT pre-trained on scientific articles, on a manually annotated\ndataset of about 50K articles from MEDLINE. Since scientifically sound articles\nare identified through a multi-step process we proposed a novel cascade\nensemble analogous to the selection process. We compared the performance of the\ncascade ensemble with a single integrated model and other types of ensembles as\nwell as with results from previous studies.\n  Results: The cascade ensemble architecture achieved 0.7505 F measure, an\nimpressive 49.1% error rate reduction, compared to a CNN model that was\npreviously proposed and evaluated on a selected subset of the 50K articles. On\nthe full dataset, the cascade ensemble achieved 0.7639 F measure, resulting in\nan error rate reduction of 19.7% compared to the best performance reported in a\nprevious study that used the full dataset.\n  Conclusion: Pre-trained contextual encoder neural networks (e.g. SciBERT)\nperform better than the models studied previously and manually created search\nfilters in filtering for scientifically sound relevant articles. The superior\nperformance achieved by the cascade ensemble is a significant result that\ngeneralizes beyond this task and the dataset, and is analogous to query\noptimization in IR and databases.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 22:23:04 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ambalavanan", "Ashwin Karthik", ""], ["Devarakonda", "Murthy", ""]]}, {"id": "2004.06226", "submitter": "Felipe Rojas", "authors": "Felipe Rojas, Lo\\\"ic Maurin, Rolando D\\\"unner, Karim Pichara", "title": "Classifying CMB time-ordered data through deep neural networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": "10.1093/mnras/staa1009", "report-no": null, "categories": "astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cosmic Microwave Background (CMB) has been measured over a wide range of\nmultipoles. Experiments with arc-minute resolution like the Atacama Cosmology\nTelescope (ACT) have contributed to the measurement of primary and secondary\nanisotropies, leading to remarkable scientific discoveries. Such findings\nrequire careful data selection in order to remove poorly-behaved detectors and\nunwanted contaminants. The current data classification methodology used by ACT\nrelies on several statistical parameters that are assessed and fine-tuned by an\nexpert. This method is highly time-consuming and band or season-specific, which\nmakes it less scalable and efficient for future CMB experiments. In this work,\nwe propose a supervised machine learning model to classify detectors of CMB\nexperiments. The model corresponds to a deep convolutional neural network. We\ntested our method on real ACT data, using the 2008 season, 148 GHz, as training\nset with labels provided by the ACT data selection software. The model learns\nto classify time-streams starting directly from the raw data. For the season\nand frequency considered during the training, we find that our classifier\nreaches a precision of 99.8%. For 220 and 280 GHz data, season 2008, we\nobtained 99.4% and 97.5% of precision, respectively. Finally, we performed a\ncross-season test over 148 GHz data from 2009 and 2010 for which our model\nreaches a precision of 99.8% and 99.5%, respectively. Our model is about 10x\nfaster than the current pipeline, making it potentially suitable for real-time\nimplementations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 22:34:30 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Rojas", "Felipe", ""], ["Maurin", "Lo\u00efc", ""], ["D\u00fcnner", "Rolando", ""], ["Pichara", "Karim", ""]]}, {"id": "2004.06229", "submitter": "Shanglin Yang", "authors": "Shizhu Liu, Shanglin Yang, and Hui Zhou", "title": "Imitation Learning for Fashion Style Based on Hierarchical Multimodal\n  Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fashion is a complex social phenomenon. People follow fashion styles from\ndemonstrations by experts or fashion icons. However, for machine agent,\nlearning to imitate fashion experts from demonstrations can be challenging,\nespecially for complex styles in environments with high-dimensional, multimodal\nobservations. Most existing research regarding fashion outfit composition\nutilizes supervised learning methods to mimic the behaviors of style icons.\nThese methods suffer from distribution shift: because the agent greedily\nimitates some given outfit demonstrations, it can drift away from one style to\nanother styles given subtle differences. In this work, we propose an\nadversarial inverse reinforcement learning formulation to recover reward\nfunctions based on hierarchical multimodal representation (HM-AIRL) during the\nimitation process. The hierarchical joint representation can more\ncomprehensively model the expert composited outfit demonstrations to recover\nthe reward function. We demonstrate that the proposed HM-AIRL model is able to\nrecover reward functions that are robust to changes in multimodal observations,\nenabling us to learn policies under significant variation between different\nstyles.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:02:25 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Liu", "Shizhu", ""], ["Yang", "Shanglin", ""], ["Zhou", "Hui", ""]]}, {"id": "2004.06230", "submitter": "Jiayu Yao", "authors": "Jiayu Yao, Emma Brunskill, Weiwei Pan, Susan Murphy, Finale\n  Doshi-Velez", "title": "Power Constrained Bandits", "comments": "Accepted at MLHC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandits often provide simple and effective personalization in\ndecision making problems, making them popular tools to deliver personalized\ninterventions in mobile health as well as other health applications. However,\nwhen bandits are deployed in the context of a scientific study -- e.g. a\nclinical trial to test if a mobile health intervention is effective -- the aim\nis not only to personalize for an individual, but also to determine, with\nsufficient statistical power, whether or not the system's intervention is\neffective. It is essential to assess the effectiveness of the intervention\nbefore broader deployment for better resource allocation. The two objectives\nare often deployed under different model assumptions, making it hard to\ndetermine how achieving the personalization and statistical power affect each\nother. In this work, we develop general meta-algorithms to modify existing\nalgorithms such that sufficient power is guaranteed while still improving each\nuser's well-being. We also demonstrate that our meta-algorithms are robust to\nvarious model mis-specifications possibly appearing in statistical studies,\nthus providing a valuable tool to study designers.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:08:52 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 14:08:51 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 20:34:10 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 07:55:49 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yao", "Jiayu", ""], ["Brunskill", "Emma", ""], ["Pan", "Weiwei", ""], ["Murphy", "Susan", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "2004.06231", "submitter": "Robert Peharz", "authors": "Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro\n  Molina, Martin Trapp, Guy Van den Broeck, Kristian Kersting, Zoubin\n  Ghahramani", "title": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic\n  Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic circuits (PCs) are a promising avenue for probabilistic\nmodeling, as they permit a wide range of exact and efficient inference\nroutines. Recent ``deep-learning-style'' implementations of PCs strive for a\nbetter scalability, but are still difficult to train on real-world data, due to\ntheir sparsely connected computational graphs. In this paper, we propose Einsum\nNetworks (EiNets), a novel implementation design for PCs, improving prior art\nin several regards. At their core, EiNets combine a large number of arithmetic\noperations in a single monolithic einsum-operation, leading to speedups and\nmemory savings of up to two orders of magnitude, in comparison to previous\nimplementations. As an algorithmic contribution, we show that the\nimplementation of Expectation-Maximization (EM) can be simplified for PCs, by\nleveraging automatic differentiation. Furthermore, we demonstrate that EiNets\nscale well to datasets which were previously out of reach, such as SVHN and\nCelebA, and that they can be used as faithful generative image models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:09:15 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Peharz", "Robert", ""], ["Lang", "Steven", ""], ["Vergari", "Antonio", ""], ["Stelzner", "Karl", ""], ["Molina", "Alejandro", ""], ["Trapp", "Martin", ""], ["Broeck", "Guy Van den", ""], ["Kersting", "Kristian", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2004.06237", "submitter": "Geoffrey McLachlan", "authors": "Geoffrey J. McLachlan, Daniel Ahfock", "title": "Estimation of Classification Rules from Partially Classified Data", "comments": "Based on invited talk given to the 16th Conference of the\n  International Federation of Classification Societies in Thessaloniki, August\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the situation where the observed sample contains some\nobservations whose class of origin is known (that is, they are classified with\nrespect to the g underlying classes of interest), and where the remaining\nobservations in the sample are unclassified (that is, their class labels are\nunknown). For class-conditional distributions taken to be known up to a vector\nof unknown parameters, the aim is to estimate the Bayes' rule of allocation for\nthe allocation of subsequent unclassified observations. Estimation on the basis\nof both the classified and unclassified data can be undertaken in a\nstraightforward manner by fitting a g-component mixture model by maximum\nlikelihood (ML) via the EM algorithm in the situation where the observed data\ncan be assumed to be an observed random sample from the adopted mixture\ndistribution. This assumption applies if the missing-data mechanism is\nignorable in the terminology pioneered by Rubin (1976). An initial likelihood\napproach was to use the so-called classification ML approach whereby the\nmissing labels are taken to be parameters to be estimated along with the\nparameters of the class-conditional distributions. However, as it can lead to\ninconsistent estimates, the focus of attention switched to the mixture ML\napproach after the appearance of the EM algorithm (Dempster et al., 1977).\nParticular attention is given here to the asymptotic relative efficiency (ARE)\nof the Bayes' rule estimated from a partially classified sample. Lastly, we\nconsider briefly some recent results in situations where the missing label\npattern is non-ignorable for the purposes of ML estimation for the mixture\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 23:35:25 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["McLachlan", "Geoffrey J.", ""], ["Ahfock", "Daniel", ""]]}, {"id": "2004.06243", "submitter": "Priyabrata Saha", "authors": "Priyabrata Saha, Saurabh Dash, Saibal Mukhopadhyay", "title": "Physics-Incorporated Convolutional Recurrent Neural Networks for Source\n  Identification and Forecasting of Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal dynamics of physical processes are generally modeled using\npartial differential equations (PDEs). Though the core dynamics follows some\nprinciples of physics, real-world physical processes are often driven by\nunknown external sources. In such cases, developing a purely analytical model\nbecomes very difficult and data-driven modeling can be of assistance. In this\npaper, we present a hybrid framework combining physics-based numerical models\nwith deep learning for source identification and forecasting of spatio-temporal\ndynamical systems with unobservable time-varying external sources. We formulate\nour model PhICNet as a convolutional recurrent neural network (RNN) which is\nend-to-end trainable for spatio-temporal evolution prediction of dynamical\nsystems and learns the source behavior as an internal state of the RNN.\nExperimental results show that the proposed model can forecast the dynamics for\na relatively long time and identify the sources as well.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:27:18 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 02:19:38 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Saha", "Priyabrata", ""], ["Dash", "Saurabh", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2004.06244", "submitter": "Azar Barkousaraie", "authors": "Azar Sadeghnejad-Barkousaraie, Gyanendra Bohara, Steve Jiang, Dan\n  Nguyen", "title": "A reinforcement learning application of guided Monte Carlo Tree Search\n  algorithm for beam orientation selection in radiation therapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the large combinatorial problem, current beam orientation optimization\nalgorithms for radiotherapy, such as column generation (CG), are typically\nheuristic or greedy in nature, leading to suboptimal solutions. We propose a\nreinforcement learning strategy using Monte Carlo Tree Search capable of\nfinding a superior beam orientation set and in less time than CG.We utilized a\nreinforcement learning structure involving a supervised learning network to\nguide Monte Carlo tree search (GTS) to explore the decision space of beam\norientation selection problem. We have previously trained a deep neural network\n(DNN) that takes in the patient anatomy, organ weights, and current beams, and\nthen approximates beam fitness values, indicating the next best beam to add.\nThis DNN is used to probabilistically guide the traversal of the branches of\nthe Monte Carlo decision tree to add a new beam to the plan. To test the\nfeasibility of the algorithm, we solved for 5-beam plans, using 13 test\nprostate cancer patients, different from the 57 training and validation\npatients originally trained the DNN. To show the strength of GTS to other\nsearch methods, performances of three other search methods including a guided\nsearch, uniform tree search and random search algorithms are also provided. On\naverage GTS outperforms all other methods, it find a solution better than CG in\n237 seconds on average, compared to CG which takes 360 seconds, and outperforms\nall other methods in finding a solution with lower objective function value in\nless than 1000 seconds. Using our guided tree search (GTS) method we were able\nto maintain a similar planning target volume (PTV) coverage within 1% error,\nand reduce the organ at risk (OAR) mean dose for body, rectum, left and right\nfemoral heads, but a slight increase of 1% in bladder mean dose.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:28:15 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sadeghnejad-Barkousaraie", "Azar", ""], ["Bohara", "Gyanendra", ""], ["Jiang", "Steve", ""], ["Nguyen", "Dan", ""]]}, {"id": "2004.06247", "submitter": "Nemanja Djuric", "authors": "Eason Wang, Henggang Cui, Sai Yalamanchi, Mohana Moorthy, Fang-Chieh\n  Chou, Nemanja Djuric", "title": "Improving Movement Predictions of Traffic Actors in Bird's-Eye View\n  Models using GANs and Differentiable Trajectory Rasterization", "comments": "Accepted for publication at ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical pieces of the self-driving puzzle is the task of\npredicting future movement of surrounding traffic actors, which allows the\nautonomous vehicle to safely and effectively plan its future route in a complex\nworld. Recently, a number of algorithms have been proposed to address this\nimportant problem, spurred by a growing interest of researchers from both\nindustry and academia. Methods based on top-down scene rasterization on one\nside and Generative Adversarial Networks (GANs) on the other have shown to be\nparticularly successful, obtaining state-of-the-art accuracies on the task of\ntraffic movement prediction. In this paper we build upon these two directions\nand propose a raster-based conditional GAN architecture, powered by a novel\ndifferentiable rasterizer module at the input of the conditional discriminator\nthat maps generated trajectories into the raster space in a differentiable\nmanner. This simplifies the task for the discriminator as trajectories that are\nnot scene-compliant are easier to discern, and allows the gradients to flow\nback forcing the generator to output better, more realistic trajectories. We\nevaluated the proposed method on a large-scale, real-world data set, showing\nthat it outperforms state-of-the-art GAN-based baselines.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:41:17 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 02:59:56 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Wang", "Eason", ""], ["Cui", "Henggang", ""], ["Yalamanchi", "Sai", ""], ["Moorthy", "Mohana", ""], ["Chou", "Fang-Chieh", ""], ["Djuric", "Nemanja", ""]]}, {"id": "2004.06248", "submitter": "Aadirupa Saha", "authors": "Aadirupa Saha, Pierre Gaillard, Michal Valko", "title": "Improved Sleeping Bandits with Stochastic Actions Sets and Adversarial\n  Rewards", "comments": "Accepted to ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of sleeping bandits with stochastic\naction sets and adversarial rewards. In this setting, in contrast to most work\nin bandits, the actions may not be available at all times. For instance, some\nproducts might be out of stock in item recommendation. The best existing\nefficient (i.e., polynomial-time) algorithms for this problem only guarantee an\n$O(T^{2/3})$ upper-bound on the regret. Yet, inefficient algorithms based on\nEXP4 can achieve $O(\\sqrt{T})$. In this paper, we provide a new computationally\nefficient algorithm inspired by EXP3 satisfying a regret of order $O(\\sqrt{T})$\nwhen the availabilities of each action $i \\in \\cA$ are independent. We then\nstudy the most general version of the problem where at each round available\nsets are generated from some unknown arbitrary distribution (i.e., without the\nindependence assumption) and propose an efficient algorithm with $O(\\sqrt {2^K\nT})$ regret guarantee. Our theoretical results are corroborated with\nexperimental evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:41:26 GMT"}, {"version": "v2", "created": "Sat, 8 Aug 2020 12:45:26 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Saha", "Aadirupa", ""], ["Gaillard", "Pierre", ""], ["Valko", "Michal", ""]]}, {"id": "2004.06272", "submitter": "Yangxin Wu", "authors": "Yangxin Wu, Gengwei Zhang, Yiming Gao, Xiajun Deng, Ke Gong, Xiaodan\n  Liang, Liang Lin", "title": "Bidirectional Graph Reasoning Network for Panoptic Segmentation", "comments": "CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches on panoptic segmentation resort to a single end-to-end\nnetwork to combine the tasks of instance segmentation and semantic\nsegmentation. However, prior models only unified the two related tasks at the\narchitectural level via a multi-branch scheme or revealed the underlying\ncorrelation between them by unidirectional feature fusion, which disregards the\nexplicit semantic and co-occurrence relations among objects and background.\nInspired by the fact that context information is critical to recognize and\nlocalize the objects, and inclusive object details are significant to parse the\nbackground scene, we thus investigate on explicitly modeling the correlations\nbetween object and background to achieve a holistic understanding of an image\nin the panoptic segmentation task. We introduce a Bidirectional Graph Reasoning\nNetwork (BGRNet), which incorporates graph structure into the conventional\npanoptic segmentation network to mine the intra-modular and intermodular\nrelations within and between foreground things and background stuff classes. In\nparticular, BGRNet first constructs image-specific graphs in both instance and\nsemantic segmentation branches that enable flexible reasoning at the proposal\nlevel and class level, respectively. To establish the correlations between\nseparate branches and fully leverage the complementary relations between things\nand stuff, we propose a Bidirectional Graph Connection Module to diffuse\ninformation across branches in a learnable fashion. Experimental results\ndemonstrate the superiority of our BGRNet that achieves the new\nstate-of-the-art performance on challenging COCO and ADE20K panoptic\nsegmentation benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 02:32:10 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Wu", "Yangxin", ""], ["Zhang", "Gengwei", ""], ["Gao", "Yiming", ""], ["Deng", "Xiajun", ""], ["Gong", "Ke", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "2004.06277", "submitter": "Peter Vamplew", "authors": "Peter Vamplew, Cameron Foale and Richard Dazeley", "title": "A Demonstration of Issues with Value-Based Multiobjective Reinforcement\n  Learning Under Stochastic State Transitions", "comments": "6 pages. Accepted for presentation in the Adaptive and Learning\n  Agents Workshop, AAMAS 2020", "journal-ref": "The impact of environmental stochasticity on value-based\n  multiobjective reinforcement learning, Neural Computing and Applications,\n  2021", "doi": "10.1007/s00521-021-05859-1", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a previously unidentified issue with model-free, value-based\napproaches to multiobjective reinforcement learning in the context of\nenvironments with stochastic state transitions. An example multiobjective\nMarkov Decision Process (MOMDP) is used to demonstrate that under such\nconditions these approaches may be unable to discover the policy which\nmaximises the Scalarised Expected Return, and in fact may converge to a\nPareto-dominated solution. We discuss several alternative methods which may be\nmore suitable for maximising SER in MOMDPs with stochastic transitions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 02:55:12 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Vamplew", "Peter", ""], ["Foale", "Cameron", ""], ["Dazeley", "Richard", ""]]}, {"id": "2004.06286", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Yifan Xu and Bao-Liang Lu", "title": "Transfer Learning for EEG-Based Brain-Computer Interfaces: A Review of\n  Progress Made Since 2016", "comments": null, "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, 2020", "doi": null, "report-no": null, "categories": "cs.HC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A brain-computer interface (BCI) enables a user to communicate with a\ncomputer directly using brain signals. The most common non-invasive BCI\nmodality, electroencephalogram (EEG), is sensitive to noise/artifact and\nsuffers between-subject/within-subject non-stationarity. Therefore, it is\ndifficult to build a generic pattern recognition model in an EEG-based BCI\nsystem that is optimal for different subjects, during different sessions, for\ndifferent devices and tasks. Usually, a calibration session is needed to\ncollect some training data for a new subject, which is time-consuming and user\nunfriendly. Transfer learning (TL), which utilizes data or knowledge from\nsimilar or relevant subjects/sessions/devices/tasks to facilitate learning for\na new subject/session/device/task, is frequently used to reduce the amount of\ncalibration effort. This paper reviews journal publications on TL approaches in\nEEG-based BCIs in the last few years, i.e., since 2016. Six paradigms and\napplications -- motor imagery, event-related potentials, steady-state visual\nevoked potentials, affective BCIs, regression problems, and adversarial attacks\n-- are considered. For each paradigm/application, we group the TL approaches\ninto cross-subject/session, cross-device, and cross-task settings and review\nthem separately. Observations and conclusions are made at the end of the paper,\nwhich may point to future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:44:55 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 22:13:09 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 22:19:40 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 23:34:11 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Wu", "Dongrui", ""], ["Xu", "Yifan", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "2004.06288", "submitter": "Yeli Feng", "authors": "Yeli Feng, Yiyu Cai", "title": "Towards Robust Classification with Image Quality Assessment", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that deep convolutional neural networks (DCNN) are\nvulnerable to adversarial examples and sensitive to perceptual quality as well\nas the acquisition condition of images. These findings raise a big concern for\nthe adoption of DCNN-based applications for critical tasks. In the literature,\nvarious defense strategies have been introduced to increase the robustness of\nDCNN, including re-training an entire model with benign noise injection,\nadversarial examples, or adding extra layers. In this paper, we investigate the\nconnection between adversarial manipulation and image quality, subsequently\npropose a protective mechanism that doesnt require re-training a DCNN. Our\nmethod combines image quality assessment with knowledge distillation to detect\ninput images that would trigger a DCCN to produce egregiously wrong results.\nUsing the ResNet model trained on ImageNet as an example, we demonstrate that\nthe detector can effectively identify poor quality and adversarial images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 03:27:35 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Feng", "Yeli", ""], ["Cai", "Yiyu", ""]]}, {"id": "2004.06298", "submitter": "Aditya Gangrade", "authors": "Aditya Gangrade, Durmus Alp Emre Acar, Venkatesh Saligrama", "title": "Budget Learning via Bracketing", "comments": "Slightly expanded version of a paper to be presented at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional machine learning applications in the mobile/IoT setting transmit\ndata to a cloud-server for predictions. Due to cost considerations (power,\nlatency, monetary), it is desirable to minimise device-to-server transmissions.\nThe budget learning (BL) problem poses the learner's goal as minimising use of\nthe cloud while suffering no discernible loss in accuracy, under the constraint\nthat the methods employed be edge-implementable.\n  We propose a new formulation for the BL problem via the concept of\nbracketings. Concretely, we propose to sandwich the cloud's prediction, $g,$\nvia functions $h^-, h^+$ from a `simple' class so that $h^- \\le g \\le h^+$\nnearly always. On an instance $x$, if $h^+(x)=h^-(x)$, we leverage local\nprocessing, and bypass the cloud. We explore theoretical aspects of this\nformulation, providing PAC-style learnability definitions; associating the\nnotion of budget learnability to approximability via brackets; and giving\nVC-theoretic analyses of their properties. We empirically validate our theory\non real-world datasets, demonstrating improved performance over prior gating\nbased methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 04:38:14 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Gangrade", "Aditya", ""], ["Acar", "Durmus Alp Emre", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "2004.06301", "submitter": "Sricharan Vijayarangan", "authors": "Sricharan Vijayarangan, Prithvi Suresh, Preejith SP, Jayaraj Joseph\n  and Mohansankar Sivaprakasam", "title": "Robust Modelling of Reflectance Pulse Oximetry for SpO$_2$ Estimation", "comments": "Accepted in EMBC 2020(EMBS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Continuous monitoring of blood oxygen saturation levels is vital for patients\nwith pulmonary disorders. Traditionally, SpO$_2$ monitoring has been carried\nout using transmittance pulse oximeters due to its dependability. However,\nSpO$_2$ measurement from transmittance pulse oximeters is limited to peripheral\nregions. This becomes a disadvantage at very low temperatures as blood\nperfusion to the peripherals decreases. On the other hand, reflectance pulse\noximeters can be used at various sites like finger, wrist, chest and forehead.\nAdditionally, reflectance pulse oximeters can be scaled down to affordable\npatches that do not interfere with the user's diurnal activities. However,\naccurate SpO$_2$ estimation from reflectance pulse oximeters is challenging due\nto its patient dependent, subjective nature of measurement. Recently, a Machine\nLearning (ML) method was used to model reflectance waveforms onto SpO$_2$\nobtained from transmittance waveforms. However, the generalizability of the\nmodel to new patients was not tested. In light of this, the current work\nimplemented multiple ML based approaches which were subsequently found to be\nincapable of generalizing to new patients. Furthermore, a minimally calibrated\ndata driven approach was utilized in order to obtain SpO$_2$ from reflectance\nPPG waveforms. The proposed solution produces an average mean absolute error of\n1.81\\% on unseen patients which is well within the clinically permissible error\nof 2\\%. Two statistical tests were conducted to establish the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 04:53:14 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Vijayarangan", "Sricharan", ""], ["Suresh", "Prithvi", ""], ["SP", "Preejith", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohansankar", ""]]}, {"id": "2004.06302", "submitter": "Eugene Belilovsky", "authors": "Mateusz Michalkiewicz, Sarah Parisot, Stavros Tsogkas, Mahsa\n  Baktashmotlagh, Anders Eriksson, Eugene Belilovsky", "title": "Few-Shot Single-View 3-D Object Reconstruction with Compositional Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive performance of deep convolutional neural networks in\nsingle-view 3D reconstruction suggests that these models perform non-trivial\nreasoning about the 3D structure of the output space. However, recent work has\nchallenged this belief, showing that complex encoder-decoder architectures\nperform similarly to nearest-neighbor baselines or simple linear decoder models\nthat exploit large amounts of per category data in standard benchmarks. On the\nother hand settings where 3D shape must be inferred for new categories with few\nexamples are more natural and require models that generalize about shapes. In\nthis work we demonstrate experimentally that naive baselines do not apply when\nthe goal is to learn to reconstruct novel objects using very few examples, and\nthat in a \\emph{few-shot} learning setting, the network must learn concepts\nthat can be applied to new categories, avoiding rote memorization. To address\ndeficiencies in existing approaches to this problem, we propose three\napproaches that efficiently integrate a class prior into a 3D reconstruction\nmodel, allowing to account for intra-class variability and imposing an implicit\ncompositional structure that the model should learn. Experiments on the popular\nShapeNet database demonstrate that our method significantly outperform existing\nbaselines on this task in the few-shot setting.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 04:53:34 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 01:21:59 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Michalkiewicz", "Mateusz", ""], ["Parisot", "Sarah", ""], ["Tsogkas", "Stavros", ""], ["Baktashmotlagh", "Mahsa", ""], ["Eriksson", "Anders", ""], ["Belilovsky", "Eugene", ""]]}, {"id": "2004.06316", "submitter": "Yivan Zhang", "authors": "Yivan Zhang, Nontawat Charoenphakdee, Zhenguo Wu, Masashi Sugiyama", "title": "Learning from Aggregate Observations", "comments": "NeurIPS 2020 proceedings version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning from aggregate observations where\nsupervision signals are given to sets of instances instead of individual\ninstances, while the goal is still to predict labels of unseen individuals. A\nwell-known example is multiple instance learning (MIL). In this paper, we\nextend MIL beyond binary classification to other problems such as multiclass\nclassification and regression. We present a general probabilistic framework\nthat accommodates a variety of aggregate observations, e.g., pairwise\nsimilarity/triplet comparison for classification and mean/difference/rank\nobservation for regression. Simple maximum likelihood solutions can be applied\nto various differentiable models such as deep neural networks and gradient\nboosting machines. Moreover, we develop the concept of consistency up to an\nequivalence relation to characterize our estimator and show that it has nice\nconvergence properties under mild assumptions. Experiments on three problem\nsettings -- classification via triplet comparison and regression via mean/rank\nobservation indicate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 06:18:50 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 06:33:49 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 05:26:43 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Zhang", "Yivan", ""], ["Charoenphakdee", "Nontawat", ""], ["Wu", "Zhenguo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2004.06320", "submitter": "Mentar Mahmudi", "authors": "Jakob Geyer, Yohannes Kassahun, Mentar Mahmudi, Xavier Ricou, Rupesh\n  Durgesh, Andrew S. Chung, Lorenz Hauswald, Viet Hoang Pham, Maximilian\n  M\\\"uhlegg, Sebastian Dorn, Tiffany Fernandez, Martin J\\\"anicke, Sudesh\n  Mirashi, Chiragkumar Savani, Martin Sturm, Oleksandr Vorobiov, Martin Oelker,\n  Sebastian Garreis, Peter Schuberth", "title": "A2D2: Audi Autonomous Driving Dataset", "comments": "https://www.a2d2.audi/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research in machine learning, mobile robotics, and autonomous driving is\naccelerated by the availability of high quality annotated data. To this end, we\nrelease the Audi Autonomous Driving Dataset (A2D2). Our dataset consists of\nsimultaneously recorded images and 3D point clouds, together with 3D bounding\nboxes, semantic segmentation, instance segmentation, and data extracted from\nthe automotive bus. Our sensor suite consists of six cameras and five LiDAR\nunits, providing full 360 degree coverage. The recorded data is time\nsynchronized and mutually registered. Annotations are for non-sequential\nframes: 41,277 frames with semantic segmentation image and point cloud labels,\nof which 12,497 frames also have 3D bounding box annotations for objects within\nthe field of view of the front camera. In addition, we provide 392,556\nsequential frames of unannotated sensor data for recordings in three cities in\nthe south of Germany. These sequences contain several loops. Faces and vehicle\nnumber plates are blurred due to GDPR legislation and to preserve anonymity.\nA2D2 is made available under the CC BY-ND 4.0 license, permitting commercial\nuse subject to the terms of the license. Data and further information are\navailable at http://www.a2d2.audi.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 06:45:07 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Geyer", "Jakob", ""], ["Kassahun", "Yohannes", ""], ["Mahmudi", "Mentar", ""], ["Ricou", "Xavier", ""], ["Durgesh", "Rupesh", ""], ["Chung", "Andrew S.", ""], ["Hauswald", "Lorenz", ""], ["Pham", "Viet Hoang", ""], ["M\u00fchlegg", "Maximilian", ""], ["Dorn", "Sebastian", ""], ["Fernandez", "Tiffany", ""], ["J\u00e4nicke", "Martin", ""], ["Mirashi", "Sudesh", ""], ["Savani", "Chiragkumar", ""], ["Sturm", "Martin", ""], ["Vorobiov", "Oleksandr", ""], ["Oelker", "Martin", ""], ["Garreis", "Sebastian", ""], ["Schuberth", "Peter", ""]]}, {"id": "2004.06321", "submitter": "Yanjun Han", "authors": "Yanjun Han, Zhengqing Zhou, Zhengyuan Zhou, Jose Blanchet, Peter W.\n  Glynn, Yinyu Ye", "title": "Sequential Batch Learning in Finite-Action Linear Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequential batch learning problem in linear contextual bandits\nwith finite action sets, where the decision maker is constrained to split\nincoming individuals into (at most) a fixed number of batches and can only\nobserve outcomes for the individuals within a batch at the batch's end.\nCompared to both standard online contextual bandits learning or offline policy\nlearning in contexutal bandits, this sequential batch learning problem provides\na finer-grained formulation of many personalized sequential decision making\nproblems in practical applications, including medical treatment in clinical\ntrials, product recommendation in e-commerce and adaptive experiment design in\ncrowdsourcing.\n  We study two settings of the problem: one where the contexts are arbitrarily\ngenerated and the other where the contexts are \\textit{iid} drawn from some\ndistribution. In each setting, we establish a regret lower bound and provide an\nalgorithm, whose regret upper bound nearly matches the lower bound. As an\nimportant insight revealed therefrom, in the former setting, we show that the\nnumber of batches required to achieve the fully online performance is\npolynomial in the time horizon, while for the latter setting, a\npure-exploitation algorithm with a judicious batch partition scheme achieves\nthe fully online performance even when the number of batches is less than\nlogarithmic in the time horizon. Together, our results provide a near-complete\ncharacterization of sequential decision making in linear contextual bandits\nwhen batch constraints are present.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 06:47:40 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Han", "Yanjun", ""], ["Zhou", "Zhengqing", ""], ["Zhou", "Zhengyuan", ""], ["Blanchet", "Jose", ""], ["Glynn", "Peter W.", ""], ["Ye", "Yinyu", ""]]}, {"id": "2004.06338", "submitter": "Sevinj Yolchuyeva", "authors": "Sevinj Yolchuyeva, G\\'eza N\\'emeth, B\\'alint Gyires-T\\'oth", "title": "Transformer based Grapheme-to-Phoneme Conversion", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1954", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism is one of the most successful techniques in deep learning\nbased Natural Language Processing (NLP). The transformer network architecture\nis completely based on attention mechanisms, and it outperforms\nsequence-to-sequence models in neural machine translation without recurrent and\nconvolutional layers. Grapheme-to-phoneme (G2P) conversion is a task of\nconverting letters (grapheme sequence) to their pronunciations (phoneme\nsequence). It plays a significant role in text-to-speech (TTS) and automatic\nspeech recognition (ASR) systems. In this paper, we investigate the application\nof transformer architecture to G2P conversion and compare its performance with\nrecurrent and convolutional neural network based approaches. Phoneme and word\nerror rates are evaluated on the CMUDict dataset for US English and the NetTalk\ndataset. The results show that transformer based G2P outperforms the\nconvolutional-based approach in terms of word error rate and our results\nsignificantly exceeded previous recurrent approaches (without attention)\nregarding word and phoneme error rates on both datasets. Furthermore, the size\nof the proposed model is much smaller than the size of the previous approaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 07:48:15 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 21:09:53 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Yolchuyeva", "Sevinj", ""], ["N\u00e9meth", "G\u00e9za", ""], ["Gyires-T\u00f3th", "B\u00e1lint", ""]]}, {"id": "2004.06341", "submitter": "Kensuke Nakamura", "authors": "Kensuke Nakamura, Stefano Soatto, Byung-Woo Hong", "title": "Stochastic batch size for adaptive regularization in deep network\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a first-order stochastic optimization algorithm incorporating\nadaptive regularization applicable to machine learning problems in deep\nlearning framework. The adaptive regularization is imposed by stochastic\nprocess in determining batch size for each model parameter at each optimization\niteration. The stochastic batch size is determined by the update probability of\neach parameter following a distribution of gradient norms in consideration of\ntheir local and global properties in the neural network architecture where the\nrange of gradient norms may vary within and across layers. We empirically\ndemonstrate the effectiveness of our algorithm using an image classification\ntask based on conventional network models applied to commonly used benchmark\ndatasets. The quantitative evaluation indicates that our algorithm outperforms\nthe state-of-the-art optimization algorithms in generalization while providing\nless sensitivity to the selection of batch size which often plays a critical\nrole in optimization, thus achieving more robustness to the selection of\nregularity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 07:54:53 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Nakamura", "Kensuke", ""], ["Soatto", "Stefano", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "2004.06343", "submitter": "Nikhil Saldanha", "authors": "Youri Arkesteijn, Nikhil Saldanha, Bastijn Kostense", "title": "Code Completion using Neural Attention and Byte Pair Encoding", "comments": "4 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to do code completion based on implementing a Neural\nNetwork from Li et. al.. Our contribution is that we use an encoding that is\nin-between character and word encoding called Byte Pair Encoding (BPE). We use\nthis on the source code files treating them as natural text without first going\nthrough the abstract syntax tree (AST). We have implemented two models: an\nattention-enhanced LSTM and a pointer network, where the pointer network was\noriginally introduced to solve out of vocabulary problems. We are interested to\nsee if BPE can replace the need for the pointer network for code completion.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 08:00:40 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Arkesteijn", "Youri", ""], ["Saldanha", "Nikhil", ""], ["Kostense", "Bastijn", ""]]}, {"id": "2004.06353", "submitter": "Lu Yin", "authors": "Lu Yin, Vlado Menkovski, Mykola Pechenizkiy", "title": "Knowledge Elicitation using Deep Metric Learning and Psychometric\n  Testing", "comments": "16 pages, 11 figures", "journal-ref": "Machine Learning and Knowledge Discovery in Databases: European\n  Conference, ECML PKDD 2020", "doi": "10.1007/978-3-030-67661-2_10", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge present in a domain is well expressed as relationships between\ncorresponding concepts. For example, in zoology, animal species form complex\nhierarchies; in genomics, the different (parts of) molecules are organized in\ngroups and subgroups based on their functions; plants, molecules, and\nastronomical objects all form complex taxonomies. Nevertheless, when applying\nsupervised machine learning (ML) in such domains, we commonly reduce the\ncomplex and rich knowledge to a fixed set of labels, and induce a model shows\ngood generalization performance with respect to these labels. The main reason\nfor such a reductionist approach is the difficulty in eliciting the domain\nknowledge from the experts. Developing a label structure with sufficient\nfidelity and providing comprehensive multi-label annotation can be exceedingly\nlabor-intensive in many real-world applications. In this paper, we provide a\nmethod for efficient hierarchical knowledge elicitation (HKE) from experts\nworking with high-dimensional data such as images or videos. Our method is\nbased on psychometric testing and active deep metric learning. The developed\nmodels embed the high-dimensional data in a metric space where distances are\nsemantically meaningful, and the data can be organized in a hierarchical\nstructure. We provide empirical evidence with a series of experiments on a\nsynthetically generated dataset of simple shapes, and Cifar 10 and\nFashion-MNIST benchmarks that our method is indeed successful in uncovering\nhierarchical structures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 08:33:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yin", "Lu", ""], ["Menkovski", "Vlado", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "2004.06355", "submitter": "Mo Deng", "authors": "Mo Deng, Shuai Li, Iksung Kang, Nicholas X. Fang and George\n  Barbastathis", "title": "On the interplay between physical and content priors in deep learning\n  for computational imaging", "comments": null, "journal-ref": null, "doi": "10.1364/OE.395204", "report-no": null, "categories": "eess.IV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has been applied extensively in many computational imaging\nproblems, often leading to superior performance over traditional iterative\napproaches. However, two important questions remain largely unanswered: first,\nhow well can the trained neural network generalize to objects very different\nfrom the ones in training? This is particularly important in practice, since\nlarge-scale annotated examples similar to those of interest are often not\navailable during training. Second, has the trained neural network learnt the\nunderlying (inverse) physics model, or has it merely done something trivial,\nsuch as memorizing the examples or point-wise pattern matching? This pertains\nto the interpretability of machine-learning based algorithms. In this work, we\nuse the Phase Extraction Neural Network (PhENN), a deep neural network (DNN)\nfor quantitative phase retrieval in a lensless phase imaging system as the\nstandard platform and show that the two questions are related and share a\ncommon crux: the choice of the training examples. Moreover, we connect the\nstrength of the regularization effect imposed by a training set to the training\nprocess with the Shannon entropy of images in the dataset. That is, the higher\nthe entropy of the training images, the weaker the regularization effect can be\nimposed. We also discover that weaker regularization effect leads to better\nlearning of the underlying propagation model, i.e. the weak object transfer\nfunction, applicable for weakly scattering objects under the weak object\napproximation. Finally, simulation and experimental results show that better\ncross-domain generalization performance can be achieved if DNN is trained on a\nhigher-entropy database, e.g. the ImageNet, than if the same DNN is trained on\na lower-entropy database, e.g. MNIST, as the former allows the underlying\nphysics model be learned better than the latter.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 08:36:46 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Deng", "Mo", ""], ["Li", "Shuai", ""], ["Kang", "Iksung", ""], ["Fang", "Nicholas X.", ""], ["Barbastathis", "George", ""]]}, {"id": "2004.06373", "submitter": "Tuanfei Zhu", "authors": "Tuanfei Zhu, Cheng Luo, Jing Li, Siqi Ren and Zhihong Zhang", "title": "Minority Oversampling for Imbalanced Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important real-world applications involve time-series data with skewed\ndistribution. Compared to conventional imbalance learning problems, the\nclassification of imbalanced time-series data is more challenging due to high\ndimensionality and high inter-variable correlation. This paper proposes a\nstructure preserving Oversampling method to combat the High-dimensional\nImbalanced Time-series classification (OHIT). OHIT first leverages a\ndensity-ratio based shared nearest neighbor clustering algorithm to capture the\nmodes of minority class in high-dimensional space. It then for each mode\napplies the shrinkage technique of large-dimensional covariance matrix to\nobtain accurate and reliable covariance structure. Finally, OHIT generates the\nstructure-preserving synthetic samples based on multivariate Gaussian\ndistribution by using the estimated covariance matrices. Experimental results\non several publicly available time-series datasets (including unimodal and\nmultimodal) demonstrate the superiority of OHIT against the state-of-the-art\noversampling algorithms in terms of F1, G-mean, and AUC.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 09:20:12 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 14:47:24 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 06:30:58 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 09:17:13 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhu", "Tuanfei", ""], ["Luo", "Cheng", ""], ["Li", "Jing", ""], ["Ren", "Siqi", ""], ["Zhang", "Zhihong", ""]]}, {"id": "2004.06383", "submitter": "Jon Vadillo Jueguen", "authors": "Jon Vadillo, Roberto Santana and Jose A. Lozano", "title": "Extending Adversarial Attacks to Produce Adversarial Class Probability\n  Distributions", "comments": "13 pages, 7 figures, 2 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the remarkable performance and generalization levels of deep learning\nmodels in a wide range of artificial intelligence tasks, it has been\ndemonstrated that these models can be easily fooled by the addition of\nimperceptible but malicious perturbations to natural inputs. These altered\ninputs are known in the literature as adversarial examples. In this paper we\npropose a novel probabilistic framework to generalize and extend adversarial\nattacks in order to produce a desired probability distribution for the classes\nwhen we apply the attack method to a large number of inputs. This novel attack\nstrategy provides the attacker with greater control over the target model, and\nincreases the complexity of detecting that the model is being attacked. We\nintroduce three different strategies to efficiently generate such attacks, and\nillustrate our approach extending DeepFool, a state-of-the-art attack algorithm\nto generate adversarial examples. We also experimentally validate our approach\nfor the spoken command classification task, an exemplary machine learning\nproblem in the audio domain. Our results demonstrate that we can closely\napproximate any probability distribution for the classes while maintaining a\nhigh fooling rate and by injecting imperceptible perturbations to the inputs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 09:39:02 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Vadillo", "Jon", ""], ["Santana", "Roberto", ""], ["Lozano", "Jose A.", ""]]}, {"id": "2004.06384", "submitter": "Shengbin Jia", "authors": "Shengbin Jia, Ling Ding, Xiaojun Chen, Shijia E, Yang Xiang", "title": "Incorporating Uncertain Segmentation Information into Chinese NER for\n  Social Media Text", "comments": "SocialNLP@ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese word segmentation is necessary to provide word-level information for\nChinese named entity recognition (NER) systems. However, segmentation error\npropagation is a challenge for Chinese NER while processing colloquial data\nlike social media text. In this paper, we propose a model (UIcwsNN) that\nspecializes in identifying entities from Chinese social media text, especially\nby leveraging ambiguous information of word segmentation. Such uncertain\ninformation contains all the potential segmentation states of a sentence that\nprovides a channel for the model to infer deep word-level characteristics. We\npropose a trilogy (i.e., candidate position embedding -> position selective\nattention -> adaptive word convolution) to encode uncertain word segmentation\ninformation and acquire appropriate word-level representation. Experiments\nresults on the social media corpus show that our model alleviates the\nsegmentation error cascading trouble effectively, and achieves a significant\nperformance improvement of more than 2% over previous state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 09:39:35 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 09:10:35 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jia", "Shengbin", ""], ["Ding", "Ling", ""], ["Chen", "Xiaojun", ""], ["E", "Shijia", ""], ["Xiang", "Yang", ""]]}, {"id": "2004.06402", "submitter": "Onur Tasar", "authors": "Onur Tasar, Yuliya Tarabalka, Alain Giros, Pierre Alliez, S\\'ebastien\n  Clerc", "title": "StandardGAN: Multi-source Domain Adaptation for Semantic Segmentation of\n  Very High Resolution Satellite Images by Data Standardization", "comments": "Accepted at CVPR EarthVision Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation for semantic segmentation has recently been actively\nstudied to increase the generalization capabilities of deep learning models.\nThe vast majority of the domain adaptation methods tackle single-source case,\nwhere the model trained on a single source domain is adapted to a target\ndomain. However, these methods have limited practical real world applications,\nsince usually one has multiple source domains with different data\ndistributions. In this work, we deal with the multi-source domain adaptation\nproblem. Our method, namely StandardGAN, standardizes each source and target\ndomains so that all the data have similar data distributions. We then use the\nstandardized source domains to train a classifier and segment the standardized\ntarget domain. We conduct extensive experiments on two remote sensing data\nsets, in which the first one consists of multiple cities from a single country,\nand the other one contains multiple cities from different countries. Our\nexperimental results show that the standardized data generated by StandardGAN\nallow the classifiers to generate significantly better segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 10:16:50 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Tasar", "Onur", ""], ["Tarabalka", "Yuliya", ""], ["Giros", "Alain", ""], ["Alliez", "Pierre", ""], ["Clerc", "S\u00e9bastien", ""]]}, {"id": "2004.06427", "submitter": "Shu Liu", "authors": "Shu Liu, Wei Li, Yunfang Wu, Qi Su, Xu Sun", "title": "Jointly Modeling Aspect and Sentiment with Dynamic Heterogeneous Graph\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target-Based Sentiment Analysis aims to detect the opinion aspects (aspect\nextraction) and the sentiment polarities (sentiment detection) towards them.\nBoth the previous pipeline and integrated methods fail to precisely model the\ninnate connection between these two objectives. In this paper, we propose a\nnovel dynamic heterogeneous graph to jointly model the two objectives in an\nexplicit way. Both the ordinary words and sentiment labels are treated as nodes\nin the heterogeneous graph, so that the aspect words can interact with the\nsentiment information. The graph is initialized with multiple types of\ndependencies, and dynamically modified during real-time prediction. Experiments\non the benchmark datasets show that our model outperforms the state-of-the-art\nmodels. Further analysis demonstrates that our model obtains significant\nperformance gain on the challenging instances under multiple-opinion aspects\nand no-opinion aspect situations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 11:27:30 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Liu", "Shu", ""], ["Li", "Wei", ""], ["Wu", "Yunfang", ""], ["Su", "Qi", ""], ["Sun", "Xu", ""]]}, {"id": "2004.06443", "submitter": "Lulu Kang", "authors": "Yiwei Wang, Jiuhai Chen, Chun Liu, Lulu Kang", "title": "Particle-based Energetic Variational Inference", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new variational inference (VI) framework, called energetic\nvariational inference (EVI). It minimizes the VI objective function based on a\nprescribed energy-dissipation law. Using the EVI framework, we can derive many\nexisting Particle-based Variational Inference (ParVI) methods, including the\npopular Stein Variational Gradient Descent (SVGD) approach. More importantly,\nmany new ParVI schemes can be created under this framework. For illustration,\nwe propose a new particle-based EVI scheme, which performs the particle-based\napproximation of the density first and then uses the approximated density in\nthe variational procedure, or \"Approximation-then-Variation\" for short. Thanks\nto this order of approximation and variation, the new scheme can maintain the\nvariational structure at the particle level, and can significantly decrease the\nKL-divergence in each iteration. Numerical experiments show the proposed method\noutperforms some existing ParVI methods in terms of fidelity to the target\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:14:08 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 18:55:35 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 15:02:28 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 18:29:58 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Wang", "Yiwei", ""], ["Chen", "Jiuhai", ""], ["Liu", "Chun", ""], ["Kang", "Lulu", ""]]}, {"id": "2004.06445", "submitter": "Amir Abdollahi", "authors": "Maryam Rahbaralam, Amir Abdollahi, Daniel Fern\\`andez-Garcia, Xavier\n  Sanchez-Vila", "title": "Stochastic modeling of non-linear adsorption with Gaussian kernel\n  density estimators", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adsorption is a relevant process in many fields, such as product\nmanufacturing or pollution remediation in porous materials. Adsorption takes\nplace at the molecular scale, amenable to be modeled by Lagrangian numerical\nmethods. We have proposed a chemical diffusion-reaction model for the\nsimulation of adsorption, based on the combination of a random walk particle\ntracking method involving the use of Gaussian Kernel Density Estimators. The\nmain feature of the proposed model is that it can effectively reproduce the\nnonlinear behavior characteristic of the Langmuir and Freundlich isotherms. In\nthe former, it is enough to add a finite number of sorption sites of\nhomogeneous sorption properties, and to set the process as the combination of\nthe forward and the backward reactions, each one of them with a prespecified\nreaction rate. To model the Freundlich isotherm instead, typical of low to\nintermediate range of solute concentrations, there is a need to assign a\ndifferent equilibrium constant to each specific sorption site, provided they\nare all drawn from a truncated power-law distribution. Both nonlinear models\ncan be combined in a single framework to obtain a typical observed behavior for\na wide range of concentration values.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:21:33 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Rahbaralam", "Maryam", ""], ["Abdollahi", "Amir", ""], ["Fern\u00e0ndez-Garcia", "Daniel", ""], ["Sanchez-Vila", "Xavier", ""]]}, {"id": "2004.06448", "submitter": "Huimin Peng", "authors": "Huimin Peng", "title": "Measurement Error in Nutritional Epidemiology: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews bias-correction models for measurement error of exposure\nvariables in the field of nutritional epidemiology. Measurement error usually\nattenuates estimated slope towards zero. Due to the influence of measurement\nerror, inference of parameter estimate is conservative and confidence interval\nof the slope parameter is too narrow. Bias-correction in estimators and\nconfidence intervals are of primary interest. We review the following\nbias-correction models: regression calibration methods, likelihood based\nmodels, missing data models, simulation based methods, nonparametric models and\nsampling based procedures.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 12:31:32 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 09:35:18 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Peng", "Huimin", ""]]}, {"id": "2004.06480", "submitter": "Astik Biswas", "authors": "N. Wilkinson, A. Biswas, E. Y{\\i}lmaz, F. de Wet, E. van der\n  Westhuizen, T.R. Niesler", "title": "Semi-supervised acoustic modelling for five-lingual code-switched ASR\n  using automatically-segmented soap opera speech", "comments": "SLTU 2020. arXiv admin note: text overlap with arXiv:2003.03135", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the impact of automatic segmentation on the\nfully-automatic, semi-supervised training of automatic speech recognition (ASR)\nsystems for five-lingual code-switched (CS) speech. Four automatic segmentation\ntechniques were evaluated in terms of the recognition performance of an ASR\nsystem trained on the resulting segments in a semi-supervised manner. The\nsystem's output was compared with the recognition rates achieved by a\nsemi-supervised system trained on manually assigned segments. Three of the\nautomatic techniques use a newly proposed convolutional neural network (CNN)\nmodel for framewise classification, and include a novel form of HMM smoothing\nof the CNN outputs. Automatic segmentation was applied in combination with\nautomatic speaker diarization. The best-performing segmentation technique was\nalso tested without speaker diarization. An evaluation based on 248 unsegmented\nsoap opera episodes indicated that voice activity detection (VAD) based on a\nCNN followed by Gaussian mixture modelhidden Markov model smoothing\n(CNN-GMM-HMM) yields the best ASR performance. The semi-supervised system\ntrained with the resulting segments achieved an overall WER improvement of 1.1%\nabsolute over the system trained with manually created segments. Furthermore,\nwe found that system performance improved even further when the automatic\nsegmentation was used in conjunction with speaker diarization.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 04:36:25 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Wilkinson", "N.", ""], ["Biswas", "A.", ""], ["Y\u0131lmaz", "E.", ""], ["de Wet", "F.", ""], ["van der Westhuizen", "E.", ""], ["Niesler", "T. R.", ""]]}, {"id": "2004.06481", "submitter": "Tomoko Nagai", "authors": "Tomoko Nagai", "title": "The covariance matrix of Green's functions and its application to\n  machine learning", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a regression algorithm based on Green's function theory is\nproposed and implemented. We first survey Green's function for the Dirichlet\nboundary value problem of 2nd order linear ordinary differential equation,\nwhich is a reproducing kernel of a suitable Hilbert space. We next consider a\ncovariance matrix composed of the normalized Green's function, which is\nregarded as aprobability density function. By supporting Bayesian approach, the\ncovariance matrix gives predictive distribution, which has the predictive mean\n$\\mu$ and the confidence interval [$\\mu$-2s, $\\mu$+2s], where s stands for a\nstandard deviation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:26:01 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Nagai", "Tomoko", ""]]}, {"id": "2004.06490", "submitter": "Chao Yang", "authors": "Hailong Sheng and Chao Yang", "title": "PFNN: A Penalty-Free Neural Network Method for Solving a Class of\n  Second-Order Boundary-Value Problems on Complex Geometries", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.110085", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PFNN, a penalty-free neural network method, to efficiently solve a\nclass of second-order boundary-value problems on complex geometries. To reduce\nthe smoothness requirement, the original problem is reformulated to a weak form\nso that the evaluations of high-order derivatives are avoided. Two neural\nnetworks, rather than just one, are employed to construct the approximate\nsolution, with one network satisfying the essential boundary conditions and the\nother handling the rest part of the domain. In this way, an unconstrained\noptimization problem, instead of a constrained one, is solved without adding\nany penalty terms. The entanglement of the two networks is eliminated with the\nhelp of a length factor function that is scale invariant and can adapt with\ncomplex geometries. We prove the convergence of the PFNN method and conduct\nnumerical experiments on a series of linear and nonlinear second-order\nboundary-value problems to demonstrate that PFNN is superior to several\nexisting approaches in terms of accuracy, flexibility and robustness.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:36:14 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 12:21:02 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Sheng", "Hailong", ""], ["Yang", "Chao", ""]]}, {"id": "2004.06493", "submitter": "Vikram Jadhao", "authors": "JCS Kadupitiya and Geoffrey C. Fox and Vikram Jadhao", "title": "Deep Learning Based Integrators for Solving Newton's Equations with\n  Large Timesteps", "comments": "14 pages, 11 figures; content is revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.soft cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical molecular dynamics simulations are based on Newton's equations of\nmotion and rely on numerical integrators to solve them. Using a small timestep\nto avoid discretization errors, Verlet integrators generate a trajectory of\nparticle positions as solutions to Newton's equations. We introduce an\nintegrator based on deep neural networks that is trained on trajectories\ngenerated using the Verlet integrator and learns to propagate the dynamics of\nparticles with timestep up to 4000$\\times$ larger compared to the Verlet\ntimestep. We demonstrate significant net speedup of up to 32000 for 1 - 16\nparticle 3D systems and over a variety of force fields.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 16:15:21 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 23:09:34 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kadupitiya", "JCS", ""], ["Fox", "Geoffrey C.", ""], ["Jadhao", "Vikram", ""]]}, {"id": "2004.06496", "submitter": "Michael Everett", "authors": "Michael Everett, Bjorn Lutjens, Jonathan P. How", "title": "Certifiable Robustness to Adversarial State Uncertainty in Deep\n  Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1910.12908", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network-based systems are now the state-of-the-art in many\nrobotics tasks, but their application in safety-critical domains remains\ndangerous without formal guarantees on network robustness. Small perturbations\nto sensor inputs (from noise or adversarial examples) are often enough to\nchange network-based decisions, which was recently shown to cause an autonomous\nvehicle to swerve into another lane. In light of these dangers, numerous\nalgorithms have been developed as defensive mechanisms from these adversarial\ninputs, some of which provide formal robustness guarantees or certificates.\nThis work leverages research on certified adversarial robustness to develop an\nonline certifiably robust for deep reinforcement learning algorithms. The\nproposed defense computes guaranteed lower bounds on state-action values during\nexecution to identify and choose a robust action under a worst-case deviation\nin input space due to possible adversaries or noise. Moreover, the resulting\npolicy comes with a certificate of solution quality, even though the true state\nand optimal action are unknown to the certifier due to the perturbations. The\napproach is demonstrated on a Deep Q-Network policy and is shown to increase\nrobustness to noise and adversaries in pedestrian collision avoidance scenarios\nand a classic control task. This work extends one of our prior works with new\nperformance guarantees, extensions to other RL algorithms, expanded results\naggregated across more scenarios, an extension into scenarios with adversarial\nbehavior, comparisons with a more computationally expensive method, and\nvisualizations that provide intuition about the robustness algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 21:36:13 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 22:02:21 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 16:57:54 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 17:15:40 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 02:21:10 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Everett", "Michael", ""], ["Lutjens", "Bjorn", ""], ["How", "Jonathan P.", ""]]}, {"id": "2004.06502", "submitter": "Kangning Liu", "authors": "Kangning Liu, Shuhang Gu, Andres Romero, Radu Timofte", "title": "Unsupervised Multimodal Video-to-Video Translation via Self-Supervised\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing unsupervised video-to-video translation methods fail to produce\ntranslated videos which are frame-wise realistic, semantic information\npreserving and video-level consistent. In this work, we propose UVIT, a novel\nunsupervised video-to-video translation model. Our model decomposes the style\nand the content, uses the specialized encoder-decoder structure and propagates\nthe inter-frame information through bidirectional recurrent neural network\n(RNN) units. The style-content decomposition mechanism enables us to achieve\nstyle consistent video translation results as well as provides us with a good\ninterface for modality flexible translation. In addition, by changing the input\nframes and style codes incorporated in our translation, we propose a video\ninterpolation loss, which captures temporal information within the sequence to\ntrain our building blocks in a self-supervised manner. Our model can produce\nphoto-realistic, spatio-temporal consistent translated videos in a multimodal\nway. Subjective and objective experimental results validate the superiority of\nour model over existing methods. More details can be found on our project\nwebsite: https://uvit.netlify.com\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:44:30 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Liu", "Kangning", ""], ["Gu", "Shuhang", ""], ["Romero", "Andres", ""], ["Timofte", "Radu", ""]]}, {"id": "2004.06510", "submitter": "Brian Subirana", "authors": "Brian Subirana, Ferran Hueto, Prithvi Rajasekaran, Jordi Laguarta,\n  Susana Puig, Josep Malvehy, Oriol Mitja, Antoni Trilla, Carlos Iv\\'an Moreno,\n  Jos\\'e Francisco Mu\\~noz Valle, Ana Esther Mercado Gonz\\'alez, Barbara\n  Vizmanos, Sanjay Sarma", "title": "Hi Sigma, do I have the Coronavirus?: Call for a New Artificial\n  Intelligence Approach to Support Health Care Professionals Dealing With The\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": "MIT Auto-ID Laboratory, Report 2020-4-10-1", "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just like your phone can detect what song is playing in crowded spaces, we\nshow that Artificial Intelligence transfer learning algorithms trained on cough\nphone recordings results in diagnostic tests for COVID-19. To gain adoption by\nthe health care community, we plan to validate our results in a clinical trial\nand three other venues in Mexico, Spain and the USA . However, if we had data\nfrom other on-going clinical trials and volunteers, we may do much more. For\nexample, for confirmed stay-at-home COVID-19 patients, a longitudinal audio\ntest could be developed to determine contact-with-hospital recommendations, and\nfor the most critical COVID-19 patients a success ratio forecast test,\nincluding patient clinical data, to prioritize ICU allocation. As a challenge\nto the engineering community and in the context of our clinical trial, the\nauthors suggest distributing cough recordings daily, hoping other trials and\ncrowdsourcing users will contribute more data. Previous approaches to complex\nAI tasks have either used a static dataset or were private efforts led by large\ncorporations. All existing COVID-19 trials published also follow this paradigm.\nInstead, we suggest a novel open collective approach to large-scale real-time\nhealth care AI. We will be posting updates at https://opensigma.mit.edu. Our\npersonal view is that our approach is the right one for large scale pandemics,\nand therefore is here to stay - will you join?\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 21:03:49 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Subirana", "Brian", ""], ["Hueto", "Ferran", ""], ["Rajasekaran", "Prithvi", ""], ["Laguarta", "Jordi", ""], ["Puig", "Susana", ""], ["Malvehy", "Josep", ""], ["Mitja", "Oriol", ""], ["Trilla", "Antoni", ""], ["Moreno", "Carlos Iv\u00e1n", ""], ["Valle", "Jos\u00e9 Francisco Mu\u00f1oz", ""], ["Gonz\u00e1lez", "Ana Esther Mercado", ""], ["Vizmanos", "Barbara", ""], ["Sarma", "Sanjay", ""]]}, {"id": "2004.06517", "submitter": "Adalberto Claudio Quiros", "authors": "Adalberto Claudio Quiros, Roderick Murray-Smith, and Ke Yuan", "title": "Learning a low dimensional manifold of real cancer tissue with\n  PathologyGAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Application of deep learning in digital pathology shows promise on improving\ndisease diagnosis and understanding. We present a deep generative model that\nlearns to simulate high-fidelity cancer tissue images while mapping the real\nimages onto an interpretable low dimensional latent space. The key to the model\nis an encoder trained by a previously developed generative adversarial network,\nPathologyGAN. We study the latent space using 249K images from two breast\ncancer cohorts. We find that the latent space encodes morphological\ncharacteristics of tissues (e.g. patterns of cancer, lymphocytes, and stromal\ncells). In addition, the latent space reveals distinctly enriched clusters of\ntissue architectures in the high-risk patient group.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:18:00 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Quiros", "Adalberto Claudio", ""], ["Murray-Smith", "Roderick", ""], ["Yuan", "Ke", ""]]}, {"id": "2004.06518", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Tolu Odukoya, Philip Potter,\n  Laura E. Barnes, Donald E. Brown", "title": "Gender Detection on Social Networks using Ensemble Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-63128-4_26", "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the ever-increasing volume of posts on social media sites such as\nFacebook and Twitter requires improved information processing methods for\nprofiling authorship. Document classification is central to this task, but the\nperformance of traditional supervised classifiers has degraded as the volume of\nsocial media has increased. This paper addresses this problem in the context of\ngender detection through ensemble classification that employs multi-model deep\nlearning architectures to generate specialized understanding from different\nfeature spaces.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 15:08:49 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 17:25:00 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 21:54:34 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Odukoya", "Tolu", ""], ["Potter", "Philip", ""], ["Barnes", "Laura E.", ""], ["Brown", "Donald E.", ""]]}, {"id": "2004.06524", "submitter": "Viktoriia Sharmanska", "authors": "Viktoriia Sharmanska, Lisa Anne Hendricks, Trevor Darrell, Novi\n  Quadrianto", "title": "Contrastive Examples for Addressing the Tyranny of the Majority", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision algorithms, e.g. for face recognition, favour groups of\nindividuals that are better represented in the training data. This happens\nbecause of the generalization that classifiers have to make. It is simpler to\nfit the majority groups as this fit is more important to overall error. We\npropose to create a balanced training dataset, consisting of the original\ndataset plus new data points in which the group memberships are intervened,\nminorities become majorities and vice versa. We show that current generative\nadversarial networks are a powerful tool for learning these data points, called\ncontrastive examples. We experiment with the equalized odds bias measure on\ntabular data as well as image data (CelebA and Diversity in Faces datasets).\nContrastive examples allow us to expose correlations between group membership\nand other seemingly neutral features. Whenever a causal graph is available, we\ncan put those contrastive examples in the perspective of counterfactuals.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:06:44 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Sharmanska", "Viktoriia", ""], ["Hendricks", "Lisa Anne", ""], ["Darrell", "Trevor", ""], ["Quadrianto", "Novi", ""]]}, {"id": "2004.06531", "submitter": "Baiming Chen", "authors": "Baiming Chen, Xiang Chen, Wu Qiong, Liang Li", "title": "Adversarial Evaluation of Autonomous Vehicles in Lane-Change Scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles must be comprehensively evaluated before deployed in\ncities and highways. However, most existing evaluation approaches for\nautonomous vehicles are static and lack adaptability, so they are usually\ninefficient in generating challenging scenarios for tested vehicles. In this\npaper, we propose an adaptive evaluation framework to efficiently evaluate\nautonomous vehicles in adversarial environments generated by deep reinforcement\nlearning. Considering the multimodal nature of dangerous scenarios, we use\nensemble models to represent different local optimums for diversity. We then\nutilize a nonparametric Bayesian method to cluster the adversarial policies.\nThe proposed method is validated in a typical lane-change scenario that\ninvolves frequent interactions between the ego vehicle and the surrounding\nvehicles. Results show that the adversarial scenarios generated by our method\nsignificantly degrade the performance of the tested vehicles. We also\nillustrate different patterns of generated adversarial environments, which can\nbe used to infer the weaknesses of the tested vehicles.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:12:17 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:27:40 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Chen", "Baiming", ""], ["Chen", "Xiang", ""], ["Qiong", "Wu", ""], ["Li", "Liang", ""]]}, {"id": "2004.06558", "submitter": "Arnaud Dapogny", "authors": "Arnaud Dapogny, K\\'evin Bailly and Matthieu Cord", "title": "Deep Entwined Learning Head Pose and Face Alignment Inside an\n  Attentional Cascade with Doubly-Conditional fusion", "comments": "Accepted for publication as an oral session @IEEE FG2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Head pose estimation and face alignment constitute a backbone preprocessing\nfor many applications relying on face analysis. While both are closely related\ntasks, they are generally addressed separately, e.g. by deducing the head pose\nfrom the landmark locations. In this paper, we propose to entwine face\nalignment and head pose tasks inside an attentional cascade. This cascade uses\na geometry transfer network for integrating heterogeneous annotations to\nenhance landmark localization accuracy. Furthermore, we propose a\ndoubly-conditional fusion scheme to select relevant feature maps, and regions\nthereof, based on a current head pose and landmark localization estimate. We\nempirically show the benefit of entwining head pose and landmark localization\nobjectives inside our architecture, and that the proposed AC-DC model enhances\nthe state-of-the-art accuracy on multiple databases for both face alignment and\nhead pose estimation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:42:35 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Dapogny", "Arnaud", ""], ["Bailly", "K\u00e9vin", ""], ["Cord", "Matthieu", ""]]}, {"id": "2004.06560", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Breaking the waves: asymmetric random periodic features for low-bitrate\n  kernel machines", "comments": null, "journal-ref": "Information and Inference: A Journal of the IMA (2021)", "doi": "10.1093/imaiai/iaab008", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many signal processing and machine learning applications are built from\nevaluating a kernel on pairs of signals, e.g. to assess the similarity of an\nincoming query to a database of known signals. This nonlinear evaluation can be\nsimplified to a linear inner product of the random Fourier features of those\nsignals: random projections followed by a periodic map, the complex\nexponential. It is known that a simple quantization of those features\n(corresponding to replacing the complex exponential by a different periodic map\nthat takes binary values, which is appealing for their transmission and\nstorage), distorts the approximated kernel, which may be undesirable in\npractice. Our take-home message is that when the features of only one of the\ntwo signals are quantized, the original kernel is recovered without distortion;\nits practical interest appears in several cases where the kernel evaluations\nare asymmetric by nature, such as a client-server scheme. Concretely, we\nintroduce the general framework of asymmetric random periodic features, where\nthe two signals of interest are observed through random periodic features:\nrandom projections followed by a general periodic map, which is allowed to be\ndifferent for both signals. We derive the influence of those periodic maps on\nthe approximated kernel, and prove uniform probabilistic error bounds holding\nfor all signal pairs from an infinite low-complexity set. Interestingly, our\nresults allow the periodic maps to be discontinuous, thanks to a new\nmathematical tool, i.e. the mean Lipschitz smoothness. We then apply this\ngeneric framework to semi-quantized kernel machines (where only one signal has\nquantized features and the other has classical random Fourier features), for\nwhich we show theoretically that the approximated kernel remains unchanged\n(with the associated error bound), and confirm the power of the approach with\nnumerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:44:54 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 11:00:15 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 10:57:05 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "2004.06565", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Robert E. Tillman, Prashant Reddy, Manuela Veloso", "title": "Bayesian Consensus: Consensus Estimates from Miscalibrated Instruments\n  under Heteroscedastic Noise", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness and Privacy", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating predictions or measurements from a set\nof human forecasters, models, sensors or other instruments which may be subject\nto bias or miscalibration and random heteroscedastic noise. We propose a\nBayesian consensus estimator that adjusts for miscalibration and noise and show\nthat this estimator is unbiased and asymptotically more efficient than naive\nalternatives. We further propose a Hierarchical Bayesian Model that leverages\nour proposed estimator and apply it to two real world forecasting challenges\nthat require consensus estimates from error prone individual estimates:\nforecasting influenza like illness (ILI) weekly percentages and forecasting\nannual earnings of public companies. We demonstrate that our approach is\neffective at mitigating bias and error and results in more accurate forecasts\nthan existing consensus models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:10:21 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 23:49:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nagpal", "Chirag", ""], ["Tillman", "Robert E.", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.06567", "submitter": "Dominik Fay", "authors": "Dominik Fay, Jens Sj\\\"olund and Tobias J. Oechtering", "title": "Decentralized Differentially Private Segmentation with PATE", "comments": "Under review for MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to preserving privacy in medical machine learning, two\nimportant considerations are (1) keeping data local to the institution and (2)\navoiding inference of sensitive information from the trained model. These are\noften addressed using federated learning and differential privacy,\nrespectively. However, the commonly used Federated Averaging algorithm requires\na high degree of synchronization between participating institutions. For this\nreason, we turn our attention to Private Aggregation of Teacher Ensembles\n(PATE), where all local models can be trained independently without\ninter-institutional communication. The purpose of this paper is thus to explore\nhow PATE -- originally designed for classification -- can best be adapted for\nsemantic segmentation. To this end, we build low-dimensional representations of\nsegmentation masks which the student can obtain through low-sensitivity queries\nto the private aggregator. On the Brain Tumor Segmentation (BraTS 2019)\ndataset, an Autoencoder-based PATE variant achieves a higher Dice coefficient\nfor the same privacy guarantee than prior work based on noisy Federated\nAveraging.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 00:05:48 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Fay", "Dominik", ""], ["Sj\u00f6lund", "Jens", ""], ["Oechtering", "Tobias J.", ""]]}, {"id": "2004.06568", "submitter": "Abhik Ghosh PhD", "authors": "Abhik Ghosh, Rita SahaRay, Sayan Chakrabarty, Sayan Bhadra", "title": "Robust Generalised Quadratic Discriminant Analysis", "comments": "Pre-print. Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic discriminant analysis (QDA) is a widely used statistical tool to\nclassify observations from different multivariate Normal populations. The\ngeneralized quadratic discriminant analysis (GQDA) classification\nrule/classifier, which generalizes the QDA and the minimum Mahalanobis distance\n(MMD) classifiers to discriminate between populations with underlying\nelliptically symmetric distributions competes quite favorably with the QDA\nclassifier when it is optimal and performs much better when QDA fails under\nnon-Normal underlying distributions, e.g. Cauchy distribution. However, the\nclassification rule in GQDA is based on the sample mean vector and the sample\ndispersion matrix of a training sample, which are extremely non-robust under\ndata contamination. In real world, since it is quite common to face data highly\nvulnerable to outliers, the lack of robustness of the classical estimators of\nthe mean vector and the dispersion matrix reduces the efficiency of the GQDA\nclassifier significantly, increasing the misclassification errors. The present\npaper investigates the performance of the GQDA classifier when the classical\nestimators of the mean vector and the dispersion matrix used therein are\nreplaced by various robust counterparts. Applications to various real data sets\nas well as simulation studies reveal far better performance of the proposed\nrobust versions of the GQDA classifier. A Comparative study has been made to\nadvocate the appropriate choice of the robust estimators to be used in a\nspecific situation of the degree of contamination of the data sets.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:21:06 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ghosh", "Abhik", ""], ["SahaRay", "Rita", ""], ["Chakrabarty", "Sayan", ""], ["Bhadra", "Sayan", ""]]}, {"id": "2004.06569", "submitter": "Davood Karimi", "authors": "Davood Karimi, Ali Gholipour", "title": "Improving Calibration and Out-of-Distribution Detection in Medical Image\n  Segmentation with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have shown to be powerful medical image\nsegmentation models. In this study, we address some of the main unresolved\nissues regarding these models. Specifically, training of these models on small\nmedical image datasets is still challenging, with many studies promoting\ntechniques such as transfer learning. Moreover, these models are infamous for\nproducing over-confident predictions and for failing silently when presented\nwith out-of-distribution (OOD) data at test time. In this paper, we advocate\nfor multi-task learning, i.e., training a single model on several different\ndatasets, spanning several different organs of interest and different imaging\nmodalities. We show that not only a single CNN learns to automatically\nrecognize the context and accurately segment the organ of interest in each\ncontext, but also that such a joint model often has more accurate and\nbetter-calibrated predictions than dedicated models trained separately on each\ndataset. Our experiments show that multi-task learning can outperform transfer\nlearning in medical image segmentation tasks. For detecting OOD data, we\npropose a method based on spectral analysis of CNN feature maps. We show that\ndifferent datasets, representing different imaging modalities and/or different\norgans of interest, have distinct spectral signatures, which can be used to\nidentify whether or not a test image is similar to the images used to train a\nmodel. We show that this approach is far more accurate than OOD detection based\non prediction uncertainty. The methods proposed in this paper contribute\nsignificantly to improving the accuracy and reliability of CNN-based medical\nimage segmentation models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 23:42:51 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 13:52:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Karimi", "Davood", ""], ["Gholipour", "Ali", ""]]}, {"id": "2004.06578", "submitter": "Muhammad E. H. Chowdhury", "authors": "Tawsifur Rahman, Muhammad E. H. Chowdhury, Amith Khandakar, Khandaker\n  R. Islam, Khandaker F. Islam, Zaid B. Mahbub, Muhammad A. Kadir, Saad Kashem", "title": "Transfer Learning with Deep Convolutional Neural Network (CNN) for\n  Pneumonia Detection using Chest X-ray", "comments": "13 Figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:2003.13145", "journal-ref": "Appl. Sci. 2020, 10(9), 3233", "doi": "10.3390/app10093233", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pneumonia is a life-threatening disease, which occurs in the lungs caused by\neither bacterial or viral infection. It can be life-endangering if not acted\nupon in the right time and thus an early diagnosis of pneumonia is vital. The\naim of this paper is to automatically detect bacterial and viral pneumonia\nusing digital x-ray images. It provides a detailed report on advances made in\nmaking accurate detection of pneumonia and then presents the methodology\nadopted by the authors. Four different pre-trained deep Convolutional Neural\nNetwork (CNN)- AlexNet, ResNet18, DenseNet201, and SqueezeNet were used for\ntransfer learning. 5247 Bacterial, viral and normal chest x-rays images\nunderwent preprocessing techniques and the modified images were trained for the\ntransfer learning based classification task. In this work, the authors have\nreported three schemes of classifications: normal vs pneumonia, bacterial vs\nviral pneumonia and normal, bacterial and viral pneumonia. The classification\naccuracy of normal and pneumonia images, bacterial and viral pneumonia images,\nand normal, bacterial and viral pneumonia were 98%, 95%, and 93.3%\nrespectively. This is the highest accuracy in any scheme than the accuracies\nreported in the literature. Therefore, the proposed study can be useful in\nfaster-diagnosing pneumonia by the radiologist and can help in the fast airport\nscreening of pneumonia patients.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:03:48 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Rahman", "Tawsifur", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khandakar", "Amith", ""], ["Islam", "Khandaker R.", ""], ["Islam", "Khandaker F.", ""], ["Mahbub", "Zaid B.", ""], ["Kadir", "Muhammad A.", ""], ["Kashem", "Saad", ""]]}, {"id": "2004.06587", "submitter": "Andre Kelm", "authors": "Andr\\'e Peter Kelm and Udo Z\\\"olzer", "title": "Walk the Lines: Object Contour Tracing CNN for Contour Completion of\n  Ships", "comments": "Submission to the ICPR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new contour tracing algorithm to enhance the results of the\nlatest object contour detectors. The goal is to achieve a perfectly closed, 1\npixel wide and detailed object contour, since this type of contour could be\nanalyzed using methods such as Fourier descriptors. Convolutional Neural\nNetworks (CNNs) are rarely used for contour tracing. However, we find CNNs are\ntailor-made for this task and that's why we present the Walk the Lines (WtL)\nalgorithm, a standard regression CNN trained to follow object contours. To make\nthe first step, we train the CNN only on ship contours, but the principle is\nalso applicable to other objects. Input data are the image and the associated\nobject contour prediction of the recently published RefineContourNet. The WtL\ngets a center pixel, which defines an input section and an angle for rotating\nthis section. Ideally, the center pixel moves on the contour, while the angle\ndescribes upcoming directional contour changes. The WtL predicts its steps\npixelwise in a selfrouting way. To obtain a complete object contour the WtL\nruns in parallel at different image locations and the traces of its individual\npaths are summed. In contrast to the comparable Non-Maximum Suppression method,\nour approach produces connected contours with finer details. Finally, the\nobject contour is binarized under the condition of being closed. In case all\nprocedures work as desired, excellent ship segmentations with high IoUs are\nproduced, showing details such as antennas and ship superstructures that are\neasily omitted by other segmentation methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:19:04 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kelm", "Andr\u00e9 Peter", ""], ["Z\u00f6lzer", "Udo", ""]]}, {"id": "2004.06599", "submitter": "Songyan Xue", "authors": "Songyan Xue, Yi Ma, Na Yi and Rahim Tafazolli", "title": "On Deep Learning Solutions for Joint Transmitter and Noncoherent\n  Receiver Design in MU-MIMO Systems", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to handle the joint transmitter and noncoherent receiver\ndesign for multiuser multiple-input multiple-output (MU-MIMO) systems through\ndeep learning. Given the deep neural network (DNN) based noncoherent receiver,\nthe novelty of this work mainly lies in the multiuser waveform design at the\ntransmitter side. According to the signal format, the proposed deep learning\nsolutions can be divided into two groups. One group is called pilot-aided\nwaveform, where the information-bearing symbols are time-multiplexed with the\npilot symbols. The other is called learning-based waveform, where the multiuser\nwaveform is partially or even completely designed by deep learning algorithms.\nSpecifically, if the information-bearing symbols are directly embedded in the\nwaveform, it is called systematic waveform. Otherwise, it is called\nnon-systematic waveform, where no artificial design is involved. Simulation\nresults show that the pilot-aided waveform design outperforms the conventional\nzero forcing receiver with least squares (LS) channel estimation on small-size\nMU-MIMO systems. By exploiting the time-domain degrees of freedom (DoF), the\nlearning-based waveform design further improves the detection performance by at\nleast 5 dB at high signal-to-noise ratio (SNR) range. Moreover, it is found\nthat the traditional weight initialization method might cause a training\nimbalance among different users in the learning-based waveform design. To\ntackle this issue, a novel weight initialization method is proposed which\nprovides a balanced convergence performance with no complexity penalty.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:27:15 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Xue", "Songyan", ""], ["Ma", "Yi", ""], ["Yi", "Na", ""], ["Tafazolli", "Rahim", ""]]}, {"id": "2004.06608", "submitter": "Danushka Bollegala", "authors": "Xia Cui and Danushka Bollegala", "title": "Multi-source Attention for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation considers the problem of generalising a model learnt using\ndata from a particular source domain to a different target domain. Often it is\ndifficult to find a suitable single source to adapt from, and one must consider\nmultiple sources. Using an unrelated source can result in sub-optimal\nperformance, known as the \\emph{negative transfer}. However, it is challenging\nto select the appropriate source(s) for classifying a given target instance in\nmulti-source unsupervised domain adaptation (UDA). We model source-selection as\nan attention-learning problem, where we learn attention over sources for a\ngiven target instance. For this purpose, we first independently learn\nsource-specific classification models, and a relatedness map between sources\nand target domains using pseudo-labelled target domain instances. Next, we\nlearn attention-weights over the sources for aggregating the predictions of the\nsource-specific models. Experimental results on cross-domain sentiment\nclassification benchmarks show that the proposed method outperforms prior\nproposals in multi-source UDA.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:51:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:48:36 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Cui", "Xia", ""], ["Bollegala", "Danushka", ""]]}, {"id": "2004.06627", "submitter": "Thibaut Theate", "authors": "Thibaut Th\\'eate, Damien Ernst", "title": "An Application of Deep Reinforcement Learning to Algorithmic Trading", "comments": "Preprint submitted to Elsevier journal \"Expert Systems with\n  Applications\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This scientific research paper presents an innovative approach based on deep\nreinforcement learning (DRL) to solve the algorithmic trading problem of\ndetermining the optimal trading position at any point in time during a trading\nactivity in stock markets. It proposes a novel DRL trading strategy so as to\nmaximise the resulting Sharpe ratio performance indicator on a broad range of\nstock markets. Denominated the Trading Deep Q-Network algorithm (TDQN), this\nnew trading strategy is inspired from the popular DQN algorithm and\nsignificantly adapted to the specific algorithmic trading problem at hand. The\ntraining of the resulting reinforcement learning (RL) agent is entirely based\non the generation of artificial trajectories from a limited set of stock market\nhistorical data. In order to objectively assess the performance of trading\nstrategies, the research paper also proposes a novel, more rigorous performance\nassessment methodology. Following this new performance assessment approach,\npromising results are reported for the TDQN strategy.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 14:57:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:01:06 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 12:09:03 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Th\u00e9ate", "Thibaut", ""], ["Ernst", "Damien", ""]]}, {"id": "2004.06632", "submitter": "Leonid Datta", "authors": "Leonid Datta", "title": "A Survey on Activation Functions and their relation with Xavier and He\n  Normal Initialization", "comments": "17 Pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In artificial neural network, the activation function and the weight\ninitialization method play important roles in training and performance of a\nneural network. The question arises is what properties of a function are\nimportant/necessary for being a well-performing activation function. Also, the\nmost widely used weight initialization methods - Xavier and He normal\ninitialization have fundamental connection with activation function. This\nsurvey discusses the important/necessary properties of activation function and\nthe most widely used activation functions (sigmoid, tanh, ReLU, LReLU and\nPReLU). This survey also explores the relationship between these activation\nfunctions and the two weight initialization methods - Xavier and He normal\ninitialization.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 18:17:56 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Datta", "Leonid", ""]]}, {"id": "2004.06633", "submitter": "Chaitanya Poolla", "authors": "Chaitanya Poolla, Abraham K. Ishihara, Dan Liddell, Rodney Martin,\n  Steven Rosenberg", "title": "Occupant Plugload Management for Demand Response in Commercial\n  Buildings: Field Experimentation and Statistical Characterization", "comments": "20 pages, 15 figures, 4 tables, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial buildings account for approximately 36% of US electricity\nconsumption, of which nearly two-thirds is met by fossil fuels [1] resulting in\nan adverse impact on the environment. Reducing this impact requires improving\nenergy efficiency and lowering energy consumption. Most existing studies focus\non designing methods to regulate and reduce HVAC and lighting energy\nconsumption. However, few studies have focused on the control of occupant\nplugload energy consumption. In this study, we conducted multiple experiments\nto analyze changes in occupant plugload energy consumption due to monetary\nincentives and/or feedback. The experiments were performed in government office\nand university buildings at NASA Research Park located in Moffett Field, CA.\nAnalysis of the data reveal significant plugload energy reduction can be\nachieved via feedback and/or incentive mechanisms. Autoregressive models are\nused to predict expected plugload savings in the presence of exogenous\nvariables. The results of this study suggest that occupant-in-the-loop control\narchitectures have the potential to reduce energy consumption and hence lower\nthe carbon footprint of commercial buildings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:23:34 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 21:57:47 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 02:07:59 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 15:01:50 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Poolla", "Chaitanya", ""], ["Ishihara", "Abraham K.", ""], ["Liddell", "Dan", ""], ["Martin", "Rodney", ""], ["Rosenberg", "Steven", ""]]}, {"id": "2004.06651", "submitter": "Chaoyang Wang", "authors": "Chaoyang Wang and Zhiqiang Guo and Jianjun Li and Peng Pan and Guohui\n  Li", "title": "A Text-based Deep Reinforcement Learning Framework for Interactive\n  Recommendation", "comments": "Accepted by ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to its nature of learning from dynamic interactions and planning for\nlong-run performance, reinforcement learning (RL) recently has received much\nattention in interactive recommender systems (IRSs). IRSs usually face the\nlarge discrete action space problem, which makes most of the existing RL-based\nrecommendation methods inefficient. Moreover, data sparsity is another\nchallenging problem that most IRSs are confronted with. While the textual\ninformation like reviews and descriptions is less sensitive to sparsity,\nexisting RL-based recommendation methods either neglect or are not suitable for\nincorporating textual information. To address these two problems, in this\npaper, we propose a Text-based Deep Deterministic Policy Gradient framework\n(TDDPG-Rec) for IRSs. Specifically, we leverage textual information to map\nitems and users into a feature space, which greatly alleviates the sparsity\nproblem. Moreover, we design an effective method to construct an action\ncandidate set. By the policy vector dynamically learned from TDDPG-Rec that\nexpresses the user's preference, we can select actions from the candidate set\neffectively. Through experiments on three public datasets, we demonstrate that\nTDDPG-Rec achieves state-of-the-art performance over several baselines in a\ntime-efficient manner.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:46:01 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:32:01 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 02:26:05 GMT"}, {"version": "v4", "created": "Sun, 26 Jul 2020 13:03:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Wang", "Chaoyang", ""], ["Guo", "Zhiqiang", ""], ["Li", "Jianjun", ""], ["Pan", "Peng", ""], ["Li", "Guohui", ""]]}, {"id": "2004.06660", "submitter": "Paul Michel", "authors": "Keita Kurita, Paul Michel, Graham Neubig", "title": "Weight Poisoning Attacks on Pre-trained Models", "comments": "Published as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, NLP has seen a surge in the usage of large pre-trained models.\nUsers download weights of models pre-trained on large datasets, then fine-tune\nthe weights on a task of their choice. This raises the question of whether\ndownloading untrusted pre-trained weights can pose a security threat. In this\npaper, we show that it is possible to construct ``weight poisoning'' attacks\nwhere pre-trained weights are injected with vulnerabilities that expose\n``backdoors'' after fine-tuning, enabling the attacker to manipulate the model\nprediction simply by injecting an arbitrary keyword. We show that by applying a\nregularization method, which we call RIPPLe, and an initialization procedure,\nwhich we call Embedding Surgery, such attacks are possible even with limited\nknowledge of the dataset and fine-tuning procedure. Our experiments on\nsentiment classification, toxicity detection, and spam detection show that this\nattack is widely applicable and poses a serious threat. Finally, we outline\npractical defenses against such attacks. Code to reproduce our experiments is\navailable at https://github.com/neulab/RIPPLe.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:51:42 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kurita", "Keita", ""], ["Michel", "Paul", ""], ["Neubig", "Graham", ""]]}, {"id": "2004.06668", "submitter": "Zahraa Abdallah Dr", "authors": "Zahraa S. Abdallah, Mohamed Medhat Gaber", "title": "Co-eye: A Multi-resolution Symbolic Representation to TimeSeries\n  Diversified Ensemble Classification", "comments": "to appear in Machine Learning, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) is a challenging task that attracted many\nresearchers in the last few years. One main challenge in TSC is the diversity\nof domains where time series data come from. Thus, there is no \"one model that\nfits all\" in TSC. Some algorithms are very accurate in classifying a specific\ntype of time series when the whole series is considered, while some only target\nthe existence/non-existence of specific patterns/shapelets. Yet other\ntechniques focus on the frequency of occurrences of discriminating\npatterns/features. This paper presents a new classification technique that\naddresses the inherent diversity problem in TSC using a nature-inspired method.\nThe technique is stimulated by how flies look at the world through \"compound\neyes\" that are made up of thousands of lenses, called ommatidia. Each\nommatidium is an eye with its own lens, and thousands of them together create a\nbroad field of vision. The developed technique similarly uses different lenses\nand representations to look at the time series, and then combines them for\nbroader visibility. These lenses have been created through\nhyper-parameterisation of symbolic representations (Piecewise Aggregate and\nFourier approximations). The algorithm builds a random forest for each lens,\nthen performs soft dynamic voting for classifying new instances using the most\nconfident eyes, i.e, forests. We evaluate the new technique, coined Co-eye,\nusing the recently released extended version of UCR archive, containing more\nthan 100 datasets across a wide range of domains. The results show the benefits\nof bringing together different perspectives reflecting on the accuracy and\nrobustness of Co-eye in comparison to other state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:16:22 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 10:37:35 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Abdallah", "Zahraa S.", ""], ["Gaber", "Mohamed Medhat", ""]]}, {"id": "2004.06673", "submitter": "Tongxue Zhou", "authors": "Tongxue Zhou, St\\'ephane Canu, Su Ruan", "title": "An automatic COVID-19 CT segmentation network using spatial and channel\n  attention mechanism", "comments": "14 pages, 6 figures", "journal-ref": "International journal of imaging systems and technology, 2020", "doi": "10.1002/ima.22527", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus disease (COVID-19) pandemic has led to a devastating effect\non the global public health. Computed Tomography (CT) is an effective tool in\nthe screening of COVID-19. It is of great importance to rapidly and accurately\nsegment COVID-19 from CT to help diagnostic and patient monitoring. In this\npaper, we propose a U-Net based segmentation network using attention mechanism.\nAs not all the features extracted from the encoders are useful for\nsegmentation, we propose to incorporate an attention mechanism including a\nspatial and a channel attention, to a U-Net architecture to re-weight the\nfeature representation spatially and channel-wise to capture rich contextual\nrelationships for better feature representation. In addition, the focal tversky\nloss is introduced to deal with small lesion segmentation. The experiment\nresults, evaluated on a COVID-19 CT segmentation dataset where 473 CT slices\nare available, demonstrate the proposed method can achieve an accurate and\nrapid segmentation on COVID-19 segmentation. The method takes only 0.29 second\nto segment a single CT slice. The obtained Dice Score, Sensitivity and\nSpecificity are 83.1%, 86.7% and 99.3%, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:21:11 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 16:31:04 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 09:21:19 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 13:16:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhou", "Tongxue", ""], ["Canu", "St\u00e9phane", ""], ["Ruan", "Su", ""]]}, {"id": "2004.06674", "submitter": "Ashish Rana", "authors": "Ashish Rana, Taranveer Singh, Harpreet Singh, Neeraj Kumar and\n  Prashant Singh Rana", "title": "Systematically designing better instance counting models on cell images\n  with Neural Arithmetic Logic Units", "comments": "* code repository for project:\n  https://github.com/ashishrana160796/nalu-cell-counting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The big problem for neural network models which are trained to count\ninstances is that whenever test range goes high training range generalization\nerror increases i.e. they are not good generalizers outside training range.\nConsider the case of automating cell counting process where more dense images\nwith higher cell counts are commonly encountered as compared to images used in\ntraining data. By making better predictions for higher ranges of cell count we\nare aiming to create better generalization systems for cell counting. With\narchitecture proposal of neural arithmetic logic units (NALU) for arithmetic\noperations, task of counting has become feasible for higher numeric ranges\nwhich were not included in training data with better accuracy. As a part of our\nstudy we used these units and different other activation functions for learning\ncell counting task with two different architectures namely Fully Convolutional\nRegression Network and U-Net. These numerically biased units are added in the\nform of residual concatenated layers to original architectures and a\ncomparative experimental study is done with these newly proposed changes. This\ncomparative study is described in terms of optimizing regression loss problem\nfrom these models trained with extensive data augmentation techniques. We were\nable to achieve better results in our experiments of cell counting tasks with\nintroduction of these numerically biased units to already existing\narchitectures in the form of residual layer concatenation connections. Our\nresults confirm that above stated numerically biased units does help models to\nlearn numeric quantities for better generalization results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:23:37 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 07:44:46 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rana", "Ashish", ""], ["Singh", "Taranveer", ""], ["Singh", "Harpreet", ""], ["Kumar", "Neeraj", ""], ["Rana", "Prashant Singh", ""]]}, {"id": "2004.06689", "submitter": "Guang Yang A", "authors": "Shaoping Hu, Yuan Gao, Zhangming Niu, Yinghui Jiang, Lao Li, Xianglu\n  Xiao, Minhao Wang, Evandro Fei Fang, Wade Menpes-Smith, Jun Xia, Hui Ye and\n  Guang Yang", "title": "Weakly Supervised Deep Learning for COVID-19 Infection Detection and\n  Classification from CT Images", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outbreak of a novel coronavirus disease (i.e., COVID-19) has been recorded\nin Wuhan, China since late December 2019, which subsequently became pandemic\naround the world. Although COVID-19 is an acutely treated disease, it can also\nbe fatal with a risk of fatality of 4.03% in China and the highest of 13.04% in\nAlgeria and 12.67% Italy (as of 8th April 2020). The onset of serious illness\nmay result in death as a consequence of substantial alveolar damage and\nprogressive respiratory failure. Although laboratory testing, e.g., using\nreverse transcription polymerase chain reaction (RT-PCR), is the golden\nstandard for clinical diagnosis, the tests may produce false negatives.\nMoreover, under the pandemic situation, shortage of RT-PCR testing resources\nmay also delay the following clinical decision and treatment. Under such\ncircumstances, chest CT imaging has become a valuable tool for both diagnosis\nand prognosis of COVID-19 patients. In this study, we propose a weakly\nsupervised deep learning strategy for detecting and classifying COVID-19\ninfection from CT images. The proposed method can minimise the requirements of\nmanual labelling of CT images but still be able to obtain accurate infection\ndetection and distinguish COVID-19 from non-COVID-19 cases. Based on the\npromising results obtained qualitatively and quantitatively, we can envisage a\nwide deployment of our developed technique in large-scale clinical studies.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:45:03 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Hu", "Shaoping", ""], ["Gao", "Yuan", ""], ["Niu", "Zhangming", ""], ["Jiang", "Yinghui", ""], ["Li", "Lao", ""], ["Xiao", "Xianglu", ""], ["Wang", "Minhao", ""], ["Fang", "Evandro Fei", ""], ["Menpes-Smith", "Wade", ""], ["Xia", "Jun", ""], ["Ye", "Hui", ""], ["Yang", "Guang", ""]]}, {"id": "2004.06698", "submitter": "Gi-Cheon Kang", "authors": "Gi-Cheon Kang, Junseok Park, Hwaran Lee, Byoung-Tak Zhang, Jin-Hwa Kim", "title": "DialGraph: Sparse Graph Learning Networks for Visual Dialog", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual dialog is a task of answering a sequence of questions grounded in an\nimage utilizing a dialog history. Previous studies have implicitly explored the\nproblem of reasoning semantic structures among the history using softmax\nattention. However, we argue that the softmax attention yields dense structures\nthat could distract to answer the questions requiring partial or even no\ncontextual information. In this paper, we formulate the visual dialog tasks as\ngraph structure learning tasks. To tackle the problem, we propose Sparse Graph\nLearning Networks (SGLNs) consisting of a multimodal node embedding module and\na sparse graph learning module. The proposed model explicitly learn sparse\ndialog structures by incorporating binary and score edges, leveraging a new\nstructural loss function. Then, it finally outputs the answer, updating each\nnode via a message passing framework. As a result, the proposed model\noutperforms the state-of-the-art approaches on the VisDial v1.0 dataset, only\nusing 10.95% of the dialog history, as well as improves interpretability\ncompared to baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:52:41 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Kang", "Gi-Cheon", ""], ["Park", "Junseok", ""], ["Lee", "Hwaran", ""], ["Zhang", "Byoung-Tak", ""], ["Kim", "Jin-Hwa", ""]]}, {"id": "2004.06700", "submitter": "Martin Isaksson", "authors": "Martin Isaksson, Karl Norrman", "title": "Secure Federated Learning in 5G Mobile Networks", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is an important enabler for optimizing, securing and\nmanaging mobile networks. This leads to increased collection and processing of\ndata from network functions, which in turn may increase threats to sensitive\nend-user information. Consequently, mechanisms to reduce threats to end-user\nprivacy are needed to take full advantage of ML. We seamlessly integrate\nFederated Learning (FL) into the 3GPP 5G Network Data Analytics (NWDA)\narchitecture, and add a Multi-Party Computation (MPC) protocol for protecting\nthe confidentiality of local updates. We evaluate the protocol and find that it\nhas much lower overhead than previous work, without affecting ML performance.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:53:33 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 08:15:08 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Isaksson", "Martin", ""], ["Norrman", "Karl", ""]]}, {"id": "2004.06778", "submitter": "Negin Karisani", "authors": "Negin Karisani, Payam Karisani", "title": "Mining Coronavirus (COVID-19) Posts in Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  World Health Organization (WHO) characterized the novel coronavirus\n(COVID-19) as a global pandemic on March 11th, 2020. Before this and in late\nJanuary, more specifically on January 27th, while the majority of the infection\ncases were still reported in China and a few cruise ships, we began crawling\nsocial media user postings using the Twitter search API. Our goal was to\nleverage machine learning and linguistic tools to better understand the impact\nof the outbreak in China. Unlike our initial expectation to monitor a local\noutbreak, COVID-19 rapidly spread across the globe. In this short article we\nreport the preliminary results of our study on automatically detecting the\npositive reports of COVID-19 from social media user postings using\nstate-of-the-art machine learning models.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 23:38:50 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Karisani", "Negin", ""], ["Karisani", "Payam", ""]]}, {"id": "2004.06784", "submitter": "Eugene Charniak", "authors": "Eugene Charniak", "title": "Extrapolation in Gridworld Markov-Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extrapolation in reinforcement learning is the ability to generalize at test\ntime given states that could never have occurred at training time. Here we\nconsider four factors that lead to improved extrapolation in a simple Gridworld\nenvironment: (a) avoiding maximum Q-value (or other deterministic methods) for\naction choice at test time, (b) ego-centric representation of the Gridworld,\n(c) building rotational and mirror symmetry into the learning mechanism using\nrotational and mirror invariant convolution (rather than standard\ntranslation-invariant convolution), and (d) adding a maximum entropy term to\nthe loss function to encourage equally good actions to be chosen equally often.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 20:07:10 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Charniak", "Eugene", ""]]}, {"id": "2004.06800", "submitter": "Lee James O'Riordan", "authors": "Lee J. O'Riordan, Myles Doyle, Fabio Baruffa, Venkatesh Kannan", "title": "A hybrid classical-quantum workflow for natural language processing", "comments": "For associated code, see https://github.com/ICHEC/QNLP", "journal-ref": null, "doi": "10.1088/2632-2153/abbd2e", "report-no": null, "categories": "quant-ph cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language processing (NLP) problems are ubiquitous in classical\ncomputing, where they often require significant computational resources to\ninfer sentence meanings. With the appearance of quantum computing hardware and\nsimulators, it is worth developing methods to examine such problems on these\nplatforms. In this manuscript we demonstrate the use of quantum computing\nmodels to perform NLP tasks, where we represent corpus meanings, and perform\ncomparisons between sentences of a given structure. We develop a hybrid\nworkflow for representing small and large scale corpus data sets to be encoded,\nprocessed, and decoded using a quantum circuit model. In addition, we provide\nour results showing the efficacy of the method, and release our developed\ntoolkit as an open software suite.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 12:19:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["O'Riordan", "Lee J.", ""], ["Doyle", "Myles", ""], ["Baruffa", "Fabio", ""], ["Kannan", "Venkatesh", ""]]}, {"id": "2004.06801", "submitter": "Anthony Corso", "authors": "Anthony Corso, Ritchie Lee, Mykel J. Kochenderfer", "title": "Scalable Autonomous Vehicle Safety Validation through Dynamic\n  Programming and Scene Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in autonomous driving is how best to use simulation to\nvalidate the safety of autonomous vehicles. Existing techniques rely on\nsimulated rollouts, which can be inefficient for finding rare failure events,\nwhile other techniques are designed to only discover a single failure. In this\nwork, we present a new safety validation approach that attempts to estimate the\ndistribution over failures of an autonomous policy using approximate dynamic\nprogramming. Knowledge of this distribution allows for the efficient discovery\nof many failure examples. To address the problem of scalability, we decompose\ncomplex driving scenarios into subproblems consisting of only the ego vehicle\nand one other vehicle. These subproblems can be solved with approximate dynamic\nprogramming and their solutions are recombined to approximate the solution to\nthe full scenario. We apply our approach to a simple two-vehicle scenario to\ndemonstrate the technique as well as a more complex five-vehicle scenario to\ndemonstrate scalability. In both experiments, we observed an increase in the\nnumber of failures discovered compared to baseline approaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:03:50 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:33:24 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Corso", "Anthony", ""], ["Lee", "Ritchie", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.06805", "submitter": "Anthony Corso", "authors": "Anthony Corso and Mykel J. Kochenderfer", "title": "Interpretable Safety Validation for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open problem for autonomous driving is how to validate the safety of an\nautonomous vehicle in simulation. Automated testing procedures can find\nfailures of an autonomous system but these failures may be difficult to\ninterpret due to their high dimensionality and may be so unlikely as to not be\nimportant. This work describes an approach for finding interpretable failures\nof an autonomous system. The failures are described by signal temporal logic\nexpressions that can be understood by a human, and are optimized to produce\nfailures that have high likelihood. Our methodology is demonstrated for the\nsafety validation of an autonomous vehicle in the context of an unprotected\nleft turn and a crosswalk with a pedestrian. Compared to a baseline importance\nsampling approach, our methodology finds more failures with higher likelihood\nwhile retaining interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:11:43 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:29:46 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Corso", "Anthony", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.06816", "submitter": "Hoel Kervadec", "authors": "Hoel Kervadec, Jose Dolz, Shanshan Wang, Eric Granger, Ismail Ben Ayed", "title": "Bounding boxes for weakly supervised segmentation: Global constraints\n  get close to full supervision", "comments": "Full paper, accepted for presentation at MIDL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel weakly supervised learning segmentation based on several\nglobal constraints derived from box annotations. Particularly, we leverage a\nclassical tightness prior to a deep learning setting via imposing a set of\nconstraints on the network outputs. Such a powerful topological prior prevents\nsolutions from excessive shrinking by enforcing any horizontal or vertical line\nwithin the bounding box to contain, at least, one pixel of the foreground\nregion. Furthermore, we integrate our deep tightness prior with a global\nbackground emptiness constraint, guiding training with information outside the\nbounding box. We demonstrate experimentally that such a global constraint is\nmuch more powerful than standard cross-entropy for the background class. Our\noptimization problem is challenging as it takes the form of a large set of\ninequality constraints on the outputs of deep networks. We solve it with\nsequence of unconstrained losses based on a recent powerful extension of the\nlog-barrier method, which is well-known in the context of interior-point\nmethods. This accommodates standard stochastic gradient descent (SGD) for\ntraining deep networks, while avoiding computationally expensive and unstable\nLagrangian dual steps and projections. Extensive experiments over two different\npublic data sets and applications (prostate and brain lesions) demonstrate that\nthe synergy between our global tightness and emptiness priors yield very\ncompetitive performances, approaching full supervision and outperforming\nsignificantly DeepCut. Furthermore, our approach removes the need for\ncomputationally expensive proposal generation. Our code is shared anonymously.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 22:11:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kervadec", "Hoel", ""], ["Dolz", "Jose", ""], ["Wang", "Shanshan", ""], ["Granger", "Eric", ""], ["Ayed", "Ismail Ben", ""]]}, {"id": "2004.06830", "submitter": "Huanyu Zhang", "authors": "Jayadev Acharya, Ziteng Sun, Huanyu Zhang", "title": "Differentially Private Assouad, Fano, and Le Cam", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Le Cam's method, Fano's inequality, and Assouad's lemma are three widely used\ntechniques to prove lower bounds for statistical estimation tasks. We propose\ntheir analogues under central differential privacy. Our results are simple,\neasy to apply and we use them to establish sample complexity bounds in several\nestimation tasks. We establish the optimal sample complexity of discrete\ndistribution estimation under total variation distance and $\\ell_2$ distance.\nWe also provide lower bounds for several other distribution classes, including\nproduct distributions and Gaussian mixtures that are tight up to logarithmic\nfactors. The technical component of our paper relates coupling between\ndistributions to the sample complexity of estimation under differential\nprivacy.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 23:10:38 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:57:18 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 03:03:57 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Acharya", "Jayadev", ""], ["Sun", "Ziteng", ""], ["Zhang", "Huanyu", ""]]}, {"id": "2004.06833", "submitter": "Saturnino Luz", "authors": "Saturnino Luz, Fasih Haider, Sofia de la Fuente, Davida Fromm, Brian\n  MacWhinney", "title": "Alzheimer's Dementia Recognition through Spontaneous Speech: The ADReSS\n  Challenge", "comments": "To appear in the Proceedings of INTERSPEECH 2020, Oct 2020, Shanghai,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ADReSS Challenge at INTERSPEECH 2020 defines a shared task through which\ndifferent approaches to the automated recognition of Alzheimer's dementia based\non spontaneous speech can be compared. ADReSS provides researchers with a\nbenchmark speech dataset which has been acoustically pre-processed and balanced\nin terms of age and gender, defining two cognitive assessment tasks, namely:\nthe Alzheimer's speech classification task and the neuropsychological score\nregression task. In the Alzheimer's speech classification task, ADReSS\nchallenge participants create models for classifying speech as dementia or\nhealthy control speech. In the the neuropsychological score regression task,\nparticipants create models to predict mini-mental state examination scores.\nThis paper describes the ADReSS Challenge in detail and presents a baseline for\nboth tasks, including feature extraction procedures and results for\nclassification and regression models. ADReSS aims to provide the speech and\nlanguage Alzheimer's research community with a platform for comprehensive\nmethodological comparisons. This will hopefully contribute to addressing the\nlack of standardisation that currently affects the field and shed light on\navenues for future research and clinical applicability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 23:25:09 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 20:24:03 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 22:44:29 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Luz", "Saturnino", ""], ["Haider", "Fasih", ""], ["de la Fuente", "Sofia", ""], ["Fromm", "Davida", ""], ["MacWhinney", "Brian", ""]]}, {"id": "2004.06838", "submitter": "Bilal Farooq", "authors": "Godwin Badu-Marfo, Bilal Farooq, and Zachary Paterson", "title": "Composite Travel Generative Adversarial Networks for Tabular and\n  Sequential Population Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agent-based transportation modelling has become the standard to simulate\ntravel behaviour, mobility choices and activity preferences using disaggregate\ntravel demand data for entire populations, data that are not typically readily\navailable. Various methods have been proposed to synthesize population data for\nthis purpose. We present a Composite Travel Generative Adversarial Network\n(CTGAN), a novel deep generative model to estimate the underlying joint\ndistribution of a population, that is capable of reconstructing composite\nsynthetic agents having tabular (e.g. age and sex) as well as sequential\nmobility data (e.g. trip trajectory and sequence). The CTGAN model is compared\nwith other recently proposed methods such as the Variational Autoencoders (VAE)\nmethod, which has shown success in high dimensional tabular population\nsynthesis. We evaluate the performance of the synthesized outputs based on\ndistribution similarity, multi-variate correlations and spatio-temporal\nmetrics. The results show the consistent and accurate generation of synthetic\npopulations and their tabular and spatially sequential attributes, generated\nover varying spatial scales and dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:06:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Badu-Marfo", "Godwin", ""], ["Farooq", "Bilal", ""], ["Paterson", "Zachary", ""]]}, {"id": "2004.06842", "submitter": "Chien-Chun Ni", "authors": "Chien-Chun Ni, Kin Sum Liu, Nicolas Torzec", "title": "Layered Graph Embedding for Entity Recommendation using Wikipedia in the\n  Yahoo! Knowledge Graph", "comments": "8 pages, 4 figures, 8 tables. To be appeared in Wiki Workshop 2020,\n  Companion Proceedings of the Web Conference 2020(WWW 20 Companion), Taipei,\n  Taiwan", "journal-ref": null, "doi": "10.1145/3366424.3383570", "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we describe an embedding-based entity recommendation framework\nfor Wikipedia that organizes Wikipedia into a collection of graphs layered on\ntop of each other, learns complementary entity representations from their\ntopology and content, and combines them with a lightweight learning-to-rank\napproach to recommend related entities on Wikipedia. Through offline and online\nevaluations, we show that the resulting embeddings and recommendations perform\nwell in terms of quality and user engagement. Balancing simplicity and quality,\nthis framework provides default entity recommendations for English and other\nlanguages in the Yahoo! Knowledge Graph, which Wikipedia is a core subset of.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:49:27 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ni", "Chien-Chun", ""], ["Liu", "Kin Sum", ""], ["Torzec", "Nicolas", ""]]}, {"id": "2004.06843", "submitter": "Yibo Yang", "authors": "Yibo Yang, Mohamed Aziz Bhouri, Paris Perdikaris", "title": "Bayesian differential programming for robust systems identification\n  under uncertainty", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a machine learning framework for Bayesian systems\nidentification from noisy, sparse and irregular observations of nonlinear\ndynamical systems. The proposed method takes advantage of recent developments\nin differentiable programming to propagate gradient information through\nordinary differential equation solvers and perform Bayesian inference with\nrespect to unknown model parameters using Hamiltonian Monte Carlo. This allows\nus to efficiently infer posterior distributions over plausible models with\nquantified uncertainty, while the use of sparsity-promoting priors enables the\ndiscovery of interpretable and parsimonious representations for the underlying\nlatent dynamics. A series of numerical studies is presented to demonstrate the\neffectiveness of the proposed methods including nonlinear oscillators,\npredator-prey systems, chaotic dynamics and systems biology. Taken all\ntogether, our findings put forth a novel, flexible and robust workflow for\ndata-driven model discovery under uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:51:14 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 23:04:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yang", "Yibo", ""], ["Bhouri", "Mohamed Aziz", ""], ["Perdikaris", "Paris", ""]]}, {"id": "2004.06846", "submitter": "Yanfeng Zhang", "authors": "Yanyan Liang, Yanfeng Zhang, Dechao Gao, Qian Xu", "title": "MxPool: Multiplex Pooling for Hierarchical Graph Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to utilize deep learning methods for graph classification tasks has\nattracted considerable research attention in the past few years. Regarding\ngraph classification tasks, the graphs to be classified may have various graph\nsizes (i.e., different number of nodes and edges) and have various graph\nproperties (e.g., average node degree, diameter, and clustering coefficient).\nThe diverse property of graphs has imposed significant challenges on existing\ngraph learning techniques since diverse graphs have different best-fit\nhyperparameters. It is difficult to learn graph features from a set of diverse\ngraphs by a unified graph neural network. This motivates us to use a multiplex\nstructure in a diverse way and utilize a priori properties of graphs to guide\nthe learning. In this paper, we propose MxPool, which concurrently uses\nmultiple graph convolution/pooling networks to build a hierarchical learning\nstructure for graph representation learning tasks. Our experiments on numerous\ngraph classification benchmarks show that our MxPool has superiority over other\nstate-of-the-art graph representation learning methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:05:29 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Liang", "Yanyan", ""], ["Zhang", "Yanfeng", ""], ["Gao", "Dechao", ""], ["Xu", "Qian", ""]]}, {"id": "2004.06848", "submitter": "Kyle Olszewski", "authors": "Kyle Olszewski, Duygu Ceylan, Jun Xing, Jose Echevarria, Zhili Chen,\n  Weikai Chen, Hao Li", "title": "Intuitive, Interactive Beard and Hair Synthesis with Generative Models", "comments": "To be presented in the 2020 Conference on Computer Vision and Pattern\n  Recognition (CVPR 2020, Oral Presentation). Supplementary video can be seen\n  at: https://www.youtube.com/watch?v=v4qOtBATrvM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an interactive approach to synthesizing realistic variations in\nfacial hair in images, ranging from subtle edits to existing hair to the\naddition of complex and challenging hair in images of clean-shaven subjects. To\ncircumvent the tedious and computationally expensive tasks of modeling,\nrendering and compositing the 3D geometry of the target hairstyle using the\ntraditional graphics pipeline, we employ a neural network pipeline that\nsynthesizes realistic and detailed images of facial hair directly in the target\nimage in under one second. The synthesis is controlled by simple and sparse\nguide strokes from the user defining the general structural and color\nproperties of the target hairstyle. We qualitatively and quantitatively\nevaluate our chosen method compared to several alternative approaches. We show\ncompelling interactive editing results with a prototype user interface that\nallows novice users to progressively refine the generated image to match their\ndesired hairstyle, and demonstrate that our approach also allows for flexible\nand high-fidelity scalp hair synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:20:10 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Olszewski", "Kyle", ""], ["Ceylan", "Duygu", ""], ["Xing", "Jun", ""], ["Echevarria", "Jose", ""], ["Chen", "Zhili", ""], ["Chen", "Weikai", ""], ["Li", "Hao", ""]]}, {"id": "2004.06853", "submitter": "Saeed Anwar", "authors": "Mehrdad Shoeiby, Mohammad Ali Armin, Sadegh Aliakbarian, Saeed Anwar,\n  Lars Petersson", "title": "Mosaic Super-resolution via Sequential Feature Pyramid Networks", "comments": "Accepted by IEEE CVPR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in the design of multi-spectral cameras have led to great interests\nin a wide range of applications, from astronomy to autonomous driving. However,\nsuch cameras inherently suffer from a trade-off between the spatial and\nspectral resolution. In this paper, we propose to address this limitation by\nintroducing a novel method to carry out super-resolution on raw mosaic images,\nmulti-spectral or RGB Bayer, captured by modern real-time single-shot mosaic\nsensors. To this end, we design a deep super-resolution architecture that\nbenefits from a sequential feature pyramid along the depth of the network.\nThis, in fact, is achieved by utilizing a convolutional LSTM (ConvLSTM) to\nlearn the inter-dependencies between features at different receptive fields.\nAdditionally, by investigating the effect of different attention mechanisms in\nour framework, we show that a ConvLSTM inspired module is able to provide\nsuperior attention in our context. Our extensive experiments and analyses\nevidence that our approach yields significant super-resolution quality,\noutperforming current state-of-the-art mosaic super-resolution methods on both\nBayer and multi-spectral images. Additionally, to the best of our knowledge,\nour method is the first specialized method to super-resolve mosaic images,\nwhether it be multi-spectral or Bayer.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:46:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Shoeiby", "Mehrdad", ""], ["Armin", "Mohammad Ali", ""], ["Aliakbarian", "Sadegh", ""], ["Anwar", "Saeed", ""], ["Petersson", "Lars", ""]]}, {"id": "2004.06874", "submitter": "Jon McCormack", "authors": "Jon McCormack and Andy Lomas", "title": "Understanding Aesthetic Evaluation using Deep Learning", "comments": "Presented at EvoMUSART 2020 Conference", "journal-ref": "In: Romero J., et al.(eds) Artificial Intelligence in Music,\n  Sound, Art and Design. EvoMUSART 2020. LNCS vol 12103. Springer, Cham (2020)", "doi": "10.1007/978-3-030-43859-3_9", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bottleneck in any evolutionary art system is aesthetic evaluation. Many\ndifferent methods have been proposed to automate the evaluation of aesthetics,\nincluding measures of symmetry, coherence, complexity, contrast and grouping.\nThe interactive genetic algorithm (IGA) relies on human-in-the-loop, subjective\nevaluation of aesthetics, but limits possibilities for large search due to user\nfatigue and small population sizes. In this paper we look at how recent\nadvances in deep learning can assist in automating personal aesthetic\njudgement. Using a leading artist's computer art dataset, we use dimensionality\nreduction methods to visualise both genotype and phenotype space in order to\nsupport the exploration of new territory in any generative system.\nConvolutional Neural Networks trained on the user's prior aesthetic evaluations\nare used to suggest new possibilities similar or between known high quality\ngenotype-phenotype mappings.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 04:18:38 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["McCormack", "Jon", ""], ["Lomas", "Andy", ""]]}, {"id": "2004.06882", "submitter": "Sujit Gujar Dr", "authors": "Manisha Padala, Debojit Das, and Sujit Gujar", "title": "Effect of Input Noise Dimension in GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are by far the most successful\ngenerative models. Learning the transformation which maps a low dimensional\ninput noise to the data distribution forms the foundation for GANs. Although\nthey have been applied in various domains, they are prone to certain challenges\nlike mode collapse and unstable training. To overcome the challenges,\nresearchers have proposed novel loss functions, architectures, and optimization\nmethods. In our work here, unlike the previous approaches, we focus on the\ninput noise and its role in the generation.\n  We aim to quantitatively and qualitatively study the effect of the dimension\nof the input noise on the performance of GANs. For quantitative measures,\ntypically \\emph{Fr\\'{e}chet Inception Distance (FID)} and \\emph{Inception Score\n(IS)} are used as performance measure on image data-sets. We compare the FID\nand IS values for DCGAN and WGAN-GP. We use three different image data-sets --\neach consisting of different levels of complexity. Through our experiments, we\nshow that the right dimension of input noise for optimal results depends on the\ndata-set and architecture used. We also observe that the state of the art\nperformance measures does not provide enough useful insights. Hence we conclude\nthat we need further theoretical analysis for understanding the relationship\nbetween the low dimensional distribution and the generated images. We also\nrequire better performance measures.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 04:56:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Padala", "Manisha", ""], ["Das", "Debojit", ""], ["Gujar", "Sujit", ""]]}, {"id": "2004.06896", "submitter": "Mao V. Ngo", "authors": "Mao V. Ngo, Tie Luo, Hakima Chaouchi, and Tony Q.S. Quek", "title": "Contextual-Bandit Anomaly Detection for IoT Data in Distributed\n  Hierarchical Edge Computing", "comments": "Accepted for presenting at IEEE International Conference on\n  Distributed Computing Systems (ICDCS), Demo Track, July 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep neural networks (DNN) greatly bolster real-time detection of\nanomalous IoT data. However, IoT devices can hardly afford complex DNN models,\nand offloading anomaly detection tasks to the cloud incurs long delay. In this\npaper, we propose and build a demo for an adaptive anomaly detection approach\nfor distributed hierarchical edge computing (HEC) systems to solve this\nproblem, for both univariate and multivariate IoT data. First, we construct\nmultiple anomaly detection DNN models with increasing complexity, and associate\neach model with a layer in HEC from bottom to top. Then, we design an adaptive\nscheme to select one of these models on the fly, based on the contextual\ninformation extracted from each input data. The model selection is formulated\nas a contextual bandit problem characterized by a single-step Markov decision\nprocess, and is solved using a reinforcement learning policy network. We build\nan HEC testbed, implement our proposed approach, and evaluate it using real IoT\ndatasets. The demo shows that our proposed approach significantly reduces\ndetection delay (e.g., by 71.4% for univariate dataset) without sacrificing\naccuracy, as compared to offloading detection tasks to the cloud. We also\ncompare it with other baseline schemes and demonstrate that it achieves the\nbest accuracy-delay tradeoff. Our demo is also available online:\nhttps://rebrand.ly/91a71\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 06:13:33 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ngo", "Mao V.", ""], ["Luo", "Tie", ""], ["Chaouchi", "Hakima", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2004.06898", "submitter": "Ankit Garg", "authors": "Ankit Garg, Neeraj Kayal, and Chandan Saha", "title": "Learning sums of powers of low-degree polynomials in the non-degenerate\n  case", "comments": "Fixed a minor bug in the statement and proof of Corollary 3.1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop algorithms for writing a polynomial as sums of powers of low\ndegree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can\nbe written as $$f = c_1Q_1^{m} + \\ldots + c_s Q_s^{m},$$ where each $c_i\\in\n\\mathbb{F}^{\\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m\n= d$. In this paper, we give a $\\text{poly}((ns)^t)$-time learning algorithm\nfor finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy\ncertain non-degeneracy conditions and $n$ is larger than $d^2$. The set of\ndegenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a\nnon-trivial variety and hence if the $Q_i$'s are chosen according to any\nreasonable (full-dimensional) distribution, then they are non-degenerate with\nhigh probability (if $s$ is not too large).\n  Our algorithm is based on a scheme for obtaining a learning algorithm for an\narithmetic circuit model from a lower bound for the same model, provided\ncertain non-degeneracy conditions hold. The scheme reduces the learning problem\nto the problem of decomposing two vector spaces under the action of a set of\nlinear operators, where the spaces and the operators are derived from the input\ncircuit and the complexity measure used in a typical lower bound proof. The\nnon-degeneracy conditions are certain restrictions on how the spaces decompose.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 06:18:41 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 08:57:22 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Garg", "Ankit", ""], ["Kayal", "Neeraj", ""], ["Saha", "Chandan", ""]]}, {"id": "2004.06904", "submitter": "Xin Ning", "authors": "Xin Ning, Shaohui Xu, Xiaoli Dong, Weijun Li, Fangzhe Nan and Yuanzhou\n  Yao", "title": "Continuous learning of face attribute synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generative adversarial network (GAN) exhibits great superiority in the\nface attribute synthesis task. However, existing methods have very limited\neffects on the expansion of new attributes. To overcome the limitations of a\nsingle network in new attribute synthesis, a continuous learning method for\nface attribute synthesis is proposed in this work. First, the feature vector of\nthe input image is extracted and attribute direction regression is performed in\nthe feature space to obtain the axes of different attributes. The feature\nvector is then linearly guided along the axis so that images with target\nattributes can be synthesized by the decoder. Finally, to make the network\ncapable of continuous learning, the orthogonal direction modification module is\nused to extend the newly-added attributes. Experimental results show that the\nproposed method can endow a single network with the ability to learn attributes\ncontinuously, and, as compared to those produced by the current\nstate-of-the-art methods, the synthetic attributes have higher accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 06:44:13 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ning", "Xin", ""], ["Xu", "Shaohui", ""], ["Dong", "Xiaoli", ""], ["Li", "Weijun", ""], ["Nan", "Fangzhe", ""], ["Yao", "Yuanzhou", ""]]}, {"id": "2004.06916", "submitter": "Edilson Arruda", "authors": "L. Tarrataca, C.M. Dias, D. B. Haddad, and E. F. Arruda", "title": "Flattening the curves: on-off lock-down strategies for COVID-19 with an\n  application to Brazi", "comments": null, "journal-ref": null, "doi": "10.1186/s13362-020-00098-w", "report-no": null, "categories": "q-bio.PE cs.LG cs.SY eess.SY q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current COVID-19 pandemic is affecting different countries in different\nways. The assortment of reporting techniques alongside other issues, such as\nunderreporting and budgetary constraints, makes predicting the spread and\nlethality of the virus a challenging task. This work attempts to gain a better\nunderstanding of how COVID-19 will affect one of the least studied countries,\nnamely Brazil. Currently, several Brazilian states are in a state of lock-down.\nHowever, there is political pressure for this type of measures to be lifted.\nThis work considers the impact that such a termination would have on how the\nvirus evolves locally. This was done by extending the SEIR model with an on /\noff strategy. Given the simplicity of SEIR we also attempted to gain more\ninsight by developing a neural regressor. We chose to employ features that\ncurrent clinical studies have pinpointed has having a connection to the\nlethality of COVID-19. We discuss how this data can be processed in order to\nobtain a robust assessment.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 07:37:08 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Tarrataca", "L.", ""], ["Dias", "C. M.", ""], ["Haddad", "D. B.", ""], ["Arruda", "E. F.", ""]]}, {"id": "2004.06947", "submitter": "Georg Steinbuss", "authors": "Georg Steinbuss and Klemens B\\\"ohm", "title": "Benchmarking Unsupervised Outlier Detection with Realistic Synthetic\n  Data", "comments": null, "journal-ref": null, "doi": "10.1145/3441453", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking unsupervised outlier detection is difficult. Outliers are rare,\nand existing benchmark data contains outliers with various and unknown\ncharacteristics. Fully synthetic data usually consists of outliers and regular\ninstance with clear characteristics and thus allows for a more meaningful\nevaluation of detection methods in principle. Nonetheless, there have only been\nfew attempts to include synthetic data in benchmarks for outlier detection.\nThis might be due to the imprecise notion of outliers or to the difficulty to\narrive at a good coverage of different domains with synthetic data. In this\nwork we propose a generic process for the generation of data sets for such\nbenchmarking. The core idea is to reconstruct regular instances from existing\nreal-world benchmark data while generating outliers so that they exhibit\ninsightful characteristics. This allows both for a good coverage of domains and\nfor helpful interpretations of results. We also describe three instantiations\nof the generic process that generate outliers with specific characteristics,\nlike local outliers. A benchmark with state-of-the-art detection methods\nconfirms that our generic process is indeed practical.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 08:55:47 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Steinbuss", "Georg", ""], ["B\u00f6hm", "Klemens", ""]]}, {"id": "2004.06954", "submitter": "Sen Chen", "authors": "Yusi Lei, Sen Chen, Lingling Fan, Fu Song, and Yang Liu", "title": "Advanced Evasion Attacks and Mitigations on Practical ML-Based Phishing\n  Website Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) based approaches have been the mainstream solution for\nanti-phishing detection. When they are deployed on the client-side, ML-based\nclassifiers are vulnerable to evasion attacks. However, such potential threats\nhave received relatively little attention because existing attacks destruct the\nfunctionalities or appearance of webpages and are conducted in the white-box\nscenario, making it less practical. Consequently, it becomes imperative to\nunderstand whether it is possible to launch evasion attacks with limited\nknowledge of the classifier, while preserving the functionalities and\nappearance.\n  In this work, we show that even in the grey-, and black-box scenarios,\nevasion attacks are not only effective on practical ML-based classifiers, but\ncan also be efficiently launched without destructing the functionalities and\nappearance. For this purpose, we propose three mutation-based attacks,\ndiffering in the knowledge of the target classifier, addressing a key technical\nchallenge: automatically crafting an adversarial sample from a known phishing\nwebsite in a way that can mislead classifiers. To launch attacks in the white-\nand grey-box scenarios, we also propose a sample-based collision attack to gain\nthe knowledge of the target classifier. We demonstrate the effectiveness and\nefficiency of our evasion attacks on the state-of-the-art, Google's phishing\npage filter, achieved 100% attack success rate in less than one second per\nwebsite. Moreover, the transferability attack on BitDefender's industrial\nphishing page classifier, TrafficLight, achieved up to 81.25% attack success\nrate. We further propose a similarity-based method to mitigate such evasion\nattacks, Pelican. We demonstrate that Pelican can effectively detect evasion\nattacks. Our findings contribute to design more robust phishing website\nclassifiers in practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:04:16 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Lei", "Yusi", ""], ["Chen", "Sen", ""], ["Fan", "Lingling", ""], ["Song", "Fu", ""], ["Liu", "Yang", ""]]}, {"id": "2004.06963", "submitter": "Lorenzo Rimella", "authors": "Lorenzo Rimella and Nick Whiteley", "title": "Dynamic Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define an evolving in time Bayesian neural network called a Hidden Markov\nneural network. The weights of a feed-forward neural network are modelled with\nthe hidden states of a Hidden Markov model, whose observed process is given by\nthe available data. A filtering algorithm is used to learn a variational\napproximation to the evolving in time posterior over the weights. Training is\npursued through a sequential version of Bayes by Backprop Blundell et al. 2015,\nwhich is enriched with a stronger regularization technique called variational\nDropConnect. The experiments test variational DropConnect on MNIST and display\nthe performance of Hidden Markov neural networks on time series.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:18:18 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:29:17 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rimella", "Lorenzo", ""], ["Whiteley", "Nick", ""]]}, {"id": "2004.06971", "submitter": "Guillaume Vaudaux-Ruth", "authors": "Guillaume Vaudaux-Ruth, Adrien Chan-Hon-Tong, Catherine Achard (ISIR,\n  PIROS, SU)", "title": "ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action\n  Spotting in Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing video content is an important task in many applications. This\ntask can be defined as the computation of the ordered list of actions present\nin a video. Such a list could be extracted using action detection algorithms.\nHowever, it is not necessary to determine the temporal boundaries of actions to\nknow their existence. Moreover, localizing precise boundaries usually requires\ndense video analysis to be effective. In this work, we propose to directly\ncompute this ordered list by sparsely browsing the video and selecting one\nframe per action instance, task known as action spotting in literature. To do\nthis, we propose ActionSpotter, a spotting algorithm that takes advantage of\nDeep Reinforcement Learning to efficiently spot actions while adapting its\nvideo browsing speed, without additional supervision. Experiments performed on\ndatasets THUMOS14 and ActivityNet show that our framework outperforms state of\nthe art detection methods. In particular, the spotting mean Average Precision\non THUMOS14 is significantly improved from 59.7% to 65.6% while skipping 23% of\nvideo.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:36:37 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 16:43:56 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Vaudaux-Ruth", "Guillaume", "", "ISIR,\n  PIROS, SU"], ["Chan-Hon-Tong", "Adrien", "", "ISIR,\n  PIROS, SU"], ["Achard", "Catherine", "", "ISIR,\n  PIROS, SU"]]}, {"id": "2004.06977", "submitter": "Bin Shi", "authors": "Bin Shi, Weijie J. Su, Michael I. Jordan", "title": "On Learning Rates and Schr\\\"odinger Operators", "comments": "49 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate is perhaps the single most important parameter in the\ntraining of neural networks and, more broadly, in stochastic (nonconvex)\noptimization. Accordingly, there are numerous effective, but poorly understood,\ntechniques for tuning the learning rate, including learning rate decay, which\nstarts with a large initial learning rate that is gradually decreased. In this\npaper, we present a general theoretical analysis of the effect of the learning\nrate in stochastic gradient descent (SGD). Our analysis is based on the use of\na learning-rate-dependent stochastic differential equation (lr-dependent SDE)\nthat serves as a surrogate for SGD. For a broad class of objective functions,\nwe establish a linear rate of convergence for this continuous-time formulation\nof SGD, highlighting the fundamental importance of the learning rate in SGD,\nand contrasting to gradient descent and stochastic gradient Langevin dynamics.\nMoreover, we obtain an explicit expression for the optimal linear rate by\nanalyzing the spectrum of the Witten-Laplacian, a special case of the\nSchr\\\"odinger operator associated with the lr-dependent SDE. Strikingly, this\nexpression clearly reveals the dependence of the linear convergence rate on the\nlearning rate -- the linear rate decreases rapidly to zero as the learning rate\ntends to zero for a broad class of nonconvex functions, whereas it stays\nconstant for strongly convex functions. Based on this sharp distinction between\nnonconvex and convex problems, we provide a mathematical interpretation of the\nbenefits of using learning rate decay for nonconvex optimization.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:52:37 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Shi", "Bin", ""], ["Su", "Weijie J.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2004.06989", "submitter": "Raja Giryes", "authors": "Raja Giryes", "title": "A function space analysis of finite neural networks with insights from\n  sampling theory", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.FA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work suggests using sampling theory to analyze the function space\nrepresented by neural networks. First, it shows, under the assumption of a\nfinite input domain, which is the common case in training neural networks, that\nthe function space generated by multi-layer networks with non-expansive\nactivation functions is smooth. This extends over previous works that show\nresults for the case of infinite width ReLU networks. Then, under the\nassumption that the input is band-limited, we provide novel error bounds for\nunivariate neural networks. We analyze both deterministic uniform and random\nsampling showing the advantage of the former.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 10:25:18 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Giryes", "Raja", ""]]}, {"id": "2004.06997", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Josef Urban, Chad E. Brown", "title": "Prolog Technology Reinforcement Learning Prover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning toolkit for experiments with guiding\nautomated theorem proving in the connection calculus. The core of the toolkit\nis a compact and easy to extend Prolog-based automated theorem prover called\nplCoP. plCoP builds on the leanCoP Prolog implementation and adds\nlearning-guided Monte-Carlo Tree Search as done in the rlCoP system. Other\ncomponents include a Python interface to plCoP and machine learners, and an\nexternal proof checker that verifies the validity of plCoP proofs. The toolkit\nis evaluated on two benchmarks and we demonstrate its extendability by two\nadditions: (1) guidance is extended to reduction steps and (2) the standard\nleanCoP calculus is extended with rewrite steps and their learned guidance. We\nargue that the Prolog setting is suitable for combining statistical and\nsymbolic learning methods. The complete toolkit is publicly released.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 10:52:04 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Zombori", "Zsolt", ""], ["Urban", "Josef", ""], ["Brown", "Chad E.", ""]]}, {"id": "2004.07009", "submitter": "Rojeh Hayek", "authors": "Rojeh Hayek, Oded Shmueli", "title": "NN-based Transformation of Any SQL Cardinality Estimator for Handling\n  DISTINCT, AND, OR and NOT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SQL queries, with the AND, OR, and NOT operators, constitute a broad class of\nhighly used queries. Thus, their cardinality estimation is important for query\noptimization. In addition, a query planner requires the set-theoretic\ncardinality (i.e., without duplicates) for queries with DISTINCT as well as in\nplanning; for example, when considering sorting options. Yet, despite the\nimportance of estimating query cardinalities in the presence of DISTINCT, AND,\nOR, and NOT, many cardinality estimation methods are limited to estimating\ncardinalities of only conjunctive queries with duplicates counted.\n  The focus of this work is on two methods for handling this deficiency that\ncan be applied to any limited cardinality estimation model. First, we describe\na specialized deep learning scheme, PUNQ, which is tailored to representing\nconjunctive SQL queries and predicting the percentage of unique rows in the\nquery's result with duplicate rows. Using the predicted percentages obtained\nvia PUNQ, we are able to transform any cardinality estimation method that only\nestimates for conjunctive queries, and which estimates cardinalities with\nduplicates (e.g., MSCN), to a method that estimates queries cardinalities\nwithout duplicates. This enables estimating cardinalities of queries with the\nDISTINCT keyword. In addition, we describe a recursive algorithm, GenCrd, for\nextending any cardinality estimation method M that only handles conjunctive\nqueries to one that estimates cardinalities for more general queries (that\ninclude AND, OR, and NOT), without changing the method M itself.\n  Our evaluation is carried out on a challenging, real-world database with\ngeneral queries that include either the DISTINCT keyword or the AND, OR, and\nNOT operators. Experimentally, we show that the proposed methods obtain\naccurate cardinality estimates with the same level of accuracy as that of the\noriginal transformed methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 11:20:06 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Hayek", "Rojeh", ""], ["Shmueli", "Oded", ""]]}, {"id": "2004.07016", "submitter": "He Wang", "authors": "Zheyan Zhang, Yongxing Wang, Peter K. Jimack, and He Wang", "title": "MeshingNet: A New Mesh Generation Method based on Deep Learning", "comments": "Accepted in International Conference on Computational Science 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.GR cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to automatic unstructured mesh generation using\nmachine learning to predict an optimal finite element mesh for a previously\nunseen problem. The framework that we have developed is based around training\nan artificial neural network (ANN) to guide standard mesh generation software,\nbased upon a prediction of the required local mesh density throughout the\ndomain. We describe the training regime that is proposed, based upon the use of\n\\emph{a posteriori} error estimation, and discuss the topologies of the ANNs\nthat we have considered. We then illustrate performance using two standard test\nproblems, a single elliptic partial differential equation (PDE) and a system of\nPDEs associated with linear elasticity. We demonstrate the effective generation\nof high quality meshes for arbitrary polygonal geometries and a range of\nmaterial parameters, using a variety of user-selected error norms.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 11:29:00 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Zhang", "Zheyan", ""], ["Wang", "Yongxing", ""], ["Jimack", "Peter K.", ""], ["Wang", "He", ""]]}, {"id": "2004.07041", "submitter": "David Tellez", "authors": "David Tellez, Diederik Hoppener, Cornelis Verhoef, Dirk Grunhagen,\n  Pieter Nierop, Michal Drozdzal, Jeroen van der Laak, Francesco Ciompi", "title": "Extending Unsupervised Neural Image Compression With Supervised\n  Multitask Learning", "comments": "Medical Imaging with Deep Learning 2020 (MIDL20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of training convolutional neural networks on\ngigapixel histopathology images to predict image-level targets. For this\npurpose, we extend Neural Image Compression (NIC), an image compression\nframework that reduces the dimensionality of these images using an encoder\nnetwork trained unsupervisedly. We propose to train this encoder using\nsupervised multitask learning (MTL) instead. We applied the proposed MTL NIC to\ntwo histopathology datasets and three tasks. First, we obtained\nstate-of-the-art results in the Tumor Proliferation Assessment Challenge of\n2016 (TUPAC16). Second, we successfully classified histopathological growth\npatterns in images with colorectal liver metastasis (CLM). Third, we predicted\npatient risk of death by learning directly from overall survival in the same\nCLM data. Our experimental results suggest that the representations learned by\nthe MTL objective are: (1) highly specific, due to the supervised training\nsignal, and (2) transferable, since the same features perform well across\ndifferent tasks. Additionally, we trained multiple encoders with different\ntraining objectives, e.g. unsupervised and variants of MTL, and observed a\npositive correlation between the number of tasks in MTL and the system\nperformance on the TUPAC16 dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:20:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Tellez", "David", ""], ["Hoppener", "Diederik", ""], ["Verhoef", "Cornelis", ""], ["Grunhagen", "Dirk", ""], ["Nierop", "Pieter", ""], ["Drozdzal", "Michal", ""], ["van der Laak", "Jeroen", ""], ["Ciompi", "Francesco", ""]]}, {"id": "2004.07049", "submitter": "Hristos Tyralis", "authors": "Hristos Tyralis, Georgia Papacharalampous", "title": "Boosting algorithms in energy research: A systematic review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms have been extensively exploited in (renewable)\nenergy research, due to their flexibility, automation and ability to handle big\ndata. Among the most prominent machine learning algorithms are the boosting\nones, which are known to be \"garnering wisdom from a council of fools\", thereby\ntransforming weak learners to strong learners. Boosting algorithms are\ncharacterized by both high flexibility and high interpretability. The latter\nproperty is the result of recent developments by the statistical community. In\nthis work, we provide understanding on the properties of boosting algorithms to\nfacilitate a better exploitation of their strengths in energy research. In this\nrespect, (a) we summarize recent advances on boosting algorithms, (b) we review\nrelevant applications in energy research with those focusing on renewable\nenergy (in particular those focusing on wind energy and solar energy)\nconsisting a significant portion of the total ones, and (c) we describe how\nboosting algorithms are implemented and how their use is related to their\nproperties. We show that boosting has been underexploited so far, while great\nadvances in the energy field (in which renewable sources play a key role) are\npossible both in terms of explanation and interpretation, and in terms of\npredictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 18:03:26 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tyralis", "Hristos", ""], ["Papacharalampous", "Georgia", ""]]}, {"id": "2004.07054", "submitter": "Yu-Huan Wu", "authors": "Yu-Huan Wu, Shang-Hua Gao, Jie Mei, Jun Xu, Deng-Ping Fan, Rong-Guo\n  Zhang, Ming-Ming Cheng", "title": "JCS: An Explainable COVID-19 Diagnosis System by Joint Classification\n  and Segmentation", "comments": "To appear in IEEE Transactions on Image Processing. Dataset and code\n  are available at https://github.com/yuhuan-wu/JCS", "journal-ref": null, "doi": "10.1109/TIP.2021.3058783", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the coronavirus disease 2019 (COVID-19) has caused a pandemic\ndisease in over 200 countries, influencing billions of humans. To control the\ninfection, identifying and separating the infected people is the most crucial\nstep. The main diagnostic tool is the Reverse Transcription Polymerase Chain\nReaction (RT-PCR) test. Still, the sensitivity of the RT-PCR test is not high\nenough to effectively prevent the pandemic. The chest CT scan test provides a\nvaluable complementary tool to the RT-PCR test, and it can identify the\npatients in the early-stage with high sensitivity. However, the chest CT scan\ntest is usually time-consuming, requiring about 21.5 minutes per case. This\npaper develops a novel Joint Classification and Segmentation (JCS) system to\nperform real-time and explainable COVID-19 chest CT diagnosis. To train our JCS\nsystem, we construct a large scale COVID-19 Classification and Segmentation\n(COVID-CS) dataset, with 144,167 chest CT images of 400 COVID-19 patients and\n350 uninfected cases. 3,855 chest CT images of 200 patients are annotated with\nfine-grained pixel-level labels of opacifications, which are increased\nattenuation of the lung parenchyma. We also have annotated lesion counts,\nopacification areas, and locations and thus benefit various diagnosis aspects.\nExtensive experiments demonstrate that the proposed JCS diagnosis system is\nvery efficient for COVID-19 classification and segmentation. It obtains an\naverage sensitivity of 95.0% and a specificity of 93.0% on the classification\ntest set, and 78.5% Dice score on the segmentation test set of our COVID-CS\ndataset. The COVID-CS dataset and code are available at\nhttps://github.com/yuhuan-wu/JCS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:30:40 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 03:06:10 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wu", "Yu-Huan", ""], ["Gao", "Shang-Hua", ""], ["Mei", "Jie", ""], ["Xu", "Jun", ""], ["Fan", "Deng-Ping", ""], ["Zhang", "Rong-Guo", ""], ["Cheng", "Ming-Ming", ""]]}, {"id": "2004.07067", "submitter": "Mohamed El-Geish", "authors": "Mohamed El-Geish", "title": "Gestalt: a Stacking Ensemble for SQuAD2.0", "comments": "11 pages, 7 figures, Stanford CS224n Natural Language Processing with\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep-learning system -- for the SQuAD2.0 task -- that finds, or\nindicates the lack of, a correct answer to a question in a context paragraph.\nOur goal is to learn an ensemble of heterogeneous SQuAD2.0 models that, when\nblended properly, outperforms the best model in the ensemble per se. We created\na stacking ensemble that combines top-N predictions from two models, based on\nALBERT and RoBERTa, into a multiclass classification task to pick the best\nanswer out of their predictions. We explored various ensemble configurations,\ninput representations, and model architectures. For evaluation, we examined\ntest-set EM and F1 scores; our best-performing ensemble incorporated a\nCNN-based meta-model and scored 87.117 and 90.306, respectively -- a relative\nimprovement of 0.55% for EM and 0.61% for F1 scores, compared to the baseline\nperformance of the best model in the ensemble, an ALBERT-based model, at 86.644\nfor EM and 89.760 for F1.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 08:09:22 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["El-Geish", "Mohamed", ""]]}, {"id": "2004.07070", "submitter": "Grzegorz Chrupa{\\l}a", "authors": "Grzegorz Chrupa{\\l}a, Bertrand Higy, Afra Alishahi", "title": "Analyzing analytical methods: The case of phonology in neural models of\n  spoken language", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the fast development of analysis techniques for NLP and speech\nprocessing systems, few systematic studies have been conducted to compare the\nstrengths and weaknesses of each method. As a step in this direction we study\nthe case of representations of phonology in neural network models of spoken\nlanguage. We use two commonly applied analytical techniques, diagnostic\nclassifiers and representational similarity analysis, to quantify to what\nextent neural activation patterns encode phonemes and phoneme sequences. We\nmanipulate two factors that can affect the outcome of analysis. First, we\ninvestigate the role of learning by comparing neural activations extracted from\ntrained versus randomly-initialized models. Second, we examine the temporal\nscope of the activations by probing both local activations corresponding to a\nfew milliseconds of the speech signal, and global activations pooled over the\nwhole utterance. We conclude that reporting analysis results with randomly\ninitialized models is crucial, and that global-scope methods tend to yield more\nconsistent results and we recommend their use as a complement to local-scope\ndiagnostic methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 13:04:15 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 07:59:40 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Chrupa\u0142a", "Grzegorz", ""], ["Higy", "Bertrand", ""], ["Alishahi", "Afra", ""]]}, {"id": "2004.07085", "submitter": "Lukas Faber", "authors": "Lukas Faber and Roger Wattenhofer", "title": "Neural Status Registers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Neural Networks can learn mathematical operations, but they do not\nextrapolate. Extrapolation means that the model can apply to larger numbers,\nwell beyond those observed during training. Recent architectures tackle\narithmetic operations and can extrapolate; however, the equally important\nproblem of quantitative reasoning remains unaddressed. In this work, we propose\na novel architectural element, the Neural Status Register (NSR), for\nquantitative reasoning over numbers. Our NSR relaxes the discrete bit logic of\nphysical status registers to continuous numbers and allows end-to-end learning\nwith gradient descent. Experiments show that the NSR achieves solutions that\nextrapolate to numbers many orders of magnitude larger than those in the\ntraining set. We successfully train the NSR on number comparisons, piecewise\ndiscontinuous functions, counting in sequences, recurrently finding minimums,\nfinding shortest paths in graphs, and comparing digits in images.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 13:34:37 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 18:58:29 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Faber", "Lukas", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2004.07093", "submitter": "Kazuki Miyazawa", "authors": "Kazuki Miyazawa, Tatsuya Aoki, Takato Horii, and Takayuki Nagai", "title": "lamBERT: Language and Action Learning Using Multimodal BERT", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the bidirectional encoder representations from transformers (BERT)\nmodel has attracted much attention in the field of natural language processing,\nowing to its high performance in language understanding-related tasks. The BERT\nmodel learns language representation that can be adapted to various tasks via\npre-training using a large corpus in an unsupervised manner. This study\nproposes the language and action learning using multimodal BERT (lamBERT) model\nthat enables the learning of language and actions by 1) extending the BERT\nmodel to multimodal representation and 2) integrating it with reinforcement\nlearning. To verify the proposed model, an experiment is conducted in a grid\nenvironment that requires language understanding for the agent to act properly.\nAs a result, the lamBERT model obtained higher rewards in multitask settings\nand transfer settings when compared to other models, such as the convolutional\nneural network-based model and the lamBERT model without pre-training.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 13:54:55 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Miyazawa", "Kazuki", ""], ["Aoki", "Tatsuya", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "2004.07116", "submitter": "Beatrice Bussolino", "authors": "Alberto Marchisio, Beatrice Bussolino, Alessio Colucci, Maurizio\n  Martina, Guido Masera, Muhammad Shafique", "title": "Q-CapsNets: A Specialized Framework for Quantizing Capsule Networks", "comments": "Accepted for publication at Design Automation Conference 2020 (DAC\n  2020)", "journal-ref": null, "doi": "10.1109/DAC18072.2020.9218746", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule Networks (CapsNets), recently proposed by the Google Brain team, have\nsuperior learning capabilities in machine learning tasks, like image\nclassification, compared to the traditional CNNs. However, CapsNets require\nextremely intense computations and are difficult to be deployed in their\noriginal form at the resource-constrained edge devices. This paper makes the\nfirst attempt to quantize CapsNet models, to enable their efficient edge\nimplementations, by developing a specialized quantization framework for\nCapsNets. We evaluate our framework for several benchmarks. On a deep CapsNet\nmodel for the CIFAR10 dataset, the framework reduces the memory footprint by\n6.2x, with only 0.15% accuracy loss. We will open-source our framework at\nhttps://git.io/JvDIF in August 2020.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 14:32:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 08:13:57 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Marchisio", "Alberto", ""], ["Bussolino", "Beatrice", ""], ["Colucci", "Alessio", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2004.07119", "submitter": "Xiaojie Guo", "authors": "Xiaojie Guo, Yuanqi Du, Sivani Tadepalli, Liang Zhao, and Amarda Shehu", "title": "Generating Tertiary Protein Structures via an Interpretative Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much scientific enquiry across disciplines is founded upon a mechanistic\ntreatment of dynamic systems that ties form to function. A highly visible\ninstance of this is in molecular biology, where an important goal is to\ndetermine functionally-relevant forms/structures that a protein molecule\nemploys to interact with molecular partners in the living cell. This goal is\ntypically pursued under the umbrella of stochastic optimization with algorithms\nthat optimize a scoring function. Research repeatedly shows that current\nscoring function, though steadily improving, correlate weakly with molecular\nactivity. Inspired by recent momentum in generative deep learning, this paper\nproposes and evaluates an alternative approach to generating\nfunctionally-relevant three-dimensional structures of a protein. Though\ntypically deep generative models struggle with highly-structured data, the work\npresented here circumvents this challenge via graph-generative models. A\ncomprehensive evaluation of several deep architectures shows the promise of\ngenerative models in directly revealing the latent space for sampling novel\ntertiary structures, as well as in highlighting axes/factors that carry\nstructural meaning and open the black box often associated with deep models.\nThe work presented here is a first step towards interpretative, deep generative\nmodels becoming viable and informative complementary approaches to protein\nstructure prediction.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:40:21 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 06:02:16 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Guo", "Xiaojie", ""], ["Du", "Yuanqi", ""], ["Tadepalli", "Sivani", ""], ["Zhao", "Liang", ""], ["Shehu", "Amarda", ""]]}, {"id": "2004.07126", "submitter": "Avi Caciularu", "authors": "Oren Barkan, Idan Rejwan, Avi Caciularu, Noam Koenigstein", "title": "Bayesian Hierarchical Words Representation Learning", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Bayesian Hierarchical Words Representation (BHWR)\nlearning algorithm. BHWR facilitates Variational Bayes word representation\nlearning combined with semantic taxonomy modeling via hierarchical priors. By\npropagating relevant information between related words, BHWR utilizes the\ntaxonomy to improve the quality of such representations. Evaluation of several\nlinguistic datasets demonstrates the advantages of BHWR over suitable\nalternatives that facilitate Bayesian modeling with or without semantic priors.\nFinally, we further show that BHWR produces better representations for rare\nwords.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 13:39:52 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Barkan", "Oren", ""], ["Rejwan", "Idan", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "2004.07150", "submitter": "Jimit Majmudar", "authors": "Jimit Majmudar, Stephen Vavasis", "title": "Provable Overlapping Community Detection in Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is a widely-studied unsupervised learning problem in\nwhich the task is to group similar entities together based on observed pairwise\nentity interactions. This problem has applications in diverse domains such as\nsocial network analysis and computational biology. There is a significant\namount of literature studying this problem under the assumption that the\ncommunities do not overlap. When the communities are allowed to overlap, often\na pure nodes assumption is made, i.e. each community has a node that belongs\nexclusively to that community. This assumption, however, may not always be\nsatisfied in practice. In this paper, we provide a provable method to detect\noverlapping communities in weighted graphs without explicitly making the pure\nnodes assumption. Moreover, contrary to most existing algorithms, our approach\nis based on convex optimization, for which many useful theoretical properties\nare already known. We demonstrate the success of our algorithm on artificial\nand real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:25:46 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:42:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Majmudar", "Jimit", ""], ["Vavasis", "Stephen", ""]]}, {"id": "2004.07155", "submitter": "Alvaro Ovalle", "authors": "Alvaro Ovalle, Simon M. Lucas", "title": "Bootstrapped model learning and error correction for planning with\n  uncertainty in model-based RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Having access to a forward model enables the use of planning algorithms such\nas Monte Carlo Tree Search and Rolling Horizon Evolution. Where a model is\nunavailable, a natural aim is to learn a model that reflects accurately the\ndynamics of the environment. In many situations it might not be possible and\nminimal glitches in the model may lead to poor performance and failure. This\npaper explores the problem of model misspecification through uncertainty-aware\nreinforcement learning agents. We propose a bootstrapped multi-headed neural\nnetwork that learns the distribution of future states and rewards. We\nexperiment with a number of schemes to extract the most likely predictions.\nMoreover, we also introduce a global error correction filter that applies\nhigh-level constraints guided by the context provided through the predictive\ndistribution. We illustrate our approach on Minipacman. The evaluation\ndemonstrates that when dealing with imperfect models, our methods exhibit\nincreased performance and stability, both in terms of model accuracy and in its\nuse within a planning algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:41:21 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Ovalle", "Alvaro", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2004.07162", "submitter": "Man-Chung Yue", "authors": "Man-Chung Yue, Daniel Kuhn, Wolfram Wiesemann", "title": "On Linear Optimization over Wasserstein Balls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wasserstein balls, which contain all probability measures within a\npre-specified Wasserstein distance to a reference measure, have recently\nenjoyed wide popularity in the distributionally robust optimization and machine\nlearning communities to formulate and solve data-driven optimization problems\nwith rigorous statistical guarantees. In this technical note we prove that the\nWasserstein ball is weakly compact under mild conditions, and we offer\nnecessary and sufficient conditions for the existence of optimal solutions. We\nalso characterize the sparsity of solutions if the Wasserstein ball is centred\nat a discrete reference measure. In comparison with the existing literature,\nwhich has proved similar results under different conditions, our proofs are\nself-contained and shorter, yet mathematically rigorous, and our necessary and\nsufficient conditions for the existence of optimal solutions are easily\nverifiable in practice.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:46:55 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 01:50:16 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Yue", "Man-Chung", ""], ["Kuhn", "Daniel", ""], ["Wiesemann", "Wolfram", ""]]}, {"id": "2004.07177", "submitter": "Jonas Latz", "authors": "Jonas Latz", "title": "Analysis of Stochastic Gradient Descent in Continuous Time", "comments": null, "journal-ref": "Statistics and Computing 31, 39, 2021", "doi": "10.1007/s11222-021-10016-8", "report-no": null, "categories": "math.PR cs.LG cs.NA math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent is an optimisation method that combines classical\ngradient descent with random subsampling within the target functional. In this\nwork, we introduce the stochastic gradient process as a continuous-time\nrepresentation of stochastic gradient descent. The stochastic gradient process\nis a dynamical system that is coupled with a continuous-time Markov process\nliving on a finite state space. The dynamical system -- a gradient flow --\nrepresents the gradient descent part, the process on the finite state space\nrepresents the random subsampling. Processes of this type are, for instance,\nused to model clonal populations in fluctuating environments. After introducing\nit, we study theoretical properties of the stochastic gradient process: We show\nthat it converges weakly to the gradient flow with respect to the full target\nfunction, as the learning rate approaches zero. We give conditions under which\nthe stochastic gradient process with constant learning rate is exponentially\nergodic in the Wasserstein sense. Then we study the case, where the learning\nrate goes to zero sufficiently slowly and the single target functions are\nstrongly convex. In this case, the process converges weakly to the point mass\nconcentrated in the global minimum of the full target function; indicating\nconsistency of the method. We conclude after a discussion of discretisation\nstrategies for the stochastic gradient process and numerical experiments.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:04:41 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 22:49:08 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2021 14:07:57 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Latz", "Jonas", ""]]}, {"id": "2004.07179", "submitter": "Dario Pasquini", "authors": "Dario Pasquini, Giuseppe Ateniese, Massimo Bernaschi", "title": "Interpretable Probabilistic Password Strength Meters via Deep Learning", "comments": "An abridged version of this paper appears in the proceedings of the\n  25th European Symposium on Research in Computer Security (ESORICS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic password strength meters have been proved to be the most\naccurate tools to measure password strength. Unfortunately, by construction,\nthey are limited to solely produce an opaque security estimation that fails to\nfully support the user during the password composition. In the present work, we\nmove the first steps towards cracking the intelligibility barrier of this\ncompelling class of meters. We show that probabilistic password meters\ninherently own the capability of describing the latent relation occurring\nbetween password strength and password structure. In our approach, the security\ncontribution of each character composing a password is disentangled and used to\nprovide explicit fine-grained feedback for the user. Furthermore, unlike\nexisting heuristic constructions, our method is free from any human bias, and,\nmore importantly, its feedback has a probabilistic interpretation. In our\ncontribution: (1) we formulate interpretable probabilistic password strength\nmeters; (2) we describe how they can be implemented via an efficient and\nlightweight deep learning framework suitable for client-side operability.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:05:50 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 11:04:04 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 09:51:16 GMT"}, {"version": "v4", "created": "Tue, 11 May 2021 18:54:22 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Pasquini", "Dario", ""], ["Ateniese", "Giuseppe", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "2004.07200", "submitter": "Jingkang Wang", "authors": "Tianshi Cao, Jingkang Wang, Yining Zhang, Sivabalan Manivasagam", "title": "BabyAI++: Towards Grounded-Language Learning beyond Memorization", "comments": "Accepted to the ICLR 2020 workshop: Beyond tabula rasa in RL\n  (BeTR-RL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite success in many real-world tasks (e.g., robotics), reinforcement\nlearning (RL) agents still learn from tabula rasa when facing new and dynamic\nscenarios. By contrast, humans can offload this burden through textual\ndescriptions. Although recent works have shown the benefits of instructive\ntexts in goal-conditioned RL, few have studied whether descriptive texts help\nagents to generalize across dynamic environments. To promote research in this\ndirection, we introduce a new platform, BabyAI++, to generate various dynamic\nenvironments along with corresponding descriptive texts. Moreover, we benchmark\nseveral baselines inherited from the instruction following setting and develop\na novel approach towards visually-grounded language learning on our platform.\nExtensive experiments show strong evidence that using descriptive texts\nimproves the generalization of RL agents across environments with varied\ndynamics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:58:19 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Cao", "Tianshi", ""], ["Wang", "Jingkang", ""], ["Zhang", "Yining", ""], ["Manivasagam", "Sivabalan", ""]]}, {"id": "2004.07202", "submitter": "Livio Baldini Soares", "authors": "Thibault F\\'evry, Livio Baldini Soares, Nicholas FitzGerald, Eunsol\n  Choi, Tom Kwiatkowski", "title": "Entities as Experts: Sparse Memory Access with Entity Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We focus on the problem of capturing declarative knowledge about entities in\nthe learned parameters of a language model. We introduce a new model - Entities\nas Experts (EAE) - that can access distinct memories of the entities mentioned\nin a piece of text. Unlike previous efforts to integrate entity knowledge into\nsequence models, EAE's entity representations are learned directly from text.\nWe show that EAE's learned representations capture sufficient knowledge to\nanswer TriviaQA questions such as \"Which Dr. Who villain has been played by\nRoger Delgado, Anthony Ainley, Eric Roberts?\", outperforming an\nencoder-generator Transformer model with 10x the parameters. According to the\nLAMA knowledge probes, EAE contains more factual knowledge than a similarly\nsized BERT, as well as previous approaches that integrate external sources of\nentity knowledge. Because EAE associates parameters with specific entities, it\nonly needs to access a fraction of its parameters at inference time, and we\nshow that the correct identification and representation of entities is\nessential to EAE's performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:00:05 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 19:00:27 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["F\u00e9vry", "Thibault", ""], ["Soares", "Livio Baldini", ""], ["FitzGerald", "Nicholas", ""], ["Choi", "Eunsol", ""], ["Kwiatkowski", "Tom", ""]]}, {"id": "2004.07210", "submitter": "Abbas Cheddad", "authors": "Abbas Cheddad", "title": "On Box-Cox Transformation for Image Normality and Pattern Classification", "comments": "The paper has 4 Tables and 6 Figures", "journal-ref": "IEEE Access, vol. 8, pp. 154975-154983, 2020", "doi": "10.1109/ACCESS.2020.3018874", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unique member of the power transformation family is known as the Box-Cox\ntransformation. The latter can be seen as a mathematical operation that leads\nto finding the optimum lambda ({\\lambda}) value that maximizes the\nlog-likelihood function to transform a data to a normal distribution and to\nreduce heteroscedasticity. In data analytics, a normality assumption underlies\na variety of statistical test models. This technique, however, is best known in\nstatistical analysis to handle one-dimensional data. Herein, this paper\nrevolves around the utility of such a tool as a pre-processing step to\ntransform two-dimensional data, namely, digital images and to study its effect.\nMoreover, to reduce time complexity, it suffices to estimate the parameter\nlambda in real-time for large two-dimensional matrices by merely considering\ntheir probability density function as a statistical inference of the underlying\ndata distribution. We compare the effect of this light-weight Box-Cox\ntransformation with well-established state-of-the-art low light image\nenhancement techniques. We also demonstrate the effectiveness of our approach\nthrough several test-bed data sets for generic improvement of visual appearance\nof images and for ameliorating the performance of a colour pattern\nclassification algorithm as an example application. Results with and without\nthe proposed approach, are compared using the AlexNet (transfer deep learning)\npretrained model. To the best of our knowledge, this is the first time that the\nBox-Cox transformation is extended to digital images by exploiting histogram\ntransformation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:10:18 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 20:00:21 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 13:13:17 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Cheddad", "Abbas", ""]]}, {"id": "2004.07211", "submitter": "Pietro Buzzega", "authors": "Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, Simone\n  Calderara", "title": "Dark Experience for General Continual Learning: a Strong, Simple\n  Baseline", "comments": "24 pages, 4 figures. Accepted at 34th Conference on Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning has inspired a plethora of approaches and evaluation\nsettings; however, the majority of them overlooks the properties of a practical\nscenario, where the data stream cannot be shaped as a sequence of tasks and\noffline training is not viable. We work towards General Continual Learning\n(GCL), where task boundaries blur and the domain and class distributions shift\neither gradually or suddenly. We address it through mixing rehearsal with\nknowledge distillation and regularization; our simple baseline, Dark Experience\nReplay, matches the network's logits sampled throughout the optimization\ntrajectory, thus promoting consistency with its past. By conducting an\nextensive analysis on both standard benchmarks and a novel GCL evaluation\nsetting (MNIST-360), we show that such a seemingly simple baseline outperforms\nconsolidated approaches and leverages limited resources. We further explore the\ngeneralization capabilities of our objective, showing its regularization being\nbeneficial beyond mere performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:13:05 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:00:23 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Buzzega", "Pietro", ""], ["Boschini", "Matteo", ""], ["Porrello", "Angelo", ""], ["Abati", "Davide", ""], ["Calderara", "Simone", ""]]}, {"id": "2004.07219", "submitter": "Justin Fu", "authors": "Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, Sergey Levine", "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning", "comments": "Website available at https://sites.google.com/view/d4rl/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The offline reinforcement learning (RL) setting (also known as full batch\nRL), where a policy is learned from a static dataset, is compelling as progress\nenables RL methods to take advantage of large, previously-collected datasets,\nmuch like how the rise of large datasets has fueled results in supervised\nlearning. However, existing online RL benchmarks are not tailored towards the\noffline setting and existing offline RL benchmarks are restricted to data\ngenerated by partially-trained agents, making progress in offline RL difficult\nto measure. In this work, we introduce benchmarks specifically designed for the\noffline setting, guided by key properties of datasets relevant to real-world\napplications of offline RL. With a focus on dataset collection, examples of\nsuch properties include: datasets generated via hand-designed controllers and\nhuman demonstrators, multitask datasets where an agent performs different tasks\nin the same environment, and datasets collected with mixtures of policies. By\nmoving beyond simple benchmark tasks and data collected by partially-trained RL\nagents, we reveal important and unappreciated deficiencies of existing\nalgorithms. To facilitate research, we have released our benchmark tasks and\ndatasets with a comprehensive evaluation of existing algorithms, an evaluation\nprotocol, and open-source examples. This serves as a common starting point for\nthe community to identify shortcomings in existing offline RL methods and a\ncollaborative route for progress in this emerging area.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:18:19 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 00:03:09 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 16:32:03 GMT"}, {"version": "v4", "created": "Sat, 6 Feb 2021 01:57:28 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fu", "Justin", ""], ["Kumar", "Aviral", ""], ["Nachum", "Ofir", ""], ["Tucker", "George", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.07223", "submitter": "Ryan Rogers", "authors": "Mark Cesar, Ryan Rogers", "title": "Bounding, Concentrating, and Truncating: Unifying Privacy Loss\n  Composition for Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy (DP) provides rigorous privacy guarantees on\nindividual's data while also allowing for accurate statistics to be conducted\non the overall, sensitive dataset. To design a private system, first private\nalgorithms must be designed that can quantify the privacy loss of each outcome\nthat is released. However, private algorithms that inject noise into the\ncomputation are not sufficient to ensure individuals' data is protected due to\nmany noisy results ultimately concentrating to the true, non-privatized result.\nHence there have been several works providing precise formulas for how the\nprivacy loss accumulates over multiple interactions with private algorithms.\nHowever, these formulas either provide very general bounds on the privacy loss,\nat the cost of being overly pessimistic for certain types of private\nalgorithms, or they can be too narrow in scope to apply to general privacy\nsystems. In this work, we unify existing privacy loss composition bounds for\nspecial classes of differentially private (DP) algorithms along with general DP\ncomposition bounds. In particular, we provide strong privacy loss bounds when\nan analyst may select pure DP, bounded range (e.g. exponential mechanisms), or\nconcentrated DP mechanisms in any order. We also provide optimal privacy loss\nbounds that apply when an analyst can select pure DP and bounded range\nmechanisms in a batch, i.e. non-adaptively. Further, when an analyst selects\nmechanisms within each class adaptively, we show a difference in privacy loss\nbetween different, predetermined orderings of pure DP and bounded range\nmechanisms. Lastly, we compare the composition bounds of Laplace and Gaussian\nmechanisms based on histogram datasets.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:33:10 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 03:40:32 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 20:20:14 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Cesar", "Mark", ""], ["Rogers", "Ryan", ""]]}, {"id": "2004.07225", "submitter": "Zahra Fatemi", "authors": "Zahra Fatemi, Elena Zheleva", "title": "Minimizing Interference and Selection Bias in Network Experiment Design", "comments": "This paper has been accepted at the International AAAI Conference on\n  Web and Social Media (ICWSM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to A/B testing in networks focus on limiting interference,\nthe concern that treatment effects can \"spill over\" from treatment nodes to\ncontrol nodes and lead to biased causal effect estimation. Prominent methods\nfor network experiment design rely on two-stage randomization, in which\nsparsely-connected clusters are identified and cluster randomization dictates\nthe node assignment to treatment and control. Here, we show that cluster\nrandomization does not ensure sufficient node randomization and it can lead to\nselection bias in which treatment and control nodes represent different\npopulations of users. To address this problem, we propose a principled\nframework for network experiment design which jointly minimizes interference\nand selection bias. We introduce the concepts of edge spillover probability and\ncluster matching and demonstrate their importance for designing network A/B\ntesting. Our experiments on a number of real-world datasets show that our\nproposed framework leads to significantly lower error in causal effect\nestimation than existing solutions.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:34:13 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Fatemi", "Zahra", ""], ["Zheleva", "Elena", ""]]}, {"id": "2004.07229", "submitter": "Deisy Morselli Gysi", "authors": "Deisy Morselli Gysi and \\'Italo Do Valle and Marinka Zitnik and Asher\n  Ameli and Xiao Gan and Onur Varol and Susan Dina Ghiassian and JJ Patten and\n  Robert Davey and Joseph Loscalzo and Albert-L\\'aszl\\'o Barab\\'asi", "title": "Network Medicine Framework for Identifying Drug Repurposing\n  Opportunities for COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current pandemic has highlighted the need for methodologies that can\nquickly and reliably prioritize clinically approved compounds for their\npotential effectiveness for SARS-CoV-2 infections. In the past decade, network\nmedicine has developed and validated multiple predictive algorithms for drug\nrepurposing, exploiting the sub-cellular network-based relationship between a\ndrug's targets and disease genes. Here, we deployed algorithms relying on\nartificial intelligence, network diffusion, and network proximity, tasking each\nof them to rank 6,340 drugs for their expected efficacy against SARS-CoV-2. To\ntest the predictions, we used as ground truth 918 drugs that had been\nexperimentally screened in VeroE6 cells, and the list of drugs under clinical\ntrial, that capture the medical community's assessment of drugs with potential\nCOVID-19 efficacy. We find that while most algorithms offer predictive power\nfor these ground truth data, no single method offers consistently reliable\noutcomes across all datasets and metrics. This prompted us to develop a\nmultimodal approach that fuses the predictions of all algorithms, showing that\na consensus among the different predictive methods consistently exceeds the\nperformance of the best individual pipelines. We find that 76 of the 77 drugs\nthat successfully reduced viral infection do not bind the proteins targeted by\nSARS-CoV-2, indicating that these drugs rely on network-based actions that\ncannot be identified using docking-based strategies. These advances offer a\nmethodological pathway to identify repurposable drugs for future pathogens and\nneglected diseases underserved by the costs and extended timeline of de novo\ndrug development.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:40:29 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 15:52:14 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gysi", "Deisy Morselli", ""], ["Valle", "\u00cdtalo Do", ""], ["Zitnik", "Marinka", ""], ["Ameli", "Asher", ""], ["Gan", "Xiao", ""], ["Varol", "Onur", ""], ["Ghiassian", "Susan Dina", ""], ["Patten", "JJ", ""], ["Davey", "Robert", ""], ["Loscalzo", "Joseph", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""]]}, {"id": "2004.07234", "submitter": "Erez Peterfreund", "authors": "Erez Peterfreund, Ofir Lindenbaum, Felix Dietrich, Tom Bertalan, Matan\n  Gavish, Ioannis G. Kevrekidis, Ronald R. Coifman", "title": "LOCA: LOcal Conformal Autoencoder for standardized data coordinates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a deep-learning based method for obtaining standardized data\ncoordinates from scientific measurements.Data observations are modeled as\nsamples from an unknown, non-linear deformation of an underlying Riemannian\nmanifold, which is parametrized by a few normalized latent variables. By\nleveraging a repeated measurement sampling strategy, we present a method for\nlearning an embedding in $\\mathbb{R}^d$ that is isometric to the latent\nvariables of the manifold. These data coordinates, being invariant under smooth\nchanges of variables, enable matching between different instrumental\nobservations of the same phenomenon. Our embedding is obtained using a LOcal\nConformal Autoencoder (LOCA), an algorithm that constructs an embedding to\nrectify deformations by using a local z-scoring procedure while preserving\nrelevant geometric information. We demonstrate the isometric embedding\nproperties of LOCA on various model settings and observe that it exhibits\npromising interpolation and extrapolation capabilities. Finally, we apply LOCA\nto single-site Wi-Fi localization data, and to $3$-dimensional curved surface\nestimation based on a $2$-dimensional projection.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:49:37 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 14:10:49 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Peterfreund", "Erez", ""], ["Lindenbaum", "Ofir", ""], ["Dietrich", "Felix", ""], ["Bertalan", "Tom", ""], ["Gavish", "Matan", ""], ["Kevrekidis", "Ioannis G.", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "2004.07266", "submitter": "Mehdi Soleimanifar", "authors": "Anurag Anshu, Srinivasan Arunachalam, Tomotaka Kuwahara, Mehdi\n  Soleimanifar", "title": "Sample-efficient learning of quantum many-body systems", "comments": "60 pages, 3 figures", "journal-ref": "Nature Physics, 2021 (Extended abstract in FOCS 2020)", "doi": "10.1038/s41567-021-01232-0", "report-no": null, "categories": "quant-ph cond-mat.stat-mech cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning the Hamiltonian of a quantum many-body\nsystem given samples from its Gibbs (thermal) state. The classical analog of\nthis problem, known as learning graphical models or Boltzmann machines, is a\nwell-studied question in machine learning and statistics. In this work, we give\nthe first sample-efficient algorithm for the quantum Hamiltonian learning\nproblem. In particular, we prove that polynomially many samples in the number\nof particles (qudits) are necessary and sufficient for learning the parameters\nof a spatially local Hamiltonian in l_2-norm.\n  Our main contribution is in establishing the strong convexity of the\nlog-partition function of quantum many-body systems, which along with the\nmaximum entropy estimation yields our sample-efficient algorithm. Classically,\nthe strong convexity for partition functions follows from the Markov property\nof Gibbs distributions. This is, however, known to be violated in its exact\nform in the quantum case. We introduce several new ideas to obtain an\nunconditional result that avoids relying on the Markov property of quantum\nsystems, at the cost of a slightly weaker bound. In particular, we prove a\nlower bound on the variance of quasi-local operators with respect to the Gibbs\nstate, which might be of independent interest. Our work paves the way toward a\nmore rigorous application of machine learning techniques to quantum many-body\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:01:59 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Anshu", "Anurag", ""], ["Arunachalam", "Srinivasan", ""], ["Kuwahara", "Tomotaka", ""], ["Soleimanifar", "Mehdi", ""]]}, {"id": "2004.07268", "submitter": "Luisa Polania", "authors": "Luisa F. Polania, Mauricio Flores, Yiran Li, and Matthew Nokleby", "title": "Learning Furniture Compatibility with Graph Neural Networks", "comments": "Accepted for publication at CVPR Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a graph neural network (GNN) approach to the problem of predicting\nthe stylistic compatibility of a set of furniture items from images. While most\nexisting results are based on siamese networks which evaluate pairwise\ncompatibility between items, the proposed GNN architecture exploits relational\ninformation among groups of items. We present two GNN models, both of which\ncomprise a deep CNN that extracts a feature representation for each image, a\ngated recurrent unit (GRU) network that models interactions between the\nfurniture items in a set, and an aggregation function that calculates the\ncompatibility score. In the first model, a generalized contrastive loss\nfunction that promotes the generation of clustered embeddings for items\nbelonging to the same furniture set is introduced. Also, in the first model,\nthe edge function between nodes in the GRU and the aggregation function are\nfixed in order to limit model complexity and allow training on smaller\ndatasets; in the second model, the edge function and aggregation function are\nlearned directly from the data. We demonstrate state-of-the art accuracy for\ncompatibility prediction and \"fill in the blank\" tasks on the Bonn and\nSingapore furniture datasets. We further introduce a new dataset, called the\nTarget Furniture Collections dataset, which contains over 6000 furniture items\nthat have been hand-curated by stylists to make up 1632 compatible sets. We\nalso demonstrate superior prediction accuracy on this dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:04:06 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Polania", "Luisa F.", ""], ["Flores", "Mauricio", ""], ["Li", "Yiran", ""], ["Nokleby", "Matthew", ""]]}, {"id": "2004.07276", "submitter": "Fernando Casta\\~neda", "authors": "Fernando Casta\\~neda, Mathias Wulfman, Ayush Agrawal, Tyler\n  Westenbroek, Claire J. Tomlin, S. Shankar Sastry, Koushil Sreenath", "title": "Improving Input-Output Linearizing Controllers for Bipedal Robots via\n  Reinforcement Learning", "comments": "Final version appearing in Learning for Dynamics and Control (L4DC)\n  2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main drawbacks of input-output linearizing controllers are the need for\nprecise dynamics models and not being able to account for input constraints.\nModel uncertainty is common in almost every robotic application and input\nsaturation is present in every real world system. In this paper, we address\nboth challenges for the specific case of bipedal robot control by the use of\nreinforcement learning techniques. Taking the structure of a standard\ninput-output linearizing controller, we use an additive learned term that\ncompensates for model uncertainty. Moreover, by adding constraints to the\nlearning problem we manage to boost the performance of the final controller\nwhen input limits are present. We demonstrate the effectiveness of the designed\nframework for different levels of uncertainty on the five-link planar walking\nrobot RABBIT.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:15:49 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 10:50:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Casta\u00f1eda", "Fernando", ""], ["Wulfman", "Mathias", ""], ["Agrawal", "Ayush", ""], ["Westenbroek", "Tyler", ""], ["Tomlin", "Claire J.", ""], ["Sastry", "S. Shankar", ""], ["Sreenath", "Koushil", ""]]}, {"id": "2004.07296", "submitter": "Neda Tavakoli", "authors": "Neda Tavakoli, Sima Siami-Namini, Mahdi Adl Khanghah, Fahimeh Mirza\n  Soltani, Akbar Siami Namin", "title": "Clustering Time Series Data through Autoencoder-based Deep Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and in particular deep learning algorithms are the emerging\napproaches to data analysis. These techniques have transformed traditional data\nmining-based analysis radically into a learning-based model in which existing\ndata sets along with their cluster labels (i.e., train set) are learned to\nbuild a supervised learning model and predict the cluster labels of unseen data\n(i.e., test set). In particular, deep learning techniques are capable of\ncapturing and learning hidden features in a given data sets and thus building a\nmore accurate prediction model for clustering and labeling problem. However,\nthe major problem is that time series data are often unlabeled and thus\nsupervised learning-based deep learning algorithms cannot be directly adapted\nto solve the clustering problems for these special and complex types of data\nsets. To address this problem, this paper introduces a two-stage method for\nclustering time series data. First, a novel technique is introduced to utilize\nthe characteristics (e.g., volatility) of given time series data in order to\ncreate labels and thus be able to transform the problem from unsupervised\nlearning into supervised learning. Second, an autoencoder-based deep learning\nmodel is built to learn and model both known and hidden features of time series\ndata along with their created labels to predict the labels of unseen time\nseries data. The paper reports a case study in which financial and stock time\nseries data of selected 70 stock indices are clustered into distinct groups\nusing the introduced two-stage procedure. The results show that the proposed\nprocedure is capable of achieving 87.5\\% accuracy in clustering and predicting\nthe labels for unseen time series data.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 18:51:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tavakoli", "Neda", ""], ["Siami-Namini", "Sima", ""], ["Khanghah", "Mahdi Adl", ""], ["Soltani", "Fahimeh Mirza", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "2004.07300", "submitter": "Jing Liu", "authors": "Yaoxin Li, Jing Liu, Guozheng Lin, Yueyuan Hou, Muyun Mou and Jiang\n  Zhang", "title": "Gumbel-softmax-based Optimization: A Simple General Framework for\n  Optimization Problems on Graphs", "comments": "arXiv admin note: text overlap with arXiv:1909.07018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer science, there exist a large number of optimization problems\ndefined on graphs, that is to find a best node state configuration or a network\nstructure such that the designed objective function is optimized under some\nconstraints. However, these problems are notorious for their hardness to solve\nbecause most of them are NP-hard or NP-complete. Although traditional general\nmethods such as simulated annealing (SA), genetic algorithms (GA) and so forth\nhave been devised to these hard problems, their accuracy and time consumption\nare not satisfying in practice. In this work, we proposed a simple, fast, and\ngeneral algorithm framework based on advanced automatic differentiation\ntechnique empowered by deep learning frameworks. By introducing Gumbel-softmax\ntechnique, we can optimize the objective function directly by gradient descent\nalgorithm regardless of the discrete nature of variables. We also introduce\nevolution strategy to parallel version of our algorithm. We test our algorithm\non three representative optimization problems on graph including modularity\noptimization from network science, Sherrington-Kirkpatrick (SK) model from\nstatistical physics, maximum independent set (MIS) and minimum vertex cover\n(MVC) problem from combinatorial optimization on graph. High-quality solutions\ncan be obtained with much less time consuming compared to traditional\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:11:00 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Li", "Yaoxin", ""], ["Liu", "Jing", ""], ["Lin", "Guozheng", ""], ["Hou", "Yueyuan", ""], ["Mou", "Muyun", ""], ["Zhang", "Jiang", ""]]}, {"id": "2004.07301", "submitter": "Andrey Guzhov", "authors": "Andrey Guzhov, Federico Raue, J\\\"orn Hees and Andreas Dengel", "title": "ESResNet: Environmental Sound Classification Based on Visual Domain\n  Models", "comments": "8 pages, 4 figures; submitted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental Sound Classification (ESC) is an active research area in the\naudio domain and has seen a lot of progress in the past years. However, many of\nthe existing approaches achieve high accuracy by relying on domain-specific\nfeatures and architectures, making it harder to benefit from advances in other\nfields (e.g., the image domain). Additionally, some of the past successes have\nbeen attributed to a discrepancy of how results are evaluated (i.e., on\nunofficial splits of the UrbanSound8K (US8K) dataset), distorting the overall\nprogression of the field.\n  The contribution of this paper is twofold. First, we present a model that is\ninherently compatible with mono and stereo sound inputs. Our model is based on\nsimple log-power Short-Time Fourier Transform (STFT) spectrograms and combines\nthem with several well-known approaches from the image domain (i.e., ResNet,\nSiamese-like networks and attention). We investigate the influence of\ncross-domain pre-training, architectural changes, and evaluate our model on\nstandard datasets. We find that our model out-performs all previously known\napproaches in a fair comparison by achieving accuracies of 97.0 % (ESC-10),\n91.5 % (ESC-50) and 84.2 % / 85.4 % (US8K mono / stereo).\n  Second, we provide a comprehensive overview of the actual state of the field,\nby differentiating several previously reported results on the US8K dataset\nbetween official or unofficial splits. For better reproducibility, our code\n(including any re-implementations) is made available.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 19:07:55 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Guzhov", "Andrey", ""], ["Raue", "Federico", ""], ["Hees", "J\u00f6rn", ""], ["Dengel", "Andreas", ""]]}, {"id": "2004.07313", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Mohammad Amin Alipour", "title": "Evaluation of Generalizability of Neural Program Analyzers under\n  Semantic-Preserving Transformations", "comments": "for related work, see arXiv:2008.01566", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundance of publicly available source code repositories, in conjunction\nwith the advances in neural networks, has enabled data-driven approaches to\nprogram analysis. These approaches, called neural program analyzers, use neural\nnetworks to extract patterns in the programs for tasks ranging from development\nproductivity to program reasoning. Despite the growing popularity of neural\nprogram analyzers, the extent to which their results are generalizable is\nunknown.\n  In this paper, we perform a large-scale evaluation of the generalizability of\ntwo popular neural program analyzers using seven semantically-equivalent\ntransformations of programs. Our results caution that in many cases the neural\nprogram analyzers fail to generalize well, sometimes to programs with\nnegligible textual differences. The results provide the initial stepping stones\nfor quantifying robustness in neural program analyzers.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 19:55:06 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 07:10:31 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "2004.07320", "submitter": "Angela Fan", "authors": "Angela Fan, Pierre Stock, Benjamin Graham, Edouard Grave, Remi\n  Gribonval, Herve Jegou, Armand Joulin", "title": "Training with Quantization Noise for Extreme Model Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of producing compact models, maximizing their accuracy\nfor a given model size. A standard solution is to train networks with\nQuantization Aware Training, where the weights are quantized during training\nand the gradients approximated with the Straight-Through Estimator. In this\npaper, we extend this approach to work beyond int8 fixed-point quantization\nwith extreme compression methods where the approximations introduced by STE are\nsevere, such as Product Quantization. Our proposal is to only quantize a\ndifferent random subset of weights during each forward, allowing for unbiased\ngradients to flow through the other weights. Controlling the amount of noise\nand its form allows for extreme compression rates while maintaining the\nperformance of the original model. As a result we establish new\nstate-of-the-art compromises between accuracy and model size both in natural\nlanguage processing and image classification. For example, applying our method\nto state-of-the-art Transformer and ConvNet architectures, we can achieve 82.5%\naccuracy on MNLI by compressing RoBERTa to 14MB and 80.0 top-1 accuracy on\nImageNet by compressing an EfficientNet-B3 to 3.3MB.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 20:10:53 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 11:59:18 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 21:43:34 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Fan", "Angela", ""], ["Stock", "Pierre", ""], ["Graham", "Benjamin", ""], ["Grave", "Edouard", ""], ["Gribonval", "Remi", ""], ["Jegou", "Herve", ""], ["Joulin", "Armand", ""]]}, {"id": "2004.07333", "submitter": "Colin Bellinger", "authors": "Colin Bellinger, Rory Coles, Mark Crowley, and Isaac Tamblyn", "title": "Reinforcement Learning in a Physics-Inspired Semi-Markov Environment", "comments": "To appear in the Canadian Conference on Artificial Intelligence, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has been demonstrated to have great potential in\nmany applications of scientific discovery and design. Recent work includes, for\nexample, the design of new structures and compositions of molecules for\ntherapeutic drugs. Much of the existing work related to the application of RL\nto scientific domains, however, assumes that the available state representation\nobeys the Markov property. For reasons associated with time, cost, sensor\naccuracy, and gaps in scientific knowledge, many scientific design and\ndiscovery problems do not satisfy the Markov property. Thus, something other\nthan a Markov decision process (MDP) should be used to plan / find the optimal\npolicy. In this paper, we present a physics-inspired semi-Markov RL\nenvironment, namely the phase change environment. In addition, we evaluate the\nperformance of value-based RL algorithms for both MDPs and partially observable\nMDPs (POMDPs) on the proposed environment. Our results demonstrate deep\nrecurrent Q-networks (DRQN) significantly outperform deep Q-networks (DQN), and\nthat DRQNs benefit from training with hindsight experience replay. Implications\nfor the use of semi-Markovian RL and POMDPs for scientific laboratories are\nalso discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 20:43:29 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bellinger", "Colin", ""], ["Coles", "Rory", ""], ["Crowley", "Mark", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2004.07341", "submitter": "Yuanfei Dai", "authors": "Yuanfei Dai, Chenhao Guo, Wenzhong Guo, Carsten Eickhoff", "title": "Drug-Drug Interaction Prediction with Wasserstein Adversarial\n  Autoencoder-based Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction between pharmacological agents can trigger unexpected adverse\nevents. Capturing richer and more comprehensive information about drug-drug\ninteractions (DDI) is one of the key tasks in public health and drug\ndevelopment. Recently, several knowledge graph embedding approaches have\nreceived increasing attention in the DDI domain due to their capability of\nprojecting drugs and interactions into a low-dimensional feature space for\npredicting links and classifying triplets. However, existing methods only apply\na uniformly random mode to construct negative samples. As a consequence, these\nsamples are often too simplistic to train an effective model. In this paper, we\npropose a new knowledge graph embedding framework by introducing adversarial\nautoencoders (AAE) based on Wasserstein distances and Gumbel-Softmax relaxation\nfor drug-drug interactions tasks. In our framework, the autoencoder is employed\nto generate high-quality negative samples and the hidden vector of the\nautoencoder is regarded as a plausible drug candidate. Afterwards, the\ndiscriminator learns the embeddings of drugs and interactions based on both\npositive and negative triplets. Meanwhile, in order to solve vanishing gradient\nproblems on the discrete representation--an inherent flaw in traditional\ngenerative models--we utilize the Gumbel-Softmax relaxation and the Wasserstein\ndistance to train the embedding model steadily. We empirically evaluate our\nmethod on two tasks, link prediction and DDI classification. The experimental\nresults show that our framework can attain significant improvements and\nnoticeably outperform competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:03:29 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:02:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Dai", "Yuanfei", ""], ["Guo", "Chenhao", ""], ["Guo", "Wenzhong", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2004.07346", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Yuval Rabani, Mark Sellke", "title": "Online Multiserver Convex Chasing and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of $k$-chasing of convex functions, a simultaneous\ngeneralization of both the famous k-server problem in $R^d$, and of the problem\nof chasing convex bodies and functions. Aside from fundamental interest in this\ngeneral form, it has natural applications to online $k$-clustering problems\nwith objectives such as $k$-median or $k$-means. We show that this problem\nexhibits a rich landscape of behavior. In general, if both $k > 1$ and $d > 1$\nthere does not exist any online algorithm with bounded competitiveness. By\ncontrast, we exhibit a class of nicely behaved functions (which include in\nparticular the above-mentioned clustering problems), for which we show that\ncompetitive online algorithms exist, and moreover with dimension-free\ncompetitive ratio. We also introduce a parallel question of top-$k$ action\nregret minimization in the realm of online convex optimization. There, too, a\nmuch rougher landscape emerges for $k > 1$. While it is possible to achieve\nvanishing regret, unlike the top-one action case the rate of vanishing does not\nspeed up for strongly convex functions. Moreover, vanishing regret necessitates\nboth intractable computations and randomness. Finally we leave open whether\nalmost dimension-free regret is achievable for $k > 1$ and general convex\nlosses. As evidence that it might be possible, we prove dimension-free regret\nfor linear losses via an information-theoretic argument.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:17:10 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Rabani", "Yuval", ""], ["Sellke", "Mark", ""]]}, {"id": "2004.07348", "submitter": "Michael Trosset", "authors": "Michael W. Trosset, Mingyue Gao, Minh Tang, Carey E. Priebe", "title": "Learning 1-Dimensional Submanifolds for Subsequent Inference on Random\n  Dot Product Graphs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random dot product graph (RDPG) is a generative model for networks in which\nvertices correspond to positions in a latent Euclidean space and edge\nprobabilities are determined by the dot products of the latent positions. We\nconsider RDPGs for which the latent positions are randomly sampled from an\nunknown $1$-dimensional submanifold of the latent space. In principle,\nrestricted inference, i.e., procedures that exploit the structure of the\nsubmanifold, should be more effective than unrestricted inference; however, it\nis not clear how to conduct restricted inference when the submanifold is\nunknown. We submit that techniques for manifold learning can be used to learn\nthe unknown submanifold well enough to realize benefit from restricted\ninference. To illustrate, we test $1$- and $2$-sample hypotheses about the\nFr\\'{e}chet means of small communities of vertices, using the complete set of\nvertices to infer latent structure. We propose test statistics that deploy the\nIsomap procedure for manifold learning, using shortest path distances on\nneighborhood graphs constructed from estimated latent positions to estimate arc\nlengths on the unknown $1$-dimensional submanifold. Unlike conventional\napplications of Isomap, the estimated latent positions do not lie on the\nsubmanifold of interest. We extend existing convergence results for Isomap to\nthis setting and use them to demonstrate that, as the number of auxiliary\nvertices increases, the power of our test converges to the power of the\ncorresponding test when the submanifold is known.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:20:10 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:32:50 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:41:56 GMT"}, {"version": "v4", "created": "Wed, 7 Jul 2021 16:10:07 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Trosset", "Michael W.", ""], ["Gao", "Mingyue", ""], ["Tang", "Minh", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2004.07351", "submitter": "Richeng Jin", "authors": "Richeng Jin, Xiaofan He and Huaiyu Dai", "title": "On the Design of Communication Efficient Federated Learning over\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, federated learning (FL), as a promising distributed machine\nlearning approach, has attracted lots of research efforts. In FL, the parameter\nserver and the mobile devices share the training parameters over wireless\nlinks. As a result, reducing the communication overhead becomes one of the most\ncritical challenges. Despite that there have been various\ncommunication-efficient machine learning algorithms in literature, few of the\nexisting works consider their implementation over wireless networks. In this\nwork, the idea of SignSGD is adopted and only the signs of the gradients are\nshared between the mobile devices and the parameter server. In addition,\ndifferent from most of the existing works that consider Channel State\nInformation (CSI) at both the transmitter side and the receiver side, only\nreceiver side CSI is assumed. In such a case, an essential problem for the\nmobile devices is to select appropriate local processing and communication\nparameters. In particular, two tradeoffs are observed under a fixed total\ntraining time: (i) given the time for each communication round, the energy\nconsumption versus the outage probability per communication round and (ii)\ngiven the energy consumption, the number of communication rounds versus the\noutage probability per communication round. Two optimization problems regarding\nthe aforementioned two tradeoffs are formulated and solved. The first problem\nminimizes the energy consumption given the outage probability (and therefore\nthe learning performance) requirement while the second problem optimizes the\nlearning performance given the energy consumption requirement. Furthermore, the\nheterogeneous data distribution scenario is considered and a new algorithm that\ncan deal with heterogeneous data distribution is proposed. Extensive\nsimulations are performed to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:25:13 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 03:26:37 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Jin", "Richeng", ""], ["He", "Xiaofan", ""], ["Dai", "Huaiyu", ""]]}, {"id": "2004.07352", "submitter": "Ralf L\\\"ammel", "authors": "John Ahlgren, Maria Eugenia Berezin, Kinga Bojarczuk, Elena Dulskyte,\n  Inna Dvortsova, Johann George, Natalija Gucevska, Mark Harman, Shan He, Ralf\n  L\\\"ammel, Erik Meijer, Silvia Sapora, and Justin Spahr-Summers", "title": "Ownership at Large -- Open Problems and Challenges in Ownership\n  Management", "comments": "Author order is alphabetical. Contact author: Ralf L\\\"ammel\n  (rlaemmel@acm.org). The subject of the paper is covered by the contact\n  author's keynote at the same conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software-intensive organizations rely on large numbers of software assets of\ndifferent types, e.g., source-code files, tables in the data warehouse, and\nsoftware configurations. Who is the most suitable owner of a given asset\nchanges over time, e.g., due to reorganization and individual function changes.\nNew forms of automation can help suggest more suitable owners for any given\nasset at a given point in time. By such efforts on ownership health,\naccountability of ownership is increased. The problem of finding the most\nsuitable owners for an asset is essentially a program comprehension problem:\nhow do we automatically determine who would be best placed to understand,\nmaintain, evolve (and thereby assume ownership of) a given asset. This paper\nintroduces the Facebook Ownesty system, which uses a combination of ultra large\nscale data mining and machine learning and has been deployed at Facebook as\npart of the company's ownership management approach. Ownesty processes many\nmillions of software assets (e.g., source-code files) and it takes into account\nworkflow and organizational aspects. The paper sets out open problems and\nchallenges on ownership for the research community with advances expected from\nthe fields of software engineering, programming languages, and machine\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 21:26:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ahlgren", "John", ""], ["Berezin", "Maria Eugenia", ""], ["Bojarczuk", "Kinga", ""], ["Dulskyte", "Elena", ""], ["Dvortsova", "Inna", ""], ["George", "Johann", ""], ["Gucevska", "Natalija", ""], ["Harman", "Mark", ""], ["He", "Shan", ""], ["L\u00e4mmel", "Ralf", ""], ["Meijer", "Erik", ""], ["Sapora", "Silvia", ""], ["Spahr-Summers", "Justin", ""]]}, {"id": "2004.07370", "submitter": "Kaizhi Qian", "authors": "Kaizhi Qian, Zeyu Jin, Mark Hasegawa-Johnson, Gautham J. Mysore", "title": "F0-consistent many-to-many non-parallel voice conversion via conditional\n  autoencoder", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9054734", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel many-to-many voice conversion remains an interesting but\nchallenging speech processing task. Many style-transfer-inspired methods such\nas generative adversarial networks (GANs) and variational autoencoders (VAEs)\nhave been proposed. Recently, AutoVC, a conditional autoencoders (CAEs) based\nmethod achieved state-of-the-art results by disentangling the speaker identity\nand speech content using information-constraining bottlenecks, and it achieves\nzero-shot conversion by swapping in a different speaker's identity embedding to\nsynthesize a new voice. However, we found that while speaker identity is\ndisentangled from speech content, a significant amount of prosodic information,\nsuch as source F0, leaks through the bottleneck, causing target F0 to fluctuate\nunnaturally. Furthermore, AutoVC has no control of the converted F0 and thus\nunsuitable for many applications. In the paper, we modified and improved\nautoencoder-based voice conversion to disentangle content, F0, and speaker\nidentity at the same time. Therefore, we can control the F0 contour, generate\nspeech with F0 consistent with the target speaker, and significantly improve\nquality and similarity. We support our improvement through quantitative and\nqualitative analysis.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:00:06 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Qian", "Kaizhi", ""], ["Jin", "Zeyu", ""], ["Hasegawa-Johnson", "Mark", ""], ["Mysore", "Gautham J.", ""]]}, {"id": "2004.07383", "submitter": "Brian Lucena", "authors": "Brian Lucena", "title": "Exploiting Categorical Structure Using Tree-Based Methods", "comments": "To appear in AISTATS 2020 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods of using categorical variables as predictors either endow\nthem with an ordinal structure or assume they have no structure at all.\nHowever, categorical variables often possess structure that is more complicated\nthan a linear ordering can capture. We develop a mathematical framework for\nrepresenting the structure of categorical variables and show how to generalize\ndecision trees to make use of this structure. This approach is applicable to\nmethods such as Gradient Boosted Trees which use a decision tree as the\nunderlying learner. We show results on weather data to demonstrate the\nimprovement yielded by this approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:58:27 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lucena", "Brian", ""]]}, {"id": "2004.07384", "submitter": "Anirudh Som", "authors": "Afra Nawar, Farhan Rahman, Narayanan Krishnamurthi, Anirudh Som and\n  Pavan Turaga", "title": "Topological Descriptors for Parkinson's Disease Classification and\n  Regression Analysis", "comments": "Accepted in the 42nd Annual International Conferences of the IEEE\n  Engineering in Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the vast majority of human subjects with neurological disease are\nstill diagnosed through in-person assessments and qualitative analysis of\npatient data. In this paper, we propose to use Topological Data Analysis (TDA)\ntogether with machine learning tools to automate the process of Parkinson's\ndisease classification and severity assessment. An automated, stable, and\naccurate method to evaluate Parkinson's would be significant in streamlining\ndiagnoses of patients and providing families more time for corrective measures.\nWe propose a methodology which incorporates TDA into analyzing Parkinson's\ndisease postural shifts data through the representation of persistence images.\nStudying the topology of a system has proven to be invariant to small changes\nin data and has been shown to perform well in discrimination tasks. The\ncontributions of the paper are twofold. We propose a method to 1) classify\nhealthy patients from those afflicted by disease and 2) diagnose the severity\nof disease. We explore the use of the proposed method in an application\ninvolving a Parkinson's disease dataset comprised of healthy-elderly,\nhealthy-young and Parkinson's disease patients. Our code is available at\nhttps://github.com/itsmeafra/Sublevel-Set-TDA.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:59:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:09:16 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Nawar", "Afra", ""], ["Rahman", "Farhan", ""], ["Krishnamurthi", "Narayanan", ""], ["Som", "Anirudh", ""], ["Turaga", "Pavan", ""]]}, {"id": "2004.07388", "submitter": "Ali Siahkoohi", "authors": "Mi Zhang and Ali Siahkoohi and Felix J. Herrmann", "title": "Transfer learning in large-scale ocean bottom seismic wavefield\n  reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Achieving desirable receiver sampling in ocean bottom acquisition is often\nnot possible because of cost considerations. Assuming adequate source sampling\nis available, which is achievable by virtue of reciprocity and the use of\nmodern randomized (simultaneous-source) marine acquisition technology, we are\nin a position to train convolutional neural networks (CNNs) to bring the\nreceiver sampling to the same spatial grid as the dense source sampling. To\naccomplish this task, we form training pairs consisting of densely sampled data\nand artificially subsampled data using a reciprocity argument and the\nassumption that the source-site sampling is dense. While this approach has\nsuccessfully been used on the recovery monochromatic frequency slices, its\napplication in practice calls for wavefield reconstruction of time-domain data.\nDespite having the option to parallelize, the overall costs of this approach\ncan become prohibitive if we decide to carry out the training and recovery\nindependently for each frequency. Because different frequency slices share\ninformation, we propose the use the method of transfer training to make our\napproach computationally more efficient by warm starting the training with CNN\nweights obtained from a neighboring frequency slices. If the two neighboring\nfrequency slices share information, we would expect the training to improve and\nconverge faster. Our aim is to prove this principle by carrying a series of\ncarefully selected experiments on a relatively large-scale five-dimensional\ndata synthetic data volume associated with wide-azimuth 3D ocean bottom node\nacquisition. From these experiments, we observe that by transfer training we\nare able t significantly speedup in the training, specially at relatively\nhigher frequencies where consecutive frequency slices are more correlated.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 23:14:36 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Zhang", "Mi", ""], ["Siahkoohi", "Ali", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2004.07395", "submitter": "Manyou Ma", "authors": "Manyou Ma and Vincent W.S. Wong", "title": "Joint User Pairing and Association for Multicell NOMA: A Pointer\n  Network-based Approach", "comments": "accepted for publication in Proc. of 6th International Workshop on\n  NOMA for 5G and Beyond, co-located with IEEE International Conference on\n  Communications (ICC), Dublin, Ireland, Jun. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the joint user pairing and association problem\nfor multicell non-orthogonal multiple access (NOMA) systems. We consider a\nscenario where the user equipments (UEs) are located in a multicell network\nequipped with multiple base stations. Each base station has multiple orthogonal\nphysical resource blocks (PRBs). Each PRB can be allocated to a pair of UEs\nusing NOMA. Each UE has the additional freedom to be served by any one of the\nbase stations, which further increases the complexity of the joint user pairing\nand association algorithm design. Leveraging the recent success on using\nmachine learning to solve numerical optimization problems, we formulate the\njoint user pairing and association problem as a combinatorial optimization\nproblem. The solution is found using an emerging deep learning architecture\ncalled Pointer Network (PtrNet), which has a lower computational complexity\ncompared to solutions based on iterative algorithms and has been proven to\nachieve near-optimal performance. The training phase of the PtrNet is based on\ndeep reinforcement learning (DRL), and does not require the use of the optimal\nsolution of the formulated problem as training labels. Simulation results show\nthat the proposed joint user pairing and association scheme achieves\nnear-optimal performance in terms of the aggregate data rate, and outperforms\nthe random user pairing and association heuristic by up to 30%.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 23:42:19 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ma", "Manyou", ""], ["Wong", "Vincent W. S.", ""]]}, {"id": "2004.07399", "submitter": "Shivam Kalra", "authors": "Mohammed Adnan, Shivam Kalra, Hamid R. Tizhoosh", "title": "Representation Learning of Histopathology Images using Graph Neural\n  Networks", "comments": "Published in CVMI at CVPR Workshops, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning for Whole Slide Images (WSIs) is pivotal in\ndeveloping image-based systems to achieve higher precision in diagnostic\npathology. We propose a two-stage framework for WSI representation learning. We\nsample relevant patches using a color-based method and use graph neural\nnetworks to learn relations among sampled patches to aggregate the image\ninformation into a single vector representation. We introduce attention via\ngraph pooling to automatically infer patches with higher relevance. We\ndemonstrate the performance of our approach for discriminating two sub-types of\nlung cancers, Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma (LUSC).\nWe collected 1,026 lung cancer WSIs with the 40$\\times$ magnification from The\nCancer Genome Atlas (TCGA) dataset, the largest public repository of\nhistopathology images and achieved state-of-the-art accuracy of 88.8% and AUC\nof 0.89 on lung cancer sub-type classification by extracting features from a\npre-trained DenseNet\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 00:09:20 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 16:39:26 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Adnan", "Mohammed", ""], ["Kalra", "Shivam", ""], ["Tizhoosh", "Hamid R.", ""]]}, {"id": "2004.07401", "submitter": "David Solans", "authors": "David Solans, Battista Biggio, Carlos Castillo", "title": "Poisoning Attacks on Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research in adversarial machine learning has shown how the performance of\nmachine learning models can be seriously compromised by injecting even a small\nfraction of poisoning points into the training data. While the effects on model\naccuracy of such poisoning attacks have been widely studied, their potential\neffects on other model performance metrics remain to be evaluated. In this\nwork, we introduce an optimization framework for poisoning attacks against\nalgorithmic fairness, and develop a gradient-based poisoning attack aimed at\nintroducing classification disparities among different groups in the data. We\nempirically show that our attack is effective not only in the white-box\nsetting, in which the attacker has full access to the target model, but also in\na more challenging black-box scenario in which the attacks are optimized\nagainst a substitute model and then transferred to the target model. We believe\nthat our findings pave the way towards the definition of an entirely novel set\nof adversarial attacks targeting algorithmic fairness in different scenarios,\nand that investigating such vulnerabilities will help design more robust\nalgorithms and countermeasures in the future.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 08:07:01 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 13:09:38 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 08:17:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Solans", "David", ""], ["Biggio", "Battista", ""], ["Castillo", "Carlos", ""]]}, {"id": "2004.07407", "submitter": "Aryan Mobiny", "authors": "Aryan Mobiny, Pietro Antonio Cicalese, Samira Zare, Pengyu Yuan,\n  Mohammadsajad Abavisani, Carol C. Wu, Jitesh Ahuja, Patricia M. de Groot,\n  Hien Van Nguyen", "title": "Radiologist-Level COVID-19 Detection Using CT Scans with Detail-Oriented\n  Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiographic images offer an alternative method for the rapid screening and\nmonitoring of Coronavirus Disease 2019 (COVID-19) patients. This approach is\nlimited by the shortage of radiology experts who can provide a timely\ninterpretation of these images. Motivated by this challenge, our paper proposes\na novel learning architecture, called Detail-Oriented Capsule Networks\n(DECAPS), for the automatic diagnosis of COVID-19 from Computed Tomography (CT)\nscans. Our network combines the strength of Capsule Networks with several\narchitecture improvements meant to boost classification accuracies. First,\nDECAPS uses an Inverted Dynamic Routing mechanism which increases model\nstability by preventing the passage of information from non-descriptive\nregions. Second, DECAPS employs a Peekaboo training procedure which uses a\ntwo-stage patch crop and drop strategy to encourage the network to generate\nactivation maps for every target concept. The network then uses the activation\nmaps to focus on regions of interest and combines both coarse and fine-grained\nrepresentations of the data. Finally, we use a data augmentation method based\non conditional generative adversarial networks to deal with the issue of data\nscarcity. Our model achieves 84.3% precision, 91.5% recall, and 96.1% area\nunder the ROC curve, significantly outperforming state-of-the-art methods. We\ncompare the performance of the DECAPS model with three experienced,\nwell-trained thoracic radiologists and show that the architecture significantly\noutperforms them. While further studies on larger datasets are required to\nconfirm this finding, our results imply that architectures like DECAPS can be\nused to assist radiologists in the CT scan mediated diagnosis of COVID-19.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 00:48:32 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Mobiny", "Aryan", ""], ["Cicalese", "Pietro Antonio", ""], ["Zare", "Samira", ""], ["Yuan", "Pengyu", ""], ["Abavisani", "Mohammadsajad", ""], ["Wu", "Carol C.", ""], ["Ahuja", "Jitesh", ""], ["de Groot", "Patricia M.", ""], ["Van Nguyen", "Hien", ""]]}, {"id": "2004.07414", "submitter": "Jungtaek Kim", "authors": "Jungtaek Kim, Hyunsoo Chung, Jinhwi Lee, Minsu Cho, Jaesik Park", "title": "Combinatorial 3D Shape Generation via Sequential Assembly", "comments": "14 pages, 20 figures, 1 table, presented at NeurIPS 2020 Workshop on\n  Machine Learning for Engineering Modeling, Simulation, and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential assembly with geometric primitives has drawn attention in robotics\nand 3D vision since it yields a practical blueprint to construct a target\nshape. However, due to its combinatorial property, a greedy method falls short\nof generating a sequence of volumetric primitives. To alleviate this\nconsequence induced by a huge number of feasible combinations, we propose a\ncombinatorial 3D shape generation framework. The proposed framework reflects an\nimportant aspect of human generation processes in real life -- we often create\na 3D shape by sequentially assembling unit primitives with geometric\nconstraints. To find the desired combination regarding combination evaluations,\nwe adopt Bayesian optimization, which is able to exploit and explore\nefficiently the feasible regions constrained by the current primitive\nplacements. An evaluation function conveys global structure guidance for an\nassembly process and stability in terms of gravity and external forces\nsimultaneously. Experimental results demonstrate that our method successfully\ngenerates combinatorial 3D shapes and simulates more realistic generation\nprocesses. We also introduce a new dataset for combinatorial 3D shape\ngeneration. All the codes are available at\n\\url{https://github.com/POSTECH-CVLab/Combinatorial-3D-Shape-Generation}.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 01:23:14 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 03:51:49 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kim", "Jungtaek", ""], ["Chung", "Hyunsoo", ""], ["Lee", "Jinhwi", ""], ["Cho", "Minsu", ""], ["Park", "Jaesik", ""]]}, {"id": "2004.07425", "submitter": "Yang Liu", "authors": "Yang Liu, Xiong Zhang, Shuqi Qin, and Xiaoping Lei", "title": "Differentially Private Linear Regression over Fully Decentralized\n  Datasets", "comments": "FL-NeurIPS'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a differentially private algorithm for linear regression\nlearning in a decentralized fashion. Under this algorithm, privacy budget is\ntheoretically derived, in addition to that the solution error is shown to be\nbounded by $O(t)$ for $O(1/t)$ descent step size and $O(\\exp(t^{1-e}))$ for\n$O(t^{-e})$ descent step size.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 02:48:21 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Xiong", ""], ["Qin", "Shuqi", ""], ["Lei", "Xiaoping", ""]]}, {"id": "2004.07427", "submitter": "Yang Liu", "authors": "Yang Liu, Xiong Zhang, and Libin Wang", "title": "Asymmetrical Vertical Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed machine learning method that aims to\npreserve the privacy of sample features and labels. In a federated learning\nsystem, ID-based sample alignment approaches are usually applied with few\nefforts made on the protection of ID privacy. In real-life applications,\nhowever, the confidentiality of sample IDs, which are the strongest row\nidentifiers, is also drawing much attention from many participants. To relax\ntheir privacy concerns about ID privacy, this paper formally proposes the\nnotion of asymmetrical vertical federated learning and illustrates the way to\nprotect sample IDs. The standard private set intersection protocol is adapted\nto achieve the asymmetrical ID alignment phase in an asymmetrical vertical\nfederated learning system. Correspondingly, a Pohlig-Hellman realization of the\nadapted protocol is provided. This paper also presents a genuine with dummy\napproach to achieving asymmetrical federated model training. To illustrate its\napplication, a federated logistic regression algorithm is provided as an\nexample. Experiments are also made for validating the feasibility of this\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 02:53:48 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 07:23:55 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 08:20:06 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Xiong", ""], ["Wang", "Libin", ""]]}, {"id": "2004.07437", "submitter": "Chitwan Saharia", "authors": "Chitwan Saharia, William Chan, Saurabh Saxena, Mohammad Norouzi", "title": "Non-Autoregressive Machine Translation with Latent Alignments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents two strong methods, CTC and Imputer, for\nnon-autoregressive machine translation that model latent alignments with\ndynamic programming. We revisit CTC for machine translation and demonstrate\nthat a simple CTC model can achieve state-of-the-art for single-step\nnon-autoregressive machine translation, contrary to what prior work indicates.\nIn addition, we adapt the Imputer model for non-autoregressive machine\ntranslation and demonstrate that Imputer with just 4 generation steps can match\nthe performance of an autoregressive Transformer baseline. Our latent alignment\nmodels are simpler than many existing non-autoregressive translation baselines;\nfor example, we do not require target length prediction or re-scoring with an\nautoregressive model. On the competitive WMT'14 En$\\rightarrow$De task, our CTC\nmodel achieves 25.7 BLEU with a single generation step, while Imputer achieves\n27.5 BLEU with 2 generation steps, and 28.0 BLEU with 4 generation steps. This\ncompares favourably to the autoregressive Transformer baseline at 27.8 BLEU.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 03:45:56 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 17:34:48 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 13:08:49 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Saharia", "Chitwan", ""], ["Chan", "William", ""], ["Saxena", "Saurabh", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "2004.07453", "submitter": "Gabriel Stanovsky", "authors": "Roy Schwartz, Gabriel Stanovsky, Swabha Swayamdipta, Jesse Dodge and\n  Noah A. Smith", "title": "The Right Tool for the Job: Matching Model and Instance Complexities", "comments": "ACL 2020; 12 pages; code available in\n  https://github.com/allenai/sledgehammer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As NLP models become larger, executing a trained model requires significant\ncomputational resources incurring monetary and environmental costs. To better\nrespect a given inference budget, we propose a modification to contextual\nrepresentation fine-tuning which, during inference, allows for an early (and\nfast) \"exit\" from neural network calculations for simple instances, and late\n(and accurate) exit for hard instances. To achieve this, we add classifiers to\ndifferent layers of BERT and use their calibrated confidence scores to make\nearly exit decisions. We test our proposed modification on five different\ndatasets in two tasks: three text classification datasets and two natural\nlanguage inference benchmarks. Our method presents a favorable speed/accuracy\ntradeoff in almost all cases, producing models which are up to five times\nfaster than the state of the art, while preserving their accuracy. Our method\nalso requires almost no additional training resources (in either time or\nparameters) compared to the baseline BERT model. Finally, our method alleviates\nthe need for costly retraining of multiple models at different levels of\nefficiency; we allow users to control the inference speed/accuracy tradeoff\nusing a single trained model, by setting a single variable at inference time.\nWe publicly release our code.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 04:28:08 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 03:45:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Schwartz", "Roy", ""], ["Stanovsky", "Gabriel", ""], ["Swayamdipta", "Swabha", ""], ["Dodge", "Jesse", ""], ["Smith", "Noah A.", ""]]}, {"id": "2004.07473", "submitter": "Patrick Ebel", "authors": "Patrick Ebel, Ibrahim Emre G\\\"ol, Christoph Lingenfelder and Andreas\n  Vogelsang", "title": "Destination Prediction Based on Partial Trajectory Data", "comments": "2020 IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-thirds of the people who buy a new car prefer to use a substitute instead\nof the built-in navigation system. However, for many applications, knowledge\nabout a user's intended destination and route is crucial. For example,\nsuggestions for available parking spots close to the destination can be made or\nride-sharing opportunities along the route are facilitated. Our approach\npredicts probable destinations and routes of a vehicle, based on the most\nrecent partial trajectory and additional contextual data. The approach follows\na three-step procedure: First, a $k$-d tree-based space discretization is\nperformed, mapping GPS locations to discrete regions. Secondly, a recurrent\nneural network is trained to predict the destination based on partial sequences\nof trajectories. The neural network produces destination scores, signifying the\nprobability of each region being the destination. Finally, the routes to the\nmost probable destinations are calculated. To evaluate the method, we compare\nmultiple neural architectures and present the experimental results of the\ndestination prediction. The experiments are based on two public datasets of\nnon-personalized, timestamped GPS locations of taxi trips. The best performing\nmodels were able to predict the destination of a vehicle with a mean error of\n1.3 km and 1.43 km respectively.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:26:10 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ebel", "Patrick", ""], ["G\u00f6l", "Ibrahim Emre", ""], ["Lingenfelder", "Christoph", ""], ["Vogelsang", "Andreas", ""]]}, {"id": "2004.07478", "submitter": "Deepak Singh", "authors": "Deepak Singh, Dilip Singh Sisodia, Pradeep Singh", "title": "Multi-Objective Evolutionary approach for the Performance Improvement of\n  Learners using Ensembling Feature selection and Discretization Technique on\n  Medical data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomedical data is filled with continuous real values; these values in the\nfeature set tend to create problems like underfitting, the curse of\ndimensionality and increase in misclassification rate because of higher\nvariance. In response, pre-processing techniques on dataset minimizes the side\neffects and have shown success in maintaining the adequate accuracy. Feature\nselection and discretization are the two necessary preprocessing steps that\nwere effectively employed to handle the data redundancies in the biomedical\ndata. However, in the previous works, the absence of unified effort by\nintegrating feature selection and discretization together in solving the data\nredundancy problem leads to the disjoint and fragmented field. This paper\nproposes a novel multi-objective based dimensionality reduction framework,\nwhich incorporates both discretization and feature reduction as an ensemble\nmodel for performing feature selection and discretization. Selection of optimal\nfeatures and the categorization of discretized and non-discretized features\nfrom the feature subset is governed by the multi-objective genetic algorithm\n(NSGA-II). The two objective, minimizing the error rate during the feature\nselection and maximizing the information gain while discretization is\nconsidered as fitness criteria.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:32:15 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Singh", "Deepak", ""], ["Sisodia", "Dilip Singh", ""], ["Singh", "Pradeep", ""]]}, {"id": "2004.07493", "submitter": "Bill Yuchen Lin", "authors": "Bill Yuchen Lin, Dong-Ho Lee, Ming Shen, Ryan Moreno, Xiao Huang,\n  Prashant Shiralkar, Xiang Ren", "title": "TriggerNER: Learning with Entity Triggers as Explanations for Named\n  Entity Recognition", "comments": "Accepted to the ACL 2020. Project page:\n  https://inklab.usc.edu/TriggerNER/ (Fixed a few typos and added a new\n  figure.)", "journal-ref": "Proc. of ACL 2020, page 8503--8511", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural models for named entity recognition (NER) in a new domain\noften requires additional human annotations (e.g., tens of thousands of labeled\ninstances) that are usually expensive and time-consuming to collect. Thus, a\ncrucial research question is how to obtain supervision in a cost-effective way.\nIn this paper, we introduce \"entity triggers,\" an effective proxy of human\nexplanations for facilitating label-efficient learning of NER models. An entity\ntrigger is defined as a group of words in a sentence that helps to explain why\nhumans would recognize an entity in the sentence.\n  We crowd-sourced 14k entity triggers for two well-studied NER datasets. Our\nproposed model, Trigger Matching Network, jointly learns trigger\nrepresentations and soft matching module with self-attention such that can\ngeneralize to unseen sentences easily for tagging. Our framework is\nsignificantly more cost-effective than the traditional neural NER frameworks.\nExperiments show that using only 20% of the trigger-annotated sentences results\nin a comparable performance as using 70% of conventional annotated sentences.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:27:43 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 10:06:37 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 07:43:25 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 01:10:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Lin", "Bill Yuchen", ""], ["Lee", "Dong-Ho", ""], ["Shen", "Ming", ""], ["Moreno", "Ryan", ""], ["Huang", "Xiao", ""], ["Shiralkar", "Prashant", ""], ["Ren", "Xiang", ""]]}, {"id": "2004.07499", "submitter": "Bill Yuchen Lin", "authors": "Dong-Ho Lee, Rahul Khanna, Bill Yuchen Lin, Jamin Chen, Seyeon Lee,\n  Qinyuan Ye, Elizabeth Boschee, Leonardo Neves, Xiang Ren", "title": "LEAN-LIFE: A Label-Efficient Annotation Framework Towards Learning from\n  Explanation", "comments": "Accepted to the ACL 2020 (demo). The first two authors contributed\n  equally. Project page: http://inklab.usc.edu/leanlife/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successfully training a deep neural network demands a huge corpus of labeled\ndata. However, each label only provides limited information to learn from and\ncollecting the requisite number of labels involves massive human effort. In\nthis work, we introduce LEAN-LIFE, a web-based, Label-Efficient AnnotatioN\nframework for sequence labeling and classification tasks, with an easy-to-use\nUI that not only allows an annotator to provide the needed labels for a task,\nbut also enables LearnIng From Explanations for each labeling decision. Such\nexplanations enable us to generate useful additional labeled data from\nunlabeled instances, bolstering the pool of available training data. On three\npopular NLP tasks (named entity recognition, relation extraction, sentiment\nanalysis), we find that using this enhanced supervision allows our models to\nsurpass competitive baseline F1 scores by more than 5-10 percentage points,\nwhile using 2X times fewer labeled instances. Our framework is the first to\nutilize this enhanced supervision technique and does so for three important\ntasks -- thus providing improved annotation recommendations to users and an\nability to build datasets of (data, label, explanation) triples instead of the\nregular (data, label) pair.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:38:07 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Dong-Ho", ""], ["Khanna", "Rahul", ""], ["Lin", "Bill Yuchen", ""], ["Chen", "Jamin", ""], ["Lee", "Seyeon", ""], ["Ye", "Qinyuan", ""], ["Boschee", "Elizabeth", ""], ["Neves", "Leonardo", ""], ["Ren", "Xiang", ""]]}, {"id": "2004.07507", "submitter": "Janghyeon Lee", "authors": "Janghyeon Lee, Hyeong Gwon Hong, Donggyu Joo, Junmo Kim", "title": "Continual Learning with Extended Kronecker-factored Approximate\n  Curvature", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a quadratic penalty method for continual learning of neural\nnetworks that contain batch normalization (BN) layers. The Hessian of a loss\nfunction represents the curvature of the quadratic penalty function, and a\nKronecker-factored approximate curvature (K-FAC) is used widely to practically\ncompute the Hessian of a neural network. However, the approximation is not\nvalid if there is dependence between examples, typically caused by BN layers in\ndeep network architectures. We extend the K-FAC method so that the\ninter-example relations are taken into account and the Hessian of deep neural\nnetworks can be properly approximated under practical assumptions. We also\npropose a method of weight merging and reparameterization to properly handle\nstatistical parameters of BN, which plays a critical role for continual\nlearning with BN, and a method that selects hyperparameters without source task\ndata. Our method shows better performance than baselines in the permuted MNIST\ntask with BN layers and in sequential learning from the ImageNet classification\ntask to fine-grained classification tasks with ResNet-50, without any explicit\nor implicit use of source task data for hyperparameter selection.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 07:58:47 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lee", "Janghyeon", ""], ["Hong", "Hyeong Gwon", ""], ["Joo", "Donggyu", ""], ["Kim", "Junmo", ""]]}, {"id": "2004.07511", "submitter": "Tom Vermeire", "authors": "Tom Vermeire, David Martens", "title": "Explainable Image Classification with Evidence Counterfactual", "comments": "23 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of state-of-the-art modeling techniques for image\nclassification impedes the ability to explain model predictions in an\ninterpretable way. Existing explanation methods generally create importance\nrankings in terms of pixels or pixel groups. However, the resulting\nexplanations lack an optimal size, do not consider feature dependence and are\nonly related to one class. Counterfactual explanation methods are considered\npromising to explain complex model decisions, since they are associated with a\nhigh degree of human interpretability. In this paper, SEDC is introduced as a\nmodel-agnostic instance-level explanation method for image classification to\nobtain visual counterfactual explanations. For a given image, SEDC searches a\nsmall set of segments that, in case of removal, alters the classification. As\nimage classification tasks are typically multiclass problems, SEDC-T is\nproposed as an alternative method that allows specifying a target\ncounterfactual class. We compare SEDC(-T) with popular feature importance\nmethods such as LRP, LIME and SHAP, and we describe how the mentioned\nimportance ranking issues are addressed. Moreover, concrete examples and\nexperiments illustrate the potential of our approach (1) to obtain trust and\ninsight, and (2) to obtain input for model improvement by explaining\nmisclassifications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:02:48 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Vermeire", "Tom", ""], ["Martens", "David", ""]]}, {"id": "2004.07512", "submitter": "Dr. Pooja Saigal", "authors": "Pooja Saigal, Reshma Khemchandani", "title": "Nonparallel Hyperplane Classifiers for Multi-category Classification", "comments": "6 Pages. Applications and Future Directions (WCI). IEEE, 2015", "journal-ref": null, "doi": "10.1109/WCI.2015.7495510", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machines (SVMs) are widely used for solving classification and\nregression problems. Recently, various nonparallel hyperplanes classification\nalgorithms (NHCAs) have been proposed, which are comparable in terms of\nclassification accuracy when compared with SVM but are computationally more\nefficient. All these NHCAs are originally proposed for binary classification\nproblems. Since, most of the real world classification problems deal with\nmultiple classes, these algorithms are extended in multi-category scenario. In\nthis paper, we present a comparative study of four NHCAs i.e. Twin SVM (TWSVM),\nGeneralized eigenvalue proximal SVM (GEPSVM), Regularized GEPSVM (RegGEPSVM)\nand Improved GEPSVM (IGEPSVM)for multi-category classification. The\nmulti-category classification algorithms for NHCA classifiers are implemented\nusing OneAgainst-All (OAA), binary tree-based (BT) and ternary decision\nstructure (TDS) approaches and the experiments are performed on benchmark UCI\ndatasets. The experimental results show that TDS-TWSVM outperforms other\nmethods in terms of classification accuracy and BT-RegGEPSVM takes the minimum\ntime for building the classifier\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:03:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Saigal", "Pooja", ""], ["Khemchandani", "Reshma", ""]]}, {"id": "2004.07530", "submitter": "Christos Kaplanis", "authors": "Christos Kaplanis, Claudia Clopath, and Murray Shanahan", "title": "Continual Reinforcement Learning with Multi-Timescale Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a multi-timescale replay (MTR) buffer for improving\ncontinual learning in RL agents faced with environments that are changing\ncontinuously over time at timescales that are unknown to the agent. The basic\nMTR buffer comprises a cascade of sub-buffers that accumulate experiences at\ndifferent timescales, enabling the agent to improve the trade-off between\nadaptation to new data and retention of old knowledge. We also combine the MTR\nframework with invariant risk minimization, with the idea of encouraging the\nagent to learn a policy that is robust across the various environments it\nencounters over time. The MTR methods are evaluated in three different\ncontinual learning settings on two continuous control tasks and, in many cases,\nshow improvement over the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:47:40 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Kaplanis", "Christos", ""], ["Clopath", "Claudia", ""], ["Shanahan", "Murray", ""]]}, {"id": "2004.07534", "submitter": "Mahmoud Hossam", "authors": "Mahmoud Hossam, Trung Le, Viet Huynh, Michael Papasimeon, and Dinh\n  Phung", "title": "OptiGAN: Generative Adversarial Networks for Goal Optimized Sequence\n  Generation", "comments": "Preprint for accepted conference paper at International Joint\n  Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenging problems in sequence generation tasks is the optimized\ngeneration of sequences with specific desired goals. Current sequential\ngenerative models mainly generate sequences to closely mimic the training data,\nwithout direct optimization of desired goals or properties specific to the\ntask. We introduce OptiGAN, a generative model that incorporates both\nGenerative Adversarial Networks (GAN) and Reinforcement Learning (RL) to\noptimize desired goal scores using policy gradients. We apply our model to text\nand real-valued sequence generation, where our model is able to achieve higher\ndesired scores out-performing GAN and RL baselines, while not sacrificing\noutput sample diversity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 08:54:00 GMT"}, {"version": "v10", "created": "Thu, 14 Jan 2021 08:13:27 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 01:48:42 GMT"}, {"version": "v3", "created": "Sat, 16 May 2020 09:32:36 GMT"}, {"version": "v4", "created": "Fri, 22 May 2020 23:51:52 GMT"}, {"version": "v5", "created": "Wed, 2 Sep 2020 20:14:13 GMT"}, {"version": "v6", "created": "Mon, 14 Sep 2020 23:58:04 GMT"}, {"version": "v7", "created": "Wed, 16 Sep 2020 01:55:15 GMT"}, {"version": "v8", "created": "Thu, 15 Oct 2020 08:47:50 GMT"}, {"version": "v9", "created": "Wed, 18 Nov 2020 20:26:16 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hossam", "Mahmoud", ""], ["Le", "Trung", ""], ["Huynh", "Viet", ""], ["Papasimeon", "Michael", ""], ["Phung", "Dinh", ""]]}, {"id": "2004.07543", "submitter": "Saisubramaniam Gopalakrishnan Mr", "authors": "Saisubramaniam Gopalakrishnan, Pranshu Ranjan Singh, Yasin Yazici,\n  Chuan-Sheng Foo, Vijay Chandrasekhar, ArulMurugan Ambikapathi", "title": "Classification Representations Can be Reused for Downstream Generations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to the convention of using supervision for class-conditioned\n$\\it{generative}$ $\\it{modeling}$, this work explores and demonstrates the\nfeasibility of a learned supervised representation space trained on a\ndiscriminative classifier for the $\\it{downstream}$ task of sample generation.\nUnlike generative modeling approaches that aim to $\\it{model}$ the manifold\ndistribution, we directly $\\it{represent}$ the given data manifold in the\nclassification space and leverage properties of latent space representations to\ngenerate new representations that are guaranteed to be in the same class.\nInterestingly, such representations allow for controlled sample generations for\nany given class from existing samples and do not require enforcing prior\ndistribution. We show that these latent space representations can be smartly\nmanipulated (using convex combinations of $n$ samples, $n\\geq2$) to yield\nmeaningful sample generations. Experiments on image datasets of varying\nresolutions demonstrate that downstream generations have higher classification\naccuracy than existing conditional generative models while being competitive in\nterms of FID.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 09:13:44 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Gopalakrishnan", "Saisubramaniam", ""], ["Singh", "Pranshu Ranjan", ""], ["Yazici", "Yasin", ""], ["Foo", "Chuan-Sheng", ""], ["Chandrasekhar", "Vijay", ""], ["Ambikapathi", "ArulMurugan", ""]]}, {"id": "2004.07584", "submitter": "Fernando Casta\\~neda", "authors": "Jason Choi, Fernando Casta\\~neda, Claire J. Tomlin, Koushil Sreenath", "title": "Reinforcement Learning for Safety-Critical Control under Model\n  Uncertainty, using Control Lyapunov Functions and Control Barrier Functions", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the issue of model uncertainty in safety-critical control is\naddressed with a data-driven approach. For this purpose, we utilize the\nstructure of an input-ouput linearization controller based on a nominal model\nalong with a Control Barrier Function and Control Lyapunov Function based\nQuadratic Program (CBF-CLF-QP). Specifically, we propose a novel reinforcement\nlearning framework which learns the model uncertainty present in the CBF and\nCLF constraints, as well as other control-affine dynamic constraints in the\nquadratic program. The trained policy is combined with the nominal model-based\nCBF-CLF-QP, resulting in the Reinforcement Learning-based CBF-CLF-QP\n(RL-CBF-CLF-QP), which addresses the problem of model uncertainty in the safety\nconstraints. The performance of the proposed method is validated by testing it\non an underactuated nonlinear bipedal robot walking on randomly spaced stepping\nstones with one step preview, obtaining stable and safe walking under model\nuncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 10:51:33 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 17:07:52 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Choi", "Jason", ""], ["Casta\u00f1eda", "Fernando", ""], ["Tomlin", "Claire J.", ""], ["Sreenath", "Koushil", ""]]}, {"id": "2004.07601", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji, Xue Li, Zi Huang, and Erik Cambria", "title": "Suicidal Ideation and Mental Disorder Detection with Attentive Relation\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health is a critical issue in modern society, and mental disorders\ncould sometimes turn to suicidal ideation without effective treatment. Early\ndetection of mental disorders and suicidal ideation from social content\nprovides a potential way for effective social intervention. However,\nclassifying suicidal ideation and other mental disorders is challenging as they\nshare similar patterns in language usage and sentimental polarity. This paper\nenhances text representation with lexicon-based sentiment scores and latent\ntopics and proposes using relation networks to detect suicidal ideation and\nmental disorders with related risk indicators. The relation module is further\nequipped with the attention mechanism to prioritize more critical relational\nfeatures. Through experiments on three real-world datasets, our model\noutperforms most of its counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 11:18:55 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 08:42:30 GMT"}, {"version": "v3", "created": "Tue, 8 Jun 2021 17:54:28 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Li", "Xue", ""], ["Huang", "Zi", ""], ["Cambria", "Erik", ""]]}, {"id": "2004.07605", "submitter": "Anil Goyal", "authors": "Anil Goyal and Jihed Khiari", "title": "Diversity-Aware Weighted Majority Vote Classifier for Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a diversity-aware ensemble learning based\nalgorithm, referred to as DAMVI, to deal with imbalanced binary classification\ntasks. Specifically, after learning base classifiers, the algorithm i)\nincreases the weights of positive examples (minority class) which are \"hard\" to\nclassify with uniformly weighted base classifiers; and ii) then learns weights\nover base classifiers by optimizing the PAC-Bayesian C-Bound that takes into\naccount the accuracy and diversity between the classifiers. We show efficiency\nof the proposed approach with respect to state-of-art models on predictive\nmaintenance task, credit card fraud detection, webpage classification and\nmedical applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 11:27:50 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Goyal", "Anil", ""], ["Khiari", "Jihed", ""]]}, {"id": "2004.07623", "submitter": "Ankur Mali", "authors": "Ankur Mali, Alexander Ororbia, Daniel Kifer, Clyde Lee Giles", "title": "Recognizing Long Grammatical Sequences Using Recurrent Networks\n  Augmented With An External Differentiable Stack", "comments": "14 pages, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent neural networks (RNNs) are a widely used deep architecture for\nsequence modeling, generation, and prediction. Despite success in applications\nsuch as machine translation and voice recognition, these stateful models have\nseveral critical shortcomings. Specifically, RNNs generalize poorly over very\nlong sequences, which limits their applicability to many important temporal\nprocessing and time series forecasting problems. For example, RNNs struggle in\nrecognizing complex context free languages (CFLs), never reaching 100% accuracy\non training. One way to address these shortcomings is to couple an RNN with an\nexternal, differentiable memory structure, such as a stack. However,\ndifferentiable memories in prior work have neither been extensively studied on\nCFLs nor tested on sequences longer than those seen in training. The few\nefforts that have studied them have shown that continuous differentiable memory\nstructures yield poor generalization for complex CFLs, making the RNN less\ninterpretable. In this paper, we improve the memory-augmented RNN with\nimportant architectural and state updating mechanisms that ensure that the\nmodel learns to properly balance the use of its latent states with external\nmemory. Our improved RNN models exhibit better generalization performance and\nare able to classify long strings generated by complex hierarchical context\nfree grammars (CFGs). We evaluate our models on CGGs, including the Dyck\nlanguages, as well as on the Penn Treebank language modelling task, and achieve\nstable, robust performance across these benchmarks. Furthermore, we show that\nonly our memory-augmented networks are capable of retaining memory for a longer\nduration up to strings of length 160.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 14:19:15 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 15:36:26 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mali", "Ankur", ""], ["Ororbia", "Alexander", ""], ["Kifer", "Daniel", ""], ["Giles", "Clyde Lee", ""]]}, {"id": "2004.07629", "submitter": "Nergis Tomen", "authors": "Ioannis Lelekas, Nergis Tomen, Silvia L. Pintea and Jan C. van Gemert", "title": "Top-Down Networks: A coarse-to-fine reimagination of CNNs", "comments": "CVPR Workshop Deep Vision 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological vision adopts a coarse-to-fine information processing pathway,\nfrom initial visual detection and binding of salient features of a visual\nscene, to the enhanced and preferential processing given relevant stimuli. On\nthe contrary, CNNs employ a fine-to-coarse processing, moving from local,\nedge-detecting filters to more global ones extracting abstract representations\nof the input. In this paper we reverse the feature extraction part of standard\nbottom-up architectures and turn them upside-down: We propose top-down\nnetworks. Our proposed coarse-to-fine pathway, by blurring higher frequency\ninformation and restoring it only at later stages, offers a line of defence\nagainst adversarial attacks that introduce high frequency noise. Moreover,\nsince we increase image resolution with depth, the high resolution of the\nfeature map in the final convolutional layer contributes to the explainability\nof the network's decision making process. This favors object-driven decisions\nover context driven ones, and thus provides better localized class activation\nmaps. This paper offers empirical evidence for the applicability of the\ntop-down resolution processing to various existing architectures on multiple\nvisual tasks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:29:48 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Lelekas", "Ioannis", ""], ["Tomen", "Nergis", ""], ["Pintea", "Silvia L.", ""], ["van Gemert", "Jan C.", ""]]}, {"id": "2004.07633", "submitter": "Jan Deriu", "authors": "Jan Deriu, Katsiaryna Mlynchyk, Philippe Schl\\\"apfer, Alvaro Rodrigo,\n  Dirk von Gr\\\"unigen, Nicolas Kaiser, Kurt Stockinger, Eneko Agirre, and Mark\n  Cieliebak", "title": "A Methodology for Creating Question Answering Corpora Using Inverse Data\n  Annotation", "comments": null, "journal-ref": "Proceedings of the 58th Annual Meeting of the Association for\n  Computational Linguistics. 2020", "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel methodology to efficiently construct a\ncorpus for question answering over structured data. For this, we introduce an\nintermediate representation that is based on the logical query plan in a\ndatabase called Operation Trees (OT). This representation allows us to invert\nthe annotation process without losing flexibility in the types of queries that\nwe generate. Furthermore, it allows for fine-grained alignment of query tokens\nto OT operations. In our method, we randomly generate OTs from a context-free\ngrammar. Afterwards, annotators have to write the appropriate natural language\nquestion that is represented by the OT. Finally, the annotators assign the\ntokens to the OT operations. We apply the method to create a new corpus OTTA\n(Operation Trees and Token Assignment), a large semantic parsing corpus for\nevaluating natural language interfaces to databases. We compare OTTA to Spider\nand LC-QuaD 2.0 and show that our methodology more than triples the annotation\nspeed while maintaining the complexity of the queries. Finally, we train a\nstate-of-the-art semantic parsing model on our data and show that our corpus is\na challenging dataset and that the token alignment can be leveraged to increase\nthe performance significantly.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:50:01 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 08:13:32 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Deriu", "Jan", ""], ["Mlynchyk", "Katsiaryna", ""], ["Schl\u00e4pfer", "Philippe", ""], ["Rodrigo", "Alvaro", ""], ["von Gr\u00fcnigen", "Dirk", ""], ["Kaiser", "Nicolas", ""], ["Stockinger", "Kurt", ""], ["Agirre", "Eneko", ""], ["Cieliebak", "Mark", ""]]}, {"id": "2004.07636", "submitter": "Stratis Limnios", "authors": "Stratis Limnios, George Dasoulas, Dimitrios M. Thilikos, Michalis\n  Vazirgiannis", "title": "Hcore-Init: Neural Network Initialization based on Graph Degeneracy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are the pinnacle of Artificial Intelligence, as in recent\nyears we witnessed many novel architectures, learning and optimization\ntechniques for deep learning. Capitalizing on the fact that neural networks\ninherently constitute multipartite graphs among neuron layers, we aim to\nanalyze directly their structure to extract meaningful information that can\nimprove the learning process. To our knowledge graph mining techniques for\nenhancing learning in neural networks have not been thoroughly investigated. In\nthis paper we propose an adapted version of the k-core structure for the\ncomplete weighted multipartite graph extracted from a deep learning\narchitecture. As a multipartite graph is a combination of bipartite graphs,\nthat are in turn the incidence graphs of hypergraphs, we design k-hypercore\ndecomposition, the hypergraph analogue of k-core degeneracy. We applied\nk-hypercore to several neural network architectures, more specifically to\nconvolutional neural networks and multilayer perceptrons for image recognition\ntasks after a very short pretraining. Then we used the information provided by\nthe hypercore numbers of the neurons to re-initialize the weights of the neural\nnetwork, thus biasing the gradient optimization scheme. Extensive experiments\nproved that k-hypercore outperforms the state-of-the-art initialization\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 12:57:14 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Limnios", "Stratis", ""], ["Dasoulas", "George", ""], ["Thilikos", "Dimitrios M.", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2004.07641", "submitter": "Lars Lorch", "authors": "Lars Lorch, Heiner Kremer, William Trouleau, Stratis Tsirtsis, Aron\n  Szanto, Bernhard Sch\\\"olkopf, and Manuel Gomez-Rodriguez", "title": "Quantifying the Effects of Contact Tracing, Testing, and Containment\n  Measures in the Presence of Infection Hotspots", "comments": "Statistical tests for overdispersion of secondary infections; contour\n  plots for parameter estimation; corrected experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple lines of evidence strongly suggest that infection hotspots, where a\nsingle individual infects many others, play a key role in the transmission\ndynamics of COVID-19. However, most of the existing epidemiological models fail\nto capture this aspect by neither representing the sites visited by individuals\nexplicitly nor characterizing disease transmission as a function of individual\nmobility patterns. In this work, we introduce a temporal point process modeling\nframework that specifically represents visits to the sites where individuals\nget in contact and infect each other. Under our model, the number of infections\ncaused by an infectious individual naturally emerges to be overdispersed. Using\nan efficient sampling algorithm, we demonstrate how to apply Bayesian\noptimization with longitudinal case data to estimate the transmission rate of\ninfectious individuals at the sites they visit and in their households.\nSimulations using fine-grained and publicly available demographic data and site\nlocations from Bern, Switzerland showcase the flexibility of our framework. To\nfacilitate research and analyses of other cities and regions, we release an\nopen-source implementation of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:18:32 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:29:32 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 13:58:12 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 13:36:24 GMT"}, {"version": "v5", "created": "Tue, 18 May 2021 13:15:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lorch", "Lars", ""], ["Kremer", "Heiner", ""], ["Trouleau", "William", ""], ["Tsirtsis", "Stratis", ""], ["Szanto", "Aron", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2004.07644", "submitter": "Dawei Liu", "authors": "Dawei Liu, Zhiyi Tang, Yuequan Bao, Hui Li", "title": "Machine-learning-based methods for output only structural modal\n  identification", "comments": "21 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a machine-learning-based approach to identify the\nmodal parameters of the output-only data for structural health monitoring (SHM)\nthat makes full use of the characteristic of independence of modal responses\nand the principle of machine learning. By taking advantage of the independence\nfeature of each mode, we use the principle of unsupervised learning, making the\ntraining process of the deep neural network becomes the process of modal\nseparation. A self-coding deep neural network is designed to identify the\nstructural modal parameters from the vibration data of structures. The mixture\nsignals, that is, the structural response data, are used as the input of the\nneural network. Then we use a complex loss function to restrict the training\nprocess of the neural network, making the output of the third layer the modal\nresponses we want, and the weights of the last two layers are mode shapes. The\ndeep neural network is essentially a nonlinear objective function optimization\nproblem. A novel loss function is proposed to constrain the independent feature\nwith consideration of uncorrelation and non-Gaussianity to restrict the\ndesigned neural network to obtain the structural modal parameters. A numerical\nexample of a simple structure and an example of actual SHM data from a\ncable-stayed bridge are presented to illustrate the modal parameter\nidentification ability of the proposed approach. The results show the\napproach's good capability in blindly extracting modal information from system\nresponses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 13:26:16 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 01:13:48 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Liu", "Dawei", ""], ["Tang", "Zhiyi", ""], ["Bao", "Yuequan", ""], ["Li", "Hui", ""]]}, {"id": "2004.07667", "submitter": "Shauli Ravfogel", "authors": "Shauli Ravfogel, Yanai Elazar, Hila Gonen, Michael Twiton, Yoav\n  Goldberg", "title": "Null It Out: Guarding Protected Attributes by Iterative Nullspace\n  Projection", "comments": "Accepted as a long paper in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to control for the kinds of information encoded in neural\nrepresentation has a variety of use cases, especially in light of the challenge\nof interpreting these models. We present Iterative Null-space Projection\n(INLP), a novel method for removing information from neural representations.\nOur method is based on repeated training of linear classifiers that predict a\ncertain property we aim to remove, followed by projection of the\nrepresentations on their null-space. By doing so, the classifiers become\noblivious to that target property, making it hard to linearly separate the data\naccording to it. While applicable for multiple uses, we evaluate our method on\nbias and fairness use-cases, and show that our method is able to mitigate bias\nin word embeddings, as well as to increase fairness in a setting of multi-class\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:02:50 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 21:09:39 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ravfogel", "Shauli", ""], ["Elazar", "Yanai", ""], ["Gonen", "Hila", ""], ["Twiton", "Michael", ""], ["Goldberg", "Yoav", ""]]}, {"id": "2004.07683", "submitter": "Tom Bosc", "authors": "Tom Bosc and Pascal Vincent", "title": "Do sequence-to-sequence VAEs learn global features of sentences?", "comments": "Camera-ready version, EMNLP2020", "journal-ref": null, "doi": "10.18653/v1/2020.emnlp-main.350", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autoregressive language models are powerful and relatively easy to train.\nHowever, these models are usually trained without explicit conditioning labels\nand do not offer easy ways to control global aspects such as sentiment or topic\nduring generation. Bowman & al. (2016) adapted the Variational Autoencoder\n(VAE) for natural language with the sequence-to-sequence architecture and\nclaimed that the latent vector was able to capture such global features in an\nunsupervised manner. We question this claim. We measure which words benefit\nmost from the latent information by decomposing the reconstruction loss per\nposition in the sentence. Using this method, we find that VAEs are prone to\nmemorizing the first words and the sentence length, producing local features of\nlimited usefulness. To alleviate this, we investigate alternative architectures\nbased on bag-of-words assumptions and language model pretraining. These\nvariants learn latent variables that are more global, i.e., more predictive of\ntopic or sentiment labels. Moreover, using reconstructions, we observe that\nthey decrease memorization: the first word and the sentence length are not\nrecovered as accurately than with the baselines, consequently yielding more\ndiverse reconstructions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:43:27 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 18:59:31 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Bosc", "Tom", ""], ["Vincent", "Pascal", ""]]}, {"id": "2004.07690", "submitter": "Phuong Ngo", "authors": "Phuong D. Ngo, Fred Godtliebsen", "title": "Data-Driven Robust Control Using Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a robust control design method using\nreinforcement-learning for controlling partially-unknown dynamical systems\nunder uncertain conditions. The method extends the optimal\nreinforcement-learning algorithm with a new learning technique that is based on\nthe robust control theory. By learning from the data, the algorithm proposed\nactions that guarantees the stability of the closed loop system within the\nuncertainties estimated from the data. Control policies are calculated by\nsolving a set of linear matrix inequalities. The controller was evaluated using\nsimulations on a blood glucose model for patients with type-1 diabetes.\nSimulation results show that the proposed methodology is capable of safely\nregulates the blood glucose within a healthy level under the influence of\nmeasurement and process noises. The controller has also significantly reduced\nthe post-meal fluctuation of the blood glucose. A comparison between the\nproposed algorithm and the existing optimal reinforcement learning algorithm\nshows the improved robustness of the closed loop system using our method.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:57:15 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ngo", "Phuong D.", ""], ["Godtliebsen", "Fred", ""]]}, {"id": "2004.07691", "submitter": "Florin Condrea", "authors": "Florin Condrea, Victor-Andrei Ivan, Marius Leordeanu", "title": "In Search of Life: Learning from Synthetic Data to Detect Vital Signs in\n  Videos", "comments": "Computer Vision and Pattern Recognition (CVPR) Workshop on Computer\n  Vision for Physiological Measurement (CVPM) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatically detecting vital signs in videos, such as the estimation of\nheart and respiration rates, is a challenging research problem in computer\nvision with important applications in the medical field. One of the key\ndifficulties in tackling this task is the lack of sufficient supervised\ntraining data, which severely limits the use of powerful deep neural networks.\nIn this paper we address this limitation through a novel deep learning\napproach, in which a recurrent deep neural network is trained to detect vital\nsigns in the infrared thermal domain from purely synthetic data. What is most\nsurprising is that our novel method for synthetic training data generation is\ngeneral, relatively simple and uses almost no prior medical domain knowledge.\nMoreover, our system, which is trained in a purely automatic manner and needs\nno human annotation, also learns to predict the respiration or heart intensity\nsignal for each moment in time and to detect the region of interest that is\nmost relevant for the given task, e.g. the nose area in the case of\nrespiration. We test the effectiveness of our proposed system on the recent\nLCAS dataset and obtain state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:02:46 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 18:18:39 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Condrea", "Florin", ""], ["Ivan", "Victor-Andrei", ""], ["Leordeanu", "Marius", ""]]}, {"id": "2004.07692", "submitter": "Jan Sokolowski", "authors": "Jan Sokolowski, Volker Schulz, Udo Schr\\\"oder, Hans-Peter Beise", "title": "A Hybrid Objective Function for Robustness of Artificial Neural Networks\n  -- Estimation of Parameters in a Mechanical System", "comments": "16 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several studies, hybrid neural networks have proven to be more robust\nagainst noisy input data compared to plain data driven neural networks. We\nconsider the task of estimating parameters of a mechanical vehicle model based\non acceleration profiles. We introduce a convolutional neural network\narchitecture that is capable to predict the parameters for a family of vehicle\nmodels that differ in the unknown parameters. We introduce a convolutional\nneural network architecture that given sequential data predicts the parameters\nof the underlying data's dynamics. This network is trained with two objective\nfunctions. The first one constitutes a more naive approach that assumes that\nthe true parameters are known. The second objective incorporates the knowledge\nof the underlying dynamics and is therefore considered as hybrid approach. We\nshow that in terms of robustness, the latter outperforms the first objective on\nnoisy input data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:06:43 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Sokolowski", "Jan", ""], ["Schulz", "Volker", ""], ["Schr\u00f6der", "Udo", ""], ["Beise", "Hans-Peter", ""]]}, {"id": "2004.07700", "submitter": "Xiao Liang", "authors": "Xiao Liang, Dan Nguyen, Steve Jiang", "title": "Generalizability issues with deep learning models in medicine and their\n  potential solutions: illustrated with Cone-Beam Computed Tomography (CBCT) to\n  Computed Tomography (CT) image conversion", "comments": "20 pages, 5 figures, 7 supplementary figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalizability is a concern when applying a deep learning (DL) model\ntrained on one dataset to other datasets. Training a universal model that works\nanywhere, anytime, for anybody is unrealistic. In this work, we demonstrate the\ngeneralizability problem, then explore potential solutions based on transfer\nlearning (TL) by using the cone-beam computed tomography (CBCT) to computed\ntomography (CT) image conversion task as the testbed. Previous works have\nconverted CBCT to CT-like images. However, all of those works studied only one\nor two anatomical sites and used images from the same vendor's scanners. Here,\nwe investigated how a model trained for one machine and one anatomical site\nworks on other machines and other sites. We trained a model on CBCT images\nacquired from one vendor's scanners for head and neck cancer patients and\napplied it to images from another vendor's scanners and for other disease\nsites. We found that generalizability could be a significant problem for this\nparticular application when applying a trained DL model to datasets from\nanother vendor's scanners. We then explored three practical solutions based on\nTL to solve this generalization problem: the target model, which is trained on\na target domain from scratch; the combined model, which is trained on both\nsource and target domain datasets from scratch; and the adapted model, which\nfine-tunes the trained source model to a target domain. We found that when\nthere are sufficient data in the target domain, all three models can achieve\ngood performance. When the target dataset is limited, the adapted model works\nthe best, which indicates that using the fine-tuning strategy to adapt the\ntrained model to an unseen target domain dataset is a viable and easy way to\nimplement DL models in the clinic.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:14:45 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 14:50:39 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Liang", "Xiao", ""], ["Nguyen", "Dan", ""], ["Jiang", "Steve", ""]]}, {"id": "2004.07703", "submitter": "Fei Pan", "authors": "Fei Pan, Inkyu Shin, Francois Rameau, Seokju Lee, In So Kweon", "title": "Unsupervised Intra-domain Adaptation for Semantic Segmentation through\n  Self-Supervision", "comments": "Accepted to CVPR 2020 as an Oral Presentation. Code is available at\n  https://github.com/feipan664/IntraDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network-based approaches have achieved remarkable\nprogress in semantic segmentation. However, these approaches heavily rely on\nannotated data which are labor intensive. To cope with this limitation,\nautomatically annotated data generated from graphic engines are used to train\nsegmentation models. However, the models trained from synthetic data are\ndifficult to transfer to real images. To tackle this issue, previous works have\nconsidered directly adapting models from the source data to the unlabeled\ntarget data (to reduce the inter-domain gap). Nonetheless, these techniques do\nnot consider the large distribution gap among the target data itself\n(intra-domain gap). In this work, we propose a two-step self-supervised domain\nadaptation approach to minimize the inter-domain and intra-domain gap together.\nFirst, we conduct the inter-domain adaptation of the model; from this\nadaptation, we separate the target domain into an easy and hard split using an\nentropy-based ranking function. Finally, to decrease the intra-domain gap, we\npropose to employ a self-supervised adaptation technique from the easy to the\nhard split. Experimental results on numerous benchmark datasets highlight the\neffectiveness of our method against existing state-of-the-art approaches. The\nsource code is available at https://github.com/feipan664/IntraDA.git.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:24:11 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 12:25:50 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 08:03:50 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 11:29:25 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Pan", "Fei", ""], ["Shin", "Inkyu", ""], ["Rameau", "Francois", ""], ["Lee", "Seokju", ""], ["Kweon", "In So", ""]]}, {"id": "2004.07707", "submitter": "Declan Oller", "authors": "Declan Oller, Tobias Glasmachers, Giuseppe Cuccu", "title": "Analyzing Reinforcement Learning Benchmarks with Random Weight Guessing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for analyzing and visualizing the complexity of\nstandard reinforcement learning (RL) benchmarks based on score distributions. A\nlarge number of policy networks are generated by randomly guessing their\nparameters, and then evaluated on the benchmark task; the study of their\naggregated results provide insights into the benchmark complexity. Our method\nguarantees objectivity of evaluation by sidestepping learning altogether: the\npolicy network parameters are generated using Random Weight Guessing (RWG),\nmaking our method agnostic to (i) the classic RL setup, (ii) any learning\nalgorithm, and (iii) hyperparameter tuning. We show that this approach isolates\nthe environment complexity, highlights specific types of challenges, and\nprovides a proper foundation for the statistical analysis of the task's\ndifficulty. We test our approach on a variety of classic control benchmarks\nfrom the OpenAI Gym, where we show that small untrained networks can provide a\nrobust baseline for a variety of tasks. The networks generated often show good\nperformance even without gradual learning, incidentally highlighting the\ntriviality of a few popular benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:32:52 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Oller", "Declan", ""], ["Glasmachers", "Tobias", ""], ["Cuccu", "Giuseppe", ""]]}, {"id": "2004.07711", "submitter": "Lamberto Ballan", "authors": "Guglielmo Camporese, Pasquale Coscia, Antonino Furnari, Giovanni Maria\n  Farinella, Lamberto Ballan", "title": "Knowledge Distillation for Action Anticipation via Label Smoothing", "comments": "Accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human capability to anticipate near future from visual observations and\nnon-verbal cues is essential for developing intelligent systems that need to\ninteract with people. Several research areas, such as human-robot interaction\n(HRI), assisted living or autonomous driving need to foresee future events to\navoid crashes or help people. Egocentric scenarios are classic examples where\naction anticipation is applied due to their numerous applications. Such\nchallenging task demands to capture and model domain's hidden structure to\nreduce prediction uncertainty. Since multiple actions may equally occur in the\nfuture, we treat action anticipation as a multi-label problem with missing\nlabels extending the concept of label smoothing. This idea resembles the\nknowledge distillation process since useful information is injected into the\nmodel during training. We implement a multi-modal framework based on long\nshort-term memory (LSTM) networks to summarize past observations and make\npredictions at different time steps. We perform extensive experiments on\nEPIC-Kitchens and EGTEA Gaze+ datasets including more than 2500 and 100 action\nclasses, respectively. The experiments show that label smoothing systematically\nimproves performance of state-of-the-art models for action anticipation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:38:53 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 13:28:40 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Camporese", "Guglielmo", ""], ["Coscia", "Pasquale", ""], ["Furnari", "Antonino", ""], ["Farinella", "Giovanni Maria", ""], ["Ballan", "Lamberto", ""]]}, {"id": "2004.07715", "submitter": "Siddharth Tourani", "authors": "Siddharth Tourani, Alexander Shekhovtsov, Carsten Rother, Bogdan\n  Savchynskyy", "title": "Taxonomy of Dual Block-Coordinate Ascent Methods for Discrete Energy\n  Minimization", "comments": "Accepted in AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the maximum-a-posteriori inference problem in discrete graphical\nmodels and study solvers based on the dual block-coordinate ascent rule. We map\nall existing solvers in a single framework, allowing for a better understanding\nof their design principles. We theoretically show that some block-optimizing\nupdates are sub-optimal and how to strictly improve them. On a wide range of\nproblem instances of varying graph connectivity, we study the performance of\nexisting solvers as well as new variants that can be obtained within the\nframework. As a result of this exploration we build a new state-of-the art\nsolver, performing uniformly better on the whole range of test instances.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:49:13 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Tourani", "Siddharth", ""], ["Shekhovtsov", "Alexander", ""], ["Rother", "Carsten", ""], ["Savchynskyy", "Bogdan", ""]]}, {"id": "2004.07740", "submitter": "Marcel Neunhoeffer", "authors": "Christian Arnold and Marcel Neunhoeffer", "title": "Really Useful Synthetic Data -- A Framework to Evaluate the Quality of\n  Differentially Private Synthetic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in generating synthetic data that allow to add principled\nways of protecting privacy -- such as Differential Privacy -- are a crucial\nstep in sharing statistical information in a privacy preserving way. But while\nthe focus has been on privacy guarantees, the resulting private synthetic data\nis only useful if it still carries statistical information from the original\ndata. To further optimise the inherent trade-off between data privacy and data\nquality, it is necessary to think closely about the latter. What is it that\ndata analysts want? Acknowledging that data quality is a subjective concept, we\ndevelop a framework to evaluate the quality of differentially private synthetic\ndata from an applied researcher's perspective. Data quality can be measured\nalong two dimensions. First, quality of synthetic data can be evaluated against\ntraining data or against an underlying population. Second, the quality of\nsynthetic data depends on general similarity of distributions or specific tasks\nsuch as inference or prediction. It is clear that accommodating all goals at\nonce is a formidable challenge. We invite the academic community to jointly\nadvance the privacy-quality frontier.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:24:22 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Arnold", "Christian", ""], ["Neunhoeffer", "Marcel", ""]]}, {"id": "2004.07754", "submitter": "Sarah Fabi", "authors": "Sarah Fabi, Sebastian Otte, Jonas Gregor Wiese, Martin V. Butz", "title": "Investigating Efficient Learning and Compositionality in Generative LSTM\n  Networks", "comments": "ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When comparing human with artificial intelligence, one major difference is\napparent: Humans can generalize very broadly from sparse data sets because they\nare able to recombine and reintegrate data components in compositional manners.\nTo investigate differences in efficient learning, Joshua B. Tenenbaum and\ncolleagues developed the character challenge: First an algorithm is trained in\ngenerating handwritten characters. In a next step, one version of a new type of\ncharacter is presented. An efficient learning algorithm is expected to be able\nto re-generate this new character, to identify similar versions of this\ncharacter, to generate new variants of it, and to create completely new\ncharacter types. In the past, the character challenge was only met by complex\nalgorithms that were provided with stochastic primitives. Here, we tackle the\nchallenge without providing primitives. We apply a minimal recurrent neural\nnetwork (RNN) model with one feedforward layer and one LSTM layer and train it\nto generate sequential handwritten character trajectories from one-hot encoded\ninputs. To manage the re-generation of untrained characters, when presented\nwith only one example of them, we introduce a one-shot inference mechanism: the\ngradient signal is backpropagated to the feedforward layer weights only,\nleaving the LSTM layer untouched. We show that our model is able to meet the\ncharacter challenge by recombining previously learned dynamic substructures,\nwhich are visible in the hidden LSTM states. Making use of the compositional\nabilities of RNNs in this way might be an important step towards bridging the\ngap between human and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:41:44 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 08:50:24 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Fabi", "Sarah", ""], ["Otte", "Sebastian", ""], ["Wiese", "Jonas Gregor", ""], ["Butz", "Martin V.", ""]]}, {"id": "2004.07780", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, J\\\"orn-Henrik Jacobsen, Claudio Michaelis, Richard\n  Zemel, Wieland Brendel, Matthias Bethge, Felix A. Wichmann", "title": "Shortcut Learning in Deep Neural Networks", "comments": "perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)", "journal-ref": null, "doi": "10.1038/s42256-020-00257-z", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distil how many\nof deep learning's problem can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:18:49 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:03:44 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 09:10:46 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 13:53:12 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Geirhos", "Robert", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Michaelis", "Claudio", ""], ["Zemel", "Richard", ""], ["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "2004.07782", "submitter": "Mostafa Karimi", "authors": "Mostafa Karimi, Arman Hasanzadeh and Yang shen", "title": "Network-principled deep generative models for designing drug\n  combinations as graph sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combination therapy has shown to improve therapeutic efficacy while reducing\nside effects. Importantly, it has become an indispensable strategy to overcome\nresistance in antibiotics, anti-microbials, and anti-cancer drugs. Facing\nenormous chemical space and unclear design principles for small-molecule\ncombinations, the computational drug-combination design has not seen generative\nmodels to meet its potential to accelerate resistance-overcoming drug\ncombination discovery. We have developed the first deep generative model for\ndrug combination design, by jointly embedding graph-structured domain knowledge\nand iteratively training a reinforcement learning-based chemical graph-set\ndesigner. First, we have developed Hierarchical Variational Graph Auto-Encoders\n(HVGAE) trained end-to-end to jointly embed gene-gene, gene-disease, and\ndisease-disease networks. Novel attentional pooling is introduced here for\nlearning disease-representations from associated genes' representations.\nSecond, targeting diseases in learned representations, we have recast the\ndrug-combination design problem as graph-set generation and developed a deep\nlearning-based model with novel rewards. Specifically, besides chemical\nvalidity rewards, we have introduced a novel generative adversarial award,\nbeing generalized sliced Wasserstein, for chemically diverse molecules with\ndistributions similar to known drugs. We have also designed a network\nprinciple-based reward for drug combinations. Numerical results indicate that,\ncompared to graph embedding methods, HVGAE learns more informative and\ngeneralizable disease representations. Case studies on four diseases show that\nnetwork-principled drug combinations tend to have low toxicity. The generated\ndrug combinations collectively cover the disease module similar to FDA-approved\ndrug combinations and could potentially suggest novel systems-pharmacology\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:22:39 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 22:38:15 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Karimi", "Mostafa", ""], ["Hasanzadeh", "Arman", ""], ["shen", "Yang", ""]]}, {"id": "2004.07790", "submitter": "Joe Stacey", "authors": "Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Sebastian Riedel,\n  Tim Rockt\\\"aschel", "title": "Avoiding the Hypothesis-Only Bias in Natural Language Inference via\n  Ensemble Adversarial Training", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference (NLI) datasets contain annotation artefacts\nresulting in spurious correlations between the natural language utterances and\ntheir respective entailment classes. These artefacts are exploited by neural\nnetworks even when only considering the hypothesis and ignoring the premise,\nleading to unwanted biases. Belinkov et al. (2019b) proposed tackling this\nproblem via adversarial training, but this can lead to learned sentence\nrepresentations that still suffer from the same biases. We show that the bias\ncan be reduced in the sentence representations by using an ensemble of\nadversaries, encouraging the model to jointly decrease the accuracy of these\ndifferent adversaries while fitting the data. This approach produces more\nrobust NLI models, outperforming previous de-biasing efforts when generalised\nto 12 other datasets (Belinkov et al., 2019a; Mahabadi et al., 2020). In\naddition, we find that the optimal number of adversarial classifiers depends on\nthe dimensionality of the sentence representations, with larger sentence\nrepresentations being more difficult to de-bias while benefiting from using a\ngreater number of adversaries.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:37:15 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 17:19:14 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 18:47:32 GMT"}, {"version": "v4", "created": "Sat, 10 Oct 2020 17:12:15 GMT"}, {"version": "v5", "created": "Thu, 27 May 2021 17:14:46 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Stacey", "Joe", ""], ["Minervini", "Pasquale", ""], ["Dubossarsky", "Haim", ""], ["Riedel", "Sebastian", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2004.07802", "submitter": "Mikhail Khodak", "authors": "Liam Li, Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar", "title": "Geometry-Aware Gradient Algorithms for Neural Architecture Search", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art methods for neural architecture search (NAS) exploit\ngradient-based optimization by relaxing the problem into continuous\noptimization over architectures and shared-weights, a noisy process that\nremains poorly understood. We argue for the study of single-level empirical\nrisk minimization to understand NAS with weight-sharing, reducing the design of\nNAS methods to devising optimizers and regularizers that can quickly obtain\nhigh-quality solutions to this problem. Invoking the theory of mirror descent,\nwe present a geometry-aware framework that exploits the underlying structure of\nthis optimization to return sparse architectural parameters, leading to simple\nyet novel algorithms that enjoy fast convergence guarantees and achieve\nstate-of-the-art accuracy on the latest NAS benchmarks in computer vision.\nNotably, we exceed the best published results for both CIFAR and ImageNet on\nboth the DARTS search space and NAS-Bench201; on the latter we achieve\nnear-oracle-optimal performance on CIFAR-10 and CIFAR-100. Together, our theory\nand experiments demonstrate a principled way to co-design optimizers and\ncontinuous relaxations of discrete NAS search spaces.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:46:39 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 16:03:42 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 22:20:48 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 14:44:17 GMT"}, {"version": "v5", "created": "Thu, 18 Mar 2021 17:47:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Li", "Liam", ""], ["Khodak", "Mikhail", ""], ["Balcan", "Maria-Florina", ""], ["Talwalkar", "Ameet", ""]]}, {"id": "2004.07804", "submitter": "Aravind Rajeswaran", "authors": "Aravind Rajeswaran, Igor Mordatch, Vikash Kumar", "title": "A Game Theoretic Framework for Model Based Reinforcement Learning", "comments": "ICML 2020. This version contains expanded discussion, hyperparameter\n  configurations, and ablation studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (MBRL) has recently gained immense\ninterest due to its potential for sample efficiency and ability to incorporate\noff-policy data. However, designing stable and efficient MBRL algorithms using\nrich function approximators have remained challenging. To help expose the\npractical challenges in MBRL and simplify algorithm design from the lens of\nabstraction, we develop a new framework that casts MBRL as a game between: (1)\na policy player, which attempts to maximize rewards under the learned model;\n(2) a model player, which attempts to fit the real-world data collected by the\npolicy player. For algorithm development, we construct a Stackelberg game\nbetween the two players, and show that it can be solved with approximate\nbi-level optimization. This gives rise to two natural families of algorithms\nfor MBRL based on which player is chosen as the leader in the Stackelberg game.\nTogether, they encapsulate, unify, and generalize many previous MBRL\nalgorithms. Furthermore, our framework is consistent with and provides a clear\nbasis for heuristics known to be important in practice from prior works.\nFinally, through experiments we validate that our proposed algorithms are\nhighly sample efficient, match the asymptotic performance of model-free policy\ngradient, and scale gracefully to high-dimensional tasks like dexterous hand\nmanipulation. Additional details and code can be obtained from the project page\nat https://sites.google.com/view/mbrl-game\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:51:45 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 05:52:14 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Rajeswaran", "Aravind", ""], ["Mordatch", "Igor", ""], ["Kumar", "Vikash", ""]]}, {"id": "2004.07807", "submitter": "Md. Rezaul Karim", "authors": "Md. Rezaul Karim and Bharathi Raja Chakravarthi and John P. McCrae and\n  Michael Cochez", "title": "Classification Benchmarks for Under-resourced Bengali Language based on\n  Multichannel Convolutional-LSTM Network", "comments": "This paper is under review in the Journal of Natural Language\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Exponential growths of social media and micro-blogging sites not only provide\nplatforms for empowering freedom of expressions and individual voices but also\nenables people to express anti-social behaviour like online harassment,\ncyberbullying, and hate speech. Numerous works have been proposed to utilize\nthese data for social and anti-social behaviours analysis, document\ncharacterization, and sentiment analysis by predicting the contexts mostly for\nhighly resourced languages such as English. However, there are languages that\nare under-resources, e.g., South Asian languages like Bengali, Tamil, Assamese,\nTelugu that lack of computational resources for the NLP tasks. In this paper,\nwe provide several classification benchmarks for Bengali, an under-resourced\nlanguage. We prepared three datasets of expressing hate, commonly used topics,\nand opinions for hate speech detection, document classification, and sentiment\nanalysis, respectively. We built the largest Bengali word embedding models to\ndate based on 250 million articles, which we call BengFastText. We perform\nthree different experiments, covering document classification, sentiment\nanalysis, and hate speech detection. We incorporate word embeddings into a\nMultichannel Convolutional-LSTM (MConv-LSTM) network for predicting different\ntypes of hate speech, document classification, and sentiment analysis.\nExperiments demonstrate that BengFastText can capture the semantics of words\nfrom respective contexts correctly. Evaluations against several baseline\nembedding models, e.g., Word2Vec and GloVe yield up to 92.30%, 82.25%, and\n90.45% F1-scores in case of document classification, sentiment analysis, and\nhate speech detection, respectively during 5-fold cross-validation tests.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 22:17:04 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 17:21:30 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Karim", "Md. Rezaul", ""], ["Chakravarthi", "Bharathi Raja", ""], ["McCrae", "John P.", ""], ["Cochez", "Michael", ""]]}, {"id": "2004.07839", "submitter": "Eliad Tsfadia", "authors": "Haim Kaplan, Yishay Mansour, Uri Stemmer, Eliad Tsfadia", "title": "Private Learning of Halfspaces: Simplifying the Construction and\n  Reducing the Sample Complexity", "comments": "Accepted to NeurIPS 2020. In this version we added a new section\n  about our new method for privately optimizing high-dimensional functions.\n  arXiv admin note: text overlap with arXiv:1902.10731", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a differentially private learner for halfspaces over a finite grid\n$G$ in $\\mathbb{R}^d$ with sample complexity $\\approx d^{2.5}\\cdot\n2^{\\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al.,\nCOLT 2019] by a $d^2$ factor. The building block for our learner is a new\ndifferentially private algorithm for approximately solving the linear\nfeasibility problem: Given a feasible collection of $m$ linear constraints of\nthe form $Ax\\geq b$, the task is to privately identify a solution $x$ that\nsatisfies most of the constraints. Our algorithm is iterative, where each\niteration determines the next coordinate of the constructed solution $x$.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:12:10 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 09:44:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Kaplan", "Haim", ""], ["Mansour", "Yishay", ""], ["Stemmer", "Uri", ""], ["Tsfadia", "Eliad", ""]]}, {"id": "2004.07871", "submitter": "Ali Siahkoohi", "authors": "Gabrio Rizzuti and Ali Siahkoohi and Philipp A. Witte and Felix J.\n  Herrmann", "title": "Parameterizing uncertainty by deep invertible networks, an application\n  to reservoir characterization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uncertainty quantification for full-waveform inversion provides a\nprobabilistic characterization of the ill-conditioning of the problem,\ncomprising the sensitivity of the solution with respect to the starting model\nand data noise. This analysis allows to assess the confidence in the candidate\nsolution and how it is reflected in the tasks that are typically performed\nafter imaging (e.g., stratigraphic segmentation following reservoir\ncharacterization). Classically, uncertainty comes in the form of a probability\ndistribution formulated from Bayesian principles, from which we seek to obtain\nsamples. A popular solution involves Monte Carlo sampling. Here, we propose\ninstead an approach characterized by training a deep network that \"pushes\nforward\" Gaussian random inputs into the model space (representing, for\nexample, density or velocity) as if they were sampled from the actual posterior\ndistribution. Such network is designed to solve a variational optimization\nproblem based on the Kullback-Leibler divergence between the posterior and the\nnetwork output distributions. This work is fundamentally rooted in recent\ndevelopments for invertible networks. Special invertible architectures, besides\nbeing computational advantageous with respect to traditional networks, do also\nenable analytic computation of the output density function. Therefore, after\ntraining, these networks can be readily used as a new prior for a related\ninversion problem. This stands in stark contrast with Monte-Carlo methods,\nwhich only produce samples. We validate these ideas with an application to\nangle-versus-ray parameter analysis for reservoir characterization.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 18:37:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Rizzuti", "Gabrio", ""], ["Siahkoohi", "Ali", ""], ["Witte", "Philipp A.", ""], ["Herrmann", "Felix J.", ""]]}, {"id": "2004.07876", "submitter": "Haimin Hu", "authors": "Haimin Hu, Mahyar Fazlyab, Manfred Morari, George J. Pappas", "title": "Reach-SDP: Reachability Analysis of Closed-Loop Systems with Neural\n  Network Controllers via Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in using neural networks in closed-loop\ncontrol systems to improve performance and reduce computational costs for\non-line implementation. However, providing safety and stability guarantees for\nthese systems is challenging due to the nonlinear and compositional structure\nof neural networks. In this paper, we propose a novel forward reachability\nanalysis method for the safety verification of linear time-varying systems with\nneural networks in feedback interconnection. Our technical approach relies on\nabstracting the nonlinear activation functions by quadratic constraints, which\nleads to an outer-approximation of forward reachable sets of the closed-loop\nsystem. We show that we can compute these approximate reachable sets using\nsemidefinite programming. We illustrate our method in a quadrotor example, in\nwhich we first approximate a nonlinear model predictive controller via a deep\nneural network and then apply our analysis tool to certify finite-time\nreachability and constraint satisfaction of the closed-loop system.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 18:48:25 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hu", "Haimin", ""], ["Fazlyab", "Mahyar", ""], ["Morari", "Manfred", ""], ["Pappas", "George J.", ""]]}, {"id": "2004.07903", "submitter": "Jeremy Tan", "authors": "Jeremy Tan and Bernhard Kainz", "title": "Divergent Search for Few-Shot Image Classification", "comments": "Submitted to GECCO2020 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is unlabelled and the target task is not known a priori, divergent\nsearch offers a strategy for learning a wide range of skills. Having such a\nrepertoire allows a system to adapt to new, unforeseen tasks. Unlabelled image\ndata is plentiful, but it is not always known which features will be required\nfor downstream tasks. We propose a method for divergent search in the few-shot\nimage classification setting and evaluate with Omniglot and Mini-ImageNet. This\nhigh-dimensional behavior space includes all possible ways of partitioning the\ndata. To manage divergent search in this space, we rely on a meta-learning\nframework to integrate useful features from diverse tasks into a single model.\nThe final layer of this model is used as an index into the `archive' of all\npast behaviors. We search for regions in the behavior space that the current\narchive cannot reach. As expected, divergent search is outperformed by models\nwith a strong bias toward the evaluation tasks. But it is able to match and\nsometimes exceed the performance of models that have a weak bias toward the\ntarget task or none at all. This demonstrates that divergent search is a viable\napproach, even in high-dimensional behavior spaces.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:47:50 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tan", "Jeremy", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2004.07906", "submitter": "Imme Ebert-Uphoff", "authors": "Kyle A. Hilburn, Imme Ebert-Uphoff, Steven D. Miller", "title": "Development and Interpretation of a Neural Network-Based Synthetic Radar\n  Reflectivity Estimator Using GOES-R Satellite Observations", "comments": "Submitted to Journal of Applied Meteorology and Climatology", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this research is to develop techniques for assimilating\nGOES-R Series observations in precipitating scenes for the purpose of improving\nshort-term convective-scale forecasts of high impact weather hazards. Whereas\none approach is radiance assimilation, the information content of GOES-R\nradiances from its Advanced Baseline Imager (ABI) saturates in precipitating\nscenes, and radiance assimilation does not make use of lightning observations\nfrom the GOES Lightning Mapper (GLM). Here, a convolutional neural network\n(CNN) is developed to transform GOES-R radiances and lightning into synthetic\nradar reflectivity fields to make use of existing radar assimilation\ntechniques. We find that the ability of CNNs to utilize spatial context is\nessential for this application and offers breakthrough improvement in skill\ncompared to traditional pixel-by-pixel based approaches. To understand the\nimproved performance, we use a novel analysis methodology that combines several\ntechniques, each providing different insights into the network's reasoning.\nChannel withholding experiments and spatial information withholding experiments\nare used to show that the CNN achieves skill at high reflectivity values from\nthe information content in radiance gradients and the presence of lightning.\nThe attribution method, layer-wise relevance propagation, demonstrates that the\nCNN uses radiance and lightning information synergistically, where lightning\nhelps the CNN focus on which neighboring locations are most important.\nSynthetic inputs are used to quantify the sensitivity to radiance gradients,\nshowing that sharper gradients produce a stronger response in predicted\nreflectivity. Finally, geostationary lightning observations are found to be\nuniquely valuable for their ability to pinpoint locations of strong radar\nechoes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 19:57:00 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hilburn", "Kyle A.", ""], ["Ebert-Uphoff", "Imme", ""], ["Miller", "Steven D.", ""]]}, {"id": "2004.07919", "submitter": "Deqiang Li", "authors": "Deqiang Li, Qianmu Li, Yanfang Ye, and Shouhuai Xu", "title": "A Framework for Enhancing Deep Neural Networks Against Adversarial\n  Malware", "comments": "A fully-fledge version for the preliminary paper arXiv:1812.08108 |\n  D. Li, Q. Li, Y. Ye, and S. Xu, \"A Framework for Enhancing Deep Neural\n  Networks Against Adversarial Malware\", in IEEE Transactions on Network\n  Science and Engineering", "journal-ref": null, "doi": "10.1109/TNSE.2021.3051354", "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based malware detection is known to be vulnerable to\nadversarial evasion attacks. The state-of-the-art is that there are no\neffective defenses against these attacks. As a response to the adversarial\nmalware classification challenge organized by the MIT Lincoln Lab and\nassociated with the AAAI-19 Workshop on Artificial Intelligence for Cyber\nSecurity (AICS'2019), we propose six guiding principles to enhance the\nrobustness of deep neural networks. Some of these principles have been\nscattered in the literature, but the others are introduced in this paper for\nthe first time. Under the guidance of these six principles, we propose a\ndefense framework to enhance the robustness of deep neural networks against\nadversarial malware evasion attacks. By conducting experiments with the Drebin\nAndroid malware dataset, we show that the framework can achieve a 98.49\\%\naccuracy (on average) against grey-box attacks, where the attacker knows some\ninformation about the defense and the defender knows some information about the\nattack, and an 89.14% accuracy (on average) against the more capable white-box\nattacks, where the attacker knows everything about the defense and the defender\nknows some information about the attack. The framework wins the AICS'2019\nchallenge by achieving a 76.02% accuracy, where neither the attacker (i.e., the\nchallenge organizer) knows the framework or defense nor we (the defender) know\nthe attacks. This gap highlights the importance of knowing about the attack.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 07:00:47 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 06:34:53 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 15:29:02 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Li", "Deqiang", ""], ["Li", "Qianmu", ""], ["Ye", "Yanfang", ""], ["Xu", "Shouhuai", ""]]}, {"id": "2004.07922", "submitter": "Ritu Yadav", "authors": "Ritu Yadav", "title": "Light-Weighted CNN for Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For management, documents are categorized into a specific category, and to do\nthese, most of the organizations use manual labor. In today's automation era,\nmanual efforts on such a task are not justified, and to avoid this, we have so\nmany software out there in the market. However, efficiency and minimal resource\nconsumption is the focal point which is also creating a competition. The\ncategorization of such documents into specified classes by machine provides\nexcellent help. One of categorization technique is text classification using a\nConvolutional neural network(TextCNN). TextCNN uses multiple sizes of filters,\nas in the case of the inception layer introduced in Googlenet. The network\nprovides good accuracy but causes high memory consumption due to a large number\nof trainable parameters. As a solution to this problem, we introduced a whole\nnew architecture based on separable convolution. The idea of separable\nconvolution already exists in the field of image classification but not yet\nintroduces to text classification tasks. With the help of this architecture, we\ncan achieve a drastic reduction in trainable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:23:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Yadav", "Ritu", ""]]}, {"id": "2004.07928", "submitter": "Dmitry Kazhdan", "authors": "Dmitry Kazhdan, Zohreh Shams, Pietro Li\\`o", "title": "MARLeME: A Multi-Agent Reinforcement Learning Model Extraction Library", "comments": "Presented at the KR2ML workshop at the 33rd Conference on Neural\n  Information Processing Systems (NeurIPS 2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Agent Reinforcement Learning (MARL) encompasses a powerful class of\nmethodologies that have been applied in a wide range of fields. An effective\nway to further empower these methodologies is to develop libraries and tools\nthat could expand their interpretability and explainability. In this work, we\nintroduce MARLeME: a MARL model extraction library, designed to improve\nexplainability of MARL systems by approximating them with symbolic models.\nSymbolic models offer a high degree of interpretability, well-defined\nproperties, and verifiable behaviour. Consequently, they can be used to inspect\nand better understand the underlying MARL system and corresponding MARL agents,\nas well as to replace all/some of the agents that are particularly safety and\nsecurity critical.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:27:38 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kazhdan", "Dmitry", ""], ["Shams", "Zohreh", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "2004.07937", "submitter": "Syed Muhammad Usman", "authors": "Syed Muhammad Usman, Shahzad Latif, Arshad Beg", "title": "Principle components analysis for seizures prediction using wavelet\n  transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is a disease in which frequent seizures occur due to abnormal\nactivity of neurons. Patients affected by this disease can be treated with the\nhelp of medicines or surgical procedures. However, both of these methods are\nnot quite useful. The only method to treat epilepsy patients effectively is to\npredict the seizure before its onset. It has been observed that abnormal\nactivity in the brain signals starts before the occurrence of seizure known as\nthe preictal state. Many researchers have proposed machine learning models for\nprediction of epileptic seizures by detecting the start of preictal state.\nHowever, pre-processing, feature extraction and classification remains a great\nchallenge in the prediction of preictal state. Therefore, we propose a model\nthat uses common spatial pattern filtering and wavelet transform for\npreprocessing, principal component analysis for feature extraction and support\nvector machines for detecting preictal state. We have applied our model on 23\nsubjects and an average sensitivity of 93.1% has been observed for 84 seizures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:32:57 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Usman", "Syed Muhammad", ""], ["Latif", "Shahzad", ""], ["Beg", "Arshad", ""]]}, {"id": "2004.07941", "submitter": "Keval Doshi", "authors": "Keval Doshi, Yasin Yilmaz", "title": "Continual Learning for Anomaly Detection in Surveillance Videos", "comments": "accepted to CVPR 2020: Workshop on Continual Learning in Computer\n  Vision. arXiv admin note: text overlap with arXiv:2004.02072", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos has been recently gaining attention.\nA challenging aspect of high-dimensional applications such as video\nsurveillance is continual learning. While current state-of-the-art deep\nlearning approaches perform well on existing public datasets, they fail to work\nin a continual learning framework due to computational and storage issues.\nFurthermore, online decision making is an important but mostly neglected factor\nin this domain. Motivated by these research gaps, we propose an online anomaly\ndetection method for surveillance videos using transfer learning and continual\nlearning, which in turn significantly reduces the training complexity and\nprovides a mechanism for continually learning from recent data without\nsuffering from catastrophic forgetting. Our proposed algorithm leverages the\nfeature extraction power of neural network-based models for transfer learning,\nand the continual learning capability of statistical detection methods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:41:20 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Doshi", "Keval", ""], ["Yilmaz", "Yasin", ""]]}, {"id": "2004.07944", "submitter": "Panagiotis Meletis", "authors": "Panagiotis Meletis, Xiaoxiao Wen, Chenyang Lu, Daan de Geus, Gijs\n  Dubbelman", "title": "Cityscapes-Panoptic-Parts and PASCAL-Panoptic-Parts datasets for Scene\n  Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this technical report, we present two novel datasets for image scene\nunderstanding. Both datasets have annotations compatible with panoptic\nsegmentation and additionally they have part-level labels for selected semantic\nclasses. This report describes the format of the two datasets, the annotation\nprotocols, the merging strategies, and presents the datasets statistics. The\ndatasets labels together with code for processing and visualization will be\npublished at https://github.com/tue-mps/panoptic_parts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 20:42:51 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Meletis", "Panagiotis", ""], ["Wen", "Xiaoxiao", ""], ["Lu", "Chenyang", ""], ["de Geus", "Daan", ""], ["Dubbelman", "Gijs", ""]]}, {"id": "2004.07948", "submitter": "Simone Raponi", "authors": "Simone Raponi, Isra Ali, Gabriele Oligeri", "title": "Sound of Guns: Digital Forensics of Gun Audio Samples meets Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying a weapon based on its muzzle blast is a challenging task that has\nsignificant applications in various security and military fields. Most of the\nexisting works rely on ad-hoc deployment of spatially diverse microphone\nsensors to capture multiple replicas of the same gunshot, which enables\naccurate detection and identification of the acoustic source. However,\ncarefully controlled setups are difficult to obtain in scenarios such as crime\nscene forensics, making the aforementioned techniques inapplicable and\nimpractical. We introduce a novel technique that requires zero knowledge about\nthe recording setup and is completely agnostic to the relative positions of\nboth the microphone and shooter. Our solution can identify the category,\ncaliber, and model of the gun, reaching over 90% accuracy on a dataset composed\nof 3655 samples that are extracted from YouTube videos. Our results demonstrate\nthe effectiveness and efficiency of applying Convolutional Neural Network (CNN)\nin gunshot classification eliminating the need for an ad-hoc setup while\nsignificantly improving the classification performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:12:45 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 14:01:00 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Raponi", "Simone", ""], ["Ali", "Isra", ""], ["Oligeri", "Gabriele", ""]]}, {"id": "2004.07950", "submitter": "Alexander Pashevich", "authors": "Alexander Pashevich, Igor Kalevatykh, Ivan Laptev, Cordelia Schmid", "title": "Learning visual policies for building 3D shape categories", "comments": "IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation and assembly tasks require non-trivial planning of actions\ndepending on the environment and the final goal. Previous work in this domain\noften assembles particular instances of objects from known sets of primitives.\nIn contrast, we aim to handle varying sets of primitives and to construct\ndifferent objects of a shape category. Given a single object instance of a\ncategory, e.g. an arch, and a binary shape classifier, we learn a visual policy\nto assemble other instances of the same category. In particular, we propose a\ndisassembly procedure and learn a state policy that discovers new object\ninstances and their assembly plans in state space. We then render simulated\nstates in the observation space and learn a heatmap representation to predict\nalternative actions from a given input image. To validate our approach, we\nfirst demonstrate its efficiency for building object categories in state space.\nWe then show the success of our visual policies for building arches from\ndifferent primitives. Moreover, we demonstrate (i) the reactive ability of our\nmethod to re-assemble objects using additional primitives and (ii) the robust\nperformance of our policy for unseen primitives resembling building blocks used\nduring training. Our visual assembly policies are trained with no real images\nand reach up to 95% success rate when evaluated on a real robot.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:29:10 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:24:32 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Pashevich", "Alexander", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2004.07955", "submitter": "Jiawang Bai", "authors": "Jiawang Bai, Bin Chen, Yiming Li, Dongxian Wu, Weiwei Guo, Shu-tao\n  Xia, En-hui Yang", "title": "Targeted Attack for Deep Hashing based Retrieval", "comments": "Accepted by ECCV 2020 as Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep hashing based retrieval method is widely adopted in large-scale\nimage and video retrieval. However, there is little investigation on its\nsecurity. In this paper, we propose a novel method, dubbed deep hashing\ntargeted attack (DHTA), to study the targeted attack on such retrieval.\nSpecifically, we first formulate the targeted attack as a point-to-set\noptimization, which minimizes the average distance between the hash code of an\nadversarial example and those of a set of objects with the target label. Then\nwe design a novel component-voting scheme to obtain an anchor code as the\nrepresentative of the set of hash codes of objects with the target label, whose\noptimality guarantee is also theoretically derived. To balance the performance\nand perceptibility, we propose to minimize the Hamming distance between the\nhash code of the adversarial example and the anchor code under the\n$\\ell^\\infty$ restriction on the perturbation. Extensive experiments verify\nthat DHTA is effective in attacking both deep hashing based image retrieval and\nvideo retrieval.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 08:36:58 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 01:25:12 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 08:24:04 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Bai", "Jiawang", ""], ["Chen", "Bin", ""], ["Li", "Yiming", ""], ["Wu", "Dongxian", ""], ["Guo", "Weiwei", ""], ["Xia", "Shu-tao", ""], ["Yang", "En-hui", ""]]}, {"id": "2004.07964", "submitter": "Florian Heimerl", "authors": "Michael Gleicher, Aditya Barve, Xinyi Yu, Florian Heimerl", "title": "Boxer: Interactive Comparison of Classifier Results", "comments": "accepted to Computer Graphic Forum (CGF) to be presented at\n  Eurographics Conference on Visualization (EuroVis) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning practitioners often compare the results of different\nclassifiers to help select, diagnose and tune models. We present Boxer, a\nsystem to enable such comparison. Our system facilitates interactive\nexploration of the experimental results obtained by applying multiple\nclassifiers to a common set of model inputs. The approach focuses on allowing\nthe user to identify interesting subsets of training and testing instances and\ncomparing performance of the classifiers on these subsets. The system couples\nstandard visual designs with set algebra interactions and comparative elements.\nThis allows the user to compose and coordinate views to specify subsets and\nassess classifier performance on them. The flexibility of these compositions\nallow the user to address a wide range of scenarios in developing and assessing\nclassifiers. We demonstrate Boxer in use cases including model selection,\ntuning, fairness assessment, and data quality diagnosis.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 21:05:34 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Gleicher", "Michael", ""], ["Barve", "Aditya", ""], ["Yu", "Xinyi", ""], ["Heimerl", "Florian", ""]]}, {"id": "2004.07965", "submitter": "Pradeeban Kathiravelu", "authors": "Pradeeban Kathiravelu, Puneet Sharma, Ashish Sharma, Imon Banerjee,\n  Hari Trivedi, Saptarshi Purkayastha, Priyanshu Sinha, Alexandre\n  Cadrin-Chenevert, Nabile Safdar, Judy Wawira Gichoya", "title": "A DICOM Framework for Machine Learning Pipelines against Real-Time\n  Radiology Images", "comments": "Preprint", "journal-ref": "Journal of Digital Imaging (JDI), 2021", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Executing machine learning (ML) pipelines in real-time on radiology images is\nhard due to the limited computing resources in clinical environments and the\nlack of efficient data transfer capabilities to run them on research clusters.\nWe propose Niffler, an integrated framework that enables the execution of ML\npipelines at research clusters by efficiently querying and retrieving radiology\nimages from the Picture Archiving and Communication Systems (PACS) of the\nhospitals. Niffler uses the Digital Imaging and Communications in Medicine\n(DICOM) protocol to fetch and store imaging data and provides metadata\nextraction capabilities and Application programming interfaces (APIs) to apply\nfilters on the images. Niffler further enables the sharing of the outcomes from\nthe ML pipelines in a de-identified manner. Niffler has been running stable for\nmore than 19 months and has supported several research projects at the\ndepartment. In this paper, we present its architecture and three of its use\ncases: an inferior vena cava (IVC) filter detection from the images in\nreal-time, identification of scanner utilization, and scanner clock\ncalibration. Evaluations on the Niffler prototype highlight its feasibility and\nefficiency in facilitating the ML pipelines on the images and metadata in\nreal-time and retrospectively.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 21:06:49 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 11:59:04 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 03:16:23 GMT"}, {"version": "v4", "created": "Wed, 5 Aug 2020 04:55:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kathiravelu", "Pradeeban", ""], ["Sharma", "Puneet", ""], ["Sharma", "Ashish", ""], ["Banerjee", "Imon", ""], ["Trivedi", "Hari", ""], ["Purkayastha", "Saptarshi", ""], ["Sinha", "Priyanshu", ""], ["Cadrin-Chenevert", "Alexandre", ""], ["Safdar", "Nabile", ""], ["Gichoya", "Judy Wawira", ""]]}, {"id": "2004.07984", "submitter": "Jean Kossaifi", "authors": "Majid Janzamin, Rong Ge, Jean Kossaifi and Anima Anandkumar", "title": "Spectral Learning on Matrices and Tensors", "comments": null, "journal-ref": "Foundations and Trends in Machine Learning: Vol. 12: No. 5-6, pp\n  393-536 (2019)", "doi": "10.1561/2200000057", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral methods have been the mainstay in several domains such as machine\nlearning and scientific computing. They involve finding a certain kind of\nspectral decomposition to obtain basis functions that can capture important\nstructures for the problem at hand. The most common spectral method is the\nprincipal component analysis (PCA). It utilizes the top eigenvectors of the\ndata covariance matrix, e.g. to carry out dimensionality reduction. This data\npre-processing step is often effective in separating signal from noise. PCA and\nother spectral techniques applied to matrices have several limitations. By\nlimiting to only pairwise moments, they are effectively making a Gaussian\napproximation on the underlying data and fail on data with hidden variables\nwhich lead to non-Gaussianity. However, in most data sets, there are latent\neffects that cannot be directly observed, e.g., topics in a document corpus, or\nunderlying causes of a disease. By extending the spectral decomposition methods\nto higher order moments, we demonstrate the ability to learn a wide range of\nlatent variable models efficiently. Higher-order moments can be represented by\ntensors, and intuitively, they can encode more information than just pairwise\nmoment matrices. More crucially, tensor decomposition can pick up latent\neffects that are missed by matrix methods, e.g. uniquely identify\nnon-orthogonal components. Exploiting these aspects turns out to be fruitful\nfor provable unsupervised learning of a wide range of latent variable models.\nWe also outline the computational techniques to design efficient tensor\ndecomposition methods. We introduce Tensorly, which has a simple python\ninterface for expressing tensor operations. It has a flexible back-end system\nsupporting NumPy, PyTorch, TensorFlow and MXNet amongst others, allowing\nmulti-GPU and CPU operations and seamless integration with deep-learning\nfunctionalities.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:53:00 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Janzamin", "Majid", ""], ["Ge", "Rong", ""], ["Kossaifi", "Jean", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2004.07986", "submitter": "Zhao Song", "authors": "Zhao Song, David P. Woodruff, Peilin Zhong", "title": "Average Case Column Subset Selection for Entrywise $\\ell_1$-Norm Loss", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We study the column subset selection problem with respect to the entrywise\n$\\ell_1$-norm loss. It is known that in the worst case, to obtain a good\nrank-$k$ approximation to a matrix, one needs an arbitrarily large\n$n^{\\Omega(1)}$ number of columns to obtain a $(1+\\epsilon)$-approximation to\nthe best entrywise $\\ell_1$-norm low rank approximation of an $n \\times n$\nmatrix. Nevertheless, we show that under certain minimal and realistic\ndistributional settings, it is possible to obtain a\n$(1+\\epsilon)$-approximation with a nearly linear running time and\npoly$(k/\\epsilon)+O(k\\log n)$ columns. Namely, we show that if the input matrix\n$A$ has the form $A = B + E$, where $B$ is an arbitrary rank-$k$ matrix, and\n$E$ is a matrix with i.i.d. entries drawn from any distribution $\\mu$ for which\nthe $(1+\\gamma)$-th moment exists, for an arbitrarily small constant $\\gamma >\n0$, then it is possible to obtain a $(1+\\epsilon)$-approximate column subset\nselection to the entrywise $\\ell_1$-norm in nearly linear time. Conversely we\nshow that if the first moment does not exist, then it is not possible to obtain\na $(1+\\epsilon)$-approximate subset selection algorithm even if one chooses any\n$n^{o(1)}$ columns. This is the first algorithm of any kind for achieving a\n$(1+\\epsilon)$-approximation for entrywise $\\ell_1$-norm loss low rank\napproximation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:57:06 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Song", "Zhao", ""], ["Woodruff", "David P.", ""], ["Zhong", "Peilin", ""]]}, {"id": "2004.07992", "submitter": "Mariana Rodrigues Makiuchi", "authors": "Mariana Rodrigues Makiuchi, Tifani Warnita, Nakamasa Inoue, Koichi\n  Shinoda, Michitaka Yoshimura, Momoko Kitazawa, Kei Funaki, Yoko Eguchi,\n  Taishiro Kishimoto", "title": "Speech Paralinguistic Approach for Detecting Dementia Using Gated\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a non-invasive and cost-effective method to automatically detect\ndementia by utilizing solely speech audio data. We extract paralinguistic\nfeatures for a short speech segment and use Gated Convolutional Neural Networks\n(GCNN) to classify it into dementia or healthy. We evaluate our method on the\nPitt Corpus and on our own dataset, the PROMPT Database. Our method yields the\naccuracy of 73.1% on the Pitt Corpus using an average of 114 seconds of speech\ndata. In the PROMPT Database, our method yields the accuracy of 74.7% using 4\nseconds of speech data and it improves to 80.8% when we use all the patient's\nspeech data. Furthermore, we evaluate our method on a three-class\nclassification problem in which we included the Mild Cognitive Impairment (MCI)\nclass and achieved the accuracy of 60.6% with 40 seconds of speech data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 23:26:43 GMT"}, {"version": "v2", "created": "Wed, 23 Sep 2020 05:30:57 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 13:00:27 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Makiuchi", "Mariana Rodrigues", ""], ["Warnita", "Tifani", ""], ["Inoue", "Nakamasa", ""], ["Shinoda", "Koichi", ""], ["Yoshimura", "Michitaka", ""], ["Kitazawa", "Momoko", ""], ["Funaki", "Kei", ""], ["Eguchi", "Yoko", ""], ["Kishimoto", "Taishiro", ""]]}, {"id": "2004.08008", "submitter": "Alexander Wong", "authors": "Linda Wang, Mahmoud Famouri, and Alexander Wong", "title": "DepthNet Nano: A Highly Compact Self-Normalizing Neural Network for\n  Monocular Depth Estimation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth estimation is an active area of research in the field of computer\nvision, and has garnered significant interest due to its rising demand in a\nlarge number of applications ranging from robotics and unmanned aerial vehicles\nto autonomous vehicles. A particularly challenging problem in this area is\nmonocular depth estimation, where the goal is to infer depth from a single\nimage. An effective strategy that has shown considerable promise in recent\nyears for tackling this problem is the utilization of deep convolutional neural\nnetworks. Despite these successes, the memory and computational requirements of\nsuch networks have made widespread deployment in embedded scenarios very\nchallenging. In this study, we introduce DepthNet Nano, a highly compact self\nnormalizing network for monocular depth estimation designed using a human\nmachine collaborative design strategy, where principled network design\nprototyping based on encoder-decoder design principles are coupled with\nmachine-driven design exploration. The result is a compact deep neural network\nwith highly customized macroarchitecture and microarchitecture designs, as well\nas self-normalizing characteristics, that are highly tailored for the task of\nembedded depth estimation. The proposed DepthNet Nano possesses a highly\nefficient network architecture (e.g., 24X smaller and 42X fewer MAC operations\nthan Alhashim et al. on KITTI), while still achieving comparable performance\nwith state-of-the-art networks on the NYU-Depth V2 and KITTI datasets.\nFurthermore, experiments on inference speed and energy efficiency on a Jetson\nAGX Xavier embedded module further illustrate the efficacy of DepthNet Nano at\ndifferent resolutions and power budgets (e.g., ~14 FPS and >0.46\nimages/sec/watt at 384 X 1280 at a 30W power budget on KITTI).\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 00:41:35 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Wang", "Linda", ""], ["Famouri", "Mahmoud", ""], ["Wong", "Alexander", ""]]}, {"id": "2004.08013", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, David Sussillo", "title": "How recurrent networks implement contextual processing in sentiment\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have a remarkable capacity for contextual processing--using\nrecent or nearby inputs to modify processing of current input. For example, in\nnatural language, contextual processing is necessary to correctly interpret\nnegation (e.g. phrases such as \"not bad\"). However, our ability to understand\nhow networks process context is limited. Here, we propose general methods for\nreverse engineering recurrent neural networks (RNNs) to identify and elucidate\ncontextual processing. We apply these methods to understand RNNs trained on\nsentiment classification. This analysis reveals inputs that induce contextual\neffects, quantifies the strength and timescale of these effects, and identifies\nsets of these inputs with similar properties. Additionally, we analyze\ncontextual effects related to differential processing of the beginning and end\nof documents. Using the insights learned from the RNNs we improve baseline\nBag-of-Words models with simple extensions that incorporate contextual\nmodification, recovering greater than 90% of the RNN's performance increase\nover the baseline. This work yields a new understanding of how RNNs process\ncontextual information, and provides tools that should provide similar insight\nmore broadly.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 00:58:30 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Sussillo", "David", ""]]}, {"id": "2004.08022", "submitter": "Piji Li", "authors": "Piji Li, Haisong Zhang, Xiaojiang Liu, Shuming Shi", "title": "SongNet: Rigid Formats Controlled Text Generation", "comments": "ACL2020, 10 pages, code: https://github.com/lipiji/SongNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation has made tremendous progress in various tasks. One\ncommon characteristic of most of the tasks is that the texts are not restricted\nto some rigid formats when generating. However, we may confront some special\ntext paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi\n(classical Chinese poetry of the Song dynasty), etc. The typical\ncharacteristics of these texts are in three folds: (1) They must comply fully\nwith the rigid predefined formats. (2) They must obey some rhyming schemes. (3)\nAlthough they are restricted to some formats, the sentence integrity must be\nguaranteed. To the best of our knowledge, text generation based on the\npredefined rigid formats has not been well investigated. Therefore, we propose\na simple and elegant framework named SongNet to tackle this problem. The\nbackbone of the framework is a Transformer-based auto-regressive language\nmodel. Sets of symbols are tailor-designed to improve the modeling performance\nespecially on format, rhyme, and sentence integrity. We improve the attention\nmechanism to impel the model to capture some future information on the format.\nA pre-training and fine-tuning framework is designed to further improve the\ngeneration quality. Extensive experiments conducted on two collected corpora\ndemonstrate that our proposed framework generates significantly better results\nin terms of both automatic metrics and the human evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 01:40:18 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 03:49:06 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Li", "Piji", ""], ["Zhang", "Haisong", ""], ["Liu", "Xiaojiang", ""], ["Shi", "Shuming", ""]]}, {"id": "2004.08038", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick, Prasanna Balaprakash, Eric Rask, and Jane Macfarlane", "title": "Transfer Learning with Graph Neural Networks for Short-Term Highway\n  Traffic Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highway traffic modeling and forecasting approaches are critical for\nintelligent transportation systems. Recently, deep-learning-based traffic\nforecasting methods have emerged as state of the art for a wide range of\ntraffic forecasting tasks. However, these methods require a large amount of\ntraining data, which needs to be collected over a significant period of time.\nThis can present a number of challenges for the development and deployment of\ndata-driven learning methods for highway networks that suffer from lack of\nhistorical data. A promising approach to address this issue is transfer\nlearning, where a model trained on one part of the highway network can be\nadapted for a different part of the highway network. We focus on diffusion\nconvolutional recurrent neural network (DCRNN), a state-of-the-art graph neural\nnetwork for highway network forecasting. It models the complex spatial and\ntemporal dynamics of the highway network using a graph-based diffusion\nconvolution operation within a recurrent neural network. DCRNN cannot perform\ntransfer learning, however, because it learns location-specific traffic\npatterns, which cannot be used for unseen regions of the network. To that end,\nwe develop a new transfer learning approach for DCRNN, where a single model\ntrained on data-rich regions of the highway network can be used to forecast\ntraffic on unseen regions of the highway network. We evaluate the ability of\nour approach to forecast the traffic on the entire California highway network\nwith one year of time series data. We show that TL-DCRNN can learn from several\nregions of the California highway network and forecast the traffic on the\nunseen regions of the network with high accuracy. Moreover, we demonstrate that\nTL-DCRNN can learn from San Francisco region traffic data and can forecast\ntraffic on the Los Angeles region and vice versa.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 02:29:42 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 13:12:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mallick", "Tanwi", ""], ["Balaprakash", "Prasanna", ""], ["Rask", "Eric", ""], ["Macfarlane", "Jane", ""]]}, {"id": "2004.08046", "submitter": "Dongyu Ru", "authors": "Dongyu Ru, Jiangtao Feng, Lin Qiu, Hao Zhou, Mingxuan Wang, Weinan\n  Zhang, Yong Yu, Lei Li", "title": "Active Sentence Learning by Adversarial Uncertainty Sampling in Discrete\n  Space", "comments": "Accepted to EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning for sentence understanding aims at discovering informative\nunlabeled data for annotation and therefore reducing the demand for labeled\ndata. We argue that the typical uncertainty sampling method for active learning\nis time-consuming and can hardly work in real-time, which may lead to\nineffective sample selection. We propose adversarial uncertainty sampling in\ndiscrete space (AUSDS) to retrieve informative unlabeled samples more\nefficiently. AUSDS maps sentences into latent space generated by the popular\npre-trained language models, and discover informative unlabeled text samples\nfor annotation via adversarial attack. The proposed approach is extremely\nefficient compared with traditional uncertainty sampling with more than 10x\nspeedup. Experimental results on five datasets show that AUSDS outperforms\nstrong baselines on effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:12:34 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 04:45:49 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Ru", "Dongyu", ""], ["Feng", "Jiangtao", ""], ["Qiu", "Lin", ""], ["Zhou", "Hao", ""], ["Wang", "Mingxuan", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""], ["Li", "Lei", ""]]}, {"id": "2004.08051", "submitter": "Keuntaek Lee", "authors": "Keuntaek Lee, Bogdan Vlahov, Jason Gibson, James M. Rehg, Evangelos A.\n  Theodorou", "title": "Approximate Inverse Reinforcement Learning from Vision-based Imitation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we present a method for obtaining an implicit objective\nfunction for vision-based navigation. The proposed methodology relies on\nImitation Learning, Model Predictive Control (MPC), and an interpretation\ntechnique used in Deep Neural Networks. We use Imitation Learning as a means to\ndo Inverse Reinforcement Learning in order to create an approximate cost\nfunction generator for a visual navigation challenge. The resulting cost\nfunction, the costmap, is used in conjunction with MPC for real-time control\nand outperforms other state-of-the-art costmap generators in novel\nenvironments. The proposed process allows for simple training and robustness to\nout-of-sample data. We apply our method to the task of vision-based autonomous\ndriving in multiple real and simulated environments and show its\ngeneralizability.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:36:50 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 03:37:41 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 19:52:37 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Lee", "Keuntaek", ""], ["Vlahov", "Bogdan", ""], ["Gibson", "Jason", ""], ["Rehg", "James M.", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "2004.08052", "submitter": "Mohammad Rahimzadeh", "authors": "Mohammad Rahimzadeh, Abolfazl Attar", "title": "A modified deep convolutional neural network for detecting COVID-19 and\n  pneumonia from chest X-ray images based on the concatenation of Xception and\n  ResNet50V2", "comments": "This is a preprint of an article published in Informatics in Medicine\n  Unlocked journal. The final authenticated version is available online at\n  https://doi.org/10.1016/j.imu.2020.100360. The Code is available at\n  https://github.com/mr7495/covid19", "journal-ref": null, "doi": "10.1016/j.imu.2020.100360", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we have trained several deep convolutional networks with\nintroduced training techniques for classifying X-ray images into three classes:\nnormal, pneumonia, and COVID-19, based on two open-source datasets. Our data\ncontains 180 X-ray images that belong to persons infected with COVID-19, and we\nattempted to apply methods to achieve the best possible results. In this\nresearch, we introduce some training techniques that help the network learn\nbetter when we have an unbalanced dataset (fewer cases of COVID-19 along with\nmore cases from other classes). We also propose a neural network that is a\nconcatenation of the Xception and ResNet50V2 networks. This network achieved\nthe best accuracy by utilizing multiple features extracted by two robust\nnetworks. For evaluating our network, we have tested it on 11302 images to\nreport the actual accuracy achievable in real circumstances. The average\naccuracy of the proposed network for detecting COVID-19 cases is 99.50%, and\nthe overall average accuracy for all classes is 91.4%.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:38:39 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 01:14:11 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Rahimzadeh", "Mohammad", ""], ["Attar", "Abolfazl", ""]]}, {"id": "2004.08066", "submitter": "Toshihisa Tanaka", "authors": "Yuki Hagiwara and Toshihisa Tanaka", "title": "YuruGAN: Yuru-Chara Mascot Generator Using Generative Adversarial\n  Networks With Clustering Small Dataset", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A yuru-chara is a mascot character created by local governments and companies\nfor publicizing information on areas and products. Because it takes various\ncosts to create a yuruchara, the utilization of machine learning techniques\nsuch as generative adversarial networks (GANs) can be expected. In recent\nyears, it has been reported that the use of class conditions in a dataset for\nGANs training stabilizes learning and improves the quality of the generated\nimages. However, it is difficult to apply class conditional GANs when the\namount of original data is small and when a clear class is not given, such as a\nyuruchara image. In this paper, we propose a class conditional GAN based on\nclustering and data augmentation. Specifically, first, we performed clustering\nbased on K-means++ on the yuru-chara image dataset and converted it into a\nclass conditional dataset. Next, data augmentation was performed on the class\nconditional dataset so that the amount of data was increased five times. In\naddition, we built a model that incorporates ResBlock and self-attention into a\nnetwork based on class conditional GAN and trained the class conditional\nyuru-chara dataset. As a result of evaluating the generated images, the effect\non the generated images by the difference of the clustering method was\nconfirmed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 05:18:49 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hagiwara", "Yuki", ""], ["Tanaka", "Toshihisa", ""]]}, {"id": "2004.08067", "submitter": "Jaeyeon Jang", "authors": "Jaeyeon Jang and Chang Ouk Kim", "title": "One-vs-Rest Network-based Deep Probability Model for Open Set\n  Recognition", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unknown examples that are unseen during training often appear in real-world\ncomputer vision tasks, and an intelligent self-learning system should be able\nto differentiate between known and unknown examples. Open set recognition,\nwhich addresses this problem, has been studied for approximately a decade.\nHowever, conventional open set recognition methods based on deep neural\nnetworks (DNNs) lack a foundation for post recognition score analysis. In this\npaper, we propose a DNN structure in which multiple one-vs-rest sigmoid\nnetworks follow a convolutional neural network feature extractor. A one-vs-rest\nnetwork, which is composed of rectified linear unit activation functions for\nthe hidden layers and a single sigmoid target class output node, can maximize\nthe ability to learn information from nonmatch examples. Furthermore, the\nnetwork yields a sophisticated nonlinear features-to-output mapping that is\nexplainable in the feature space. By introducing extreme value theory-based\ncalibration techniques, the nonlinear and explainable mapping provides a\nwell-grounded class membership probability models. Our experiments show that\none-vs-rest networks can provide more informative hidden representations for\nunknown examples than the commonly used SoftMax layer. In addition, the\nproposed probability model outperformed the state-of-the art methods in open\nset classification scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 05:24:34 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 06:37:47 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Jang", "Jaeyeon", ""], ["Kim", "Chang Ouk", ""]]}, {"id": "2004.08068", "submitter": "Xiaocong Chen", "authors": "Xiaocong Chen, Chaoran Huang, Lina Yao, Xianzhi Wang, Wei Liu, Wenjie\n  Zhang", "title": "Knowledge-guided Deep Reinforcement Learning for Interactive\n  Recommendation", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207010", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommendation aims to learn from dynamic interactions between\nitems and users to achieve responsiveness and accuracy. Reinforcement learning\nis inherently advantageous for coping with dynamic environments and thus has\nattracted increasing attention in interactive recommendation research. Inspired\nby knowledge-aware recommendation, we proposed Knowledge-Guided deep\nReinforcement learning (KGRL) to harness the advantages of both reinforcement\nlearning and knowledge graphs for interactive recommendation. This model is\nimplemented upon the actor-critic network framework. It maintains a local\nknowledge network to guide decision-making and employs the attention mechanism\nto capture long-term semantics between items. We have conducted comprehensive\nexperiments in a simulated online environment with six public real-world\ndatasets and demonstrated the superiority of our model over several\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 05:26:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Chen", "Xiaocong", ""], ["Huang", "Chaoran", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Liu", "Wei", ""], ["Zhang", "Wenjie", ""]]}, {"id": "2004.08083", "submitter": "Arkabandhu Chowdhury", "authors": "Arkabandhu Chowdhury, Dipak Chaudhari, Swarat Chaudhuri, Chris\n  Jermaine", "title": "Meta-Meta Classification for One-Shot Learning", "comments": "10 pages without references, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach, called meta-meta classification, to learning in\nsmall-data settings. In this approach, one uses a large set of learning\nproblems to design an ensemble of learners, where each learner has high bias\nand low variance and is skilled at solving a specific type of learning problem.\nThe meta-meta classifier learns how to examine a given learning problem and\ncombine the various learners to solve the problem. The meta-meta learning\napproach is especially suited to solving few-shot learning tasks, as it is\neasier to learn to classify a new learning problem with little data than it is\nto apply a learning algorithm to a small data set. We evaluate the approach on\na one-shot, one-class-versus-all classification task and show that it is able\nto outperform traditional meta-learning as well as ensembling approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:05:03 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 16:46:20 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 02:28:08 GMT"}, {"version": "v4", "created": "Sun, 14 Jun 2020 01:02:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Chowdhury", "Arkabandhu", ""], ["Chaudhari", "Dipak", ""], ["Chaudhuri", "Swarat", ""], ["Jermaine", "Chris", ""]]}, {"id": "2004.08085", "submitter": "Remi Gribonval", "authors": "R\\'emi Gribonval (PANAMA, DANTE), Gilles Blanchard (LMO), Nicolas\n  Keriven (GIPSA-GAIA), Yann Traonmilin (IMB)", "title": "Statistical Learning Guarantees for Compressive Clustering and\n  Compressive Mixture Modeling", "comments": "This preprint results from a split and profound restructuring and\n  improvements of of https://hal.inria.fr/hal-01544609v2It is a companion paper\n  to https://hal.inria.fr/hal-01544609v3", "journal-ref": "Mathematical Statistics and Learning, EMS Publishing House, In\n  press", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide statistical learning guarantees for two unsupervised learning\ntasks in the context of compressive statistical learning, a general framework\nfor resource-efficient large-scale learning that we introduced in a companion\npaper. The principle of compressive statistical learning is to compress a\ntraining collection, in one pass, into a low-dimensional sketch (a vector of\nrandom empirical generalized moments) that captures the information relevant to\nthe considered learning task. We explicit random feature functions which\nempirical averages preserve the needed information for compressive clustering\nand compressive Gaussian mixture modeling with fixed known variance, and\nestablish sufficient sketch sizes given the problem dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:05:29 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 09:23:11 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Gribonval", "R\u00e9mi", "", "PANAMA, DANTE"], ["Blanchard", "Gilles", "", "LMO"], ["Keriven", "Nicolas", "", "GIPSA-GAIA"], ["Traonmilin", "Yann", "", "IMB"]]}, {"id": "2004.08096", "submitter": "Yanghua Jin", "authors": "Naofumi Akimoto, Huachun Zhu, Yanghua Jin, Yoshimitsu Aoki", "title": "Fast Soft Color Segmentation", "comments": "Accepted at CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of soft color segmentation, defined as decomposing a\ngiven image into several RGBA layers, each containing only homogeneous color\nregions. The resulting layers from decomposition pave the way for applications\nthat benefit from layer-based editing, such as recoloring and compositing of\nimages and videos. The current state-of-the-art approach for this problem is\nhindered by slow processing time due to its iterative nature, and consequently\ndoes not scale to certain real-world scenarios. To address this issue, we\npropose a neural network based method for this task that decomposes a given\nimage into multiple layers in a single forward pass. Furthermore, our method\nseparately decomposes the color layers and the alpha channel layers. By\nleveraging a novel training objective, our method achieves proper assignment of\ncolors amongst layers. As a consequence, our method achieve promising quality\nwithout existing issue of inference speed for iterative approaches. Our\nthorough experimental analysis shows that our method produces qualitative and\nquantitative results comparable to previous methods while achieving a 300,000x\nspeed improvement. Finally, we utilize our proposed method on several\napplications, and demonstrate its speed advantage, especially in video editing.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:43:33 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Akimoto", "Naofumi", ""], ["Zhu", "Huachun", ""], ["Jin", "Yanghua", ""], ["Aoki", "Yoshimitsu", ""]]}, {"id": "2004.08100", "submitter": "Mahdi Kherad", "authors": "Mahdi Kherad and Amir Jalaly Bidgoly", "title": "Recommendation system using a deep learning and graph analysis approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a user connects to the Internet to fulfill his needs, he often\nencounters a huge amount of related information. Recommender systems are the\ntechniques for massively filtering information and offering the items that\nusers find them satisfying and interesting. The advances in machine learning\nmethods, especially deep learning, have led to great achievements in\nrecommender systems, although these systems still suffer from challenges such\nas cold-start and sparsity problems. To solve these problems, context\ninformation such as user communication network is usually used. In this paper,\nwe have proposed a novel recommendation method based on Matrix Factorization\nand graph analysis methods. In addition, we leverage deep Autoencoders to\ninitialize users and items latent factors, and deep embedding method gathers\nusers' latent factors from the user trust graph. The proposed method is\nimplemented on two standard datasets. The experimental results and comparisons\ndemonstrate that the proposed approach is superior to the existing\nstate-of-the-art recommendation methods. Our approach outperforms other\ncomparative methods and achieves great improvements.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:05:33 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 11:59:00 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 07:46:45 GMT"}, {"version": "v4", "created": "Thu, 16 Jul 2020 05:26:05 GMT"}, {"version": "v5", "created": "Tue, 28 Jul 2020 06:42:44 GMT"}, {"version": "v6", "created": "Thu, 8 Jul 2021 12:28:08 GMT"}, {"version": "v7", "created": "Fri, 9 Jul 2021 14:12:47 GMT"}, {"version": "v8", "created": "Tue, 13 Jul 2021 18:28:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Kherad", "Mahdi", ""], ["Bidgoly", "Amir Jalaly", ""]]}, {"id": "2004.08101", "submitter": "Attila Tiba", "authors": "Andras Hajdu, Gyorgy Terdik, Attila Tiba, Henrietta Toman", "title": "A stochastic approach to handle knapsack problems in the creation of\n  ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble-based methods are highly popular approaches that increase the\naccuracy of a decision by aggregating the opinions of individual voters. The\ncommon point is to maximize accuracy; however, a natural limitation occurs if\nincremental costs are also assigned to the individual voters. Consequently, we\ninvestigate creating ensembles under an additional constraint on the total cost\nof the members. This task can be formulated as a knapsack problem, where the\nenergy is the ensemble accuracy formed by some aggregation rules. However, the\ngenerally applied aggregation rules lead to a nonseparable energy function,\nwhich takes the common solution tools -- such as dynamic programming -- out of\naction. We introduce a novel stochastic approach that considers the energy as\nthe joint probability function of the member accuracies. This type of knowledge\ncan be efficiently incorporated in a stochastic search process as a stopping\nrule, since we have the information on the expected accuracy or, alternatively,\nthe probability of finding more accurate ensembles. Experimental analyses of\nthe created ensembles of pattern classifiers and object detectors confirm the\nefficiency of our approach. Moreover, we propose a novel stochastic search\nstrategy that better fits the energy, compared with general approaches such as\nsimulated annealing.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:06:34 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Hajdu", "Andras", ""], ["Terdik", "Gyorgy", ""], ["Tiba", "Attila", ""], ["Toman", "Henrietta", ""]]}, {"id": "2004.08103", "submitter": "Sricharan Vijayarangan", "authors": "Sricharan Vijayarangan, Vignesh R, Balamurali Murugesan, Preejith SP,\n  Jayaraj Joseph and Mohansankar Sivaprakasam", "title": "RPnet: A Deep Learning approach for robust R Peak detection in noisy ECG", "comments": "Accepted in EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Automatic detection of R-peaks in an Electrocardiogram signal is crucial in a\nmultitude of applications including Heart Rate Variability (HRV) analysis and\nCardio Vascular Disease(CVD) diagnosis. Although there have been numerous\napproaches that have successfully addressed the problem, there has been a\nnotable dip in the performance of these existing detectors on ECG episodes that\ncontain noise and HRV Irregulates. On the other hand, Deep Learning(DL) based\nmethods have shown to be adept at modelling data that contain noise. In image\nto image translation, Unet is the fundamental block in many of the networks. In\nthis work, a novel application of the Unet combined with Inception and Residual\nblocks is proposed to perform the extraction of R-peaks from an ECG.\nFurthermore, the problem formulation also robustly deals with issues of\nvariability and sparsity of ECG R-peaks. The proposed network was trained on a\ndatabase containing ECG episodes that have CVD and was tested against three\ntraditional ECG detectors on a validation set. The model achieved an F1 score\nof 0.9837, which is a substantial improvement over the other beat detectors.\nFurthermore, the model was also evaluated on three other databases. The\nproposed network achieved high F1 scores across all datasets which established\nits generalizing capacity. Additionally, a thorough analysis of the model's\nperformance in the presence of different levels of noise was carried out.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:11:39 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Vijayarangan", "Sricharan", ""], ["R", "Vignesh", ""], ["Murugesan", "Balamurali", ""], ["SP", "Preejith", ""], ["Joseph", "Jayaraj", ""], ["Sivaprakasam", "Mohansankar", ""]]}, {"id": "2004.08108", "submitter": "Jorge Pe\\~na Queralta", "authors": "Wenshuai Zhao, Dihong Jiang, Jorge Pe\\~na Queralta, Tomi Westerlund", "title": "Multi-Scale Supervised 3D U-Net for Kidneys and Kidney Tumor\n  Segmentation", "comments": null, "journal-ref": null, "doi": "10.1016/j.imu.2020.100357", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate segmentation of kidneys and kidney tumors is an essential step for\nradiomic analysis as well as developing advanced surgical planning techniques.\nIn clinical analysis, the segmentation is currently performed by clinicians\nfrom the visual inspection images gathered through a computed tomography (CT)\nscan. This process is laborious and its success significantly depends on\nprevious experience. Moreover, the uncertainty in the tumor location and\nheterogeneity of scans across patients increases the error rate. To tackle this\nissue, computer-aided segmentation based on deep learning techniques have\nbecome increasingly popular. We present a multi-scale supervised 3D U-Net, MSS\nU-Net, to automatically segment kidneys and kidney tumors from CT images. Our\narchitecture combines deep supervision with exponential logarithmic loss to\nincrease the 3D U-Net training efficiency. Furthermore, we introduce a\nconnected-component based post processing method to enhance the performance of\nthe overall process. This architecture shows superior performance compared to\nstate-of-the-art works using data from KiTS19 public dataset, with the Dice\ncoefficient of kidney and tumor up to 0.969 and 0.805 respectively. The\nsegmentation techniques introduced in this paper have been tested in the KiTS19\nchallenge with its corresponding dataset.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:25:43 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Zhao", "Wenshuai", ""], ["Jiang", "Dihong", ""], ["Queralta", "Jorge Pe\u00f1a", ""], ["Westerlund", "Tomi", ""]]}, {"id": "2004.08113", "submitter": "Senlin Shu", "authors": "Senlin Shu, Fengmao Lv, Lei Feng, Yan Yan, Shuo He, Jun He, Li Li", "title": "Incorporating Multiple Cluster Centers for Multi-Label Learning", "comments": "19 pages with 4 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-label learning deals with the problem that each instance is associated\nwith multiple labels simultaneously. Most of the existing approaches aim to\nimprove the performance of multi-label learning by exploiting label\ncorrelations. Although the data augmentation technique is widely used in many\nmachine learning tasks, it is still unclear whether data augmentation is\nhelpful to multi-label learning. In this paper, (to the best of our knowledge)\nwe provide the first attempt to leverage the data augmentation technique to\nimprove the performance of multi-label learning. Specifically, we first propose\na novel data augmentation approach that performs clustering on the real\nexamples and treats the cluster centers as virtual examples, and these virtual\nexamples naturally embody the local label correlations and label importances.\nThen, motivated by the cluster assumption that examples in the same cluster\nshould have the same label, we propose a novel regularization term to bridge\nthe gap between the real examples and virtual examples, which can promote the\nlocal smoothness of the learning function. Extensive experimental results on a\nnumber of real-world multi-label data sets clearly demonstrate that our\nproposed approach outperforms the state-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:39:58 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 13:57:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Shu", "Senlin", ""], ["Lv", "Fengmao", ""], ["Feng", "Lei", ""], ["Yan", "Yan", ""], ["He", "Shuo", ""], ["He", "Jun", ""], ["Li", "Li", ""]]}, {"id": "2004.08114", "submitter": "Philip John Gorinski", "authors": "Gabriel Gordon-Hall, Philip John Gorinski, Gerasimos Lampouras,\n  Ignacio Iacobacci", "title": "Show Us the Way: Learning to Manage Dialog from Demonstrations", "comments": "8 pages + 2 pages references, 4 figures, 4 tables, accepted to DSTC8\n  Workshop at AAAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our submission to the End-to-End Multi-Domain Dialog Challenge\nTrack of the Eighth Dialog System Technology Challenge. Our proposed dialog\nsystem adopts a pipeline architecture, with distinct components for Natural\nLanguage Understanding, Dialog State Tracking, Dialog Management and Natural\nLanguage Generation. At the core of our system is a reinforcement learning\nalgorithm which uses Deep Q-learning from Demonstrations to learn a dialog\npolicy with the help of expert examples. We find that demonstrations are\nessential to training an accurate dialog policy where both state and action\nspaces are large. Evaluation of our Dialog Management component shows that our\napproach is effective - beating supervised and reinforcement learning\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:41:54 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Gordon-Hall", "Gabriel", ""], ["Gorinski", "Philip John", ""], ["Lampouras", "Gerasimos", ""], ["Iacobacci", "Ignacio", ""]]}, {"id": "2004.08116", "submitter": "Motoshi Abe", "authors": "Hideki Oki, Motoshi Abe, Junichi Miyao, Takio Kurita", "title": "Triplet Loss for Knowledge Distillation", "comments": "Accepted to IJCNN 2020, Source code is at\n  https://github.com/i13abe/Triplet-Loss-for-Knowledge-Distillation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has spread rapidly, and deeper, larger models\nhave been proposed. However, the calculation cost becomes enormous as the size\nof the models becomes larger. Various techniques for compressing the size of\nthe models have been proposed to improve performance while reducing\ncomputational costs. One of the methods to compress the size of the models is\nknowledge distillation (KD). Knowledge distillation is a technique for\ntransferring knowledge of deep or ensemble models with many parameters (teacher\nmodel) to smaller shallow models (student model). Since the purpose of\nknowledge distillation is to increase the similarity between the teacher model\nand the student model, we propose to introduce the concept of metric learning\ninto knowledge distillation to make the student model closer to the teacher\nmodel using pairs or triplets of the training samples. In metric learning, the\nresearchers are developing the methods to build a model that can increase the\nsimilarity of outputs for similar samples. Metric learning aims at reducing the\ndistance between similar and increasing the distance between dissimilar. The\nfunctionality of the metric learning to reduce the differences between similar\noutputs can be used for the knowledge distillation to reduce the differences\nbetween the outputs of the teacher model and the student model. Since the\noutputs of the teacher model for different objects are usually different, the\nstudent model needs to distinguish them. We think that metric learning can\nclarify the difference between the different outputs, and the performance of\nthe student model could be improved. We have performed experiments to compare\nthe proposed method with state-of-the-art knowledge distillation methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:48:29 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Oki", "Hideki", ""], ["Abe", "Motoshi", ""], ["Miyao", "Junichi", ""], ["Kurita", "Takio", ""]]}, {"id": "2004.08118", "submitter": "Ebin Zacharias", "authors": "Ebin Zacharias, Didier Stricker, Martin Teuchler and Kripasindhu\n  Sarkar", "title": "Object Detection and Recognition of Swap-Bodies using Camera mounted on\n  a Vehicle", "comments": "13 pages 9 figures 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection and identification is a challenging area of computer vision\nand a fundamental requirement for autonomous cars. This project aims to jointly\nperform object detection of a swap-body and to find the type of swap-body by\nreading an ILU code using an efficient optical character recognition (OCR)\nmethod. Recent research activities have drastically improved deep learning\ntechniques which proves to enhance the field of computer vision. Collecting\nenough images for training the model is a critical step towards achieving good\nresults. The data for training were collected from different locations with\nmaximum possible variations and the details are explained. In addition, data\naugmentation methods applied for training has proved to be effective in\nimproving the performance of the trained model. Training the model achieved\ngood results and the test results are also provided. The final model was tested\nwith images and videos. Finally, this paper also draws attention to some of the\nmajor challenges faced during various stages of the project and the possible\nsolutions applied.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:49:54 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Zacharias", "Ebin", ""], ["Stricker", "Didier", ""], ["Teuchler", "Martin", ""], ["Sarkar", "Kripasindhu", ""]]}, {"id": "2004.08119", "submitter": "Raul De Maio PhD", "authors": "Laura Aquilanti, Simone Cacace, Fabio Camilli and Raul De Maio", "title": "A Mean Field Games model for finite mixtures of Bernoulli and\n  Categorical distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models are an important tool in the statistical analysis of\ndata, for example in data clustering. The optimal parameters of a mixture model\nare usually computed by maximizing the log-likelihood functional via the\nExpectation-Maximization algorithm. We propose an alternative approach based on\nthe theory of Mean Field Games, a class of differential games with an infinite\nnumber of agents. We show that the solution of a finite state space\nmulti-population Mean Field Games system characterizes the critical points of\nthe log-likelihood functional for a Bernoulli mixture. The approach is then\ngeneralized to mixture models of categorical distributions. Hence, the Mean\nField Games approach provides a method to compute the parameters of the mixture\nmodel, and we show its application to some standard examples in cluster\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 08:50:05 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 08:52:28 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Aquilanti", "Laura", ""], ["Cacace", "Simone", ""], ["Camilli", "Fabio", ""], ["De Maio", "Raul", ""]]}, {"id": "2004.08139", "submitter": "Nathanael Perraudin N. P.", "authors": "Nathana\\\"el Perraudin, Sandro Marcon, Aurelien Lucchi, Tomasz Kacprzak", "title": "Emulation of cosmological mass maps with conditional generative\n  adversarial networks", "comments": "Accepted at the Workshop at the 33rd Conference on Neural Information\n  Processing Systems (NeurIPS), December 14, 2019,\n  https://ml4physicalsciences.github.io/files/NeurIPS_ML4PS_2019_97.pdf\n  Accepted in Frontiers in Artificial Intelligence in May 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weak gravitational lensing mass maps play a crucial role in understanding the\nevolution of structures in the universe and our ability to constrain\ncosmological models. The prediction of these mass maps is based on expensive\nN-body simulations, which can create a computational bottleneck for\ncosmological analyses. Modern deep generative models, such as Generative\nAdversarial Networks (GAN), have demonstrated their potential to achieve this\ngoal. Most existing GAN approaches produce simulations for a fixed value of the\ncosmological parameters, which limits their practical applicability. We propose\na novel conditional GAN model that is able to generate mass maps for any pair\nof matter density $\\Omega_m$ and matter clustering strength $\\sigma_8$,\nparameters which have the largest impact on the evolution of structures in the\nuniverse. Our results show that our conditional GAN can interpolate efficiently\nwithin the space of simulated cosmologies, and generate maps anywhere inside\nthis space with good visual quality high statistical accuracy. We perform an\nextensive quantitative comparison of the N-body and GAN -generated maps using a\nrange of metrics: the pixel histograms, peak counts, power spectra, bispectra,\nMinkowski functionals, correlation matrices of the power spectra, the\nMulti-Scale Structural Similarity Index (MS-SSIM) and our equivalent of the\nFr\\'echet Inception Distance (FID). We find a very good agreement on these\nmetrics, with typical differences are <5% at the centre of the simulation grid,\nand slightly worse for cosmologies at the grid edges. The agreement for the\nbispectrum is slightly worse, on the <20% level. This contribution is a step\ntowards building emulators of mass maps directly, capturing both the\ncosmological signal and its variability. We make the code and the data publicly\navailable: https://renkulab.io/gitlab/nathanael.perraudin/darkmattergan\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:34:34 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 09:32:38 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Perraudin", "Nathana\u00ebl", ""], ["Marcon", "Sandro", ""], ["Lucchi", "Aurelien", ""], ["Kacprzak", "Tomasz", ""]]}, {"id": "2004.08151", "submitter": "Wei Peng", "authors": "Wei Peng, Weien Zhou, Jun Zhang, Wen Yao", "title": "Accelerating Physics-Informed Neural Network Training with Prior\n  Dictionaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) can be regarded as general-purpose\nPDE solvers, but it might be slow to train PINNs on particular problems, and\nthere is no theoretical guarantee of corresponding error bounds. In this\nmanuscript, we propose a variant called Prior Dictionary based Physics-Informed\nNeural Networks (PD-PINNs). Equipped with task-dependent dictionaries, PD-PINNs\nenjoy enhanced representation power on the tasks, which helps to capture\nfeatures provided by dictionaries so that the proposed neural networks can\nachieve faster convergence in the process of training. In various numerical\nsimulations, compared with existing PINN methods, combining prior dictionaries\ncan significantly enhance convergence speed. In terms of theory, we obtain the\nerror bounds applicable to PINNs and PD-PINNs for solving elliptic partial\ndifferential equations of second order. It is proved that under certain mild\nconditions, the prediction error made by neural networks can be bounded by\nexpected loss of PDEs and boundary conditions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:14:41 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 02:10:56 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Peng", "Wei", ""], ["Zhou", "Weien", ""], ["Zhang", "Jun", ""], ["Yao", "Wen", ""]]}, {"id": "2004.08152", "submitter": "Mohammadamin Tavakoli", "authors": "Mohammadamin Tavakoli and Pierre Baldi", "title": "Continuous Representation of Molecules Using Graph Variational\n  Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to continuously represent molecules, we propose a generative model\nin the form of a VAE which is operating on the 2D-graph structure of molecules.\nA side predictor is employed to prune the latent space and help the decoder in\ngenerating meaningful adjacency tensor of molecules. Other than the potential\napplicability in drug design and property prediction, we show the superior\nperformance of this technique in comparison to other similar methods based on\nthe SMILES representation of the molecules with RNN based encoder and decoder.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:19:55 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tavakoli", "Mohammadamin", ""], ["Baldi", "Pierre", ""]]}, {"id": "2004.08153", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Athanasios Voulodimos, Anastasios Doulamis,\n  Nikolaos Bakalos, Nikolaos Doulamis", "title": "Space-Time Domain Tensor Neural Networks: An Application on Human Pose\n  Classification", "comments": "8 pages, 8 figures, accepted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in sensing technologies require the design and development of\npattern recognition models capable of processing spatiotemporal data\nefficiently. In this study, we propose a spatially and temporally aware\ntensor-based neural network for human pose classification using\nthree-dimensional skeleton data. Our model employs three novel components.\nFirst, an input layer capable of constructing highly discriminative\nspatiotemporal features. Second, a tensor fusion operation that produces\ncompact yet rich representations of the data, and third, a tensor-based neural\nnetwork that processes data representations in their original tensor form. Our\nmodel is end-to-end trainable and characterized by a small number of trainable\nparameters making it suitable for problems where the annotated data is limited.\nExperimental evaluation of the proposed model indicates that it can achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:20:56 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 17:52:46 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Voulodimos", "Athanasios", ""], ["Doulamis", "Anastasios", ""], ["Bakalos", "Nikolaos", ""], ["Doulamis", "Nikolaos", ""]]}, {"id": "2004.08154", "submitter": "Yong-Lu Li", "authors": "Yong-Lu Li, Xinpeng Liu, Han Lu, Shiyi Wang, Junqi Liu, Jiefeng Li,\n  Cewu Lu", "title": "Detailed 2D-3D Joint Representation for Human-Object Interaction", "comments": "Accepted to CVPR 2020, supplementary materials included, code\n  available:https://github.com/DirtyHarryLYL/DJ-RN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-Object Interaction (HOI) detection lies at the core of action\nunderstanding. Besides 2D information such as human/object appearance and\nlocations, 3D pose is also usually utilized in HOI learning since its\nview-independence. However, rough 3D body joints just carry sparse body\ninformation and are not sufficient to understand complex interactions. Thus, we\nneed detailed 3D body shape to go further. Meanwhile, the interacted object in\n3D is also not fully studied in HOI learning. In light of these, we propose a\ndetailed 2D-3D joint representation learning method. First, we utilize the\nsingle-view human body capture method to obtain detailed 3D body, face and hand\nshapes. Next, we estimate the 3D object location and size with reference to the\n2D human-object spatial configuration and object category priors. Finally, a\njoint learning framework and cross-modal consistency tasks are proposed to\nlearn the joint HOI representation. To better evaluate the 2D ambiguity\nprocessing capacity of models, we propose a new benchmark named Ambiguous-HOI\nconsisting of hard ambiguous images. Extensive experiments in large-scale HOI\nbenchmark and Ambiguous-HOI show impressive effectiveness of our method. Code\nand data are available at https://github.com/DirtyHarryLYL/DJ-RN.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 10:22:12 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 04:51:52 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Li", "Yong-Lu", ""], ["Liu", "Xinpeng", ""], ["Lu", "Han", ""], ["Wang", "Shiyi", ""], ["Liu", "Junqi", ""], ["Li", "Jiefeng", ""], ["Lu", "Cewu", ""]]}, {"id": "2004.08170", "submitter": "Javier Del Ser Dr.", "authors": "Javier Del Ser, Ibai Lana, Eric L. Manibardo, Izaskun Oregi, Eneko\n  Osaba, Jesus L. Lobo, Miren Nekane Bilbao, Eleni I. Vlahogianni", "title": "Deep Echo State Networks for Short-Term Traffic Forecasting: Performance\n  Comparison and Statistical Assessment", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In short-term traffic forecasting, the goal is to accurately predict future\nvalues of a traffic parameter of interest occurring shortly after the\nprediction is queried. The activity reported in this long-standing research\nfield has been lately dominated by different Deep Learning approaches, yielding\noverly complex forecasting models that in general achieve accuracy gains of\nquestionable practical utility. In this work we elaborate on the performance of\nDeep Echo State Networks for this particular task. The efficient learning\nalgorithm and simpler parametric configuration of these alternative modeling\napproaches make them emerge as a competitive traffic forecasting method for\nreal ITS applications deployed in devices and systems with stringently limited\ncomputational resources. An extensive comparison benchmark is designed with\nreal traffic data captured over the city of Madrid (Spain), amounting to more\nthan 130 automatic Traffic Readers (ATRs) and several shallow learning,\nensembles and Deep Learning models. Results from this comparison benchmark and\nthe analysis of the statistical significance of the reported performance gaps\nare decisive: Deep Echo State Networks achieve more accurate traffic forecasts\nthan the rest of considered modeling counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:07:25 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Del Ser", "Javier", ""], ["Lana", "Ibai", ""], ["Manibardo", "Eric L.", ""], ["Oregi", "Izaskun", ""], ["Osaba", "Eneko", ""], ["Lobo", "Jesus L.", ""], ["Bilbao", "Miren Nekane", ""], ["Vlahogianni", "Eleni I.", ""]]}, {"id": "2004.08172", "submitter": "Maciej Wo{\\l}czyk", "authors": "Bartosz W\\'ojcik, Maciej Wo{\\l}czyk, Klaudia Ba{\\l}azy, Jacek Tabor", "title": "Finding the Optimal Network Depth in Classification Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a fast end-to-end method for training lightweight neural networks\nusing multiple classifier heads. By allowing the model to determine the\nimportance of each head and rewarding the choice of a single shallow\nclassifier, we are able to detect and remove unneeded components of the\nnetwork. This operation, which can be seen as finding the optimal depth of the\nmodel, significantly reduces the number of parameters and accelerates inference\nacross different hardware processing units, which is not the case for many\nstandard pruning methods. We show the performance of our method on multiple\nnetwork architectures and datasets, analyze its optimization properties, and\nconduct ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:08:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["Wo\u0142czyk", "Maciej", ""], ["Ba\u0142azy", "Klaudia", ""], ["Tabor", "Jacek", ""]]}, {"id": "2004.08176", "submitter": "Maria Ines Silva", "authors": "Maria In\\^es Silva and Roberto Henriques", "title": "Exploring time-series motifs through DTW-SOM", "comments": "8 pages, 12 figures, Accepted for presentation at the International\n  Joint Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif discovery is a fundamental step in data mining tasks for time-series\ndata such as clustering, classification and anomaly detection. Even though many\npapers have addressed the problem of how to find motifs in time-series by\nproposing new motif discovery algorithms, not much work has been done on the\nexploration of the motifs extracted by these algorithms. In this paper, we\nargue that visually exploring time-series motifs computed by motif discovery\nalgorithms can be useful to understand and debug results. To explore the output\nof motif discovery algorithms, we propose the use of an adapted Self-Organizing\nMap, the DTW-SOM, on the list of motif's centers. In short, DTW-SOM is a\nvanilla Self-Organizing Map with three main differences, namely (1) the use the\nDynamic Time Warping distance instead of the Euclidean distance, (2) the\nadoption of two new network initialization routines (a random sample\ninitialization and an anchor initialization) and (3) the adjustment of the\nAdaptation phase of the training to work with variable-length time-series\nsequences. We test DTW-SOM in a synthetic motif dataset and two real\ntime-series datasets from the UCR Time Series Classification Archive. After an\nexploration of results, we conclude that DTW-SOM is capable of extracting\nrelevant information from a set of motifs and display it in a visualization\nthat is space-efficient.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:21:16 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Silva", "Maria In\u00eas", ""], ["Henriques", "Roberto", ""]]}, {"id": "2004.08178", "submitter": "Yekun Chai", "authors": "Yekun Chai, Shuo Jin, Xinwen Hou", "title": "Highway Transformer: Self-Gating Enhanced Self-Attentive Networks", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention mechanisms have made striking state-of-the-art (SOTA) progress\nin various sequence learning tasks, standing on the multi-headed dot product\nattention by attending to all the global contexts at different locations.\nThrough a pseudo information highway, we introduce a gated component\nself-dependency units (SDU) that incorporates LSTM-styled gating units to\nreplenish internal semantic importance within the multi-dimensional latent\nspace of individual representations. The subsidiary content-based SDU gates\nallow for the information flow of modulated latent embeddings through skipped\nconnections, leading to a clear margin of convergence speed with gradient\ndescent algorithms. We may unveil the role of gating mechanism to aid in the\ncontext-based Transformer modules, with hypothesizing that SDU gates,\nespecially on shallow layers, could push it faster to step towards suboptimal\npoints during the optimization process.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:25:07 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 08:57:04 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 08:43:45 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 15:09:28 GMT"}, {"version": "v5", "created": "Tue, 24 Nov 2020 16:19:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Chai", "Yekun", ""], ["Jin", "Shuo", ""], ["Hou", "Xinwen", ""]]}, {"id": "2004.08189", "submitter": "Juana Valeria Hurtado", "authors": "Juana Valeria Hurtado, Rohit Mohan, Wolfram Burgard, Abhinav Valada", "title": "MOPT: Multi-Object Panoptic Tracking", "comments": "Code & models are available at\n  http://rl.uni-freiburg.de/research/panoptictracking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive understanding of dynamic scenes is a critical prerequisite for\nintelligent robots to autonomously operate in their environment. Research in\nthis domain, which encompasses diverse perception problems, has primarily been\nfocused on addressing specific tasks individually rather than modeling the\nability to understand dynamic scenes holistically. In this paper, we introduce\na novel perception task denoted as multi-object panoptic tracking (MOPT), which\nunifies the conventionally disjoint tasks of semantic segmentation, instance\nsegmentation, and multi-object tracking. MOPT allows for exploiting pixel-level\nsemantic information of 'thing' and 'stuff' classes, temporal coherence, and\npixel-level associations over time, for the mutual benefit of each of the\nindividual sub-problems. To facilitate quantitative evaluations of MOPT in a\nunified manner, we propose the soft panoptic tracking quality (sPTQ) metric. As\na first step towards addressing this task, we propose the novel\nPanopticTrackNet architecture that builds upon the state-of-the-art top-down\npanoptic segmentation network EfficientPS by adding a new tracking head to\nsimultaneously learn all sub-tasks in an end-to-end manner. Additionally, we\npresent several strong baselines that combine predictions from state-of-the-art\npanoptic segmentation and multi-object tracking models for comparison. We\npresent extensive quantitative and qualitative evaluations of both vision-based\nand LiDAR-based MOPT that demonstrate encouraging results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 11:45:28 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 14:57:01 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Hurtado", "Juana Valeria", ""], ["Mohan", "Rohit", ""], ["Burgard", "Wolfram", ""], ["Valada", "Abhinav", ""]]}, {"id": "2004.08195", "submitter": "Pablo Barros", "authors": "Pablo Barros, Nikhil Churamani, Alessandra Sciutti", "title": "The FaceChannel: A Light-weight Deep Neural Network for Facial\n  Expression Recognition", "comments": "Accepted at the Workshop on Affect Recognition in-the-wild:\n  Uni/Multi-Modal Analysis & VA-AU-Expression Challenges, FG2020", "journal-ref": null, "doi": "10.1109/FG47880.2020.00070", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Current state-of-the-art models for automatic FER are based on very deep\nneural networks that are difficult to train. This makes it challenging to adapt\nthese models to changing conditions, a requirement from FER models given the\nsubjective nature of affect perception and understanding. In this paper, we\naddress this problem by formalizing the FaceChannel, a light-weight neural\nnetwork that has much fewer parameters than common deep neural networks. We\nperform a series of experiments on different benchmark datasets to demonstrate\nhow the FaceChannel achieves a comparable, if not better, performance, as\ncompared to the current state-of-the-art in FER.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 12:03:14 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Barros", "Pablo", ""], ["Churamani", "Nikhil", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2004.08207", "submitter": "Marco Paggi", "authors": "Marco Paggi", "title": "Simulation of Covid-19 epidemic evolution: are compartmental models\n  really predictive?", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models for the simulation of the severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2) epidemic evolution would be extremely\nuseful to support authorities in designing healthcare policies and lockdown\nmeasures to contain its impact on public health and economy. In Italy, the\ndevised forecasts have been mostly based on a pure data-driven approach, by\nfitting and extrapolating open data on the epidemic evolution collected by the\nItalian Civil Protection Center. In this respect, SIR epidemiological models,\nwhich start from the description of the nonlinear interactions between\npopulation compartments, would be a much more desirable approach to understand\nand predict the collective emergent response. The present contribution\naddresses the fundamental question whether a SIR epidemiological model,\nsuitably enriched with asymptomatic and dead individual compartments, could be\nable to provide reliable predictions on the epidemic evolution. To this aim, a\nmachine learning approach based on particle swarm optimization (PSO) is\nproposed to automatically identify the model parameters based on a training set\nof data of progressive increasing size, considering Lombardy in Italy as a case\nstudy. The analysis of the scatter in the forecasts shows that model\npredictions are quite sensitive to the size of the dataset used for training,\nand that further data are still required to achieve convergent -- and therefore\nreliable -- predictions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 08:42:11 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Paggi", "Marco", ""]]}, {"id": "2004.08212", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski and Josef Urban", "title": "Stateful Premise Selection by Recurrent Neural Networks", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a new learning-based method for selecting facts\n(premises) when proving new goals over large formal libraries. Unlike previous\nmethods that choose sets of facts independently of each other by their rank,\nthe new method uses the notion of \\emph{state} that is updated each time a\nchoice of a fact is made. Our stateful architecture is based on recurrent\nneural networks which have been recently very successful in stateful tasks such\nas language translation. The new method is combined with data augmentation\ntechniques, evaluated in several ways on a standard large-theory benchmark, and\ncompared to state-of-the-art premise approach based on gradient boosted trees.\nIt is shown to perform significantly better and to solve many new problems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 14:59:37 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "2004.08217", "submitter": "Lama Niyazi", "authors": "Lama B. Niyazi, Abla Kammoun, Hayssam Dahrouj, Mohamed-Slim Alouini,\n  and Tareq Y. Al-Naffouri", "title": "Asymptotic Analysis of an Ensemble of Randomly Projected Linear\n  Discriminants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets from the fields of bioinformatics, chemometrics, and face\nrecognition are typically characterized by small samples of high-dimensional\ndata. Among the many variants of linear discriminant analysis that have been\nproposed in order to rectify the issues associated with classification in such\na setting, the classifier in [1], composed of an ensemble of randomly projected\nlinear discriminants, seems especially promising; it is computationally\nefficient and, with the optimal projection dimension parameter setting, is\ncompetitive with the state-of-the-art. In this work, we seek to further\nunderstand the behavior of this classifier through asymptotic analysis. Under\nthe assumption of a growth regime in which the dataset and projection\ndimensions grow at constant rates to each other, we use random matrix theory to\nderive asymptotic misclassification probabilities showing the effect of the\nensemble as a regularization of the data sample covariance matrix. The\nasymptotic errors further help to identify situations in which the ensemble\noffers a performance advantage. We also develop a consistent estimator of the\nmisclassification probability as an alternative to the computationally-costly\ncross-validation estimator, which is conventionally used for parameter tuning.\nFinally, we demonstrate the use of our estimator for tuning the projection\ndimension on both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 12:47:04 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Niyazi", "Lama B.", ""], ["Kammoun", "Abla", ""], ["Dahrouj", "Hayssam", ""], ["Alouini", "Mohamed-Slim", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "2004.08227", "submitter": "Siddharth Tourani", "authors": "Siddharth Tourani, Alexander Shekhovtsov, Carsten Rother, Bogdan\n  Savchynskyy", "title": "MPLP++: Fast, Parallel Dual Block-Coordinate Ascent for Dense Graphical\n  Models", "comments": "Accepted in ECCV-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense, discrete Graphical Models with pairwise potentials are a powerful\nclass of models which are employed in state-of-the-art computer vision and\nbio-imaging applications. This work introduces a new MAP-solver, based on the\npopular Dual Block-Coordinate Ascent principle. Surprisingly, by making a small\nchange to the low-performing solver, the Max Product Linear Programming (MPLP)\nalgorithm, we derive the new solver MPLP++ that significantly outperforms all\nexisting solvers by a large margin, including the state-of-the-art solver\nTree-Reweighted Sequential (TRWS) message-passing algorithm. Additionally, our\nsolver is highly parallel, in contrast to TRWS, which gives a further boost in\nperformance with the proposed GPU and multi-thread CPU implementations. We\nverify the superiority of our algorithm on dense problems from publicly\navailable benchmarks, as well, as a new benchmark for 6D Object Pose\nestimation. We also provide an ablation study with respect to graph density.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 16:20:53 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tourani", "Siddharth", ""], ["Shekhovtsov", "Alexander", ""], ["Rother", "Carsten", ""], ["Savchynskyy", "Bogdan", ""]]}, {"id": "2004.08237", "submitter": "Yanghao Lin", "authors": "Xu Cao, Yanghao Lin", "title": "CAggNet: Crossing Aggregation Network for Medical Image Segmentation", "comments": "Accepted by ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Crossing Aggregation Network (CAggNet), a novel\ndensely connected semantic segmentation approach for medical image analysis.\nThe crossing aggregation network improves the idea from deep layer aggregation\nand makes significant innovations in semantic and spatial information fusion.\nIn CAggNet, the simple skip connection structure of general U-Net is replaced\nby aggregations of multi-level down-sampling and up-sampling layers, which is a\nnew form of nested skip connection. This aggregation architecture enables the\nnetwork to fuse both coarse and fine features interactively in semantic\nsegmentation. It also introduces weighted aggregation module to up-sample\nmulti-scale output at the end of the network. We have evaluated and compared\nour CAggNet with several advanced U-Net based methods in two public medical\nimage datasets, including the 2018 Data Science Bowl nuclei detection dataset\nand the 2015 MICCAI gland segmentation competition dataset. Experimental\nresults indicate that CAggNet improves medical object recognition and achieves\na more accurate and efficient segmentation compared to existing improved U-Net\nand UNet++ structure.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:39:38 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 13:28:12 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Cao", "Xu", ""], ["Lin", "Yanghao", ""]]}, {"id": "2004.08243", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, Mayank Meghwanshi, Bamdev Mishra", "title": "Geometry-aware Domain Adaptation for Unsupervised Alignment of Word\n  Embeddings", "comments": "Accepted as a short paper in ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel manifold based geometric approach for learning\nunsupervised alignment of word embeddings between the source and the target\nlanguages. Our approach formulates the alignment learning problem as a domain\nadaptation problem over the manifold of doubly stochastic matrices. This\nviewpoint arises from the aim to align the second order information of the two\nlanguage spaces. The rich geometry of the doubly stochastic manifold allows to\nemploy efficient Riemannian conjugate gradient algorithm for the proposed\nformulation. Empirically, the proposed approach outperforms state-of-the-art\noptimal transport based approach on the bilingual lexicon induction task across\nseveral language pairs. The performance improvement is more significant for\ndistant language pairs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 04:41:06 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 14:48:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Meghwanshi", "Mayank", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.08246", "submitter": "Domenico Gatti", "authors": "Hassan Abdallah, Asiri Liyanaarachchi, Maranda Saigh, Samantha\n  Silvers, Suzan Arslanturk, Douglas J. Taatjes, Lars Larsson, Bhanu P. Jena,\n  Domenico L. Gatti", "title": "Res-CR-Net, a residual network with a novel architecture optimized for\n  the semantic segmentation of microscopy images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have been widely used to carry out segmentation\ntasks in both electron and light microscopy. Most DNNs developed for this\npurpose are based on some variation of the encoder-decoder type U-Net\narchitecture, in combination with residual blocks to increase ease of training\nand resilience to gradient degradation. Here we introduce Res-CR-Net, a type of\nDNN that features residual blocks with either a bundle of separable atrous\nconvolutions with different dilation rates or a convolutional LSTM. The number\nof filters used in each residual block and the number of blocks are the only\nhyperparameters that need to be modified in order to optimize the network\ntraining for a variety of different microscopy images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:21:01 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Abdallah", "Hassan", ""], ["Liyanaarachchi", "Asiri", ""], ["Saigh", "Maranda", ""], ["Silvers", "Samantha", ""], ["Arslanturk", "Suzan", ""], ["Taatjes", "Douglas J.", ""], ["Larsson", "Lars", ""], ["Jena", "Bhanu P.", ""], ["Gatti", "Domenico L.", ""]]}, {"id": "2004.08247", "submitter": "Mathew Cherukara", "authors": "Mathew J. Cherukara, Tao Zhou, Youssef Nashed, Pablo Enfedaque, Alex\n  Hexemer, Ross J. Harder and Martin V. Holt", "title": "Real-time sparse-sampled Ptychographic imaging through deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cond-mat.mes-hall cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ptychography has rapidly grown in the fields of X-ray and electron imaging\nfor its unprecedented ability to achieve nano or atomic scale resolution while\nsimultaneously retrieving chemical or magnetic information from a sample. A\nptychographic reconstruction is achieved by means of solving a complex inverse\nproblem that imposes constraints both on the acquisition and on the analysis of\nthe data, which typically precludes real-time imaging due to computational cost\ninvolved in solving this inverse problem. In this work we propose PtychoNN, a\nnovel approach to solve the ptychography reconstruction problem based on deep\nconvolutional neural networks. We demonstrate how the proposed method can be\nused to predict real-space structure and phase at each scan point solely from\nthe corresponding far-field diffraction data. The presented results demonstrate\nhow PtychoNN can effectively be used on experimental data, being able to\ngenerate high quality reconstructions of a sample up to hundreds of times\nfaster than state-of-the-art ptychography reconstruction solutions once\ntrained. By surpassing the typical constraints of iterative model-based\nmethods, we can significantly relax the data acquisition sampling conditions\nand produce equally satisfactory reconstructions. Besides drastically\naccelerating acquisition and analysis, this capability can enable new imaging\nscenarios that were not possible before, in cases of dose sensitive, dynamic\nand extremely voluminous samples.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 23:43:17 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Cherukara", "Mathew J.", ""], ["Zhou", "Tao", ""], ["Nashed", "Youssef", ""], ["Enfedaque", "Pablo", ""], ["Hexemer", "Alex", ""], ["Harder", "Ross J.", ""], ["Holt", "Martin V.", ""]]}, {"id": "2004.08249", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, Jiawei Han", "title": "Understanding the Difficulty of Training Transformers", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers have proved effective in many NLP tasks. However, their training\nrequires non-trivial efforts regarding designing cutting-edge optimizers and\nlearning rate schedulers carefully (e.g., conventional SGD fails to train\nTransformers effectively). Our objective here is to understand $\\textit{what\ncomplicates Transformer training}$ from both empirical and theoretical\nperspectives. Our analysis reveals that unbalanced gradients are not the root\ncause of the instability of training. Instead, we identify an amplification\neffect that influences training substantially -- for each layer in a\nmulti-layer Transformer model, heavy dependency on its residual branch makes\ntraining unstable, since it amplifies small parameter perturbations (e.g.,\nparameter updates) and results in significant disturbances in the model output.\nYet we observe that a light dependency limits the model potential and leads to\ninferior trained models. Inspired by our analysis, we propose Admin\n($\\textbf{Ad}$aptive $\\textbf{m}$odel $\\textbf{in}$itialization) to stabilize\nstabilize the early stage's training and unleash its full potential in the late\nstage. Extensive experiments show that Admin is more stable, converges faster,\nand leads to better performance. Implementations are released at:\nhttps://github.com/LiyuanLucasLiu/Transforemr-Clinic.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 13:59:07 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 05:05:56 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Liu", "Liyuan", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Chen", "Weizhu", ""], ["Han", "Jiawei", ""]]}, {"id": "2004.08250", "submitter": "George Sterpu", "authors": "George Sterpu, Christian Saam, Naomi Harte", "title": "How to Teach DNNs to Pay Attention to the Visual Modality in Speech\n  Recognition", "comments": "in IEEE/ACM Transactions on Audio, Speech, and Language Processing\n  (to appear)", "journal-ref": null, "doi": "10.1109/TASLP.2020.2980436", "report-no": null, "categories": "eess.AS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-Visual Speech Recognition (AVSR) seeks to model, and thereby exploit,\nthe dynamic relationship between a human voice and the corresponding mouth\nmovements. A recently proposed multimodal fusion strategy, AV Align, based on\nstate-of-the-art sequence to sequence neural networks, attempts to model this\nrelationship by explicitly aligning the acoustic and visual representations of\nspeech. This study investigates the inner workings of AV Align and visualises\nthe audio-visual alignment patterns. Our experiments are performed on two of\nthe largest publicly available AVSR datasets, TCD-TIMIT and LRS2. We find that\nAV Align learns to align acoustic and visual representations of speech at the\nframe level on TCD-TIMIT in a generally monotonic pattern. We also determine\nthe cause of initially seeing no improvement over audio-only speech recognition\non the more challenging LRS2. We propose a regularisation method which involves\npredicting lip-related Action Units from visual representations. Our\nregularisation method leads to better exploitation of the visual modality, with\nperformance improvements between 7% and 30% depending on the noise level.\nFurthermore, we show that the alternative Watch, Listen, Attend, and Spell\nnetwork is affected by the same problem as AV Align, and that our proposed\napproach can effectively help it learn visual representations. Our findings\nvalidate the suitability of the regularisation method to AVSR and encourage\nresearchers to rethink the multimodal convergence problem when having one\ndominant modality.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 13:59:19 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Sterpu", "George", ""], ["Saam", "Christian", ""], ["Harte", "Naomi", ""]]}, {"id": "2004.08260", "submitter": "Alberto Natali", "authors": "Alberto Natali, Elvin Isufi, Geert Leus", "title": "Forecasting Multi-Dimensional Processes over Graphs", "comments": "ICASSP 2020, Barcelona", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forecasting of multi-variate time processes through graph-based\ntechniques has recently been addressed under the graph signal processing\nframework. However, problems in the representation and the processing arise\nwhen each time series carries a vector of quantities rather than a scalar one.\nTo tackle this issue, we devise a new framework and propose new methodologies\nbased on the graph vector autoregressive model. More explicitly, we leverage\nproduct graphs to model the high-dimensional graph data and develop\nmulti-dimensional graph-based vector autoregressive models to forecast future\ntrends with a number of parameters that is independent of the number of time\nseries and a linear computational complexity. Numerical results demonstrating\nthe prediction of moving point clouds corroborate our findings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:14:50 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Natali", "Alberto", ""], ["Isufi", "Elvin", ""], ["Leus", "Geert", ""]]}, {"id": "2004.08285", "submitter": "Shaocheng Huang", "authors": "Shaocheng Huang, Yu Ye, Ming Xiao", "title": "Learning Based Hybrid Beamforming Design for Full-Duplex Millimeter Wave\n  Systems", "comments": "13 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millimeter Wave (mmWave) communications with full-duplex (FD) have the\npotential of increasing the spectral efficiency, relative to those with\nhalf-duplex. However, the residual self-interference (SI) from FD and high\npathloss inherent to mmWave signals may degrade the system performance.\nMeanwhile, hybrid beamforming (HBF) is an efficient technology to enhance the\nchannel gain and mitigate interference with reasonable complexity. However,\nconventional HBF approaches for FD mmWave systems are based on optimization\nprocesses, which are either too complex or strongly rely on the quality of\nchannel state information (CSI). We propose two learning schemes to design HBF\nfor FD mmWave systems, i.e., extreme learning machine based HBF (ELM-HBF) and\nconvolutional neural networks based HBF (CNN-HBF). Specifically, we first\npropose an alternating direction method of multipliers (ADMM) based algorithm\nto achieve SI cancellation beamforming, and then use a\nmajorization-minimization (MM) based algorithm for joint transmitting and\nreceiving HBF optimization. To train the learning networks, we simulate noisy\nchannels as input, and select the hybrid beamformers calculated by proposed\nalgorithms as targets. Results show that both learning based schemes can\nprovide more robust HBF performance and achieve at least 22.1% higher spectral\nefficiency compared to orthogonal matching pursuit (OMP) algorithms. Besides,\nthe online prediction time of proposed learning based schemes is almost 20\ntimes faster than the OMP scheme. Furthermore, the training time of ELM-HBF is\nabout 600 times faster than that of CNN-HBF with 64 transmitting and receiving\nantennas.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:48:57 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Huang", "Shaocheng", ""], ["Ye", "Yu", ""], ["Xiao", "Ming", ""]]}, {"id": "2004.08286", "submitter": "Bilal Farooq", "authors": "Lama Alfaseeh, Ran Tu, Bilal Farooq, and Marianne Hatzopoulou", "title": "Greenhouse Gas Emission Prediction on Road Network using Deep Sequence\n  Learning", "comments": null, "journal-ref": null, "doi": "10.1016/j.trd.2020.102593", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mitigating the substantial undesirable impact of transportation systems on\nthe environment is paramount. Thus, predicting Greenhouse Gas (GHG) emissions\nis one of the profound topics, especially with the emergence of intelligent\ntransportation systems (ITS). We develop a deep learning framework to predict\nlink-level GHG emission rate (ER) (in CO2eq gram/second) based on the most\nrepresentative predictors, such as speed, density, and the GHG ER of previous\ntime steps. In particular, various specifications of the long-short term memory\n(LSTM) networks with exogenous variables are examined and compared with\nclustering and the autoregressive integrated moving average (ARIMA) model with\nexogenous variables. The downtown Toronto road network is used as the case\nstudy and highly detailed data are synthesized using a calibrated traffic\nmicrosimulation and MOVES. It is found that LSTM specification with speed,\ndensity, GHG ER, and in-links speed from three previous minutes performs the\nbest while adopting 2 hidden layers and when the hyper-parameters are\nsystematically tuned. Adopting a 30 second updating interval improves slightly\nthe correlation between true and predicted GHG ERs, but contributes negatively\nto the prediction accuracy as reflected on the increased root mean square error\n(RMSE) value. Efficiently predicting GHG emissions at a higher frequency with\nlower data requirements will pave the way to non-myopic eco-routing on\nlarge-scale road networks {to alleviate the adverse impact on the global\nwarming\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 14:25:32 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 16:39:52 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Alfaseeh", "Lama", ""], ["Tu", "Ran", ""], ["Farooq", "Bilal", ""], ["Hatzopoulou", "Marianne", ""]]}, {"id": "2004.08287", "submitter": "Jyotibdha Acharya", "authors": "Jyotibdha Acharya, Arindam Basu", "title": "Deep Neural Network for Respiratory Sound Classification in Wearable\n  Devices Enabled by Patient Specific Model Tuning", "comments": null, "journal-ref": null, "doi": "10.1109/TBCAS.2020.2981172", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The primary objective of this paper is to build classification models and\nstrategies to identify breathing sound anomalies (wheeze, crackle) for\nautomated diagnosis of respiratory and pulmonary diseases. In this work we\npropose a deep CNN-RNN model that classifies respiratory sounds based on\nMel-spectrograms. We also implement a patient specific model tuning strategy\nthat first screens respiratory patients and then builds patient specific\nclassification models using limited patient data for reliable anomaly\ndetection. Moreover, we devise a local log quantization strategy for model\nweights to reduce the memory footprint for deployment in memory constrained\nsystems such as wearable devices. The proposed hybrid CNN-RNN model achieves a\nscore of 66.31% on four-class classification of breathing cycles for ICBHI'17\nscientific challenge respiratory sound database. When the model is re-trained\nwith patient specific data, it produces a score of 71.81% for leave-one-out\nvalidation. The proposed weight quantization technique achieves ~4X reduction\nin total memory cost without loss of performance. The main contribution of the\npaper is as follows: Firstly, the proposed model is able to achieve state of\nthe art score on the ICBHI'17 dataset. Secondly, deep learning models are shown\nto successfully learn domain specific knowledge when pre-trained with breathing\ndata and produce significantly superior performance compared to generalized\nmodels. Finally, local log quantization of trained weights is shown to be able\nto reduce the memory requirement significantly. This type of patient-specific\nre-training strategy can be very useful in developing reliable long-term\nautomated patient monitoring systems particularly in wearable healthcare\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 15:42:58 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Acharya", "Jyotibdha", ""], ["Basu", "Arindam", ""]]}, {"id": "2004.08289", "submitter": "Ozan Ozdenizci", "authors": "Mo Han, Ozan Ozdenizci, Ye Wang, Toshiaki Koike-Akino, Deniz Erdogmus", "title": "Disentangled Adversarial Transfer Learning for Physiological Biosignals", "comments": "42nd Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in wearable sensors demonstrate promising results for\nmonitoring physiological status in effective and comfortable ways. One major\nchallenge of physiological status assessment is the problem of transfer\nlearning caused by the domain inconsistency of biosignals across users or\ndifferent recording sessions from the same user. We propose an adversarial\ninference approach for transfer learning to extract disentangled\nnuisance-robust representations from physiological biosignal data in stress\nstatus level assessment. We exploit the trade-off between task-related features\nand person-discriminative information by using both an adversary network and a\nnuisance network to jointly manipulate and disentangle the learned latent\nrepresentations by the encoder, which are then input to a discriminative\nclassifier. Results on cross-subjects transfer evaluations demonstrate the\nbenefits of the proposed adversarial framework, and thus show its capabilities\nto adapt to a broader range of subjects. Finally we highlight that our proposed\nadversarial transfer learning approach is also applicable to other deep feature\nlearning frameworks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 01:56:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Han", "Mo", ""], ["Ozdenizci", "Ozan", ""], ["Wang", "Ye", ""], ["Koike-Akino", "Toshiaki", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2004.08290", "submitter": "Anastasia Bugaenko", "authors": "Anastasia Bugaenko", "title": "Empirical Study of Market Impact Conditional on Order-Flow Imbalance", "comments": "This copy of the research does not include the source code. Please\n  contact the author for reference to the source code", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we have empirically investigated the key drivers affecting\nliquidity in equity markets. We illustrated how theoretical models, such as\nKyle's model, of agents' interplay in the financial markets, are aligned with\nthe phenomena observed in publicly available trades and quotes data.\nSpecifically, we confirmed that for small signed order-flows, the price impact\ngrows linearly with increase in the order-flow imbalance. We have, further,\nimplemented a machine learning algorithm to forecast market impact given a\nsigned order-flow. Our findings suggest that machine learning models can be\nused in estimation of financial variables; and predictive accuracy of such\nlearning algorithms can surpass the performance of traditional statistical\napproaches.\n  Understanding the determinants of price impact is crucial for several\nreasons. From a theoretical stance, modelling the impact provides a statistical\nmeasure of liquidity. Practitioners adopt impact models as a pre-trade tool to\nestimate expected transaction costs and optimize the execution of their\nstrategies. This further serves as a post-trade valuation benchmark as\nsuboptimal execution can significantly deteriorate a portfolio performance.\n  More broadly, the price impact reflects the balance of liquidity across\nmarkets. This is of central importance to regulators as it provides an\nall-encompassing explanation of the correlation between market design and\nsystemic risk, enabling regulators to design more stable and efficient markets.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:58:29 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 20:23:39 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bugaenko", "Anastasia", ""]]}, {"id": "2004.08297", "submitter": "Aakash Kaku", "authors": "Aakash Kaku, Avinash Parnandi, Anita Venkatesan, Natasha Pandit, Heidi\n  Schambra and Carlos Fernandez-Granda", "title": "Towards data-driven stroke rehabilitation via wearable sensors and deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovery after stroke is often incomplete, but rehabilitation training may\npotentiate recovery by engaging endogenous neuroplasticity. In preclinical\nmodels of stroke, high doses of rehabilitation training are required to restore\nfunctional movement to the affected limbs of animals. In humans, however, the\nnecessary dose of training to potentiate recovery is not known. This ignorance\nstems from the lack of objective, pragmatic approaches for measuring training\ndoses in rehabilitation activities. Here, to develop a measurement approach, we\ntook the critical first step of automatically identifying functional\nprimitives, the basic building block of activities. Forty-eight individuals\nwith chronic stroke performed a variety of rehabilitation activities while\nwearing inertial measurement units (IMUs) to capture upper body motion.\nPrimitives were identified by human labelers, who labeled and segmented the\nassociated IMU data. We performed automatic classification of these primitives\nusing machine learning. We designed a convolutional neural network model that\noutperformed existing methods. The model includes an initial module to compute\nseparate embeddings of different physical quantities in the sensor data. In\naddition, it replaces batch normalization (which performs normalization based\non statistics computed from the training data) with instance normalization\n(which uses statistics computed from the test data). This increases robustness\nto possible distributional shifts when applying the method to new patients.\nWith this approach, we attained an average classification accuracy of 70%.\nThus, using a combination of IMU-based motion capture and deep learning, we\nwere able to identify primitives automatically. This approach builds towards\nobjectively-measured rehabilitation training, enabling the identification and\ncounting of functional primitives that accrues to a training dose.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 18:05:44 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 15:51:24 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 22:24:10 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kaku", "Aakash", ""], ["Parnandi", "Avinash", ""], ["Venkatesan", "Anita", ""], ["Pandit", "Natasha", ""], ["Schambra", "Heidi", ""], ["Fernandez-Granda", "Carlos", ""]]}, {"id": "2004.08299", "submitter": "Hwanhee Lee", "authors": "Hwanhee Lee, Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung\n  Bui and Kyomin Jung", "title": "DSTC8-AVSD: Multimodal Semantic Transformer Network with Retrieval Style\n  Word Generator", "comments": "Presented at DSTC Workshop @ AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio Visual Scene-aware Dialog (AVSD) is the task of generating a response\nfor a question with a given scene, video, audio, and the history of previous\nturns in the dialog. Existing systems for this task employ the transformers or\nrecurrent neural network-based architecture with the encoder-decoder framework.\nEven though these techniques show superior performance for this task, they have\nsignificant limitations: the model easily overfits only to memorize the\ngrammatical patterns; the model follows the prior distribution of the\nvocabularies in a dataset. To alleviate the problems, we propose a Multimodal\nSemantic Transformer Network. It employs a transformer-based architecture with\nan attention-based word embedding layer that generates words by querying word\nembeddings. With this design, our model keeps considering the meaning of the\nwords at the generation stage. The empirical results demonstrate the\nsuperiority of our proposed model that outperforms most of the previous works\nfor the AVSD task.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 07:10:08 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Lee", "Hwanhee", ""], ["Yoon", "Seunghyun", ""], ["Dernoncourt", "Franck", ""], ["Kim", "Doo Soon", ""], ["Bui", "Trung", ""], ["Jung", "Kyomin", ""]]}, {"id": "2004.08301", "submitter": "Koujin Takeda", "authors": "Hiroki Kitano, Koujin Takeda", "title": "Belief Propagation for Maximum Coverage on Weighted Bipartite Graph and\n  Application to Text Summarization", "comments": "4 pages, 4 figures", "journal-ref": "J. Phys. Soc. Jpn. 89, 043801 (2020)", "doi": "10.7566/JPSJ.89.043801", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study text summarization from the viewpoint of maximum coverage problem.\nIn graph theory, the task of text summarization is regarded as maximum coverage\nproblem on bipartite graph with weighted nodes. In recent study,\nbelief-propagation based algorithm for maximum coverage on unweighted graph was\nproposed using the idea of statistical mechanics. We generalize it to weighted\ngraph for text summarization. Then we apply our algorithm to weighted biregular\nrandom graph for verification of maximum coverage performance. We also apply it\nto bipartite graph representing real document in open text dataset, and check\nthe performance of text summarization. As a result, our algorithm exhibits\nbetter performance than greedy-type algorithm in some setting of text\nsummarization.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 05:50:20 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Kitano", "Hiroki", ""], ["Takeda", "Koujin", ""]]}, {"id": "2004.08333", "submitter": "Alireza Borjali", "authors": "Alireza Borjali, Martin Magneli, David Shin, Henrik Malchau, Orhun K.\n  Muratoglu, Kartik M. Varadarajan", "title": "Natural Language Processing with Deep Learning for Medical Adverse Event\n  Detection from Free-Text Medical Narratives: A Case Study of Detecting Total\n  Hip Replacement Dislocation", "comments": null, "journal-ref": null, "doi": "10.1016/j.compbiomed.2020.104140", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and timely detection of medical adverse events (AEs) from free-text\nmedical narratives is challenging. Natural language processing (NLP) with deep\nlearning has already shown great potential for analyzing free-text data, but\nits application for medical AE detection has been limited. In this study we\nproposed deep learning based NLP (DL-NLP) models for efficient and accurate hip\ndislocation AE detection following total hip replacement from standard\n(radiology notes) and non-standard (follow-up telephone notes) free-text\nmedical narratives. We benchmarked these proposed models with a wide variety of\ntraditional machine learning based NLP (ML-NLP) models, and also assessed the\naccuracy of International Classification of Diseases (ICD) and Current\nProcedural Terminology (CPT) codes in capturing these hip dislocation AEs in a\nmulti-center orthopaedic registry. All DL-NLP models out-performed all of the\nML-NLP models, with a convolutional neural network (CNN) model achieving the\nbest overall performance (Kappa = 0.97 for radiology notes, and Kappa = 1.00\nfor follow-up telephone notes). On the other hand, the ICD/CPT codes of the\npatients who sustained a hip dislocation AE were only 75.24% accurate, showing\nthe potential of the proposed model to be used in largescale orthopaedic\nregistries for accurate and efficient hip dislocation AE detection to improve\nthe quality of care and patient outcome.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 16:25:36 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 18:54:36 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Borjali", "Alireza", ""], ["Magneli", "Martin", ""], ["Shin", "David", ""], ["Malchau", "Henrik", ""], ["Muratoglu", "Orhun K.", ""], ["Varadarajan", "Kartik M.", ""]]}, {"id": "2004.08336", "submitter": "J\\\"uri Lember", "authors": "Alexey Koloydenko, Kristi Kuljus, J\\\"uri Lember", "title": "MAP segmentation in Bayesian hidden Markov models: a case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the maximum posterior probability (MAP)\nstate sequence for a finite state and finite emission alphabet hidden Markov\nmodel (HMM) in the Bayesian setup, where both emission and transition matrices\nhave Dirichlet priors. We study a training set consisting of thousands of\nprotein alignment pairs. The training data is used to set the prior\nhyperparameters for Bayesian MAP segmentation. Since the Viterbi algorithm is\nnot applicable any more, there is no simple procedure to find the MAP path, and\nseveral iterative algorithms are considered and compared. The main goal of the\npaper is to test the Bayesian setup against the frequentist one, where the\nparameters of HMM are estimated using the training data.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 16:42:18 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Koloydenko", "Alexey", ""], ["Kuljus", "Kristi", ""], ["Lember", "J\u00fcri", ""]]}, {"id": "2004.08340", "submitter": "Vahid Moosavi", "authors": "Zifeng Guo, Joao P. Leitao, Nuno E. Simoes, and Vahid Moosavi", "title": "Data-driven Flood Emulation: Speeding up Urban Flood Predictions by Deep\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational complexity has been the bottleneck of applying physically-based\nsimulations on large urban areas with high spatial resolution for efficient and\nsystematic flooding analyses and risk assessments. To address this issue of\nlong computational time, this paper proposes that the prediction of maximum\nwater depth rasters can be considered as an image-to-image translation problem\nwhere the results are generated from input elevation rasters using the\ninformation learned from data rather than by conducting simulations, which can\nsignificantly accelerate the prediction process. The proposed approach was\nimplemented by a deep convolutional neural network trained on flood simulation\ndata of 18 designed hyetographs on three selected catchments. Multiple tests\nwith both designed and real rainfall events were performed and the results show\nthat the flood predictions by neural network uses only 0.5 % of time comparing\nwith physically-based approaches, with promising accuracy and ability of\ngeneralizations. The proposed neural network can also potentially be applied to\ndifferent but relevant problems including flood predictions for urban layout\nplanning.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 16:44:46 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 10:19:29 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Guo", "Zifeng", ""], ["Leitao", "Joao P.", ""], ["Simoes", "Nuno E.", ""], ["Moosavi", "Vahid", ""]]}, {"id": "2004.08349", "submitter": "George De Ath", "authors": "George De Ath and Jonathan E. Fieldsend and Richard M. Everson", "title": "What do you Mean? The Role of the Mean Function in Bayesian Optimisation", "comments": "Genetic and Evolutionary Computation Conference Companion 2020 (GECCO\n  '20 Companion). 9 pages (main paper) + 4 pages (supplementary material). Code\n  avaliable at http://github.com/georgedeath/bomean", "journal-ref": null, "doi": "10.1145/3377929.3398118", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation is a popular approach for optimising expensive\nblack-box functions. The next location to be evaluated is selected via\nmaximising an acquisition function that balances exploitation and exploration.\nGaussian processes, the surrogate models of choice in Bayesian optimisation,\nare often used with a constant prior mean function equal to the arithmetic mean\nof the observed function values. We show that the rate of convergence can\ndepend sensitively on the choice of mean function. We empirically investigate 8\nmean functions (constant functions equal to the arithmetic mean, minimum,\nmedian and maximum of the observed function evaluations, linear, quadratic\npolynomials, random forests and RBF networks), using 10 synthetic test problems\nand two real-world problems, and using the Expected Improvement and Upper\nConfidence Bound acquisition functions. We find that for design dimensions\n$\\ge5$ using a constant mean function equal to the worst observed quality value\nis consistently the best choice on the synthetic problems considered. We argue\nthat this worst-observed-quality function promotes exploitation leading to more\nrapid convergence. However, for the real-world tasks the more complex mean\nfunctions capable of modelling the fitness landscape may be effective, although\nthere is no clearly optimum choice.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:10:17 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 11:54:38 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["De Ath", "George", ""], ["Fieldsend", "Jonathan E.", ""], ["Everson", "Richard M.", ""]]}, {"id": "2004.08352", "submitter": "Vineet Mehta", "authors": "Vineet Mehta, Abhinav Dhall, Sujata Pal, Shehroz S. Khan", "title": "Motion and Region Aware Adversarial Learning for Fall Detection with\n  Thermal Imaging", "comments": "8 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic fall detection is a vital technology for ensuring the health and\nsafety of people. Home-based camera systems for fall detection often put\npeople's privacy at risk. Thermal cameras can partially or fully obfuscate\nfacial features, thus preserving the privacy of a person. Another challenge is\nthe less occurrence of falls in comparison to the normal activities of daily\nliving. As fall occurs rarely, it is non-trivial to learn algorithms due to\nclass imbalance. To handle these problems, we formulate fall detection as an\nanomaly detection within an adversarial framework using thermal imaging. We\npresent a novel adversarial network that comprises of two-channel 3D\nconvolutional autoencoders which reconstructs the thermal data and the optical\nflow input sequences respectively. We introduce a technique to track the region\nof interest, a region-based difference constraint, and a joint discriminator to\ncompute the reconstruction error. A larger reconstruction error indicates the\noccurrence of a fall. The experiments on a publicly available thermal fall\ndataset show the superior results obtained compared to the standard baseline.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:17:29 GMT"}, {"version": "v2", "created": "Sat, 24 Oct 2020 22:06:49 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Mehta", "Vineet", ""], ["Dhall", "Abhinav", ""], ["Pal", "Sujata", ""], ["Khan", "Shehroz S.", ""]]}, {"id": "2004.08356", "submitter": "Aditi Mavalankar", "authors": "Aditi Mavalankar", "title": "Goal-conditioned Batch Reinforcement Learning for Rotation Invariant\n  Locomotion", "comments": "Accepted to the BeTR-RL workshop at ICLR 2020. Link to code:\n  https://github.com/aditimavalankar/gc-batch-rl-locomotion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to learn goal-conditioned policies for locomotion\nin a batch RL setting. The batch data is collected by a policy that is not\ngoal-conditioned. For the locomotion task, this translates to data collection\nusing a policy learnt by the agent for walking straight in one direction, and\nusing that data to learn a goal-conditioned policy that enables the agent to\nwalk in any direction. The data collection policy used should be invariant to\nthe direction the agent is facing i.e. regardless of its initial orientation,\nthe agent should take the same actions to walk forward. We exploit this\nproperty to learn a goal-conditioned policy using two key ideas: (1) augmenting\ndata by generating trajectories with the same actions in different directions,\nand (2) learning an encoder that enforces invariance between these rotated\ntrajectories with a Siamese framework. We show that our approach outperforms\nexisting RL algorithms on 3-D locomotion agents like Ant, Humanoid and\nMinitaur.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:25:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mavalankar", "Aditi", ""]]}, {"id": "2004.08366", "submitter": "Yun Zeng", "authors": "Yun Zeng, Siqi Zuo, Dongcai Shen", "title": "DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the limitations of deep learning models with sparse features today\nstems from the predefined nature of their input, which requires a dictionary be\ndefined prior to the training. With this paper we propose both a theory and a\nworking system design which remove this limitation, and show that the resulting\nmodels are able to perform better and efficiently run at a much larger scale.\nSpecifically, we achieve this by decoupling a model's content from its form to\ntackle architecture evolution and memory growth separately. To efficiently\nhandle model growth, we propose a new neuron model, called DynamicCell, drawing\ninspiration from from the free energy principle [15] to introduce the concept\nof reaction to discharge non-digestive energy, which also subsumes gradient\ndescent based approaches as its special cases. We implement DynamicCell by\nintroducing a new server into TensorFlow to take over most of the work\ninvolving model growth. Consequently, it enables any existing deep learning\nmodels to efficiently handle arbitrary number of distinct sparse features\n(e.g., search queries), and grow incessantly without redefining the model. Most\nnotably, one of our models, which has been reliably running in production for\nover a year, is capable of suggesting high quality keywords for advertisers of\nGoogle Smart Campaigns and achieved significant accuracy gains based on a\nchallenging metric -- evidence that data-driven, self-evolving systems can\npotentially exceed the performance of traditional rule-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:43:51 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Zeng", "Yun", ""], ["Zuo", "Siqi", ""], ["Shen", "Dongcai", ""]]}, {"id": "2004.08371", "submitter": "Esteban Marquer", "authors": "Lea Dieudonat, Kelvin Han, Phyllicia Leavitt, Esteban Marquer", "title": "Exploring the Combination of Contextual Word Embeddings and Knowledge\n  Graph Embeddings", "comments": "pre-publication, 16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ``Classical'' word embeddings, such as Word2Vec, have been shown to capture\nthe semantics of words based on their distributional properties. However, their\nability to represent the different meanings that a word may have is limited.\nSuch approaches also do not explicitly encode relations between entities, as\ndenoted by words. Embeddings of knowledge bases (KB) capture the explicit\nrelations between entities denoted by words, but are not able to directly\ncapture the syntagmatic properties of these words. To our knowledge, recent\nresearch have focused on representation learning that augment the strengths of\none with the other. In this work, we begin exploring another approach using\ncontextual and KB embeddings jointly at the same level and propose two tasks --\nan entity typing and a relation typing task -- that evaluate the performance of\ncontextual and KB embeddings. We also evaluated a concatenated model of\ncontextual and KB embeddings with these two tasks, and obtain conclusive\nresults on the first task. We hope our work may contribute as a basis for\nmodels and datasets that develop in the direction of this approach.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:49:45 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Dieudonat", "Lea", ""], ["Han", "Kelvin", ""], ["Leavitt", "Phyllicia", ""], ["Marquer", "Esteban", ""]]}, {"id": "2004.08379", "submitter": "Sivaramakrishnan Rajaraman", "authors": "Sivaramakrishnan Rajaraman, Jen Siegelman, Philip O. Alderson, Lucas\n  S. Folio, Les R. Folio and Sameer K. Antani", "title": "Iteratively Pruned Deep Learning Ensembles for COVID-19 Detection in\n  Chest X-rays", "comments": "11 pages, 8 figures, IEEE Access journal published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate use of iteratively pruned deep learning model ensembles for\ndetecting pulmonary manifestation of COVID-19 with chest X-rays. This disease\nis caused by the novel Severe Acute Respiratory Syndrome Coronavirus 2\n(SARS-CoV-2) virus, also known as the novel Coronavirus (2019-nCoV). A custom\nconvolutional neural network and a selection of ImageNet pretrained models are\ntrained and evaluated at patient-level on publicly available CXR collections to\nlearn modality-specific feature representations. The learned knowledge is\ntransferred and fine-tuned to improve performance and generalization in the\nrelated task of classifying CXRs as normal, showing bacterial pneumonia, or\nCOVID-19-viral abnormalities. The best performing models are iteratively pruned\nto reduce complexity and improve memory efficiency. The predictions of the\nbest-performing pruned models are combined through different ensemble\nstrategies to improve classification performance. Empirical evaluations\ndemonstrate that the weighted average of the best-performing pruned models\nsignificantly improves performance resulting in an accuracy of 99.01% and area\nunder the curve of 0.9972 in detecting COVID-19 findings on CXRs. The combined\nuse of modality-specific knowledge transfer, iterative model pruning, and\nensemble learning resulted in improved predictions. We expect that this model\ncan be quickly adopted for COVID-19 screening using chest radiographs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 00:09:29 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 15:18:01 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 15:05:31 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rajaraman", "Sivaramakrishnan", ""], ["Siegelman", "Jen", ""], ["Alderson", "Philip O.", ""], ["Folio", "Lucas S.", ""], ["Folio", "Les R.", ""], ["Antani", "Sameer K.", ""]]}, {"id": "2004.08410", "submitter": "Xiao Li", "authors": "Xiao Li, Hanchen Xu, Jinming Zhang, Hua-hua Chang", "title": "Deep Reinforcement Learning for Adaptive Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate the adaptive learning problem---the problem of\nhow to find an individualized learning plan (called policy) that chooses the\nmost appropriate learning materials based on learner's latent traits---faced in\nadaptive learning systems as a Markov decision process (MDP). We assume latent\ntraits to be continuous with an unknown transition model. We apply a model-free\ndeep reinforcement learning algorithm---the deep Q-learning algorithm---that\ncan effectively find the optimal learning policy from data on learners'\nlearning process without knowing the actual transition model of the learners'\ncontinuous latent traits. To efficiently utilize available data, we also\ndevelop a transition model estimator that emulates the learner's learning\nprocess using neural networks. The transition model estimator can be used in\nthe deep Q-learning algorithm so that it can more efficiently discover the\noptimal learning policy for a learner. Numerical simulation studies verify that\nthe proposed algorithm is very efficient in finding a good learning policy,\nespecially with the aid of a transition model estimator, it can find the\noptimal learning policy after training using a small number of learners.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 18:04:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Li", "Xiao", ""], ["Xu", "Hanchen", ""], ["Zhang", "Jinming", ""], ["Chang", "Hua-hua", ""]]}, {"id": "2004.08423", "submitter": "Xin Chen", "authors": "Xin Chen, Lingxi Xie, Jun Wu, Longhui Wei, Yuhui Xu and Qi Tian", "title": "Fitting the Search Space of Weight-sharing NAS with Graph Convolutional\n  Networks", "comments": "Accepted to AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search has attracted wide attentions in both academia and\nindustry. To accelerate it, researchers proposed weight-sharing methods which\nfirst train a super-network to reuse computation among different operators,\nfrom which exponentially many sub-networks can be sampled and efficiently\nevaluated. These methods enjoy great advantages in terms of computational\ncosts, but the sampled sub-networks are not guaranteed to be estimated\nprecisely unless an individual training process is taken. This paper owes such\ninaccuracy to the inevitable mismatch between assembled network layers, so that\nthere is a random error term added to each estimation. We alleviate this issue\nby training a graph convolutional network to fit the performance of sampled\nsub-networks so that the impact of random errors becomes minimal. With this\nstrategy, we achieve a higher rank correlation coefficient in the selected set\nof candidates, which consequently leads to better performance of the final\narchitecture. In addition, our approach also enjoys the flexibility of being\nused under different hardware constraints, since the graph convolutional\nnetwork has provided an efficient lookup table of the performance of\narchitectures in the entire search space.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:12:39 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 09:47:03 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Chen", "Xin", ""], ["Xie", "Lingxi", ""], ["Wu", "Jun", ""], ["Wei", "Longhui", ""], ["Xu", "Yuhui", ""], ["Tian", "Qi", ""]]}, {"id": "2004.08431", "submitter": "Florian Mouret", "authors": "Florian Mouret and Mohanad Albughdadi and Sylvie Duthoit and Denis\n  Kouam\\'e and Guillaume Rieu and Jean-Yves Tourneret", "title": "Outlier detection at the parcel-level in wheat and rapeseed crops using\n  multispectral and SAR time series", "comments": null, "journal-ref": "Remote Sens. 2021, 13(5), 956", "doi": "10.3390/rs13050956", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the detection of anomalous crop development at the\nparcel-level based on an unsupervised outlier detection technique. The\nexperimental validation is conducted on rapeseed and wheat parcels located in\nBeauce (France). The proposed methodology consists of four sequential steps: 1)\npreprocessing of synthetic aperture radar (SAR) and multispectral images\nacquired using Sentinel-1 and Sentinel-2 satellites, 2) extraction of SAR and\nmultispectral pixel-level features, 3) computation of parcel-level features\nusing zonal statistics and 4) outlier detection. The different types of\nanomalies that can affect the studied crops are analyzed and described. The\ndifferent factors that can influence the outlier detection results are\ninvestigated with a particular attention devoted to the synergy between\nSentinel-1 and Sentinel-2 data. Overall, the best performance is obtained when\nusing jointly a selection of Sentinel-1 and Sentinel-2 features with the\nisolation forest algorithm. The selected features are VV and VH backscattering\ncoefficients for Sentinel-1 and 5 Vegetation Indexes for Sentinel-2 (among us,\nthe Normalized Difference Vegetation Index and two variants of the Normalized\nDifference Water). When using these features with an outlier ratio of 10%, the\npercentage of detected true positives (i.e., crop anomalies) is equal to 94.1%\nfor rapeseed parcels and 95.5% for wheat parcels.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:50:25 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:38:21 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 09:49:06 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Mouret", "Florian", ""], ["Albughdadi", "Mohanad", ""], ["Duthoit", "Sylvie", ""], ["Kouam\u00e9", "Denis", ""], ["Rieu", "Guillaume", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "2004.08434", "submitter": "Cameron Musco", "authors": "Cameron Musco and Christopher Musco", "title": "Projection-Cost-Preserving Sketches: Proof Strategies and Constructions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we illustrate how common matrix approximation methods, such as\nrandom projection and random sampling, yield projection-cost-preserving\nsketches, as introduced in [FSS13, CEM+15]. A projection-cost-preserving sketch\nis a matrix approximation which, for a given parameter $k$, approximately\npreserves the distance of the target matrix to all $k$-dimensional subspaces.\nSuch sketches have applications to scalable algorithms for linear algebra, data\nscience, and machine learning. Our goal is to simplify the presentation of\nproof techniques introduced in [CEM+15] and [CMM17] so that they can serve as a\nguide for future work. We also refer the reader to [CYD19], which gives a\nsimilar simplified exposition of the proof covered in Section 2.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:56:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Musco", "Cameron", ""], ["Musco", "Christopher", ""]]}, {"id": "2004.08439", "submitter": "Alexander Hagen PhD", "authors": "Alex Hagen, Eric Church, Jan Strube, Kolahal Bhattacharya, and Vinay\n  Amatya", "title": "Scaling the training of particle classification on simulated MicroBooNE\n  events to multiple GPUs", "comments": "6 pages, 4 figures, Accepted for publication in Journal of Physics:\n  Conference Series - Proceedings of the 19th International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research", "journal-ref": null, "doi": "10.1088/1742-6596/1525/1/012104", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measurements in Liquid Argon Time Projection Chamber (LArTPC) neutrino\ndetectors, such as the MicroBooNE detector at Fermilab, feature large, high\nfidelity event images. Deep learning techniques have been extremely successful\nin classification tasks of photographs, but their application to LArTPC event\nimages is challenging, due to the large size of the events. Events in these\ndetectors are typically two orders of magnitude larger than images found in\nclassical challenges, like recognition of handwritten digits contained in the\nMNIST database or object recognition in the ImageNet database. Ideally,\ntraining would occur on many instances of the entire event data, instead of\nmany instances of cropped regions of interest from the event data. However,\nsuch efforts lead to extremely long training cycles, which slow down the\nexploration of new network architectures and hyperparameter scans to improve\nthe classification performance. We present studies of scaling a LArTPC\nclassification problem on multiple architectures, spanning multiple nodes. The\nstudies are carried out on simulated events in the MicroBooNE detector. We\nemphasize that it is beyond the scope of this study to optimize networks or\nextract the physics from any results here. Institutional computing at Pacific\nNorthwest National Laboratory and the SummitDev machine at Oak Ridge National\nLaboratory's Leadership Computing Facility have been used. To our knowledge,\nthis is the first use of state-of-the-art Convolutional Neural Networks for\nparticle physics and their attendant compute techniques onto the DOE Leadership\nClass Facilities. We expect benefits to accrue particularly to the Deep\nUnderground Neutrino Experiment (DUNE) LArTPC program, the flagship US High\nEnergy Physics (HEP) program for the coming decades.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:21:27 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Hagen", "Alex", ""], ["Church", "Eric", ""], ["Strube", "Jan", ""], ["Bhattacharya", "Kolahal", ""], ["Amatya", "Vinay", ""]]}, {"id": "2004.08440", "submitter": "Haoze Wu", "authors": "Haoze Wu, Alex Ozdemir, Aleksandar Zelji\\'c, Ahmed Irfan, Kyle Julian,\n  Divya Gopinath, Sadjad Fouladi, Guy Katz, Corina Pasareanu and Clark Barrett", "title": "Parallelization Techniques for Verifying Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes with parallel optimization techniques for\nsolving Boolean satisfiability, we investigate a set of strategies and\nheuristics that aim to leverage parallel computing to improve the scalability\nof neural network verification. We introduce an algorithm based on partitioning\nthe verification problem in an iterative manner and explore two partitioning\nstrategies, that work by partitioning the input space or by case splitting on\nthe phases of the neuron activations, respectively. We also introduce a highly\nparallelizable pre-processing algorithm that uses the neuron activation phases\nto simplify the neural network verification problems. An extensive experimental\nevaluation shows the benefit of these techniques on both existing benchmarks\nand new benchmarks from the aviation domain. A preliminary experiment with\nultra-scaling our algorithm using a large distributed cloud-based platform also\nshows promising results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:21:47 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 20:43:08 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 16:15:13 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Wu", "Haoze", ""], ["Ozdemir", "Alex", ""], ["Zelji\u0107", "Aleksandar", ""], ["Irfan", "Ahmed", ""], ["Julian", "Kyle", ""], ["Gopinath", "Divya", ""], ["Fouladi", "Sadjad", ""], ["Katz", "Guy", ""], ["Pasareanu", "Corina", ""], ["Barrett", "Clark", ""]]}, {"id": "2004.08483", "submitter": "Santiago Ontanon", "authors": "Joshua Ainslie, Santiago Ontanon, Chris Alberti, Vaclav Cvicek,\n  Zachary Fisher, Philip Pham, Anirudh Ravula, Sumit Sanghai, Qifan Wang, Li\n  Yang", "title": "ETC: Encoding Long and Structured Inputs in Transformers", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer models have advanced the state of the art in many Natural\nLanguage Processing (NLP) tasks. In this paper, we present a new Transformer\narchitecture, Extended Transformer Construction (ETC), that addresses two key\nchallenges of standard Transformer architectures, namely scaling input length\nand encoding structured inputs. To scale attention to longer inputs, we\nintroduce a novel global-local attention mechanism between global tokens and\nregular input tokens. We also show that combining global-local attention with\nrelative position encodings and a Contrastive Predictive Coding (CPC)\npre-training objective allows ETC to encode structured inputs. We achieve\nstate-of-the-art results on four natural language datasets requiring long\nand/or structured inputs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 23:10:18 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 01:06:32 GMT"}, {"version": "v3", "created": "Sat, 19 Sep 2020 00:39:40 GMT"}, {"version": "v4", "created": "Tue, 22 Sep 2020 15:22:46 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 16:54:17 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ainslie", "Joshua", ""], ["Ontanon", "Santiago", ""], ["Alberti", "Chris", ""], ["Cvicek", "Vaclav", ""], ["Fisher", "Zachary", ""], ["Pham", "Philip", ""], ["Ravula", "Anirudh", ""], ["Sanghai", "Sumit", ""], ["Wang", "Qifan", ""], ["Yang", "Li", ""]]}, {"id": "2004.08499", "submitter": "Shenli Yuan", "authors": "Shenli Yuan, Lin Shao, Connor L. Yako, Alex Gruebele, and J. Kenneth\n  Salisbury", "title": "Design and Control of Roller Grasper V2 for In-Hand Manipulation", "comments": "2020 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS) October 25-29, 2020, Las Vegas, NV, USA (Virtual)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform in-hand manipulation still remains an unsolved\nproblem; having this capability would allow robots to perform sophisticated\ntasks requiring repositioning and reorienting of grasped objects. In this work,\nwe present a novel non-anthropomorphic robot grasper with the ability to\nmanipulate objects by means of active surfaces at the fingertips. Active\nsurfaces are achieved by spherical rolling fingertips with two degrees of\nfreedom (DoF) -- a pivoting motion for surface reorientation -- and a\ncontinuous rolling motion for moving the object. A further DoF is in the base\nof each finger, allowing the fingers to grasp objects over a range of size and\nshapes. Instantaneous kinematics was derived and objects were successfully\nmanipulated both with a custom handcrafted control scheme as well as one\nlearned through imitation learning, in simulation and experimentally on the\nhardware.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 00:54:09 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 23:16:45 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Yuan", "Shenli", ""], ["Shao", "Lin", ""], ["Yako", "Connor L.", ""], ["Gruebele", "Alex", ""], ["Salisbury", "J. Kenneth", ""]]}, {"id": "2004.08526", "submitter": "Seiichi Uchida", "authors": "Masaya Ikoma, Brian Kenji Iwana, Seiichi Uchida", "title": "Effect of Text Color on Word Embeddings", "comments": "to appear at the 14th International Workshop on Document Analysis\n  Systems (DAS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural scenes and documents, we can find the correlation between a text\nand its color. For instance, the word, \"hot\", is often printed in red, while\n\"cold\" is often in blue. This correlation can be thought of as a feature that\nrepresents the semantic difference between the words. Based on this\nobservation, we propose the idea of using text color for word embeddings. While\ntext-only word embeddings (e.g. word2vec) have been extremely successful, they\noften represent antonyms as similar since they are often interchangeable in\nsentences. In this paper, we try two tasks to verify the usefulness of text\ncolor in understanding the meanings of words, especially in identifying\nsynonyms and antonyms. First, we quantify the color distribution of words from\nthe book cover images and analyze the correlation between the color and meaning\nof the word. Second, we try to retrain word embeddings with the color\ndistribution of words as a constraint. By observing the changes in the word\nembeddings of synonyms and antonyms before and after re-training, we aim to\nunderstand the kind of words that have positive or negative effects in their\nword embeddings when incorporating text color information.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 05:14:18 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Ikoma", "Masaya", ""], ["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "2004.08541", "submitter": "Mohamed Gani Parisa Beham", "authors": "D.Sabari Nathan and M.Parisa Beham and S. M. Md Mansoor Roomi", "title": "Moire Image Restoration using Multi Level Hyper Vision Net", "comments": "8 pages , 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A moire pattern in the images is resulting from high frequency patterns\ncaptured by the image sensor (colour filter array) that appear after\ndemosaicing. These Moire patterns would appear in natural images of scenes with\nhigh frequency content. The Moire pattern can also vary intensely due to a\nminimal change in the camera direction/positioning. Thus the Moire pattern\ndepreciates the quality of photographs. An important issue in demoireing\npattern is that the Moireing patterns have dynamic structure with varying\ncolors and forms. These challenges makes the demoireing more difficult than\nmany other image restoration tasks. Inspired by these challenges in demoireing,\na multilevel hyper vision net is proposed to remove the Moire pattern to\nimprove the quality of the images. As a key aspect, in this network we involved\nresidual channel attention block that can be used to extract and adaptively\nfuse hierarchical features from all the layers efficiently. The proposed\nalgorithms has been tested with the NTIRE 2020 challenge dataset and thus\nachieved 36.85 and 0.98 Peak to Signal Noise Ratio (PSNR) and Structural\nSimilarity (SSIM) Index respectively.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 06:54:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Nathan", "D. Sabari", ""], ["Beham", "M. Parisa", ""], ["Roomi", "S. M. Md Mansoor", ""]]}, {"id": "2004.08545", "submitter": "Ahmed Guecioueur", "authors": "Ahmed Guecioueur and Franz J. Kir\\'aly", "title": "Kernels for time series with irregularly-spaced multivariate\n  observations", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series are an interesting frontier for kernel-based methods, for the\nsimple reason that there is no kernel designed to represent them and their\nunique characteristics in full generality. Existing sequential kernels ignore\nthe time indices, with many assuming that the series must be regularly-spaced;\nsome such kernels are not even psd. In this manuscript, we show that a \"series\nkernel\" that is general enough to represent irregularly-spaced multivariate\ntime series may be built out of well-known \"vector kernels\". We also show that\nall series kernels constructed using our methodology are psd, and are thus\nwidely applicable. We demonstrate this point by formulating a Gaussian\nprocess-based strategy - with our series kernel at its heart - to make\npredictions about test series when given a training set. We validate the\nstrategy experimentally by estimating its generalisation error on multiple\ndatasets and comparing it to relevant baselines. We also demonstrate that our\nseries kernel may be used for the more traditional setting of time series\nclassification, where its performance is broadly in line with alternative\nmethods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 07:51:54 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Guecioueur", "Ahmed", ""], ["Kir\u00e1ly", "Franz J.", ""]]}, {"id": "2004.08546", "submitter": "Chaoyang He", "authors": "Chaoyang He, Murali Annavaram, Salman Avestimehr", "title": "Towards Non-I.I.D. and Invisible Data with FedNAS: Federated Deep\n  Learning via Neural Architecture Search", "comments": "accepted to CVPR 2020 workshop on neural architecture search and\n  beyond for representation learning. Code is released at https://fedml.ai", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.MA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) has been proved to be an effective learning framework\nwhen data cannot be centralized due to privacy, communication costs, and\nregulatory restrictions. When training deep learning models under an FL\nsetting, people employ the predefined model architecture discovered in the\ncentralized environment. However, this predefined architecture may not be the\noptimal choice because it may not fit data with non-identical and independent\ndistribution (non-IID). Thus, we advocate automating federated learning\n(AutoFL) to improve model accuracy and reduce the manual design effort. We\nspecifically study AutoFL via Neural Architecture Search (NAS), which can\nautomate the design process. We propose a Federated NAS (FedNAS) algorithm to\nhelp scattered workers collaboratively searching for a better architecture with\nhigher accuracy. We also build a system based on FedNAS. Our experiments on\nnon-IID dataset show that the architecture searched by FedNAS can outperform\nthe manually predefined architecture.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 08:04:44 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 23:59:20 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 18:47:25 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 02:18:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["He", "Chaoyang", ""], ["Annavaram", "Murali", ""], ["Avestimehr", "Salman", ""]]}, {"id": "2004.08572", "submitter": "Viraj Kulkarni", "authors": "Sudeep Kondal, Viraj Kulkarni, Ashrika Gaikwad, Amit Kharat, Aniruddha\n  Pant", "title": "Automatic Grading of Knee Osteoarthritis on the Kellgren-Lawrence Scale\n  from Radiographs Using Convolutional Neural Networks", "comments": "5 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The severity of knee osteoarthritis is graded using the 5-point\nKellgren-Lawrence (KL) scale where healthy knees are assigned grade 0, and the\nsubsequent grades 1-4 represent increasing severity of the affliction. Although\nseveral methods have been proposed in recent years to develop models that can\nautomatically predict the KL grade from a given radiograph, most models have\nbeen developed and evaluated on datasets not sourced from India. These models\nfail to perform well on the radiographs of Indian patients. In this paper, we\npropose a novel method using convolutional neural networks to automatically\ngrade knee radiographs on the KL scale. Our method works in two connected\nstages: in the first stage, an object detection model segments individual knees\nfrom the rest of the image; in the second stage, a regression model\nautomatically grades each knee separately on the KL scale. We train our model\nusing the publicly available Osteoarthritis Initiative (OAI) dataset and\ndemonstrate that fine-tuning the model before evaluating it on a dataset from a\nprivate hospital significantly improves the mean absolute error from 1.09 (95%\nCI: 1.03-1.15) to 0.28 (95% CI: 0.25-0.32). Additionally, we compare\nclassification and regression models built for the same task and demonstrate\nthat regression outperforms classification.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 09:46:55 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Kondal", "Sudeep", ""], ["Kulkarni", "Viraj", ""], ["Gaikwad", "Ashrika", ""], ["Kharat", "Amit", ""], ["Pant", "Aniruddha", ""]]}, {"id": "2004.08581", "submitter": "Zhe Liu", "authors": "Zhe Liu, Lina Yao, Xianzhi Wang, Lei Bai and Jake An", "title": "Are You A Risk Taker? Adversarial Learning of Asymmetric Cross-Domain\n  Alignment for Risk Tolerance Prediction", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207111", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current studies on survey analysis and risk tolerance modelling lack\nprofessional knowledge and domain-specific models. Given the effectiveness of\ngenerative adversarial learning in cross-domain information, we design an\nAsymmetric cross-Domain Generative Adversarial Network (ADGAN) for domain scale\ninequality. ADGAN utilizes the information-sufficient domain to provide extra\ninformation to improve the representation learning on the\ninformation-insufficient domain via domain alignment. We provide data analysis\nand user model on two data sources: Consumer Consumption Information and Survey\nInformation. We further test ADGAN on a real-world dataset with view embedding\nstructures and show ADGAN can better deal with the class imbalance and\nunqualified data space than state-of-the-art, demonstrating the effectiveness\nof leveraging asymmetrical domain information.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 10:20:28 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Liu", "Zhe", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Bai", "Lei", ""], ["An", "Jake", ""]]}, {"id": "2004.08597", "submitter": "Ananya Uppal", "authors": "Ananya Uppal, Shashank Singh, Barnabas Poczos", "title": "Robust Density Estimation under Besov IPM Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study minimax convergence rates of nonparametric density estimation in the\nHuber contamination model, in which a proportion of the data comes from an\nunknown outlier distribution. We provide the first results for this problem\nunder a large family of losses, called Besov integral probability metrics\n(IPMs), that includes $\\mathcal{L}^p$, Wasserstein, Kolmogorov-Smirnov, and\nother common distances between probability distributions. Specifically, under a\nrange of smoothness assumptions on the population and outlier distributions, we\nshow that a re-scaled thresholding wavelet series estimator achieves minimax\noptimal convergence rates under a wide variety of losses. Finally, based on\nconnections that have recently been shown between nonparametric density\nestimation under IPM losses and generative adversarial networks (GANs), we show\nthat certain GAN architectures also achieve these minimax rates.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:30:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Uppal", "Ananya", ""], ["Singh", "Shashank", ""], ["Poczos", "Barnabas", ""]]}, {"id": "2004.08599", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Three Modern Roles for Logic in AI", "comments": "To be published in PODS 2020", "journal-ref": null, "doi": "10.1145/3375395.3389131", "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider three modern roles for logic in artificial intelligence, which\nare based on the theory of tractable Boolean circuits: (1) logic as a basis for\ncomputation, (2) logic for learning from a combination of data and knowledge,\nand (3) logic for reasoning about the behavior of machine learning systems.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:51:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "2004.08600", "submitter": "Chris Reinke", "authors": "Chris Reinke", "title": "Time Adaptive Reinforcement Learning", "comments": "ICLR 2020 Workshop: Beyond Tabula Rasa in Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) allows to solve complex tasks such as Go often\nwith a stronger performance than humans. However, the learned behaviors are\nusually fixed to specific tasks and unable to adapt to different contexts. Here\nwe consider the case of adapting RL agents to different time restrictions, such\nas finishing a task with a given time limit that might change from one task\nexecution to the next. We define such problems as Time Adaptive Markov Decision\nProcesses and introduce two model-free, value-based algorithms: the Independent\nGamma-Ensemble and the n-Step Ensemble. In difference to classical approaches,\nthey allow a zero-shot adaptation between different time restrictions. The\nproposed approaches represent general mechanisms to handle time adaptive tasks\nmaking them compatible with many existing RL methods, algorithms, and\nscenarios.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 11:52:07 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Reinke", "Chris", ""]]}, {"id": "2004.08614", "submitter": "Tejas Gokhale", "authors": "Kuldeep Kulkarni, Tejas Gokhale, Rajhans Singh, Pavan Turaga, Aswin\n  Sankaranarayanan", "title": "Halluci-Net: Scene Completion by Exploiting Object Co-occurrence\n  Relationships", "comments": "Accepted to AI for Content Creation Workshop @CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there has been substantial progress in image synthesis from\nsemantic labelmaps. However, methods used for this task assume the availability\nof complete and unambiguous labelmaps, with instance boundaries of objects, and\nclass labels for each pixel. This reliance on heavily annotated inputs\nrestricts the application of image synthesis techniques to real-world\napplications, especially under uncertainty due to weather, occlusion, or noise.\nOn the other hand, algorithms that can synthesize images from sparse labelmaps\nor sketches are highly desirable as tools that can guide content creators and\nartists to quickly generate scenes by simply specifying locations of a few\nobjects. In this paper, we address the problem of complex scene completion from\nsparse labelmaps. Under this setting, very few details about the scene (30\\% of\nobject instances) are available as input for image synthesis. We propose a\ntwo-stage deep network based method, called `Halluci-Net', that learns\nco-occurence relationships between objects in scenes, and then exploits these\nrelationships to produce a dense and complete labelmap. The generated dense\nlabelmap can then be used as input by state-of-the-art image synthesis\ntechniques like pix2pixHD to obtain the final image. The proposed method is\nevaluated on the Cityscapes dataset and it outperforms two baselines methods on\nperformance metrics like Fr\\'echet Inception Distance (FID), semantic\nsegmentation accuracy, and similarity in object co-occurrences. We also show\nqualitative results on a subset of ADE20K dataset that contains bedroom images.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 13:12:59 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 03:04:53 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Kulkarni", "Kuldeep", ""], ["Gokhale", "Tejas", ""], ["Singh", "Rajhans", ""], ["Turaga", "Pavan", ""], ["Sankaranarayanan", "Aswin", ""]]}, {"id": "2004.08620", "submitter": "Yongqiang Cai", "authors": "Yongqiang Cai, Qianxiao Li, Zuowei Shen", "title": "Optimization in Machine Learning: A Distribution Space Approach", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the viewpoint that optimization problems encountered in machine\nlearning can often be interpreted as minimizing a convex functional over a\nfunction space, but with a non-convex constraint set introduced by model\nparameterization. This observation allows us to repose such problems via a\nsuitable relaxation as convex optimization problems in the space of\ndistributions over the training parameters. We derive some simple relationships\nbetween the distribution-space problem and the original problem, e.g. a\ndistribution-space solution is at least as good as a solution in the original\nspace. Moreover, we develop a numerical algorithm based on mixture\ndistributions to perform approximate optimization directly in distribution\nspace. Consistency of this approximation is established and the numerical\nefficacy of the proposed algorithm is illustrated on simple examples. In both\ntheory and practice, this formulation provides an alternative approach to\nlarge-scale optimization in machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 13:38:06 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cai", "Yongqiang", ""], ["Li", "Qianxiao", ""], ["Shen", "Zuowei", ""]]}, {"id": "2004.08628", "submitter": "B.S. Vivek", "authors": "Vivek B.S. and R. Venkatesh Babu", "title": "Single-step Adversarial training with Dropout Scheduling", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have shown impressive performance across a spectrum of\ncomputer vision applications including medical diagnosis and autonomous\ndriving. One of the major concerns that these models face is their\nsusceptibility to adversarial attacks. Realizing the importance of this issue,\nmore researchers are working towards developing robust models that are less\naffected by adversarial attacks. Adversarial training method shows promising\nresults in this direction. In adversarial training regime, models are trained\nwith mini-batches augmented with adversarial samples. Fast and simple methods\n(e.g., single-step gradient ascent) are used for generating adversarial\nsamples, in order to reduce computational complexity. It is shown that models\ntrained using single-step adversarial training method (adversarial samples are\ngenerated using non-iterative method) are pseudo robust. Further, this pseudo\nrobustness of models is attributed to the gradient masking effect. However,\nexisting works fail to explain when and why gradient masking effect occurs\nduring single-step adversarial training. In this work, (i) we show that models\ntrained using single-step adversarial training method learn to prevent the\ngeneration of single-step adversaries, and this is due to over-fitting of the\nmodel during the initial stages of training, and (ii) to mitigate this effect,\nwe propose a single-step adversarial training method with dropout scheduling.\nUnlike models trained using existing single-step adversarial training methods,\nmodels trained using the proposed single-step adversarial training method are\nrobust against both single-step and multi-step adversarial attacks, and the\nperformance is on par with models trained using computationally expensive\nmulti-step adversarial training methods, in white-box and black-box settings.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 14:14:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["S.", "Vivek B.", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "2004.08646", "submitter": "Yuchen Xiao", "authors": "Yuchen Xiao, Joshua Hoffman, and Christopher Amato", "title": "Macro-Action-Based Deep Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": "3rd Conference on Robot Learning (CoRL 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world multi-robot systems, performing high-quality, collaborative\nbehaviors requires robots to asynchronously reason about high-level action\nselection at varying time durations. Macro-Action Decentralized Partially\nObservable Markov Decision Processes (MacDec-POMDPs) provide a general\nframework for asynchronous decision making under uncertainty in fully\ncooperative multi-agent tasks. However, multi-agent deep reinforcement learning\nmethods have only been developed for (synchronous) primitive-action problems.\nThis paper proposes two Deep Q-Network (DQN) based methods for learning\ndecentralized and centralized macro-action-value functions with novel\nmacro-action trajectory replay buffers introduced for each case. Evaluations on\nbenchmark problems and a larger domain demonstrate the advantage of learning\nwith macro-actions over primitive-actions and the scalability of our\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 15:46:38 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xiao", "Yuchen", ""], ["Hoffman", "Joshua", ""], ["Amato", "Christopher", ""]]}, {"id": "2004.08648", "submitter": "Saeed Moazami", "authors": "Saeed Moazami, Peggy Doerschuk", "title": "Modeling Survival in model-based Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although recent model-free reinforcement learning algorithms have been shown\nto be capable of mastering complicated decision-making tasks, the sample\ncomplexity of these methods has remained a hurdle to utilizing them in many\nreal-world applications. In this regard, model-based reinforcement learning\nproposes some remedies. Yet, inherently, model-based methods are more\ncomputationally expensive and susceptible to sub-optimality. One reason is that\nmodel-generated data are always less accurate than real data, and this often\nleads to inaccurate transition and reward function models. With the aim to\nmitigate this problem, this work presents the notion of survival by discussing\ncases in which the agent's goal is to survive and its analogy to maximizing the\nexpected rewards. To that end, a substitute model for the reward function\napproximator is introduced that learns to avoid terminal states rather than to\nmaximize accumulated rewards from safe states. Focusing on terminal states, as\na small fraction of state-space, reduces the training effort drastically. Next,\na model-based reinforcement learning method is proposed (Survive) to train an\nagent to avoid dangerous states through a safety map model built upon temporal\ncredit assignment in the vicinity of terminal states. Finally, the performance\nof the presented algorithm is investigated, along with a comparison between the\nproposed and current methods.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 15:49:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Moazami", "Saeed", ""], ["Doerschuk", "Peggy", ""]]}, {"id": "2004.08657", "submitter": "Kwangjun Ahn", "authors": "Kwangjun Ahn and Suvrit Sra", "title": "On Tight Convergence Rates of Without-replacement SGD", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For solving finite-sum optimization problems, SGD without replacement\nsampling is empirically shown to outperform SGD. Denoting by $n$ the number of\ncomponents in the cost and $K$ the number of epochs of the algorithm , several\nrecent works have shown convergence rates of without-replacement SGD that have\nbetter dependency on $n$ and $K$ than the baseline rate of $O(1/(nK))$ for SGD.\nHowever, there are two main limitations shared among those works: the rates\nhave extra poly-logarithmic factors on $nK$, and denoting by $\\kappa$ the\ncondition number of the problem, the rates hold after $\\kappa^c\\log(nK)$ epochs\nfor some $c>0$. In this work, we overcome these limitations by analyzing step\nsizes that vary across epochs.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 16:14:11 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ahn", "Kwangjun", ""], ["Sra", "Suvrit", ""]]}, {"id": "2004.08675", "submitter": "Valerii Likhosherstov", "authors": "Valerii Likhosherstov, Jared Davis, Krzysztof Choromanski, Adrian\n  Weller", "title": "CWY Parametrization: a Solution for Parallelized Optimization of\n  Orthogonal and Stiefel Matrices", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR:\n  Volume 130. Copyright 2021 by the author(s)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an efficient approach for optimization over orthogonal groups on\nhighly parallel computation units such as GPUs or TPUs. As in earlier work, we\nparametrize an orthogonal matrix as a product of Householder reflections.\nHowever, to overcome low parallelization capabilities of computing Householder\nreflections sequentially, we propose employing an accumulation scheme called\nthe compact WY (or CWY) transform -- a compact parallelization-friendly matrix\nrepresentation for the series of Householder reflections. We further develop a\nnovel Truncated CWY (or T-CWY) approach for Stiefel manifold parametrization\nwhich has a competitive complexity and, again, yields benefits when computed on\nGPUs and TPUs. We prove that our CWY and T-CWY methods lead to convergence to a\nstationary point of the training objective when coupled with stochastic\ngradient descent. We apply our methods to train recurrent neural network\narchitectures in the tasks of neural machine translation and video prediction.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 17:58:43 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:40:06 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 13:19:03 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Likhosherstov", "Valerii", ""], ["Davis", "Jared", ""], ["Choromanski", "Krzysztof", ""], ["Weller", "Adrian", ""]]}, {"id": "2004.08688", "submitter": "Fabi\\'an Latorre", "authors": "Fabian Latorre, Paul Rolland, Volkan Cevher", "title": "Lipschitz constant estimation of Neural Networks via sparse polynomial\n  optimization", "comments": "Published as a conference paper in ICLR2020, originally submitted in\n  September 25 2019 and available at https://openreview.net/forum?id=rJe4_xSFDB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LiPopt, a polynomial optimization framework for computing\nincreasingly tighter upper bounds on the Lipschitz constant of neural networks.\nThe underlying optimization problems boil down to either linear (LP) or\nsemidefinite (SDP) programming. We show how to use the sparse connectivity of a\nnetwork, to significantly reduce the complexity of computation. This is\nspecially useful for convolutional as well as pruned neural networks. We\nconduct experiments on networks with random weights as well as networks trained\non MNIST, showing that in the particular case of the $\\ell_\\infty$-Lipschitz\nconstant, our approach yields superior estimates, compared to baselines\navailable in the literature.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 18:55:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Latorre", "Fabian", ""], ["Rolland", "Paul", ""], ["Cevher", "Volkan", ""]]}, {"id": "2004.08690", "submitter": "Hamed Sadeghi", "authors": "Hamed Sadeghi, Shahram Shirani, David W. Capson", "title": "A fast semi-automatic method for classification and counting the number\n  and types of blood cells in an image", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel and fast semi-automatic method for segmentation, locating and\ncounting blood cells in an image is proposed. In this method, thresholding is\nused to separate the nucleus from the other parts. We also use Hough transform\nfor circles to locate the center of white cells. Locating and counting of red\ncells is performed using template matching. We make use of finding local\nmaxima, labeling and mean value computation in order to shrink the areas\nobtained after applying Hough transform or template matching, to a single pixel\nas representative of location of each region. The proposed method is very fast\nand computes the number and location of white cells accurately. It is also\ncapable of locating and counting the red cells with a small error.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 19:23:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sadeghi", "Hamed", ""], ["Shirani", "Shahram", ""], ["Capson", "David W.", ""]]}, {"id": "2004.08697", "submitter": "Mengyue Yang", "authors": "Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, Jun\n  Wang", "title": "CausalVAE: Disentangled Representation Learning via Neural Structural\n  Causal Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning disentanglement aims at finding a low dimensional representation\nwhich consists of multiple explanatory and generative factors of the\nobservational data. The framework of variational autoencoder (VAE) is commonly\nused to disentangle independent factors from observations. However, in real\nscenarios, factors with semantics are not necessarily independent. Instead,\nthere might be an underlying causal structure which renders these factors\ndependent. We thus propose a new VAE based framework named CausalVAE, which\nincludes a Causal Layer to transform independent exogenous factors into causal\nendogenous ones that correspond to causally related concepts in data. We\nfurther analyze the model identifiabitily, showing that the proposed model\nlearned from observations recovers the true one up to a certain degree.\nExperiments are conducted on various datasets, including synthetic and real\nword benchmark CelebA. Results show that the causal representations learned by\nCausalVAE are semantically interpretable, and their causal relationship as a\nDirected Acyclic Graph (DAG) is identified with good accuracy. Furthermore, we\ndemonstrate that the proposed CausalVAE model is able to generate\ncounterfactual data through \"do-operation\" to the causal factors.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 20:09:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:58:52 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 06:57:18 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 06:31:17 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 06:46:00 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Yang", "Mengyue", ""], ["Liu", "Furui", ""], ["Chen", "Zhitang", ""], ["Shen", "Xinwei", ""], ["Hao", "Jianye", ""], ["Wang", "Jun", ""]]}, {"id": "2004.08704", "submitter": "Hongxu Yin", "authors": "Wenhan Xia, Hongxu Yin, Niraj K. Jha", "title": "Efficient Synthesis of Compact Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been deployed in myriad machine learning\napplications. However, advances in their accuracy are often achieved with\nincreasingly complex and deep network architectures. These large, deep models\nare often unsuitable for real-world applications, due to their massive\ncomputational cost, high memory bandwidth, and long latency. For example,\nautonomous driving requires fast inference based on Internet-of-Things (IoT)\nedge devices operating under run-time energy and memory storage constraints. In\nsuch cases, compact DNNs can facilitate deployment due to their reduced energy\nconsumption, memory requirement, and inference latency. Long short-term\nmemories (LSTMs) are a type of recurrent neural network that have also found\nwidespread use in the context of sequential data modeling. They also face a\nmodel size vs. accuracy trade-off. In this paper, we review major approaches\nfor automatically synthesizing compact, yet accurate, DNN/LSTM models suitable\nfor real-world applications. We also outline some challenges and future areas\nof exploration.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:20:04 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xia", "Wenhan", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2004.08705", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, Alberto Redondo, David Rios Insua,\n  Fabrizio Ruggeri", "title": "Protecting Classifiers From Attacks. A Bayesian Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification problems in security settings are usually modeled as\nconfrontations in which an adversary tries to fool a classifier manipulating\nthe covariates of instances to obtain a benefit. Most approaches to such\nproblems have focused on game-theoretic ideas with strong underlying common\nknowledge assumptions, which are not realistic in the security realm. We\nprovide an alternative Bayesian framework that accounts for the lack of precise\nknowledge about the attacker's behavior using adversarial risk analysis. A key\ningredient required by our framework is the ability to sample from the\ndistribution of originating instances given the possibly attacked observed one.\nWe propose a sampling procedure based on approximate Bayesian computation, in\nwhich we simulate the attacker's problem taking into account our uncertainty\nabout his elements. For large scale problems, we propose an alternative,\nscalable approach that could be used when dealing with differentiable\nclassifiers. Within it, we move the computational load to the training phase,\nsimulating attacks from an adversary, adapting the framework to obtain a\nclassifier robustified against attacks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:21:56 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Redondo", "Alberto", ""], ["Insua", "David Rios", ""], ["Ruggeri", "Fabrizio", ""]]}, {"id": "2004.08708", "submitter": "Shakti Kumar", "authors": "Jerrod Parker, Shakti Kumar, Joe Roussy", "title": "Adaptive Attention Span in Computer Vision", "comments": "6 pages with 1 Algorithm, 4 figures, 1 Table and 1 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in Transformers for language modeling have opened new\nareas of research in computer vision. Results from late 2019 showed vast\nperformance increases in both object detection and recognition when\nconvolutions are replaced by local self-attention kernels. Models using local\nself-attention kernels were also shown to have less parameters and FLOPS\ncompared to equivalent architectures that only use convolutions. In this work\nwe propose a novel method for learning the local self-attention kernel size. We\nthen compare its performance to fixed-size local attention and convolution\nkernels. The code for all our experiments and models is available at\nhttps://github.com/JoeRoussy/adaptive-attention-in-cv\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:32:47 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Parker", "Jerrod", ""], ["Kumar", "Shakti", ""], ["Roussy", "Joe", ""]]}, {"id": "2004.08726", "submitter": "Aylin Caliskan", "authors": "Autumn Toney, Akshat Pandey, Wei Guo, David Broniatowski, Aylin\n  Caliskan", "title": "Automatically Characterizing Targeted Information Operations Through\n  Biases Present in Discourse on Twitter", "comments": "5 pages, 4 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper considers the problem of automatically characterizing overall\nattitudes and biases that may be associated with emerging information\noperations via artificial intelligence. Accurate analysis of these emerging\ntopics usually requires laborious, manual analysis by experts to annotate\nmillions of tweets to identify biases in new topics. We introduce extensions of\nthe Word Embedding Association Test from Caliskan et al. to a new domain\n(Caliskan, 2017). Our practical and unsupervised method is used to quantify\nbiases promoted in information operations. We validate our method using known\ninformation operation-related tweets from Twitter's Transparency Report. We\nperform a case study on the COVID-19 pandemic to evaluate our method's\nperformance on non-labeled Twitter data, demonstrating its usability in\nemerging domains.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 23:03:14 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 20:16:21 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 02:12:53 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Toney", "Autumn", ""], ["Pandey", "Akshat", ""], ["Guo", "Wei", ""], ["Broniatowski", "David", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2004.08730", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Predicting MMSE Score from Finger-Tapping Measurement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dementia is a leading cause of diseases for the elderly. Early diagnosis is\nvery important for the elderly living with dementias. In this paper, we propose\na method for dementia diagnosis by predicting MMSE score from finger-tapping\nmeasurement with machine learning pipeline. Based on measurement of finger\ntapping movement, the pipeline is first to select finger-tapping attributes\nwith copula entropy and then to predict MMSE score from the selected attributes\nwith predictive models. Experiments on real world data show that the predictive\nmodels such developed present good prediction performance. As a byproduct, the\nassociations between certain finger-tapping attributes (Number of taps and SD\nof inter-tapping interval) and MMSE score are discovered with copula entropy,\nwhich may be interpreted as the biological relationship between cognitive\nability and motor ability and therefore makes the predictive models\nexplainable. The selected finger-tapping attributes can be considered as\ndementia biomarkers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 23:30:57 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "2004.08731", "submitter": "Brent Biseda", "authors": "Brent Biseda and Katie Mo", "title": "Enhancing Pharmacovigilance with Drug Reviews and Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores whether the use of drug reviews and social media could be\nleveraged as potential alternative sources for pharmacovigilance of adverse\ndrug reactions (ADRs). We examined the performance of BERT alongside two\nvariants that are trained on biomedical papers, BioBERT7, and clinical notes,\nClinical BERT8. A variety of 8 different BERT models were fine-tuned and\ncompared across three different tasks in order to evaluate their relative\nperformance to one another in the ADR tasks. The tasks include sentiment\nclassification of drug reviews, presence of ADR in twitter postings, and named\nentity recognition of ADRs in twitter postings. BERT demonstrates its\nflexibility with high performance across all three different pharmacovigilance\nrelated tasks.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 23:35:24 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Biseda", "Brent", ""], ["Mo", "Katie", ""]]}, {"id": "2004.08742", "submitter": "Joshua Bassey", "authors": "Joshua Bassey, Xiangfang Li, Lijun Qian", "title": "Device Authentication Codes based on RF Fingerprinting using Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Device Authentication Code (DAC), a novel method\nfor authenticating IoT devices with wireless interface by exploiting their\nradio frequency (RF) signatures. The proposed DAC is based on RF\nfingerprinting, information theoretic method, feature learning, and\ndiscriminatory power of deep learning. Specifically, an autoencoder is used to\nautomatically extract features from the RF traces, and the reconstruction error\nis used as the DAC and this DAC is unique to the device and the particular\nmessage of interest. Then Kolmogorov-Smirnov (K-S) test is used to match the\ndistribution of the reconstruction error generated by the autoencoder and the\nreceived message, and the result will determine whether the device of interest\nbelongs to an authorized user. We validate this concept on two experimentally\ncollected RF traces from six ZigBee and five universal software defined radio\nperipheral (USRP) devices, respectively. The traces span a range of Signalto-\nNoise Ratio by varying locations and mobility of the devices and channel\ninterference and noise to ensure robustness of the model. Experimental results\ndemonstrate that DAC is able to prevent device impersonation by extracting\nsalient features that are unique to any wireless device of interest and can be\nused to identify RF devices. Furthermore, the proposed method does not need the\nRF traces of the intruder during model training yet be able to identify devices\nnot seen during training, which makes it practical.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 01:50:29 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bassey", "Joshua", ""], ["Li", "Xiangfang", ""], ["Qian", "Lijun", ""]]}, {"id": "2004.08763", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Kevin Xie, Florian Shkurti", "title": "Model-Predictive Control via Cross-Entropy and Gradient-Based\n  Optimization", "comments": "L4DC 2020; Accepted for presentation in the 2nd Annual Conference on\n  Learning for Dynamics and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works in high-dimensional model-predictive control and model-based\nreinforcement learning with learned dynamics and reward models have resorted to\npopulation-based optimization methods, such as the Cross-Entropy Method (CEM),\nfor planning a sequence of actions. To decide on an action to take, CEM\nconducts a search for the action sequence with the highest return according to\nthe dynamics model and reward. Action sequences are typically randomly sampled\nfrom an unconditional Gaussian distribution and evaluated on the environment.\nThis distribution is iteratively updated towards action sequences with higher\nreturns. However, this planning method can be very inefficient, especially for\nhigh-dimensional action spaces. An alternative line of approaches optimize\naction sequences directly via gradient descent, but are prone to local optima.\nWe propose a method to solve this planning problem by interleaving CEM and\ngradient descent steps in optimizing the action sequence. Our experiments show\nfaster convergence of the proposed hybrid approach, even for high-dimensional\naction spaces, avoidance of local minima, and better or equal performance to\nCEM. Code accompanying the paper is available here\nhttps://github.com/homangab/gradcem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:54:50 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Xie", "Kevin", ""], ["Shkurti", "Florian", ""]]}, {"id": "2004.08771", "submitter": "Florin Rusu", "authors": "Yujing Ma and Florin Rusu", "title": "Heterogeneous CPU+GPU Stochastic Gradient Descent Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widely-adopted practice is to train deep learning models with specialized\nhardware accelerators, e.g., GPUs or TPUs, due to their superior performance on\nlinear algebra operations. However, this strategy does not employ effectively\nthe extensive CPU and memory resources -- which are used only for\npreprocessing, data transfer, and scheduling -- available by default on the\naccelerated servers. In this paper, we study training algorithms for deep\nlearning on heterogeneous CPU+GPU architectures. Our two-fold objective --\nmaximize convergence rate and resource utilization simultaneously -- makes the\nproblem challenging. In order to allow for a principled exploration of the\ndesign space, we first introduce a generic deep learning framework that\nexploits the difference in computational power and memory hierarchy between CPU\nand GPU through asynchronous message passing. Based on insights gained through\nexperimentation with the framework, we design two heterogeneous asynchronous\nstochastic gradient descent (SGD) algorithms. The first algorithm -- CPU+GPU\nHogbatch -- combines small batches on CPU with large batches on GPU in order to\nmaximize the utilization of both resources. However, this generates an\nunbalanced model update distribution which hinders the statistical convergence.\nThe second algorithm -- Adaptive Hogbatch -- assigns batches with continuously\nevolving size based on the relative speed of CPU and GPU. This balances the\nmodel updates ratio at the expense of a customizable decrease in utilization.\nWe show that the implementation of these algorithms in the proposed CPU+GPU\nframework achieves both faster convergence and higher resource utilization than\nTensorFlow on several real datasets and on two computing architectures -- an\non-premises server and a cloud instance.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 05:21:20 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ma", "Yujing", ""], ["Rusu", "Florin", ""]]}, {"id": "2004.08773", "submitter": "Alper Atamturk", "authors": "Alper Atamt\\\"urk and Andr\\'es G\\'omez", "title": "Safe Screening Rules for $\\ell_0$-Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give safe screening rules to eliminate variables from regression with\n$\\ell_0$ regularization or cardinality constraint. These rules are based on\nguarantees that a feature may or may not be selected in an optimal solution.\nThe screening rules can be computed from a convex relaxation solution in linear\ntime, without solving the $\\ell_0$ optimization problem. Thus, they can be used\nin a preprocessing step to safely remove variables from consideration apriori.\nNumerical experiments on real and synthetic data indicate that, on average,\n76\\% of the variables can be fixed to their optimal values, hence, reducing the\ncomputational burden for optimization substantially. Therefore, the proposed\nfast and effective screening rules extend the scope of algorithms for\n$\\ell_0$-regression to larger data sets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 06:07:09 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Atamt\u00fcrk", "Alper", ""], ["G\u00f3mez", "Andr\u00e9s", ""]]}, {"id": "2004.08780", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana and Seiichi Uchida", "title": "Time Series Data Augmentation for Neural Networks by Time Warping with a\n  Discriminative Teacher", "comments": "Submitted to ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become a powerful tool in pattern recognition and part\nof their success is due to generalization from using large datasets. However,\nunlike other domains, time series classification datasets are often small. In\norder to address this problem, we propose a novel time series data augmentation\ncalled guided warping. While many data augmentation methods are based on random\ntransformations, guided warping exploits the element alignment properties of\nDynamic Time Warping (DTW) and shapeDTW, a high-level DTW method based on shape\ndescriptors, to deterministically warp sample patterns. In this way, the time\nseries are mixed by warping the features of a sample pattern to match the time\nsteps of a reference pattern. Furthermore, we introduce a discriminative\nteacher in order to serve as a directed reference for the guided warping. We\nevaluate the method on all 85 datasets in the 2015 UCR Time Series Archive with\na deep convolutional neural network (CNN) and a recurrent neural network (RNN).\nThe code with an easy to use implementation can be found at\nhttps://github.com/uchidalab/time_series_augmentation .\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 06:33:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "2004.08782", "submitter": "Kamran Alipour", "authors": "Ali Hariri, Kamran Alipour, Yash Mantri, Jurgen P. Schulze, and Jesse\n  V. Jokerst", "title": "Deep Learning Improves Contrast in Low-Fluence Photoacoustic Imaging", "comments": "submitted to Biomedical Optics Express journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low fluence illumination sources can facilitate clinical transition of\nphotoacoustic imaging because they are rugged, portable, affordable, and safe.\nHowever, these sources also decrease image quality due to their low fluence.\nHere, we propose a denoising method using a multi-level wavelet-convolutional\nneural network to map low fluence illumination source images to its\ncorresponding high fluence excitation map. Quantitative and qualitative results\nshow a significant potential to remove the background noise and preserve the\nstructures of target. Substantial improvements up to 2.20, 2.25, and 4.3-fold\nfor PSNR, SSIM, and CNR metrics were observed, respectively. We also observed\nenhanced contrast (up to 1.76-fold) in an in vivo application using our\nproposed methods. We suggest that this tool can improve the value of such\nsources in photoacoustic imaging.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 07:06:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hariri", "Ali", ""], ["Alipour", "Kamran", ""], ["Mantri", "Yash", ""], ["Schulze", "Jurgen P.", ""], ["Jokerst", "Jesse V.", ""]]}, {"id": "2004.08790", "submitter": "Huimin Huang", "authors": "Huimin Huang, Lanfen Lin, Ruofeng Tong, Hongjie Hu, Qiaowei Zhang,\n  Yutaro Iwamoto, Xianhua Han, Yen-Wei Chen, Jian Wu", "title": "UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a growing interest has been seen in deep learning-based semantic\nsegmentation. UNet, which is one of deep learning networks with an\nencoder-decoder architecture, is widely used in medical image segmentation.\nCombining multi-scale features is one of important factors for accurate\nsegmentation. UNet++ was developed as a modified Unet by designing an\narchitecture with nested and dense skip connections. However, it does not\nexplore sufficient information from full scales and there is still a large room\nfor improvement. In this paper, we propose a novel UNet 3+, which takes\nadvantage of full-scale skip connections and deep supervisions. The full-scale\nskip connections incorporate low-level details with high-level semantics from\nfeature maps in different scales; while the deep supervision learns\nhierarchical representations from the full-scale aggregated feature maps. The\nproposed method is especially benefiting for organs that appear at varying\nscales. In addition to accuracy improvements, the proposed UNet 3+ can reduce\nthe network parameters to improve the computation efficiency. We further\npropose a hybrid loss function and devise a classification-guided module to\nenhance the organ boundary and reduce the over-segmentation in a non-organ\nimage, yielding more accurate segmentation results. The effectiveness of the\nproposed method is demonstrated on two datasets. The code is available at:\ngithub.com/ZJUGiveLab/UNet-Version\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 08:05:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Huang", "Huimin", ""], ["Lin", "Lanfen", ""], ["Tong", "Ruofeng", ""], ["Hu", "Hongjie", ""], ["Zhang", "Qiaowei", ""], ["Iwamoto", "Yutaro", ""], ["Han", "Xianhua", ""], ["Chen", "Yen-Wei", ""], ["Wu", "Jian", ""]]}, {"id": "2004.08821", "submitter": "Florenc Demrozi Dr.", "authors": "Florenc Demrozi, Graziano Pravadelli, Azra Bihorac, and Parisa Rashidi", "title": "Human Activity Recognition using Inertial, Physiological and\n  Environmental Sensors: a Comprehensive Survey", "comments": "Accepted for Publication in IEEE Access DOI:\n  10.1109/ACCESS.2020.3037715", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3037715", "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, Human Activity Recognition (HAR) has become a vibrant\nresearch area, especially due to the spread of electronic devices such as\nsmartphones, smartwatches and video cameras present in our daily lives. In\naddition, the advance of deep learning and other machine learning algorithms\nhas allowed researchers to use HAR in various domains including sports, health\nand well-being applications. For example, HAR is considered as one of the most\npromising assistive technology tools to support elderly's daily life by\nmonitoring their cognitive and physical function through daily activities. This\nsurvey focuses on critical role of machine learning in developing HAR\napplications based on inertial sensors in conjunction with physiological and\nenvironmental sensors.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 11:32:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 09:23:38 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Demrozi", "Florenc", ""], ["Pravadelli", "Graziano", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.08826", "submitter": "Mateus Dias Ribeiro", "authors": "Mateus Dias Ribeiro and Abdul Rehman and Sheraz Ahmed and Andreas\n  Dengel", "title": "DeepCFD: Efficient Steady-State Laminar Flow Approximation with Deep\n  Convolutional Neural Networks", "comments": "23 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.LG physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Fluid Dynamics (CFD) simulation by the numerical solution of\nthe Navier-Stokes equations is an essential tool in a wide range of\napplications from engineering design to climate modeling. However, the\ncomputational cost and memory demand required by CFD codes may become very high\nfor flows of practical interest, such as in aerodynamic shape optimization.\nThis expense is associated with the complexity of the fluid flow governing\nequations, which include non-linear partial derivative terms that are of\ndifficult solution, leading to long computational times and limiting the number\nof hypotheses that can be tested during the process of iterative design.\nTherefore, we propose DeepCFD: a convolutional neural network (CNN) based model\nthat efficiently approximates solutions for the problem of non-uniform steady\nlaminar flows. The proposed model is able to learn complete solutions of the\nNavier-Stokes equations, for both velocity and pressure fields, directly from\nground-truth data generated using a state-of-the-art CFD code. Using DeepCFD,\nwe found a speedup of up to 3 orders of magnitude compared to the standard CFD\napproach at a cost of low error rates.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 12:00:37 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 15:25:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Ribeiro", "Mateus Dias", ""], ["Rehman", "Abdul", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "2004.08830", "submitter": "Muhammad Burhan Hafez", "authors": "Muhammad Burhan Hafez, Cornelius Weber, Matthias Kerzel, Stefan\n  Wermter", "title": "Improving Robot Dual-System Motor Learning with Intrinsically Motivated\n  Meta-Control and Latent-Space Experience Imagination", "comments": null, "journal-ref": "Robotics and Autonomous Systems 133 (2020) 103630", "doi": "10.1016/j.robot.2020.103630", "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining model-based and model-free learning systems has been shown to\nimprove the sample efficiency of learning to perform complex robotic tasks.\nHowever, dual-system approaches fail to consider the reliability of the learned\nmodel when it is applied to make multiple-step predictions, resulting in a\ncompounding of prediction errors and performance degradation. In this paper, we\npresent a novel dual-system motor learning approach where a meta-controller\narbitrates online between model-based and model-free decisions based on an\nestimate of the local reliability of the learned model. The reliability\nestimate is used in computing an intrinsic feedback signal, encouraging actions\nthat lead to data that improves the model. Our approach also integrates\narbitration with imagination where a learned latent-space model generates\nimagined experiences, based on its local reliability, to be used as additional\ntraining data. We evaluate our approach against baseline and state-of-the-art\nmethods on learning vision-based robotic grasping in simulation and real world.\nThe results show that our approach outperforms the compared methods and learns\nnear-optimal grasping policies in dense- and sparse-reward environments.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 12:14:46 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 16:03:29 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 09:12:31 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hafez", "Muhammad Burhan", ""], ["Weber", "Cornelius", ""], ["Kerzel", "Matthias", ""], ["Wermter", "Stefan", ""]]}, {"id": "2004.08851", "submitter": "Chandan Biswas", "authors": "Chandan Biswas, Debasis Ganguly and Ujjwal Bhattacharya", "title": "Approximate Nearest Neighbour Search on Privacy-aware Encoding of User\n  Locations to Identify Susceptible Infections in Simulated Epidemics", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amidst an increasing number of infected cases during the Covid-19 pandemic,\nit is essential to trace, as early as possible, the susceptible people who\nmight have been infected by the disease due to their close proximity with\npeople who were tested positive for the virus. This early contact tracing is\nlikely to limit the rate of spread of the infection within a locality. In this\npaper, we investigate how effectively and efficiently can such a list of\nsusceptible people be found given a list of infected persons and their\nlocations. To address this problem from an information retrieval (search)\nperspective, we represent the location of each person at each time instant as a\npoint in a vector space. By using the locations of the given list of infected\npersons as queries, we investigate the feasibility of applying approximate\nnearest neighbour (ANN) based indexing and retrieval approaches to obtain a\nlist of top-k suspected users in real-time. Since leveraging information from\ntrue user location data can lead to security and privacy concerns, we also\ninvestigate what effects does distance-preserving encoding methods have on the\neffectiveness of the ANN methods. Experiments conducted on real and synthetic\ndatasets demonstrate that the top-k retrieved lists of susceptible users\nretrieved with existing ANN approaches (KD-tree and HNSW) yield satisfactory\nprecision and recall values, thus indicating that ANN approaches can\npotentially be applied in practice to facilitate real-time contact tracing even\nunder the presence of imposed privacy constraints.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 13:34:16 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:44:19 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Biswas", "Chandan", ""], ["Ganguly", "Debasis", ""], ["Bhattacharya", "Ujjwal", ""]]}, {"id": "2004.08856", "submitter": "Yang Zhao", "authors": "Yang Zhao, Jun Zhao, Mengmeng Yang, Teng Wang, Ning Wang, Lingjuan\n  Lyu, Dusit Niyato, Kwok-Yan Lam", "title": "Local Differential Privacy based Federated Learning for Internet of\n  Things", "comments": "This paper appears in IEEE Internet of Things Journal (IoT-J)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Vehicles (IoV) is a promising branch of the Internet of Things.\nIoV simulates a large variety of crowdsourcing applications such as Waze, Uber,\nand Amazon Mechanical Turk, etc. Users of these applications report the\nreal-time traffic information to the cloud server which trains a machine\nlearning model based on traffic information reported by users for intelligent\ntraffic management. However, crowdsourcing application owners can easily infer\nusers' location information, which raises severe location privacy concerns of\nthe users. In addition, as the number of vehicles increases, the frequent\ncommunication between vehicles and the cloud server incurs unexpected amount of\ncommunication cost. To avoid the privacy threat and reduce the communication\ncost, in this paper, we propose to integrate federated learning and local\ndifferential privacy (LDP) to facilitate the crowdsourcing applications to\nachieve the machine learning model. Specifically, we propose four LDP\nmechanisms to perturb gradients generated by vehicles. The Three-Outputs\nmechanism is proposed which introduces three different output possibilities to\ndeliver a high accuracy when the privacy budget is small. The output\npossibilities of Three-Outputs can be encoded with two bits to reduce the\ncommunication cost. Besides, to maximize the performance when the privacy\nbudget is large, an optimal piecewise mechanism (PM-OPT) is proposed. We\nfurther propose a suboptimal mechanism (PM-SUB) with a simple formula and\ncomparable utility to PM-OPT. Then, we build a novel hybrid mechanism by\ncombining Three-Outputs and PM-SUB.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:03:10 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 15:08:01 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Zhao", "Yang", ""], ["Zhao", "Jun", ""], ["Yang", "Mengmeng", ""], ["Wang", "Teng", ""], ["Wang", "Ning", ""], ["Lyu", "Lingjuan", ""], ["Niyato", "Dusit", ""], ["Lam", "Kwok-Yan", ""]]}, {"id": "2004.08861", "submitter": "Jie Fu", "authors": "Jie Fu, Xue Geng, Zhijian Duan, Bohan Zhuang, Xingdi Yuan, Adam\n  Trischler, Jie Lin, Chris Pal, Hao Dong", "title": "Role-Wise Data Augmentation for Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Distillation (KD) is a common method for transferring the\n``knowledge'' learned by one machine learning model (the \\textit{teacher}) into\nanother model (the \\textit{student}), where typically, the teacher has a\ngreater capacity (e.g., more parameters or higher bit-widths). To our\nknowledge, existing methods overlook the fact that although the student absorbs\nextra knowledge from the teacher, both models share the same input data -- and\nthis data is the only medium by which the teacher's knowledge can be\ndemonstrated. Due to the difference in model capacities, the student may not\nbenefit fully from the same data points on which the teacher is trained. On the\nother hand, a human teacher may demonstrate a piece of knowledge with\nindividualized examples adapted to a particular student, for instance, in terms\nof her cultural background and interests. Inspired by this behavior, we design\ndata augmentation agents with distinct roles to facilitate knowledge\ndistillation. Our data augmentation agents generate distinct training data for\nthe teacher and student, respectively. We find empirically that specially\ntailored data points enable the teacher's knowledge to be demonstrated more\neffectively to the student. We compare our approach with existing KD methods on\ntraining popular neural architectures and demonstrate that role-wise data\naugmentation improves the effectiveness of KD over strong prior approaches. The\ncode for reproducing our results can be found at\nhttps://github.com/bigaidream-projects/role-kd\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:22:17 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Fu", "Jie", ""], ["Geng", "Xue", ""], ["Duan", "Zhijian", ""], ["Zhuang", "Bohan", ""], ["Yuan", "Xingdi", ""], ["Trischler", "Adam", ""], ["Lin", "Jie", ""], ["Pal", "Chris", ""], ["Dong", "Hao", ""]]}, {"id": "2004.08867", "submitter": "Yulong Lu", "authors": "Yulong Lu and Jianfeng Lu", "title": "A Universal Approximation Theorem of Deep Neural Networks for Expressing\n  Probability Distributions", "comments": "Accepted in the Thirty-fourth Conference on Neural Information\n  Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the universal approximation property of deep neural\nnetworks for representing probability distributions. Given a target\ndistribution $\\pi$ and a source distribution $p_z$ both defined on\n$\\mathbb{R}^d$, we prove under some assumptions that there exists a deep neural\nnetwork $g:\\mathbb{R}^d\\rightarrow \\mathbb{R}$ with ReLU activation such that\nthe push-forward measure $(\\nabla g)_\\# p_z$ of $p_z$ under the map $\\nabla g$\nis arbitrarily close to the target measure $\\pi$. The closeness are measured by\nthree classes of integral probability metrics between probability\ndistributions: $1$-Wasserstein distance, maximum mean distance (MMD) and\nkernelized Stein discrepancy (KSD). We prove upper bounds for the size (width\nand depth) of the deep neural network in terms of the dimension $d$ and the\napproximation error $\\varepsilon$ with respect to the three discrepancies. In\nparticular, the size of neural network can grow exponentially in $d$ when\n$1$-Wasserstein distance is used as the discrepancy, whereas for both MMD and\nKSD the size of neural network only depends on $d$ at most polynomially. Our\nproof relies on convergence estimates of empirical measures under\naforementioned discrepancies and semi-discrete optimal transport.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:45:47 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 19:05:19 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 04:29:47 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Lu", "Yulong", ""], ["Lu", "Jianfeng", ""]]}, {"id": "2004.08870", "submitter": "Marcin Mozejko", "authors": "Marcin Mo\\.zejko, Tomasz Latkowski, {\\L}ukasz Treszczotko, Micha{\\l}\n  Szafraniuk, Krzysztof Trojanowski", "title": "Superkernel Neural Architecture Search for Image Denoising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancements in Neural Architecture Search(NAS) resulted in finding\nnew state-of-the-art Artificial Neural Network (ANN) solutions for tasks like\nimage classification, object detection, or semantic segmentation without\nsubstantial human supervision. In this paper, we focus on exploring NAS for a\ndense prediction task that is image denoising. Due to a costly training\nprocedure, most NAS solutions for image enhancement rely on reinforcement\nlearning or evolutionary algorithm exploration, which usually take weeks (or\neven months) to train. Therefore, we introduce a new efficient implementation\nof various superkernel techniques that enable fast (6-8 RTX2080 GPU hours)\nsingle-shot training of models for dense predictions. We demonstrate the\neffectiveness of our method on the SIDD+ benchmark for image denoising.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:52:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mo\u017cejko", "Marcin", ""], ["Latkowski", "Tomasz", ""], ["Treszczotko", "\u0141ukasz", ""], ["Szafraniuk", "Micha\u0142", ""], ["Trojanowski", "Krzysztof", ""]]}, {"id": "2004.08883", "submitter": "Chao Qu", "authors": "Chao Qu, Hui Li, Chang Liu, Junwu Xiong, James Zhang, Wei Chu,\n  Weiqiang Wang, Yuan Qi, Le Song", "title": "Intention Propagation for Multi-agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hallmark of an AI agent is to mimic human beings to understand and interact\nwith others. In this paper, we propose a collaborative multi-agent\nreinforcement learning algorithm to learn a \\emph{joint} policy through the\ninteractions over agents. To make a joint decision over the group, each agent\nmakes an initial decision and tells its policy to its neighbors. Then each\nagent modifies its own policy properly based on received messages and spreads\nout its plan. As this intention propagation procedure goes on, we prove that it\nconverges to a mean-field approximation of the joint policy with the framework\nof neural embedded probabilistic inference. We evaluate our algorithm on\nseveral large scale challenging tasks and demonstrate that it outperforms\nprevious state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 15:42:55 GMT"}, {"version": "v2", "created": "Sun, 16 Aug 2020 05:13:41 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2021 02:16:01 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Qu", "Chao", ""], ["Li", "Hui", ""], ["Liu", "Chang", ""], ["Xiong", "Junwu", ""], ["Zhang", "James", ""], ["Chu", "Wei", ""], ["Wang", "Weiqiang", ""], ["Qi", "Yuan", ""], ["Song", "Le", ""]]}, {"id": "2004.08885", "submitter": "Behnam Ojaghi Kahjogh", "authors": "Behnam Ojaghi Kahjogh and Mohammad Mahdi Dehshibi", "title": "A supervised active learning method for identifying critical nodes in\n  Wireless Sensor Network", "comments": "Due to finding an inconsistency in the proposed method, we\n  temporarily removed PDF. We will subsequently update this record", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Energy Efficiency of a wireless sensor network (WSN) relies on its main\ncharacteristics, including hop-number, user's location, allocated power, and\nrelay. Identifying nodes, which have more impact on these characteristics, is,\nhowever, subject to a substantial computational overhead and energy\nconsumption. In this paper, we proposed an active learning approach to address\nthe computational overhead of identifying critical nodes in a WSN. The proposed\napproach can overcome biasing in identifying non-critical nodes and needs much\nless effort in fine-tuning to adapt to the dynamic nature of WSN. This method\nbenefits from the cooperation of clustering and classification modules to\niteratively decrease the required number of data in a typical supervised\nlearning scenario and to increase the accuracy in the presence of uninformative\nexamples, i.e., non-critical nodes. Experiments show that the proposed method\nhas more flexibility, compared to the state-of-the-art, to be employed in large\nscale WSN environments, the fifth-generation mobile networks (5G), and\nmassively distributed IoT (i.e., sensor networks), where it can prolong the\nnetwork lifetime.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 15:48:27 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 12:23:57 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2020 16:14:26 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kahjogh", "Behnam Ojaghi", ""], ["Dehshibi", "Mohammad Mahdi", ""]]}, {"id": "2004.08886", "submitter": "Yue Shi", "authors": "Yue Shi, Liangxiu Han, Wenjiang Huang, Sheng Chang, Yingying Dong,\n  Darren Dancey, Lianghao Han", "title": "A Biologically Interpretable Two-stage Deep Neural Network (BIT-DNN) For\n  Vegetation Recognition From Hyperspectral Imagery", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TGRS.2021.3058782", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral-spatial based deep learning models have recently proven to be\neffective in hyperspectral image (HSI) classification for various earth\nmonitoring applications such as land cover classification and agricultural\nmonitoring. However, due to the nature of \"black-box\" model representation, how\nto explain and interpret the learning process and the model decision,\nespecially for vegetation classification, remains an open challenge. This study\nproposes a novel interpretable deep learning model -- a biologically\ninterpretable two-stage deep neural network (BIT-DNN), by incorporating the\nprior-knowledge (i.e. biophysical and biochemical attributes and their\nhierarchical structures of target entities) based spectral-spatial feature\ntransformation into the proposed framework, capable of achieving both high\naccuracy and interpretability on HSI based classification tasks. The proposed\nmodel introduces a two-stage feature learning process: in the first stage, an\nenhanced interpretable feature block extracts the low-level spectral features\nassociated with the biophysical and biochemical attributes of target entities;\nand in the second stage, an interpretable capsule block extracts and\nencapsulates the high-level joint spectral-spatial features representing the\nhierarchical structure of biophysical and biochemical attributes of these\ntarget entities, which provides the model an improved performance on\nclassification and intrinsic interpretability with reduced computational\ncomplexity. We have tested and evaluated the model using four real HSI datasets\nfor four separate tasks (i.e. plant species classification, land cover\nclassification, urban scene recognition, and crop disease recognition tasks).\nThe proposed model has been compared with five state-of-the-art deep learning\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 15:58:19 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 14:26:14 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Shi", "Yue", ""], ["Han", "Liangxiu", ""], ["Huang", "Wenjiang", ""], ["Chang", "Sheng", ""], ["Dong", "Yingying", ""], ["Dancey", "Darren", ""], ["Han", "Lianghao", ""]]}, {"id": "2004.08891", "submitter": "Weiguan Wang", "authors": "Johannes Ruf, Weiguan Wang", "title": "Hedging with Linear Regressions and Neural Networks", "comments": "Forthcoming in the Journal of Business & Economic Statistics", "journal-ref": null, "doi": "10.1080/07350015.2021.1931241", "report-no": null, "categories": "q-fin.RM cs.LG q-fin.MF q-fin.ST stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study neural networks as nonparametric estimation tools for the hedging of\noptions. To this end, we design a network, named HedgeNet, that directly\noutputs a hedging strategy. This network is trained to minimise the hedging\nerror instead of the pricing error. Applied to end-of-day and tick prices of\nS&P 500 and Euro Stoxx 50 options, the network is able to reduce the mean\nsquared hedging error of the Black-Scholes benchmark significantly. However, a\nsimilar benefit arises by simple linear regressions that incorporate the\nleverage effect.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:07:45 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:23:09 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 08:11:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ruf", "Johannes", ""], ["Wang", "Weiguan", ""]]}, {"id": "2004.08900", "submitter": "Or Sharir", "authors": "Or Sharir, Barak Peleg and Yoav Shoham", "title": "The Cost of Training NLP Models: A Concise Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the cost of training large-scale language models, and the drivers\nof these costs. The intended audience includes engineers and scientists\nbudgeting their model-training experiments, as well as non-practitioners trying\nto make sense of the economics of modern-day Natural Language Processing (NLP).\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:28:35 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Sharir", "Or", ""], ["Peleg", "Barak", ""], ["Shoham", "Yoav", ""]]}, {"id": "2004.08906", "submitter": "Evgenii Zheltonozshkii", "authors": "Alex Karbachevsky, Chaim Baskin, Evgenii Zheltonozhskii, Yevgeny\n  Yermolin, Freddy Gabbay, Alex M. Bronstein, Avi Mendelson", "title": "HCM: Hardware-Aware Complexity Metric for Neural Network Architectures", "comments": null, "journal-ref": null, "doi": "10.3390/su13020717", "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become common in many fields\nincluding computer vision, speech recognition, and natural language processing.\nAlthough CNN hardware accelerators are already included as part of many SoC\narchitectures, the task of achieving high accuracy on resource-restricted\ndevices is still considered challenging, mainly due to the vast number of\ndesign parameters that need to be balanced to achieve an efficient solution.\nQuantization techniques, when applied to the network parameters, lead to a\nreduction of power and area and may also change the ratio between communication\nand computation. As a result, some algorithmic solutions may suffer from lack\nof memory bandwidth or computational resources and fail to achieve the expected\nperformance due to hardware constraints. Thus, the system designer and the\nmicro-architect need to understand at early development stages the impact of\ntheir high-level decisions (e.g., the architecture of the CNN and the amount of\nbits used to represent its parameters) on the final product (e.g., the expected\npower saving, area, and accuracy). Unfortunately, existing tools fall short of\nsupporting such decisions.\n  This paper introduces a hardware-aware complexity metric that aims to assist\nthe system designer of the neural network architectures, through the entire\nproject lifetime (especially at its early stages) by predicting the impact of\narchitectural and micro-architectural decisions on the final product. We\ndemonstrate how the proposed metric can help evaluate different design\nalternatives of neural network models on resource-restricted devices such as\nreal-time embedded systems, and to avoid making design mistakes at early\nstages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:42:51 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 12:56:25 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Karbachevsky", "Alex", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Yermolin", "Yevgeny", ""], ["Gabbay", "Freddy", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "2004.08914", "submitter": "Sima Sinaei", "authors": "Seyed Ahmad Mirsalari, Sima Sinaei, Mostafa E. Salehi, Masoud\n  Daneshtalab", "title": "MuBiNN: Multi-Level Binarized Recurrent Neural Network for EEG signal\n  Classification", "comments": "To appear in IEEE International Symposium on Circuits & Systems in\n  2020. arXiv admin note: text overlap with arXiv:1807.04093 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) are widely used for learning sequences in\napplications such as EEG classification. Complex RNNs could be hardly deployed\non wearable devices due to their computation and memory-intensive processing\npatterns. Generally, reduction in precision leads much more efficiency and\nbinarized RNNs are introduced as energy-efficient solutions. However, naive\nbinarization methods lead to significant accuracy loss in EEG classification.\nIn this paper, we propose a multi-level binarized LSTM, which significantly\nreduces computations whereas ensuring an accuracy pretty close to the full\nprecision LSTM. Our method reduces the delay of the 3-bit LSTM cell operation\n47* with less than 0.01% accuracy loss.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 17:24:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Mirsalari", "Seyed Ahmad", ""], ["Sinaei", "Sima", ""], ["Salehi", "Mostafa E.", ""], ["Daneshtalab", "Masoud", ""]]}, {"id": "2004.08919", "submitter": "Kexin Huang", "authors": "Kexin Huang, Tianfan Fu, Lucas Glass, Marinka Zitnik, Cao Xiao, Jimeng\n  Sun", "title": "DeepPurpose: a Deep Learning Library for Drug-Target Interaction\n  Prediction", "comments": "Published in Bioinformatics (2020)", "journal-ref": null, "doi": "10.1093/bioinformatics/btaa1005", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accurate prediction of drug-target interactions (DTI) is crucial for drug\ndiscovery. Recently, deep learning (DL) models for show promising performance\nfor DTI prediction. However, these models can be difficult to use for both\ncomputer scientists entering the biomedical field and bioinformaticians with\nlimited DL experience. We present DeepPurpose, a comprehensive and easy-to-use\ndeep learning library for DTI prediction. DeepPurpose supports training of\ncustomized DTI prediction models by implementing 15 compound and protein\nencoders and over 50 neural architectures, along with providing many other\nuseful features. We demonstrate state-of-the-art performance of DeepPurpose on\nseveral benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 17:31:55 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 13:10:26 GMT"}, {"version": "v3", "created": "Wed, 9 Dec 2020 23:14:48 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Huang", "Kexin", ""], ["Fu", "Tianfan", ""], ["Glass", "Lucas", ""], ["Zitnik", "Marinka", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""]]}, {"id": "2004.08924", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy and Joseph E. Gonzalez and Michael I. Jordan and\n  Ion Stoica", "title": "Mechanism Design with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a multi-round welfare-maximising mechanism design problem in\ninstances where agents do not know their values. On each round, a mechanism\nassigns an allocation each to a set of agents and charges them a price; then\nthe agents provide (stochastic) feedback to the mechanism for the allocation\nthey received. This is motivated by applications in cloud markets and online\nadvertising where an agent may know her value for an allocation only after\nexperiencing it. Therefore, the mechanism needs to explore different\nallocations for each agent, while simultaneously attempting to find the\nsocially optimal set of allocations. Our focus is on truthful and individually\nrational mechanisms which imitate the classical VCG mechanism in the long run.\nTo that end, we define three notions of regret for the welfare, the individual\nutilities of each agent and that of the mechanism. We show that these three\nterms are interdependent via an $\\Omega(T^{\\frac{2}{3}})$ lower bound for the\nmaximum of these three terms after $T$ rounds of allocations, and describe a\nfamily of anytime algorithms which achieve this rate. Our framework provides\nflexibility to control the pricing scheme so as to trade-off between the agent\nand seller regrets, and additionally to control the degree of truthfulness and\nindividual rationality.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:00:58 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:23:06 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 22:03:03 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Gonzalez", "Joseph E.", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "2004.08925", "submitter": "Benjamin Paassen", "authors": "Benjamin Paassen, Irena Koprinska, Kalina Yacef", "title": "Tree Echo State Autoencoders with Grammars", "comments": "accepted at the 2020 International Joint Conference on Neural\n  Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tree data occurs in many forms, such as computer programs, chemical\nmolecules, or natural language. Unfortunately, the non-vectorial and discrete\nnature of trees makes it challenging to construct functions with tree-formed\noutput, complicating tasks such as optimization or time series prediction.\nAutoencoders address this challenge by mapping trees to a vectorial latent\nspace, where tasks are easier to solve, and then mapping the solution back to a\ntree structure. However, existing autoencoding approaches for tree data fail to\ntake the specific grammatical structure of tree domains into account and rely\non deep learning, thus requiring large training datasets and long training\ntimes. In this paper, we propose tree echo state autoencoders (TES-AE), which\nare guided by a tree grammar and can be trained within seconds by virtue of\nreservoir computing. In our evaluation on three datasets, we demonstrate that\nour proposed approach is not only much faster than a state-of-the-art deep\nlearning autoencoding approach (D-VAE) but also has less autoencoding error if\nlittle data and time is given.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:04:33 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Paassen", "Benjamin", ""], ["Koprinska", "Irena", ""], ["Yacef", "Kalina", ""]]}, {"id": "2004.08930", "submitter": "Bo Li", "authors": "Alexander Mozeika and Bo Li and David Saad", "title": "Space of Functions Computed by Deep-Layered Machines", "comments": null, "journal-ref": "Phys. Rev. Lett. 125, 168301 (2020)", "doi": "10.1103/PhysRevLett.125.168301", "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the space of functions computed by random-layered machines,\nincluding deep neural networks and Boolean circuits. Investigating the\ndistribution of Boolean functions computed on the recurrent and layer-dependent\narchitectures, we find that it is the same in both models. Depending on the\ninitial conditions and computing elements used, we characterize the space of\nfunctions computed at the large depth limit and show that the macroscopic\nentropy of Boolean functions is either monotonically increasing or decreasing\nwith the growing depth.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:31:03 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 21:06:29 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 01:36:46 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Mozeika", "Alexander", ""], ["Li", "Bo", ""], ["Saad", "David", ""]]}, {"id": "2004.08957", "submitter": "Min Gao", "authors": "Min Gao, Yukun Guo, Tristan T. Hormel, Jiande Sun, Thomas Hwang and\n  Yali Jia", "title": "Reconstruction of high-resolution 6x6-mm OCT angiograms using deep\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical optical coherence tomographic angiography (OCTA) acquisition areas on\ncommercial devices are 3x3- or 6x6-mm. Compared to 3x3-mm angiograms with\nproper sampling density, 6x6-mm angiograms have significantly lower scan\nquality, with reduced signal-to-noise ratio and worse shadow artifacts due to\nundersampling. Here, we propose a deep-learning-based high-resolution angiogram\nreconstruction network (HARNet) to generate enhanced 6x6-mm superficial\nvascular complex (SVC) angiograms. The network was trained on data from 3x3-mm\nand 6x6-mm angiograms from the same eyes. The reconstructed 6x6-mm angiograms\nhave significantly lower noise intensity and better vascular connectivity than\nthe original images. The algorithm did not generate false flow signal at the\nnoise level presented by the original angiograms. The image enhancement\nproduced by our algorithm may improve biomarker measurements and qualitative\nclinical assessment of 6x6-mm OCTA.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 20:43:13 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:18:03 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gao", "Min", ""], ["Guo", "Yukun", ""], ["Hormel", "Tristan T.", ""], ["Sun", "Jiande", ""], ["Hwang", "Thomas", ""], ["Jia", "Yali", ""]]}, {"id": "2004.08965", "submitter": "Shengchang Zhang", "authors": "Shengchang Zhang, Jie Xiang, Weijian Han", "title": "Machine Learning based Pallets Detection and Tracking in AGVs", "comments": "6 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.SY eess.IV eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of automated guided vehicles (AGVs) has played a pivotal role in\nmanufacturing and distribution operations, providing reliable and efficient\nproduct handling. In this project, we constructed a deep learning-based pallets\ndetection and tracking architecture for pallets detection and position\ntracking. By using data preprocessing and augmentation techniques and\nexperiment with hyperparameter tuning, we achieved the result with 25%\nreduction of error rate, 28.5% reduction of false negative rate, and 20%\nreduction of training time.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 21:17:13 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Shengchang", ""], ["Xiang", "Jie", ""], ["Han", "Weijian", ""]]}, {"id": "2004.08977", "submitter": "Shengchang Zhang", "authors": "Shengchang Zhang, Ahmed EI Koubia, Khaled Abdul Karim Mohammed", "title": "Traffic Lane Detection using FCN", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic lane detection is a crucial technology that enables self-driving\ncars to properly position themselves in a multi-lane urban driving\nenvironments. However, detecting diverse road markings in various weather\nconditions is a challenging task for conventional image processing or computer\nvision techniques. In recent years, the application of Deep Learning and Neural\nNetworks in this area has proven to be very effective. In this project, we\ndesigned an Encoder- Decoder, Fully Convolutional Network for lane detection.\nThis model was applied to a real-world large scale dataset and achieved a level\nof accuracy that outperformed our baseline model.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 22:25:12 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Shengchang", ""], ["Koubia", "Ahmed EI", ""], ["Mohammed", "Khaled Abdul Karim", ""]]}, {"id": "2004.08981", "submitter": "Daniil Merkulov", "authors": "Daniil Merkulov, Ivan Oseledets", "title": "Stochastic gradient algorithms from ODE splitting perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a different view on stochastic optimization, which goes back to\nthe splitting schemes for approximate solutions of ODE. In this work, we\nprovide a connection between stochastic gradient descent approach and\nfirst-order splitting scheme for ODE. We consider the special case of\nsplitting, which is inspired by machine learning applications and derive a new\nupper bound on the global splitting error for it. We present, that the Kaczmarz\nmethod is the limit case of the splitting scheme for the unit batch SGD for\nlinear least squares problem. We support our findings with systematic empirical\nstudies, which demonstrates, that a more accurate solution of local problems\nleads to the stepsize robustness and provides better convergence in time and\niterations on the softmax regression problem.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 22:45:32 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Merkulov", "Daniil", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2004.08998", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, H. He, T. Yang, X. Wang, R. C. de Lamare", "title": "Study of Diffusion Normalized Least Mean M-estimate Algorithms", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes diffusion normalized least mean M-estimate algorithm based\non the modified Huber function, which can equip distributed networks with\nrobust learning capability in the presence of impulsive interference. In order\nto exploit the system's underlying sparsity to further improve the learning\nperformance, a sparse-aware variant is also developed by incorporating the\n$l_0$-norm of the estimates into the update process. We then analyze the\ntransient, steady-state and stability behaviors of the algorithms in a unified\nframework. In particular, we present an analytical method that is simpler than\nconventional approaches to deal with the score function since it removes the\nrequirements of integrals and Price's theorem. Simulations in various impulsive\nnoise scenarios show that the proposed algorithms are superior to some existing\ndiffusion algorithms and the theoretical results are verifiable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 00:28:41 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yu", "Y.", ""], ["He", "H.", ""], ["Yang", "T.", ""], ["Wang", "X.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "2004.09007", "submitter": "Ahmed Abdelkader", "authors": "Ahmed Abdelkader, Michael J. Curry, Liam Fowl, Tom Goldstein, Avi\n  Schwarzschild, Manli Shu, Christoph Studer, Chen Zhu", "title": "Headless Horseman: Adversarial Attacks on Transfer Learning Models", "comments": "5 pages, 2 figures. Accepted in ICASSP 2020. Code available on\n  https://github.com/zhuchen03/headless-attack.git", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053181", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning facilitates the training of task-specific classifiers using\npre-trained models as feature extractors. We present a family of transferable\nadversarial attacks against such classifiers, generated without access to the\nclassification head; we call these \\emph{headless attacks}. We first\ndemonstrate successful transfer attacks against a victim network using\n\\textit{only} its feature extractor. This motivates the introduction of a\nlabel-blind adversarial attack. This transfer attack method does not require\nany information about the class-label space of the victim. Our attack lowers\nthe accuracy of a ResNet18 trained on CIFAR10 by over 40\\%.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 01:07:45 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Abdelkader", "Ahmed", ""], ["Curry", "Michael J.", ""], ["Fowl", "Liam", ""], ["Goldstein", "Tom", ""], ["Schwarzschild", "Avi", ""], ["Shu", "Manli", ""], ["Studer", "Christoph", ""], ["Zhu", "Chen", ""]]}, {"id": "2004.09010", "submitter": "Imran Razzak Dr", "authors": "Arshia Rehman, Saeeda Naz, Imran Razzak", "title": "Leveraging Big Data Analytics in Healthcare Enhancement: Trends,\n  Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians decisions are becoming more and more evidence-based meaning in no\nother field the big data analytics so promising as in healthcare. Due to the\nsheer size and availability of healthcare data, big data analytics has\nrevolutionized this industry and promises us a world of opportunities. It\npromises us the power of early detection, prediction, prevention and helps us\nto improve the quality of life. Researchers and clinicians are working to\ninhibit big data from having a positive impact on health in the future.\nDifferent tools and techniques are being used to analyze, process, accumulate,\nassimilate and manage large amount of healthcare data either in structured or\nunstructured form. In this paper, we would like to address the need of big data\nanalytics in healthcare: why and how can it help to improve life?. We present\nthe emerging landscape of big data and analytical techniques in the five\nsub-disciplines of healthcare i.e.medical image analysis and imaging\ninformatics, bioinformatics, clinical informatics, public health informatics\nand medical signal analytics. We presents different architectures, advantages\nand repositories of each discipline that draws an integrated depiction of how\ndistinct healthcare activities are accomplished in the pipeline to facilitate\nindividual patients from multiple perspectives. Finally the paper ends with the\nnotable applications and challenges in adoption of big data analytics in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:46:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rehman", "Arshia", ""], ["Naz", "Saeeda", ""], ["Razzak", "Imran", ""]]}, {"id": "2004.09017", "submitter": "Qiao Liu", "authors": "Qiao Liu, Jiaze Xu, Rui Jiang, Wing Hung Wong", "title": "Roundtrip: A Deep Generative Neural Density Estimator", "comments": null, "journal-ref": "Proceedings of the National Academy of Sciences, 2021, 118(15)", "doi": "10.1073/pnas.2101344118", "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Density estimation is a fundamental problem in both statistics and machine\nlearning. In this study, we proposed Roundtrip as a general-purpose neural\ndensity estimator based on deep generative models. Roundtrip retains the\ngenerative power of generative adversarial networks (GANs) but also provides\nestimates of density values. Unlike previous neural density estimators that put\nstringent conditions on the transformation from the latent space to the data\nspace, Roundtrip enables the use of much more general mappings. In a series of\nexperiments, Roundtrip achieves state-of-the-art performance in a diverse range\nof density estimation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 01:47:00 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 02:30:16 GMT"}, {"version": "v3", "created": "Sun, 10 May 2020 06:30:26 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 07:17:33 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Liu", "Qiao", ""], ["Xu", "Jiaze", ""], ["Jiang", "Rui", ""], ["Wong", "Wing Hung", ""]]}, {"id": "2004.09031", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Minxue Tang, Wei Wen, Feng Yan, Daniel Hu, Ang Li, Hai\n  Li, Yiran Chen", "title": "Learning Low-rank Deep Neural Networks via Singular Vector Orthogonality\n  Regularization and Singular Value Sparsification", "comments": "In proceeding of 2020 IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition Workshops (CVPRW). To be presented at EDLCV 2020 workshop\n  co-located with CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural networks (DNNs) often require high memory consumption and\nlarge computational loads. In order to deploy DNN algorithms efficiently on\nedge or mobile devices, a series of DNN compression algorithms have been\nexplored, including factorization methods. Factorization methods approximate\nthe weight matrix of a DNN layer with the multiplication of two or multiple\nlow-rank matrices. However, it is hard to measure the ranks of DNN layers\nduring the training process. Previous works mainly induce low-rank through\nimplicit approximations or via costly singular value decomposition (SVD)\nprocess on every training step. The former approach usually induces a high\naccuracy loss while the latter has a low efficiency. In this work, we propose\nSVD training, the first method to explicitly achieve low-rank DNNs during\ntraining without applying SVD on every step. SVD training first decomposes each\nlayer into the form of its full-rank SVD, then performs training directly on\nthe decomposed weights. We add orthogonality regularization to the singular\nvectors, which ensure the valid form of SVD and avoid gradient\nvanishing/exploding. Low-rank is encouraged by applying sparsity-inducing\nregularizers on the singular values of each layer. Singular value pruning is\napplied at the end to explicitly reach a low-rank model. We empirically show\nthat SVD training can significantly reduce the rank of DNN layers and achieve\nhigher reduction on computation load under the same accuracy, comparing to not\nonly previous factorization methods but also state-of-the-art filter pruning\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 02:40:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yang", "Huanrui", ""], ["Tang", "Minxue", ""], ["Wen", "Wei", ""], ["Yan", "Feng", ""], ["Hu", "Daniel", ""], ["Li", "Ang", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.09034", "submitter": "Damien Teney", "authors": "Damien Teney, Ehsan Abbasnedjad, Anton van den Hengel", "title": "Learning What Makes a Difference from Counterfactual Examples and\n  Gradient Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary challenges limiting the applicability of deep learning is\nits susceptibility to learning spurious correlations rather than the underlying\nmechanisms of the task of interest. The resulting failure to generalise cannot\nbe addressed by simply using more data from the same distribution. We propose\nan auxiliary training objective that improves the generalization capabilities\nof neural networks by leveraging an overlooked supervisory signal found in\nexisting datasets. We use pairs of minimally-different examples with different\nlabels, a.k.a counterfactual or contrasting examples, which provide a signal\nindicative of the underlying causal structure of the task. We show that such\npairs can be identified in a number of existing datasets in computer vision\n(visual question answering, multi-label image classification) and natural\nlanguage processing (sentiment analysis, natural language inference). The new\ntraining objective orients the gradient of a model's decision function with\npairs of counterfactual examples. Models trained with this technique\ndemonstrate improved performance on out-of-distribution test sets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 02:47:49 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Teney", "Damien", ""], ["Abbasnedjad", "Ehsan", ""], ["Hengel", "Anton van den", ""]]}, {"id": "2004.09036", "submitter": "Yefei Zha", "authors": "Yefei Zha, Ruobing Li, Hui Lin", "title": "Gated Convolutional Bidirectional Attention-based Model for Off-topic\n  Spoken Response Detection", "comments": "ACL2020 long paper", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.56", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-topic spoken response detection, the task aiming at predicting whether a\nresponse is off-topic for the corresponding prompt, is important for an\nautomated speaking assessment system. In many real-world educational\napplications, off-topic spoken response detectors are required to achieve high\nrecall for off-topic responses not only on seen prompts but also on prompts\nthat are unseen during training. In this paper, we propose a novel approach for\noff-topic spoken response detection with high off-topic recall on both seen and\nunseen prompts. We introduce a new model, Gated Convolutional Bidirectional\nAttention-based Model (GCBiA), which applies bi-attention mechanism and\nconvolutions to extract topic words of prompts and key-phrases of responses,\nand introduces gated unit and residual connections between major layers to\nbetter represent the relevance of responses and prompts. Moreover, a new\nnegative sampling method is proposed to augment training data. Experiment\nresults demonstrate that our novel approach can achieve significant\nimprovements in detecting off-topic responses with extremely high on-topic\nrecall, for both seen and unseen prompts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 03:16:06 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 02:12:17 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 02:22:50 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2020 07:08:36 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Zha", "Yefei", ""], ["Li", "Ruobing", ""], ["Lin", "Hui", ""]]}, {"id": "2004.09043", "submitter": "Eric Zelikman", "authors": "Eric Zelikman, William Yin, Kenneth Wang", "title": "Learning as Reinforcement: Applying Principles of Neuroscience for More\n  General Reinforcement Learning Agents", "comments": "Originally completed as part of Stanford's CS 234 \"Reinforcement\n  Learning.\" Presented at the California Cognitive Science Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant challenge in developing AI that can generalize well is\ndesigning agents that learn about their world without being told what to learn,\nand apply that learning to challenges with sparse rewards. Moreover, most\ntraditional reinforcement learning approaches explicitly separate learning and\ndecision making in a way that does not correspond to biological learning. We\nimplement an architecture founded in principles of experimental neuroscience,\nby combining computationally efficient abstractions of biological algorithms.\nOur approach is inspired by research on spike-timing dependent plasticity, the\ntransition between short and long term memory, and the role of various\nneurotransmitters in rewarding curiosity. The Neurons-in-a-Box architecture can\nlearn in a wholly generalizable manner, and demonstrates an efficient way to\nbuild and apply representations without explicitly optimizing over a set of\ncriteria or actions. We find it performs well in many environments including\nOpenAI Gym's Mountain Car, which has no reward besides touching a hard-to-reach\nflag on a hill, Inverted Pendulum, where it learns simple strategies to improve\nthe time it holds a pendulum up, a video stream, where it spontaneously learns\nto distinguish an open and closed hand, as well as other environments like\nGoogle Chrome's Dinosaur Game.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 04:06:21 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zelikman", "Eric", ""], ["Yin", "William", ""], ["Wang", "Kenneth", ""]]}, {"id": "2004.09044", "submitter": "Chi Zhang", "authors": "Yixin Zhu, Tao Gao, Lifeng Fan, Siyuan Huang, Mark Edmonds, Hangxin\n  Liu, Feng Gao, Chi Zhang, Siyuan Qi, Ying Nian Wu, Joshua B. Tenenbaum,\n  Song-Chun Zhu", "title": "Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike\n  Common Sense", "comments": "For high quality figures, please refer to\n  http://wellyzhang.github.io/attach/dark.pdf", "journal-ref": "Engineering, Feb, 2020", "doi": "10.1016/j.eng.2020.01.011", "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in deep learning is essentially based on a \"big data for\nsmall tasks\" paradigm, under which massive amounts of data are used to train a\nclassifier for a single narrow task. In this paper, we call for a shift that\nflips this paradigm upside down. Specifically, we propose a \"small data for big\ntasks\" paradigm, wherein a single artificial intelligence (AI) system is\nchallenged to develop \"common sense\", enabling it to solve a wide range of\ntasks with little training data. We illustrate the potential power of this new\nparadigm by reviewing models of common sense that synthesize recent\nbreakthroughs in both machine and human vision. We identify functionality,\nphysics, intent, causality, and utility (FPICU) as the five core domains of\ncognitive AI with humanlike common sense. When taken as a unified concept,\nFPICU is concerned with the questions of \"why\" and \"how\", beyond the dominant\n\"what\" and \"where\" framework for understanding vision. They are invisible in\nterms of pixels but nevertheless drive the creation, maintenance, and\ndevelopment of visual scenes. We therefore coin them the \"dark matter\" of\nvision. Just as our universe cannot be understood by merely studying observable\nmatter, we argue that vision cannot be understood without studying FPICU. We\ndemonstrate the power of this perspective to develop cognitive AI systems with\nhumanlike common sense by showing how to observe and apply FPICU with little\ntraining data to solve a wide range of challenging tasks, including tool use,\nplanning, utility inference, and social learning. In summary, we argue that the\nnext generation of AI must embrace \"dark\" humanlike common sense for solving\nnovel tasks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 04:07:28 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhu", "Yixin", ""], ["Gao", "Tao", ""], ["Fan", "Lifeng", ""], ["Huang", "Siyuan", ""], ["Edmonds", "Mark", ""], ["Liu", "Hangxin", ""], ["Gao", "Feng", ""], ["Zhang", "Chi", ""], ["Qi", "Siyuan", ""], ["Wu", "Ying Nian", ""], ["Tenenbaum", "Joshua B.", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2004.09073", "submitter": "Ranjan Maitra", "authors": "Geoffrey Z. Thompson and Ranjan Maitra", "title": "CatSIM: A Categorical Image Similarity Metric", "comments": "17 pages, 16 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CatSIM, a new similarity metric for binary and multinary two-\nand three-dimensional images and volumes. CatSIM uses a structural similarity\nimage quality paradigm and is robust to small perturbations in location so that\nstructures in similar, but not entirely overlapping, regions of two images are\nrated higher than using simple matching. The metric can also compare arbitrary\nregions inside images. CatSIM is evaluated on artificial data sets, image\nquality assessment surveys and two imaging applications\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 06:03:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Thompson", "Geoffrey Z.", ""], ["Maitra", "Ranjan", ""]]}, {"id": "2004.09112", "submitter": "Hanbaek Lyu", "authors": "Hanbaek Lyu, Christopher Strohmeier, Georg Menz, and Deanna Needell", "title": "COVID-19 Time-series Prediction by Joint Dictionary Learning and Online\n  NMF", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the spread and containment of COVID-19 is a challenge of utmost\nimportance that the broader scientific community is currently facing. One of\nthe main sources of difficulty is that a very limited amount of daily COVID-19\ncase data is available, and with few exceptions, the majority of countries are\ncurrently in the \"exponential spread stage,\" and thus there is scarce\ninformation available which would enable one to predict the phase transition\nbetween spread and containment.\n  In this paper, we propose a novel approach to predicting the spread of\nCOVID-19 based on dictionary learning and online nonnegative matrix\nfactorization (online NMF). The key idea is to learn dictionary patterns of\nshort evolution instances of the new daily cases in multiple countries at the\nsame time, so that their latent correlation structures are captured in the\ndictionary patterns. We first learn such patterns by minibatch learning from\nthe entire time-series and then further adapt them to the time-series by online\nNMF. As we progressively adapt and improve the learned dictionary patterns to\nthe more recent observations, we also use them to make one-step predictions by\nthe partial fitting. Lastly, by recursively applying the one-step predictions,\nwe can extrapolate our predictions into the near future. Our prediction results\ncan be directly attributed to the learned dictionary patterns due to their\ninterpretability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:02:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Lyu", "Hanbaek", ""], ["Strohmeier", "Christopher", ""], ["Menz", "Georg", ""], ["Needell", "Deanna", ""]]}, {"id": "2004.09124", "submitter": "Rahma Chaabouni", "authors": "Rahma Chaabouni, Eugene Kharitonov, Diane Bouchacourt, Emmanuel\n  Dupoux, Marco Baroni", "title": "Compositionality and Generalization in Emergent Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language allows us to refer to novel composite concepts by combining\nexpressions denoting their parts according to systematic rules, a property\nknown as \\emph{compositionality}. In this paper, we study whether the language\nemerging in deep multi-agent simulations possesses a similar ability to refer\nto novel primitive combinations, and whether it accomplishes this feat by\nstrategies akin to human-language compositionality. Equipped with new ways to\nmeasure compositionality in emergent languages inspired by disentanglement in\nrepresentation learning, we establish three main results. First, given\nsufficiently large input spaces, the emergent language will naturally develop\nthe ability to refer to novel composite concepts. Second, there is no\ncorrelation between the degree of compositionality of an emergent language and\nits ability to generalize. Third, while compositionality is not necessary for\ngeneralization, it provides an advantage in terms of language transmission: The\nmore compositional a language is, the more easily it will be picked up by new\nlearners, even when the latter differ in architecture from the original agents.\nWe conclude that compositionality does not arise from simple generalization\npressure, but if an emergent language does chance upon it, it will be more\nlikely to survive and thrive.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:30:14 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Chaabouni", "Rahma", ""], ["Kharitonov", "Eugene", ""], ["Bouchacourt", "Diane", ""], ["Dupoux", "Emmanuel", ""], ["Baroni", "Marco", ""]]}, {"id": "2004.09134", "submitter": "Florenc Demrozi Dr.", "authors": "Florenc Demrozi, Graziano Pravadelli, Patrick J Tighe, Azra Bihorac\n  and Parisa Rashidi", "title": "Joint Distribution and Transitions of Pain and Activity in Critically\n  Ill Patients", "comments": "Accepted for Publication in EMBC 2020", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176453", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain and physical function are both essential indices of recovery in\ncritically ill patients in the Intensive Care Units (ICU). Simultaneous\nmonitoring of pain intensity and patient activity can be important for\ndetermining which analgesic interventions can optimize mobility and function,\nwhile minimizing opioid harm. Nonetheless, so far, our knowledge of the\nrelation between pain and activity has been limited to manual and sporadic\nactivity assessments. In recent years, wearable devices equipped with 3-axis\naccelerometers have been used in many domains to provide a continuous and\nautomated measure of mobility and physical activity. In this study, we\ncollected activity intensity data from 57 ICU patients, using the Actigraph\nGT3X device. We also collected relevant clinical information, including nurse\nassessments of pain intensity, recorded every 1-4 hours. Our results show the\njoint distribution and state transition of joint activity and pain states in\ncritically ill patients.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:56:13 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Demrozi", "Florenc", ""], ["Pravadelli", "Graziano", ""], ["Tighe", "Patrick J", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.09140", "submitter": "Alexey Zaytsev", "authors": "Roman Kail, Alexey Zaytsev, Evgeny Burnaev", "title": "Recurrent Convolutional Neural Networks help to predict location of\n  Earthquakes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the applicability of modern neural network architectures to the\nmidterm prediction of earthquakes. Our data-based classification model aims to\npredict if an earthquake with the magnitude above a threshold takes place at a\ngiven area of size $10 \\times 10$ kilometers in $10$-$60$ days from a given\nmoment. Our deep neural network model has a recurrent part (LSTM) that accounts\nfor time dependencies between earthquakes and a convolutional part that\naccounts for spatial dependencies. Obtained results show that neural\nnetworks-based models beat baseline feature-based models that also account for\nspatio-temporal dependencies between different earthquakes. For historical data\non Japan earthquakes our model predicts occurrence of an earthquake in $10$ to\n$60$ days from a given moment with magnitude $M_c > 5$ with quality metrics ROC\nAUC $0.975$ and PR AUC $0.0890$, making $1.18 \\cdot 10^3$ correct predictions,\nwhile missing $2.09 \\cdot 10^3$ earthquakes and making $192 \\cdot 10^3$ false\nalarms. The baseline approach has similar ROC AUC $0.992$, number of correct\npredictions $1.19 \\cdot 10^3$, and missing $2.07 \\cdot 10^3$ earthquakes, but\nsignificantly worse PR AUC $0.00911$, and number of false alarms $1004 \\cdot\n10^3$.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:05:13 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:25:20 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 14:13:17 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Kail", "Roman", ""], ["Zaytsev", "Alexey", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2004.09141", "submitter": "Jimmy Wu", "authors": "Jimmy Wu, Xingyuan Sun, Andy Zeng, Shuran Song, Johnny Lee, Szymon\n  Rusinkiewicz, Thomas Funkhouser", "title": "Spatial Action Maps for Mobile Manipulation", "comments": "To appear at Robotics: Science and Systems (RSS), 2020. Project page:\n  https://spatial-action-maps.cs.princeton.edu", "journal-ref": null, "doi": "10.15607/RSS.2020.XVI.035", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical end-to-end formulations for learning robotic navigation involve\npredicting a small set of steering command actions (e.g., step forward, turn\nleft, turn right, etc.) from images of the current state (e.g., a bird's-eye\nview of a SLAM reconstruction). Instead, we show that it can be advantageous to\nlearn with dense action representations defined in the same domain as the\nstate. In this work, we present \"spatial action maps,\" in which the set of\npossible actions is represented by a pixel map (aligned with the input image of\nthe current state), where each pixel represents a local navigational endpoint\nat the corresponding scene location. Using ConvNets to infer spatial action\nmaps from state images, action predictions are thereby spatially anchored on\nlocal visual features in the scene, enabling significantly faster learning of\ncomplex behaviors for mobile manipulation tasks with reinforcement learning. In\nour experiments, we task a robot with pushing objects to a goal location, and\nfind that policies learned with spatial action maps achieve much better\nperformance than traditional alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:06:10 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 10:56:49 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Wu", "Jimmy", ""], ["Sun", "Xingyuan", ""], ["Zeng", "Andy", ""], ["Song", "Shuran", ""], ["Lee", "Johnny", ""], ["Rusinkiewicz", "Szymon", ""], ["Funkhouser", "Thomas", ""]]}, {"id": "2004.09148", "submitter": "Fredrik Hellstr\\\"om", "authors": "Fredrik Hellstr\\\"om, Giuseppe Durisi", "title": "Generalization Error Bounds via $m$th Central Moments of the Information\n  Density", "comments": "ISIT 2020. Corrected Corollary 7 and the discussion in section II-D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general approach to deriving bounds on the generalization error\nof randomized learning algorithms. Our approach can be used to obtain bounds on\nthe average generalization error as well as bounds on its tail probabilities,\nboth for the case in which a new hypothesis is randomly generated every time\nthe algorithm is used - as often assumed in the probably approximately correct\n(PAC)-Bayesian literature - and in the single-draw case, where the hypothesis\nis extracted only once. For this last scenario, we present a novel bound that\nis explicit in the central moments of the information density. The bound\nreveals that the higher the order of the information density moment that can be\ncontrolled, the milder the dependence of the generalization bound on the\ndesired confidence level. Furthermore, we use tools from binary hypothesis\ntesting to derive a second bound, which is explicit in the tail of the\ninformation density. This bound confirms that a fast decay of the tail of the\ninformation density yields a more favorable dependence of the generalization\nbound on the confidence level.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:23:49 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:11:09 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hellstr\u00f6m", "Fredrik", ""], ["Durisi", "Giuseppe", ""]]}, {"id": "2004.09152", "submitter": "Fredrik Bagge Carlson", "authors": "Fredrik Bagge Carlson, Mandar Chitre", "title": "New Metrics Between Rational Spectra and their Connection to Optimal\n  Transport", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SP eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a series of metrics between pairs of signals, linear systems or\nrational spectra, based on optimal transport and linear-systems theory. The\nmetrics operate on the locations of the poles of rational functions and admit\nvery efficient computation of distances, barycenters, displacement\ninterpolation and projections. We establish the connection to the Wasserstein\ndistance between rational spectra, and demonstrate the use of the metrics in\ntasks such as signal classification, clustering, detection and approximation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:29:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Carlson", "Fredrik Bagge", ""], ["Chitre", "Mandar", ""]]}, {"id": "2004.09166", "submitter": "Matthias Rath", "authors": "Matthias Rath and Alexandru Paul Condurache", "title": "Invariant Integration in Deep Convolutional Feature Space", "comments": "Accepted at ESANN 2020 (European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this contribution, we show how to incorporate prior knowledge to a deep\nneural network architecture in a principled manner. We enforce feature space\ninvariances using a novel layer based on invariant integration. This allows us\nto construct a complete feature space invariant to finite transformation\ngroups.\n  We apply our proposed layer to explicitly insert invariance properties for\nvision-related classification tasks, demonstrate our approach for the case of\nrotation invariance and report state-of-the-art performance on the\nRotated-MNIST dataset. Our method is especially beneficial when training with\nlimited data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:45:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rath", "Matthias", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2004.09167", "submitter": "Akshay Smit", "authors": "Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Y. Ng,\n  Matthew P. Lungren", "title": "CheXbert: Combining Automatic Labelers and Expert Annotations for\n  Accurate Radiology Report Labeling Using BERT", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of labels from radiology text reports enables large-scale\ntraining of medical imaging models. Existing approaches to report labeling\ntypically rely either on sophisticated feature engineering based on medical\ndomain knowledge or manual annotations by experts. In this work, we introduce a\nBERT-based approach to medical image report labeling that exploits both the\nscale of available rule-based systems and the quality of expert annotations. We\ndemonstrate superior performance of a biomedically pretrained BERT model first\ntrained on annotations of a rule-based labeler and then finetuned on a small\nset of expert annotations augmented with automated backtranslation. We find\nthat our final model, CheXbert, is able to outperform the previous best\nrules-based labeler with statistical significance, setting a new SOTA for\nreport labeling on one of the largest datasets of chest x-rays.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:46:40 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:32:06 GMT"}, {"version": "v3", "created": "Sun, 18 Oct 2020 20:30:22 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Smit", "Akshay", ""], ["Jain", "Saahil", ""], ["Rajpurkar", "Pranav", ""], ["Pareek", "Anuj", ""], ["Ng", "Andrew Y.", ""], ["Lungren", "Matthew P.", ""]]}, {"id": "2004.09169", "submitter": "Andrei-Timotei Ardelean", "authors": "Andrei-Timotei Ardelean, Lucian Mircea Sasu", "title": "Pose Manipulation with Identity Preservation", "comments": "9 pages, journal article", "journal-ref": "International Journal of Computers Communications & Control, Vol\n  15, Nr 2, 3862, 2020", "doi": "10.15837/ijccc.2020.2.3862", "report-no": null, "categories": "cs.CV cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new model which generates images in novel poses e.g.\nby altering face expression and orientation, from just a few instances of a\nhuman subject. Unlike previous approaches which require large datasets of a\nspecific person for training, our approach may start from a scarce set of\nimages, even from a single image. To this end, we introduce Character Adaptive\nIdentity Normalization GAN (CainGAN) which uses spatial characteristic features\nextracted by an embedder and combined across source images. The identity\ninformation is propagated throughout the network by applying conditional\nnormalization. After extensive adversarial training, CainGAN receives figures\nof faces from a certain individual and produces new ones while preserving the\nperson's identity. Experimental results show that the quality of generated\nimages scales with the size of the input set used during inference.\nFurthermore, quantitative measurements indicate that CainGAN performs better\ncompared to other methods when training data is limited.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:51:31 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Ardelean", "Andrei-Timotei", ""], ["Sasu", "Lucian Mircea", ""]]}, {"id": "2004.09179", "submitter": "Julia Lust", "authors": "Julia Lust and Alexandru Paul Condurache", "title": "GraN: An Efficient Gradient-Norm Based Detector for Adversarial and\n  Misclassified Examples", "comments": "Accepted at ESANN 2020 (European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are vulnerable to adversarial examples and other\ndata perturbations. Especially in safety critical applications of DNNs, it is\ntherefore crucial to detect misclassified samples. The current state-of-the-art\ndetection methods require either significantly more runtime or more parameters\nthan the original network itself. This paper therefore proposes GraN, a time-\nand parameter-efficient method that is easily adaptable to any DNN.\n  GraN is based on the layer-wise norm of the DNN's gradient regarding the loss\nof the current input-output combination, which can be computed via\nbackpropagation. GraN achieves state-of-the-art performance on numerous problem\nset-ups.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:09:27 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Lust", "Julia", ""], ["Condurache", "Alexandru Paul", ""]]}, {"id": "2004.09180", "submitter": "Evangelos Pournaras", "authors": "Thomas Asikis, Johannes Klinglmayr, Dirk Helbing, Evangelos Pournaras", "title": "How Value-Sensitive Design Can Empower Sustainable Consumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a so-called overpopulated world, sustainable consumption is of existential\nimportance.However, the expanding spectrum of product choices and their\nproduction complexity challenge consumers to make informed and value-sensitive\ndecisions. Recent approaches based on (personalized) psychological manipulation\nare often intransparent, potentially privacy-invasive and inconsistent with\n(informational) self-determination. In contrast, responsible consumption based\non informed choices currently requires reasoning to an extent that tends to\noverwhelm human cognitive capacity. As a result, a collective shift towards\nsustainable consumption remains a grand challenge. Here we demonstrate a novel\npersonal shopping assistant implemented as a smart phone app that supports a\nvalue-sensitive design and leverages sustainability awareness, using experts'\nknowledge and \"wisdom of the crowd\" for transparent product information and\nexplainable product ratings. Real-world field experiments in two supermarkets\nconfirm higher sustainability awareness and a bottom-up behavioral shift\ntowards more sustainable consumption. These results encourage novel business\nmodels for retailers and producers, ethically aligned with consumer preferences\nand with higher sustainability.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:11:20 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 07:16:28 GMT"}, {"version": "v3", "created": "Thu, 14 May 2020 07:43:13 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 14:56:03 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Asikis", "Thomas", ""], ["Klinglmayr", "Johannes", ""], ["Helbing", "Dirk", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2004.09189", "submitter": "Chen Wu", "authors": "Chen Wu, Prince Zizhuang Wang, William Yang Wang", "title": "On the Encoder-Decoder Incompatibility in Variational Text Modeling and\n  Beyond", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) combine latent variables with amortized\nvariational inference, whose optimization usually converges into a trivial\nlocal optimum termed posterior collapse, especially in text modeling. By\ntracking the optimization dynamics, we observe the encoder-decoder\nincompatibility that leads to poor parameterizations of the data manifold. We\nargue that the trivial local optimum may be avoided by improving the encoder\nand decoder parameterizations since the posterior network is part of a\ntransition map between them. To this end, we propose Coupled-VAE, which couples\na VAE model with a deterministic autoencoder with the same structure and\nimproves the encoder and decoder parameterizations via encoder weight sharing\nand decoder signal matching. We apply the proposed Coupled-VAE approach to\nvarious VAE models with different regularization, posterior family, decoder\nstructure, and optimization strategy. Experiments on benchmark datasets (i.e.,\nPTB, Yelp, and Yahoo) show consistently improved results in terms of\nprobability estimation and richness of the latent space. We also generalize our\nmethod to conditional language modeling and propose Coupled-CVAE, which largely\nimproves the diversity of dialogue generation on the Switchboard dataset.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:34:10 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wu", "Chen", ""], ["Wang", "Prince Zizhuang", ""], ["Wang", "William Yang", ""]]}, {"id": "2004.09199", "submitter": "Xialei Liu", "authors": "Xialei Liu, Chenshen Wu, Mikel Menta, Luis Herranz, Bogdan Raducanu,\n  Andrew D. Bagdanov, Shangling Jui, Joost van de Weijer", "title": "Generative Feature Replay For Class-Incremental Learning", "comments": "Accepted at CVPR2020: Workshop on Continual Learning in Computer\n  Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humans are capable of learning new tasks without forgetting previous ones,\nwhile neural networks fail due to catastrophic forgetting between new and\npreviously-learned tasks. We consider a class-incremental setting which means\nthat the task-ID is unknown at inference time. The imbalance between old and\nnew classes typically results in a bias of the network towards the newest ones.\nThis imbalance problem can either be addressed by storing exemplars from\nprevious tasks, or by using image replay methods. However, the latter can only\nbe applied to toy datasets since image generation for complex datasets is a\nhard problem.\n  We propose a solution to the imbalance problem based on generative feature\nreplay which does not require any exemplars. To do this, we split the network\ninto two parts: a feature extractor and a classifier. To prevent forgetting, we\ncombine generative feature replay in the classifier with feature distillation\nin the feature extractor. Through feature generation, our method reduces the\ncomplexity of generative replay and prevents the imbalance problem. Our\napproach is computationally efficient and scalable to large datasets.\nExperiments confirm that our approach achieves state-of-the-art results on\nCIFAR-100 and ImageNet, while requiring only a fraction of the storage needed\nfor exemplar-based continual learning. Code available at\n\\url{https://github.com/xialeiliu/GFR-IL}.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:58:20 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Liu", "Xialei", ""], ["Wu", "Chenshen", ""], ["Menta", "Mikel", ""], ["Herranz", "Luis", ""], ["Raducanu", "Bogdan", ""], ["Bagdanov", "Andrew D.", ""], ["Jui", "Shangling", ""], ["van de Weijer", "Joost", ""]]}, {"id": "2004.09215", "submitter": "Zhengwei Wang", "authors": "Zhengwei Wang, Qi She, Tejo Chalasani, Aljosa Smolic", "title": "CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture\n  Recognition", "comments": "CVPR 2020 Workshop at Continual Learning (CLVISION)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Egocentric gestures are the most natural form of communication for humans to\ninteract with wearable devices such as VR/AR helmets and glasses. A major issue\nin such scenarios for real-world applications is that may easily become\nnecessary to add new gestures to the system e.g., a proper VR system should\nallow users to customize gestures incrementally. Traditional deep learning\nmethods require storing all previous class samples in the system and training\nthe model again from scratch by incorporating previous samples and new samples,\nwhich costs humongous memory and significantly increases computation over time.\nIn this work, we demonstrate a lifelong 3D convolutional framework --\nc(C)la(a)ss increment(t)al net(Net)work (CatNet), which considers temporal\ninformation in videos and enables lifelong learning for egocentric gesture\nvideo recognition by learning the feature representation of an exemplar set\nselected from previous class samples. Importantly, we propose a two-stream\nCatNet, which deploys RGB and depth modalities to train two separate networks.\nWe evaluate CatNets on a publicly available dataset -- EgoGesture dataset, and\nshow that CatNets can learn many classes incrementally over a long period of\ntime. Results also demonstrate that the two-stream architecture achieves the\nbest performance on both joint training and class incremental training compared\nto 3 other one-stream architectures. The codes and pre-trained models used in\nthis work are provided at https://github.com/villawang/CatNet.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:36:02 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wang", "Zhengwei", ""], ["She", "Qi", ""], ["Chalasani", "Tejo", ""], ["Smolic", "Aljosa", ""]]}, {"id": "2004.09218", "submitter": "Jens Nevens", "authors": "Jens Nevens and Paul Van Eecke and Katrien Beuls", "title": "A Practical Guide to Studying Emergent Communication through Grounded\n  Language Games", "comments": "This paper was officially published at the 'Language Learning for\n  Artificial Agents (L2A2) Symposium' of the 2019 Artificial Intelligence and\n  Simulation of Behaviour (AISB) Convention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how an effective and efficient communication system can\nemerge in a population of agents that need to solve a particular task attracts\nmore and more attention from researchers in many fields, including artificial\nintelligence, linguistics and statistical physics. A common methodology for\nstudying this question consists of carrying out multi-agent experiments in\nwhich a population of agents takes part in a series of scripted and\ntask-oriented communicative interactions, called 'language games'. While each\nindividual language game is typically played by two agents in the population, a\nlarge series of games allows the population to converge on a shared\ncommunication system. Setting up an experiment in which a rich system for\ncommunicating about the real world emerges is a major enterprise, as it\nrequires a variety of software components for running multi-agent experiments,\nfor interacting with sensors and actuators, for conceptualising and\ninterpreting semantic structures, and for mapping between these semantic\nstructures and linguistic utterances. The aim of this paper is twofold. On the\none hand, it introduces a high-level robot interface that extends the Babel\nsoftware system, presenting for the first time a toolkit that provides flexible\nmodules for dealing with each subtask involved in running advanced grounded\nlanguage game experiments. On the other hand, it provides a practical guide to\nusing the toolkit for implementing such experiments, taking a grounded colour\nnaming game experiment as a didactic example.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:48:24 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Nevens", "Jens", ""], ["Van Eecke", "Paul", ""], ["Beuls", "Katrien", ""]]}, {"id": "2004.09219", "submitter": "Pratik Jawanpuria", "authors": "Pratik Jawanpuria, N T V Satya Dev, Anoop Kunchukuttan, Bamdev Mishra", "title": "Learning Geometric Word Meta-Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a geometric framework for learning meta-embeddings of words from\ndifferent embedding sources. Our framework transforms the embeddings into a\ncommon latent space, where, for example, simple averaging of different\nembeddings (of a given word) is more amenable. The proposed latent space arises\nfrom two particular geometric transformations - the orthogonal rotations and\nthe Mahalanobis metric scaling. Empirical results on several word similarity\nand word analogy benchmarks illustrate the efficacy of the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:49:04 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jawanpuria", "Pratik", ""], ["Dev", "N T V Satya", ""], ["Kunchukuttan", "Anoop", ""], ["Mishra", "Bamdev", ""]]}, {"id": "2004.09222", "submitter": "Alexandr Katrutsa", "authors": "Julia Gusak, Larisa Markeeva, Talgat Daulbaev, Alexandr Katrutsa,\n  Andrzej Cichocki, Ivan Oseledets", "title": "Towards Understanding Normalization in Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization is an important and vastly investigated technique in deep\nlearning. However, its role for Ordinary Differential Equation based networks\n(neural ODEs) is still poorly understood. This paper investigates how different\nnormalization techniques affect the performance of neural ODEs. Particularly,\nwe show that it is possible to achieve 93% accuracy in the CIFAR-10\nclassification task, and to the best of our knowledge, this is the highest\nreported accuracy among neural ODEs tested on this problem.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 11:54:55 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 19:43:36 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Gusak", "Julia", ""], ["Markeeva", "Larisa", ""], ["Daulbaev", "Talgat", ""], ["Katrutsa", "Alexandr", ""], ["Cichocki", "Andrzej", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2004.09226", "submitter": "Francesco Cricri", "authors": "Nannan Zou, Honglei Zhang, Francesco Cricri, Hamed R. Tavakoli, Jani\n  Lainema, Emre Aksu, Miska Hannuksela, Esa Rahtu", "title": "End-to-End Learning for Video Frame Compression with Self-Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core components of conventional (i.e., non-learned) video codecs\nconsists of predicting a frame from a previously-decoded frame, by leveraging\ntemporal correlations. In this paper, we propose an end-to-end learned system\nfor compressing video frames. Instead of relying on pixel-space motion (as with\noptical flow), our system learns deep embeddings of frames and encodes their\ndifference in latent space. At decoder-side, an attention mechanism is designed\nto attend to the latent space of frames to decide how different parts of the\nprevious and current frame are combined to form the final predicted current\nframe. Spatially-varying channel allocation is achieved by using importance\nmasks acting on the feature-channels. The model is trained to reduce the\nbitrate by minimizing a loss on importance maps and a loss on the probability\noutput by a context model for arithmetic coding. In our experiments, we show\nthat the proposed system achieves high compression rates and high objective\nvisual quality as measured by MS-SSIM and PSNR. Furthermore, we provide\nablation studies where we highlight the contribution of different components.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 12:11:08 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zou", "Nannan", ""], ["Zhang", "Honglei", ""], ["Cricri", "Francesco", ""], ["Tavakoli", "Hamed R.", ""], ["Lainema", "Jani", ""], ["Aksu", "Emre", ""], ["Hannuksela", "Miska", ""], ["Rahtu", "Esa", ""]]}, {"id": "2004.09251", "submitter": "Luca Ciampi", "authors": "Luca Ciampi and Carlos Santiago and Joao Paulo Costeira and Claudio\n  Gennaro and Giuseppe Amato", "title": "Unsupervised Vehicle Counting via Multiple Camera Domain Adaptation", "comments": "1st International Workshop on New Foundations for Human-Centered AI\n  (NeHuAI) at ECAI-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring vehicle flows in cities is crucial to improve the urban\nenvironment and quality of life of citizens. Images are the best sensing\nmodality to perceive and assess the flow of vehicles in large areas. Current\ntechnologies for vehicle counting in images hinge on large quantities of\nannotated data, preventing their scalability to city-scale as new cameras are\nadded to the system. This is a recurrent problem when dealing with physical\nsystems and a key research area in Machine Learning and AI. We propose and\ndiscuss a new methodology to design image-based vehicle density estimators with\nfew labeled data via multiple camera domain adaptations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:00:46 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 17:34:22 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Ciampi", "Luca", ""], ["Santiago", "Carlos", ""], ["Costeira", "Joao Paulo", ""], ["Gennaro", "Claudio", ""], ["Amato", "Giuseppe", ""]]}, {"id": "2004.09258", "submitter": "Vidit Saxena", "authors": "Vidit Saxena, Joseph E. Gonzalez, and Joakim Jald\\'en", "title": "Thompson Sampling for Linearly Constrained Bandits", "comments": "10 pages, 2 figures, updated version of paper accepted at AISTATS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We address multi-armed bandits (MAB) where the objective is to maximize the\ncumulative reward under a probabilistic linear constraint. For a few real-world\ninstances of this problem, constrained extensions of the well-known Thompson\nSampling (TS) heuristic have recently been proposed. However, finite-time\nanalysis of constrained TS is challenging; as a result, only O(\\sqrt{T}) bounds\non the cumulative reward loss (i.e., the regret) are available. In this paper,\nwe describe LinConTS, a TS-based algorithm for bandits that place a linear\nconstraint on the probability of earning a reward in every round. We show that\nfor LinConTS, the regret as well as the cumulative constraint violations are\nupper bounded by O(\\log T) for the suboptimal arms. We develop a proof\ntechnique that relies on careful analysis of the dual problem and combine it\nwith recent theoretical work on unconstrained TS. Through numerical experiments\non two real-world datasets, we demonstrate that LinConTS outperforms an\nasymptotically optimal upper confidence bound (UCB) scheme in terms of\nsimultaneously minimizing the regret and the violation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:06:35 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 18:34:47 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Saxena", "Vidit", ""], ["Gonzalez", "Joseph E.", ""], ["Jald\u00e9n", "Joakim", ""]]}, {"id": "2004.09263", "submitter": "Ralf Gulde", "authors": "Ralf Gulde, Marc Tuscher, Akos Csiszar, Oliver Riedel and Alexander\n  Verl", "title": "Reinforcement Learning Approach to Vibration Compensation for Dynamic\n  Feed Drive Systems", "comments": null, "journal-ref": null, "doi": "10.1109/AI4I46381.2019.00015", "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vibration compensation is important for many domains. For the machine tool\nindustry it translates to higher machining precision and longer component\nlifetime. Current methods for vibration damping have their shortcomings (e.g.\nneed for accurate dynamic models). In this paper we present a reinforcement\nlearning based approach to vibration compensation applied to a machine tool\naxis. The work describes the problem formulation, the solution, the\nimplementation and experiments using industrial machine tool hardware and\ncontrol system.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 14:22:36 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gulde", "Ralf", ""], ["Tuscher", "Marc", ""], ["Csiszar", "Akos", ""], ["Riedel", "Oliver", ""], ["Verl", "Alexander", ""]]}, {"id": "2004.09274", "submitter": "Hossein Shirazi", "authors": "Ehsan Farzadnia, Hossein Shirazi, Alireza Nowroozi", "title": "A New Intrusion Detection System using the Improved Dendritic Cell\n  Algorithm", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.17223.65442", "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dendritic Cell Algorithm (DCA) as one of the emerging evolutionary\nalgorithms is based on the behavior of the specific immune agents; known as\nDendritic Cells (DCs). DCA has several potentially beneficial features for\nbinary classification problems. In this paper, we aim at providing a new\nversion of this immune-inspired mechanism acts as a semi-supervised classifier\nwhich can be a defensive shield in network intrusion detection problem. Till\nnow, no strategy or idea has already been adopted on the GetAntigen() function\non detection phase, but randomly sampling entails the DCA to provide\nundesirable results in several cycles in each time. This leads to uncertainty.\nWhereas it must be accomplished by biological behaviors of DCs in tissues, we\nhave proposed a novel strategy which exactly acts based on its immunological\nfunctionalities of dendritic cells. The proposed mechanism focuses on two\nitems: First, to obviate the challenge of needing to have a preordered antigen\nset for computing danger signal, and the second, to provide a novel\nimmune-inspired idea in order to non-random data sampling. A variable\nfunctional migration threshold is also computed cycle by cycle that shows\nnecessity of the Migration threshold (MT) flexibility. A significant criterion\nso called capability of intrusion detection (CID) used for tests. All of the\ntests have been performed in a new benchmark dataset named UNSW-NB15.\nExperimental consequences demonstrate that the present schema dominates the\nstandard DCA and has higher CID in comparison with other approaches found in\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 09:21:34 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Farzadnia", "Ehsan", ""], ["Shirazi", "Hossein", ""], ["Nowroozi", "Alireza", ""]]}, {"id": "2004.09275", "submitter": "Zhila Esna Ashari", "authors": "Niloofar Hezarjaribi, Zhila Esna Ashari, James F. Frenzel, Hassan\n  Ghasemzadeh, and Saied Hemati", "title": "Personality Assessment from Text for Machine Commonsense Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents PerSense, a framework to estimate human personality\ntraits based on expressed texts and to use them for commonsense reasoning\nanalysis. The personality assessment approaches include an aggregated\nProbability Density Functions (PDF), and Machine Learning (ML) models. Our goal\nis to demonstrate the feasibility of using machine learning algorithms on\npersonality trait data to predict humans' responses to open-ended commonsense\nquestions. We assess the performance of the PerSense algorithms for personality\nassessment by conducting an experiment focused on Neuroticism, an important\npersonality trait crucial in mental health analysis and suicide prevention by\ncollecting data from a diverse population with different Neuroticism scores.\nOur analysis shows that the algorithms achieve comparable results to the ground\ntruth data. Specifically, the PDF approach achieves 97% accuracy when the\nconfidence factor, the logarithmic ratio of the first to the second guess\nprobability, is greater than 3. Additionally, ML approach obtains its highest\naccuracy, 82.2%, with a multilayer Perceptron classifier. To assess the\nfeasibility of commonsense reasoning analysis, we train ML algorithms to\npredict responses to commonsense questions. Our analysis of data collected with\n300 participants demonstrate that PerSense predicts answers to commonsense\nquestions with 82.3% accuracy using a Random Forest classifier.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 07:30:47 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hezarjaribi", "Niloofar", ""], ["Ashari", "Zhila Esna", ""], ["Frenzel", "James F.", ""], ["Ghasemzadeh", "Hassan", ""], ["Hemati", "Saied", ""]]}, {"id": "2004.09280", "submitter": "Vitaly Vanchurin", "authors": "Vitaly Vanchurin", "title": "Towards a theory of machine learning", "comments": "32 pages, 6 figures, accepted for publication in Machine Learning:\n  Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn hep-th quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a neural network as a septuple consisting of (1) a state vector,\n(2) an input projection, (3) an output projection, (4) a weight matrix, (5) a\nbias vector, (6) an activation map and (7) a loss function. We argue that the\nloss function can be imposed either on the boundary (i.e. input and/or output\nneurons) or in the bulk (i.e. hidden neurons) for both supervised and\nunsupervised systems. We apply the principle of maximum entropy to derive a\ncanonical ensemble of the state vectors subject to a constraint imposed on the\nbulk loss function by a Lagrange multiplier (or an inverse temperature\nparameter). We show that in an equilibrium the canonical partition function\nmust be a product of two factors: a function of the temperature and a function\nof the bias vector and weight matrix. Consequently, the total Shannon entropy\nconsists of two terms which represent respectively a thermodynamic entropy and\na complexity of the neural network. We derive the first and second laws of\nlearning: during learning the total entropy must decrease until the system\nreaches an equilibrium (i.e. the second law), and the increment in the loss\nfunction must be proportional to the increment in the thermodynamic entropy\nplus the increment in the complexity (i.e. the first law). We calculate the\nentropy destruction to show that the efficiency of learning is given by the\nLaplacian of the total free energy which is to be maximized in an optimal\nneural architecture, and explain why the optimization condition is better\nsatisfied in a deep network with a large number of hidden layers. The key\nproperties of the model are verified numerically by training a supervised\nfeedforward neural network using the method of stochastic gradient descent. We\nalso discuss a possibility that the entire universe on its most fundamental\nlevel is a neural network.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 00:41:46 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 17:25:59 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 16:28:07 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 17:41:30 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Vanchurin", "Vitaly", ""]]}, {"id": "2004.09281", "submitter": "James-A. Goulet", "authors": "James-A. Goulet, Luong Ha Nguyen and Saeid Amiri", "title": "Tractable Approximate Gaussian Inference for Bayesian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an analytical method allowing for tractable\napproximate Gaussian inference (TAGI) in Bayesian neural networks. The method\nenables: (1) the analytical inference of the posterior mean vector and diagonal\ncovariance matrix for weights and bias, (2) the end-to-end treatment of\nuncertainty from the input layer to the output, and (3) the online inference of\nmodel parameters using a single observation at a time. The method proposed has\na computational complexity of O(n) with respect to the number of parameters n,\nand the tests performed on regression and classification benchmarks confirm\nthat, for a same network architecture, it matches the performance of existing\nmethods relying on gradient backpropagation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:37:08 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Goulet", "James-A.", ""], ["Nguyen", "Luong Ha", ""], ["Amiri", "Saeid", ""]]}, {"id": "2004.09297", "submitter": "Kaitao Song", "authors": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu and Tie-Yan Liu", "title": "MPNet: Masked and Permuted Pre-training for Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT adopts masked language modeling (MLM) for pre-training and is one of the\nmost successful pre-training models. Since BERT neglects dependency among\npredicted tokens, XLNet introduces permuted language modeling (PLM) for\npre-training to address this problem. However, XLNet does not leverage the full\nposition information of a sentence and thus suffers from position discrepancy\nbetween pre-training and fine-tuning. In this paper, we propose MPNet, a novel\npre-training method that inherits the advantages of BERT and XLNet and avoids\ntheir limitations. MPNet leverages the dependency among predicted tokens\nthrough permuted language modeling (vs. MLM in BERT), and takes auxiliary\nposition information as input to make the model see a full sentence and thus\nreducing the position discrepancy (vs. PLM in XLNet). We pre-train MPNet on a\nlarge-scale dataset (over 160GB text corpora) and fine-tune on a variety of\ndown-streaming tasks (GLUE, SQuAD, etc). Experimental results show that MPNet\noutperforms MLM and PLM by a large margin, and achieves better results on these\ntasks compared with previous state-of-the-art pre-trained methods (e.g., BERT,\nXLNet, RoBERTa) under the same model setting. The code and the pre-trained\nmodels are available at: https://github.com/microsoft/MPNet.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:54:12 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 06:54:52 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Song", "Kaitao", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Lu", "Jianfeng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2004.09304", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Ryan Murray, Matthew Thorpe", "title": "From graph cuts to isoperimetric inequalities: Convergence rates of\n  Cheeger cuts on data clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP cs.CG cs.LG math.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study statistical properties of graph-based clustering\nalgorithms that rely on the optimization of balanced graph cuts, the main\nexample being the optimization of Cheeger cuts. We consider proximity graphs\nbuilt from data sampled from an underlying distribution supported on a generic\nsmooth compact manifold $M$. In this setting, we obtain high probability\nconvergence rates for both the Cheeger constant and the associated Cheeger cuts\ntowards their continuum counterparts. The key technical tools are careful\nestimates of interpolation operators which lift empirical Cheeger cuts to the\ncontinuum, as well as continuum stability estimates for isoperimetric problems.\nTo our knowledge the quantitative estimates obtained here are the first of\ntheir kind.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:58:52 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Murray", "Ryan", ""], ["Thorpe", "Matthew", ""]]}, {"id": "2004.09309", "submitter": "Gil Shomron", "authors": "Gil Shomron, Uri Weiser", "title": "Non-Blocking Simultaneous Multithreading: Embracing the Resiliency of\n  Deep Neural Networks", "comments": "MICRO-53", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.CV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known for their inability to utilize\nunderlying hardware resources due to hardware susceptibility to sparse\nactivations and weights. Even in finer granularities, many of the non-zero\nvalues hold a portion of zero-valued bits that may cause inefficiencies when\nexecuted on hardware. Inspired by conventional CPU simultaneous multithreading\n(SMT) that increases computer resource utilization by sharing them across\nseveral threads, we propose non-blocking SMT (NB-SMT) designated for DNN\naccelerators. Like conventional SMT, NB-SMT shares hardware resources among\nseveral execution flows. Yet, unlike SMT, NB-SMT is non-blocking, as it handles\nstructural hazards by exploiting the algorithmic resiliency of DNNs. Instead of\nopportunistically dispatching instructions while they wait in a reservation\nstation for available hardware, NB-SMT temporarily reduces the computation\nprecision to accommodate all threads at once, enabling a non-blocking\noperation. We demonstrate NB-SMT applicability using SySMT, an NB-SMT-enabled\noutput-stationary systolic array (OS-SA). Compared with a conventional OS-SA, a\n2-threaded SySMT consumes 1.4x the area and delivers 2x speedup with 33% energy\nsavings and less than 1% accuracy degradation of state-of-the-art CNNs with\nImageNet. A 4-threaded SySMT consumes 2.5x the area and delivers, for example,\n3.4x speedup and 39% energy savings with 1% accuracy degradation of 40%-pruned\nResNet-18.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 09:29:56 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 20:54:37 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Shomron", "Gil", ""], ["Weiser", "Uri", ""]]}, {"id": "2004.09317", "submitter": "Federico Paredes-Vall\\'es", "authors": "D. B. de Jong, F. Paredes-Vall\\'es, G. C. H. E. de Croon", "title": "How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired\n  Study", "comments": "16 pages, 15 figures", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3083538", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end trained convolutional neural networks have led to a breakthrough\nin optical flow estimation. The most recent advances focus on improving the\noptical flow estimation by improving the architecture and setting a new\nbenchmark on the publicly available MPI-Sintel dataset. Instead, in this\narticle, we investigate how deep neural networks estimate optical flow. A\nbetter understanding of how these networks function is important for (i)\nassessing their generalization capabilities to unseen inputs, and (ii)\nsuggesting changes to improve their performance. For our investigation, we\nfocus on FlowNetS, as it is the prototype of an encoder-decoder neural network\nfor optical flow estimation. Furthermore, we use a filter identification method\nthat has played a major role in uncovering the motion filters present in animal\nbrains in neuropsychological research. The method shows that the filters in the\ndeepest layer of FlowNetS are sensitive to a variety of motion patterns. Not\nonly do we find translation filters, as demonstrated in animal brains, but\nthanks to the easier measurements in artificial neural networks, we even unveil\ndilation, rotation, and occlusion filters. Furthermore, we find similarities in\nthe refinement part of the network and the perceptual filling-in process which\noccurs in the mammal primary visual cortex.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:08:28 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:16:45 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["de Jong", "D. B.", ""], ["Paredes-Vall\u00e9s", "F.", ""], ["de Croon", "G. C. H. E.", ""]]}, {"id": "2004.09320", "submitter": "Max Ehrlich", "authors": "Max Ehrlich, Larry Davis, Ser-Nam Lim, Abhinav Shrivastava", "title": "Quantization Guided JPEG Artifact Correction", "comments": "Published in the proceedings of ECCV 2020, please see our released\n  code and models at https://gitlab.com/Queuecumber/quantization-guided-ac", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The JPEG image compression algorithm is the most popular method of image\ncompression because of its ability for large compression ratios. However, to\nachieve such high compression, information is lost. For aggressive quantization\nsettings, this leads to a noticeable reduction in image quality. Artifact\ncorrection has been studied in the context of deep neural networks for some\ntime, but the current state-of-the-art methods require a different model to be\ntrained for each quality setting, greatly limiting their practical application.\nWe solve this problem by creating a novel architecture which is parameterized\nby the JPEG files quantization matrix. This allows our single model to achieve\nstate-of-the-art performance over models trained for specific quality settings.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 00:10:08 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:28:51 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Ehrlich", "Max", ""], ["Davis", "Larry", ""], ["Lim", "Ser-Nam", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2004.09338", "submitter": "Venky Soundararajan", "authors": "FNU Shweta, Karthik Murugadoss, Samir Awasthi, AJ Venkatakrishnan,\n  Arjun Puranik, Martin Kang, Brian W. Pickering, John C. O'Horo, Philippe R.\n  Bauer, Raymund R. Razonable, Paschalis Vergidis, Zelalem Temesgen, Stacey\n  Rizza, Maryam Mahmood, Walter R. Wilson, Douglas Challener, Praveen Anand,\n  Matt Liebers, Zainab Doctor, Eli Silvert, Hugo Solomon, Tyler Wagner, Gregory\n  J. Gores, Amy W. Williams, John Halamka, Venky Soundararajan, Andrew D.\n  Badley", "title": "Augmented Curation of Unstructured Clinical Notes from a Massive EHR\n  System Reveals Specific Phenotypic Signature of Impending COVID-19 Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the temporal dynamics of COVID-19 patient phenotypes is\nnecessary to derive fine-grained resolution of pathophysiology. Here we use\nstate-of-the-art deep neural networks over an institution-wide machine\nintelligence platform for the augmented curation of 15.8 million clinical notes\nfrom 30,494 patients subjected to COVID-19 PCR diagnostic testing. By\ncontrasting the Electronic Health Record (EHR)-derived clinical phenotypes of\nCOVID-19-positive (COVIDpos, n=635) versus COVID-19-negative (COVIDneg,\nn=29,859) patients over each day of the week preceding the PCR testing date, we\nidentify anosmia/dysgeusia (37.4-fold), myalgia/arthralgia (2.6-fold), diarrhea\n(2.2-fold), fever/chills (2.1-fold), respiratory difficulty (1.9-fold), and\ncough (1.8-fold) as significantly amplified in COVIDpos over COVIDneg patients.\nThe specific combination of cough and diarrhea has a 3.2-fold amplification in\nCOVIDpos patients during the week prior to PCR testing, and along with\nanosmia/dysgeusia, constitutes the earliest EHR-derived signature of COVID-19\n(4-7 days prior to typical PCR testing date). This study introduces an\nAugmented Intelligence platform for the real-time synthesis of institutional\nknowledge captured in EHRs. The platform holds tremendous potential for scaling\nup curation throughput, with minimal need for retraining underlying neural\nnetworks, thus promising EHR-powered early diagnosis for a broad spectrum of\ndiseases.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 17:10:46 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 19:39:16 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Shweta", "FNU", ""], ["Murugadoss", "Karthik", ""], ["Awasthi", "Samir", ""], ["Venkatakrishnan", "AJ", ""], ["Puranik", "Arjun", ""], ["Kang", "Martin", ""], ["Pickering", "Brian W.", ""], ["O'Horo", "John C.", ""], ["Bauer", "Philippe R.", ""], ["Razonable", "Raymund R.", ""], ["Vergidis", "Paschalis", ""], ["Temesgen", "Zelalem", ""], ["Rizza", "Stacey", ""], ["Mahmood", "Maryam", ""], ["Wilson", "Walter R.", ""], ["Challener", "Douglas", ""], ["Anand", "Praveen", ""], ["Liebers", "Matt", ""], ["Doctor", "Zainab", ""], ["Silvert", "Eli", ""], ["Solomon", "Hugo", ""], ["Wagner", "Tyler", ""], ["Gores", "Gregory J.", ""], ["Williams", "Amy W.", ""], ["Halamka", "John", ""], ["Soundararajan", "Venky", ""], ["Badley", "Andrew D.", ""]]}, {"id": "2004.09342", "submitter": "Joseph Euzebe Tate", "authors": "Liangjie Chen and Joseph Euzebe Tate", "title": "Hot-Starting the Ac Power Flow with Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining good initial conditions to solve the Newton-Raphson (NR) based ac\npower flow (ACPF) problem can be a very difficult task. In this paper, we\npropose a framework to obtain the initial bus voltage magnitude and phase\nvalues that decrease the solution iterations and time for the NR based ACPF\nmodel, using the dc power flow (DCPF) results and one dimensional convolutional\nneural networks (1D CNNs). We generate the dataset used to train the 1D CNNs by\nsampling from a distribution of load demands, and by computing the DCPF and\nACPF results for each sample. Experiments on the IEEE 118-bus and\n\\textsc{Pegase} 2869-bus study systems show that we can achieve 33.56\\% and\n30.06\\% reduction in solution time, and 66.47% and 49.52% reduction in solution\niterations per case, respectively. We include the 1D CNN architectures and the\nhyperparameters used, which can be expanded on by the future studies on this\ntopic.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:42:36 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Chen", "Liangjie", ""], ["Tate", "Joseph Euzebe", ""]]}, {"id": "2004.09345", "submitter": "Satoshi Takabe", "authors": "Satoshi Takabe and Tadashi Wadayama", "title": "Deep Unfolded Multicast Beamforming", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicast beamforming is a promising technique for multicast communication.\nProviding an efficient and powerful beamforming design algorithm is a crucial\nissue because multicast beamforming problems such as a max-min-fair problem are\nNP-hard in general. Recently, deep learning-based approaches have been proposed\nfor beamforming design. Although these approaches using deep neural networks\nexhibit reasonable performance gain compared with conventional\noptimization-based algorithms, their scalability is an emerging problem for\nlarge systems in which beamforming design becomes a more demanding task. In\nthis paper, we propose a novel deep unfolded trainable beamforming design with\nhigh scalability and efficiency. The algorithm is designed by expanding the\nrecursive structure of an existing algorithm based on projections onto convex\nsets and embedding a constant number of trainable parameters to the expanded\nnetwork, which leads to a scalable and stable training process. Numerical\nresults show that the proposed algorithm can accelerate its convergence speed\nby using unsupervised learning, which is a challenging training process for\ndeep unfolding.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:44:43 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Takabe", "Satoshi", ""], ["Wadayama", "Tadashi", ""]]}, {"id": "2004.09347", "submitter": "Abhishek Niranjan", "authors": "Abhishek Niranjan, Mukesh Sharma, Sai Bharath Chandra Gutha, M Ali\n  Basha Shaik", "title": "End-to-End Whisper to Natural Speech Conversion using Modified\n  Transformer Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine recognition of an atypical speech like whispered speech, is a\nchallenging task. We introduce whisper-to-natural-speech conversion using\nsequence-to-sequence approach by proposing enhanced transformer architecture,\nwhich uses both parallel and non-parallel data. We investigate different\nfeatures like Mel frequency cepstral coefficients and smoothed spectral\nfeatures. The proposed networks are trained end-to-end using supervised\napproach for feature-to-feature transformation. Further, we also investigate\nthe effectiveness of embedded auxillary decoder used after N encoder\nsub-layers, trained with the frame-level objective function for identifying\nsource phoneme labels. We show results on opensource wTIMIT and CHAINS datasets\nby measuring word error rate using end-to-end ASR and also BLEU scores for the\ngenerated speech. Alternatively, we also propose a novel method to measure\nspectral shape of it by measuring formant distributions w.r.t. reference\nspeech, as formant divergence metric. We have found whisper-to-natural\nconverted speech formants probability distribution is similar to the\ngroundtruth distribution. To the authors' best knowledge, this is the first\ntime enhanced transformer has been proposed, both with and without auxiliary\ndecoder for whisper-to-natural-speech conversion and vice versa.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 14:47:46 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 07:08:37 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 09:27:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Niranjan", "Abhishek", ""], ["Sharma", "Mukesh", ""], ["Gutha", "Sai Bharath Chandra", ""], ["Shaik", "M Ali Basha", ""]]}, {"id": "2004.09367", "submitter": "Jung-Woo Ha", "authors": "Jung-Woo Ha, Kihyun Nam, Jingu Kang, Sang-Woo Lee, Sohee Yang,\n  Hyunhoon Jung, Eunmi Kim, Hyeji Kim, Soojin Kim, Hyun Ah Kim, Kyoungtae Doh,\n  Chan Kyu Lee, Nako Sung, Sunghun Kim", "title": "ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic\n  Speech Recognition of Contact Centers", "comments": "5 pages, 2 figures, 4 tables, The first two authors equally\n  contributed to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) via call is essential for various\napplications, including AI for contact center (AICC) services. Despite the\nadvancement of ASR, however, most publicly available call-based speech corpora\nsuch as Switchboard are old-fashioned. Also, most existing call corpora are in\nEnglish and mainly focus on open domain dialog or general scenarios such as\naudiobooks. Here we introduce a new large-scale Korean call-based speech corpus\nunder a goal-oriented dialog scenario from more than 11,000 people, i.e.,\nClovaCall corpus. ClovaCall includes approximately 60,000 pairs of a short\nsentence and its corresponding spoken utterance in a restaurant reservation\ndomain. We validate the effectiveness of our dataset with intensive experiments\nusing two standard ASR models. Furthermore, we release our ClovaCall dataset\nand baseline source codes to be available via\nhttps://github.com/ClovaAI/ClovaCall.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:12:29 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 06:53:34 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ha", "Jung-Woo", ""], ["Nam", "Kihyun", ""], ["Kang", "Jingu", ""], ["Lee", "Sang-Woo", ""], ["Yang", "Sohee", ""], ["Jung", "Hyunhoon", ""], ["Kim", "Eunmi", ""], ["Kim", "Hyeji", ""], ["Kim", "Soojin", ""], ["Kim", "Hyun Ah", ""], ["Doh", "Kyoungtae", ""], ["Lee", "Chan Kyu", ""], ["Sung", "Nako", ""], ["Kim", "Sunghun", ""]]}, {"id": "2004.09370", "submitter": "Yuval Dagan", "authors": "Yuval Dagan, Constantinos Daskalakis, Nishanth Dikkala, Anthimos\n  Vardis Kandiros", "title": "Learning Ising models from one or multiple samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been two separate lines of work on estimating Ising models: (1)\nestimating them from multiple independent samples under minimal assumptions\nabout the model's interaction matrix; and (2) estimating them from one sample\nin restrictive settings. We propose a unified framework that smoothly\ninterpolates between these two settings, enabling significantly richer\nestimation guarantees from one, a few, or many samples.\n  Our main theorem provides guarantees for one-sample estimation, quantifying\nthe estimation error in terms of the metric entropy of a family of interaction\nmatrices. As corollaries of our main theorem, we derive bounds when the model's\ninteraction matrix is a (sparse) linear combination of known matrices, or it\nbelongs to a finite set, or to a high-dimensional manifold. In fact, our main\nresult handles multiple independent samples by viewing them as one sample from\na larger model, and can be used to derive estimation bounds that are\nqualitatively similar to those obtained in the afore-described multiple-sample\nliterature. Our technical approach benefits from sparsifying a model's\ninteraction network, conditioning on subsets of variables that make the\ndependencies in the resulting conditional distribution sufficiently weak. We\nuse this sparsification technique to prove strong concentration and\nanti-concentration results for the Ising model, which we believe have\napplications beyond the scope of this paper.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:17:05 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 01:53:59 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 16:27:23 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Dagan", "Yuval", ""], ["Daskalakis", "Constantinos", ""], ["Dikkala", "Nishanth", ""], ["Kandiros", "Anthimos Vardis", ""]]}, {"id": "2004.09376", "submitter": "Liming Zhang", "authors": "Liming Zhang", "title": "Conditional-UNet: A Condition-aware Deep Model for Coherent Human\n  Activity Recognition From Wearables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing human activities from multi-channel time series data collected\nfrom wearable sensors is ever more practical. However, in real-world\nconditions, coherent activities and body movements could happen at the same\ntime, like moving head during walking or sitting. A new problem, so-called\n\"Coherent Human Activity Recognition (Co-HAR)\", is more complicated than normal\nmulti-class classification tasks since signals of different movements are mixed\nand interfered with each other. On the other side, we consider such Co-HAR as a\ndense labelling problem that classify each sample on a time step with a label\nto provide high-fidelity and duration-varied support to applications. In this\npaper, a novel condition-aware deep architecture \"Conditional-UNet\" is\ndeveloped to allow dense labeling for Co-HAR problem. We also contribute a\nfirst-of-its-kind Co-HAR dataset for head movement recognition under walk or\nsit condition for future research. Experiments on head gesture recognition show\nthat our model achieve overall 2%-3% performance gain of F1 score over existing\nstate-of-the-art deep methods, and more importantly, systematic and\ncomprehensive improvements on real head gesture classes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:45:44 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Zhang", "Liming", ""]]}, {"id": "2004.09388", "submitter": "Yu-Feng Li", "authors": "Tong Wei, Feng Shi, Hai Wang, Wei-Wei Tu. Yu-Feng Li", "title": "MixPUL: Consistency-based Augmentation for Positive and Unlabeled\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from positive and unlabeled data (PU learning) is prevalent in\npractical applications where only a couple of examples are positively labeled.\nPrevious PU learning studies typically rely on existing samples such that the\ndata distribution is not extensively explored. In this work, we propose a\nsimple yet effective data augmentation method, coined~\\algo, based on\n\\emph{consistency regularization} which provides a new perspective of using PU\ndata. In particular, the proposed~\\algo~incorporates supervised and\nunsupervised consistency training to generate augmented data. To facilitate\nsupervised consistency, reliable negative examples are mined from unlabeled\ndata due to the absence of negative samples. Unsupervised consistency is\nfurther encouraged between unlabeled datapoints. In addition,~\\algo~reduces\nmargin loss between positive and unlabeled pairs, which explicitly optimizes\nAUC and yields faster convergence. Finally, we conduct a series of studies to\ndemonstrate the effectiveness of consistency regularization. We examined three\nkinds of reliable negative mining methods. We show that~\\algo~achieves an\naveraged improvement of classification error from 16.49 to 13.09 on the\nCIFAR-10 dataset across different positive data amount.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:43:33 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Wei", "Tong", ""], ["Shi", "Feng", ""], ["Wang", "Hai", ""], ["Li", "Wei-Wei Tu. Yu-Feng", ""]]}, {"id": "2004.09392", "submitter": "WaiChing Sun", "authors": "Kun Wang, WaiChing Sun, Qiang Du", "title": "A non-cooperative meta-modeling game for automated third-party\n  calibrating, validating, and falsifying constitutive laws with parallelized\n  adversarial attacks", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113514", "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evaluation of constitutive models, especially for high-risk and\nhigh-regret engineering applications, requires efficient and rigorous\nthird-party calibration, validation and falsification. While there are numerous\nefforts to develop paradigms and standard procedures to validate models,\ndifficulties may arise due to the sequential, manual and often biased nature of\nthe commonly adopted calibration and validation processes, thus slowing down\ndata collections, hampering the progress towards discovering new physics,\nincreasing expenses and possibly leading to misinterpretations of the\ncredibility and application ranges of proposed models. This work attempts to\nintroduce concepts from game theory and machine learning techniques to overcome\nmany of these existing difficulties. We introduce an automated meta-modeling\ngame where two competing AI agents systematically generate experimental data to\ncalibrate a given constitutive model and to explore its weakness, in order to\nimprove experiment design and model robustness through competition. The two\nagents automatically search for the Nash equilibrium of the meta-modeling game\nin an adversarial reinforcement learning framework without human intervention.\nBy capturing all possible design options of the laboratory experiments into a\nsingle decision tree, we recast the design of experiments as a game of\ncombinatorial moves that can be resolved through deep reinforcement learning by\nthe two competing players. Our adversarial framework emulates idealized\nscientific collaborations and competitions among researchers to achieve a\nbetter understanding of the application range of the learned material laws and\nprevent misinterpretations caused by conventional AI-based third-party\nvalidation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 18:43:28 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Kun", ""], ["Sun", "WaiChing", ""], ["Du", "Qiang", ""]]}, {"id": "2004.09395", "submitter": "Minghuan Liu", "authors": "Minghuan Liu, Tairan He, Minkai Xu, Weinan Zhang", "title": "Energy-Based Imitation Learning", "comments": "Correct minor errors. 15 pages (6 pages of supplementary), 8 figures,\n  Accepted by AAMAS-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle a common scenario in imitation learning (IL), where agents try to\nrecover the optimal policy from expert demonstrations without further access to\nthe expert or environment reward signals. Except the simple Behavior Cloning\n(BC) that adopts supervised learning followed by the problem of compounding\nerror, previous solutions like inverse reinforcement learning (IRL) and recent\ngenerative adversarial methods involve a bi-level or alternating optimization\nfor updating the reward function and the policy, suffering from high\ncomputational cost and training instability. Inspired by recent progress in\nenergy-based model (EBM), in this paper, we propose a simplified IL framework\nnamed Energy-Based Imitation Learning (EBIL). Instead of updating the reward\nand policy iteratively, EBIL breaks out of the traditional IRL paradigm by a\nsimple and flexible two-stage solution: first estimating the expert energy as\nthe surrogate reward function through score matching, then utilizing such a\nreward for learning the policy by reinforcement learning algorithms. EBIL\ncombines the idea of both EBM and occupancy measure matching, and via theoretic\nanalysis we reveal that EBIL and Max-Entropy IRL (MaxEnt IRL) approaches are\ntwo sides of the same coin, and thus EBIL could be an alternative of\nadversarial IRL methods. Extensive experiments on qualitative and quantitative\nevaluations indicate that EBIL is able to recover meaningful and interpretative\nreward signals while achieving effective and comparable performance against\nexisting algorithms on IL benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:49:35 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 16:39:21 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2021 13:14:13 GMT"}, {"version": "v4", "created": "Thu, 15 Apr 2021 04:30:35 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Liu", "Minghuan", ""], ["He", "Tairan", ""], ["Xu", "Minkai", ""], ["Zhang", "Weinan", ""]]}, {"id": "2004.09397", "submitter": "Ricardo Cerri", "authors": "Ricardo Cerri, Joel David Costa J\\'unior, Elaine Ribeiro de Faria\n  Paiva and Jo\\~ao Manuel Portela da Gama", "title": "Multi-label Stream Classification with Self-Organizing Maps", "comments": "7 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several learning algorithms have been proposed for offline multi-label\nclassification. However, applications in areas such as traffic monitoring,\nsocial networks, and sensors produce data continuously, the so called data\nstreams, posing challenges to batch multi-label learning. With the lack of\nstationarity in the distribution of data streams, new algorithms are needed to\nonline adapt to such changes (concept drift). Also, in realistic applications,\nchanges occur in scenarios of infinitely delayed labels, where the true classes\nof the arrival instances are never available. We propose an online unsupervised\nincremental method based on self-organizing maps for multi-label stream\nclassification with infinitely delayed labels. In the classification phase, we\nuse a k-nearest neighbors strategy to compute the winning neurons in the maps,\nadapting to concept drift by online adjusting neuron weight vectors and dataset\nlabel cardinality. We predict labels for each instance using the Bayes rule and\nthe outputs of each neuron, adapting the probabilities and conditional\nprobabilities of the classes in the stream. Experiments using synthetic and\nreal datasets show that our method is highly competitive with several ones from\nthe literature, in both stationary and concept drift scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:52:38 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cerri", "Ricardo", ""], ["J\u00fanior", "Joel David Costa", ""], ["Paiva", "Elaine Ribeiro de Faria", ""], ["da Gama", "Jo\u00e3o Manuel Portela", ""]]}, {"id": "2004.09406", "submitter": "Christina Funke", "authors": "Christina M. Funke, Judy Borowski, Karolina Stosio, Wieland Brendel,\n  Thomas S. A. Wallis, Matthias Bethge", "title": "Five Points to Check when Comparing Visual Perception in Humans and\n  Machines", "comments": "V3: minor changes like in published JOV version\n  (https://doi.org/10.1167/jov.21.3.16) V2: New title; added general section\n  (checklist); manuscript restructured such that each case study is one\n  chapter; adversarial examples in first study replaced by different analysis", "journal-ref": "Journal of Vision 21, no. 3 (2021): 16-16", "doi": "10.1167/jov.21.3.16", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of machines to human-level performance in complex recognition\ntasks, a growing amount of work is directed towards comparing information\nprocessing in humans and machines. These studies are an exciting chance to\nlearn about one system by studying the other. Here, we propose ideas on how to\ndesign, conduct and interpret experiments such that they adequately support the\ninvestigation of mechanisms when comparing human and machine perception. We\ndemonstrate and apply these ideas through three case studies. The first case\nstudy shows how human bias can affect how we interpret results, and that\nseveral analytic tools can help to overcome this human reference point. In the\nsecond case study, we highlight the difference between necessary and sufficient\nmechanisms in visual reasoning tasks. Thereby, we show that contrary to\nprevious suggestions, feedback mechanisms might not be necessary for the tasks\nin question. The third case study highlights the importance of aligning\nexperimental conditions. We find that a previously-observed difference in\nobject recognition does not hold when adapting the experiment to make\nconditions more equitable between humans and machines. In presenting a\nchecklist for comparative studies of visual reasoning in humans and machines,\nwe hope to highlight how to overcome potential pitfalls in design or inference.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:05:36 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 08:37:22 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:03:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Funke", "Christina M.", ""], ["Borowski", "Judy", ""], ["Stosio", "Karolina", ""], ["Brendel", "Wieland", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""]]}, {"id": "2004.09416", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Nicolas Skatchkovsky and Osvaldo Simeone", "title": "VOWEL: A Local Online Learning Rule for Recurrent Networks of\n  Probabilistic Spiking Winner-Take-All Circuits", "comments": "14 pages, submitted for possible conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of spiking neurons and Winner-Take-All spiking circuits (WTA-SNNs)\ncan detect information encoded in spatio-temporal multi-valued events. These\nare described by the timing of events of interest, e.g., clicks, as well as by\ncategorical numerical values assigned to each event, e.g., like or dislike.\nOther use cases include object recognition from data collected by neuromorphic\ncameras, which produce, for each pixel, signed bits at the times of\nsufficiently large brightness variations. Existing schemes for training\nWTA-SNNs are limited to rate-encoding solutions, and are hence able to detect\nonly spatial patterns. Developing more general training algorithms for\narbitrary WTA-SNNs inherits the challenges of training (binary) Spiking Neural\nNetworks (SNNs). These amount, most notably, to the non-differentiability of\nthreshold functions, to the recurrent behavior of spiking neural models, and to\nthe difficulty of implementing backpropagation in neuromorphic hardware. In\nthis paper, we develop a variational online local training rule for WTA-SNNs,\nreferred to as VOWEL, that leverages only local pre- and post-synaptic\ninformation for visible circuits, and an additional common reward signal for\nhidden circuits. The method is based on probabilistic generalized linear neural\nmodels, control variates, and variational regularization. Experimental results\non real-world neuromorphic datasets with multi-valued events demonstrate the\nadvantages of WTA-SNNs over conventional binary SNNs trained with\nstate-of-the-art methods, especially in the presence of limited computing\nresources.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:21:18 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jang", "Hyeryung", ""], ["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2004.09434", "submitter": "Barbara Pascal", "authors": "Barbara Pascal and Samuel Vaiter and Nelly Pustelnik and Patrice Abry", "title": "Automated data-driven selection of the hyperparameters for\n  Total-Variation based texture segmentation", "comments": "Submitted to SIAM Imaging Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized Least Squares are widely used in signal and image processing. Yet,\nit suffers from a major limitation since it requires fine-tuning of the\nregularization parameters. Under assumptions on the noise probability\ndistribution, Stein-based approaches provide unbiased estimator of the\nquadratic risk. The Generalized Stein Unbiased Risk Estimator is revisited to\nhandle correlated Gaussian noise without requiring to invert the covariance\nmatrix. Then, in order to avoid expansive grid search, it is necessary to\ndesign algorithmic scheme minimizing the quadratic risk with respect to\nregularization parameters. This work extends the Stein's Unbiased GrAdient\nestimator of the Risk of Deledalle et al. to the case of correlated Gaussian\nnoise, deriving a general automatic tuning of regularization parameters. First,\nthe theoretical asymptotic unbiasedness of the gradient estimator is\ndemonstrated in the case of general correlated Gaussian noise. Then, the\nproposed parameter selection strategy is particularized to fractal texture\nsegmentation, where problem formulation naturally entails inter-scale and\nspatially correlated noise. Numerical assessment is provided, as well as\ndiscussion of the practical issues.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:43:09 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 16:43:41 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Pascal", "Barbara", ""], ["Vaiter", "Samuel", ""], ["Pustelnik", "Nelly", ""], ["Abry", "Patrice", ""]]}, {"id": "2004.09454", "submitter": "Yuan Zhou", "authors": "Nikolai Karpov, Qin Zhang, Yuan Zhou", "title": "Collaborative Top Distribution Identifications with Limited Interaction", "comments": "Accepted for presentation at FOCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following problem in this paper: given a set of $n$\ndistributions, find the top-$m$ ones with the largest means. This problem is\nalso called {\\em top-$m$ arm identifications} in the literature of\nreinforcement learning, and has numerous applications. We study the problem in\nthe collaborative learning model where we have multiple agents who can draw\nsamples from the $n$ distributions in parallel. Our goal is to characterize the\ntradeoffs between the running time of learning process and the number of rounds\nof interaction between agents, which is very expensive in various scenarios. We\ngive optimal time-round tradeoffs, as well as demonstrate complexity\nseparations between top-$1$ arm identification and top-$m$ arm identifications\nfor general $m$ and between fixed-time and fixed-confidence variants. As a\nbyproduct, we also give an algorithm for selecting the distribution with the\n$m$-th largest mean in the collaborative learning model.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:11:20 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 02:31:05 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Karpov", "Nikolai", ""], ["Zhang", "Qin", ""], ["Zhou", "Yuan", ""]]}, {"id": "2004.09466", "submitter": "Elias Chaibub Neto", "authors": "Elias Chaibub Neto", "title": "Causality-aware counterfactual confounding adjustment for feature\n  representations learned by deep models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal modeling has been recognized as a potential solution to many\nchallenging problems in machine learning (ML). Here, we describe how a recently\nproposed counterfactual approach developed to deconfound linear structural\ncausal models can still be used to deconfound the feature representations\nlearned by deep neural network (DNN) models. The key insight is that by\ntraining an accurate DNN using softmax activation at the classification layer,\nand then adopting the representation learned by the last layer prior to the\noutput layer as our features, we have that, by construction, the learned\nfeatures will fit well a (multi-class) logistic regression model, and will be\nlinearly associated with the labels. As a consequence, deconfounding approaches\nbased on simple linear models can be used to deconfound the feature\nrepresentations learned by DNNs. We validate the proposed methodology using\ncolored versions of the MNIST dataset. Our results illustrate how the approach\ncan effectively combat confounding and improve model stability in the context\nof dataset shifts generated by selection biases.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:37:36 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 02:07:04 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 17:31:26 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2020 03:25:16 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Neto", "Elias Chaibub", ""]]}, {"id": "2004.09468", "submitter": "Wojciech Czarnecki", "authors": "Wojciech Marian Czarnecki, Gauthier Gidel, Brendan Tracey, Karl Tuyls,\n  Shayegan Omidshafiei, David Balduzzi, Max Jaderberg", "title": "Real World Games Look Like Spinning Tops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the geometrical properties of real world games (e.g.\nTic-Tac-Toe, Go, StarCraft II). We hypothesise that their geometrical structure\nresemble a spinning top, with the upright axis representing transitive\nstrength, and the radial axis, which corresponds to the number of cycles that\nexist at a particular transitive strength, representing the non-transitive\ndimension. We prove the existence of this geometry for a wide class of real\nworld games, exposing their temporal nature. Additionally, we show that this\nunique structure also has consequences for learning - it clarifies why\npopulations of strategies are necessary for training of agents, and how\npopulation size relates to the structure of the game. Finally, we empirically\nvalidate these claims by using a selection of nine real world two-player\nzero-sum symmetric games, showing 1) the spinning top structure is revealed and\ncan be easily re-constructed by using a new method of Nash clustering to\nmeasure the interaction between transitive and cyclical strategy behaviour, and\n2) the effect that population size has on the convergence in these games.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:41:42 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:41:23 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["Gidel", "Gauthier", ""], ["Tracey", "Brendan", ""], ["Tuyls", "Karl", ""], ["Omidshafiei", "Shayegan", ""], ["Balduzzi", "David", ""], ["Jaderberg", "Max", ""]]}, {"id": "2004.09473", "submitter": "Haiguang Liao", "authors": "Haiguang Liao, Qingyi Dong, Xuliang Dong, Wentai Zhang, Wangyang\n  Zhang, Weiyi Qi, Elias Fallon, Levent Burak Kara", "title": "Attention Routing: track-assignment detailed routing using\n  attention-based reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the physical design of integrated circuits, global and detailed routing\nare critical stages involving the determination of the interconnected paths of\neach net on a circuit while satisfying the design constraints. Existing actual\nrouters as well as routability predictors either have to resort to expensive\napproaches that lead to high computational times, or use heuristics that do not\ngeneralize well. Even though new, learning-based routing methods have been\nproposed to address this need, requirements on labelled data and difficulties\nin addressing complex design rule constraints have limited their adoption in\nadvanced technology node physical design problems. In this work, we propose a\nnew router: attention router, which is the first attempt to solve the\ntrack-assignment detailed routing problem using reinforcement learning. Complex\ndesign rule constraints are encoded into the routing algorithm and an\nattention-model-based REINFORCE algorithm is applied to solve the most critical\nstep in routing: sequencing device pairs to be routed. The attention router and\nits baseline genetic router are applied to solve different commercial advanced\ntechnologies analog circuits problem sets. The attention router demonstrates\ngeneralization ability to unseen problems and is also able to achieve more than\n100 times acceleration over the genetic router without significantly\ncompromising the routing solution quality. We also discover a similarity\nbetween the attention router and the baseline genetic router in terms of\npositive correlations in cost and routing patterns, which demonstrate the\nattention router's ability to be utilized not only as a detailed router but\nalso as a predictor for routability and congestion.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:50:13 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 20:44:33 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Liao", "Haiguang", ""], ["Dong", "Qingyi", ""], ["Dong", "Xuliang", ""], ["Zhang", "Wentai", ""], ["Zhang", "Wangyang", ""], ["Qi", "Weiyi", ""], ["Fallon", "Elias", ""], ["Kara", "Levent Burak", ""]]}, {"id": "2004.09476", "submitter": "Chuang Gan", "authors": "Chuang Gan, Deng Huang, Hang Zhao, Joshua B. Tenenbaum, Antonio\n  Torralba", "title": "Music Gesture for Visual Sound Separation", "comments": "CVPR 2020. Project page: http://music-gesture.csail.mit.edu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent deep learning approaches have achieved impressive performance on\nvisual sound separation tasks. However, these approaches are mostly built on\nappearance and optical flow like motion feature representations, which exhibit\nlimited abilities to find the correlations between audio signals and visual\npoints, especially when separating multiple instruments of the same types, such\nas multiple violins in a scene. To address this, we propose \"Music Gesture,\" a\nkeypoint-based structured representation to explicitly model the body and\nfinger movements of musicians when they perform music. We first adopt a\ncontext-aware graph network to integrate visual semantic context with body\ndynamics, and then apply an audio-visual fusion model to associate body\nmovements with the corresponding audio signals. Experimental results on three\nmusic performance datasets show: 1) strong improvements upon benchmark metrics\nfor hetero-musical separation tasks (i.e. different instruments); 2) new\nability for effective homo-musical separation for piano, flute, and trumpet\nduets, which to our best knowledge has never been achieved with alternative\nmethods. Project page: http://music-gesture.csail.mit.edu.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:53:46 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gan", "Chuang", ""], ["Huang", "Deng", ""], ["Zhao", "Hang", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "2004.09481", "submitter": "Albert Cheu", "authors": "Victor Balcer, Albert Cheu, Matthew Joseph, and Jieming Mao", "title": "Connecting Robust Shuffle Privacy and Pan-Privacy", "comments": "This version removes a uniformity tester which we found does not\n  satisfy pure d.p", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\emph{shuffle model} of differential privacy, data-holding users send\nrandomized messages to a secure shuffler, the shuffler permutes the messages,\nand the resulting collection of messages must be differentially private with\nregard to user data. In the \\emph{pan-private} model, an algorithm processes a\nstream of data while maintaining an internal state that is differentially\nprivate with regard to the stream data. We give evidence connecting these two\napparently different models.\n  Our results focus on \\emph{robustly} shuffle private protocols, whose privacy\nguarantees are not greatly affected by malicious users. First, we give robustly\nshuffle private protocols and upper bounds for counting distinct elements and\nuniformity testing. Second, we use pan-private lower bounds to prove robustly\nshuffle private lower bounds for both problems. Focusing on the dependence on\nthe domain size $k$, we find that robust approximate shuffle privacy and\napproximate pan-privacy have additive error $\\Theta(\\sqrt{k})$ for counting\ndistinct elements. For uniformity testing, we give a robust approximate shuffle\nprivate protocol with sample complexity $\\tilde O(k^{2/3})$ and show that an\n$\\Omega(k^{2/3})$ dependence is necessary for any robust pure shuffle private\ntester. Finally, we show that this connection is useful in both directions: we\ngive a pan-private adaptation of recent work on shuffle private histograms and\nuse it to recover further separations between pan-privacy and interactive local\nprivacy.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:58:14 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 15:07:25 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 22:17:25 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 03:45:00 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Balcer", "Victor", ""], ["Cheu", "Albert", ""], ["Joseph", "Matthew", ""], ["Mao", "Jieming", ""]]}, {"id": "2004.09506", "submitter": "Maciej Skorski", "authors": "Maciej Skorski, Alessandro Temperoni, Martin Theobald", "title": "Revisiting Initialization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proper initialization of weights is crucial for the effective training\nand fast convergence of deep neural networks (DNNs). Prior work in this area\nhas mostly focused on balancing the variance among weights per layer to\nmaintain stability of (i) the input data propagated forwards through the\nnetwork and (ii) the loss gradients propagated backwards, respectively. This\nprevalent heuristic is however agnostic of dependencies among gradients across\nthe various layers and captures only firstorder effects. In this paper, we\npropose and discuss an initialization principle that is based on a rigorous\nestimation of the global curvature of weights across layers by approximating\nand controlling the norm of their Hessian matrix. The proposed approach is more\nsystematic and recovers previous results for DNN activations such as smooth\nfunctions, dropouts, and ReLU. Our experiments on Word2Vec and the MNIST/CIFAR\nimage classification tasks confirm that tracking the Hessian norm is a useful\ndiagnostic tool which helps to more rigorously initialize weights\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:12:56 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 17:55:16 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 17:51:07 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Skorski", "Maciej", ""], ["Temperoni", "Alessandro", ""], ["Theobald", "Martin", ""]]}, {"id": "2004.09508", "submitter": "Reza Pourreza", "authors": "Vijay Veerabadran, Reza Pourreza, Amirhossein Habibian, Taco Cohen", "title": "Adversarial Distortion for Learned Video Compression", "comments": "CVPR Workshops, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel adversarial lossy video compression model.\nAt extremely low bit-rates, standard video coding schemes suffer from\nunpleasant reconstruction artifacts such as blocking, ringing etc. Existing\nlearned neural approaches to video compression have achieved reasonable success\non reducing the bit-rate for efficient transmission and reduce the impact of\nartifacts to an extent. However, they still tend to produce blurred results\nunder extreme compression. In this paper, we present a deep adversarial learned\nvideo compression model that minimizes an auxiliary adversarial distortion\nobjective. We find this adversarial objective to correlate better with human\nperceptual quality judgement relative to traditional quality metrics such as\nMS-SSIM and PSNR. Our experiments using a state-of-the-art learned video\ncompression system demonstrate a reduction of perceptual artifacts and\nreconstruction of detail lost especially under extremely high compression.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 17:06:31 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 01:57:34 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 18:42:25 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Veerabadran", "Vijay", ""], ["Pourreza", "Reza", ""], ["Habibian", "Amirhossein", ""], ["Cohen", "Taco", ""]]}, {"id": "2004.09546", "submitter": "Ali Javed", "authors": "Ali Javed, Byung Suk Lee, Dona M. Rizzo", "title": "A Benchmark Study on Time Series Clustering", "comments": "Typos corrected, figures resolution changed", "journal-ref": "Machine Learning with Applications, 1:100001, 2020", "doi": "10.1016/j.mlwa.2020.100001", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first time series clustering benchmark utilizing all\ntime series datasets currently available in the University of California\nRiverside (UCR) archive -- the state of the art repository of time series data.\nSpecifically, the benchmark examines eight popular clustering methods\nrepresenting three categories of clustering algorithms (partitional,\nhierarchical and density-based) and three types of distance measures\n(Euclidean, dynamic time warping, and shape-based). We lay out six restrictions\nwith special attention to making the benchmark as unbiased as possible. A\nphased evaluation approach was then designed for summarizing dataset-level\nassessment metrics and discussing the results. The benchmark study presented\ncan be a useful reference for the research community on its own; and the\ndataset-level assessment metrics reported may be used for designing evaluation\nframeworks to answer different research questions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:06:42 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 16:15:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Javed", "Ali", ""], ["Lee", "Byung Suk", ""], ["Rizzo", "Dona M.", ""]]}, {"id": "2004.09557", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "SoCal: Selective Oracle Questioning for Consistency-based Active\n  Learning of Cardiac Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ubiquity and rate of collection of cardiac signals produce large,\nunlabelled datasets. Active learning (AL) can exploit such datasets by\nincorporating human annotators (oracles) to improve generalization performance.\nHowever, the over-reliance of existing algorithms on oracles continues to\nburden physicians. To minimize this burden, we propose SoCal, a\nconsistency-based AL framework that dynamically determines whether to request a\nlabel from an oracle or to generate a pseudo-label instead. We show that our\nframework decreases the labelling burden while maintaining strong performance,\neven in the presence of a noisy oracle.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:20:03 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 18:49:00 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.09563", "submitter": "Yingyu Liang", "authors": "Hui Yuan, Yingyu Liang", "title": "Learning Entangled Single-Sample Distributions via Iterative Trimming", "comments": "Updated on AISTAT 2020 camera-ready: added comments on existing work\n  at the end of Section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of entangled single-sample distributions, the goal is to\nestimate some common parameter shared by a family of distributions, given one\n\\emph{single} sample from each distribution. We study mean estimation and\nlinear regression under general conditions, and analyze a simple and\ncomputationally efficient method based on iteratively trimming samples and\nre-estimating the parameter on the trimmed sample set. We show that the method\nin logarithmic iterations outputs an estimation whose error only depends on the\nnoise level of the $\\lceil \\alpha n \\rceil$-th noisiest data point where\n$\\alpha$ is a constant and $n$ is the sample size. This means it can tolerate a\nconstant fraction of high-noise points. These are the first such results for\nthe method under our general conditions. It also justifies the wide application\nand empirical success of iterative trimming in practice. Our theoretical\nresults are complemented by experiments on synthetic data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:37:43 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 16:04:55 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Yuan", "Hui", ""], ["Liang", "Yingyu", ""]]}, {"id": "2004.09565", "submitter": "Daniel Obmann", "authors": "Daniel Obmann, Linh Nguyen, Johannes Schwab, Markus Haltmeier", "title": "Sparse aNETT for Solving Inverse Problems with Deep Learning", "comments": "The original proceeding is part of the ISBI 2020 and only contains 4\n  pages due to page restrictions", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a sparse reconstruction framework (aNETT) for solving inverse\nproblems. Opposed to existing sparse reconstruction techniques that are based\non linear sparsifying transforms, we train an autoencoder network $D \\circ E$\nwith $E$ acting as a nonlinear sparsifying transform and minimize a Tikhonov\nfunctional with learned regularizer formed by the $\\ell^q$-norm of the encoder\ncoefficients and a penalty for the distance to the data manifold. We propose a\nstrategy for training an autoencoder based on a sample set of the underlying\nimage class such that the autoencoder is independent of the forward operator\nand is subsequently adapted to the specific forward model. Numerical results\nare presented for sparse view CT, which clearly demonstrate the feasibility,\nrobustness and the improved generalization capability and stability of aNETT\nover post-processing networks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:43:13 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Obmann", "Daniel", ""], ["Nguyen", "Linh", ""], ["Schwab", "Johannes", ""], ["Haltmeier", "Markus", ""]]}, {"id": "2004.09569", "submitter": "Moritz Wolter", "authors": "Moritz Wolter (Bonn University, Fraunhofer Center for Machine Learning\n  and SCAI) and Shaohui Lin (National University of Singapore) and Angela Yao\n  (National University of Singapore)", "title": "Neural network compression via learnable wavelet transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wavelets are well known for data compression, yet have rarely been applied to\nthe compression of neural networks. This paper shows how the fast wavelet\ntransform can be used to compress linear layers in neural networks. Linear\nlayers still occupy a significant portion of the parameters in recurrent neural\nnetworks (RNNs). Through our method, we can learn both the wavelet bases and\ncorresponding coefficients to efficiently represent the linear layers of RNNs.\nOur wavelet compressed RNNs have significantly fewer parameters yet still\nperform competitively with the state-of-the-art on synthetic and real-world RNN\nbenchmarks. Wavelet optimization adds basis flexibility, without large numbers\nof extra weights. Source code is available at\nhttps://github.com/v0lta/Wavelet-network-compression.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 18:52:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 14:49:49 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 11:59:07 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Wolter", "Moritz", "", "Bonn University, Fraunhofer Center for Machine Learning\n  and SCAI"], ["Lin", "Shaohui", "", "National University of Singapore"], ["Yao", "Angela", "", "National University of Singapore"]]}, {"id": "2004.09575", "submitter": "Shan Huang", "authors": "Shan Huang, William Klein, Harvey Gould", "title": "Predicting nucleation near the spinodal in the Ising model using machine\n  learning", "comments": null, "journal-ref": "Phys. Rev. E 103, 033305 (2021)", "doi": "10.1103/PhysRevE.103.033305", "report-no": null, "categories": "physics.comp-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a Convolutional Neural Network (CNN) and two logistic regression\nmodels to predict the probability of nucleation in the two-dimensional Ising\nmodel. The three models successfully predict the probability for the Nearest\nNeighbor Ising model for which classical nucleation is observed. The CNN\noutperforms the logistic regression models near the spinodal of the Long Range\nIsing model, but the accuracy of its predictions decreases as the quenches\napproach the spinodal. Occlusion analysis suggests that this decrease is due to\nthe vanishing difference between the density of the nucleating droplet and the\nbackground. Our results are consistent with the general conclusion that\npredictability decreases near a critical point.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:04:38 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 16:25:15 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Huang", "Shan", ""], ["Klein", "William", ""], ["Gould", "Harvey", ""]]}, {"id": "2004.09576", "submitter": "Yash Bhalgat", "authors": "Yash Bhalgat, Jinwon Lee, Markus Nagel, Tijmen Blankevoort, Nojun Kwak", "title": "LSQ+: Improving low-bit quantization through learnable offsets and\n  better initialization", "comments": "Camera-ready for Joint Workshop on Efficient Deep Learning in\n  Computer Vision, CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unlike ReLU, newer activation functions (like Swish, H-swish, Mish) that are\nfrequently employed in popular efficient architectures can also result in\nnegative activation values, with skewed positive and negative ranges. Typical\nlearnable quantization schemes [PACT, LSQ] assume unsigned quantization for\nactivations and quantize all negative activations to zero which leads to\nsignificant loss in performance. Naively using signed quantization to\naccommodate these negative values requires an extra sign bit which is expensive\nfor low-bit (2-, 3-, 4-bit) quantization. To solve this problem, we propose\nLSQ+, a natural extension of LSQ, wherein we introduce a general asymmetric\nquantization scheme with trainable scale and offset parameters that can learn\nto accommodate the negative activations. Gradient-based learnable quantization\nschemes also commonly suffer from high instability or variance in the final\ntraining performance, hence requiring a great deal of hyper-parameter tuning to\nreach a satisfactory performance. LSQ+ alleviates this problem by using an\nMSE-based initialization scheme for the quantization parameters. We show that\nthis initialization leads to significantly lower variance in final performance\nacross multiple training runs. Overall, LSQ+ shows state-of-the-art results for\nEfficientNet and MixNet and also significantly outperforms LSQ for low-bit\nquantization of neural nets with Swish activations (e.g.: 1.8% gain with W4A4\nquantization and upto 5.6% gain with W2A2 quantization of EfficientNet-B0 on\nImageNet dataset). To the best of our knowledge, ours is the first work to\nquantize such architectures to extremely low bit-widths.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:04:51 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Bhalgat", "Yash", ""], ["Lee", "Jinwon", ""], ["Nagel", "Markus", ""], ["Blankevoort", "Tijmen", ""], ["Kwak", "Nojun", ""]]}, {"id": "2004.09578", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "CLOPS: Continual Learning of Physiological Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms are known to experience destructive interference\nwhen instances violate the assumption of being independent and identically\ndistributed (i.i.d). This violation, however, is ubiquitous in clinical\nsettings where data are streamed temporally and from a multitude of\nphysiological sensors. To overcome this obstacle, we propose CLOPS, a\nreplay-based continual learning strategy. In three continual learning scenarios\nbased on three publically-available datasets, we show that CLOPS can outperform\nthe state-of-the-art methods, GEM and MIR. Moreover, we propose end-to-end\ntrainable parameters, which we term task-instance parameters, that can be used\nto quantify task difficulty and similarity. This quantification yields insights\ninto both network interpretability and clinical applications, where task\ndifficulty is poorly quantified.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:09:18 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 17:05:08 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.09579", "submitter": "Qingchun Hou", "authors": "Qingchun Hou, Ning Zhang, Daniel S. Kirschen, Ershun Du, Yaohua Cheng,\n  Chongqing Kang", "title": "Sparse Oblique Decision Tree for Power System Security Rules Extraction\n  and Embedding", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the penetration of variable generation has a substantial effect on\nthe operational reliability of power systems. The higher level of uncertainty\nthat stems from this variability makes it more difficult to determine whether a\ngiven operating condition will be secure or insecure. Data-driven techniques\nprovide a promising way to identify security rules that can be embedded in\neconomic dispatch model to keep power system operating states secure. This\npaper proposes using a sparse weighted oblique decision tree to learn accurate,\nunderstandable, and embeddable security rules that are linear and can be\nextracted as sparse matrices using a recursive algorithm. These matrices can\nthen be easily embedded as security constraints in power system economic\ndispatch calculations using the Big-M method. Tests on several large datasets\nwith high renewable energy penetration demonstrate the effectiveness of the\nproposed method. In particular, the sparse weighted oblique decision tree\noutperforms the state-of-art weighted oblique decision tree while keeping the\nsecurity rules simple. When embedded in the economic dispatch, these rules\nsignificantly increase the percentage of secure states and reduce the average\nsolution time.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:11:41 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hou", "Qingchun", ""], ["Zhang", "Ning", ""], ["Kirschen", "Daniel S.", ""], ["Du", "Ershun", ""], ["Cheng", "Yaohua", ""], ["Kang", "Chongqing", ""]]}, {"id": "2004.09589", "submitter": "Timothy Chu", "authors": "Timothy Chu and Gary L. Miller and Noel J. Walkington and Alex L. Wang", "title": "Weighted Cheeger and Buser Inequalities, with Applications to Clustering\n  and Cutting Probability Densities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how sparse or isoperimetric cuts of a probability\ndensity function relate to Cheeger cuts of its principal eigenfunction, for\nappropriate definitions of `sparse cut' and `principal eigenfunction'.\n  We construct these appropriate definitions of sparse cut and principal\neigenfunction in the probability density setting. Then, we prove Cheeger and\nBuser type inequalities similar to those for the normalized graph Laplacian of\nAlon-Milman. We demonstrate that no such inequalities hold for most prior\ndefinitions of sparse cut and principal eigenfunction. We apply this result to\ngenerate novel algorithms for cutting probability densities and clustering\ndata, including a principled variant of spectral clustering.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:31:25 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:21:30 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 15:40:42 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Chu", "Timothy", ""], ["Miller", "Gary L.", ""], ["Walkington", "Noel J.", ""], ["Wang", "Alex L.", ""]]}, {"id": "2004.09602", "submitter": "Patrick Judd", "authors": "Hao Wu, Patrick Judd, Xiaojie Zhang, Mikhail Isaev, Paulius\n  Micikevicius", "title": "Integer Quantization for Deep Learning Inference: Principles and\n  Empirical Evaluation", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization techniques can reduce the size of Deep Neural Networks and\nimprove inference latency and throughput by taking advantage of high throughput\ninteger instructions. In this paper we review the mathematical aspects of\nquantization parameters and evaluate their choices on a wide range of neural\nnetwork models for different application domains, including vision, speech, and\nlanguage. We focus on quantization techniques that are amenable to acceleration\nby processors with high-throughput integer math pipelines. We also present a\nworkflow for 8-bit quantization that is able to maintain accuracy within 1% of\nthe floating-point baseline on all networks studied, including models that are\nmore difficult to quantize, such as MobileNets and BERT-large.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 19:59:22 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wu", "Hao", ""], ["Judd", "Patrick", ""], ["Zhang", "Xiaojie", ""], ["Isaev", "Mikhail", ""], ["Micikevicius", "Paulius", ""]]}, {"id": "2004.09607", "submitter": "Tuan Dinh", "authors": "Viet Lam Phung, Phan Huy Kinh, Anh Tuan Dinh, Quoc Bao Nguyen", "title": "Data Processing for Optimizing Naturalness of Vietnamese Text-to-speech\n  System", "comments": "8 pages, 2 figures, submit to Oriental Cocosda", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract End-to-end text-to-speech (TTS) systems has proved its great success\nin the presence of a large amount of high-quality training data recorded in\nanechoic room with high-quality microphone. Another approach is to use\navailable source of found data like radio broadcast news. We aim to optimize\nthe naturalness of TTS system on the found data using a novel data processing\nmethod. The data processing method includes 1) utterance selection and 2)\nprosodic punctuation insertion to prepare training data which can optimize the\nnaturalness of TTS systems. We showed that using the processing data method, an\nend-to-end TTS achieved a mean opinion score (MOS) of 4.1 compared to 4.3 of\nnatural speech. We showed that the punctuation insertion contributed the most\nto the result. To facilitate the research and development of TTS systems, we\ndistributed the processed data of one speaker at\nhttps://forms.gle/6Hk5YkqgDxAaC2BU6.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:11:53 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Phung", "Viet Lam", ""], ["Kinh", "Phan Huy", ""], ["Dinh", "Anh Tuan", ""], ["Nguyen", "Quoc Bao", ""]]}, {"id": "2004.09608", "submitter": "Kimon Fountoulakis", "authors": "K. Fountoulakis, M. Liu, D. F. Gleich, and M. W. Mahoney", "title": "Flow-based Algorithms for Improving Clusters: A Unifying Framework,\n  Software, and Performance", "comments": "71 Pages, 21 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering points in a vector space or nodes in a graph is a ubiquitous\nprimitive in statistical data analysis, and it is commonly used for exploratory\ndata analysis. In practice, it is often of interest to \"refine\" or \"improve\" a\ngiven cluster that has been obtained by some other method. In this survey, we\nfocus on principled algorithms for this cluster improvement problem. Many such\ncluster improvement algorithms are flow-based methods, by which we mean that\noperationally they require the solution of a sequence of maximum flow problems\non a (typically implicitly) modified data graph. These cluster improvement\nalgorithms are powerful, both in theory and in practice, but they have not been\nwidely adopted for problems such as community detection, local graph\nclustering, semi-supervised learning, etc. Possible reasons for this are: the\nsteep learning curve for these algorithms; the lack of efficient and easy to\nuse software; and the lack of detailed numerical experiments on real-world data\nthat demonstrate their usefulness. Our objective here is to address these\nissues. To do so, we guide the reader through the whole process of\nunderstanding how to implement and apply these powerful algorithms. We present\na unifying fractional programming optimization framework that permits us to\ndistill out in a simple way the crucial components of all these algorithms. It\nalso makes apparent similarities and differences between related methods.\nViewing these cluster improvement algorithms via a fractional programming\nframework suggests directions for future algorithm development. Finally, we\ndevelop efficient implementations of these algorithms in our\nLocalGraphClustering python package, and we perform extensive numerical\nexperiments to demonstrate the performance of these methods on social networks\nand image-based data graphs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:14:00 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 05:23:40 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Fountoulakis", "K.", ""], ["Liu", "M.", ""], ["Gleich", "D. F.", ""], ["Mahoney", "M. W.", ""]]}, {"id": "2004.09610", "submitter": "Valery Vishnevskiy", "authors": "Valery Vishnevskiy, Jonas Walheim, Sebastian Kozerke", "title": "Deep variational network for rapid 4D flow MRI reconstruction", "comments": "15 pages, 6 figures", "journal-ref": "Nature Machine Intelligence 2, 228-235 (2020)", "doi": "10.1038/s42256-020-0165-6", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase-contrast magnetic resonance imaging (MRI) provides time-resolved\nquantification of blood flow dynamics that can aid clinical diagnosis. Long in\nvivo scan times due to repeated three-dimensional (3D) volume sampling over\ncardiac phases and breathing cycles necessitate accelerated imaging techniques\nthat leverage data correlations. Standard compressed sensing reconstruction\nmethods require tuning of hyperparameters and are computationally expensive,\nwhich diminishes the potential reduction of examination times. We propose an\nefficient model-based deep neural reconstruction network and evaluate its\nperformance on clinical aortic flow data. The network is shown to reconstruct\nundersampled 4D flow MRI data in under a minute on standard consumer hardware.\nRemarkably, the relatively low amounts of tunable parameters allowed the\nnetwork to be trained on images from 11 reference scans while generalizing well\nto retrospective and prospective undersampled data for various acceleration\nfactors and anatomies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:17:49 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Vishnevskiy", "Valery", ""], ["Walheim", "Jonas", ""], ["Kozerke", "Sebastian", ""]]}, {"id": "2004.09612", "submitter": "Ricardo Bessa Dr.", "authors": "Carla Gon\\c{c}alves and Ricardo J. Bessa and Pierre Pinson", "title": "A Critical Overview of Privacy-Preserving Approaches for Collaborative\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation between different data owners may lead to an improvement in\nforecast quality - for instance by benefiting from spatial-temporal\ndependencies in geographically distributed time series. Due to business\ncompetitive factors and personal data protection questions, said data owners\nmight be unwilling to share their data, which increases the interest in\ncollaborative privacy-preserving forecasting. This paper analyses the\nstate-of-the-art and unveils several shortcomings of existing methods in\nguaranteeing data privacy when employing Vector Autoregressive (VAR) models.\nThe paper also provides mathematical proofs and numerical analysis to evaluate\nexisting privacy-preserving methods, dividing them into three groups: data\ntransformation, secure multi-party computations, and decomposition methods. The\nanalysis shows that state-of-the-art techniques have limitations in preserving\ndata privacy, such as a trade-off between privacy and forecasting accuracy,\nwhile the original data in iterative model fitting processes, in which\nintermediate results are shared, can be inferred after some iterations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:21:04 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 21:08:19 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 09:54:50 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 08:56:09 GMT"}, {"version": "v5", "created": "Fri, 22 May 2020 10:09:04 GMT"}, {"version": "v6", "created": "Sat, 10 Oct 2020 12:37:17 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Gon\u00e7alves", "Carla", ""], ["Bessa", "Ricardo J.", ""], ["Pinson", "Pierre", ""]]}, {"id": "2004.09628", "submitter": "James Ferlez", "authors": "James Ferlez and Xiaowu Sun and Yasser Shoukry", "title": "Two-Level Lattice Neural Network Architectures for Control of Nonlinear\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of automatically designing a Rectified\nLinear Unit (ReLU) Neural Network (NN) architecture (number of layers and\nnumber of neurons per layer) with the guarantee that it is sufficiently\nparametrized to control a nonlinear system. Whereas current state-of-the-art\ntechniques are based on hand-picked architectures or heuristic based search to\nfind such NN architectures, our approach exploits the given model of the system\nto design an architecture; as a result, we provide a guarantee that the\nresulting NN architecture is sufficient to implement a controller that\nsatisfies an achievable specification. Our approach exploits two basic ideas.\nFirst, assuming that the system can be controlled by an unknown\nLipschitz-continuous state-feedback controller with some Lipschitz constant\nupper-bounded by $K_\\text{cont}$, we bound the number of affine functions\nneeded to construct a Continuous Piecewise Affine (CPWA) function that can\napproximate the unknown Lipschitz-continuous controller. Second, we utilize the\nauthors' recent results on a novel NN architecture named as the Two-Level\nLattice (TLL) NN architecture, which was shown to be capable of implementing\nany CPWA function just from the knowledge of the number of affine functions\nthat compromises this CPWA function.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 20:45:08 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 18:24:51 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ferlez", "James", ""], ["Sun", "Xiaowu", ""], ["Shoukry", "Yasser", ""]]}, {"id": "2004.09646", "submitter": "Qing Zhou", "authors": "Bingling Wang and Qing Zhou", "title": "Causal network learning with non-invertible functional relationships", "comments": null, "journal-ref": "Computational Statistics and Data Analysis, 156: 107141 (2021)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of causal relationships from observational data is an important\nproblem in many areas. Several recent results have established the\nidentifiability of causal DAGs with non-Gaussian and/or nonlinear structural\nequation models (SEMs). In this paper, we focus on nonlinear SEMs defined by\nnon-invertible functions, which exist in many data domains, and propose a novel\ntest for non-invertible bivariate causal models. We further develop a method to\nincorporate this test in structure learning of DAGs that contain both linear\nand nonlinear causal relations. By extensive numerical comparisons, we show\nthat our algorithms outperform existing DAG learning methods in identifying\ncausal graphical structures. We illustrate the practical application of our\nmethod in learning causal networks for combinatorial binding of transcription\nfactors from ChIP-Seq data.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:32:05 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Bingling", ""], ["Zhou", "Qing", ""]]}, {"id": "2004.09655", "submitter": "Gustavo H. A. Santos", "authors": "Ananda Streit, Gustavo H. A. Santos, Rosa Le\\~ao, Edmundo de Souza e\n  Silva, Daniel Menasch\\'e, Don Towsley", "title": "Network Anomaly Detection based on Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting anomalies in time series from network measurements\nhas been widely studied and is a topic of fundamental importance. Many anomaly\ndetection methods are based on packet inspection collected at the network core\nrouters, with consequent disadvantages in terms of computational cost and\nprivacy. We propose an alternative method in which packet header inspection is\nnot needed. The method is based on the extraction of a normal subspace obtained\nby the tensor decomposition technique considering the correlation between\ndifferent metrics. We propose a new approach for online tensor decomposition\nwhere changes in the normal subspace can be tracked efficiently. Another\nadvantage of our proposal is the interpretability of the obtained models. The\nflexibility of the method is illustrated by applying it to two distinct\nexamples, both using actual data collected on residential routers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:45:05 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Streit", "Ananda", ""], ["Santos", "Gustavo H. A.", ""], ["Le\u00e3o", "Rosa", ""], ["Silva", "Edmundo de Souza e", ""], ["Menasch\u00e9", "Daniel", ""], ["Towsley", "Don", ""]]}, {"id": "2004.09656", "submitter": "Mohammad Sadegh Talebi", "authors": "Hippolyte Bourel and Odalric-Ambrym Maillard and Mohammad Sadegh\n  Talebi", "title": "Tightening Exploration in Upper Confidence Reinforcement Learning", "comments": "Appeared in Proceedings of the 27th International Conference on\n  Machine Learning (ICML 2020). This is an improved post-proceeding version\n  correcting minor errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upper confidence reinforcement learning (UCRL2) algorithm introduced in\n(Jaksch et al., 2010) is a popular method to perform regret minimization in\nunknown discrete Markov Decision Processes under the average-reward criterion.\nDespite its nice and generic theoretical regret guarantees, this algorithm and\nits variants have remained until now mostly theoretical as numerical\nexperiments in simple environments exhibit long burn-in phases before the\nlearning takes place. In pursuit of practical efficiency, we present UCRL3,\nfollowing the lines of UCRL2, but with two key modifications: First, it uses\nstate-of-the-art time-uniform concentration inequalities to compute confidence\nsets on the reward and (component-wise) transition distributions for each\nstate-action pair. Furthermore, to tighten exploration, it uses an adaptive\ncomputation of the support of each transition distribution, which in turn\nenables us to revisit the extended value iteration procedure of UCRL2 to\noptimize over distributions with reduced support by disregarding low\nprobability transitions, while still ensuring near-optimism. We demonstrate,\nthrough numerical experiments in standard environments, that reducing\nexploration this way yields a substantial numerical improvement compared to\nUCRL2 and its variants. On the theoretical side, these key modifications enable\nus to derive a regret bound for UCRL3 improving on UCRL2, that for the first\ntime makes appear notions of local diameter and local effective support, thanks\nto variance-aware concentration bounds.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:52:10 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 11:45:41 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 19:21:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Bourel", "Hippolyte", ""], ["Maillard", "Odalric-Ambrym", ""], ["Talebi", "Mohammad Sadegh", ""]]}, {"id": "2004.09665", "submitter": "Zexi Chen", "authors": "Zexi Chen, Benjamin Dutton, Bharathkumar Ramachandra, Tianfu Wu, Ranga\n  Raju Vatsavai", "title": "Local Clustering with Mean Teacher for Semi-supervised Learning", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mean Teacher (MT) model of Tarvainen and Valpola has shown favorable\nperformance on several semi-supervised benchmark datasets. MT maintains a\nteacher model's weights as the exponential moving average of a student model's\nweights and minimizes the divergence between their probability predictions\nunder diverse perturbations of the inputs. However, MT is known to suffer from\nconfirmation bias, that is, reinforcing incorrect teacher model predictions. In\nthis work, we propose a simple yet effective method called Local Clustering\n(LC) to mitigate the effect of confirmation bias. In MT, each data point is\nconsidered independent of other points during training; however, data points\nare likely to be close to each other in feature space if they share similar\nfeatures. Motivated by this, we cluster data points locally by minimizing the\npairwise distance between neighboring data points in feature space. Combined\nwith a standard classification cross-entropy objective on labeled data points,\nthe misclassified unlabeled data points are pulled towards high-density regions\nof their correct class with the help of their neighbors, thus improving model\nperformance. We demonstrate on semi-supervised benchmark datasets SVHN and\nCIFAR-10 that adding our LC loss to MT yields significant improvements compared\nto MT and performance comparable to the state of the art in semi-supervised\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 22:31:31 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 00:47:01 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Chen", "Zexi", ""], ["Dutton", "Benjamin", ""], ["Ramachandra", "Bharathkumar", ""], ["Wu", "Tianfu", ""], ["Vatsavai", "Ranga Raju", ""]]}, {"id": "2004.09666", "submitter": "Faisal Mahmood", "authors": "Ming Y. Lu, Drew F. K. Williamson, Tiffany Y. Chen, Richard J. Chen,\n  Matteo Barbieri and Faisal Mahmood", "title": "Data Efficient and Weakly Supervised Computational Pathology on Whole\n  Slide Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly emerging field of computational pathology has the potential to\nenable objective diagnosis, therapeutic response prediction and identification\nof new morphological features of clinical relevance. However, deep\nlearning-based computational pathology approaches either require manual\nannotation of gigapixel whole slide images (WSIs) in fully-supervised settings\nor thousands of WSIs with slide-level labels in a weakly-supervised setting.\nMoreover, whole slide level computational pathology methods also suffer from\ndomain adaptation and interpretability issues. These challenges have prevented\nthe broad adaptation of computational pathology for clinical and research\npurposes. Here we present CLAM - Clustering-constrained attention multiple\ninstance learning, an easy-to-use, high-throughput, and interpretable WSI-level\nprocessing and learning method that only requires slide-level labels while\nbeing data efficient, adaptable and capable of handling multi-class subtyping\nproblems. CLAM is a deep-learning-based weakly-supervised method that uses\nattention-based learning to automatically identify sub-regions of high\ndiagnostic value in order to accurately classify the whole slide, while also\nutilizing instance-level clustering over the representative regions identified\nto constrain and refine the feature space. In three separate analyses, we\ndemonstrate the data efficiency and adaptability of CLAM and its superior\nperformance over standard weakly-supervised classification. We demonstrate that\nCLAM models are interpretable and can be used to identify well-known and new\nmorphological features. We further show that models trained using CLAM are\nadaptable to independent test cohorts, cell phone microscopy images, and\nbiopsies. CLAM is a general-purpose and adaptable method that can be used for a\nvariety of different computational pathology tasks in both clinical and\nresearch settings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:00:13 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 02:03:49 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Lu", "Ming Y.", ""], ["Williamson", "Drew F. K.", ""], ["Chen", "Tiffany Y.", ""], ["Chen", "Richard J.", ""], ["Barbieri", "Matteo", ""], ["Mahmood", "Faisal", ""]]}, {"id": "2004.09673", "submitter": "John Francis", "authors": "John Paul Francis, Hongzhi Wang, Kate White, Tanveer Syeda-Mahmood,\n  Raymond Stevens", "title": "Neural Network Segmentation of Cell Ultrastructure Using Incomplete\n  Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pancreatic beta cell is an important target in diabetes research. For\nscalable modeling of beta cell ultrastructure, we investigate automatic\nsegmentation of whole cell imaging data acquired through soft X-ray tomography.\nDuring the course of the study, both complete and partial ultrastructure\nannotations were produced manually for different subsets of the data. To more\neffectively use existing annotations, we propose a method that enables the\napplication of partially labeled data for full label segmentation. For\nexperimental validation, we apply our method to train a convolutional neural\nnetwork with a set of 12 fully annotated data and 12 partially annotated data\nand show promising improvement over standard training that uses fully annotated\ndata alone.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:28:11 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Francis", "John Paul", ""], ["Wang", "Hongzhi", ""], ["White", "Kate", ""], ["Syeda-Mahmood", "Tanveer", ""], ["Stevens", "Raymond", ""]]}, {"id": "2004.09675", "submitter": "Ali Hassan", "authors": "Ali Hassan, Deepjyoti Deka, Michael Chertkov and Yury Dvorkin", "title": "Data-Driven Learning and Load Ensemble Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand response (DR) programs aim to engage distributed small-scale flexible\nloads, such as thermostatically controllable loads (TCLs), to provide various\ngrid support services. Linearly Solvable Markov Decision Process (LS-MDP), a\nvariant of the traditional MDP, is used to model aggregated TCLs. Then, a\nmodel-free reinforcement learning technique called Z-learning is applied to\nlearn the value function and derive the optimal policy for the DR aggregator to\ncontrol TCLs. The learning process is robust against uncertainty that arises\nfrom estimating the passive dynamics of the aggregated TCLs. The efficiency of\nthis data-driven learning is demonstrated through simulations on Heating,\nCooling & Ventilation (HVAC) units in a testbed neighborhood of residential\nhouses.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:32:10 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hassan", "Ali", ""], ["Deka", "Deepjyoti", ""], ["Chertkov", "Michael", ""], ["Dvorkin", "Yury", ""]]}, {"id": "2004.09677", "submitter": "Finbarr Timbers", "authors": "Finbarr Timbers, Edward Lockhart, Marc Lanctot, Martin Schmid, Julian\n  Schrittwieser, Thomas Hubert, Michael Bowling", "title": "Approximate exploitability: Learning a best response in large games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard metric used to measure the approximate optimality of policies in\nimperfect information games is exploitability, i.e. the performance of a policy\nagainst its worst-case opponent. However, exploitability is intractable to\ncompute in large games as it requires a full traversal of the game tree to\ncalculate a best response to the given policy. We introduce a new metric,\napproximate exploitability, that calculates an analogous metric using an\napproximate best response; the approximation is done by using search and\nreinforcement learning. This is a generalization of local best response, a\ndomain specific evaluation metric used in poker. We provide empirical results\nfor a specific instance of the method, demonstrating that our method converges\nto exploitability in the tabular and function approximation settings for small\ngames. In large games, our method learns to exploit both strong and weak\nagents, learning to exploit an AlphaZero agent.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:36:40 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 16:13:05 GMT"}, {"version": "v3", "created": "Tue, 22 Sep 2020 15:59:02 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Timbers", "Finbarr", ""], ["Lockhart", "Edward", ""], ["Lanctot", "Marc", ""], ["Schmid", "Martin", ""], ["Schrittwieser", "Julian", ""], ["Hubert", "Thomas", ""], ["Bowling", "Michael", ""]]}, {"id": "2004.09679", "submitter": "Weizhe Hua", "authors": "Weizhe Hua, Muhammad Umar, Zhiru Zhang, G. Edward Suh", "title": "MgX: Near-Zero Overhead Memory Protection with an Application to Secure\n  DNN Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose MgX, a near-zero overhead memory protection scheme\nfor hardware accelerators. MgX minimizes the performance overhead of off-chip\nmemory encryption and integrity verification by exploiting the\napplication-specific aspect of accelerators. Accelerators tend to explicitly\nmanage data movement between on-chip and off-chip memory, typically at an\nobject granularity that is much larger than cache lines. Exploiting these\naccelerator-specific characteristics, MgX generates version numbers used in\nmemory encryption and integrity verification only using on-chip state without\nstoring them in memory, and also customizes the granularity of the memory\nprotection to match the granularity used by the accelerator. To demonstrate the\napplicability of MgX, we present an in-depth study of MgX for deep neural\nnetwork (DNN) and also describe implementations for H.264 video decoding and\ngenome alignment. Experimental results show that applying MgX has less than 1%\nperformance overhead for both DNN inference and training on state-of-the-art\nDNN architectures.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 23:46:22 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hua", "Weizhe", ""], ["Umar", "Muhammad", ""], ["Zhang", "Zhiru", ""], ["Suh", "G. Edward", ""]]}, {"id": "2004.09691", "submitter": "Gabriele Cesa", "authors": "Mirgahney Mohamed, Gabriele Cesa, Taco S. Cohen and Max Welling", "title": "A Data and Compute Efficient Design for Limited-Resources Deep Learning", "comments": "Accepted for poster presentation at the Practical Machine Learning\n  for Developing Countries (PML4DC) workshop, ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Thanks to their improved data efficiency, equivariant neural networks have\ngained increased interest in the deep learning community. They have been\nsuccessfully applied in the medical domain where symmetries in the data can be\neffectively exploited to build more accurate and robust models. To be able to\nreach a much larger body of patients, mobile, on-device implementations of deep\nlearning solutions have been developed for medical applications. However,\nequivariant models are commonly implemented using large and computationally\nexpensive architectures, not suitable to run on mobile devices. In this work,\nwe design and test an equivariant version of MobileNetV2 and further optimize\nit with model quantization to enable more efficient inference. We achieve\nclose-to state of the art performance on the Patch Camelyon (PCam) medical\ndataset while being more computationally efficient.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 00:49:11 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 11:29:18 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mohamed", "Mirgahney", ""], ["Cesa", "Gabriele", ""], ["Cohen", "Taco S.", ""], ["Welling", "Max", ""]]}, {"id": "2004.09694", "submitter": "Wei Zhu", "authors": "Wei Zhu, Haofu Liao, Wenbin Li, Weijian Li, Jiebo Luo", "title": "Alleviating the Incompatibility between Cross Entropy Loss and Episode\n  Training for Few-shot Skin Disease Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skin disease classification from images is crucial to dermatological\ndiagnosis. However, identifying skin lesions involves a variety of aspects in\nterms of size, color, shape, and texture. To make matters worse, many\ncategories only contain very few samples, posing great challenges to\nconventional machine learning algorithms and even human experts. Inspired by\nthe recent success of Few-Shot Learning (FSL) in natural image classification,\nwe propose to apply FSL to skin disease identification to address the extreme\nscarcity of training sample problem. However, directly applying FSL to this\ntask does not work well in practice, and we find that the problem can be\nlargely attributed to the incompatibility between Cross Entropy (CE) and\nepisode training, which are both commonly used in FSL. Based on a detailed\nanalysis, we propose the Query-Relative (QR) loss, which proves superior to CE\nunder episode training and is closely related to recently proposed mutual\ninformation estimation. Moreover, we further strengthen the proposed QR loss\nwith a novel adaptive hard margin strategy. Comprehensive experiments validate\nthe effectiveness of the proposed FSL scheme and the possibility to diagnosis\nrare skin disease with a few labeled samples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 00:57:11 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zhu", "Wei", ""], ["Liao", "Haofu", ""], ["Li", "Wenbin", ""], ["Li", "Weijian", ""], ["Luo", "Jiebo", ""]]}, {"id": "2004.09702", "submitter": "Will Zou", "authors": "Will Y. Zou, Shuyang Du, James Lee, Jan Pedersen", "title": "Heterogeneous Causal Learning for Effectiveness Optimization in User\n  Marketing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  User marketing is a key focus of consumer-based internet companies. Learning\nalgorithms are effective to optimize marketing campaigns which increase user\nengagement, and facilitates cross-marketing to related products. By attracting\nusers with rewards, marketing methods are effective to boost user activity in\nthe desired products. Rewards incur significant cost that can be off-set by\nincrease in future revenue. Most methodologies rely on churn predictions to\nprevent losing users to make marketing decisions, which cannot capture up-lift\nacross counterfactual outcomes with business metrics. Other predictive models\nare capable of estimating heterogeneous treatment effects, but fail to capture\nthe balance of cost versus benefit. We propose a treatment effect optimization\nmethodology for user marketing. This algorithm learns from past experiments and\nutilizes novel optimization methods to optimize cost efficiency with respect to\nuser selection. The method optimizes decisions using deep learning optimization\nmodels to treat and reward users, which is effective in producing\ncost-effective, impactful marketing campaigns. Our methodology demonstrates\nsuperior algorithmic flexibility with integration with deep learning methods\nand dealing with business constraints. The effectiveness of our model surpasses\nthe quasi-oracle estimation (R-learner) model and causal forests. We also\nestablished evaluation metrics that reflect the cost-efficiency and real-world\nbusiness value. Our proposed constrained and direct optimization algorithms\noutperform by 24.6% compared with the best performing method in prior art and\nbaseline methods. The methodology is useful in many product scenarios such as\noptimal treatment allocation and it has been deployed in production world-wide.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:34:34 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zou", "Will Y.", ""], ["Du", "Shuyang", ""], ["Lee", "James", ""], ["Pedersen", "Jan", ""]]}, {"id": "2004.09703", "submitter": "Will Zou", "authors": "Will Y. Zou, Smitha Shyam, Michael Mui, Mingshi Wang, Jan Pedersen,\n  Zoubin Ghahramani", "title": "Learning Continuous Treatment Policy and Bipartite Embeddings for\n  Matching with Heterogeneous Causal Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Causal inference methods are widely applied in the fields of medicine,\npolicy, and economics. Central to these applications is the estimation of\ntreatment effects to make decisions. Current methods make binary yes-or-no\ndecisions based on the treatment effect of a single outcome dimension. These\nmethods are unable to capture continuous space treatment policies with a\nmeasure of intensity. They also lack the capacity to consider the complexity of\ntreatment such as matching candidate treatments with the subject. We propose to\nformulate the effectiveness of treatment as a parametrizable model, expanding\nto a multitude of treatment intensities and complexities through the continuous\npolicy treatment function, and the likelihood of matching. Our proposal to\ndecompose treatment effect functions into effectiveness factors presents a\nframework to model a rich space of actions using causal inference. We utilize\ndeep learning to optimize the desired holistic metric space instead of\npredicting single-dimensional treatment counterfactual. This approach employs a\npopulation-wide effectiveness measure and significantly improves the overall\neffectiveness of the model. The performance of our algorithms is. demonstrated\nwith experiments. When using generic continuous space treatments and matching\narchitecture, we observe a 41% improvement upon prior art with\ncost-effectiveness and 68% improvement upon a similar method in the average\ntreatment effect. The algorithms capture subtle variations in treatment space,\nstructures the efficient optimizations techniques, and opens up the arena for\nmany applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:36:20 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zou", "Will Y.", ""], ["Shyam", "Smitha", ""], ["Mui", "Michael", ""], ["Wang", "Mingshi", ""], ["Pedersen", "Jan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "2004.09710", "submitter": "Gianlucca Zuin", "authors": "Gianlucca Zuin, Adriano Veloso, Jo\\~ao C\\^andido Portinari and Nivio\n  Ziviani", "title": "Automatic Tag Recommendation for Painting Artworks Using Diachronic\n  Descriptions", "comments": "IJCNN-2020. July 19-24th, 2020. Glasgow (UK)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we deal with the problem of automatic tag recommendation for\npainting artworks. Diachronic descriptions containing deviations on the\nvocabulary used to describe each painting usually occur when the work is done\nby many experts over time. The objective of this work is to provide a framework\nthat produces a more accurate and homogeneous set of tags for each painting in\na large collection. To validate our method we build a model based on a\nweakly-supervised neural network for over $5{,}300$ paintings with hand-labeled\ndescriptions made by experts for the paintings of the Brazilian painter Candido\nPortinari. This work takes place with the Portinari Project which started in\n1979 intending to recover and catalog the paintings of the Brazilian painter.\nThe Portinari paintings at that time were in private collections and museums\nspread around the world and thus inaccessible to the public. The descriptions\nof each painting were made by a large number of collaborators over 40 years as\nthe paintings were recovered and these diachronic descriptions caused\ndeviations on the vocabulary used to describe each painting. Our proposed\nframework consists of (i) a neural network that receives as input the image of\neach painting and uses frequent itemsets as possible tags, and (ii) a\nclustering step in which we group related tags based on the output of the\npre-trained classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:10:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Zuin", "Gianlucca", ""], ["Veloso", "Adriano", ""], ["Portinari", "Jo\u00e3o C\u00e2ndido", ""], ["Ziviani", "Nivio", ""]]}, {"id": "2004.09719", "submitter": "Xiangpeng Wan", "authors": "Xiangpeng Wan, Hakim Ghazzai, and Yehia Massoud", "title": "Word Embedding-based Text Processing for Comprehensive Summarization and\n  Distinct Information Extraction", "comments": "This paper is accepted for publication in IEEE Technology Engineering\n  Management Society International Conference (TEMSCON'20), Metro Detroit,\n  Michigan (USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose two automated text processing frameworks\nspecifically designed to analyze online reviews. The objective of the first\nframework is to summarize the reviews dataset by extracting essential sentence.\nThis is performed by converting sentences into numerical vectors and clustering\nthem using a community detection algorithm based on their similarity levels.\nAfterwards, a correlation score is measured for each sentence to determine its\nimportance level in each cluster and assign it as a tag for that community. The\nsecond framework is based on a question-answering neural network model trained\nto extract answers to multiple different questions. The collected answers are\neffectively clustered to find multiple distinct answers to a single question\nthat might be asked by a customer. The proposed frameworks are shown to be more\ncomprehensive than existing reviews processing solutions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:43:31 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Wan", "Xiangpeng", ""], ["Ghazzai", "Hakim", ""], ["Massoud", "Yehia", ""]]}, {"id": "2004.09722", "submitter": "Baichuan Huang", "authors": "Baichuan Huang, Hongwei Yi, Can Huang, Yijia He, Jingbin Liu, Xiao Liu", "title": "M^3VSNet: Unsupervised Multi-metric Multi-view Stereo Network", "comments": "Welcome to communicate with the author by the repo\n  https://github.com/whubaichuan/M3VSNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present Multi-view stereo (MVS) methods with supervised learning-based\nnetworks have an impressive performance comparing with traditional MVS methods.\nHowever, the ground-truth depth maps for training are hard to be obtained and\nare within limited kinds of scenarios. In this paper, we propose a novel\nunsupervised multi-metric MVS network, named M^3VSNet, for dense point cloud\nreconstruction without any supervision. To improve the robustness and\ncompleteness of point cloud reconstruction, we propose a novel multi-metric\nloss function that combines pixel-wise and feature-wise loss function to learn\nthe inherent constraints from different perspectives of matching\ncorrespondences. Besides, we also incorporate the normal-depth consistency in\nthe 3D point cloud format to improve the accuracy and continuity of the\nestimated depth maps. Experimental results show that M3VSNet establishes the\nstate-of-the-arts unsupervised method and achieves comparable performance with\nprevious supervised MVSNet on the DTU dataset and demonstrates the powerful\ngeneralization ability on the Tanks and Temples benchmark with effective\nimprovement. Our code is available at https://github.com/whubaichuan/M3VSNet.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:45:25 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 11:29:16 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Huang", "Baichuan", ""], ["Yi", "Hongwei", ""], ["Huang", "Can", ""], ["He", "Yijia", ""], ["Liu", "Jingbin", ""], ["Liu", "Xiao", ""]]}, {"id": "2004.09724", "submitter": "Abd AlRahman AlMomani", "authors": "Abd AlRahman AlMomani and Erik Bollt", "title": "An Early Warning Sign of Critical Transition in The Antarctic Ice Sheet\n  -- A Data Driven Tool for Spatiotemporal Tipping Point", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": "10.5194/npg-28-153-2021", "report-no": null, "categories": "physics.ao-ph cs.LG eess.IV math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our recently developed tool, called Directed Affinity Segmentation was\noriginally designed for data-driven discovery of coherent sets in fluidic\nsystems. Here we interpret that it can also be used to indicate early warning\nsigns of critical transitions in ice shelves as seen from remote sensing data.\nWe apply a directed spectral clustering methodology, including an asymmetric\naffinity matrix and the associated directed graph Laplacian, to reprocess the\nice velocity data and remote sensing satellite images of the Larsen C ice\nshelf. Our tool has enabled the simulated prediction of historical events from\nhistorical data, fault lines responsible for the critical transitions leading\nto the break up of the Larsen C ice shelf crack, which resulted in the A68\niceberg. Such benchmarking of methods using data from the past to forecast\nevents that are now also in the past is sometimes called post-casting,\nanalogous to forecasting into the future. Our method indicated the coming\ncrisis months before the actual occurrence.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:51:43 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 11:09:31 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["AlMomani", "Abd AlRahman", ""], ["Bollt", "Erik", ""]]}, {"id": "2004.09725", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Simona Santamaria, David Dao, Bj\\\"orn L\\\"utjens, Ce Zhang", "title": "TrueBranch: Metric Learning-based Verification of Forest Conservation\n  Projects", "comments": "*Authors have contributed equally. Published as Spotlight\n  Presentation at ICLR 2020 Workshop on Tackling Climate Change with Machine\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  International stakeholders increasingly invest in offsetting carbon\nemissions, for example, via issuing Payments for Ecosystem Services (PES) to\nforest conservation projects. Issuing trusted payments requires a transparent\nmonitoring, reporting, and verification (MRV) process of the ecosystem services\n(e.g., carbon stored in forests). The current MRV process, however, is either\ntoo expensive (on-ground inspection of forest) or inaccurate (satellite).\nRecent works propose low-cost and accurate MRV via automatically determining\nforest carbon from drone imagery, collected by the landowners. The automation\nof MRV, however, opens up the possibility that landowners report untruthful\ndrone imagery. To be robust against untruthful reporting, we propose\nTrueBranch, a metric learning-based algorithm that verifies the truthfulness of\ndrone imagery from forest conservation projects. TrueBranch aims to detect\nuntruthfully reported drone imagery by matching it with public satellite\nimagery. Preliminary results suggest that nominal distance metrics are not\nsufficient to reliably detect untruthfully reported imagery. TrueBranch\nleverages metric learning to create a feature embedding in which truthfully and\nuntruthfully collected imagery is easily distinguishable by distance\nthresholding.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:52:27 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Santamaria", "Simona", ""], ["Dao", "David", ""], ["L\u00fctjens", "Bj\u00f6rn", ""], ["Zhang", "Ce", ""]]}, {"id": "2004.09735", "submitter": "Tatsuya Akutsu", "authors": "Avraham A. Melkman, Sini Guo, Wai-Ki Ching, Pengyu Liu, Tatsuya Akutsu", "title": "On the Compressive Power of Boolean Threshold Autoencoders", "comments": "13 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An autoencoder is a layered neural network whose structure can be viewed as\nconsisting of an encoder, which compresses an input vector of dimension $D$ to\na vector of low dimension $d$, and a decoder which transforms the\nlow-dimensional vector back to the original input vector (or one that is very\nsimilar). In this paper we explore the compressive power of autoencoders that\nare Boolean threshold networks by studying the numbers of nodes and layers that\nare required to ensure that the numbers of nodes and layers that are required\nto ensure that each vector in a given set of distinct input binary vectors is\ntransformed back to its original. We show that for any set of $n$ distinct\nvectors there exists a seven-layer autoencoder with the smallest possible\nmiddle layer, (i.e., its size is logarithmic in $n$), but that there is a set\nof $n$ vectors for which there is no three-layer autoencoder with a middle\nlayer of the same size. In addition we present a kind of trade-off: if a\nconsiderably larger middle layer is permissible then a five-layer autoencoder\ndoes exist. We also study encoding by itself. The results we obtain suggest\nthat it is the decoding that constitutes the bottleneck of autoencoding. For\nexample, there always is a three-layer Boolean threshold encoder that\ncompresses $n$ vectors into a dimension that is reduced to twice the logarithm\nof $n$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:21:43 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Melkman", "Avraham A.", ""], ["Guo", "Sini", ""], ["Ching", "Wai-Ki", ""], ["Liu", "Pengyu", ""], ["Akutsu", "Tatsuya", ""]]}, {"id": "2004.09739", "submitter": "Tanmoy Chakraborty", "authors": "Tanya Chowdhury, Sachin Kumar, Tanmoy Chakraborty", "title": "Neural Abstractive Summarization with Structural Attention", "comments": "7 pages, 4 tables, 2 figures, IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attentional, RNN-based encoder-decoder architectures have achieved impressive\nperformance on abstractive summarization of news articles. However, these\nmethods fail to account for long term dependencies within the sentences of a\ndocument. This problem is exacerbated in multi-document summarization tasks\nsuch as summarizing the popular opinion in threads present in community\nquestion answering (CQA) websites such as Yahoo! Answers and Quora. These\nthreads contain answers which often overlap or contradict each other. In this\nwork, we present a hierarchical encoder based on structural attention to model\nsuch inter-sentence and inter-document dependencies. We set the popular\npointer-generator architecture and some of the architectures derived from it as\nour baselines and show that they fail to generate good summaries in a\nmulti-document setting. We further illustrate that our proposed model achieves\nsignificant improvement over the baselines in both single and multi-document\nsummarization settings -- in the former setting, it beats the best baseline by\n1.31 and 7.8 ROUGE-1 points on CNN and CQA datasets, respectively; in the\nlatter setting, the performance is further improved by 1.6 ROUGE-1 points on\nthe CQA dataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:39:15 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 05:32:59 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Chowdhury", "Tanya", ""], ["Kumar", "Sachin", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "2004.09740", "submitter": "Wenjie Li", "authors": "Wenjie Li, Zhaoyang Zhang, Xinjiang Wang, Ping Luo", "title": "AdaX: Adaptive Gradient Descent with Exponential Long Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although adaptive optimization algorithms such as Adam show fast convergence\nin many machine learning tasks, this paper identifies a problem of Adam by\nanalyzing its performance in a simple non-convex synthetic problem, showing\nthat Adam's fast convergence would possibly lead the algorithm to local\nminimums. To address this problem, we improve Adam by proposing a novel\nadaptive gradient descent algorithm named AdaX. Unlike Adam that ignores the\npast gradients, AdaX exponentially accumulates the long-term gradient\ninformation in the past during training, to adaptively tune the learning rate.\nWe thoroughly prove the convergence of AdaX in both the convex and non-convex\nsettings. Extensive experiments show that AdaX outperforms Adam in various\ntasks of computer vision and natural language processing and can catch up with\nStochastic Gradient Descent.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 03:46:58 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:05:58 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Wenjie", ""], ["Zhang", "Zhaoyang", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""]]}, {"id": "2004.09749", "submitter": "Duy Vo Nguyen Le", "authors": "Vo Nguyen Le Duy, Ichiro Takeuchi", "title": "Parametric Programming Approach for More Powerful and General Lasso\n  Selective Inference", "comments": "International Conference on Artificial Intelligence and Statistics\n  (AISTATS) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective Inference (SI) has been actively studied in the past few years for\nconducting inference on the features of linear models that are adaptively\nselected by feature selection methods such as Lasso. The basic idea of SI is to\nmake inference conditional on the selection event. Unfortunately, the main\nlimitation of the original SI approach for Lasso is that the inference is\nconducted not only conditional on the selected features but also on their signs\n-- this leads to loss of power because of over-conditioning. Although this\nlimitation can be circumvented by considering the union of such selection\nevents for all possible combinations of signs, this is only feasible when the\nnumber of selected features is sufficiently small. To address this\ncomputational bottleneck, we propose a parametric programming-based method that\ncan conduct SI without conditioning on signs even when we have thousands of\nactive features. The main idea is to compute the continuum path of Lasso\nsolutions in the direction of a test statistic, and identify the subset of the\ndata space corresponding to the feature selection event by following the\nsolution path. The proposed parametric programming-based method not only avoids\nthe aforementioned computational bottleneck but also improves the performance\nand practicality of SI for Lasso in various respects. We conduct several\nexperiments to demonstrate the effectiveness and efficiency of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 04:46:29 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 08:23:47 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 13:18:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2004.09754", "submitter": "Mang Tik Chiu", "authors": "Mang Tik Chiu, Xingqian Xu, Kai Wang, Jennifer Hobbs, Naira\n  Hovakimyan, Thomas S. Huang, Honghui Shi, Yunchao Wei, Zilong Huang,\n  Alexander Schwing, Robert Brunner, Ivan Dozier, Wyatt Dozier, Karen\n  Ghandilyan, David Wilson, Hyunseong Park, Junhee Kim, Sungho Kim, Qinghui\n  Liu, Michael C. Kampffmeyer, Robert Jenssen, Arnt B. Salberg, Alexandre\n  Barbosa, Rodrigo Trevisan, Bingchen Zhao, Shaozuo Yu, Siwei Yang, Yin Wang,\n  Hao Sheng, Xiao Chen, Jingyi Su, Ram Rajagopal, Andrew Ng, Van Thong Huynh,\n  Soo-Hyung Kim, In-Seop Na, Ujjwal Baid, Shubham Innani, Prasad Dutande,\n  Bhakti Baheti, Sanjay Talbar, Jianyu Tang", "title": "The 1st Agriculture-Vision Challenge: Methods and Results", "comments": "CVPR 2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first Agriculture-Vision Challenge aims to encourage research in\ndeveloping novel and effective algorithms for agricultural pattern recognition\nfrom aerial images, especially for the semantic segmentation task associated\nwith our challenge dataset. Around 57 participating teams from various\ncountries compete to achieve state-of-the-art in aerial agriculture semantic\nsegmentation. The Agriculture-Vision Challenge Dataset was employed, which\ncomprises of 21,061 aerial and multi-spectral farmland images. This paper\nprovides a summary of notable methods and results in the challenge. Our\nsubmission server and leaderboard will continue to open for researchers that\nare interested in this challenge dataset and task; the link can be found here.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 05:02:31 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 17:24:31 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Chiu", "Mang Tik", ""], ["Xu", "Xingqian", ""], ["Wang", "Kai", ""], ["Hobbs", "Jennifer", ""], ["Hovakimyan", "Naira", ""], ["Huang", "Thomas S.", ""], ["Shi", "Honghui", ""], ["Wei", "Yunchao", ""], ["Huang", "Zilong", ""], ["Schwing", "Alexander", ""], ["Brunner", "Robert", ""], ["Dozier", "Ivan", ""], ["Dozier", "Wyatt", ""], ["Ghandilyan", "Karen", ""], ["Wilson", "David", ""], ["Park", "Hyunseong", ""], ["Kim", "Junhee", ""], ["Kim", "Sungho", ""], ["Liu", "Qinghui", ""], ["Kampffmeyer", "Michael C.", ""], ["Jenssen", "Robert", ""], ["Salberg", "Arnt B.", ""], ["Barbosa", "Alexandre", ""], ["Trevisan", "Rodrigo", ""], ["Zhao", "Bingchen", ""], ["Yu", "Shaozuo", ""], ["Yang", "Siwei", ""], ["Wang", "Yin", ""], ["Sheng", "Hao", ""], ["Chen", "Xiao", ""], ["Su", "Jingyi", ""], ["Rajagopal", "Ram", ""], ["Ng", "Andrew", ""], ["Huynh", "Van Thong", ""], ["Kim", "Soo-Hyung", ""], ["Na", "In-Seop", ""], ["Baid", "Ujjwal", ""], ["Innani", "Shubham", ""], ["Dutande", "Prasad", ""], ["Baheti", "Bhakti", ""], ["Talbar", "Sanjay", ""], ["Tang", "Jianyu", ""]]}, {"id": "2004.09756", "submitter": "Seyedmehdi Abtahi", "authors": "SeyedMehdi Abtahi and Nima Assadian", "title": "Integrated attitude estimation and control of satellite with thruster\n  actuator using ANFIS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a new estimation and control strategy to control the\nsatellite attitude. As the attitude control strategy plays an essential role in\nthe different kinds of space missions, scientists try to improve the\nperformance of the satellite attitude system, regardless of the expense. In\nthis study, we proposed an adaptive neuro-fuzzy integrated (ANFIS) satellite\nattitude estimation and control system. A pulse modulator is used to generate\nthe right ON/OFF commands of the thruster actuator. To evaluate the performance\nof the ANFIS controller in closed-loop simulation, an ANFIS observer is used to\nestimate the attitude and angular velocities of the satellite using a\nmagnetometer, sun sensor, and rate gyro data. Besides, a new ANFIS system will\nbe proposed and evaluated that can simultaneously control and estimate the\nsystem. The performance of the ANFIS controller is compared with the optimal\nPID controller in a Monte Carlo simulation using different initial conditions,\ndisturbance, and noise. The simulations are performed to verify the ANFIS\ncontroller's ability to decrease settling time and fuel consumption in\ncomparison with the optimal PID controller. Also, examine the ANFIS estimator,\nand the results demonstrate the high skill of these designated observers.\nMoreover, we proposed an integrated ANFIS estimator and controller for\nsatellite attitude control and estimation in the presence of noise and\nuncertainty, which can reduce the computational effort and offer smooth\nactuator actions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 05:09:26 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 15:52:07 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Abtahi", "SeyedMehdi", ""], ["Assadian", "Nima", ""]]}, {"id": "2004.09764", "submitter": "Fang Xianghong", "authors": "Xianghong Fang and Haoli Bai and Zenglin Xu and Michael Lyu and Irwin\n  King", "title": "Discrete Variational Attention Models for Language Generation", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Variational autoencoders have been widely applied for natural language\ngeneration, however, there are two long-standing problems: information\nunder-representation and posterior collapse. The former arises from the fact\nthat only the last hidden state from the encoder is transformed to the latent\nspace, which is insufficient to summarize data. The latter comes as a result of\nthe imbalanced scale between the reconstruction loss and the KL divergence in\nthe objective function. To tackle these issues, in this paper we propose the\ndiscrete variational attention model with categorical distribution over the\nattention mechanism owing to the discrete nature in languages. Our approach is\ncombined with an auto-regressive prior to capture the sequential dependency\nfrom observations, which can enhance the latent space for language generation.\nMoreover, thanks to the property of discreteness, the training of our proposed\napproach does not suffer from posterior collapse. Furthermore, we carefully\nanalyze the superiority of discrete latent space over the continuous space with\nthe common Gaussian distribution. Extensive experiments on language generation\ndemonstrate superior advantages of our proposed approach in comparison with the\nstate-of-the-art counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 05:49:04 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2020 08:02:24 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 15:18:57 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 06:35:02 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Fang", "Xianghong", ""], ["Bai", "Haoli", ""], ["Xu", "Zenglin", ""], ["Lyu", "Michael", ""], ["King", "Irwin", ""]]}, {"id": "2004.09780", "submitter": "Shaofeng Deng", "authors": "Shaofeng Deng, Shuyang Ling, Thomas Strohmer", "title": "Strong Consistency, Graph Laplacians, and the Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering has become one of the most popular algorithms in data\nclustering and community detection. We study the performance of classical\ntwo-step spectral clustering via the graph Laplacian to learn the stochastic\nblock model. Our aim is to answer the following question: when is spectral\nclustering via the graph Laplacian able to achieve strong consistency, i.e.,\nthe exact recovery of the underlying hidden communities? Our work provides an\nentrywise analysis (an $\\ell_{\\infty}$-norm perturbation bound) of the Fielder\neigenvector of both the unnormalized and the normalized Laplacian associated\nwith the adjacency matrix sampled from the stochastic block model. We prove\nthat spectral clustering is able to achieve exact recovery of the planted\ncommunity structure under conditions that match the information-theoretic\nlimits.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:16:46 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Deng", "Shaofeng", ""], ["Ling", "Shuyang", ""], ["Strohmer", "Thomas", ""]]}, {"id": "2004.09783", "submitter": "Juan Chen", "authors": "Juan Chen, Zhiwen Xiao, Huanlai Xing, Penglin Dai, Shouxi Luo,\n  Muhammad Azhar Iqbal", "title": "STDPG: A Spatio-Temporal Deterministic Policy Gradient Agent for Dynamic\n  Routing in SDN", "comments": "6 pages,5 figures,accepted by IEEE ICC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic routing in software-defined networking (SDN) can be viewed as a\ncentralized decision-making problem. Most of the existing deep reinforcement\nlearning (DRL) agents can address it, thanks to the deep neural network\n(DNN)incorporated. However, fully-connected feed-forward neural network (FFNN)\nis usually adopted, where spatial correlation and temporal variation of traffic\nflows are ignored. This drawback usually leads to significantly high\ncomputational complexity due to large number of training parameters. To\novercome this problem, we propose a novel model-free framework for dynamic\nrouting in SDN, which is referred to as spatio-temporal deterministic policy\ngradient (STDPG) agent. Both the actor and critic networks are based on\nidentical DNN structure, where a combination of convolutional neural network\n(CNN) and long short-term memory network (LSTM) with temporal attention\nmechanism, CNN-LSTM-TAM, is devised. By efficiently exploiting spatial and\ntemporal features, CNNLSTM-TAM helps the STDPG agent learn better from the\nexperience transitions. Furthermore, we employ the prioritized experience\nreplay (PER) method to accelerate the convergence of model training. The\nexperimental results show that STDPG can automatically adapt for current\nnetwork environment and achieve robust convergence. Compared with a number\nstate-ofthe-art DRL agents, STDPG achieves better routing solutions in terms of\nthe average end-to-end delay.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:19:07 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chen", "Juan", ""], ["Xiao", "Zhiwen", ""], ["Xing", "Huanlai", ""], ["Dai", "Penglin", ""], ["Luo", "Shouxi", ""], ["Iqbal", "Muhammad Azhar", ""]]}, {"id": "2004.09788", "submitter": "Jinyoung Kim Dr.", "authors": "Jinyoung Kim, Remi Patriat, Jordan Kaplan, Oren Solomon, Noam Harel", "title": "Deep Cerebellar Nuclei Segmentation via Semi-Supervised Deep\n  Context-Aware Learning from 7T Diffusion MRI", "comments": "56 pages (one column), 13 figures, 5 tables, supplementary materials,\n  Accepted for publication in IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep cerebellar nuclei are a key structure of the cerebellum that are\ninvolved in processing motor and sensory information. It is thus a crucial step\nto accurately segment deep cerebellar nuclei for the understanding of the\ncerebellum system and its utility in deep brain stimulation treatment. However,\nit is challenging to clearly visualize such small nuclei under standard\nclinical magnetic resonance imaging (MRI) protocols and therefore precise\nsegmentation is not feasible. Recent advances in 7 Tesla (T) MRI technology and\ngreat potential of deep neural networks facilitate automatic patient-specific\nsegmentation. In this paper, we propose a novel deep learning framework\n(referred to as DCN-Net) for fast, accurate, and robust patient-specific\nsegmentation of deep cerebellar dentate and interposed nuclei on 7T diffusion\nMRI. DCN-Net effectively encodes contextual information on the patch images\nwithout consecutive pooling operations and adding complexity via proposed\ndilated dense blocks. During the end-to-end training, label probabilities of\ndentate and interposed nuclei are independently learned with a hybrid loss,\nhandling highly imbalanced data. Finally, we utilize self-training strategies\nto cope with the problem of limited labeled data. To this end, auxiliary\ndentate and interposed nuclei labels are created on unlabeled data by using\nDCN-Net trained on manual labels. We validate the proposed framework using 7T\nB0 MRIs from 60 subjects. Experimental results demonstrate that DCN-Net\nprovides better segmentation than atlas-based deep cerebellar nuclei\nsegmentation tools and other state-of-the-art deep neural networks in terms of\naccuracy and consistency. We further prove the effectiveness of the proposed\ncomponents within DCN-Net in dentate and interposed nuclei segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:30:07 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 06:26:20 GMT"}, {"version": "v3", "created": "Sun, 31 May 2020 01:47:33 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Kim", "Jinyoung", ""], ["Patriat", "Remi", ""], ["Kaplan", "Jordan", ""], ["Solomon", "Oren", ""], ["Harel", "Noam", ""]]}, {"id": "2004.09795", "submitter": "Long Chen", "authors": "Long Chen, Martin Strauch, Matthias Daub, Xiaochen Jiang, Marcus\n  Jansen, Hans-Georg Luigs, Susanne Schultz-Kuhlmann, Stefan Kr\\\"ussel, Dorif\n  Merhof", "title": "A CNN Framenwork Based on Line Annotations for Detecting Nematodes in\n  Microscopic Images", "comments": "ISBI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plant parasitic nematodes cause damage to crop plants on a global scale.\nRobust detection on image data is a prerequisite for monitoring such nematodes,\nas well as for many biological studies involving the nematode C. elegans, a\ncommon model organism. Here, we propose a framework for detecting worm-shaped\nobjects in microscopic images that is based on convolutional neural networks\n(CNNs). We annotate nematodes with curved lines along the body, which is more\nsuitable for worm-shaped objects than bounding boxes. The trained model\npredicts worm skeletons and body endpoints. The endpoints serve to untangle the\nskeletons from which segmentation masks are reconstructed by estimating the\nbody width at each location along the skeleton. With light-weight backbone\nnetworks, we achieve 75.85 % precision, 73.02 % recall on a potato cyst\nnematode data set and 84.20 % precision, 85.63 % recall on a public C. elegans\ndata set.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 07:48:02 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chen", "Long", ""], ["Strauch", "Martin", ""], ["Daub", "Matthias", ""], ["Jiang", "Xiaochen", ""], ["Jansen", "Marcus", ""], ["Luigs", "Hans-Georg", ""], ["Schultz-Kuhlmann", "Susanne", ""], ["Kr\u00fcssel", "Stefan", ""], ["Merhof", "Dorif", ""]]}, {"id": "2004.09803", "submitter": "Subhashis Banerjee", "authors": "Arpan Mangal, Surya Kalia, Harish Rajgopal, Krithika Rangarajan, Vinay\n  Namboodiri, Subhashis Banerjee, Chetan Arora", "title": "CovidAID: COVID-19 Detection Using Chest X-Ray", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential increase in COVID-19 patients is overwhelming healthcare\nsystems across the world. With limited testing kits, it is impossible for every\npatient with respiratory illness to be tested using conventional techniques\n(RT-PCR). The tests also have long turn-around time, and limited sensitivity.\nDetecting possible COVID-19 infections on Chest X-Ray may help quarantine high\nrisk patients while test results are awaited. X-Ray machines are already\navailable in most healthcare systems, and with most modern X-Ray systems\nalready digitized, there is no transportation time involved for the samples\neither. In this work we propose the use of chest X-Ray to prioritize the\nselection of patients for further RT-PCR testing. This may be useful in an\ninpatient setting where the present systems are struggling to decide whether to\nkeep the patient in the ward along with other patients or isolate them in\nCOVID-19 areas. It would also help in identifying patients with high likelihood\nof COVID with a false negative RT-PCR who would need repeat testing. Further,\nwe propose the use of modern AI techniques to detect the COVID-19 patients\nusing X-Ray images in an automated manner, particularly in settings where\nradiologists are not available, and help make the proposed testing technology\nscalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural\nnetwork based model to triage patients for appropriate testing. On the publicly\navailable covid-chestxray-dataset [2], our model gives 90.5% accuracy with 100%\nsensitivity (recall) for the COVID-19 infection. We significantly improve upon\nthe results of Covid-Net [10] on the same dataset.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:02:52 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Mangal", "Arpan", ""], ["Kalia", "Surya", ""], ["Rajgopal", "Harish", ""], ["Rangarajan", "Krithika", ""], ["Namboodiri", "Vinay", ""], ["Banerjee", "Subhashis", ""], ["Arora", "Chetan", ""]]}, {"id": "2004.09808", "submitter": "Chaojie Ji", "authors": "Chaojie Ji, Ruxin Wang, Hongyan Wu", "title": "Perturb More, Trap More: Understanding Behaviors of Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While graph neural networks (GNNs) have shown a great potential in various\ntasks on graph, the lack of transparency has hindered understanding how GNNs\narrived at its predictions. Although few explainers for GNNs are explored, the\nconsideration of local fidelity, indicating how the model behaves around an\ninstance should be predicted, is neglected. In this paper, we first propose a\nnovel post-hoc framework based on local fidelity for any trained GNNs - TraP2,\nwhich can generate a high-fidelity explanation. Considering that both relevant\ngraph structure and important features inside each node need to be highlighted,\na three-layer architecture in TraP2 is designed: i) interpretation domain are\ndefined by Translation layer in advance; ii) local predictive behavior of GNNs\nbeing explained are probed and monitored by Perturbation layer, in which\nmultiple perturbations for graph structure and feature-level are conducted in\ninterpretation domain; iii) high faithful explanations are generated by fitting\nthe local decision boundary through Paraphrase layer. Finally, TraP2 is\nevaluated on six benchmark datasets based on five desired attributions:\naccuracy, fidelity, decisiveness, insight and inspiration, which achieves\n$10.2\\%$ higher explanation accuracy than the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:07:01 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:08:51 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ji", "Chaojie", ""], ["Wang", "Ruxin", ""], ["Wu", "Hongyan", ""]]}, {"id": "2004.09817", "submitter": "Sohei Itahara", "authors": "Sohei Itahara, Takayuki Nishio, Masahiro Morikura and Koji Yamamoto", "title": "Lottery Hypothesis based Unsupervised Pre-training for Model Compression\n  in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables a neural network (NN) to be trained using\nprivacy-sensitive data on mobile devices while retaining all the data on their\nlocal storages. However, FL asks the mobile devices to perform heavy\ncommunication and computation tasks, i.e., devices are requested to upload and\ndownload large-volume NN models and train them. This paper proposes a novel\nunsupervised pre-training method adapted for FL, which aims to reduce both the\ncommunication and computation costs through model compression. Since the\ncommunication and computation costs are highly dependent on the volume of NN\nmodels, reducing the volume without decreasing model performance can reduce\nthese costs. The proposed pre-training method leverages unlabeled data, which\nis expected to be obtained from the Internet or data repository much more\neasily than labeled data. The key idea of the proposed method is to obtain a\n``good'' subnetwork from the original NN using the unlabeled data based on the\nlottery hypothesis. The proposed method trains an original model using a\ndenoising auto encoder with the unlabeled data and then prunes small-magnitude\nparameters of the original model to generate a small but good subnetwork. The\nproposed method is evaluated using an image classification task. The results\nshow that the proposed method requires 35\\% less traffic and computation time\nthan previous methods when achieving a certain test accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:31:23 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Itahara", "Sohei", ""], ["Nishio", "Takayuki", ""], ["Morikura", "Masahiro", ""], ["Yamamoto", "Koji", ""]]}, {"id": "2004.09820", "submitter": "Liwei Jiang", "authors": "Liwei Jiang, Dan Li, Qisheng Wang, Shuai Wang, Songtao Wang", "title": "Improving Positive Unlabeled Learning: Practical AUL Estimation and New\n  Training Method for Extremely Imbalanced Data Sets", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Positive Unlabeled (PU) learning is widely used in many applications, where a\nbinary classifier is trained on the datasets consisting of only positive and\nunlabeled samples. In this paper, we improve PU learning over state-of-the-art\nfrom two aspects. Firstly, existing model evaluation methods for PU learning\nrequires ground truth of unlabeled samples, which is unlikely to be obtained in\npractice. In order to release this restriction, we propose an asymptotic\nunbiased practical AUL (area under the lift) estimation method, which makes use\nof raw PU data without prior knowledge of unlabeled samples.\n  Secondly, we propose ProbTagging, a new training method for extremely\nimbalanced data sets, where the number of unlabeled samples is hundreds or\nthousands of times that of positive samples. ProbTagging introduces probability\ninto the aggregation method. Specifically, each unlabeled sample is tagged\npositive or negative with the probability calculated based on the similarity to\nits positive neighbors. Based on this, multiple data sets are generated to\ntrain different models, which are then combined into an ensemble model.\nCompared to state-of-the-art work, the experimental results show that\nProbTagging can increase the AUC by up to 10%, based on three industrial and\ntwo artificial PU data sets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:32:57 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Jiang", "Liwei", ""], ["Li", "Dan", ""], ["Wang", "Qisheng", ""], ["Wang", "Shuai", ""], ["Wang", "Songtao", ""]]}, {"id": "2004.09821", "submitter": "Long Chen", "authors": "Long Chen, Martin Strauch, Dorit Merhof", "title": "Instance Segmentation of Biomedical Images with an Object-aware\n  Embedding Learned with Local Constraints", "comments": "MICCAI 2019", "journal-ref": "vol 11764, pp 451-459, MICCAI 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic instance segmentation is a problem that occurs in many biomedical\napplications. State-of-the-art approaches either perform semantic segmentation\nor refine object bounding boxes obtained from detection methods. Both suffer\nfrom crowded objects to varying degrees, merging adjacent objects or\nsuppressing a valid object. In this work, we assign an embedding vector to each\npixel through a deep neural network. The network is trained to output embedding\nvectors of similar directions for pixels from the same object, while adjacent\nobjects are orthogonal in the embedding space, which effectively avoids the\nfusion of objects in a crowd. Our method yields state-of-the-art results even\nwith a light-weighted backbone network on a cell segmentation (BBBC006 +\nDSB2018) and a leaf segmentation data set (CVPPP2017). The code and model\nweights are public available.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:33:29 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chen", "Long", ""], ["Strauch", "Martin", ""], ["Merhof", "Dorit", ""]]}, {"id": "2004.09832", "submitter": "Long Chen", "authors": "Long Chen, Dorit Merhof", "title": "MixNet: Multi-modality Mix Network for Brain Segmentation", "comments": "BrainLes, MICCAI 2018", "journal-ref": "pp 267-376, MICCAI 2018 Brainlesion: Glioma, Multiple Sclerosis,\n  Stroke and Traumatic Brain Injuries", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated brain structure segmentation is important to many clinical\nquantitative analysis and diagnoses. In this work, we introduce MixNet, a 2D\nsemantic-wise deep convolutional neural network to segment brain structure in\nmulti-modality MRI images. The network is composed of our modified deep\nresidual learning units. In the unit, we replace the traditional convolution\nlayer with the dilated convolutional layer, which avoids the use of pooling\nlayers and deconvolutional layers, reducing the number of network parameters.\nFinal predictions are made by aggregating information from multiple scales and\nmodalities. A pyramid pooling module is used to capture spatial information of\nthe anatomical structures at the output end. In addition, we test three\narchitectures (MixNetv1, MixNetv2 and MixNetv3) which fuse the modalities\ndifferently to see the effect on the results. Our network achieves the\nstate-of-the-art performance. MixNetv2 was submitted to the MRBrainS challenge\nat MICCAI 2018 and won the 3rd place in the 3-label task. On the MRBrainS2018\ndataset, which includes subjects with a variety of pathologies, the overall DSC\n(Dice Coefficient) of 84.7% (gray matter), 87.3% (white matter) and 83.4%\n(cerebrospinal fluid) were obtained with only 7 subjects as training data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:55:55 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Chen", "Long", ""], ["Merhof", "Dorit", ""]]}, {"id": "2004.09845", "submitter": "Xueying Shi", "authors": "Xueying Shi, Yueming Jin, Qi Dou, Pheng-Ann Heng", "title": "LRTD: Long-Range Temporal Dependency based Active Learning for Surgical\n  Workflow Recognition", "comments": "Accepted as a conference paper in IPCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic surgical workflow recognition in video is an essentially\nfundamental yet challenging problem for developing computer-assisted and\nrobotic-assisted surgery. Existing approaches with deep learning have achieved\nremarkable performance on analysis of surgical videos, however, heavily relying\non large-scale labelled datasets. Unfortunately, the annotation is not often\navailable in abundance, because it requires the domain knowledge of surgeons.\nIn this paper, we propose a novel active learning method for cost-effective\nsurgical video analysis. Specifically, we propose a non-local recurrent\nconvolutional network (NL-RCNet), which introduces non-local block to capture\nthe long-range temporal dependency (LRTD) among continuous frames. We then\nformulate an intra-clip dependency score to represent the overall dependency\nwithin this clip. By ranking scores among clips in unlabelled data pool, we\nselect the clips with weak dependencies to annotate, which indicates the most\ninformative ones to better benefit network training. We validate our approach\non a large surgical video dataset (Cholec80) by performing surgical workflow\nrecognition task. By using our LRTD based selection strategy, we can outperform\nother state-of-the-art active learning methods. Using only up to 50% of\nsamples, our approach can exceed the performance of full-data training.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:21:22 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 05:57:47 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Shi", "Xueying", ""], ["Jin", "Yueming", ""], ["Dou", "Qi", ""], ["Heng", "Pheng-Ann", ""]]}, {"id": "2004.09846", "submitter": "Richa Verma", "authors": "Somjit Nath, Richa Verma, Abhik Ray, Harshad Khadilkar", "title": "SIBRE: Self Improvement Based REwards for Adaptive Feedback in\n  Reinforcement Learning", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a generic reward shaping approach for improving the rate of\nconvergence in reinforcement learning (RL), called Self Improvement Based\nREwards, or SIBRE. The approach is designed for use in conjunction with any\nexisting RL algorithm, and consists of rewarding improvement over the agent's\nown past performance. We prove that SIBRE converges in expectation under the\nsame conditions as the original RL algorithm. The reshaped rewards help\ndiscriminate between policies when the original rewards are weakly\ndiscriminated or sparse. Experiments on several well-known benchmark\nenvironments with different RL algorithms show that SIBRE converges to the\noptimal policy faster and more stably. We also perform sensitivity analysis\nwith respect to hyper-parameters, in comparison with baseline RL algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:22:16 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 04:27:49 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 10:08:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Nath", "Somjit", ""], ["Verma", "Richa", ""], ["Ray", "Abhik", ""], ["Khadilkar", "Harshad", ""]]}, {"id": "2004.09855", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Sebastijan Duman\\v{c}i\\'c", "title": "Learning large logic programs by going beyond entailment", "comments": "IJCAI2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in inductive logic programming (ILP) is learning large\nprograms. We argue that a key limitation of existing systems is that they use\nentailment to guide the hypothesis search. This approach is limited because\nentailment is a binary decision: a hypothesis either entails an example or does\nnot, and there is no intermediate position. To address this limitation, we go\nbeyond entailment and use \\emph{example-dependent} loss functions to guide the\nsearch, where a hypothesis can partially cover an example. We implement our\nidea in Brute, a new ILP system which uses best-first search, guided by an\nexample-dependent loss function, to incrementally build programs. Our\nexperiments on three diverse program synthesis domains (robot planning, string\ntransformations, and ASCII art), show that Brute can substantially outperform\nexisting ILP systems, both in terms of predictive accuracies and learning\ntimes, and can learn programs 20 times larger than state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:31:06 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:11:00 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Cropper", "Andrew", ""], ["Duman\u010di\u0107", "Sebastijan", ""]]}, {"id": "2004.09863", "submitter": "Asunci\\'on Jim\\'enez-Cordero", "authors": "Asunci\\'on Jim\\'enez-Cordero, Juan Miguel Morales and Salvador Pineda", "title": "A novel embedded min-max approach for feature selection in nonlinear\n  support vector machine classification", "comments": "Published at European Journal of Operational Research", "journal-ref": null, "doi": "10.1016/j.ejor.2020.12.009", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, feature selection has become a challenging problem in\nseveral machine learning fields, such as classification problems. Support\nVector Machine (SVM) is a well-known technique applied in classification tasks.\nVarious methodologies have been proposed in the literature to select the most\nrelevant features in SVM. Unfortunately, all of them either deal with the\nfeature selection problem in the linear classification setting or propose\nad-hoc approaches that are difficult to implement in practice. In contrast, we\npropose an embedded feature selection method based on a min-max optimization\nproblem, where a trade-off between model complexity and classification accuracy\nis sought. By leveraging duality theory, we equivalently reformulate the\nmin-max problem and solve it without further ado using off-the-shelf software\nfor nonlinear optimization. The efficiency and usefulness of our approach are\ntested on several benchmark data sets in terms of accuracy, number of selected\nfeatures and interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:40:38 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 14:24:48 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 16:35:04 GMT"}, {"version": "v4", "created": "Fri, 15 Jan 2021 15:40:42 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Jim\u00e9nez-Cordero", "Asunci\u00f3n", ""], ["Morales", "Juan Miguel", ""], ["Pineda", "Salvador", ""]]}, {"id": "2004.09864", "submitter": "Linfei Feng", "authors": "Linfei Feng", "title": "Reinforcement Learning to Optimize the Logistics Distribution Routes of\n  Unmanned Aerial Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Path planning methods for the unmanned aerial vehicle (UAV) in goods delivery\nhave drawn great attention from industry and academics because of its\nflexibility which is suitable for many situations in the \"Last Kilometer\"\nbetween customer and delivery nodes. However, the complicated situation is\nstill a problem for traditional combinatorial optimization methods. Based on\nthe state-of-the-art Reinforcement Learning (RL), this paper proposed an\nimproved method to achieve path planning for UAVs in complex surroundings:\nmultiple no-fly zones. The improved approach leverages the attention mechanism\nand includes the embedding mechanism as the encoder and three different widths\nof beam search (i.e.,~1, 5, and 10) as the decoders. Policy gradients are\nutilized to train the RL model for obtaining the optimal strategies during\ninference. The results show the feasibility and efficiency of the model\napplying in this kind of complicated situation. Comparing the model with the\nresults obtained by the optimization solver OR-tools, it improves the\nreliability of the distribution system and has a guiding significance for the\nbroad application of UAVs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 09:42:03 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Feng", "Linfei", ""]]}, {"id": "2004.09890", "submitter": "David Harbecke", "authors": "David Harbecke, Christoph Alt", "title": "Considering Likelihood in NLP Classification Explanations with Occlusion\n  and Language Modeling", "comments": "ACL 2020 Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, state-of-the-art NLP models gained an increasing syntactic and\nsemantic understanding of language, and explanation methods are crucial to\nunderstand their decisions. Occlusion is a well established method that\nprovides explanations on discrete language data, e.g. by removing a language\nunit from an input and measuring the impact on a model's decision. We argue\nthat current occlusion-based methods often produce invalid or syntactically\nincorrect language data, neglecting the improved abilities of recent NLP\nmodels. Furthermore, gradient-based explanation methods disregard the discrete\ndistribution of data in NLP. Thus, we propose OLM: a novel explanation method\nthat combines occlusion and language models to sample valid and syntactically\ncorrect replacements with high likelihood, given the context of the original\ninput. We lay out a theoretical foundation that alleviates these weaknesses of\nother explanation methods in NLP and provide results that underline the\nimportance of considering data likelihood in occlusion-based explanation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 10:37:44 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Harbecke", "David", ""], ["Alt", "Christoph", ""]]}, {"id": "2004.09900", "submitter": "Harvineet Singh", "authors": "Harvineet Singh, Moumita Sinha, Atanu R. Sinha, Sahil Garg, Neha\n  Banerjee", "title": "An RNN-Survival Model to Decide Email Send Times", "comments": "11 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email communications are ubiquitous. Firms control send times of emails and\nthereby the instants at which emails reach recipients (it is assumed email is\nreceived instantaneously from the send time). However, they do not control the\nduration it takes for recipients to open emails, labeled as time-to-open.\nImportantly, among emails that are opened, most occur within a short window\nfrom their send times. We posit that emails are likely to be opened sooner when\nsend times are convenient for recipients, while for other send times, emails\ncan get ignored. Thus, to compute appropriate send times it is important to\npredict times-to-open accurately. We propose a recurrent neural network (RNN)\nin a survival model framework to predict times-to-open, for each recipient.\nUsing that we compute appropriate send times. We experiment on a data set of\nemails sent to a million customers over five months. The sequence of emails\nreceived by a person from a sender is a result of interactions with past emails\nfrom the sender, and hence contain useful signal that inform our model. This\nsequential dependence affords our proposed RNN-Survival (RNN-S) approach to\noutperform survival analysis approaches in predicting times-to-open. We show\nthat best times to send emails can be computed accurately from predicted\ntimes-to-open. This approach allows a firm to tune send times of emails, which\nis in its control, to favorably influence open rates and engagement.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 10:53:14 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Singh", "Harvineet", ""], ["Sinha", "Moumita", ""], ["Sinha", "Atanu R.", ""], ["Garg", "Sahil", ""], ["Banerjee", "Neha", ""]]}, {"id": "2004.09906", "submitter": "Jaber Kakar", "authors": "Jaber Kakar and Aydin Sezgin", "title": "Robust Interference Management for SISO Systems with Multiple\n  Over-the-Air Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.IR cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the over-the-air computation of sums.\nSpecifically, we wish to compute $M\\geq 2$ sums\n$s_m=\\sum_{k\\in\\mathcal{D}m}x_k$ over a shared complex-valued MAC at once with\nminimal mean-squared error ($\\mathsf{MSE}$). Finding appropriate Tx-Rx scaling\nfactors balance between a low error in the computation of $s_n$ and the\ninterference induced by it in the computation of other sums $s_m$, $m\\neq n$.\nIn this paper, we are interested in designing an optimal Tx-Rx scaling policy\nthat minimizes the mean-squared error $\\max_{m\\in[1:M]}\\mathsf{MSE}_m$ subject\nto a Tx power constraint with maximum power $P$. We show that an optimal design\nof the Tx-Rx scaling policy $\\left(\\bar{\\mathbf{a}},\\bar{\\mathbf{b}}\\right)$\ninvolves optimizing (a) their phases and (b) their absolute values in order to\n(i) decompose the computation of $M$ sums into, respectively, $M_R$ and $M_I$\n($M=M_R+M_I$) calculations over real and imaginary part of the Rx signal and\n(ii) to minimize the computation over each part -- real and imaginary --\nindividually. The primary focus of this paper is on (b). We derive conditions\n(i) on the feasibility of the optimization problem and (ii) on the Tx-Rx\nscaling policy of a local minimum for $M_w=2$ computations over the real\n($w=R$) or the imaginary ($w=I$) part. Extensive simulations over a single Rx\nchain for $M_w=2$ show that the level of interference in terms of $\\Delta\nD=|\\mathcal{D}_2|-|\\mathcal{D}_1|$ plays an important role on the ergodic\nworst-case $\\mathsf{MSE}$. At very high $\\mathsf{SNR}$, typically only the\nsensor with the weakest channel transmits with full power while all remaining\nsensors transmit with less to limit the interference. Interestingly, we observe\nthat due to residual interference, the ergodic worst-case $\\mathsf{MSE}$ is not\nvanishing; rather, it converges to $\\frac{|\\mathcal{D}_1||\\mathcal{D}_2|}{K}$\nas $\\mathsf{SNR}\\rightarrow\\infty$.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 11:15:26 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Kakar", "Jaber", ""], ["Sezgin", "Aydin", ""]]}, {"id": "2004.09910", "submitter": "Chiheon Kim", "authors": "Chiheon Kim, Heungsub Lee, Myungryong Jeong, Woonhyuk Baek, Boogeon\n  Yoon, Ildoo Kim, Sungbin Lim, Sungwoong Kim", "title": "torchgpipe: On-the-fly Pipeline Parallelism for Training Giant Models", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and implement a ready-to-use library in PyTorch for performing\nmicro-batch pipeline parallelism with checkpointing proposed by GPipe (Huang et\nal., 2019). In particular, we develop a set of design components to enable\npipeline-parallel gradient computation in PyTorch's define-by-run and eager\nexecution environment. We show that each component is necessary to fully\nbenefit from pipeline parallelism in such environment, and demonstrate the\nefficiency of the library by applying it to various network architectures\nincluding AmoebaNet-D and U-Net. Our library is available at\nhttps://github.com/kakaobrain/torchgpipe .\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 11:27:00 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Kim", "Chiheon", ""], ["Lee", "Heungsub", ""], ["Jeong", "Myungryong", ""], ["Baek", "Woonhyuk", ""], ["Yoon", "Boogeon", ""], ["Kim", "Ildoo", ""], ["Lim", "Sungbin", ""], ["Kim", "Sungwoong", ""]]}, {"id": "2004.09931", "submitter": "Sebastijan Dumancic", "authors": "Sebastijan Dumancic and Tias Guns and Andrew Cropper", "title": "Knowledge Refactoring for Inductive Program Synthesis", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans constantly restructure knowledge to use it more efficiently. Our goal\nis to give a machine learning system similar abilities so that it can learn\nmore efficiently. We introduce the \\textit{knowledge refactoring} problem,\nwhere the goal is to restructure a learner's knowledge base to reduce its size\nand to minimise redundancy in it. We focus on inductive logic programming,\nwhere the knowledge base is a logic program. We introduce Knorf, a system which\nsolves the refactoring problem using constraint optimisation. We evaluate our\napproach on two program induction domains: real-world string transformations\nand building Lego structures. Our experiments show that learning from\nrefactored knowledge can improve predictive accuracies fourfold and reduce\nlearning times by half.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:04:38 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 16:19:22 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 08:23:31 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dumancic", "Sebastijan", ""], ["Guns", "Tias", ""], ["Cropper", "Andrew", ""]]}, {"id": "2004.09957", "submitter": "Jason Rhuggenaath", "authors": "Jason Rhuggenaath, Alp Akcay, Yingqian Zhang and Uzay Kaymak", "title": "Algorithms for slate bandits with non-separable reward functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a slate bandit problem where the function that\ndetermines the slate-level reward is non-separable: the optimal value of the\nfunction cannot be determined by learning the optimal action for each slot. We\nare mainly concerned with cases where the number of slates is large relative to\nthe time horizon, so that trying each slate as a separate arm in a traditional\nmulti-armed bandit, would not be feasible. Our main contribution is the design\nof algorithms that still have sub-linear regret with respect to the time\nhorizon, despite the large number of slates. Experimental results on simulated\ndata and real-world data show that our proposed method outperforms popular\nbenchmark bandit algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:45:02 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Rhuggenaath", "Jason", ""], ["Akcay", "Alp", ""], ["Zhang", "Yingqian", ""], ["Kaymak", "Uzay", ""]]}, {"id": "2004.09963", "submitter": "Nick James", "authors": "Arjun Prakash, Nick James, Max Menzies, Gilad Francis", "title": "Structural clustering of volatility regimes for dynamic trading\n  strategies", "comments": "Expression edits and small methodological changes relative to v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method to find the number of volatility regimes in a\nnonstationary financial time series by applying unsupervised learning to its\nvolatility structure. We use change point detection to partition a time series\ninto locally stationary segments and then compute a distance matrix between\nsegment distributions. The segments are clustered into a learned number of\ndiscrete volatility regimes via an optimization routine. Using this framework,\nwe determine a volatility clustering structure for financial indices, large-cap\nequities, exchange-traded funds and currency pairs. Our method overcomes the\nrigid assumptions necessary to implement many parametric regime-switching\nmodels, while effectively distilling a time series into several characteristic\nbehaviours. Our results provide significant simplification of these time series\nand a strong descriptive analysis of prior behaviours of volatility. This\nempirical analysis could be used with other regime-switching implementations,\njustifying the parametric structure encoded in any candidate model. Finally, we\ncreate and validate a dynamic trading strategy that learns the optimal match\nbetween the current distribution of a time series and its past regimes, thereby\nmaking online risk-avoidance decisions in the present.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:54:23 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 10:54:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Prakash", "Arjun", ""], ["James", "Nick", ""], ["Menzies", "Max", ""], ["Francis", "Gilad", ""]]}, {"id": "2004.09965", "submitter": "Guy Shacht", "authors": "Guy Shacht, Sharon Fogel, Dov Danon, Daniel Cohen-Or and Ilya\n  Leizerson", "title": "Single Pair Cross-Modality Super Resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-visual imaging sensors are widely used in the industry for different\npurposes. Those sensors are more expensive than visual (RGB) sensors, and\nusually produce images with lower resolution. To this end, Cross-Modality\nSuper-Resolution methods were introduced, where an RGB image of a\nhigh-resolution assists in increasing the resolution of the low-resolution\nmodality. However, fusing images from different modalities is not a trivial\ntask; the output must be artifact-free and remain loyal to the characteristics\nof the target modality. Moreover, the input images are never perfectly aligned,\nwhich results in further artifacts during the fusion process.\n  We present CMSR, a deep network for Cross-Modality Super-Resolution, which\nunlike previous methods, is designed to deal with weakly aligned images. The\nnetwork is trained on the two input images only, learns their internal\nstatistics and correlations, and applies them to up-sample the target modality.\nCMSR contains an internal transformer that is trained on-the-fly together with\nthe up-sampling process itself, without explicit supervision. We show that CMSR\nsucceeds to increase the resolution of the input image, gaining valuable\ninformation from its RGB counterpart, yet in a conservative way, without\nintroducing artifacts or irrelevant details.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:57:51 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 11:54:55 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2021 09:42:09 GMT"}, {"version": "v4", "created": "Fri, 22 Jan 2021 16:17:27 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Shacht", "Guy", ""], ["Fogel", "Sharon", ""], ["Danon", "Dov", ""], ["Cohen-Or", "Daniel", ""], ["Leizerson", "Ilya", ""]]}, {"id": "2004.09968", "submitter": "Viet Duong", "authors": "Viet Duong, Phu Pham, Tongyu Yang, Yu Wang, Jiebo Luo", "title": "The Ivory Tower Lost: How College Students Respond Differently than the\n  General Public to the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the pandemic of the novel Coronavirus Disease-2019 (COVID-19) has\npresented governments with ultimate challenges. In the United States, the\ncountry with the highest confirmed COVID-19 infection cases, a nationwide\nsocial distancing protocol has been implemented by the President. For the first\ntime in a hundred years since the 1918 flu pandemic, the US population is\nmandated to stay in their households and avoid public contact. As a result, the\nmajority of public venues and services have ceased their operations. Following\nthe closure of the University of Washington on March 7th, more than a thousand\ncolleges and universities in the United States have cancelled in-person classes\nand campus activities, impacting millions of students. This paper aims to\ndiscover the social implications of this unprecedented disruption in our\ninteractive society regarding both the general public and higher education\npopulations by mining people's opinions on social media. We discover several\ntopics embedded in a large number of COVID-19 tweets that represent the most\ncentral issues related to the pandemic, which are of great concerns for both\ncollege students and the general public. Moreover, we find significant\ndifferences between these two groups of Twitter users with respect to the\nsentiments they expressed towards the COVID-19 issues. To our best knowledge,\nthis is the first social media-based study which focuses on the college student\ncommunity's demographics and responses to prevalent social issues during a\nmajor crisis.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 13:02:38 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Duong", "Viet", ""], ["Pham", "Phu", ""], ["Yang", "Tongyu", ""], ["Wang", "Yu", ""], ["Luo", "Jiebo", ""]]}, {"id": "2004.09974", "submitter": "Canxiang Yan", "authors": "Canxiang Yan, Jianhao Yan, Yangyin Xu, Cheng Niu, Jie Zhou", "title": "Learning to Encode Evolutionary Knowledge for Automatic Commenting Long\n  Novels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static knowledge graph has been incorporated extensively into\nsequence-to-sequence framework for text generation. While effectively\nrepresenting structured context, static knowledge graph failed to represent\nknowledge evolution, which is required in modeling dynamic events. In this\npaper, an automatic commenting task is proposed for long novels, which involves\nunderstanding context of more than tens of thousands of words. To model the\ndynamic storyline, especially the transitions of the characters and their\nrelations, Evolutionary Knowledge Graph(EKG) is proposed and learned within a\nmulti-task framework. Given a specific passage to comment, sequential modeling\nis used to incorporate historical and future embedding for context\nrepresentation. Further, a graph-to-sequence model is designed to utilize the\nEKG for comment generation. Extensive experimental results show that our\nEKG-based method is superior to several strong baselines on both automatic and\nhuman evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 13:09:50 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yan", "Canxiang", ""], ["Yan", "Jianhao", ""], ["Xu", "Yangyin", ""], ["Niu", "Cheng", ""], ["Zhou", "Jie", ""]]}, {"id": "2004.09978", "submitter": "Brian Gaudet", "authors": "Brian Gaudet, Roberto Furfaro, Richard Linares, Andrea Scorsoglio", "title": "Reinforcement Meta-Learning for Interception of Maneuvering\n  Exoatmospheric Targets with Parasitic Attitude Loop", "comments": "Under Consideration for publication in Journal of Spacecraft and\n  Rockets. arXiv admin note: text overlap with arXiv:1906.02113", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Reinforcement Meta-Learning to optimize an adaptive integrated\nguidance, navigation, and control system suitable for exoatmospheric\ninterception of a maneuvering target. The system maps observations consisting\nof strapdown seeker angles and rate gyro measurements directly to thruster\non-off commands. Using a high fidelity six degree-of-freedom simulator, we\ndemonstrate that the optimized policy can adapt to parasitic effects including\nseeker angle measurement lag, thruster control lag, the parasitic attitude loop\nresulting from scale factor errors and Gaussian noise on angle and rotational\nvelocity measurements, and a time varying center of mass caused by fuel\nconsumption and slosh. Importantly, the optimized policy gives good performance\nover a wide range of challenging target maneuvers. Unlike previous work that\nenhances range observability by inducing line of sight oscillations, our system\nis optimized to use only measurements available from the seeker and rate gyros.\nThrough extensive Monte Carlo simulation of randomized exoatmospheric\ninterception scenarios, we demonstrate that the optimized policy gives\nperformance close to that of augmented proportional navigation with perfect\nknowledge of the full engagement state. The optimized system is computationally\nefficient and requires minimal memory, and should be compatible with today's\nflight processors.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 21:20:59 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Gaudet", "Brian", ""], ["Furfaro", "Roberto", ""], ["Linares", "Richard", ""], ["Scorsoglio", "Andrea", ""]]}, {"id": "2004.09986", "submitter": "Daniel Leite", "authors": "Daniel Leite, Leticia Decker, Marcio Santana, Paulo Souza", "title": "EGFC: Evolving Gaussian Fuzzy Classifier from Never-Ending\n  Semi-Supervised Data Streams -- With Application to Power Quality Disturbance\n  Detection and Classification", "comments": "10 pages, 6 figures, 1 table, IEEE International Conference on Fuzzy\n  Systems (FUZZ-IEEE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-quality disturbances lead to several drawbacks such as limitation of\nthe production capacity, increased line and equipment currents, and consequent\nohmic losses; higher operating temperatures, premature faults, reduction of\nlife expectancy of machines, malfunction of equipment, and unplanned outages.\nReal-time detection and classification of disturbances are deemed essential to\nindustry standards. We propose an Evolving Gaussian Fuzzy Classification (EGFC)\nframework for semi-supervised disturbance detection and classification combined\nwith a hybrid Hodrick-Prescott and Discrete-Fourier-Transform\nattribute-extraction method applied over a landmark window of voltage\nwaveforms. Disturbances such as spikes, notching, harmonics, and oscillatory\ntransient are considered. Different from other monitoring systems, which\nrequire offline training of models based on a limited amount of data and\noccurrences, the proposed online data-stream-based EGFC method is able to learn\ndisturbance patterns autonomously from never-ending data streams by adapting\nthe parameters and structure of a fuzzy rule base on the fly. Moreover, the\nfuzzy model obtained is linguistically interpretable, which improves model\nacceptability. We show encouraging classification results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:08:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Leite", "Daniel", ""], ["Decker", "Leticia", ""], ["Santana", "Marcio", ""], ["Souza", "Paulo", ""]]}, {"id": "2004.09995", "submitter": "Zhongpai Gao", "authors": "Zhongpai Gao, Junchi Yan, Guangtao Zhai, Juyong Zhang, Yiyan Yang,\n  Xiaokang Yang", "title": "Learning Local Neighboring Structure for Robust 3D Shape Representation", "comments": null, "journal-ref": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI\n  2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mesh is a powerful data structure for 3D shapes. Representation learning for\n3D meshes is important in many computer vision and graphics applications. The\nrecent success of convolutional neural networks (CNNs) for structured data\n(e.g., images) suggests the value of adapting insight from CNN for 3D shapes.\nHowever, 3D shape data are irregular since each node's neighbors are unordered.\nVarious graph neural networks for 3D shapes have been developed with isotropic\nfilters or predefined local coordinate systems to overcome the node\ninconsistency on graphs. However, isotropic filters or predefined local\ncoordinate systems limit the representation power. In this paper, we propose a\nlocal structure-aware anisotropic convolutional operation (LSA-Conv) that\nlearns adaptive weighting matrices for each node according to the local\nneighboring structure and performs shared anisotropic filters. In fact, the\nlearnable weighting matrix is similar to the attention matrix in the random\nsynthesizer -- a new Transformer model for natural language processing (NLP).\nComprehensive experiments demonstrate that our model produces significant\nimprovement in 3D shape reconstruction compared to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 13:40:03 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 16:39:17 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2020 13:32:12 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gao", "Zhongpai", ""], ["Yan", "Junchi", ""], ["Zhai", "Guangtao", ""], ["Zhang", "Juyong", ""], ["Yang", "Yiyan", ""], ["Yang", "Xiaokang", ""]]}, {"id": "2004.10019", "submitter": "Yuan Zhou", "authors": "Zihan Zhang, Yuan Zhou, Xiangyang Ji", "title": "Almost Optimal Model-Free Reinforcement Learning via Reference-Advantage\n  Decomposition", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the reinforcement learning problem in the setting of finite-horizon\nepisodic Markov Decision Processes (MDPs) with $S$ states, $A$ actions, and\nepisode length $H$. We propose a model-free algorithm UCB-Advantage and prove\nthat it achieves $\\tilde{O}(\\sqrt{H^2SAT})$ regret where $T = KH$ and $K$ is\nthe number of episodes to play. Our regret bound improves upon the results of\n[Jin et al., 2018] and matches the best known model-based algorithms as well as\nthe information theoretic lower bound up to logarithmic factors. We also show\nthat UCB-Advantage achieves low local switching cost and applies to concurrent\nreinforcement learning, improving upon the recent results of [Bai et al.,\n2019].\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:00:06 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 13:35:38 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zhang", "Zihan", ""], ["Zhou", "Yuan", ""], ["Ji", "Xiangyang", ""]]}, {"id": "2004.10020", "submitter": "Gan Sun", "authors": "Gan Sun, Yang Cong (Senior Member, IEEE), Jiahua Dong, Qiang Wang, and\n  Ji Liu", "title": "Data Poisoning Attacks on Federated Machine Learning", "comments": "8pages,16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated machine learning which enables resource constrained node devices\n(e.g., mobile phones and IoT devices) to learn a shared model while keeping the\ntraining data local, can provide privacy, security and economic benefits by\ndesigning an effective communication protocol. However, the communication\nprotocol amongst different nodes could be exploited by attackers to launch data\npoisoning attacks, which has been demonstrated as a big threat to most machine\nlearning models. In this paper, we attempt to explore the vulnerability of\nfederated machine learning. More specifically, we focus on attacking a\nfederated multi-task learning framework, which is a federated learning\nframework via adopting a general multi-task learning framework to handle\nstatistical challenges. We formulate the problem of computing optimal poisoning\nattacks on federated multi-task learning as a bilevel program that is adaptive\nto arbitrary choice of target nodes and source attacking nodes. Then we propose\na novel systems-aware optimization method, ATTack on Federated Learning\n(AT2FL), which is efficiency to derive the implicit gradients for poisoned\ndata, and further compute optimal attack strategies in the federated machine\nlearning. Our work is an earlier study that considers issues of data poisoning\nattack for federated learning. To the end, experimental results on real-world\ndatasets show that federated multi-task learning model is very sensitive to\npoisoning attacks, when the attackers either directly poison the target nodes\nor indirectly poison the related nodes by exploiting the communication\nprotocol.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:45:05 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Sun", "Gan", "", "Senior Member, IEEE"], ["Cong", "Yang", "", "Senior Member, IEEE"], ["Dong", "Jiahua", ""], ["Wang", "Qiang", ""], ["Liu", "Ji", ""]]}, {"id": "2004.10066", "submitter": "Yifei Liu", "authors": "Yifei Liu, Chao Chen, Xi Zhang, Sihong Xie", "title": "Rigorous Explanation of Inference on Probabilistic Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models, such as Markov random fields (MRF), exploit\ndependencies among random variables to model a rich family of joint probability\ndistributions. Sophisticated inference algorithms, such as belief propagation\n(BP), can effectively compute the marginal posteriors. Nonetheless, it is still\ndifficult to interpret the inference outcomes for important human decision\nmaking. There is no existing method to rigorously attribute the inference\noutcomes to the contributing factors of the graphical models. Shapley values\nprovide an axiomatic framework, but naively computing or even approximating the\nvalues on general graphical models is challenging and less studied. We propose\nGraphShapley to integrate the decomposability of Shapley values, the structure\nof MRFs, and the iterative nature of BP inference in a principled way for fast\nShapley value computation, that 1) systematically enumerates the important\ncontributions to the Shapley values of the explaining variables without\nduplicate; 2) incrementally compute the contributions without starting from\nscratches. We theoretically characterize GraphShapley regarding independence,\nequal contribution, and additivity. On nine graphs, we demonstrate that\nGraphShapley provides sensible and practical explanations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:57:12 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Liu", "Yifei", ""], ["Chen", "Chao", ""], ["Zhang", "Xi", ""], ["Xie", "Sihong", ""]]}, {"id": "2004.10076", "submitter": "Raghavendra Selvan", "authors": "Raghavendra Selvan and Erik B Dam", "title": "Tensor Networks for Medical Image Classification", "comments": "Accepted for publication at International Conference on Medical\n  Imaging with Deep Learning (MIDL), 2020. Reviews on Openreview here:\n  https://openreview.net/forum?id=jjk6bxk07G", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing adoption of machine learning tools like neural networks\nacross several domains, interesting connections and comparisons to concepts\nfrom other domains are coming to light. In this work, we focus on the class of\nTensor Networks, which has been a work horse for physicists in the last two\ndecades to analyse quantum many-body systems. Building on the recent interest\nin tensor networks for machine learning, we extend the Matrix Product State\ntensor networks (which can be interpreted as linear classifiers operating in\nexponentially high dimensional spaces) to be useful in medical image analysis\ntasks. We focus on classification problems as a first step where we motivate\nthe use of tensor networks and propose adaptions for 2D images using classical\nimage domain concepts such as local orderlessness of images. With the proposed\nlocally orderless tensor network model (LoTeNet), we show that tensor networks\nare capable of attaining performance that is comparable to state-of-the-art\ndeep learning methods. We evaluate the model on two publicly available medical\nimaging datasets and show performance improvements with fewer model\nhyperparameters and lesser computational resources compared to relevant\nbaseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:02:58 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Selvan", "Raghavendra", ""], ["Dam", "Erik B", ""]]}, {"id": "2004.10083", "submitter": "Seyma Yucer", "authors": "Seyma Yucer, Furkan Tektas, Mesih Veysi Kilinc, Ilyas Kandemir, Hasari\n  Celebi, Yakup Genc, Yusuf Sinan Akgul", "title": "RSSI-based Outdoor Localization with Single Unmanned Aerial Vehicle", "comments": "Accepted by IEEE Wireless Communications and Networking Conference\n  (WCNC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization of a target object has been performed conventionally using\nmultiple terrestrial reference nodes. This paradigm is recently shifted towards\nutilization of unmanned aerial vehicles (UAVs) for locating target objects.\nSince locating of a target using simultaneous multiple UAVs is costly and\nimpractical, achieving this task by utilizing single UAV becomes desirable.\nHence, in this paper, we propose an RSSI-based localization method that\nutilizes only a single UAV. The proposed approach is based on clustering method\nalong with the Singular Value Decomposition (SVD). The performance of the\nproposed method is verified by the experimental measurements collected by a UAV\nthat we have designed and computer simulations. The results show that the\nproposed method can achieve location accuracy as low as 7m depending on the\nnumber of iterations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 15:05:41 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Yucer", "Seyma", ""], ["Tektas", "Furkan", ""], ["Kilinc", "Mesih Veysi", ""], ["Kandemir", "Ilyas", ""], ["Celebi", "Hasari", ""], ["Genc", "Yakup", ""], ["Akgul", "Yusuf Sinan", ""]]}, {"id": "2004.10098", "submitter": "Nikhil Mehta", "authors": "Nikhil Mehta, Kevin J Liang, Vinay K Verma and Lawrence Carin", "title": "Continual Learning using a Bayesian Nonparametric Dictionary of Weight\n  Factors", "comments": "Proceedings of the 24th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2021 Post-conference updates: Fixed\n  typo in equation (11) and updated references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Naively trained neural networks tend to experience catastrophic forgetting in\nsequential task settings, where data from previous tasks are unavailable. A\nnumber of methods, using various model expansion strategies, have been proposed\nrecently as possible solutions. However, determining how much to expand the\nmodel is left to the practitioner, and often a constant schedule is chosen for\nsimplicity, regardless of how complex the incoming task is. Instead, we propose\na principled Bayesian nonparametric approach based on the Indian Buffet Process\n(IBP) prior, letting the data determine how much to expand the model\ncomplexity. We pair this with a factorization of the neural network's weight\nmatrices. Such an approach allows the number of factors of each weight matrix\nto scale with the complexity of the task, while the IBP prior encourages sparse\nweight factor selection and factor reuse, promoting positive knowledge transfer\nbetween tasks. We demonstrate the effectiveness of our method on a number of\ncontinual learning benchmarks and analyze how weight factors are allocated and\nreused throughout the training.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:20:19 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 04:08:52 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 23:28:11 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Mehta", "Nikhil", ""], ["Liang", "Kevin J", ""], ["Verma", "Vinay K", ""], ["Carin", "Lawrence", ""]]}, {"id": "2004.10120", "submitter": "Ga\\\"etan Hadjeres", "authors": "Ga\\\"etan Hadjeres and L\\'eopold Crestel", "title": "Vector Quantized Contrastive Predictive Coding for Template-based Music\n  Generation", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a flexible method for generating variations of\ndiscrete sequences in which tokens can be grouped into basic units, like\nsentences in a text or bars in music. More precisely, given a template\nsequence, we aim at producing novel sequences sharing perceptible similarities\nwith the original template without relying on any annotation; so our problem of\ngenerating variations is intimately linked to the problem of learning relevant\nhigh-level representations without supervision. Our contribution is two-fold:\nFirst, we propose a self-supervised encoding technique, named Vector Quantized\nContrastive Predictive Coding which allows to learn a meaningful assignment of\nthe basic units over a discrete set of codes, together with mechanisms allowing\nto control the information content of these learnt discrete representations.\nSecondly, we show how these compressed representations can be used to generate\nvariations of a template sequence by using an appropriate attention pattern in\nthe Transformer architecture. We illustrate our approach on the corpus of J.S.\nBach chorales where we discuss the musical meaning of the learnt discrete codes\nand show that our proposed method allows to generate coherent and high-quality\nvariations of a given template.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 15:58:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Hadjeres", "Ga\u00ebtan", ""], ["Crestel", "L\u00e9opold", ""]]}, {"id": "2004.10126", "submitter": "Takato Yasuno", "authors": "Takato Yasuno", "title": "Generative Synthetic Augmentation using Label-to-Image Translation for\n  Nuclei Image Segmentation", "comments": "15pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical image diagnosis, pathology image analysis using semantic\nsegmentation becomes important for efficient screening as a field of digital\npathology. The spatial augmentation is ordinary used for semantic segmentation.\nTumor images under malignant are rare and to annotate the labels of nuclei\nregion takes much time-consuming. We require an effective use of dataset to\nmaximize the segmentation accuracy. It is expected that some augmentation to\ntransform generalized images influence the segmentation performance. We propose\na synthetic augmentation using label-to-image translation, mapping from a\nsemantic label with the edge structure to a real image. Exactly this paper deal\nwith stain slides of nuclei in tumor. Actually, we demonstrate several\nsegmentation algorithms applied to the initial dataset that contains real\nimages and labels using synthetic augmentation in order to add their\ngeneralized images. We computes and reports that a proposed synthetic\naugmentation procedure improve their accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:10:11 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:00:27 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 22:48:46 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Yasuno", "Takato", ""]]}, {"id": "2004.10130", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Masazumi Amakata, Masahiro Okano", "title": "Natural Disaster Classification using Aerial Photography Explainable for\n  Typhoon Damaged Feature", "comments": "10pages, 5figures", "journal-ref": "ICPR2020 Workshops and Challenges (forthcoming on 10 January 2021)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years, typhoon damages has become social problem owing to climate\nchange. In 9 September 2019, Typhoon Faxai passed on the Chiba in Japan, whose\ndamages included with electric provision stop because of strong wind recorded\non the maximum 45 meter per second. A large amount of tree fell down, and the\nneighbor electric poles also fell down at the same time. These disaster\nfeatures have caused that it took 18 days for recovery longer than past ones.\nImmediate responses are important for faster recovery. As long as we can,\naerial survey for global screening of devastated region would be required for\ndecision support to respond where to recover ahead. This paper proposes a\npractical method to visualize the damaged areas focused on the typhoon disaster\nfeatures using aerial photography. This method can classify eight classes which\ncontains land covers without damages and areas with disaster. Using target\nfeature class probabilities, we can visualize disaster feature map to scale a\ncolor range. Furthermore, we can realize explainable map on each unit grid\nimages to compute the convolutional activation map using Grad-CAM. We\ndemonstrate case studies applied to aerial photographs recorded at the Chiba\nregion after typhoon.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:21:52 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 10:46:54 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 16:43:35 GMT"}, {"version": "v4", "created": "Fri, 23 Oct 2020 09:06:28 GMT"}, {"version": "v5", "created": "Mon, 16 Nov 2020 14:29:26 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yasuno", "Takato", ""], ["Amakata", "Masazumi", ""], ["Okano", "Masahiro", ""]]}, {"id": "2004.10151", "submitter": "Ari Holtzman", "authors": "Yonatan Bisk, Ari Holtzman, Jesse Thomason, Jacob Andreas, Yoshua\n  Bengio, Joyce Chai, Mirella Lapata, Angeliki Lazaridou, Jonathan May,\n  Aleksandr Nisnevich, Nicolas Pinto, Joseph Turian", "title": "Experience Grounds Language", "comments": "Empirical Methods in Natural Language Processing (EMNLP), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language understanding research is held back by a failure to relate language\nto the physical world it describes and to the social interactions it\nfacilitates. Despite the incredible effectiveness of language processing models\nto tackle tasks after being trained on text alone, successful linguistic\ncommunication relies on a shared experience of the world. It is this shared\nexperience that makes utterances meaningful.\n  Natural language processing is a diverse field, and progress throughout its\ndevelopment has come from new representational theories, modeling techniques,\ndata collection paradigms, and tasks. We posit that the present success of\nrepresentation learning approaches trained on large, text-only corpora requires\nthe parallel tradition of research on the broader physical and social context\nof language to address the deeper questions of communication.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 16:56:27 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 02:03:56 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 00:40:12 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Bisk", "Yonatan", ""], ["Holtzman", "Ari", ""], ["Thomason", "Jesse", ""], ["Andreas", "Jacob", ""], ["Bengio", "Yoshua", ""], ["Chai", "Joyce", ""], ["Lapata", "Mirella", ""], ["Lazaridou", "Angeliki", ""], ["May", "Jonathan", ""], ["Nisnevich", "Aleksandr", ""], ["Pinto", "Nicolas", ""], ["Turian", "Joseph", ""]]}, {"id": "2004.10162", "submitter": "Sanchari Sen", "authors": "Sanchari Sen, Balaraman Ravindran, Anand Raghunathan", "title": "EMPIR: Ensembles of Mixed Precision Deep Networks for Increased\n  Robustness against Adversarial Attacks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their\nadoption in safety-critical applications such as self-driving cars, drones, and\nhealthcare. Notably, DNNs are vulnerable to adversarial attacks in which small\ninput perturbations can produce catastrophic misclassifications. In this work,\nwe propose EMPIR, ensembles of quantized DNN models with different numerical\nprecisions, as a new approach to increase robustness against adversarial\nattacks. EMPIR is based on the observation that quantized neural networks often\ndemonstrate much higher robustness to adversarial attacks than full precision\nnetworks, but at the cost of a substantial loss in accuracy on the original\n(unperturbed) inputs. EMPIR overcomes this limitation to achieve the 'best of\nboth worlds', i.e., the higher unperturbed accuracies of the full precision\nmodels combined with the higher robustness of the low precision models, by\ncomposing them in an ensemble. Further, as low precision DNN models have\nsignificantly lower computational and storage requirements than full precision\nmodels, EMPIR models only incur modest compute and memory overheads compared to\na single full-precision model (<25% in our evaluations). We evaluate EMPIR\nacross a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10\nand ImageNet) and under 4 different adversarial attacks. Our results indicate\nthat EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5%\nfor the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets\nrespectively, when compared to single full-precision models, without\nsacrificing accuracy on the unperturbed inputs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:17:09 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Sen", "Sanchari", ""], ["Ravindran", "Balaraman", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2004.10166", "submitter": "Shashank Srikant", "authors": "Shashank Srikant, Nicolas Lesimple, Una-May O'Reilly", "title": "Dependency-Based Neural Representations for Classifying Lines of\n  Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of classifying a line of program as containing a\nvulnerability or not using machine learning. Such a line-level classification\ntask calls for a program representation which goes beyond reasoning from the\ntokens present in the line. We seek a distributed representation in a latent\nfeature space which can capture the control and data dependencies of tokens\nappearing on a line of program, while also ensuring lines of similar meaning\nhave similar features. We present a neural architecture, Vulcan, that\nsuccessfully demonstrates both these requirements. It extracts contextual\ninformation about tokens in a line and inputs them as Abstract Syntax Tree\n(AST) paths to a bi-directional LSTM with an attention mechanism. It\nconcurrently represents the meanings of tokens in a line by recursively\nembedding the lines where they are most recently defined. In our experiments,\nVulcan compares favorably with a state-of-the-art classifier, which requires\nsignificant preprocessing of programs, suggesting the utility of using deep\nlearning to model program dependence information.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 17:00:22 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Srikant", "Shashank", ""], ["Lesimple", "Nicolas", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2004.10170", "submitter": "Victor Blanco", "authors": "V\\'ictor Blanco, Alberto Jap\\'on and Justo Puerto", "title": "A Mathematical Programming approach to Binary Supervised Classification\n  with Label Noise", "comments": "17 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose novel methodologies to construct Support Vector\nMachine -based classifiers that takes into account that label noises occur in\nthe training sample. We propose different alternatives based on solving Mixed\nInteger Linear and Non Linear models by incorporating decisions on relabeling\nsome of the observations in the training dataset. The first method incorporates\nrelabeling directly in the SVM model while a second family of methods combines\nclustering with classification at the same time, giving rise to a model that\napplies simultaneously similarity measures and SVM. Extensive computational\nexperiments are reported based on a battery of standard datasets taken from UCI\nMachine Learning repository, showing the effectiveness of the proposed\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:25:54 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Blanco", "V\u00edctor", ""], ["Jap\u00f3n", "Alberto", ""], ["Puerto", "Justo", ""]]}, {"id": "2004.10178", "submitter": "Ariel Neufeld", "authors": "Pushpendu Ghosh, Ariel Neufeld, Jajati Keshari Sahoo", "title": "Forecasting directional movements of stock prices for intraday trading\n  using LSTM and random forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as\ntraining methodologies to analyze their effectiveness in forecasting\nout-of-sample directional movements of constituent stocks of the S&P 500 from\nJanuary 1993 till December 2018 for intraday trading. We introduce a\nmulti-feature setting consisting not only of the returns with respect to the\nclosing prices, but also with respect to the opening prices and intraday\nreturns. As trading strategy, we use Krauss et al. (2017) and Fischer & Krauss\n(2018) as benchmark. On each trading day, we buy the 10 stocks with the highest\nprobability and sell short the 10 stocks with the lowest probability to\noutperform the market in terms of intraday returns -- all with equal monetary\nweight. Our empirical results show that the multi-feature setting provides a\ndaily return, prior to transaction costs, of 0.64% using LSTM networks, and\n0.54% using random forests. Hence we outperform the single-feature setting in\nFischer & Krauss (2018) and Krauss et al. (2017) consisting only of the daily\nreturns with respect to the closing prices, having corresponding daily returns\nof 0.41% and of 0.39% with respect to LSTM and random forests, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:35:48 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 19:16:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ghosh", "Pushpendu", ""], ["Neufeld", "Ariel", ""], ["Sahoo", "Jajati Keshari", ""]]}, {"id": "2004.10181", "submitter": "Suyash Gupta", "authors": "Maxime Cauchois and Suyash Gupta and John Duchi", "title": "Knowing what you know: valid and validated confidence sets in multiclass\n  and multilabel prediction", "comments": "Updated section on multilabel settings addressing the cases when\n  labels may repel each other", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop conformal prediction methods for constructing valid predictive\nconfidence sets in multiclass and multilabel problems without assumptions on\nthe data generating distribution. A challenge here is that typical conformal\nprediction methods---which give marginal validity (coverage)\nguarantees---provide uneven coverage, in that they address easy examples at the\nexpense of essentially ignoring difficult examples. By leveraging ideas from\nquantile regression, we build methods that always guarantee correct coverage\nbut additionally provide (asymptotically optimal) conditional coverage for both\nmulticlass and multilabel prediction problems. To address the potential\nchallenge of exponentially large confidence sets in multilabel prediction, we\nbuild tree-structured classifiers that efficiently account for interactions\nbetween labels. Our methods can be bolted on top of any classification\nmodel---neural network, random forest, boosted tree---to guarantee its\nvalidity. We also provide an empirical evaluation, simultaneously providing new\nvalidation methods, that suggests the more robust coverage of our confidence\nsets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:45:38 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 22:53:23 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 18:22:12 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Cauchois", "Maxime", ""], ["Gupta", "Suyash", ""], ["Duchi", "John", ""]]}, {"id": "2004.10188", "submitter": "Marc'Aurelio Ranzato", "authors": "Anton Bakhtin and Yuntian Deng and Sam Gross and Myle Ott and\n  Marc'Aurelio Ranzato and Arthur Szlam", "title": "Residual Energy-Based Models for Text", "comments": "long journal version", "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-41", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current large-scale auto-regressive language models display impressive\nfluency and can generate convincing text. In this work we start by asking the\nquestion: Can the generations of these models be reliably distinguished from\nreal text by statistical discriminators? We find experimentally that the answer\nis affirmative when we have access to the training data for the model, and\nguardedly affirmative even if we do not.\n  This suggests that the auto-regressive models can be improved by\nincorporating the (globally normalized) discriminators into the generative\nprocess. We give a formalism for this using the Energy-Based Model framework,\nand show that it indeed improves the results of the generative models, measured\nboth in terms of perplexity and in terms of human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:44:03 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:50:36 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bakhtin", "Anton", ""], ["Deng", "Yuntian", ""], ["Gross", "Sam", ""], ["Ott", "Myle", ""], ["Ranzato", "Marc'Aurelio", ""], ["Szlam", "Arthur", ""]]}, {"id": "2004.10190", "submitter": "Ryan Julian", "authors": "Ryan Julian, Benjamin Swanson, Gaurav S. Sukhatme, Sergey Levine,\n  Chelsea Finn, and Karol Hausman", "title": "Never Stop Learning: The Effectiveness of Fine-Tuning in Robotic\n  Reinforcement Learning", "comments": "8.5 pages, 9 figures. See video overview and experiments at\n  https://youtu.be/pPDVewcSpdc and project website at\n  https://ryanjulian.me/continual-fine-tuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the great promises of robot learning systems is that they will be able\nto learn from their mistakes and continuously adapt to ever-changing\nenvironments. Despite this potential, most of the robot learning systems today\nare deployed as a fixed policy and they are not being adapted after their\ndeployment. Can we efficiently adapt previously learned behaviors to new\nenvironments, objects and percepts in the real world? In this paper, we present\na method and empirical evidence towards a robot learning framework that\nfacilitates continuous adaption. In particular, we demonstrate how to adapt\nvision-based robotic manipulation policies to new variations by fine-tuning via\noff-policy reinforcement learning, including changes in background, object\nshape and appearance, lighting conditions, and robot morphology. Further, this\nadaptation uses less than 0.2% of the data necessary to learn the task from\nscratch. We find that our approach of adapting pre-trained policies leads to\nsubstantial performance gains over the course of fine-tuning, and that\npre-training via RL is essential: training from scratch or adapting from\nsupervised ImageNet features are both unsuccessful with such small amounts of\ndata. We also find that these positive results hold in a limited continual\nlearning setting, in which we repeatedly fine-tune a single lineage of policies\nusing data from a succession of new tasks. Our empirical conclusions are\nconsistently supported by experiments on simulated manipulation tasks, and by\n52 unique fine-tuning experiments on a real robotic grasping system pre-trained\non 580,000 grasps.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:57:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 13:43:53 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Julian", "Ryan", ""], ["Swanson", "Benjamin", ""], ["Sukhatme", "Gaurav S.", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""], ["Hausman", "Karol", ""]]}, {"id": "2004.10201", "submitter": "Payam Karisani", "authors": "Payam Karisani, Joyce C. Ho, and Eugene Agichtein", "title": "Domain-Guided Task Decomposition with Self-Training for Detecting\n  Personal Events in Social Media", "comments": "WWW 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining social media content for tasks such as detecting personal experiences\nor events, suffer from lexical sparsity, insufficient training data, and\ninventive lexicons. To reduce the burden of creating extensive labeled data and\nimprove classification performance, we propose to perform these tasks in two\nsteps: 1. Decomposing the task into domain-specific sub-tasks by identifying\nkey concepts, thus utilizing human domain understanding; and 2. Combining the\nresults of learners for each key concept using co-training to reduce the\nrequirements for labeled training data. We empirically show the effectiveness\nand generality of our approach, Co-Decomp, using three representative social\nmedia mining tasks, namely Personal Health Mention detection, Crisis Report\ndetection, and Adverse Drug Reaction monitoring. The experiments show that our\nmodel is able to outperform the state-of-the-art text classification\nmodels--including those using the recently introduced BERT model--when small\namounts of training data are available.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 14:50:31 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Karisani", "Payam", ""], ["Ho", "Joyce C.", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2004.10220", "submitter": "Andriy Mulyar", "authors": "Andriy Mulyar and Bridget T. McInnes", "title": "MT-Clinical BERT: Scaling Clinical Information Extraction with Multitask\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical notes contain an abundance of important but not-readily accessible\ninformation about patients. Systems to automatically extract this information\nrely on large amounts of training data for which their exists limited resources\nto create. Furthermore, they are developed dis-jointly; meaning that no\ninformation can be shared amongst task-specific systems. This bottle-neck\nunnecessarily complicates practical application, reduces the performance\ncapabilities of each individual solution and associates the engineering debt of\nmanaging multiple information extraction systems. We address these challenges\nby developing Multitask-Clinical BERT: a single deep learning model that\nsimultaneously performs eight clinical tasks spanning entity extraction, PHI\nidentification, language entailment and similarity by sharing representations\namongst tasks. We find our single system performs competitively with all\nstate-the-art task-specific systems while also benefiting from massive\ncomputational benefits at inference.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 18:04:08 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mulyar", "Andriy", ""], ["McInnes", "Bridget T.", ""]]}, {"id": "2004.10221", "submitter": "Benjamin Billot", "authors": "Benjamin Billot, Eleanor D. Robinson, Adrian V. Dalca, Juan Eugenio\n  Iglesias", "title": "Partial Volume Segmentation of Brain MRI Scans of any Resolution and\n  Contrast", "comments": "12 pages, 7 figures", "journal-ref": "International Conference on Medical Image Computing and\n  Computer-Assisted Intervention (MICCAI) 2020, pp. 177-187", "doi": "10.1007/978-3-030-59728-3_18", "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial voluming (PV) is arguably the last crucial unsolved problem in\nBayesian segmentation of brain MRI with probabilistic atlases. PV occurs when\nvoxels contain multiple tissue classes, giving rise to image intensities that\nmay not be representative of any one of the underlying classes. PV is\nparticularly problematic for segmentation when there is a large resolution gap\nbetween the atlas and the test scan, e.g., when segmenting clinical scans with\nthick slices, or when using a high-resolution atlas. In this work, we present\nPV-SynthSeg, a convolutional neural network (CNN) that tackles this problem by\ndirectly learning a mapping between (possibly multi-modal) low resolution (LR)\nscans and underlying high resolution (HR) segmentations. PV-SynthSeg simulates\nLR images from HR label maps with a generative model of PV, and can be trained\nto segment scans of any desired target contrast and resolution, even for\npreviously unseen modalities where neither images nor segmentations are\navailable at training. PV-SynthSeg does not require any preprocessing, and runs\nin seconds. We demonstrate the accuracy and flexibility of the method with\nextensive experiments on three datasets and 2,680 scans. The code is available\nat https://github.com/BBillot/SynthSeg.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 18:04:44 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 12:01:53 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 12:56:24 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Billot", "Benjamin", ""], ["Robinson", "Eleanor D.", ""], ["Dalca", "Adrian V.", ""], ["Iglesias", "Juan Eugenio", ""]]}, {"id": "2004.10240", "submitter": "Konstantinos Benidis", "authors": "Konstantinos Benidis, Syama Sundar Rangapuram, Valentin Flunkert,\n  Bernie Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael\n  Bohlke-Schneider, David Salinas, Lorenzo Stella, Laurent Callot, Tim\n  Januschowski", "title": "Neural forecasting: Introduction and literature overview", "comments": "66 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based forecasting methods have become ubiquitous in\nlarge-scale industrial forecasting applications over the last years. As the\nprevalence of neural network based solutions among the best entries in the\nrecent M4 competition shows, the recent popularity of neural forecasting\nmethods is not limited to industry and has also reached academia. This article\naims at providing an introduction and an overview of some of the advances that\nhave permitted the resurgence of neural networks in machine learning. Building\non these foundations, the article then gives an overview of the recent\nliterature on neural networks for forecasting and applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 18:53:42 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Benidis", "Konstantinos", ""], ["Rangapuram", "Syama Sundar", ""], ["Flunkert", "Valentin", ""], ["Wang", "Bernie", ""], ["Maddix", "Danielle", ""], ["Turkmen", "Caner", ""], ["Gasthaus", "Jan", ""], ["Bohlke-Schneider", "Michael", ""], ["Salinas", "David", ""], ["Stella", "Lorenzo", ""], ["Callot", "Laurent", ""], ["Januschowski", "Tim", ""]]}, {"id": "2004.10245", "submitter": "Daphney-Stavroula Zois", "authors": "Yasitha Warahena Liyanage, Daphney-Stavroula Zois, Charalampos Chelmis", "title": "On-the-Fly Joint Feature Selection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint feature selection and classification in an online setting is essential\nfor time-sensitive decision making. However, most existing methods treat this\ncoupled problem independently. Specifically, online feature selection methods\ncan handle either streaming features or data instances offline to produce a\nfixed set of features for classification, while online classification methods\nclassify incoming instances using full knowledge about the feature space.\nNevertheless, all existing methods utilize a set of features, common for all\ndata instances, for classification. Instead, we propose a framework to perform\njoint feature selection and classification on-the-fly, so as to minimize the\nnumber of features evaluated for every data instance and maximize\nclassification accuracy. We derive the optimum solution of the associated\noptimization problem and analyze its structure. Two algorithms are proposed,\nETANA and F-ETANA, which are based on the optimum solution and its properties.\nWe evaluate the performance of the proposed algorithms on several public\ndatasets, demonstrating (i) the dominance of the proposed algorithms over the\nstate-of-the-art, and (ii) its applicability to broad range of application\ndomains including clinical research and natural language processing.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:19:39 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Liyanage", "Yasitha Warahena", ""], ["Zois", "Daphney-Stavroula", ""], ["Chelmis", "Charalampos", ""]]}, {"id": "2004.10246", "submitter": "Shakeel Raja Mr.", "authors": "Shakeel Raja", "title": "Music Generation with Temporal Structure Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a novel feature augmentation approach for\ngenerating structured musical compositions comprising melodies and harmonies.\nThe proposed method augments a connectionist generation model with count-down\nto song conclusion and meter markers as extra input features to study whether\nneural networks can learn to produce more aesthetically pleasing and structured\nmusical output as a consequence of augmenting the input data with structural\nfeatures. An RNN architecture with LSTM cells is trained on the Nottingham folk\nmusic dataset in a supervised sequence learning setup, following a Music\nLanguage Modelling approach, and then applied to generation of harmonies and\nmelodies. Our experiments show an improved prediction performance for both\ntypes of annotation. The generated music was also subjectively evaluated using\nan on-line Turing style listening test which confirms a substantial improvement\nin the aesthetic quality and in the perceived structure of the music generated\nusing the temporal structure.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:19:58 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Raja", "Shakeel", ""]]}, {"id": "2004.10250", "submitter": "David Evans", "authors": "Mainuddin Ahmad Jonas, David Evans", "title": "Certifying Joint Adversarial Robustness for Model Ensembles", "comments": "Open source code for our implementation and for reproducing our\n  experiments is available at\n  https://github.com/jonas-maj/ensemble-adversarial-robustness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are often vulnerable to adversarial\nexamples.Several proposed defenses deploy an ensemble of models with the hope\nthat, although the individual models may be vulnerable, an adversary will not\nbe able to find an adversarial example that succeeds against the ensemble.\nDepending on how the ensemble is used, an attacker may need to find a single\nadversarial example that succeeds against all, or a majority, of the models in\nthe ensemble. The effectiveness of ensemble defenses against strong adversaries\ndepends on the vulnerability spaces of models in the ensemble being disjoint.\nWe consider the joint vulnerability of an ensemble of models, and propose a\nnovel technique for certifying the joint robustness of ensembles, building upon\nprior works on single-model robustness certification. We evaluate the\nrobustness of various models ensembles, including models trained using\ncost-sensitive robustness to be diverse, to improve understanding of the\npotential effectiveness of ensemble models as a defense against adversarial\nexamples.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:38:31 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Jonas", "Mainuddin Ahmad", ""], ["Evans", "David", ""]]}, {"id": "2004.10255", "submitter": "Yonatan Woodbridge", "authors": "Yonatan Woodbridge, Gal Elidan and Ami Wiesel", "title": "Convex Nonparanormal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying uncertainty in predictions or, more generally, estimating the\nposterior conditional distribution, is a core challenge in machine learning and\nstatistics. We introduce Convex Nonparanormal Regression (CNR), a conditional\nnonparanormal approach for coping with this task. CNR involves a convex\noptimization of a posterior defined via a rich dictionary of pre-defined non\nlinear transformations on Gaussians. It can fit an arbitrary conditional\ndistribution, including multimodal and non-symmetric posteriors. For the\nspecial but powerful case of a piecewise linear dictionary, we provide a closed\nform of the posterior mean which can be used for point-wise predictions.\nFinally, we demonstrate the advantages of CNR over classical competitors using\nsynthetic and real world data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:42:43 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 05:46:26 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Woodbridge", "Yonatan", ""], ["Elidan", "Gal", ""], ["Wiesel", "Ami", ""]]}, {"id": "2004.10267", "submitter": "Alexander Hanbo Li", "authors": "Alexander Hanbo Li, Yaqing Wang, Changyou Chen, Jing Gao", "title": "Decomposed Adversarial Learned Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective inference for a generative adversarial model remains an important\nand challenging problem. We propose a novel approach, Decomposed Adversarial\nLearned Inference (DALI), which explicitly matches prior and conditional\ndistributions in both data and code spaces, and puts a direct constraint on the\ndependency structure of the generative model. We derive an equivalent form of\nthe prior and conditional matching objective that can be optimized efficiently\nwithout any parametric assumption on the data. We validate the effectiveness of\nDALI on the MNIST, CIFAR-10, and CelebA datasets by conducting quantitative and\nqualitative evaluations. Results demonstrate that DALI significantly improves\nboth reconstruction and generation as compared to other adversarial inference\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:00:35 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Li", "Alexander Hanbo", ""], ["Wang", "Yaqing", ""], ["Chen", "Changyou", ""], ["Gao", "Jing", ""]]}, {"id": "2004.10275", "submitter": "Michael Chang", "authors": "Michael Alan Chang, Domenic Bottini, Lisa Jian, Pranay Kumar, Aurojit\n  Panda, Scott Shenker", "title": "How to Train your DNN: The Network Operator Edition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Nets have hit quite a crest, But physical networks are where they\nmust rest, And here we put them all to the test, To see which network\noptimization is best.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:14:46 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Chang", "Michael Alan", ""], ["Bottini", "Domenic", ""], ["Jian", "Lisa", ""], ["Kumar", "Pranay", ""], ["Panda", "Aurojit", ""], ["Shenker", "Scott", ""]]}, {"id": "2004.10281", "submitter": "Matthew Wicker", "authors": "Matthew Wicker, Luca Laurenti, Andrea Patane, Marta Kwiatkowska", "title": "Probabilistic Safety for Bayesian Neural Networks", "comments": "UAI 2020; 13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study probabilistic safety for Bayesian Neural Networks (BNNs) under\nadversarial input perturbations. Given a compact set of input points, $T\n\\subseteq \\mathbb{R}^m$, we study the probability w.r.t. the BNN posterior that\nall the points in $T$ are mapped to the same region $S$ in the output space. In\nparticular, this can be used to evaluate the probability that a network sampled\nfrom the BNN is vulnerable to adversarial attacks. We rely on relaxation\ntechniques from non-convex optimization to develop a method for computing a\nlower bound on probabilistic safety for BNNs, deriving explicit procedures for\nthe case of interval and linear function propagation techniques. We apply our\nmethods to BNNs trained on a regression task, airborne collision avoidance, and\nMNIST, empirically showing that our approach allows one to certify\nprobabilistic safety of BNNs with millions of parameters.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:25:33 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 02:06:15 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Wicker", "Matthew", ""], ["Laurenti", "Luca", ""], ["Patane", "Andrea", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2004.10290", "submitter": "Jianping Lin", "authors": "Jianping Lin, Dong Liu, Houqiang Li, Feng Wu", "title": "M-LVC: Multiple Frames Prediction for Learned Video Compression", "comments": "Accepted to appear in CVPR2020; camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end learned video compression scheme for low-latency\nscenarios. Previous methods are limited in using the previous one frame as\nreference. Our method introduces the usage of the previous multiple frames as\nreferences. In our scheme, the motion vector (MV) field is calculated between\nthe current frame and the previous one. With multiple reference frames and\nassociated multiple MV fields, our designed network can generate more accurate\nprediction of the current frame, yielding less residual. Multiple reference\nframes also help generate MV prediction, which reduces the coding cost of MV\nfield. We use two deep auto-encoders to compress the residual and the MV,\nrespectively. To compensate for the compression error of the auto-encoders, we\nfurther design a MV refinement network and a residual refinement network,\ntaking use of the multiple reference frames as well. All the modules in our\nscheme are jointly optimized through a single rate-distortion loss function. We\nuse a step-by-step training strategy to optimize the entire scheme.\nExperimental results show that the proposed method outperforms the existing\nlearned video compression methods for low-latency mode. Our method also\nperforms better than H.265 in both PSNR and MS-SSIM. Our code and models are\npublicly available.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:42:02 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Lin", "Jianping", ""], ["Liu", "Dong", ""], ["Li", "Houqiang", ""], ["Wu", "Feng", ""]]}, {"id": "2004.10293", "submitter": "Xu Shen", "authors": "Xu Shen, Ivo Batkovic, Vijay Govindarajan, Paolo Falcone, Trevor\n  Darrell, and Francesco Borrelli", "title": "ParkPredict: Motion and Intent Prediction of Vehicles in Parking Lots", "comments": "* Indicates equal contribution. Accepted at IEEE Intelligent Vehicles\n  Symposium (IV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of predicting driver behavior in parking lots, an\nenvironment which is less structured than typical road networks and features\ncomplex, interactive maneuvers in a compact space. Using the CARLA simulator,\nwe develop a parking lot environment and collect a dataset of human parking\nmaneuvers. We then study the impact of model complexity and feature information\nby comparing a multi-modal Long Short-Term Memory (LSTM) prediction model and a\nConvolution Neural Network LSTM (CNN-LSTM) to a physics-based Extended Kalman\nFilter (EKF) baseline. Our results show that 1) intent can be estimated well\n(roughly 85% top-1 accuracy and nearly 100% top-3 accuracy with the LSTM and\nCNN-LSTM model); 2) knowledge of the human driver's intended parking spot has a\nmajor impact on predicting parking trajectory; and 3) the semantic\nrepresentation of the environment improves long term predictions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:46:32 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Shen", "Xu", ""], ["Batkovic", "Ivo", ""], ["Govindarajan", "Vijay", ""], ["Falcone", "Paolo", ""], ["Darrell", "Trevor", ""], ["Borrelli", "Francesco", ""]]}, {"id": "2004.10301", "submitter": "Jayesh Gupta", "authors": "Jayesh K. Gupta, Kunal Menda, Zachary Manchester and Mykel J.\n  Kochenderfer", "title": "Structured Mechanical Models for Robot Learning and Control", "comments": "First two authors contributed equally. Accepted at L4DC2020. Source\n  code and videos at https://sites.google.com/stanford.edu/smm/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-based methods are the dominant paradigm for controlling robotic\nsystems, though their efficacy depends heavily on the accuracy of the model\nused. Deep neural networks have been used to learn models of robot dynamics\nfrom data, but they suffer from data-inefficiency and the difficulty to\nincorporate prior knowledge. We introduce Structured Mechanical Models, a\nflexible model class for mechanical systems that are data-efficient, easily\namenable to prior knowledge, and easily usable with model-based control\ntechniques. The goal of this work is to demonstrate the benefits of using\nStructured Mechanical Models in lieu of black-box neural networks when modeling\nrobot dynamics. We demonstrate that they generalize better from limited data\nand yield more reliable model-based controllers on a variety of simulated\nrobotic domains.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 21:12:03 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Gupta", "Jayesh K.", ""], ["Menda", "Kunal", ""], ["Manchester", "Zachary", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2004.10341", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad\n  Shafique", "title": "DRMap: A Generic DRAM Data Mapping Policy for Energy-Efficient\n  Processing of Convolutional Neural Networks", "comments": "To appear at the 57th Design Automation Conference (DAC), July 2020,\n  San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many convolutional neural network (CNN) accelerators face performance- and\nenergy-efficiency challenges which are crucial for embedded implementations,\ndue to high DRAM access latency and energy. Recently, some DRAM architectures\nhave been proposed to exploit subarray-level parallelism for decreasing the\naccess latency. Towards this, we present a design space exploration methodology\nto study the latency and energy of different mapping policies on different DRAM\narchitectures, and identify the pareto-optimal design choices. The results show\nthat the energy-efficient DRAM accesses can be achieved by a mapping policy\nthat orderly prioritizes to maximize the row buffer hits, bank- and\nsubarray-level parallelism.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:26:23 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Hanif", "Muhammad Abdullah", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2004.10342", "submitter": "Ankit Singh Rawat", "authors": "Felix X. Yu, Ankit Singh Rawat, Aditya Krishna Menon, Sanjiv Kumar", "title": "Federated Learning with Only Positive Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning a multi-class classification model in the federated\nsetting, where each user has access to the positive data associated with only a\nsingle class. As a result, during each federated learning round, the users need\nto locally update the classifier without having access to the features and the\nmodel parameters for the negative classes. Thus, naively employing conventional\ndecentralized learning such as the distributed SGD or Federated Averaging may\nlead to trivial or extremely poor classifiers. In particular, for the embedding\nbased classifiers, all the class embeddings might collapse to a single point.\n  To address this problem, we propose a generic framework for training with\nonly positive labels, namely Federated Averaging with Spreadout (FedAwS), where\nthe server imposes a geometric regularizer after each round to encourage\nclasses to be spreadout in the embedding space. We show, both theoretically and\nempirically, that FedAwS can almost match the performance of conventional\nlearning where users have access to negative labels. We further extend the\nproposed method to the settings with large output spaces.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:35:02 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Yu", "Felix X.", ""], ["Rawat", "Ankit Singh", ""], ["Menon", "Aditya Krishna", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.10356", "submitter": "Denis Dos Reis", "authors": "Denis dos Reis, Marc\\'ilio de Souto, Elaine de Sousa, Gustavo Batista", "title": "Quantifying With Only Positive Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification is the research field that studies the task of counting how\nmany data points belong to each class in an unlabeled sample. Traditionally,\nresearchers in this field assume the availability of training data containing\nlabeled observations for all classes to induce quantification models. Although\nquantification methods usually estimate counts for every class, we are often\ninterested in those regarding only a target class. In this context, we have\nproposed a novel setting, known as One-class Quantification (OCQ), where\nreliable training data is only available for the target class. On the other\nhand, Positive and Unlabeled Learning (PUL), which is another branch of Machine\nLearning, has offered solutions that can be applied to OCQ, despite\nquantification not being the focal point of PUL. In this article, we close the\ngap between PUL and OCQ and bring both areas together under a unified view. We\ncompare our methods, Passive Aggressive Threshold (PAT) and One Distribution\nInside (ODIn), against PUL methods and show that PAT generally is the fastest\nand most accurate algorithm. Contrary to PUL methods, PAT and ODIn also can\ninduce quantification models that can be replied to quantify different samples\nof data. We additionally introduce Exhaustive TIcE (ExTIcE), an improved\nversion of the PUL algorithm Tree Induction for c Estimation (TIcE), and show\nthat it quantifies more accurately than PAT and the other algorithms in\nscenarios where a considerable number of negative observations are identical to\npositive observations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 01:18:25 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Reis", "Denis dos", ""], ["de Souto", "Marc\u00edlio", ""], ["de Sousa", "Elaine", ""], ["Batista", "Gustavo", ""]]}, {"id": "2004.10386", "submitter": "Jingfeng Zhang", "authors": "Jingfeng Zhang, Cheng Li, Antonio Robles-Kelly and Mohan Kankanhalli", "title": "Hierarchically Fair Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the federated learning is adopted among competitive agents with siloed\ndatasets, agents are self-interested and participate only if they are fairly\nrewarded. To encourage the application of federated learning, this paper\nemploys a management strategy, i.e., more contributions should lead to more\nrewards. We propose a novel hierarchically fair federated learning (HFFL)\nframework. Under this framework, agents are rewarded in proportion to their\npre-negotiated contribution levels. HFFL+ extends this to incorporate\nheterogeneous models. Theoretical analysis and empirical evaluation on several\ndatasets confirm the efficacy of our frameworks in upholding fairness and thus\nfacilitating federated learning in the competitive settings.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:41:06 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:42:33 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Zhang", "Jingfeng", ""], ["Li", "Cheng", ""], ["Robles-Kelly", "Antonio", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "2004.10387", "submitter": "Qing Han", "authors": "Qing Han, Shusen Yang, Xuebin Ren, Cong Zhao, Jingqi Zhang, Xinyu Yang", "title": "OL4EL: Online Learning for Edge-cloud Collaborative Learning on\n  Heterogeneous Edges with Resource Constraints", "comments": "7 pages, 5 figures, to appear in IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning (ML) at network edge is a promising paradigm\nthat can preserve both network bandwidth and privacy of data providers.\nHowever, heterogeneous and limited computation and communication resources on\nedge servers (or edges) pose great challenges on distributed ML and formulate a\nnew paradigm of Edge Learning (i.e. edge-cloud collaborative machine learning).\nIn this article, we propose a novel framework of 'learning to learn' for\neffective Edge Learning (EL) on heterogeneous edges with resource constraints.\nWe first model the dynamic determination of collaboration strategy (i.e. the\nallocation of local iterations at edge servers and global aggregations on the\nCloud during collaborative learning process) as an online optimization problem\nto achieve the tradeoff between the performance of EL and the resource\nconsumption of edge servers. Then, we propose an Online Learning for EL (OL4EL)\nframework based on the budget-limited multi-armed bandit model. OL4EL supports\nboth synchronous and asynchronous learning patterns, and can be used for both\nsupervised and unsupervised learning tasks. To evaluate the performance of\nOL4EL, we conducted both real-world testbed experiments and extensive\nsimulations based on docker containers, where both Support Vector Machine and\nK-means were considered as use cases. Experimental results demonstrate that\nOL4EL significantly outperforms state-of-the-art EL and other collaborative ML\napproaches in terms of the trade-off between learning performance and resource\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:51:58 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 08:13:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Han", "Qing", ""], ["Yang", "Shusen", ""], ["Ren", "Xuebin", ""], ["Zhao", "Cong", ""], ["Zhang", "Jingqi", ""], ["Yang", "Xinyu", ""]]}, {"id": "2004.10390", "submitter": "Yang Guo", "authors": "Xi Wu, Yang Guo, Jiefeng Chen, Yingyu Liang, Somesh Jha, Prasad\n  Chalasani", "title": "Representation Bayesian Risk Decompositions and Multi-Source Domain\n  Adaptation", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider representation learning (hypothesis class $\\mathcal{H} =\n\\mathcal{F}\\circ\\mathcal{G}$) where training and test distributions can be\ndifferent. Recent studies provide hints and failure examples for domain\ninvariant representation learning, a common approach for this problem, but the\nexplanations provided are somewhat different and do not provide a unified\npicture. In this paper, we provide new decompositions of risk which give\nfiner-grained explanations and clarify potential generalization issues. For\nSingle-Source Domain Adaptation, we give an exact decomposition (an equality)\nof the target risk, via a natural hybrid argument, as sum of three factors: (1)\nsource risk, (2) representation conditional label divergence, and (3)\nrepresentation covariate shift. We derive a similar decomposition for the\nMulti-Source case. These decompositions reveal factors (2) and (3) as the\nprecise reasons for failure to generalize. For example, we demonstrate that\ndomain adversarial neural networks (DANN) attempt to regularize for (3) but\nmiss (2), while a recent technique Invariant Risk Minimization (IRM) attempts\nto account for (2) but does not consider (3). We also verify our observations\nexperimentally.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 04:09:21 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 02:25:37 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wu", "Xi", ""], ["Guo", "Yang", ""], ["Chen", "Jiefeng", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""], ["Chalasani", "Prasad", ""]]}, {"id": "2004.10397", "submitter": "Wenqi Wei", "authors": "Wenqi Wei, Ling Liu, Margaret Loper, Ka-Ho Chow, Mehmet Emre Gursoy,\n  Stacey Truex and Yanzhao Wu", "title": "A Framework for Evaluating Gradient Leakage Attacks in Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is an emerging distributed machine learning framework\nfor collaborative model training with a network of clients (edge devices). FL\noffers default client privacy by allowing clients to keep their sensitive data\non local devices and to only share local training parameter updates with the\nfederated server. However, recent studies have shown that even sharing local\nparameter updates from a client to the federated server may be susceptible to\ngradient leakage attacks and intrude the client privacy regarding its training\ndata. In this paper, we present a principled framework for evaluating and\ncomparing different forms of client privacy leakage attacks. We first provide\nformal and experimental analysis to show how adversaries can reconstruct the\nprivate local training data by simply analyzing the shared parameter update\nfrom local training (e.g., local gradient or weight update vector). We then\nanalyze how different hyperparameter configurations in federated learning and\ndifferent settings of the attack algorithm may impact on both attack\neffectiveness and attack cost. Our framework also measures, evaluates, and\nanalyzes the effectiveness of client privacy leakage attacks under different\ngradient compression ratios when using communication efficient FL protocols.\nOur experiments also include some preliminary mitigation strategies to\nhighlight the importance of providing a systematic attack evaluation framework\ntowards an in-depth understanding of the various forms of client privacy\nleakage threats in federated learning and developing theoretical foundations\nfor attack mitigation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 05:15:03 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 04:31:26 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Wei", "Wenqi", ""], ["Liu", "Ling", ""], ["Loper", "Margaret", ""], ["Chow", "Ka-Ho", ""], ["Gursoy", "Mehmet Emre", ""], ["Truex", "Stacey", ""], ["Wu", "Yanzhao", ""]]}, {"id": "2004.10398", "submitter": "Min-hwan Oh", "authors": "Min-hwan Oh, Garud Iyengar", "title": "Sequential Anomaly Detection using Inverse Reinforcement Learning", "comments": "Published in KDD 2019 (Oral in Research Paper Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most interesting application scenarios in anomaly detection is\nwhen sequential data are targeted. For example, in a safety-critical\nenvironment, it is crucial to have an automatic detection system to screen the\nstreaming data gathered by monitoring sensors and to report abnormal\nobservations if detected in real-time. Oftentimes, stakes are much higher when\nthese potential anomalies are intentional or goal-oriented. We propose an\nend-to-end framework for sequential anomaly detection using inverse\nreinforcement learning (IRL), whose objective is to determine the\ndecision-making agent's underlying function which triggers his/her behavior.\nThe proposed method takes the sequence of actions of a target agent (and\npossibly other meta information) as input. The agent's normal behavior is then\nunderstood by the reward function which is inferred via IRL. We use a neural\nnetwork to represent a reward function. Using a learned reward function, we\nevaluate whether a new observation from the target agent follows a normal\npattern. In order to construct a reliable anomaly detection method and take\ninto consideration the confidence of the predicted anomaly score, we adopt a\nBayesian approach for IRL. The empirical study on publicly available real-world\ndata shows that our proposed method is effective in identifying anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 05:17:36 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Oh", "Min-hwan", ""], ["Iyengar", "Garud", ""]]}, {"id": "2004.10410", "submitter": "Joeran Beel", "authors": "Mark Grennan, Joeran Beel", "title": "Synthetic vs. Real Reference Strings for Citation Parsing, and the\n  Importance of Re-training and Out-Of-Sample Data for Meaningful Evaluations:\n  Experiments with GROBID, GIANT and Cora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citation parsing, particularly with deep neural networks, suffers from a lack\nof training data as available datasets typically contain only a few thousand\ntraining instances. Manually labelling citation strings is very time-consuming,\nhence synthetically created training data could be a solution. However, as of\nnow, it is unknown if synthetically created reference-strings are suitable to\ntrain machine learning algorithms for citation parsing. To find out, we train\nGrobid, which uses Conditional Random Fields, with a) human-labelled reference\nstrings from 'real' bibliographies and b) synthetically created reference\nstrings from the GIANT dataset. We find that both synthetic and organic\nreference strings are equally suited for training Grobid (F1 = 0.74). We\nadditionally find that retraining Grobid has a notable impact on its\nperformance, for both synthetic and real data (+30% in F1). Having as many\ntypes of labelled fields as possible during training also improves\neffectiveness, even if these fields are not available in the evaluation data\n(+13.5% F1). We conclude that synthetic data is suitable for training (deep)\ncitation parsing models. We further suggest that in future evaluations of\nreference parsers both evaluation data similar and dissimilar to the training\ndata should be used for more meaningful evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 06:34:36 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 14:36:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Grennan", "Mark", ""], ["Beel", "Joeran", ""]]}, {"id": "2004.10430", "submitter": "Jie Chen", "authors": "Jie Chen, Wenjun Xu", "title": "Policy Gradient from Demonstration and Curiosity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With reinforcement learning, an agent could learn complex behaviors from\nhigh-level abstractions of the task. However, exploration and reward shaping\nremained challenging for existing methods, especially in scenarios where the\nextrinsic feedback was sparse. Expert demonstrations have been investigated to\nsolve these difficulties, but a tremendous number of high-quality\ndemonstrations were usually required. In this work, an integrated policy\ngradient algorithm was proposed to boost exploration and facilitate intrinsic\nreward learning from only limited number of demonstrations. We achieved this by\nreformulating the original reward function with two additional terms, where the\nfirst term measured the Jensen-Shannon divergence between current policy and\nthe expert, and the second term estimated the agent's uncertainty about the\nenvironment. The presented algorithm was evaluated on a range of simulated\ntasks with sparse extrinsic reward signals where only one single demonstrated\ntrajectory was provided to each task, superior exploration efficiency and high\naverage return were demonstrated in all tasks. Furthermore, it was found that\nthe agent could imitate the expert's behavior and meanwhile sustain high\nreturn.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 07:57:39 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 10:57:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Chen", "Jie", ""], ["Xu", "Wenjun", ""]]}, {"id": "2004.10439", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Krister Wolff, Leo Laine", "title": "Tactical Decision-Making in Autonomous Driving by Reinforcement Learning\n  with Uncertainty Estimation", "comments": null, "journal-ref": "IEEE Intelligent Vehicles Symposium (IV), 2020, pp. 1292-1298", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) can be used to create a tactical decision-making\nagent for autonomous driving. However, previous approaches only output\ndecisions and do not provide information about the agent's confidence in the\nrecommended actions. This paper investigates how a Bayesian RL technique, based\non an ensemble of neural networks with additional randomized prior functions\n(RPF), can be used to estimate the uncertainty of decisions in autonomous\ndriving. A method for classifying whether or not an action should be considered\nsafe is also introduced. The performance of the ensemble RPF method is\nevaluated by training an agent on a highway driving scenario. It is shown that\nthe trained agent can estimate the uncertainty of its decisions and indicate an\nunacceptable level when the agent faces a situation that is far from the\ntraining distribution. Furthermore, within the training distribution, the\nensemble RPF agent outperforms a standard Deep Q-Network agent. In this study,\nthe estimated uncertainty is used to choose safe actions in unknown situations.\nHowever, the uncertainty information could also be used to identify situations\nthat should be added to the training process.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:22:28 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""]]}, {"id": "2004.10454", "submitter": "Yi Ren", "authors": "Yi Ren, Jinglin Liu, Xu Tan, Zhou Zhao, Sheng Zhao, Tie-Yan Liu", "title": "A Study of Non-autoregressive Model for Sequence Generation", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-autoregressive (NAR) models generate all the tokens of a sequence in\nparallel, resulting in faster generation speed compared to their autoregressive\n(AR) counterparts but at the cost of lower accuracy. Different techniques\nincluding knowledge distillation and source-target alignment have been proposed\nto bridge the gap between AR and NAR models in various tasks such as neural\nmachine translation (NMT), automatic speech recognition (ASR), and text to\nspeech (TTS). With the help of those techniques, NAR models can catch up with\nthe accuracy of AR models in some tasks but not in some others. In this work,\nwe conduct a study to understand the difficulty of NAR sequence generation and\ntry to answer: (1) Why NAR models can catch up with AR models in some tasks but\nnot all? (2) Why techniques like knowledge distillation and source-target\nalignment can help NAR models. Since the main difference between AR and NAR\nmodels is that NAR models do not use dependency among target tokens while AR\nmodels do, intuitively the difficulty of NAR sequence generation heavily\ndepends on the strongness of dependency among target tokens. To quantify such\ndependency, we propose an analysis model called CoMMA to characterize the\ndifficulty of different NAR sequence generation tasks. We have several\ninteresting findings: 1) Among the NMT, ASR and TTS tasks, ASR has the most\ntarget-token dependency while TTS has the least. 2) Knowledge distillation\nreduces the target-token dependency in target sequence and thus improves the\naccuracy of NAR models. 3) Source-target alignment constraint encourages\ndependency of a target token on source tokens and thus eases the training of\nNAR models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:16:09 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 00:17:11 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ren", "Yi", ""], ["Liu", "Jinglin", ""], ["Tan", "Xu", ""], ["Zhao", "Zhou", ""], ["Zhao", "Sheng", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2004.10468", "submitter": "Dani Kiyasseh", "authors": "Dani Kiyasseh, Tingting Zhu, David A. Clifton", "title": "SoQal: Selective Oracle Questioning in Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Large sets of unlabelled data within the healthcare domain remain\nunderutilized. Active learning offers a way to exploit these datasets by\niteratively requesting an oracle (e.g. medical professional) to label\ninstances. This process, which can be costly and time-consuming is\noverly-dependent upon an oracle. To alleviate this burden, we propose SoQal, a\nquestioning strategy that dynamically determines when a label should be\nrequested from an oracle. We perform experiments on five publically-available\ndatasets and illustrate SoQal's superiority relative to baseline approaches,\nincluding its ability to reduce oracle label requests by up to 35%. SoQal also\nperforms competitively in the presence of label noise: a scenario that\nsimulates clinicians' uncertain diagnoses when faced with difficult\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:53:55 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kiyasseh", "Dani", ""], ["Zhu", "Tingting", ""], ["Clifton", "David A.", ""]]}, {"id": "2004.10476", "submitter": "Yaoming Cai", "authors": "Yaoming Cai, Zijia Zhang, Zhihua Cai, Xiaobo Liu, Xinwei Jiang, and\n  Qin Yan", "title": "Graph Convolutional Subspace Clustering: A Robust Subspace Clustering\n  Framework for Hyperspectral Image", "comments": "This paper is submitted to IEEE TGRS", "journal-ref": null, "doi": "10.1109/TGRS.2020.3018135", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperspectral image (HSI) clustering is a challenging task due to the high\ncomplexity of HSI data. Subspace clustering has been proven to be powerful for\nexploiting the intrinsic relationship between data points. Despite the\nimpressive performance in the HSI clustering, traditional subspace clustering\nmethods often ignore the inherent structural information among data. In this\npaper, we revisit the subspace clustering with graph convolution and present a\nnovel subspace clustering framework called Graph Convolutional Subspace\nClustering (GCSC) for robust HSI clustering. Specifically, the framework\nrecasts the self-expressiveness property of the data into the non-Euclidean\ndomain, which results in a more robust graph embedding dictionary. We show that\ntraditional subspace clustering models are the special forms of our framework\nwith the Euclidean data. Basing on the framework, we further propose two novel\nsubspace clustering models by using the Frobenius norm, namely Efficient GCSC\n(EGCSC) and Efficient Kernel GCSC (EKGCSC). Both models have a globally optimal\nclosed-form solution, which makes them easier to implement, train, and apply in\npractice. Extensive experiments on three popular HSI datasets demonstrate that\nEGCSC and EKGCSC can achieve state-of-the-art clustering performance and\ndramatically outperforms many existing methods with significant margins.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:09:19 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cai", "Yaoming", ""], ["Zhang", "Zijia", ""], ["Cai", "Zhihua", ""], ["Liu", "Xiaobo", ""], ["Jiang", "Xinwei", ""], ["Yan", "Qin", ""]]}, {"id": "2004.10495", "submitter": "Dong Wang", "authors": "Dong Wang, Xiaoqian Qin, Fengyi Song, Li Cheng", "title": "Stabilizing Training of Generative Adversarial Nets via Langevin Stein\n  Variational Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs), famous for the capability of learning\ncomplex underlying data distribution, are however known to be tricky in the\ntraining process, which would probably result in mode collapse or performance\ndeterioration. Current approaches of dealing with GANs' issues almost utilize\nsome practical training techniques for the purpose of regularization, which on\nthe other hand undermines the convergence and theoretical soundness of GAN. In\nthis paper, we propose to stabilize GAN training via a novel particle-based\nvariational inference -- Langevin Stein variational gradient descent (LSVGD),\nwhich not only inherits the flexibility and efficiency of original SVGD but\naims to address its instability issues by incorporating an extra disturbance\ninto the update dynamics. We further demonstrate that by properly adjusting the\nnoise variance, LSVGD simulates a Langevin process whose stationary\ndistribution is exactly the target distribution. We also show that LSVGD\ndynamics has an implicit regularization which is able to enhance particles'\nspread-out and diversity. At last we present an efficient way of applying\nparticle-based variational inference on a general GAN training procedure no\nmatter what loss function is adopted. Experimental results on one synthetic\ndataset and three popular benchmark datasets -- Cifar-10, Tiny-ImageNet and\nCelebA validate that LSVGD can remarkably improve the performance and stability\nof various GAN models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:20:04 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Wang", "Dong", ""], ["Qin", "Xiaoqian", ""], ["Song", "Fengyi", ""], ["Cheng", "Li", ""]]}, {"id": "2004.10507", "submitter": "Sushmita Mitra Prof.", "authors": "Sanhita Basu, Sushmita Mitra, Nilanjan Saha", "title": "Deep Learning for Screening COVID-19 using Chest X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever increasing demand for screening millions of prospective \"novel\ncoronavirus\" or COVID-19 cases, and due to the emergence of high false\nnegatives in the commonly used PCR tests, the necessity for probing an\nalternative simple screening mechanism of COVID-19 using radiological images\n(like chest X-Rays) assumes importance. In this scenario, machine learning (ML)\nand deep learning (DL) offer fast, automated, effective strategies to detect\nabnormalities and extract key features of the altered lung parenchyma, which\nmay be related to specific signatures of the COVID-19 virus. However, the\navailable COVID-19 datasets are inadequate to train deep neural networks.\nTherefore, we propose a new concept called domain extension transfer learning\n(DETL). We employ DETL, with pre-trained deep convolutional neural network, on\na related large chest X-Ray dataset that is tuned for classifying between four\nclasses \\textit{viz.} $normal$, $pneumonia$, $other\\_disease$, and $Covid-19$.\nA 5-fold cross validation is performed to estimate the feasibility of using\nchest X-Rays to diagnose COVID-19. The initial results show promise, with the\npossibility of replication on bigger and more diverse data sets. The overall\naccuracy was measured as $90.13\\% \\pm 0.14$. In order to get an idea about the\nCOVID-19 detection transparency, we employed the concept of Gradient Class\nActivation Map (Grad-CAM) for detecting the regions where the model paid more\nattention during the classification. This was found to strongly correlate with\nclinical findings, as validated by experts.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:41:50 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 05:44:02 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 04:31:56 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2020 20:17:35 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Basu", "Sanhita", ""], ["Mitra", "Sushmita", ""], ["Saha", "Nilanjan", ""]]}, {"id": "2004.10522", "submitter": "Lucie Perrotta", "authors": "Lucie Perrotta", "title": "Practical calibration of the temperature parameter in Gibbs posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PAC-Bayesian algorithms and Gibbs posteriors are gaining popularity due to\ntheir robustness against model misspecification even when Bayesian inference is\ninconsistent. The PAC-Bayesian alpha-posterior is a generalization of the\nstandard Bayes posterior which can be tempered with a parameter alpha to handle\ninconsistency. Data driven methods for tuning alpha have been proposed but are\nstill few, and are often computationally heavy. Additionally, the adequacy of\nthese methods in cases where we use variational approximations instead of exact\nalpha-posteriors is not clear. This narrows their usage to simple models and\nprevents their application to large-scale problems. We hence need fast methods\nto tune alpha that work with both exact and variational alpha-posteriors.\nFirst, we propose two data driven methods for tuning alpha, based on\nsample-splitting and bootstrapping respectively. Second, we formulate the\n(exact or variational) posteriors of three popular statistical models, and\nmodify them into alpha-posteriors. For each model, we test our strategies and\ncompare them with standard Bayes and Grunwald's SafeBayes. While bootstrapping\nachieves mixed results, sample-splitting and SafeBayes perform well on the\nexact and variational alpha-posteriors we describe, and achieve better results\nthan standard Bayes in misspecified or complex models. Additionally,\nsample-splitting outperforms SafeBayes in terms of speed. Sample-splitting\noffers a fast and easy solution to inconsistency and typically performs\nsimilarly or better than Bayesian inference. Our results provide hints on the\ncalibration of alpha in PAC-Bayesian and Gibbs posteriors, and may facilitate\nusing these methods in large and complex models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:23:45 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Perrotta", "Lucie", ""]]}, {"id": "2004.10529", "submitter": "Mengheng Xue", "authors": "Mengheng Xue, Samantha Kappagoda and David K. A. Mordecai", "title": "Energy Disaggregation with Semi-supervised Sparse Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential smart meters have been widely installed in urban houses\nnationwide to provide efficient and responsive monitoring and billing for\nconsumers. Studies have shown that providing customers with device-level usage\ninformation can lead consumers to economize significant amounts of energy,\nwhile modern smart meters can only provide informative whole-home data with low\nresolution. Thus, energy disaggregation research which aims to decompose the\naggregated energy consumption data into its component appliances has attracted\nbroad attention. In this paper, a discriminative disaggregation model based on\nsparse coding has been evaluated on large-scale household power usage dataset\nfor energy conservation. We utilize a structured prediction model for providing\ndiscriminative sparse coding training, accordingly, maximizing the energy\ndisaggregation performance. Designing such large scale disaggregation task is\ninvestigated analytically, and examined in the real-world smart meter dataset\ncompared with benchmark models.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 21:05:25 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 20:32:46 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 16:03:15 GMT"}, {"version": "v4", "created": "Mon, 13 Jul 2020 16:07:59 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Xue", "Mengheng", ""], ["Kappagoda", "Samantha", ""], ["Mordecai", "David K. A.", ""]]}, {"id": "2004.10536", "submitter": "Iris Huijben", "authors": "Iris A.M. Huijben, Bastiaan S. Veeling, and Ruud J.G. van Sloun", "title": "Learning Sampling and Model-Based Signal Recovery for Compressed Sensing\n  MRI", "comments": null, "journal-ref": "In ICASSP 2020-2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)", "doi": "10.1109/ICASSP40776.2020.9053331", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) MRI relies on adequate undersampling of the k-space\nto accelerate the acquisition without compromising image quality. Consequently,\nthe design of optimal sampling patterns for these k-space coefficients has\nreceived significant attention, with many CS MRI methods exploiting\nvariable-density probability distributions. Realizing that an optimal sampling\npattern may depend on the downstream task (e.g. image reconstruction,\nsegmentation, or classification), we here propose joint learning of both\ntask-adaptive k-space sampling and a subsequent model-based proximal-gradient\nrecovery network. The former is enabled through a probabilistic generative\nmodel that leverages the Gumbel-softmax relaxation to sample across trainable\nbeliefs while maintaining differentiability. The proposed combination of a\nhighly flexible sampling model and a model-based (sampling-adaptive) image\nreconstruction network facilitates exploration and efficient training, yielding\nimproved MR image quality compared to other sampling baselines.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:50:03 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Huijben", "Iris A. M.", ""], ["Veeling", "Bastiaan S.", ""], ["van Sloun", "Ruud J. G.", ""]]}, {"id": "2004.10537", "submitter": "Dominik Martin", "authors": "Dominik Martin, Philipp Spitzer, Niklas K\\\"uhl", "title": "A New Metric for Lumpy and Intermittent Demand Forecasts:\n  Stock-keeping-oriented Prediction Error Costs", "comments": "Proceedings of the 53rd Annual Hawaii International Conference on\n  System Sciences (HICSS-53), Grand Wailea, Maui, HI, January 7-10, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasts of product demand are essential for short- and long-term\noptimization of logistics and production. Thus, the most accurate prediction\npossible is desirable. In order to optimally train predictive models, the\ndeviation of the forecast compared to the actual demand needs to be assessed by\na proper metric. However, if a metric does not represent the actual prediction\nerror, predictive models are insufficiently optimized and, consequently, will\nyield inaccurate predictions. The most common metrics such as MAPE or RMSE,\nhowever, are not suitable for the evaluation of forecasting errors, especially\nfor lumpy and intermittent demand patterns, as they do not sufficiently account\nfor, e.g., temporal shifts (prediction before or after actual demand) or\ncost-related aspects. Therefore, we propose a novel metric that, in addition to\nstatistical considerations, also addresses business aspects. Additionally, we\nevaluate the metric based on simulated and real demand time series from the\nautomotive aftermarket.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 12:50:24 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Martin", "Dominik", ""], ["Spitzer", "Philipp", ""], ["K\u00fchl", "Niklas", ""]]}, {"id": "2004.10568", "submitter": "Markus Nagel", "authors": "Markus Nagel, Rana Ali Amjad, Mart van Baalen, Christos Louizos,\n  Tijmen Blankevoort", "title": "Up or Down? Adaptive Rounding for Post-Training Quantization", "comments": "Published as a conference paper at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When quantizing neural networks, assigning each floating-point weight to its\nnearest fixed-point value is the predominant approach. We find that, perhaps\nsurprisingly, this is not the best we can do. In this paper, we propose\nAdaRound, a better weight-rounding mechanism for post-training quantization\nthat adapts to the data and the task loss. AdaRound is fast, does not require\nfine-tuning of the network, and only uses a small amount of unlabelled data. We\nstart by theoretically analyzing the rounding problem for a pre-trained neural\nnetwork. By approximating the task loss with a Taylor series expansion, the\nrounding task is posed as a quadratic unconstrained binary optimization\nproblem. We simplify this to a layer-wise local loss and propose to optimize\nthis loss with a soft relaxation. AdaRound not only outperforms\nrounding-to-nearest by a significant margin but also establishes a new\nstate-of-the-art for post-training quantization on several networks and tasks.\nWithout fine-tuning, we can quantize the weights of Resnet18 and Resnet50 to 4\nbits while staying within an accuracy loss of 1%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 13:44:28 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:51:23 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Nagel", "Markus", ""], ["Amjad", "Rana Ali", ""], ["van Baalen", "Mart", ""], ["Louizos", "Christos", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2004.10586", "submitter": "Sam Coveney Dr", "authors": "Sam Coveney, Cesare Corrado, Caroline H Roney, Daniel O'Hare, Steven E\n  Williams, Mark D O'Neill, Steven A Niederer, Richard H Clayton, Jeremy E\n  Oakley, Richard D Wilkinson", "title": "Gaussian Process Manifold Interpolation for Probabilistic Atrial\n  Activation Maps and Uncertain Conduction Velocity", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2019.0345", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In patients with atrial fibrillation, local activation time (LAT) maps are\nroutinely used for characterising patient pathophysiology. The gradient of LAT\nmaps can be used to calculate conduction velocity (CV), which directly relates\nto material conductivity and may provide an important measure of atrial\nsubstrate properties. Including uncertainty in CV calculations would help with\ninterpreting the reliability of these measurements. Here, we build upon a\nrecent insight into reduced-rank Gaussian processes (GP) to perform\nprobabilistic interpolation of uncertain LAT directly on human atrial\nmanifolds. Our Gaussian Process Manifold Interpolation (GPMI) method accounts\nfor the topology of the atria, and allows for calculation of statistics for\npredicted CV. We demonstrate our method on two clinical cases, and perform\nvalidation against a simulated ground truth. CV uncertainty depends on data\ndensity, wave propagation direction, and CV magnitude. GPMI is suitable for\nprobabilistic interpolation of other uncertain quantities on non-Euclidean\nmanifolds.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:10:05 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 10:57:59 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Coveney", "Sam", ""], ["Corrado", "Cesare", ""], ["Roney", "Caroline H", ""], ["O'Hare", "Daniel", ""], ["Williams", "Steven E", ""], ["O'Neill", "Mark D", ""], ["Niederer", "Steven A", ""], ["Clayton", "Richard H", ""], ["Oakley", "Jeremy E", ""], ["Wilkinson", "Richard D", ""]]}, {"id": "2004.10599", "submitter": "Antoine Blanchard", "authors": "Antoine Blanchard and Themistoklis Sapsis", "title": "Bayesian Optimization with Output-Weighted Optimal Sampling", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109901", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian optimization, accounting for the importance of the output\nrelative to the input is a crucial yet challenging exercise, as it can\nconsiderably improve the final result but often involves inaccurate and\ncumbersome entropy estimations. We approach the problem from the perspective of\nimportance-sampling theory, and advocate the use of the likelihood ratio to\nguide the search algorithm towards regions of the input space where the\nobjective function to be minimized assumes abnormally small values. The\nlikelihood ratio acts as a sampling weight and can be computed at each\niteration without severely deteriorating the overall efficiency of the\nalgorithm. In particular, it can be approximated in a way that makes the\napproach tractable in high dimensions. The \"likelihood-weighted\" acquisition\nfunctions introduced in this work are found to outperform their unweighted\ncounterparts in a number of applications.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:38:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 16:37:03 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 15:54:17 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 21:58:21 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Blanchard", "Antoine", ""], ["Sapsis", "Themistoklis", ""]]}, {"id": "2004.10603", "submitter": "Yang Zhao", "authors": "Yang Zhao, Ping Yu, Suchismit Mahapatra, Qinliang Su and Changyou Chen", "title": "Improve Variational Autoencoder for Text Generationwith Discrete Latent\n  Bottleneck", "comments": "replaced", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are essential tools in end-to-end\nrepresentation learning. However, the sequential text generation common pitfall\nwith VAEs is that the model tends to ignore latent variables with a strong\nauto-regressive decoder. In this paper, we propose a principled approach to\nalleviate this issue by applying a discretized bottleneck to enforce an\nimplicit latent feature matching in a more compact latent space. We impose a\nshared discrete latent space where each input is learned to choose a\ncombination of latent atoms as a regularized latent representation. Our model\nendows a promising capability to model underlying semantics of discrete\nsequences and thus provide more interpretative latent structures. Empirically,\nwe demonstrate our model's efficiency and effectiveness on a broad range of\ntasks, including language modeling, unaligned text style transfer, dialog\nresponse generation, and neural machine translation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:41:37 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 16:16:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zhao", "Yang", ""], ["Yu", "Ping", ""], ["Mahapatra", "Suchismit", ""], ["Su", "Qinliang", ""], ["Chen", "Changyou", ""]]}, {"id": "2004.10605", "submitter": "Ioan-Adrian Cosma Mr.", "authors": "Adrian Cosma, Mihai Ghidoveanu, Michael Panaitescu-Liess and Marius\n  Popescu", "title": "Self-Supervised Representation Learning on Document Images", "comments": "15 pages, 5 figures. Accepted at DAS 2020: IAPR International\n  Workshop on Document Analysis Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work analyses the impact of self-supervised pre-training on document\nimages in the context of document image classification. While previous\napproaches explore the effect of self-supervision on natural images, we show\nthat patch-based pre-training performs poorly on document images because of\ntheir different structural properties and poor intra-sample semantic\ninformation. We propose two context-aware alternatives to improve performance\non the Tobacco-3482 image classification task. We also propose a novel method\nfor self-supervision, which makes use of the inherent multi-modality of\ndocuments (image and text), which performs better than other popular\nself-supervised methods, including supervised ImageNet pre-training, on\ndocument image classification scenarios with a limited amount of data.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 10:14:06 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 08:48:48 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Cosma", "Adrian", ""], ["Ghidoveanu", "Mihai", ""], ["Panaitescu-Liess", "Michael", ""], ["Popescu", "Marius", ""]]}, {"id": "2004.10608", "submitter": "Filipe Condessa", "authors": "Filipe Condessa, Zico Kolter", "title": "Provably robust deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in adversarial attacks has developed provably robust methods for\ntraining deep neural network classifiers. However, although they are often\nmentioned in the context of robustness, deep generative models themselves have\nreceived relatively little attention in terms of formally analyzing their\nrobustness properties. In this paper, we propose a method for training provably\nrobust generative models, specifically a provably robust version of the\nvariational auto-encoder (VAE). To do so, we first formally define a\n(certifiably) robust lower bound on the variational lower bound of the\nlikelihood, and then show how this bound can be optimized during training to\nproduce a robust VAE. We evaluate the method on simple examples, and show that\nit is able to produce generative models that are substantially more robust to\nadversarial attacks (i.e., an adversary trying to perturb inputs so as to\ndrastically lower their likelihood under the model).\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:47:41 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Condessa", "Filipe", ""], ["Kolter", "Zico", ""]]}, {"id": "2004.10618", "submitter": "Werner Zellinger", "authors": "Werner Zellinger", "title": "Moment-Based Domain Adaptation: Learning Bounds and Algorithms", "comments": "Doctoral Thesis developed at the Department of Knowledge-Based\n  Mathematical Systems at the Johannes Kepler University Linz under the\n  supervision of Susanne Saminger-Platz and Bernhard Moser", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis contributes to the mathematical foundation of domain adaptation\nas emerging field in machine learning. In contrast to classical statistical\nlearning, the framework of domain adaptation takes into account deviations\nbetween probability distributions in the training and application setting.\nDomain adaptation applies for a wider range of applications as future samples\noften follow a distribution that differs from the ones of the training samples.\nA decisive point is the generality of the assumptions about the similarity of\nthe distributions. Therefore, in this thesis we study domain adaptation\nproblems under as weak similarity assumptions as can be modelled by finitely\nmany moments.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:59:08 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Zellinger", "Werner", ""]]}, {"id": "2004.10629", "submitter": "Stefan T. Radev", "authors": "Stefan T. Radev, Marco D'Alessandro, Ulf K. Mertens, Andreas Voss,\n  Ullrich K\\\"othe, Paul-Christian B\\\"urkner", "title": "Amortized Bayesian model comparison with evidential deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Comparing competing mathematical models of complex natural processes is a\nshared goal among many branches of science. The Bayesian probabilistic\nframework offers a principled way to perform model comparison and extract\nuseful metrics for guiding decisions. However, many interesting models are\nintractable with standard Bayesian methods, as they lack a closed-form\nlikelihood function or the likelihood is computationally too expensive to\nevaluate. With this work, we propose a novel method for performing Bayesian\nmodel comparison using specialized deep learning architectures. Our method is\npurely simulation-based and circumvents the step of explicitly fitting all\nalternative models under consideration to each observed dataset. Moreover, it\nrequires no hand-crafted summary statistics of the data and is designed to\namortize the cost of simulation over multiple models and observable datasets.\nThis makes the method particularly effective in scenarios where model fit needs\nto be assessed for a large number of datasets, so that per-dataset inference is\npractically infeasible.Finally, we propose a novel way to measure epistemic\nuncertainty in model comparison problems. We demonstrate the utility of our\nmethod on toy examples and simulated data from non-trivial models from\ncognitive science and single-cell neuroscience. We show that our method\nachieves excellent results in terms of accuracy, calibration, and efficiency\nacross the examples considered in this work. We argue that our framework can\nenhance and enrich model-based analysis and inference in many fields dealing\nwith computational models of natural processes. We further argue that the\nproposed measure of epistemic uncertainty provides a unique proxy to quantify\nabsolute evidence even in a framework which assumes that the true\ndata-generating model is within a finite set of candidate models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:15:46 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 10:46:25 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 22:11:39 GMT"}, {"version": "v4", "created": "Tue, 2 Mar 2021 09:20:49 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Radev", "Stefan T.", ""], ["D'Alessandro", "Marco", ""], ["Mertens", "Ulf K.", ""], ["Voss", "Andreas", ""], ["K\u00f6the", "Ullrich", ""], ["B\u00fcrkner", "Paul-Christian", ""]]}, {"id": "2004.10631", "submitter": "Yi Cao Mr", "authors": "Yi Cao", "title": "The new methods for equity fund selection and optimal portfolio\n  construction", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We relook at the classic equity fund selection and portfolio construction\nproblems from a new perspective and propose an easy-to-implement framework to\ntackle the problem in practical investment. Rather than the conventional way by\nconstructing a long only portfolio from a big universe of stocks or macro\nfactors, we show how to produce a long-short portfolio from a smaller pool of\nstocks from mutual fund top holdings and generate impressive results. As these\nmethods are based on statistical evidence, we need closely monitoring the model\nvalidity, and prepare repair strategies.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 08:24:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cao", "Yi", ""]]}, {"id": "2004.10638", "submitter": "Michal Najman", "authors": "Olga Petrova, Karel Durkota, Galina Alperovich, Karel Horak, Michal\n  Najman, Branislav Bosansky, Viliam Lisy", "title": "Discovering Imperfectly Observable Adversarial Actions using Anomaly\n  Detection", "comments": "9 pages, 3 figures, 3 tables. Extended Abstract of this paper is\n  accepted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a method for discovering unusual and suspicious\nbehavior. In many real-world scenarios, the examined events can be directly\nlinked to the actions of an adversary, such as attacks on computer networks or\nfrauds in financial operations. While the defender wants to discover such\nmalicious behavior, the attacker seeks to accomplish their goal (e.g.,\nexfiltrating data) while avoiding the detection. To this end, anomaly detectors\nhave been used in a game-theoretic framework that captures these goals of a\ntwo-player competition. We extend the existing models to more realistic\nsettings by (1) allowing both players to have continuous action spaces and by\nassuming that (2) the defender cannot perfectly observe the action of the\nattacker. We propose two algorithms for solving such games -- a direct\nextension of existing algorithms based on discretizing the feature space and\nlinear programming and the second algorithm based on constrained learning.\nExperiments show that both algorithms are applicable for cases with low feature\nspace dimensions but the learning-based method produces less exploitable\nstrategies and it is scalable to higher dimensions. Moreover, we use real-world\ndata to compare our approaches with existing classifiers in a data-exfiltration\nscenario via the DNS channel. The results show that our models are\nsignificantly less exploitable by an informed attacker.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:31:53 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Petrova", "Olga", ""], ["Durkota", "Karel", ""], ["Alperovich", "Galina", ""], ["Horak", "Karel", ""], ["Najman", "Michal", ""], ["Bosansky", "Branislav", ""], ["Lisy", "Viliam", ""]]}, {"id": "2004.10652", "submitter": "Jordan Ott", "authors": "Jordan Ott, Mike Pritchard, Natalie Best, Erik Linstead, Milan Curcic,\n  Pierre Baldi", "title": "A Fortran-Keras Deep Learning Bridge for Scientific Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing artificial neural networks is commonly achieved via high-level\nprogramming languages like Python and easy-to-use deep learning libraries like\nKeras. These software libraries come pre-loaded with a variety of network\narchitectures, provide autodifferentiation, and support GPUs for fast and\nefficient computation. As a result, a deep learning practitioner will favor\ntraining a neural network model in Python, where these tools are readily\navailable. However, many large-scale scientific computation projects are\nwritten in Fortran, making it difficult to integrate with modern deep learning\nmethods. To alleviate this problem, we introduce a software library, the\nFortran-Keras Bridge (FKB). This two-way bridge connects environments where\ndeep learning resources are plentiful, with those where they are scarce. The\npaper describes several unique features offered by FKB, such as customizable\nlayers, loss functions, and network ensembles.\n  The paper concludes with a case study that applies FKB to address open\nquestions about the robustness of an experimental approach to global climate\nsimulation, in which subgrid physics are outsourced to deep neural network\nemulators. In this context, FKB enables a hyperparameter search of one hundred\nplus candidate models of subgrid cloud and radiation physics, initially\nimplemented in Keras, to be transferred and used in Fortran. Such a process\nallows the model's emergent behavior to be assessed, i.e. when fit\nimperfections are coupled to explicit planetary-scale fluid dynamics. The\nresults reveal a previously unrecognized strong relationship between offline\nvalidation error and online performance, in which the choice of optimizer\nproves unexpectedly critical. This reveals many neural network architectures\nthat produce considerable improvements in stability including some with reduced\nerror, for an especially challenging training dataset.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:10:09 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 00:15:48 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Ott", "Jordan", ""], ["Pritchard", "Mike", ""], ["Best", "Natalie", ""], ["Linstead", "Erik", ""], ["Curcic", "Milan", ""], ["Baldi", "Pierre", ""]]}, {"id": "2004.10657", "submitter": "Miltiadis Allamanis", "authors": "Miltiadis Allamanis, Earl T. Barr, Soline Ducousso, and Zheng Gao", "title": "Typilus: Neural Type Hints", "comments": "Accepted to PLDI 2020", "journal-ref": null, "doi": "10.1145/3385412.3385997", "report-no": null, "categories": "cs.PL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type inference over partial contexts in dynamically typed languages is\nchallenging. In this work, we present a graph neural network model that\npredicts types by probabilistically reasoning over a program's structure,\nnames, and patterns. The network uses deep similarity learning to learn a\nTypeSpace -- a continuous relaxation of the discrete space of types -- and how\nto embed the type properties of a symbol (i.e. identifier) into it.\nImportantly, our model can employ one-shot learning to predict an open\nvocabulary of types, including rare and user-defined ones. We realise our\napproach in Typilus for Python that combines the TypeSpace with an optional\ntype checker. We show that Typilus accurately predicts types. Typilus\nconfidently predicts types for 70% of all annotatable symbols; when it predicts\na type, that type optionally type checks 95% of the time. Typilus can also find\nincorrect type annotations; two important and popular open source libraries,\nfairseq and allennlp, accepted our pull requests that fixed the annotation\nerrors Typilus discovered.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:14:03 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Allamanis", "Miltiadis", ""], ["Barr", "Earl T.", ""], ["Ducousso", "Soline", ""], ["Gao", "Zheng", ""]]}, {"id": "2004.10664", "submitter": "Tongxue Zhou", "authors": "Tongxue Zhou, Su Ruan, St\\'ephane Canu", "title": "A review: Deep learning for medical image segmentation using\n  multi-modality fusion", "comments": "26 pages, 8 figures", "journal-ref": "Array, Volumes 3-4, September-December 2019, Article 100004", "doi": "10.1016/j.array.2019.100004", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modality is widely used in medical imaging, because it can provide\nmultiinformation about a target (tumor, organ or tissue). Segmentation using\nmultimodality consists of fusing multi-information to improve the segmentation.\nRecently, deep learning-based approaches have presented the state-of-the-art\nperformance in image classification, segmentation, object detection and\ntracking tasks. Due to their self-learning and generalization ability over\nlarge amounts of data, deep learning recently has also gained great interest in\nmulti-modal medical image segmentation. In this paper, we give an overview of\ndeep learning-based approaches for multi-modal medical image segmentation task.\nFirstly, we introduce the general principle of deep learning and multi-modal\nmedical image segmentation. Secondly, we present different deep learning\nnetwork architectures, then analyze their fusion strategies and compare their\nresults. The earlier fusion is commonly used, since it's simple and it focuses\non the subsequent segmentation network architecture. However, the later fusion\ngives more attention on fusion strategy to learn the complex relationship\nbetween different modalities. In general, compared to the earlier fusion, the\nlater fusion can give more accurate result if the fusion method is effective\nenough. We also discuss some common problems in medical image segmentation.\nFinally, we summarize and provide some perspectives on the future research.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 16:00:53 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 15:33:31 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Zhou", "Tongxue", ""], ["Ruan", "Su", ""], ["Canu", "St\u00e9phane", ""]]}, {"id": "2004.10667", "submitter": "Yutaka Nagashima", "authors": "Yutaka Nagashima", "title": "Simple Dataset for Proof Method Recommendation in Isabelle/HOL (Dataset\n  Description)", "comments": "This is the preprint of our short paper accepted at the 13th\n  Conference on Intelligent Computer Mathematics (CICM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a growing number of researchers have applied machine learning to\nassist users of interactive theorem provers. However, the expressive nature of\nunderlying logics and esoteric structures of proof documents impede machine\nlearning practitioners, who often do not have much expertise in formal logic,\nlet alone Isabelle/HOL, from achieving a large scale success in this field. In\nthis data description, we present a simple dataset that contains data on over\n400k proof method applications along with over 100 extracted features for each\nin a format that can be processed easily without any knowledge about formal\nlogic. Our simple data format allows machine learning practitioners to try\nmachine learning tools to predict proof methods in Isabelle/HOL without\nrequiring domain expertise in logic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:00:11 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:38:37 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 07:46:04 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Nagashima", "Yutaka", ""]]}, {"id": "2004.10694", "submitter": "Zhao Zhong", "authors": "Yikang Zhang, Jian Zhang, Qiang Wang, Zhao Zhong", "title": "DyNet: Dynamic Convolution for Accelerating Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution operator is the core of convolutional neural networks (CNNs) and\noccupies the most computation cost. To make CNNs more efficient, many methods\nhave been proposed to either design lightweight networks or compress models.\nAlthough some efficient network structures have been proposed, such as\nMobileNet or ShuffleNet, we find that there still exists redundant information\nbetween convolution kernels. To address this issue, we propose a novel dynamic\nconvolution method to adaptively generate convolution kernels based on image\ncontents. To demonstrate the effectiveness, we apply dynamic convolution on\nmultiple state-of-the-art CNNs. On one hand, we can reduce the computation cost\nremarkably while maintaining the performance. For\nShuffleNetV2/MobileNetV2/ResNet18/ResNet50, DyNet can reduce\n37.0/54.7/67.2/71.3% FLOPs without loss of accuracy. On the other hand, the\nperformance can be largely boosted if the computation cost is maintained. Based\non the architecture MobileNetV3-Small/Large, DyNet achieves 70.3/77.1% Top-1\naccuracy on ImageNet with an improvement of 2.9/1.9%. To verify the\nscalability, we also apply DyNet on segmentation task, the results show that\nDyNet can reduce 69.3% FLOPs while maintaining Mean IoU on segmentation task.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 16:58:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Zhang", "Yikang", ""], ["Zhang", "Jian", ""], ["Wang", "Qiang", ""], ["Zhong", "Zhao", ""]]}, {"id": "2004.10696", "submitter": "Demetris Marnerides", "authors": "Demetris Marnerides, Thomas Bashford-Rogers and Kurt Debattista", "title": "Spectrally Consistent UNet for High Fidelity Image Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the current de-facto models used for\nmany imaging tasks due to their high learning capacity as well as their\narchitectural qualities. The ubiquitous UNet architecture provides an efficient\nand multi-scale solution that combines local and global information. Despite\nthe success of UNet architectures, the use of upsampling layers can cause\nartefacts. In this work, a method for assessing the structural biases of UNets\nand the effects these have on the outputs is presented, characterising their\nimpact in the Fourier domain. A new upsampling module is proposed, based on a\nnovel use of the Guided Image Filter, that provides spectrally consistent\noutputs when used in a UNet architecture, forming the Guided UNet (GUNet). The\nGUNet architecture is applied and evaluated for example applications of inverse\ntone mapping/dynamic range expansion and colourisation from grey-scale images\nand is shown to provide higher fidelity outputs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:04:02 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 09:32:09 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Marnerides", "Demetris", ""], ["Bashford-Rogers", "Thomas", ""], ["Debattista", "Kurt", ""]]}, {"id": "2004.10698", "submitter": "Keting Lu", "authors": "Keting Lu, Shiqi Zhang, Xiaoping Chen", "title": "AutoEG: Automated Experience Grafting for Off-Policy Deep Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms frequently require prohibitive\ninteraction experience to ensure the quality of learned policies. The\nlimitation is partly because the agent cannot learn much from the many\nlow-quality trials in early learning phase, which results in low learning rate.\nFocusing on addressing this limitation, this paper makes a twofold\ncontribution. First, we develop an algorithm, called Experience Grafting (EG),\nto enable RL agents to reorganize segments of the few high-quality trajectories\nfrom the experience pool to generate many synthetic trajectories while\nretaining the quality. Second, building on EG, we further develop an AutoEG\nagent that automatically learns to adjust the grafting-based learning strategy.\nResults collected from a set of six robotic control environments show that, in\ncomparison to a standard deep RL algorithm (DDPG), AutoEG increases the speed\nof learning process by at least 30%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:07:08 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 14:32:51 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lu", "Keting", ""], ["Zhang", "Shiqi", ""], ["Chen", "Xiaoping", ""]]}, {"id": "2004.10700", "submitter": "Netanel Raviv", "authors": "Netanel Raviv, Siddharth Jain, Pulakesh Upadhyaya, Jehoshua Bruck, and\n  Anxiao Jiang", "title": "CodNN -- Robust Neural Networks From Coded Classification", "comments": "To appear in ISIT '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are a revolutionary force in the ongoing\ninformation revolution, and yet their intrinsic properties remain a mystery. In\nparticular, it is widely known that DNNs are highly sensitive to noise, whether\nadversarial or random. This poses a fundamental challenge for hardware\nimplementations of DNNs, and for their deployment in critical applications such\nas autonomous driving. In this paper we construct robust DNNs via error\ncorrecting codes. By our approach, either the data or internal layers of the\nDNN are coded with error correcting codes, and successful computation under\nnoise is guaranteed. Since DNNs can be seen as a layered concatenation of\nclassification tasks, our research begins with the core task of classifying\nnoisy coded inputs, and progresses towards robust DNNs. We focus on binary data\nand linear codes. Our main result is that the prevalent parity code can\nguarantee robustness for a large family of DNNs, which includes the recently\npopularized binarized neural networks. Further, we show that the coded\nclassification problem has a deep connection to Fourier analysis of Boolean\nfunctions. In contrast to existing solutions in the literature, our results do\nnot rely on altering the training process of the DNN, and provide\nmathematically rigorous guarantees rather than experimental evidence.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:07:15 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 22:55:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Raviv", "Netanel", ""], ["Jain", "Siddharth", ""], ["Upadhyaya", "Pulakesh", ""], ["Bruck", "Jehoshua", ""], ["Jiang", "Anxiao", ""]]}, {"id": "2004.10701", "submitter": "John Ram\\'irez", "authors": "John Ram\\'irez-Figueroa, Carlos Mart\\'in-Barreiro, Ana B.\n  Nieto-Librero, Victor Leiva-S\\'anchez, Purificaci\\'on Galindo-Villard\\'on", "title": "Disjoint principal component analysis by constrained binary particle\n  swarm optimization", "comments": "34 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an alternative method to the disjoint principal\ncomponent analysis. The method consists of a principal component analysis with\nconstraints, which allows us to determine disjoint components that are linear\ncombinations of disjoint subsets of the original variables. The proposed method\nis named constrained binary optimization by particle swarm disjoint principal\ncomponent analysis, since it is based on the particle swarm optimization. The\nmethod uses stochastic optimization to find solutions in cases of high\ncomputational complexity. The algorithm associated with the method starts\ngenerating randomly a particle population which iteratively evolves until\nattaining a global optimum which is function of the disjoint components.\nNumerical results are provided to confirm the quality of the solutions attained\nby the proposed method. Illustrative examples with real data are conducted to\nshow the potential applications of the method.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:07:19 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Ram\u00edrez-Figueroa", "John", ""], ["Mart\u00edn-Barreiro", "Carlos", ""], ["Nieto-Librero", "Ana B.", ""], ["Leiva-S\u00e1nchez", "Victor", ""], ["Galindo-Villard\u00f3n", "Purificaci\u00f3n", ""]]}, {"id": "2004.10703", "submitter": "Arun Maiya", "authors": "Arun S. Maiya", "title": "ktrain: A Low-Code Library for Augmented Machine Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ktrain, a low-code Python library that makes machine learning more\naccessible and easier to apply. As a wrapper to TensorFlow and many other\nlibraries (e.g., transformers, scikit-learn, stellargraph), it is designed to\nmake sophisticated, state-of-the-art machine learning models simple to build,\ntrain, inspect, and apply by both beginners and experienced practitioners.\nFeaturing modules that support text data (e.g., text classification, sequence\ntagging, open-domain question-answering), vision data (e.g., image\nclassification), graph data (e.g., node classification, link prediction), and\ntabular data, ktrain presents a simple unified interface enabling one to\nquickly solve a wide range of tasks in as little as three or four \"commands\" or\nlines of code.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 14:18:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:48:35 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 15:50:12 GMT"}, {"version": "v4", "created": "Fri, 31 Jul 2020 21:25:30 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Maiya", "Arun S.", ""]]}, {"id": "2004.10705", "submitter": "Stanis{\\l}aw Ka\\'zmierczak", "authors": "Stanis{\\l}aw Ka\\'zmierczak, Jacek Ma\\'ndziuk", "title": "A Committee of Convolutional Neural Networks for Image Classication in\n  the Concurrent Presence of Feature and Label Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification has become a ubiquitous task. Models trained on good\nquality data achieve accuracy which in some application domains is already\nabove human-level performance. Unfortunately, real-world data are quite often\ndegenerated by the noise existing in features and/or labels. There are quite\nmany papers that handle the problem of either feature or label noise,\nseparately. However, to the best of our knowledge, this piece of research is\nthe first attempt to address the problem of concurrent occurrence of both types\nof noise. Basing on the MNIST, CIFAR-10 and CIFAR-100 datasets, we\nexperimentally proved that the difference by which committees beat single\nmodels increases along with noise level, no matter it is an attribute or label\ndisruption. Thus, it makes ensembles legitimate to be applied to noisy images\nwith noisy labels. The aforementioned committees' advantage over single models\nis positively correlated with dataset difficulty level as well. We propose\nthree committee selection algorithms that outperform a strong baseline\nalgorithm which relies on an ensemble of individual (nonassociated) best\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 00:22:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:54:13 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ka\u017amierczak", "Stanis\u0142aw", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2004.10710", "submitter": "Jo\\~ao Caldeira", "authors": "Jo\\~ao Caldeira, Brian Nord", "title": "Deeply Uncertain: Comparing Methods of Uncertainty Quantification in\n  Deep Learning Algorithms", "comments": "11 pages, 3 figures; Presented at ICLR 2020 Workshop on Fundamental\n  Science in the era of AI; changes to match accepted version", "journal-ref": "Mach. Learn.: Sci. Technol. 2 015002 (2021)", "doi": "10.1088/2632-2153/aba6f3", "report-no": "FERMILAB-PUB-20-157-SCD", "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparison of methods for uncertainty quantification (UQ) in\ndeep learning algorithms in the context of a simple physical system. Three of\nthe most common uncertainty quantification methods - Bayesian Neural Networks\n(BNN), Concrete Dropout (CD), and Deep Ensembles (DE) - are compared to the\nstandard analytic error propagation. We discuss this comparison in terms\nendemic to both machine learning (\"epistemic\" and \"aleatoric\") and the physical\nsciences (\"statistical\" and \"systematic\"). The comparisons are presented in\nterms of simulated experimental measurements of a single pendulum - a\nprototypical physical system for studying measurement and analysis techniques.\nOur results highlight some pitfalls that may occur when using these UQ methods.\nFor example, when the variation of noise in the training set is small, all\nmethods predicted the same relative uncertainty independently of the inputs.\nThis issue is particularly hard to avoid in BNN. On the other hand, when the\ntest set contains samples far from the training distribution, we found that no\nmethods sufficiently increased the uncertainties associated to their\npredictions. This problem was particularly clear for CD. In light of these\nresults, we make some recommendations for usage and interpretation of UQ\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:13:15 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 16:09:59 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 17:21:41 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Caldeira", "Jo\u00e3o", ""], ["Nord", "Brian", ""]]}, {"id": "2004.10715", "submitter": "Jithin Jagannath", "authors": "Anu Jagannath, Jithin Jagannath, and Tommaso Melodia", "title": "Redefining Wireless Communication for 6G: Signal Processing Meets Deep\n  Learning with Deep Unfolding", "comments": "Preprint submitted to IEEE Transactions on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The year 2019 witnessed the rollout of the 5G standard, which promises to\noffer significant data rate improvement over 4G. While 5G is still in its\ninfancy, there has been an increased shift in the research community for\ncommunication technologies beyond 5G. The recent emergence of machine learning\napproaches for enhancing wireless communications and empowering them with\nmuch-desired intelligence holds immense potential for redefining wireless\ncommunication for 6G. The evolving communication systems will be bottlenecked\nin terms of latency, throughput, and reliability by the underlying signal\nprocessing at the physical layer. In this position paper, we motivate the need\nto redesign iterative signal processing algorithms by leveraging deep unfolding\ntechniques to fulfill the physical layer requirements for 6G networks. To this\nend, we begin by presenting the service requirements and the key challenges\nposed by the envisioned 6G communication architecture. We outline the\ndeficiencies of the traditional algorithmic principles and data-hungry deep\nlearning (DL) approaches in the context of 6G networks. Specifically, deep\nunfolded signal processing is presented by sketching the interplay between\ndomain knowledge and DL. The deep unfolded approaches reviewed in this article\nare positioned explicitly in the context of the requirements imposed by the\nnext generation of cellular networks. Finally, this article motivates open\nresearch challenges to truly realize hardware-efficient edge intelligence for\nfuture 6G networks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:20:00 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 01:31:17 GMT"}, {"version": "v3", "created": "Sun, 7 Mar 2021 00:54:10 GMT"}, {"version": "v4", "created": "Mon, 17 May 2021 13:14:46 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jagannath", "Anu", ""], ["Jagannath", "Jithin", ""], ["Melodia", "Tommaso", ""]]}, {"id": "2004.10723", "submitter": "Shi Yu", "authors": "Shi Yu", "title": "Eigendecomposition of Q in Equally Constrained Quadratic Programming", "comments": "Needs further improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying eigenvalue decomposition on the quadratic term matrix in a type\nof linear equally constrained quadratic programming (EQP), there exists a\nlinear mapping to project optimal solutions between the new EQP formulation\nwhere $Q$ is diagonalized and the original formulation. Although such a mapping\nrequires a particular type of equality constraints, it is generalizable to some\nreal problems such as efficient frontier for portfolio allocation and\nclassification of Least Square Support Vector Machines (LSSVM). The established\nmapping could be potentially useful to explore optimal solutions in subspace,\nbut it is not very clear to the author. This work was inspired by similar work\nproved on unconstrained formulation discussed earlier in \\cite{Tan}, but its\ncurrent proof is much improved and generalized. To the author's knowledge, very\nfew similar discussion appears in literature.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:25:46 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:07:45 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Yu", "Shi", ""]]}, {"id": "2004.10734", "submitter": "Ivan Ezhov", "authors": "Ahmad B Qasim, Ivan Ezhov, Suprosanna Shit, Oliver Schoppe, Johannes C\n  Paetzold, Anjany Sekuboyina, Florian Kofler, Jana Lipkova, Hongwei Li, Bjoern\n  Menze", "title": "Red-GAN: Attacking class imbalance via conditioned generation. Yet\n  another perspective on medical image synthesis for skin lesion dermoscopy and\n  brain tumor MRI", "comments": null, "journal-ref": "Published in Proceedings of the 3rd edition of Medical Imaging\n  with Deep Learning, Montr\\'eal, Canada, PMLR 121, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting learning algorithms under scarce data regimes is a limitation and\na reality of the medical imaging field. In an attempt to mitigate the problem,\nwe propose a data augmentation protocol based on generative adversarial\nnetworks. We condition the networks at a pixel-level (segmentation mask) and at\na global-level information (acquisition environment or lesion type). Such\nconditioning provides immediate access to the image-label pairs while\ncontrolling global class specific appearance of the synthesized images. To\nstimulate synthesis of the features relevant for the segmentation task, an\nadditional passive player in a form of segmentor is introduced into the\nadversarial game. We validate the approach on two medical datasets: BraTS,\nISIC. By controlling the class distribution through injection of synthetic\nimages into the training set we achieve control over the accuracy levels of the\ndatasets' classes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:38:48 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 15:44:11 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 23:03:24 GMT"}, {"version": "v4", "created": "Sun, 28 Mar 2021 00:15:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Qasim", "Ahmad B", ""], ["Ezhov", "Ivan", ""], ["Shit", "Suprosanna", ""], ["Schoppe", "Oliver", ""], ["Paetzold", "Johannes C", ""], ["Sekuboyina", "Anjany", ""], ["Kofler", "Florian", ""], ["Lipkova", "Jana", ""], ["Li", "Hongwei", ""], ["Menze", "Bjoern", ""]]}, {"id": "2004.10746", "submitter": "Azalia Mirhoseini", "authors": "Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe Jiang, Ebrahim\n  Songhori, Shen Wang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Sungmin Bae,\n  Azade Nazi, Jiwoo Pak, Andy Tong, Kavya Srinivasa, William Hang, Emre Tuncer,\n  Anand Babu, Quoc V. Le, James Laudon, Richard Ho, Roger Carpenter, Jeff Dean", "title": "Chip Placement with Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a learning-based approach to chip placement, one of\nthe most complex and time-consuming stages of the chip design process. Unlike\nprior methods, our approach has the ability to learn from past experience and\nimprove over time. In particular, as we train over a greater number of chip\nblocks, our method becomes better at rapidly generating optimized placements\nfor previously unseen chip blocks. To achieve these results, we pose placement\nas a Reinforcement Learning (RL) problem and train an agent to place the nodes\nof a chip netlist onto a chip canvas. To enable our RL policy to generalize to\nunseen blocks, we ground representation learning in the supervised task of\npredicting placement quality. By designing a neural architecture that can\naccurately predict reward across a wide variety of netlists and their\nplacements, we are able to generate rich feature embeddings of the input\nnetlists. We then use this architecture as the encoder of our policy and value\nnetworks to enable transfer learning. Our objective is to minimize PPA (power,\nperformance, and area), and we show that, in under 6 hours, our method can\ngenerate placements that are superhuman or comparable on modern accelerator\nnetlists, whereas existing baselines require human experts in the loop and take\nseveral weeks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:56:07 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Mirhoseini", "Azalia", ""], ["Goldie", "Anna", ""], ["Yazgan", "Mustafa", ""], ["Jiang", "Joe", ""], ["Songhori", "Ebrahim", ""], ["Wang", "Shen", ""], ["Lee", "Young-Joon", ""], ["Johnson", "Eric", ""], ["Pathak", "Omkar", ""], ["Bae", "Sungmin", ""], ["Nazi", "Azade", ""], ["Pak", "Jiwoo", ""], ["Tong", "Andy", ""], ["Srinivasa", "Kavya", ""], ["Hang", "William", ""], ["Tuncer", "Emre", ""], ["Babu", "Anand", ""], ["Le", "Quoc V.", ""], ["Laudon", "James", ""], ["Ho", "Richard", ""], ["Carpenter", "Roger", ""], ["Dean", "Jeff", ""]]}, {"id": "2004.10756", "submitter": "Hayata Yamasaki", "authors": "Hayata Yamasaki, Sathyawageeswar Subramanian, Sho Sonoda, Masato\n  Koashi", "title": "Learning with Optimized Random Features: Exponential Speedup by Quantum\n  Machine Learning without Sparsity and Low-Rank Assumptions", "comments": "37 pages, 2 figures, accepted at Thirty-fourth Conference on Neural\n  Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel methods augmented with random features give scalable algorithms for\nlearning from big data. But it has been computationally hard to sample random\nfeatures according to a probability distribution that is optimized for the\ndata, so as to minimize the required number of features for achieving the\nlearning to a desired accuracy. Here, we develop a quantum algorithm for\nsampling from this optimized distribution over features, in runtime $O(D)$ that\nis linear in the dimension $D$ of the input data. Our algorithm achieves an\nexponential speedup in $D$ compared to any known classical algorithm for this\nsampling task. In contrast to existing quantum machine learning algorithms, our\nalgorithm circumvents sparsity and low-rank assumptions and thus has wide\napplicability. We also show that the sampled features can be combined with\nregression by stochastic gradient descent to achieve the learning without\ncanceling out our exponential speedup. Our algorithm based on sampling\noptimized random features leads to an accelerated framework for machine\nlearning that takes advantage of quantum computers.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 18:00:00 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 20:07:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Yamasaki", "Hayata", ""], ["Subramanian", "Sathyawageeswar", ""], ["Sonoda", "Sho", ""], ["Koashi", "Masato", ""]]}, {"id": "2004.10792", "submitter": "Sara Hosseinzadeh Kassani", "authors": "Sara Hosseinzadeh Kassani, Peyman Hosseinzadeh Kassani, Michal J.\n  Wesolowski, Kevin A. Schneider, Ralph Deters", "title": "Automatic Polyp Segmentation Using Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer is the third most common cancer-related death after lung\ncancer and breast cancer worldwide. The risk of developing colorectal cancer\ncould be reduced by early diagnosis of polyps during a colonoscopy.\nComputer-aided diagnosis systems have the potential to be applied for polyp\nscreening and reduce the number of missing polyps. In this paper, we compare\nthe performance of different deep learning architectures as feature extractors,\ni.e. ResNet, DenseNet, InceptionV3, InceptionResNetV2 and SE-ResNeXt in the\nencoder part of a U-Net architecture. We validated the performance of presented\nensemble models on the CVC-Clinic (GIANA 2018) dataset. The DenseNet169 feature\nextractor combined with U-Net architecture outperformed the other counterparts\nand achieved an accuracy of 99.15\\%, Dice similarity coefficient of 90.87%, and\nJaccard index of 83.82%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 18:54:29 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Kassani", "Sara Hosseinzadeh", ""], ["Kassani", "Peyman Hosseinzadeh", ""], ["Wesolowski", "Michal J.", ""], ["Schneider", "Kevin A.", ""], ["Deters", "Ralph", ""]]}, {"id": "2004.10798", "submitter": "Bahman Moraffah", "authors": "Bahman Moraffah and Antonia Papndreou-Suppopola", "title": "Bayesian nonparametric modeling for predicting dynamic dependencies in\n  multiple object tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some challenging problems in tracking multiple objects include the\ntime-dependent cardinality, unordered measurements and object parameter\nlabeling. In this paper, we employ Bayesian Bayesian nonparametric methods to\naddress these challenges. In particular, we propose modeling the multiple\nobject parameter state prior using the dependent Dirichlet and Pitman-Yor\nprocesses. These nonparametric models have been shown to be more flexible and\nrobust, when compared to existing methods, for estimating the time-varying\nnumber of objects, providing object labeling and identifying measurement to\nobject associations. Monte Carlo sampling methods are then proposed to\nefficiently learn the trajectory of objects from noisy measurements. Using\nsimulations, we demonstrate the estimation performance advantage of the new\nmethods when compared to existing algorithms such as the generalized labeled\nmulti-Bernoulli filter.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:07:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Moraffah", "Bahman", ""], ["Papndreou-Suppopola", "Antonia", ""]]}, {"id": "2004.10799", "submitter": "Aleksandr Laptev", "authors": "Andrei Andrusenko, Aleksandr Laptev, Ivan Medennikov", "title": "Towards a Competitive End-to-End Speech Recognition for CHiME-6 Dinner\n  Party Transcription", "comments": "Accepted by Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1074", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While end-to-end ASR systems have proven competitive with the conventional\nhybrid approach, they are prone to accuracy degradation when it comes to noisy\nand low-resource conditions. In this paper, we argue that, even in such\ndifficult cases, some end-to-end approaches show performance close to the\nhybrid baseline. To demonstrate this, we use the CHiME-6 Challenge data as an\nexample of challenging environments and noisy conditions of everyday speech. We\nexperimentally compare and analyze CTC-Attention versus RNN-Transducer\napproaches along with RNN versus Transformer architectures. We also provide a\ncomparison of acoustic features and speech enhancements. Besides, we evaluate\nthe effectiveness of neural network language models for hypothesis re-scoring\nin low-resource conditions. Our best end-to-end model based on RNN-Transducer,\ntogether with improved beam search, reaches quality by only 3.8% WER abs. worse\nthan the LF-MMI TDNN-F CHiME-6 Challenge baseline. With the Guided Source\nSeparation based training data augmentation, this approach outperforms the\nhybrid baseline system by 2.7% WER abs. and the end-to-end system best known\nbefore by 25.7% WER abs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:08:33 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 18:12:17 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 19:36:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Andrusenko", "Andrei", ""], ["Laptev", "Aleksandr", ""], ["Medennikov", "Ivan", ""]]}, {"id": "2004.10802", "submitter": "Jared Kaplan", "authors": "Utkarsh Sharma, Jared Kaplan", "title": "A Neural Scaling Law from the Dimension of the Data Manifold", "comments": "16+12 pages, 11+11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is plentiful, the loss achieved by well-trained neural networks\nscales as a power-law $L \\propto N^{-\\alpha}$ in the number of network\nparameters $N$. This empirical scaling law holds for a wide variety of data\nmodalities, and may persist over many orders of magnitude. The scaling law can\nbe explained if neural models are effectively just performing regression on a\ndata manifold of intrinsic dimension $d$. This simple theory predicts that the\nscaling exponents $\\alpha \\approx 4/d$ for cross-entropy and mean-squared error\nlosses. We confirm the theory by independently measuring the intrinsic\ndimension and the scaling exponents in a teacher/student framework, where we\ncan study a variety of $d$ and $\\alpha$ by dialing the properties of random\nteacher networks. We also test the theory with CNN image classifiers on several\ndatasets and with GPT-type language models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:16:06 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sharma", "Utkarsh", ""], ["Kaplan", "Jared", ""]]}, {"id": "2004.10805", "submitter": "Antonio Blanca", "authors": "Antonio Blanca, Zongchen Chen, Daniel \\v{S}tefankovi\\v{c} and Eric\n  Vigoda", "title": "Hardness of Identity Testing for Restricted Boltzmann Machines and Potts\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study identity testing for restricted Boltzmann machines (RBMs), and more\ngenerally for undirected graphical models. Given sample access to the Gibbs\ndistribution corresponding to an unknown or hidden model $M^*$ and given an\nexplicit model $M$, can we distinguish if either $M = M^*$ or if they are\n(statistically) far apart? Daskalakis et al. (2018) presented a polynomial-time\nalgorithm for identity testing for the ferromagnetic (attractive) Ising model.\nIn contrast, for the antiferromagnetic (repulsive) Ising model, Bez\\'akov\\'a et\nal. (2019) proved that unless $RP=NP$ there is no identity testing algorithm\nwhen $\\beta d=\\omega(\\log{n})$, where $d$ is the maximum degree of the visible\ngraph and $\\beta$ is the largest edge weight in absolute value.\n  We prove analogous hardness results for RBMs (i.e., mixed Ising models on\nbipartite graphs), even when there are no latent variables or an external\nfield. Specifically, we show that if $RP \\neq NP$, then when $\\beta\nd=\\omega(\\log{n})$ there is no polynomial-time algorithm for identity testing\nfor RBMs; when $\\beta d =O(\\log{n})$ there is an efficient identity testing\nalgorithm that utilizes the structure learning algorithm of Klivans and Meka\n(2017). In addition, we prove similar lower bounds for purely ferromagnetic\nRBMs with inconsistent external fields, and for the ferromagnetic Potts model.\nPrevious hardness results for identity testing of Bez\\'akov\\'a et al. (2019)\nutilized the hardness of finding the maximum cuts, which corresponds to the\nground states of the antiferromagnetic Ising model. Since RBMs are on bipartite\ngraphs such an approach is not feasible. We instead introduce a general\nmethodology to reduce from the corresponding approximate counting problem and\nutilize the phase transition that is exhibited by RBMs and the mean-field Potts\nmodel.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:21:01 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Blanca", "Antonio", ""], ["Chen", "Zongchen", ""], ["\u0160tefankovi\u010d", "Daniel", ""], ["Vigoda", "Eric", ""]]}, {"id": "2004.10816", "submitter": "Majid Asgari-Bidhendi", "authors": "Majid Asgari-Bidhendi, Farzane Fakhrian and Behrouz Minaei-Bidgoli", "title": "ParsEL 1.0: Unsupervised Entity Linking in Persian Social Media Texts", "comments": "8 pages, 3 figures. ParsEL service (source code is available in\n  github)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, social media data has exponentially increased, which can be\nenumerated as one of the largest data repositories in the world. A large\nportion of this social media data is natural language text. However, the\nnatural language is highly ambiguous due to exposure to the frequent\noccurrences of entities, which have polysemous words or phrases. Entity linking\nis the task of linking the entity mentions in the text to their corresponding\nentities in a knowledge base. Recently, FarsBase, a Persian knowledge graph,\nhas been introduced containing almost half a million entities. In this paper,\nwe propose an unsupervised Persian Entity Linking system, the first entity\nlinking system specially focused on the Persian language, which utilizes\ncontext-dependent and context-independent features. For this purpose, we also\npublish the first entity linking corpus of the Persian language containing\n67,595 words that have been crawled from social media texts of some popular\nchannels in the Telegram messenger. The output of the proposed method is 86.94%\nf-score for the Persian language, which is comparable with the similar\nstate-of-the-art methods in the English language.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:34:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Asgari-Bidhendi", "Majid", ""], ["Fakhrian", "Farzane", ""], ["Minaei-Bidgoli", "Behrouz", ""]]}, {"id": "2004.10823", "submitter": "Tomoki Koriyama", "authors": "Tomoki Koriyama, Hiroshi Saruwatari", "title": "Utterance-level Sequential Modeling For Deep Gaussian Process Based\n  Speech Synthesis Using Simple Recurrent Unit", "comments": "5 pages. Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep Gaussian process (DGP) model with a recurrent\narchitecture for speech sequence modeling. DGP is a Bayesian deep model that\ncan be trained effectively with the consideration of model complexity and is a\nkernel regression model that can have high expressibility. In the previous\nstudies, it was shown that the DGP-based speech synthesis outperformed neural\nnetwork-based one, in which both models used a feed-forward architecture. To\nimprove the naturalness of synthetic speech, in this paper, we show that DGP\ncan be applied to utterance-level modeling using recurrent architecture models.\nWe adopt a simple recurrent unit (SRU) for the proposed model to achieve a\nrecurrent architecture, in which we can execute fast speech parameter\ngeneration by using the high parallelization nature of SRU. The objective and\nsubjective evaluation results show that the proposed SRU-DGP-based speech\nsynthesis outperforms not only feed-forward DGP but also automatically tuned\nSRU- and long short-term memory (LSTM)-based neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:51:36 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Koriyama", "Tomoki", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "2004.10824", "submitter": "Dan Nascimento Gomes Do Valle", "authors": "Dan Valle, Tiago Pimentel, Adriano Veloso", "title": "Assessing the Reliability of Visual Explanations of Deep Models with\n  Adversarial Perturbations", "comments": "Accepted for publication at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in complex deep neural networks for computer vision applications\nis increasing. This leads to the need for improving the interpretable\ncapabilities of these models. Recent explanation methods present visualizations\nof the relevance of pixels from input images, thus enabling the direct\ninterpretation of properties of the input that lead to a specific output. These\nmethods produce maps of pixel importance, which are commonly evaluated by\nvisual inspection. This means that the effectiveness of an explanation method\nis assessed based on human expectation instead of actual feature importance.\nThus, in this work we propose an objective measure to evaluate the reliability\nof explanations of deep models. Specifically, our approach is based on changes\nin the network's outcome resulting from the perturbation of input images in an\nadversarial way. We present a comparison between widely-known explanation\nmethods using our proposed approach. Finally, we also propose a straightforward\napplication of our approach to clean relevance maps, creating more\ninterpretable maps without any loss in essential explanation (as per our\nproposed measure).\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:57:34 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Valle", "Dan", ""], ["Pimentel", "Tiago", ""], ["Veloso", "Adriano", ""]]}, {"id": "2004.10846", "submitter": "Xuan Zhang", "authors": "Yuri Faenza, Swati Gupta, Xuan Zhang", "title": "Impact of Bias on School Admissions and Targeted Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation criteria for school admissions do not account for the impact of\nimplicit bias on applications, due to e.g., socioeconomic status of students or\ntraining resources available to them. We present, to the best of our knowledge,\nthe first mathematical analysis of the impact of biased evaluations of students\non school admissions. In our model, students have a unanimous ranking of\nschools, schools observe \"biased\" potentials for a group of students and true\npotentials for others, and then accept the best students from those available\nto them. Our framework for evaluating the effects of bias and of targeted\nintervention can incorporate any distribution of students' potentials and deals\nwith the following questions: how much are students and schools affected by\nsuch bias; do schools have an incentive to interview students; how should\nlimited resources be allocated to minimize the \"impact\" of bias on students.\nWhen students' potentials are Pareto distributed, we find that schools have\nlittle incentive to change their evaluation mechanisms. Moreover, additional\nresources are best targeted at average students, as opposed to top students,\nthus questioning existing scholarship mechanisms. This optimal target range\nshifts towards top students, when students' potentials are Gaussian\ndistributed. We validate these findings using SAT scores data from New York\nCity high schools. Our conclusions are robust, as qualitative takeaways from\nour analysis remain the same even when some of our modeling assumptions are\nrelaxed.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:50:31 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 19:08:44 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Faenza", "Yuri", ""], ["Gupta", "Swati", ""], ["Zhang", "Xuan", ""]]}, {"id": "2004.10854", "submitter": "Dionysios Diamantopoulos", "authors": "Dionysios Diamantopoulos, Burkhard Ringlein, Mitra Purandare,\n  Gagandeep Singh, and Christoph Hagleitner", "title": "Agile Autotuning of a Transprecision Tensor Accelerator Overlay for TVM\n  Compiler Stack", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Specialized accelerators for tensor-operations, such as blocked-matrix\noperations and multi-dimensional convolutions, have been emerged as powerful\narchitecture choices for high-performance Deep-Learning computing. The rapid\ndevelopment of frameworks, models, and precision options challenges the\nadaptability of such tensor-accelerators since the adaptation to new\nrequirements incurs significant engineering costs. Programmable tensor\naccelerators offer a promising alternative by allowing reconfiguration of a\nvirtual architecture that overlays on top of the physical FPGA configurable\nfabric. We propose an overlay ({\\tau}-VTA) and an optimization method guided by\nagile-inspired auto-tuning techniques. We achieve higher performance and faster\nconvergence than state-of-art.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:12:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Diamantopoulos", "Dionysios", ""], ["Ringlein", "Burkhard", ""], ["Purandare", "Mitra", ""], ["Singh", "Gagandeep", ""], ["Hagleitner", "Christoph", ""]]}, {"id": "2004.10856", "submitter": "Zhenkun Cai", "authors": "Zhenkun Cai, Kaihao Ma, Xiao Yan, Yidi Wu, Yuzhen Huang, James Cheng,\n  Teng Su, Fan Yu", "title": "TensorOpt: Exploring the Tradeoffs in Distributed DNN Training with\n  Auto-Parallelism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good parallelization strategy can significantly improve the efficiency or\nreduce the cost for the distributed training of deep neural networks (DNNs).\nRecently, several methods have been proposed to find efficient parallelization\nstrategies but they all optimize a single objective (e.g., execution time,\nmemory consumption) and produce only one strategy. We propose FT, an efficient\nalgorithm that searches for an optimal set of parallelization strategies to\nallow the trade-off among different objectives. FT can adapt to different\nscenarios by minimizing the memory consumption when the number of devices is\nlimited and fully utilize additional resources to reduce the execution time.\nFor popular DNN models (e.g., vision, language), an in-depth analysis is\nconducted to understand the trade-offs among different objectives and their\ninfluence on the parallelization strategies. We also develop a user-friendly\nsystem, called TensorOpt, which allows users to run their distributed DNN\ntraining jobs without caring the details of parallelization strategies.\nExperimental results show that FT runs efficiently and provides accurate\nestimation of runtime costs, and TensorOpt is more flexible in adapting to\nresource availability compared with existing frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 02:57:35 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cai", "Zhenkun", ""], ["Ma", "Kaihao", ""], ["Yan", "Xiao", ""], ["Wu", "Yidi", ""], ["Huang", "Yuzhen", ""], ["Cheng", "James", ""], ["Su", "Teng", ""], ["Yu", "Fan", ""]]}, {"id": "2004.10882", "submitter": "Jan Philip G\\\"opfert", "authors": "Niklas Risse, Christina G\\\"opfert, and Jan Philip G\\\"opfert", "title": "How to compare adversarial robustness of classifiers from a global\n  perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial robustness of machine learning models has attracted considerable\nattention over recent years. Adversarial attacks undermine the reliability of\nand trust in machine learning models, but the construction of more robust\nmodels hinges on a rigorous understanding of adversarial robustness as a\nproperty of a given model. Point-wise measures for specific threat models are\ncurrently the most popular tool for comparing the robustness of classifiers and\nare used in most recent publications on adversarial robustness. In this work,\nwe use recently proposed robustness curves to show that point-wise measures\nfail to capture important global properties that are essential to reliably\ncompare the robustness of different classifiers. We introduce new ways in which\nrobustness curves can be used to systematically uncover these properties and\nprovide concrete recommendations for researchers and practitioners when\nassessing and comparing the robustness of trained models. Furthermore, we\ncharacterize scale as a way to distinguish small and large perturbations, and\nrelate it to inherent properties of data sets, demonstrating that robustness\nthresholds must be chosen accordingly. We release code to reproduce all\nexperiments presented in this paper, which includes a Python module to\ncalculate robustness curves for arbitrary data sets and classifiers, supporting\na number of frameworks, including TensorFlow, PyTorch and JAX.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:07:49 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 20:05:25 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Risse", "Niklas", ""], ["G\u00f6pfert", "Christina", ""], ["G\u00f6pfert", "Jan Philip", ""]]}, {"id": "2004.10883", "submitter": "Aaron Tuor", "authors": "Aaron Tuor, Jan Drgona, Draguna Vrabie", "title": "Constrained Neural Ordinary Differential Equations with Stability\n  Guarantees", "comments": "4 pages, Appendix", "journal-ref": "Presented at DEEPDIFFEQ 2020 : ICLR Workshop on Integration of\n  Deep Neural Models and Differential Equations", "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential equations are frequently used in engineering domains, such as\nmodeling and control of industrial systems, where safety and performance\nguarantees are of paramount importance. Traditional physics-based modeling\napproaches require domain expertise and are often difficult to tune or adapt to\nnew systems. In this paper, we show how to model discrete ordinary differential\nequations (ODE) with algebraic nonlinearities as deep neural networks with\nvarying degrees of prior knowledge. We derive the stability guarantees of the\nnetwork layers based on the implicit constraints imposed on the weight's\neigenvalues. Moreover, we show how to use barrier methods to generically handle\nadditional inequality constraints. We demonstrate the prediction accuracy of\nlearned neural ODEs evaluated on open-loop simulations compared to ground truth\ndynamics with bi-linear terms.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:07:57 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Tuor", "Aaron", ""], ["Drgona", "Jan", ""], ["Vrabie", "Draguna", ""]]}, {"id": "2004.10887", "submitter": "Apoorv Shukla", "authors": "Apoorv Shukla, Kevin Hudemann, Zsolt V\\'agi, Lily H\\\"ugerich, Georgios\n  Smaragdakis, Stefan Schmid, Artur Hecker, Anja Feldmann", "title": "Towards Runtime Verification of Programmable Switches", "comments": "added a missing author name to a reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it possible to patch software bugs in P4 programs without human\ninvolvement? We show that this is partially possible in many cases due to\nadvances in software testing and the structure of P4 programs. Our insight is\nthat runtime verification can detect bugs, even those that are not detected at\ncompile-time, with machine learning-guided fuzzing. This enables a more\nautomated and real-time localization of bugs in P4 programs using software\ntesting techniques like Tarantula. Once the bug in a P4 program is localized,\nthe faulty code can be patched due to the programmable nature of P4. In\naddition, platform-dependent bugs can be detected. From P4_14 to P4_16 (latest\nversion), our observation is that as the programmable blocks increase, the\npatchability of P4 programs increases accordingly. To this end, we design,\ndevelop, and evaluate P6 that (a) detects, (b) localizes, and (c) patches bugs\nin P4 programs with minimal human interaction. P6 tests P4 switch\nnon-intrusively, i.e., requires no modification to the P4 program for detecting\nand localizing bugs. We used a P6 prototype to detect and patch seven existing\nbugs in eight publicly available P4 application programs deployed on two\ndifferent switch platforms: behavioral model (bmv2) and Tofino. Our evaluation\nshows that P6 significantly outperforms bug detection baselines while\ngenerating fewer packets and patches bugs in P4 programs such as switch.p4\nwithout triggering any regressions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:22:32 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 13:34:57 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shukla", "Apoorv", ""], ["Hudemann", "Kevin", ""], ["V\u00e1gi", "Zsolt", ""], ["H\u00fcgerich", "Lily", ""], ["Smaragdakis", "Georgios", ""], ["Schmid", "Stefan", ""], ["Hecker", "Artur", ""], ["Feldmann", "Anja", ""]]}, {"id": "2004.10888", "submitter": "Shangtong Zhang", "authors": "Shangtong Zhang, Bo Liu, Shimon Whiteson", "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mean-variance policy iteration (MVPI) framework for risk-averse\ncontrol in a discounted infinite horizon MDP optimizing the variance of a\nper-step reward random variable. MVPI enjoys great flexibility in that any\npolicy evaluation method and risk-neutral control method can be dropped in for\nrisk-averse control off the shelf, in both on- and off-policy settings. This\nflexibility reduces the gap between risk-neutral control and risk-averse\ncontrol and is achieved by working on a novel augmented MDP directly. We\npropose risk-averse TD3 as an example instantiating MVPI, which outperforms\nvanilla TD3 and many previous risk-averse control methods in challenging Mujoco\nrobot simulation tasks under a risk-aware performance metric. This risk-averse\nTD3 is the first to introduce deterministic policies and off-policy learning\ninto risk-averse reinforcement learning, both of which are key to the\nperformance boost we show in Mujoco domains.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:23:44 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:57:35 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:42:41 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 01:02:59 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Shangtong", ""], ["Liu", "Bo", ""], ["Whiteson", "Shimon", ""]]}, {"id": "2004.10898", "submitter": "Badrish Chandramouli", "authors": "Zongheng Yang, Badrish Chandramouli, Chi Wang, Johannes Gehrke, Yinan\n  Li, Umar Farooq Minhas, Per-{\\AA}ke Larson, Donald Kossmann, Rajeev Acharya", "title": "Qd-tree: Learning Data Layouts for Big Data Analytics", "comments": "ACM SIGMOD 2020", "journal-ref": null, "doi": "10.1145/3318464.3389770", "report-no": null, "categories": "cs.DB cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporations today collect data at an unprecedented and accelerating scale,\nmaking the need to run queries on large datasets increasingly important.\nTechnologies such as columnar block-based data organization and compression\nhave become standard practice in most commercial database systems. However, the\nproblem of best assigning records to data blocks on storage is still open. For\nexample, today's systems usually partition data by arrival time into row\ngroups, or range/hash partition the data based on selected fields. For a given\nworkload, however, such techniques are unable to optimize for the important\nmetric of the number of blocks accessed by a query. This metric directly\nrelates to the I/O cost, and therefore performance, of most analytical queries.\nFurther, they are unable to exploit additional available storage to drive this\nmetric down further.\n  In this paper, we propose a new framework called a query-data routing tree,\nor qd-tree, to address this problem, and propose two algorithms for their\nconstruction based on greedy and deep reinforcement learning techniques.\nExperiments over benchmark and real workloads show that a qd-tree can provide\nphysical speedups of more than an order of magnitude compared to current\nblocking schemes, and can reach within 2X of the lower bound for data skipping\nbased on selectivity, while providing complete semantic descriptions of created\nblocks.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 23:42:59 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Yang", "Zongheng", ""], ["Chandramouli", "Badrish", ""], ["Wang", "Chi", ""], ["Gehrke", "Johannes", ""], ["Li", "Yinan", ""], ["Minhas", "Umar Farooq", ""], ["Larson", "Per-\u00c5ke", ""], ["Kossmann", "Donald", ""], ["Acharya", "Rajeev", ""]]}, {"id": "2004.10899", "submitter": "Irene Li", "authors": "Irene Li, Yixin Li, Tianxiao Li, Sergio Alvarez-Napagao, Dario\n  Garcia-Gasulla and Toyotaro Suzumura", "title": "What are We Depressed about When We Talk about COVID19: Mental Health\n  Analysis on Tweets Using Natural Language Processing", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of coronavirus disease 2019 (COVID-19) recently has affected\nhuman life to a great extent. Besides direct physical and economic threats, the\npandemic also indirectly impact people's mental health conditions, which can be\noverwhelming but difficult to measure. The problem may come from various\nreasons such as unemployment status, stay-at-home policy, fear for the virus,\nand so forth. In this work, we focus on applying natural language processing\n(NLP) techniques to analyze tweets in terms of mental health. We trained deep\nmodels that classify each tweet into the following emotions: anger,\nanticipation, disgust, fear, joy, sadness, surprise and trust. We build the\nEmoCT (Emotion-Covid19-Tweet) dataset for the training purpose by manually\nlabeling 1,000 English tweets. Furthermore, we propose and compare two methods\nto find out the reasons that are causing sadness and fear.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 23:45:04 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 18:32:01 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2020 23:06:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Li", "Irene", ""], ["Li", "Yixin", ""], ["Li", "Tianxiao", ""], ["Alvarez-Napagao", "Sergio", ""], ["Garcia-Gasulla", "Dario", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "2004.10914", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Kannan Ramchandran", "title": "Alternating Minimization Converges Super-Linearly for Mixed Linear\n  Regression", "comments": "Accepted for publication at AISTATS, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of solving mixed random linear equations. We have\nunlabeled observations coming from multiple linear regressions, and each\nobservation corresponds to exactly one of the regression models. The goal is to\nlearn the linear regressors from the observations. Classically, Alternating\nMinimization (AM) (which is a variant of Expectation Maximization (EM)) is used\nto solve this problem. AM iteratively alternates between the estimation of\nlabels and solving the regression problems with the estimated labels.\nEmpirically, it is observed that, for a large variety of non-convex problems\nincluding mixed linear regression, AM converges at a much faster rate compared\nto gradient based algorithms. However, the existing theory suggests similar\nrate of convergence for AM and gradient based methods, failing to capture this\nempirical behavior. In this paper, we close this gap between theory and\npractice for the special case of a mixture of $2$ linear regressions. We show\nthat, provided initialized properly, AM enjoys a \\emph{super-linear} rate of\nconvergence in certain parameter regimes. To the best of our knowledge, this is\nthe first work that theoretically establishes such rate for AM. Hence, if we\nwant to recover the unknown regressors upto an error (in $\\ell_2$ norm) of\n$\\epsilon$, AM only takes $\\mathcal{O}(\\log \\log (1/\\epsilon))$ iterations.\nFurthermore, we compare AM with a gradient based heuristic algorithm\nempirically and show that AM dominates in iteration complexity as well as\nwall-clock time.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 00:42:21 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 18:57:59 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ghosh", "Avishek", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "2004.10915", "submitter": "Aditya Menon", "authors": "Ankit Singh Rawat, Aditya Krishna Menon, Andreas Veit, Felix Yu,\n  Sashank J. Reddi, Sanjiv Kumar", "title": "Doubly-stochastic mining for heterogeneous retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern retrieval problems are characterised by training sets with potentially\nbillions of labels, and heterogeneous data distributions across subpopulations\n(e.g., users of a retrieval system may be from different countries), each of\nwhich poses a challenge. The first challenge concerns scalability: with a large\nnumber of labels, standard losses are difficult to optimise even on a single\nexample. The second challenge concerns uniformity: one ideally wants good\nperformance on each subpopulation. While several solutions have been proposed\nto address the first challenge, the second challenge has received relatively\nless attention. In this paper, we propose doubly-stochastic mining (S2M ), a\nstochastic optimization technique that addresses both challenges. In each\niteration of S2M, we compute a per-example loss based on a subset of hardest\nlabels, and then compute the minibatch loss based on the hardest examples. We\nshow theoretically and empirically that by focusing on the hardest examples,\nS2M ensures that all data subpopulations are modelled well.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 00:43:13 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Menon", "Aditya Krishna", ""], ["Veit", "Andreas", ""], ["Yu", "Felix", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2004.10919", "submitter": "Shuangyong Song", "authors": "Shuangyong Song, Chao Wang", "title": "TCNN: Triple Convolutional Neural Network Models for Retrieval-based\n  Question Answering System in E-commerce", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic question-answering (QA) systems have boomed during last few years,\nand commonly used techniques can be roughly categorized into Information\nRetrieval (IR)-based and generation-based. A key solution to the IR based\nmodels is to retrieve the most similar knowledge entries of a given query from\na QA knowledge base, and then rerank those knowledge entries with semantic\nmatching models. In this paper, we aim to improve an IR based e-commerce QA\nsystem-AliMe with proposed text matching models, including a basic Triple\nConvolutional Neural Network (TCNN) model and two Attention-based TCNN (ATCNN)\nmodels. Experimental results show their effect.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 01:02:15 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Song", "Shuangyong", ""], ["Wang", "Chao", ""]]}, {"id": "2004.10927", "submitter": "Shunsuke Aoki", "authors": "Shunsuke Aoki, Takamasa Higuchi, Onur Altintas", "title": "Cooperative Perception with Deep Reinforcement Learning for Connected\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor-based perception on vehicles are becoming prevalent and important to\nenhance the road safety. Autonomous driving systems use cameras, LiDAR, and\nradar to detect surrounding objects, while human-driven vehicles use them to\nassist the driver. However, the environmental perception by individual vehicles\nhas the limitations on coverage and/or detection accuracy. For example, a\nvehicle cannot detect objects occluded by other moving/static obstacles. In\nthis paper, we present a cooperative perception scheme with deep reinforcement\nlearning to enhance the detection accuracy for the surrounding objects. By\nusing the deep reinforcement learning to select the data to transmit, our\nscheme mitigates the network load in vehicular communication networks and\nenhances the communication reliability. To design, test, and verify the\ncooperative perception scheme, we develop a Cooperative & Intelligent Vehicle\nSimulation (CIVS) Platform, which integrates three software components: traffic\nsimulator, vehicle simulator, and object classifier. We evaluate that our\nscheme decreases packet loss and thereby increases the detection accuracy by up\nto 12%, compared to the baseline protocol.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 01:44:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Aoki", "Shunsuke", ""], ["Higuchi", "Takamasa", ""], ["Altintas", "Onur", ""]]}, {"id": "2004.10931", "submitter": "Xiaowei Yue", "authors": "Xiaowei Yue, Yuchen Wen, Jeffrey H. Hunt, and Jianjun Shi", "title": "Active Learning for Gaussian Process Considering Uncertainties with\n  Application to Shape Control of Composite Fuselage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the machine learning domain, active learning is an iterative data\nselection algorithm for maximizing information acquisition and improving model\nperformance with limited training samples. It is very useful, especially for\nthe industrial applications where training samples are expensive,\ntime-consuming, or difficult to obtain. Existing methods mainly focus on active\nlearning for classification, and a few methods are designed for regression such\nas linear regression or Gaussian process. Uncertainties from measurement errors\nand intrinsic input noise inevitably exist in the experimental data, which\nfurther affects the modeling performance. The existing active learning methods\ndo not incorporate these uncertainties for Gaussian process. In this paper, we\npropose two new active learning algorithms for the Gaussian process with\nuncertainties, which are variance-based weighted active learning algorithm and\nD-optimal weighted active learning algorithm. Through numerical study, we show\nthat the proposed approach can incorporate the impact from uncertainties, and\nrealize better prediction performance. This approach has been applied to\nimproving the predictive modeling for automatic shape control of composite\nfuselage.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 02:04:53 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Yue", "Xiaowei", ""], ["Wen", "Yuchen", ""], ["Hunt", "Jeffrey H.", ""], ["Shi", "Jianjun", ""]]}, {"id": "2004.10941", "submitter": "Raef Bassily", "authors": "Raef Bassily, Albert Cheu, Shay Moran, Aleksandar Nikolov, Jonathan\n  Ullman, Zhiwei Steven Wu", "title": "Private Query Release Assisted by Public Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of differentially private query release assisted by\naccess to public data. In this problem, the goal is to answer a large class\n$\\mathcal{H}$ of statistical queries with error no more than $\\alpha$ using a\ncombination of public and private samples. The algorithm is required to satisfy\ndifferential privacy only with respect to the private samples. We study the\nlimits of this task in terms of the private and public sample complexities.\n  First, we show that we can solve the problem for any query class\n$\\mathcal{H}$ of finite VC-dimension using only $d/\\alpha$ public samples and\n$\\sqrt{p}d^{3/2}/\\alpha^2$ private samples, where $d$ and $p$ are the\nVC-dimension and dual VC-dimension of $\\mathcal{H}$, respectively. In\ncomparison, with only private samples, this problem cannot be solved even for\nsimple query classes with VC-dimension one, and without any private samples, a\nlarger public sample of size $d/\\alpha^2$ is needed. Next, we give sample\ncomplexity lower bounds that exhibit tight dependence on $p$ and $\\alpha$. For\nthe class of decision stumps, we give a lower bound of $\\sqrt{p}/\\alpha$ on the\nprivate sample complexity whenever the public sample size is less than\n$1/\\alpha^2$. Given our upper bounds, this shows that the dependence on\n$\\sqrt{p}$ is necessary in the private sample complexity. We also give a lower\nbound of $1/\\alpha$ on the public sample complexity for a broad family of query\nclasses, which by our upper bound, is tight in $\\alpha$.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 02:46:37 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bassily", "Raef", ""], ["Cheu", "Albert", ""], ["Moran", "Shay", ""], ["Nikolov", "Aleksandar", ""], ["Ullman", "Jonathan", ""], ["Wu", "Zhiwei Steven", ""]]}, {"id": "2004.10956", "submitter": "Xiaoyu Tao", "authors": "Xiaoyu Tao, Xiaopeng Hong, Xinyuan Chang, Songlin Dong, Xing Wei,\n  Yihong Gong", "title": "Few-Shot Class-Incremental Learning", "comments": "Accepted by CVPR 2020 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to incrementally learn new classes is crucial to the development\nof real-world artificial intelligence systems. In this paper, we focus on a\nchallenging but practical few-shot class-incremental learning (FSCIL) problem.\nFSCIL requires CNN models to incrementally learn new classes from very few\nlabelled samples, without forgetting the previously learned ones. To address\nthis problem, we represent the knowledge using a neural gas (NG) network, which\ncan learn and preserve the topology of the feature manifold formed by different\nclasses. On this basis, we propose the TOpology-Preserving knowledge\nInCrementer (TOPIC) framework. TOPIC mitigates the forgetting of the old\nclasses by stabilizing NG's topology and improves the representation learning\nfor few-shot new classes by growing and adapting NG to new training samples.\nComprehensive experimental results demonstrate that our proposed method\nsignificantly outperforms other state-of-the-art class-incremental learning\nmethods on CIFAR100, miniImageNet, and CUB200 datasets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 03:38:33 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:12:32 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tao", "Xiaoyu", ""], ["Hong", "Xiaopeng", ""], ["Chang", "Xinyuan", ""], ["Dong", "Songlin", ""], ["Wei", "Xing", ""], ["Gong", "Yihong", ""]]}, {"id": "2004.10958", "submitter": "Yiwen Sun", "authors": "Yiwen Sun, Yulu Wang, Kun Fu, Zheng Wang, Changshui Zhang, Jieping Ye", "title": "Constructing Geographic and Long-term Temporal Graph for Traffic\n  Forecasting", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic forecasting influences various intelligent transportation system\n(ITS) services and is of great significance for user experience as well as\nurban traffic control. It is challenging due to the fact that the road network\ncontains complex and time-varying spatial-temporal dependencies. Recently, deep\nlearning based methods have achieved promising results by adopting graph\nconvolutional network (GCN) to extract the spatial correlations and recurrent\nneural network (RNN) to capture the temporal dependencies. However, the\nexisting methods often construct the graph only based on road network\nconnectivity, which limits the interaction between roads. In this work, we\npropose Geographic and Long term Temporal Graph Convolutional Recurrent Neural\nNetwork (GLT-GCRNN), a novel framework for traffic forecasting that learns the\nrich interactions between roads sharing similar geographic or longterm temporal\npatterns. Extensive experiments on a real-world traffic state dataset validate\nthe effectiveness of our method by showing that GLT-GCRNN outperforms the\nstate-of-the-art methods in terms of different metrics.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 03:50:46 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sun", "Yiwen", ""], ["Wang", "Yulu", ""], ["Fu", "Kun", ""], ["Wang", "Zheng", ""], ["Zhang", "Changshui", ""], ["Ye", "Jieping", ""]]}, {"id": "2004.10963", "submitter": "Yueming Yin", "authors": "Yueming Yin, Zhen Yang, Haifeng Hu and Xiaofu Wu", "title": "Metric-Learning-Assisted Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain alignment (DA) has been widely used in unsupervised domain adaptation.\nMany existing DA methods assume that a low source risk, together with the\nalignment of distributions of source and target, means a low target risk. In\nthis paper, we show that this does not always hold. We thus propose a novel\nmetric-learning-assisted domain adaptation (MLA-DA) method, which employs a\nnovel triplet loss for helping better feature alignment. We explore the\nrelationship between the second largest probability of a target sample's\nprediction and its distance to the decision boundary. Based on the\nrelationship, we propose a novel mechanism to adaptively adjust the margin in\nthe triplet loss according to target predictions. Experimental results show\nthat the use of proposed triplet loss can achieve clearly better results. We\nalso demonstrate the performance improvement of MLA-DA on all four standard\nbenchmarks compared with the state-of-the-art unsupervised domain adaptation\nmethods. Furthermore, MLA-DA shows stable performance in robust experiments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 04:20:02 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 12:22:47 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 09:41:08 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Yin", "Yueming", ""], ["Yang", "Zhen", ""], ["Hu", "Haifeng", ""], ["Wu", "Xiaofu", ""]]}, {"id": "2004.10964", "submitter": "Suchin Gururangan", "authors": "Suchin Gururangan, Ana Marasovi\\'c, Swabha Swayamdipta, Kyle Lo, Iz\n  Beltagy, Doug Downey, Noah A. Smith", "title": "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models pretrained on text from a wide variety of sources form the\nfoundation of today's NLP. In light of the success of these broad-coverage\nmodels, we investigate whether it is still helpful to tailor a pretrained model\nto the domain of a target task. We present a study across four domains\n(biomedical and computer science publications, news, and reviews) and eight\nclassification tasks, showing that a second phase of pretraining in-domain\n(domain-adaptive pretraining) leads to performance gains, under both high- and\nlow-resource settings. Moreover, adapting to the task's unlabeled data\n(task-adaptive pretraining) improves performance even after domain-adaptive\npretraining. Finally, we show that adapting to a task corpus augmented using\nsimple data selection strategies is an effective alternative, especially when\nresources for domain-adaptive pretraining might be unavailable. Overall, we\nconsistently find that multi-phase adaptive pretraining offers large gains in\ntask performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 04:21:19 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 05:07:34 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 22:00:44 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Gururangan", "Suchin", ""], ["Marasovi\u0107", "Ana", ""], ["Swayamdipta", "Swabha", ""], ["Lo", "Kyle", ""], ["Beltagy", "Iz", ""], ["Downey", "Doug", ""], ["Smith", "Noah A.", ""]]}, {"id": "2004.10968", "submitter": "Kaiyan Chang", "authors": "Kaiyan Chang, Wei Jiang, Jinyu Zhan, Zicheng Gong, Weijia Pan", "title": "ArchNet: Data Hiding Model in Distributed Machine Learning System", "comments": null, "journal-ref": null, "doi": "10.1016/j.sysarc.2020.101912", "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating idle embedded devices into cloud computing is a promising\napproach to support distributed machine learning. In this paper, we approach to\naddress the data hiding problem in such distributed machine learning systems.\nFor the purpose of the data encryption in the distributed machine learning\nsystems, we propose the Tripartite Asymmetric Encryption theorem and give\nmathematical proof. Based on the theorem, we design a general image encryption\nscheme ArchNet.The scheme has been implemented on MNIST, Fashion-MNIST and\nCifar-10 datasets to simulate real situation. We use different base models on\nthe encrypted datasets and compare the results with the RC4 algorithm and\ndifferential privacy policy. Experiment results evaluated the efficiency of the\nproposed design. Specifically, our design can improve the accuracy on MNIST up\nto 97.26% compared with RC4.The accuracies on the datasets encrypted by ArchNet\nare 97.26%, 84.15% and 79.80%, and they are 97.31%, 82.31% and 80.22% on the\noriginal datasets, which shows that the encrypted accuracy of ArchNet has the\nsame performance as the base model. It also shows that ArchNet can be deployed\non the distributed system with embedded devices.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 04:59:05 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 09:31:43 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Chang", "Kaiyan", ""], ["Jiang", "Wei", ""], ["Zhan", "Jinyu", ""], ["Gong", "Zicheng", ""], ["Pan", "Weijia", ""]]}, {"id": "2004.10969", "submitter": "Samson Zhou", "authors": "Sepideh Mahabadi, Ilya Razenshteyn, David P. Woodruff, Samson Zhou", "title": "Non-Adaptive Adaptive Sampling on Turnstile Streams", "comments": "To appear at STOC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive sampling is a useful algorithmic tool for data summarization\nproblems in the classical centralized setting, where the entire dataset is\navailable to the single processor performing the computation. Adaptive sampling\nrepeatedly selects rows of an underlying matrix\n$\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$, where $n\\gg d$, with probabilities\nproportional to their distances to the subspace of the previously selected\nrows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass\nalgorithms in the streaming model of computation due to its inherently\nsequential nature of assigning sampling probabilities to each row only after\nthe previous iteration is completed. Surprisingly, we show this is not the case\nby giving the first one-pass algorithms for adaptive sampling on turnstile\nstreams and using space $\\text{poly}(d,k,\\log n)$, where $k$ is the number of\nadaptive sampling rounds to be performed.\n  Our adaptive sampling procedure has a number of applications to various data\nsummarization problems that either improve state-of-the-art or have only been\npreviously studied in the more relaxed row-arrival model. We give the first\nrelative-error algorithms for column subset selection, subspace approximation,\nprojective clustering, and volume maximization on turnstile streams that use\nspace sublinear in $n$. We complement our volume maximization algorithmic\nresults with lower bounds that are tight up to lower order terms, even for\nmulti-pass algorithms. By a similar construction, we also obtain lower bounds\nfor volume maximization in the row-arrival model, which we match with\ncompetitive upper bounds.\n  See paper for full abstract.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:00:21 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Mahabadi", "Sepideh", ""], ["Razenshteyn", "Ilya", ""], ["Woodruff", "David P.", ""], ["Zhou", "Samson", ""]]}, {"id": "2004.10975", "submitter": "Warasinee Chaisangmongkon", "authors": "Isarun Chamveha, Trongtum Tongdee, Pairash Saiviroonporn, and\n  Warasinee Chaisangmongkon", "title": "Local Adaptation Improves Accuracy of Deep Learning Model for Automated\n  X-Ray Thoracic Disease Detection : A Thai Study", "comments": "9 pages, 2 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite much promising research in the area of artificial intelligence for\nmedical image diagnosis, there has been no large-scale validation study done in\nThailand to confirm the accuracy and utility of such algorithms when applied to\nlocal datasets. Here we present a wide-reaching development and testing of a\ndeep learning algorithm for automated thoracic disease detection, utilizing\n421,859 local chest radiographs. Our study shows that convolutional neural\nnetworks can achieve remarkable performance in detecting 13 common abnormality\nconditions on chest X-ray, and the incorporation of local images into the\ntraining set is key to the model's success. This paper presents a\nstate-of-the-art model for CXR abnormality detection, reaching an average AUROC\nof 0.91. This model, if integrated to the workflow, can result in up to 55.6%\nwork reduction for medical practitioners in the CXR analysis process. Our work\nemphasizes the importance of investing in local research of medical diagnosis\nalgorithms to ensure safe and efficient usage within the intended region.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:25:26 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:03:23 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 08:20:14 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Chamveha", "Isarun", ""], ["Tongdee", "Trongtum", ""], ["Saiviroonporn", "Pairash", ""], ["Chaisangmongkon", "Warasinee", ""]]}, {"id": "2004.10980", "submitter": "Woo Seok Lee", "authors": "Woo Seok Lee and Sergej Flach", "title": "Deep Learning of Chaos Classification", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG nlin.CD physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train an artificial neural network which distinguishes chaotic and regular\ndynamics of the two-dimensional Chirikov standard map. We use finite length\ntrajectories and compare the performance with traditional numerical methods\nwhich need to evaluate the Lyapunov exponent. The neural network has superior\nperformance for short periods with length down to 10 Lyapunov times on which\nthe traditional Lyapunov exponent computation is far from converging. We show\nthe robustness of the neural network to varying control parameters, in\nparticular we train with one set of control parameters, and successfully test\nin a complementary set. Furthermore, we use the neural network to successfully\ntest the dynamics of discrete maps in different dimensions, e.g. the\none-dimensional logistic map and a three-dimensional discrete version of the\nLorenz system. Our results demonstrate that a convolutional neural network can\nbe used as an excellent chaos indicator.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:50:44 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lee", "Woo Seok", ""], ["Flach", "Sergej", ""]]}, {"id": "2004.10981", "submitter": "Kexin Lyu", "authors": "Jia Cai, Kexin Lv, Junyi Huo, Xiaolin Huang, Jie Yang", "title": "Sparse Generalized Canonical Correlation Analysis: Distributed\n  Alternating Iteration based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse canonical correlation analysis (CCA) is a useful statistical tool to\ndetect latent information with sparse structures. However, sparse CCA works\nonly for two datasets, i.e., there are only two views or two distinct objects.\nTo overcome this limitation, in this paper, we propose a sparse generalized\ncanonical correlation analysis (GCCA), which could detect the latent relations\nof multiview data with sparse structures. Moreover, the introduced sparsity\ncould be considered as Laplace prior on the canonical variates. Specifically,\nwe convert the GCCA into a linear system of equations and impose $\\ell_1$\nminimization penalty for sparsity pursuit. This results in a nonconvex problem\non Stiefel manifold, which is difficult to solve. Motivated by Boyd's consensus\nproblem, an algorithm based on distributed alternating iteration approach is\ndeveloped and theoretical consistency analysis is investigated elaborately\nunder mild conditions. Experiments on several synthetic and real world datasets\ndemonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:53:48 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Cai", "Jia", ""], ["Lv", "Kexin", ""], ["Huo", "Junyi", ""], ["Huang", "Xiaolin", ""], ["Yang", "Jie", ""]]}, {"id": "2004.10984", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger and Oliver Schulte", "title": "A Complete Characterization of Projectivity for Statistical Relational\n  Models", "comments": "Extended version (with proof appendix) of paper that is too appear in\n  Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A generative probabilistic model for relational data consists of a family of\nprobability distributions for relational structures over domains of different\nsizes. In most existing statistical relational learning (SRL) frameworks, these\nmodels are not projective in the sense that the marginal of the distribution\nfor size-$n$ structures on induced sub-structures of size $k<n$ is equal to the\ngiven distribution for size-$k$ structures. Projectivity is very beneficial in\nthat it directly enables lifted inference and statistically consistent learning\nfrom sub-sampled relational structures. In earlier work some simple fragments\nof SRL languages have been identified that represent projective models.\nHowever, no complete characterization of, and representation framework for\nprojective models has been given. In this paper we fill this gap: exploiting\nrepresentation theorems for infinite exchangeable arrays we introduce a class\nof directed graphical latent variable models that precisely correspond to the\nclass of projective relational models. As a by-product we also obtain a\ncharacterization for when a given distribution over size-$k$ structures is the\nstatistical frequency distribution of size-$k$ sub-structures in much larger\nsize-$n$ structures. These results shed new light onto the old open problem of\nhow to apply Halpern et al.'s \"random worlds approach\" for probabilistic\ninference to general relational signatures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 05:58:27 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 11:44:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jaeger", "Manfred", ""], ["Schulte", "Oliver", ""]]}, {"id": "2004.10987", "submitter": "Qingsen Yan", "authors": "Qingsen Yan, Bo Wang, Dong Gong, Chuan Luo, Wei Zhao, Jianhu Shen,\n  Qinfeng Shi, Shuo Jin, Liang Zhang and Zheng You", "title": "COVID-19 Chest CT Image Segmentation -- A Deep Convolutional Neural\n  Network Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel coronavirus disease 2019 (COVID-19) was detected and has spread\nrapidly across various countries around the world since the end of the year\n2019, Computed Tomography (CT) images have been used as a crucial alternative\nto the time-consuming RT-PCR test. However, pure manual segmentation of CT\nimages faces a serious challenge with the increase of suspected cases,\nresulting in urgent requirements for accurate and automatic segmentation of\nCOVID-19 infections. Unfortunately, since the imaging characteristics of the\nCOVID-19 infection are diverse and similar to the backgrounds, existing medical\nimage segmentation methods cannot achieve satisfactory performance. In this\nwork, we try to establish a new deep convolutional neural network tailored for\nsegmenting the chest CT images with COVID-19 infections. We firstly maintain a\nlarge and new chest CT image dataset consisting of 165,667 annotated chest CT\nimages from 861 patients with confirmed COVID-19. Inspired by the observation\nthat the boundary of the infected lung can be enhanced by adjusting the global\nintensity, in the proposed deep CNN, we introduce a feature variation block\nwhich adaptively adjusts the global properties of the features for segmenting\nCOVID-19 infection. The proposed FV block can enhance the capability of feature\nrepresentation effectively and adaptively for diverse cases. We fuse features\nat different scales by proposing Progressive Atrous Spatial Pyramid Pooling to\nhandle the sophisticated infection areas with diverse appearance and shapes. We\nconducted experiments on the data collected in China and Germany and show that\nthe proposed deep CNN can produce impressive performance effectively.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 06:09:16 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 01:45:16 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yan", "Qingsen", ""], ["Wang", "Bo", ""], ["Gong", "Dong", ""], ["Luo", "Chuan", ""], ["Zhao", "Wei", ""], ["Shen", "Jianhu", ""], ["Shi", "Qinfeng", ""], ["Jin", "Shuo", ""], ["Zhang", "Liang", ""], ["You", "Zheng", ""]]}, {"id": "2004.11001", "submitter": "Michael Gadermayr", "authors": "Michael Gadermayr, Maximilian Tschuchnig, Laxmi Gupta, Dorit Merhof,\n  Nils Kr\\\"amer, Daniel Truhn, Burkhard Gess", "title": "An Asymmetric Cycle-Consistency Loss for Dealing with Many-to-One\n  Mappings in Image Translation: A Study on Thigh MR Scans", "comments": "Presented at IEEE ISBI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks using a cycle-consistency loss facilitate\nunpaired training of image-translation models and thereby exhibit a very high\npotential in manifold medical applications. However, the fact that images in\none domain potentially map to more than one image in another domain (e.g. in\ncase of pathological changes) exhibits a major challenge for training the\nnetworks. In this work, we offer a solution to improve the training process in\ncase of many-to-one mappings by modifying the cycle-consistency loss. We show\nformally and empirically that the proposed method improves the performance\nsignificantly without radically changing the architecture and without\nincreasing the overall complexity. We evaluate our method on thigh MRI scans\nwith the final goal of segmenting the muscle in fat-infiltrated patients' data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 06:59:58 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 06:00:07 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 18:06:13 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Gadermayr", "Michael", ""], ["Tschuchnig", "Maximilian", ""], ["Gupta", "Laxmi", ""], ["Merhof", "Dorit", ""], ["Kr\u00e4mer", "Nils", ""], ["Truhn", "Daniel", ""], ["Gess", "Burkhard", ""]]}, {"id": "2004.11005", "submitter": "Fabio Calefato", "authors": "Nicole Novielli, Fabio Calefato, Filippo Lanubile", "title": "Love, Joy, Anger, Sadness, Fear, and Surprise: SE Needs Special Kinds of\n  AI: A Case Study on Text Mining and SE", "comments": null, "journal-ref": "IEEE Software May/June 2020, Vol. 37, No. 3, pp. 86-91", "doi": "10.1109/MS.2020.2968557", "report-no": null, "categories": "cs.SE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do you like your code? What kind of code makes developers happiest? What\nmakes them angriest? Is it possible to monitor the mood of a large team of\ncoders to determine when and where a codebase needs additional help?\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 07:11:12 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Novielli", "Nicole", ""], ["Calefato", "Fabio", ""], ["Lanubile", "Filippo", ""]]}, {"id": "2004.11015", "submitter": "Benjamin Hettwer", "authors": "Benjamin Hettwer (1 and 2), Tobias Horn (3), Stefan Gehrer (4) and Tim\n  G\\\"uneysu (2) ((1) Robert Bosch GmbH, Corporate Sector Research, Renningen,\n  Germany, (2) Horst G\\\"ortz Institute for IT-Security, Ruhr University Bochum,\n  Germany,(3) Esslingen University of Applied Sciences, Esslingen, Germany, (4)\n  Robert Bosch LLC, Corporate Sector Research, Pittsburgh, USA)", "title": "Encoding Power Traces as Images for Efficient Side-Channel Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Side-Channel Attacks (SCAs) are a powerful method to attack implementations\nof cryptographic algorithms. State-of-the-art techniques such as template\nattacks and stochastic models usually require a lot of manual preprocessing and\nfeature extraction by the attacker. Deep Learning (DL) methods have been\nintroduced to simplify SCAs and simultaneously lowering the amount of required\nside-channel traces for a successful attack. However, the general success of DL\nis largely driven by their capability to classify images, a field in which they\neasily outperform humans. In this paper, we present a novel technique to\ninterpret 1D traces as 2D images. We show and compare several techniques to\ntransform power traces into images, and apply these on different\nimplementations of the Advanced Encryption Standard (AES). By allowing the\nneural network to interpret the trace as an image, we are able to significantly\nreduce the number of required attack traces for a correct key guess.We also\ndemonstrate that the attack efficiency can be improved by using multiple 2D\nimages in the depth channel as an input. Furthermore, by applying image-based\ndata augmentation, we show how the number of profiling traces is reduced by a\nfactor of 50 while simultaneously enhancing the attack performance. This is a\ncrucial improvement, as the amount of traces that can be recorded by an\nattacker is often very limited in real-life applications.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 08:00:37 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 08:53:52 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hettwer", "Benjamin", "", "1 and 2"], ["Horn", "Tobias", ""], ["Gehrer", "Stefan", ""], ["G\u00fcneysu", "Tim", ""]]}, {"id": "2004.11022", "submitter": "Hao Yan", "authors": "Ziyue Li, Hao Yan, Chen Zhang, Fugee Tsung", "title": "Long-Short Term Spatiotemporal Tensor Prediction for Passenger Flow\n  Profile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal data is very common in many applications, such as\nmanufacturing systems and transportation systems. It is typically difficult to\nbe accurately predicted given intrinsic complex spatial and temporal\ncorrelations. Most of the existing methods based on various statistical models\nand regularization terms, fail to preserve innate features in data alongside\ntheir complex correlations. In this paper, we focus on a tensor-based\nprediction and propose several practical techniques to improve prediction. For\nlong-term prediction specifically, we propose the \"Tensor Decomposition +\n2-Dimensional Auto-Regressive Moving Average (2D-ARMA)\" model, and an effective\nway to update prediction real-time; For short-term prediction, we propose to\nconduct tensor completion based on tensor clustering to avoid oversimplifying\nand ensure accuracy. A case study based on the metro passenger flow data is\nconducted to demonstrate the improved performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 08:30:00 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Li", "Ziyue", ""], ["Yan", "Hao", ""], ["Zhang", "Chen", ""], ["Tsung", "Fugee", ""]]}, {"id": "2004.11054", "submitter": "Philip John Gorinski", "authors": "Gabriel Gordon-Hall, Philip John Gorinski, Shay B. Cohen", "title": "Learning Dialog Policies from Weak Demonstrations", "comments": "9 pages + 2 pages references + 1 page appendices, 6 figures, 2\n  tables, 1 algorithm, accepted as long paper at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is a promising approach to training a dialog\nmanager, but current methods struggle with the large state and action spaces of\nmulti-domain dialog systems. Building upon Deep Q-learning from Demonstrations\n(DQfD), an algorithm that scores highly in difficult Atari games, we leverage\ndialog data to guide the agent to successfully respond to a user's requests. We\nmake progressively fewer assumptions about the data needed, using labeled,\nreduced-labeled, and even unlabeled data to train expert demonstrators. We\nintroduce Reinforced Fine-tune Learning, an extension to DQfD, enabling us to\novercome the domain gap between the datasets and the environment. Experiments\nin a challenging multi-domain dialog system framework validate our approaches,\nand get high success rates even when trained on out-of-domain data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:22:16 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 16:02:03 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Gordon-Hall", "Gabriel", ""], ["Gorinski", "Philip John", ""], ["Cohen", "Shay B.", ""]]}, {"id": "2004.11055", "submitter": "Alma Rahat PhD", "authors": "Alma Rahat and Michael Wood", "title": "On Bayesian Search for the Feasible Space Under Computationally\n  Expensive Constraints", "comments": "Accepted at The Sixth International Conference on Machine Learning,\n  Optimization, and Data Science. Main content 12 pages, a total of 19 pages\n  with supplementary. 3 Figures and 2 tables. Python code for Bayesian search\n  is available at: http://bitbucket.org/arahat/lod-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are often interested in identifying the feasible subset of a decision\nspace under multiple constraints to permit effective design exploration. If\ndetermining feasibility required computationally expensive simulations, the\ncost of exploration would be prohibitive. Bayesian search is data-efficient for\nsuch problems: starting from a small dataset, the central concept is to use\nBayesian models of constraints with an acquisition function to locate promising\nsolutions that may improve predictions of feasibility when the dataset is\naugmented. At the end of this sequential active learning approach with a\nlimited number of expensive evaluations, the models can accurately predict the\nfeasibility of any solution obviating the need for full simulations. In this\npaper, we propose a novel acquisition function that combines the probability\nthat a solution lies at the boundary between feasible and infeasible spaces\n(representing exploitation) and the entropy in predictions (representing\nexploration). Experiments confirmed the efficacy of the proposed function.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:22:32 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 12:00:05 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Rahat", "Alma", ""], ["Wood", "Michael", ""]]}, {"id": "2004.11056", "submitter": "Maria Santamaria", "authors": "Maria Santamaria, Saverio Blasi, Ebroul Izquierdo, Marta Mrak", "title": "Analytic Simplification of Neural Network based Intra-Prediction Modes\n  for Video Compression", "comments": "To apper in IEEE ICMEW 2020", "journal-ref": "2020 IEEE International Conference on Multimedia & Expo Workshops\n  (ICMEW), 6-10 July 2020, London, United Kingdom", "doi": "10.1109/ICMEW46912.2020.9106027", "report-no": null, "categories": "eess.IV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for video content at higher resolutions, it is\nevermore critical to find ways to limit the complexity of video encoding tasks\nin order to reduce costs, power consumption and environmental impact of video\nservices. In the last few years, algorithms based on Neural Networks (NN) have\nbeen shown to benefit many conventional video coding modules. But while such\ntechniques can considerably improve the compression efficiency, they usually\nare very computationally intensive. It is highly beneficial to simplify models\nlearnt by NN so that meaningful insights can be exploited with the goal of\nderiving less complex solutions. This paper presents two ways to derive\nsimplified intra-prediction from learnt models, and shows that these\nstreamlined techniques can lead to efficient compression solutions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:25:54 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Santamaria", "Maria", ""], ["Blasi", "Saverio", ""], ["Izquierdo", "Ebroul", ""], ["Mrak", "Marta", ""]]}, {"id": "2004.11077", "submitter": "Barbara Barabasz", "authors": "Barbara Barabasz", "title": "Quantaized Winograd/Toom-Cook Convolution for DNNs: Beyond Canonical\n  Polynomials Base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem how to speed up the convolution computations in Deep Neural\nNetworks is widely investigated in recent years. The Winograd convolution\nalgorithm is a common used method that significantly reduces time consumption.\nHowever, it suffers from a problem with numerical accuracy particularly for\nlower precisions. In this paper we present the application of base change\ntechnique for quantized Winograd-aware training model. We show that we can\ntrain the $8$ bit quantized network to nearly the same accuracy (up to 0.5%\nloss) for tested network (Resnet18) and dataset (CIFAR10) as for quantized\ndirect convolution with few additional operations in pre/post transformations.\nKeeping Hadamard product on $9$ bits allow us to obtain the same accuracy as\nfor direct convolution.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:15:27 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Barabasz", "Barbara", ""]]}, {"id": "2004.11094", "submitter": "Alec Koppel", "authors": "Alec Koppel, Hrusikesha Pradhan, Ketan Rajawat", "title": "Consistent Online Gaussian Process Regression Without the Sample\n  Complexity Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes provide a framework for nonlinear nonparametric Bayesian\ninference widely applicable across science and engineering. Unfortunately,\ntheir computational burden scales cubically with the training sample size,\nwhich in the case that samples arrive in perpetuity, approaches infinity. This\nissue necessitates approximations for use with streaming data, which to date\nmostly lack convergence guarantees. Thus, we develop the first online Gaussian\nprocess approximation that preserves convergence to the population posterior,\ni.e., asymptotic posterior consistency, while ameliorating its intractable\ncomplexity growth with the sample size. We propose an online compression scheme\nthat, following each a posteriori update, fixes an error neighborhood with\nrespect to the Hellinger metric centered at the current posterior, and greedily\ntosses out past kernel dictionary elements until its boundary is hit. We call\nthe resulting method Parsimonious Online Gaussian Processes (POG). For\ndiminishing error radius, exact asymptotic consistency is preserved (Theorem\n1(i)) at the cost of unbounded memory in the limit. On the other hand, for\nconstant error radius, POG converges to a neighborhood of the population\nposterior (Theorem 1(ii))but with finite memory at-worst determined by the\nmetric entropy of the feature space (Theorem 2). Experimental results are\npresented on several nonlinear regression problems which illuminates the merits\nof this approach as compared with alternatives that fix the subspace dimension\ndefining the history of past points.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:52:06 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 15:49:51 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Koppel", "Alec", ""], ["Pradhan", "Hrusikesha", ""], ["Rajawat", "Ketan", ""]]}, {"id": "2004.11098", "submitter": "Friedrich Solowjow", "authors": "Friedrich Solowjow, Dominik Baumann, Christian Fiedler, Andreas\n  Jocham, Thomas Seel, and Sebastian Trimpe", "title": "A Kernel Two-sample Test for Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating whether data streams were generated by the same distribution is at\nthe heart of many machine learning problems, e.g. to detect changes. This is\nparticularly relevant for data generated by dynamical systems since they are\nessential for many real-world processes in biomedical, economic, or engineering\nsystems. While kernel two-sample tests are powerful for comparing independent\nand identically distributed random variables, no established method exists for\ncomparing dynamical systems. The key problem is the critical independence\nassumption, which is inherently violated in dynamical systems. We propose a\nnovel two-sample test for dynamical systems by addressing three core\nchallenges: we (i) introduce a novel notion of mixing that captures\nautocorrelations in a relevant metric, (ii) propose an efficient way to\nestimate the speed of mixing purely from data, and (iii) integrate these into\nestablished kernel-two sample tests. The result is a data-driven method for\ncomparison of dynamical systems that is easy to use in practice and comes with\nsound theoretical guarantees. In an example application to anomaly detection\nfrom human walking data, we show that the test readily applies without the need\nfor feature engineering, heuristics, and human expert knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 11:57:26 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 17:08:22 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Solowjow", "Friedrich", ""], ["Baumann", "Dominik", ""], ["Fiedler", "Christian", ""], ["Jocham", "Andreas", ""], ["Seel", "Thomas", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2004.11114", "submitter": "Patrick McClure", "authors": "Patrick McClure, Dustin Moraczewski, Ka Chun Lam, Adam Thomas,\n  Francisco Pereira", "title": "Improving the Interpretability of fMRI Decoding using Deep Neural\n  Networks and Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are being increasingly used to make predictions\nfrom functional magnetic resonance imaging (fMRI) data. However, they are\nwidely seen as uninterpretable \"black boxes\", as it can be difficult to\ndiscover what input information is used by the DNN in the process, something\nimportant in both cognitive neuroscience and clinical applications. A saliency\nmap is a common approach for producing interpretable visualizations of the\nrelative importance of input features for a prediction. However, methods for\ncreating maps often fail due to DNNs being sensitive to input noise, or by\nfocusing too much on the input and too little on the model. It is also\nchallenging to evaluate how well saliency maps correspond to the truly relevant\ninput information, as ground truth is not always available. In this paper, we\nreview a variety of methods for producing gradient-based saliency maps, and\npresent a new adversarial training method we developed to make DNNs robust to\ninput noise, with the goal of improving interpretability. We introduce two\nquantitative evaluation procedures for saliency map methods in fMRI, applicable\nwhenever a DNN or linear model is being trained to decode some information from\nimaging data. We evaluate the procedures using a synthetic dataset where the\ncomplex activation structure is known, and on saliency maps produced for DNN\nand linear models for task decoding in the Human Connectome Project (HCP)\ndataset. Our key finding is that saliency maps produced with different methods\nvary widely in interpretability, in both in synthetic and HCP fMRI data.\nStrikingly, even when DNN and linear models decode at comparable levels of\nperformance, DNN saliency maps score higher on interpretability than linear\nmodel saliency maps (derived via weights or gradient). Finally, saliency maps\nproduced with our adversarial training method outperform those from other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 12:56:24 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:15:40 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 16:01:57 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["McClure", "Patrick", ""], ["Moraczewski", "Dustin", ""], ["Lam", "Ka Chun", ""], ["Thomas", "Adam", ""], ["Pereira", "Francisco", ""]]}, {"id": "2004.11116", "submitter": "Guillaume Sanchez", "authors": "Guillaume Sanchez, Vincente Guis, Ricard Marxer, Fr\\'ed\\'eric Bouchara", "title": "Deep Learning Classification With Noisy Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning systems have shown tremendous accuracy in image classification,\nat the cost of big image datasets. Collecting such amounts of data can lead to\nlabelling errors in the training set. Indexing multimedia content for\nretrieval, classification or recommendation can involve tagging or\nclassification based on multiple criteria. In our case, we train face\nrecognition systems for actors identification with a closed set of identities\nwhile being exposed to a significant number of perturbators (actors unknown to\nour database). Face classifiers are known to be sensitive to label noise. We\nreview recent works on how to manage noisy annotations when training deep\nlearning classifiers, independently from our interest in face recognition.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:02:45 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Sanchez", "Guillaume", ""], ["Guis", "Vincente", ""], ["Marxer", "Ricard", ""], ["Bouchara", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2004.11120", "submitter": "Varun Bhatt", "authors": "Varun Bhatt, Shalini Shrivastava, Tanmay Chavan, Udayan Ganguly", "title": "Software-Level Accuracy Using Stochastic Computing With\n  Charge-Trap-Flash Based Weight Matrix", "comments": "8 pages, 8 figures, submitted to the International Joint Conference\n  on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The in-memory computing paradigm with emerging memory devices has been\nrecently shown to be a promising way to accelerate deep learning. Resistive\nprocessing unit (RPU) has been proposed to enable the vector-vector outer\nproduct in a crossbar array using a stochastic train of identical pulses to\nenable one-shot weight update, promising intense speed-up in matrix\nmultiplication operations, which form the bulk of training neural networks.\nHowever, the performance of the system suffers if the device does not satisfy\nthe condition of linear conductance change over around 1,000 conductance\nlevels. This is a challenge for nanoscale memories. Recently, Charge Trap Flash\n(CTF) memory was shown to have a large number of levels before saturation, but\nvariable non-linearity. In this paper, we explore the trade-off between the\nrange of conductance change and linearity. We show, through simulations, that\nat an optimum choice of the range, our system performs nearly as well as the\nmodels trained using exact floating point operations, with less than 1%\nreduction in the performance. Our system reaches an accuracy of 97.9% on MNIST\ndataset, 89.1% and 70.5% accuracy on CIFAR-10 and CIFAR-100 datasets (using\npre-extracted features). We also show its use in reinforcement learning, where\nit is used for value function approximation in Q-Learning, and learns to\ncomplete an episode the mountain car control problem in around 146 steps.\nBenchmarked to state-of-the-art, the CTF based RPU shows best in class\nperformance to enable software equivalent performance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:45:58 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bhatt", "Varun", ""], ["Shrivastava", "Shalini", ""], ["Chavan", "Tanmay", ""], ["Ganguly", "Udayan", ""]]}, {"id": "2004.11123", "submitter": "Georgios Leontidis", "authors": "Benedict Delahaye Chivers, John Wallbank, Steven J. Cole, Ondrej\n  Sebek, Simon Stanley, Matthew Fry and Georgios Leontidis", "title": "Imputation of missing sub-hourly precipitation data in a large sensor\n  network: a machine learning approach", "comments": "24 pages, 7 figures, 5 tables", "journal-ref": "Journal of Hydrology 2020", "doi": "10.1016/j.jhydrol.2020.125126", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precipitation data collected at sub-hourly resolution represents specific\nchallenges for missing data recovery by being largely stochastic in nature and\nhighly unbalanced in the duration of rain vs non-rain. Here we present a\ntwo-step analysis utilising current machine learning techniques for imputing\nprecipitation data sampled at 30-minute intervals by devolving the task into\n(a) the classification of rain or non-rain samples, and (b) regressing the\nabsolute values of predicted rain samples. Investigating 37 weather stations in\nthe UK, this machine learning process produces more accurate predictions for\nrecovering precipitation data than an established surface fitting technique\nutilising neighbouring rain gauges. Increasing available features for the\ntraining of machine learning algorithms increases performance with the\nintegration of weather data at the target site with externally sourced rain\ngauges providing the highest performance. This method informs machine learning\nmodels by utilising information in concurrently collected environmental data to\nmake accurate predictions of missing rain data. Capturing complex non-linear\nrelationships from weakly correlated variables is critical for data recovery at\nsub-hourly resolutions. Such pipelines for data recovery can be developed and\ndeployed for highly automated and near instantaneous imputation of missing\nvalues in ongoing datasets at high temporal resolutions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 10:47:18 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 09:11:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chivers", "Benedict Delahaye", ""], ["Wallbank", "John", ""], ["Cole", "Steven J.", ""], ["Sebek", "Ondrej", ""], ["Stanley", "Simon", ""], ["Fry", "Matthew", ""], ["Leontidis", "Georgios", ""]]}, {"id": "2004.11127", "submitter": "Ghislain Durif", "authors": "Benjamin Charlier, Jean Feydy, Joan Alexis Glaun\\`es,\n  Fran\\c{c}ois-David Collin, Ghislain Durif", "title": "Kernel Operations on the GPU, with Autodiff, without Memory Overflows", "comments": "6 pages", "journal-ref": "Journal of Machine Learning Research 22, 1-6 (2021).\n  https://jmlr.org/papers/v22/20-275.html", "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The KeOps library provides a fast and memory-efficient GPU support for\ntensors whose entries are given by a mathematical formula, such as kernel and\ndistance matrices. KeOps alleviates the major bottleneck of tensor-centric\nlibraries for kernel and geometric applications: memory consumption. It also\nsupports automatic differentiation and outperforms standard GPU baselines,\nincluding PyTorch CUDA tensors or the Halide and TVM libraries. KeOps combines\noptimized C++/CUDA schemes with binders for high-level languages: Python (Numpy\nand PyTorch), Matlab and GNU R. As a result, high-level \"quadratic\" codes can\nnow scale up to large data sets with millions of samples processed in seconds.\nKeOps brings graphics-like performances for kernel methods and is freely\navailable on standard repositories (PyPi, CRAN). To showcase its versatility,\nwe provide tutorials in a wide range of settings online at\n\\url{www.kernel-operations.io}.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 08:54:10 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 12:36:50 GMT"}], "update_date": "2021-04-10", "authors_parsed": [["Charlier", "Benjamin", ""], ["Feydy", "Jean", ""], ["Glaun\u00e8s", "Joan Alexis", ""], ["Collin", "Fran\u00e7ois-David", ""], ["Durif", "Ghislain", ""]]}, {"id": "2004.11138", "submitter": "Yisroel Mirsky Dr.", "authors": "Yisroel Mirsky, Wenke Lee", "title": "The Creation and Detection of Deepfakes: A Survey", "comments": null, "journal-ref": "ACM Computing Surveys (CSUR), 2020, preprint", "doi": "10.1145/3425780", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative deep learning algorithms have progressed to a point where it is\ndifficult to tell the difference between what is real and what is fake. In\n2018, it was discovered how easy it is to use this technology for unethical and\nmalicious applications, such as the spread of misinformation, impersonation of\npolitical leaders, and the defamation of innocent individuals. Since then,\nthese `deepfakes' have advanced significantly.\n  In this paper, we explore the creation and detection of deepfakes and provide\nan in-depth view of how these architectures work. The purpose of this survey is\nto provide the reader with a deeper understanding of (1) how deepfakes are\ncreated and detected, (2) the current trends and advancements in this domain,\n(3) the shortcomings of the current defense solutions, and (4) the areas which\nrequire further research and attention.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:35:49 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 22:32:42 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 22:44:33 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Mirsky", "Yisroel", ""], ["Lee", "Wenke", ""]]}, {"id": "2004.11141", "submitter": "Mirko Polato", "authors": "Tommaso Carraro, Mirko Polato, Fabio Aiolli", "title": "Conditioned Variational Autoencoder for top-N item recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a Conditioned Variational Autoencoder (C-VAE) for\nconstrained top-N item recommendation where the recommended items must satisfy\na given condition. The proposed model architecture is similar to a standard VAE\nin which the condition vector is fed into the encoder. The constrained ranking\nis learned during training thanks to a new reconstruction loss that takes the\ninput condition into account. We show that our model generalizes the\nstate-of-the-art Mult-VAE collaborative filtering model. Moreover, we provide\ninsights on what C-VAE learns in the latent space, providing a human-friendly\ninterpretation. Experimental results underline the potential of C-VAE in\nproviding accurate recommendations under constraints. Finally, the performed\nanalyses suggest that C-VAE can be used in other recommendation scenarios, such\nas context-aware recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:29:34 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 16:15:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Carraro", "Tommaso", ""], ["Polato", "Mirko", ""], ["Aiolli", "Fabio", ""]]}, {"id": "2004.11145", "submitter": "Xiangfeng Wang", "authors": "Wenhao Li and Bo Jin and Xiangfeng Wang and Junchi Yan and Hongyuan\n  Zha", "title": "F2A2: Flexible Fully-decentralized Approximate Actor-critic for\n  Cooperative Multi-agent Reinforcement Learning", "comments": "arXiv admin note: text overlap with arXiv:1810.02912,\n  arXiv:1803.11485 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional centralized multi-agent reinforcement learning (MARL) algorithms\nare sometimes unpractical in complicated applications, due to non-interactivity\nbetween agents, curse of dimensionality and computation complexity. Hence,\nseveral decentralized MARL algorithms are motivated. However, existing\ndecentralized methods only handle the fully cooperative setting where massive\ninformation needs to be transmitted in training. The block coordinate gradient\ndescent scheme they used for successive independent actor and critic steps can\nsimplify the calculation, but it causes serious bias. In this paper, we propose\na flexible fully decentralized actor-critic MARL framework, which can combine\nmost of actor-critic methods, and handle large-scale general cooperative\nmulti-agent setting. A primal-dual hybrid gradient descent type algorithm\nframework is designed to learn individual agents separately for\ndecentralization. From the perspective of each agent, policy improvement and\nvalue evaluation are jointly optimized, which can stabilize multi-agent policy\nlearning. Furthermore, our framework can achieve scalability and stability for\nlarge-scale environment and reduce information transmission, by the parameter\nsharing mechanism and a novel modeling-other-agents methods based on\ntheory-of-mind and online supervised learning. Sufficient experiments in\ncooperative Multi-agent Particle Environment and StarCraft II show that our\ndecentralized MARL instantiation algorithms perform competitively against\nconventional centralized and decentralized methods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 14:56:29 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Li", "Wenhao", ""], ["Jin", "Bo", ""], ["Wang", "Xiangfeng", ""], ["Yan", "Junchi", ""], ["Zha", "Hongyuan", ""]]}, {"id": "2004.11147", "submitter": "Hanchen Wang", "authors": "Hanchen Wang, Defu Lian, Ying Zhang, Lu Qin, Xiangjian He, Yiguang\n  Lin, Xuemin Lin", "title": "Binarized Graph Neural Network", "comments": null, "journal-ref": null, "doi": "10.1007/s11280-021-00878-3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been some breakthroughs in graph analysis by applying\nthe graph neural networks (GNNs) following a neighborhood aggregation scheme,\nwhich demonstrate outstanding performance in many tasks. However, we observe\nthat the parameters of the network and the embedding of nodes are represented\nin real-valued matrices in existing GNN-based graph embedding approaches which\nmay limit the efficiency and scalability of these models. It is well-known that\nbinary vector is usually much more space and time efficient than the\nreal-valued vector. This motivates us to develop a binarized graph neural\nnetwork to learn the binary representations of the nodes with binary network\nparameters following the GNN-based paradigm. Our proposed method can be\nseamlessly integrated into the existing GNN-based embedding approaches to\nbinarize the model parameters and learn the compact embedding. Extensive\nexperiments indicate that the proposed binarized graph neural network, namely\nBGN, is orders of magnitude more efficient in terms of both time and space\nwhile matching the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 09:43:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Wang", "Hanchen", ""], ["Lian", "Defu", ""], ["Zhang", "Ying", ""], ["Qin", "Lu", ""], ["He", "Xiangjian", ""], ["Lin", "Yiguang", ""], ["Lin", "Xuemin", ""]]}, {"id": "2004.11149", "submitter": "Huimin Peng", "authors": "Huimin Peng", "title": "A Comprehensive Overview and Survey of Recent Advances in Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews meta-learning also known as learning-to-learn which\nseeks rapid and accurate model adaptation to unseen tasks with applications in\nhighly automated AI, few-shot learning, natural language processing and\nrobotics. Unlike deep learning, meta-learning can be applied to few-shot\nhigh-dimensional datasets and considers further improving model generalization\nto unseen tasks. Deep learning is focused upon in-sample prediction and\nmeta-learning concerns model adaptation for out-of-sample prediction.\nMeta-learning can continually perform self-improvement to achieve highly\nautonomous AI. Meta-learning may serve as an additional generalization block\ncomplementary for original deep learning model. Meta-learning seeks adaptation\nof machine learning models to unseen tasks which are vastly different from\ntrained tasks. Meta-learning with coevolution between agent and environment\nprovides solutions for complex tasks unsolvable by training from scratch.\nMeta-learning methodology covers a wide range of great minds and thoughts. We\nbriefly introduce meta-learning methodologies in the following categories:\nblack-box meta-learning, metric-based meta-learning, layered meta-learning and\nBayesian meta-learning framework. Recent applications concentrate upon the\nintegration of meta-learning with other machine learning framework to provide\nfeasible integrated problem solutions. We briefly present recent meta-learning\nadvances and discuss potential future research directions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:11:08 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 02:10:16 GMT"}, {"version": "v3", "created": "Fri, 8 May 2020 08:48:02 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2020 08:12:11 GMT"}, {"version": "v5", "created": "Sun, 7 Jun 2020 08:16:14 GMT"}, {"version": "v6", "created": "Sat, 11 Jul 2020 14:26:42 GMT"}, {"version": "v7", "created": "Mon, 26 Oct 2020 06:18:08 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Peng", "Huimin", ""]]}, {"id": "2004.11154", "submitter": "Fanghui Liu", "authors": "Fanghui Liu, Xiaolin Huang, Yudong Chen, and Johan A.K. Suykens", "title": "Random Features for Kernel Approximation: A Survey on Algorithms,\n  Theory, and Beyond", "comments": "Short version will be published on IEEE TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random features is one of the most popular techniques to speed up kernel\nmethods in large-scale problems. Related works have been recognized by the\nNeurIPS Test-of-Time award in 2017 and the ICML Best Paper Finalist in 2019.\nThe body of work on random features has grown rapidly, and hence it is\ndesirable to have a comprehensive overview on this topic explaining the\nconnections among various algorithms and theoretical results. In this survey,\nwe systematically review the work on random features from the past ten years.\nFirst, the motivations, characteristics and contributions of representative\nrandom features based algorithms are summarized according to their sampling\nschemes, learning procedures, variance reduction properties and how they\nexploit training data. Second, we review theoretical results that center around\nthe following key question: how many random features are needed to ensure a\nhigh approximation quality or no loss in the empirical/expected risks of the\nlearned estimator. Third, we provide a comprehensive evaluation of popular\nrandom features based algorithms on several large-scale benchmark datasets and\ndiscuss their approximation quality and prediction performance for\nclassification. Last, we discuss the relationship between random features and\nmodern over-parameterized deep neural networks (DNNs), including the use of\nhigh dimensional random features in the analysis of DNNs as well as the gaps\nbetween current theoretical and empirical results. This survey may serve as a\ngentle introduction to this topic, and as a users' guide for practitioners\ninterested in applying the representative algorithms and understanding\ntheoretical results under various technical assumptions. We hope that this\nsurvey will facilitate discussion on the open problems in this topic, and more\nimportantly, shed light on future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:44:48 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 20:32:47 GMT"}, {"version": "v3", "created": "Sat, 4 Jul 2020 19:26:26 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 11:13:28 GMT"}, {"version": "v5", "created": "Sun, 11 Jul 2021 18:59:32 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Liu", "Fanghui", ""], ["Huang", "Xiaolin", ""], ["Chen", "Yudong", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2004.11157", "submitter": "Andres Carvallo", "authors": "Vladimir Araujo, Andres Carvallo, Carlos Aspillaga and Denis Parra", "title": "On Adversarial Examples for Biomedical NLP Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of pre-trained word embeddings has motivated its use in tasks in\nthe biomedical domain. The BERT language model has shown remarkable results on\nstandard performance metrics in tasks such as Named Entity Recognition (NER)\nand Semantic Textual Similarity (STS), which has brought significant progress\nin the field of NLP. However, it is unclear whether these systems work\nseemingly well in critical domains, such as legal or medical. For that reason,\nin this work, we propose an adversarial evaluation scheme on two well-known\ndatasets for medical NER and STS. We propose two types of attacks inspired by\nnatural spelling errors and typos made by humans. We also propose another type\nof attack that uses synonyms of medical terms. Under these adversarial\nsettings, the accuracy of the models drops significantly, and we quantify the\nextent of this performance loss. We also show that we can significantly improve\nthe robustness of the models by training them with adversarial examples. We\nhope our work will motivate the use of adversarial examples to evaluate and\ndevelop models with increased robustness for medical tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:46:11 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Araujo", "Vladimir", ""], ["Carvallo", "Andres", ""], ["Aspillaga", "Carlos", ""], ["Parra", "Denis", ""]]}, {"id": "2004.11163", "submitter": "Lorik Dumani", "authors": "Stefan Ollinger, Lorik Dumani, Premtim Sahitaj, Ralph Bergmann, Ralf\n  Schenkel", "title": "Same Side Stance Classification Task: Facilitating Argument Stance\n  Classification by Fine-tuning a BERT Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on computational argumentation is currently being intensively\ninvestigated. The goal of this community is to find the best pro and con\narguments for a user given topic either to form an opinion for oneself, or to\npersuade others to adopt a certain standpoint. While existing argument mining\nmethods can find appropriate arguments for a topic, a correct classification\ninto pro and con is not yet reliable. The same side stance classification task\nprovides a dataset of argument pairs classified by whether or not both\narguments share the same stance and does not need to distinguish between\ntopic-specific pro and con vocabulary but only the argument similarity within a\nstance needs to be assessed. The results of our contribution to the task are\nbuild on a setup based on the BERT architecture. We fine-tuned a pre-trained\nBERT model for three epochs and used the first 512 tokens of each argument to\npredict if two arguments share the same stance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:54:31 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ollinger", "Stefan", ""], ["Dumani", "Lorik", ""], ["Sahitaj", "Premtim", ""], ["Bergmann", "Ralph", ""], ["Schenkel", "Ralf", ""]]}, {"id": "2004.11165", "submitter": "Susanne Dandl", "authors": "Susanne Dandl, Christoph Molnar, Martin Binder and Bernd Bischl", "title": "Multi-Objective Counterfactual Explanations", "comments": null, "journal-ref": "Parallel Problem Solving from Nature - PPSN XVI. PPSN 2020.\n  Lecture Notes in Computer Science, vol 12269", "doi": "10.1007/978-3-030-58112-1_31", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Counterfactual explanations are one of the most popular methods to make\npredictions of black box machine learning models interpretable by providing\nexplanations in the form of `what-if scenarios'. Most current approaches\noptimize a collapsed, weighted sum of multiple objectives, which are naturally\ndifficult to balance a-priori. We propose the Multi-Objective Counterfactuals\n(MOC) method, which translates the counterfactual search into a multi-objective\noptimization problem. Our approach not only returns a diverse set of\ncounterfactuals with different trade-offs between the proposed objectives, but\nalso maintains diversity in feature space. This enables a more detailed\npost-hoc analysis to facilitate better understanding and also more options for\nactionable user responses to change the predicted outcome. Our approach is also\nmodel-agnostic and works for numerical and categorical input features. We show\nthe usefulness of MOC in concrete cases and compare our approach with\nstate-of-the-art methods for counterfactual explanations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:56:39 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 10:03:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Dandl", "Susanne", ""], ["Molnar", "Christoph", ""], ["Binder", "Martin", ""], ["Bischl", "Bernd", ""]]}, {"id": "2004.11170", "submitter": "Andrea De Lorenzo", "authors": "Marco Virgolin, Andrea De Lorenzo, Eric Medvet, and Francesca Randone", "title": "Learning a Formula of Interpretability to Learn Interpretable Formulas", "comments": "16 pages, 4 figures Accepted at PPSN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many risk-sensitive applications require Machine Learning (ML) models to be\ninterpretable. Attempts to obtain interpretable models typically rely on\ntuning, by trial-and-error, hyper-parameters of model complexity that are only\nloosely related to interpretability. We show that it is instead possible to\ntake a meta-learning approach: an ML model of non-trivial Proxies of Human\nInterpretability (PHIs) can be learned from human feedback, then this model can\nbe incorporated within an ML training process to directly optimize for\ninterpretability. We show this for evolutionary symbolic regression. We first\ndesign and distribute a survey finalized at finding a link between features of\nmathematical formulas and two established PHIs, simulatability and\ndecomposability. Next, we use the resulting dataset to learn an ML model of\ninterpretability. Lastly, we query this model to estimate the interpretability\nof evolving solutions within bi-objective genetic programming. We perform\nexperiments on five synthetic and eight real-world symbolic regression\nproblems, comparing to the traditional use of solution size minimization. The\nresults show that the use of our model leads to formulas that are, for a same\nlevel of accuracy-interpretability trade-off, either significantly more or\nequally accurate. Moreover, the formulas are also arguably more interpretable.\nGiven the very positive results, we believe that our approach represents an\nimportant stepping stone for the design of next-generation interpretable\n(evolutionary) ML algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 13:59:49 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 15:08:37 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Virgolin", "Marco", ""], ["De Lorenzo", "Andrea", ""], ["Medvet", "Eric", ""], ["Randone", "Francesca", ""]]}, {"id": "2004.11184", "submitter": "Aaron Tuor", "authors": "Jan Drgona, Aaron Tuor, Draguna Vrabie", "title": "Learning Stable Adaptive Explicit Differentiable Predictive Control for\n  Unknown Linear Systems", "comments": "11 pages. Code for reproducing our experiments is available at:\n  https://github.com/pnnl/deps_arXiv20204", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present differentiable predictive control (DPC), a method for learning\nconstrained adaptive neural control policies and dynamical models of unknown\nlinear systems. DPC presents an approximate data-driven solution approach to\nthe explicit Model Predictive Control (MPC) problem as a scalable alternative\nto computationally expensive multiparametric programming solvers. DPC is\nformulated as a constrained deep learning problem whose architecture is\ninspired by the structure of classical MPC. The optimization of the neural\ncontrol policy is based on automatic differentiation of the MPC-inspired loss\nfunction through a differentiable closed-loop system model. This novel solution\napproach can optimize adaptive neural control policies for time-varying\nreferences while obeying state and input constraints without the prior need of\nan MPC controller. We show that DPC can learn to stabilize constrained neural\ncontrol policies for systems with unstable dynamics. Moreover, we provide\nsufficient conditions for asymptotic stability of generic closed-loop system\ndynamics with neural feedback policies. In simulation case studies, we assess\nthe performance of the proposed DPC method in terms of reference tracking,\nrobustness, and computational and memory footprints compared against classical\nmodel-based and data-driven control approaches. We demonstrate that DPC scales\nlinearly with problem size, compared to exponential scalability of classical\nexplicit MPC based on multiparametric programming.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:24:44 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 00:38:27 GMT"}, {"version": "v3", "created": "Mon, 17 Aug 2020 22:14:24 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 12:37:15 GMT"}, {"version": "v5", "created": "Fri, 23 Jul 2021 16:48:34 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Drgona", "Jan", ""], ["Tuor", "Aaron", ""], ["Vrabie", "Draguna", ""]]}, {"id": "2004.11198", "submitter": "Fabrizio Frasca", "authors": "Fabrizio Frasca, Emanuele Rossi, Davide Eynard, Ben Chamberlain,\n  Michael Bronstein, Federico Monti", "title": "SIGN: Scalable Inception Graph Neural Networks", "comments": "Extended experiments to ogbn-papers100M", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has recently been applied to a broad spectrum\nof problems ranging from computer graphics and chemistry to high energy physics\nand social media. The popularity of graph neural networks has sparked interest,\nboth in academia and in industry, in developing methods that scale to very\nlarge graphs such as Facebook or Twitter social networks. In most of these\napproaches, the computational cost is alleviated by a sampling strategy\nretaining a subset of node neighbors or subgraphs at training time. In this\npaper we propose a new, efficient and scalable graph deep learning architecture\nwhich sidesteps the need for graph sampling by using graph convolutional\nfilters of different size that are amenable to efficient precomputation,\nallowing extremely fast training and inference. Our architecture allows using\ndifferent local graph operators (e.g. motif-induced adjacency matrices or\nPersonalized Page Rank diffusion matrix) to best suit the task at hand. We\nconduct extensive experimental evaluation on various open benchmarks and show\nthat our approach is competitive with other state-of-the-art architectures,\nwhile requiring a fraction of the training and inference time. Moreover, we\nobtain state-of-the-art results on ogbn-papers100M, the largest public graph\ndataset, with over 110 million nodes and 1.5 billion edges.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 14:46:10 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 10:34:37 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 19:20:22 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Frasca", "Fabrizio", ""], ["Rossi", "Emanuele", ""], ["Eynard", "Davide", ""], ["Chamberlain", "Ben", ""], ["Bronstein", "Michael", ""], ["Monti", "Federico", ""]]}, {"id": "2004.11204", "submitter": "Keshab Parhi", "authors": "Lulu Ge and Keshab K. Parhi", "title": "Classification using Hyperdimensional Computing: A Review", "comments": "IEEE Circuits and Systems Magazine (2020)", "journal-ref": "IEEE Circuits and Systems Magazine, 20(2), pp. 30-47, June 2020", "doi": "10.1109/MCAS.2020.2988388", "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperdimensional (HD) computing is built upon its unique data type referred\nto as hypervectors. The dimension of these hypervectors is typically in the\nrange of tens of thousands. Proposed to solve cognitive tasks, HD computing\naims at calculating similarity among its data. Data transformation is realized\nby three operations, including addition, multiplication and permutation. Its\nultra-wide data representation introduces redundancy against noise. Since\ninformation is evenly distributed over every bit of the hypervectors, HD\ncomputing is inherently robust. Additionally, due to the nature of those three\noperations, HD computing leads to fast learning ability, high energy efficiency\nand acceptable accuracy in learning and classification tasks. This paper\nintroduces the background of HD computing, and reviews the data representation,\ndata transformation, and similarity measurement. The orthogonality in high\ndimensions presents opportunities for flexible computing. To balance the\ntradeoff between accuracy and efficiency, strategies include but are not\nlimited to encoding, retraining, binarization and hardware acceleration.\nEvaluations indicate that HD computing shows great potential in addressing\nproblems using data in the form of letters, signals and images. HD computing\nespecially shows significant promise to replace machine learning algorithms as\na light-weight classifier in the field of internet of things (IoTs).\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 23:51:44 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Ge", "Lulu", ""], ["Parhi", "Keshab K.", ""]]}, {"id": "2004.11206", "submitter": "Sima Sinaei", "authors": "Najmeh Nazari, Seyed Ahmad Mirsalari, Sima Sinaei, Mostafa E. Salehi,\n  Masoud Daneshtalab", "title": "Multi-level Binarized LSTM in EEG Classification for Wearable Devices", "comments": "o appear in IEEE International Conference on Parallel, Distributed\n  and Network-based Processing in 2020. arXiv admin note: text overlap with\n  arXiv:1812.04818 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) is widely used in various sequential\napplications. Complex LSTMs could be hardly deployed on wearable and\nresourced-limited devices due to the huge amount of computations and memory\nrequirements. Binary LSTMs are introduced to cope with this problem, however,\nthey lead to significant accuracy loss in some application such as EEG\nclassification which is essential to be deployed in wearable devices. In this\npaper, we propose an efficient multi-level binarized LSTM which has\nsignificantly reduced computations whereas ensuring an accuracy pretty close to\nfull precision LSTM. By deploying 5-level binarized weights and inputs, our\nmethod reduces area and delay of MAC operation about 31* and 27* in 65nm\ntechnology, respectively with less than 0.01% accuracy loss. In contrast to\nmany compute-intensive deep-learning approaches, the proposed algorithm is\nlightweight, and therefore, brings performance efficiency with accurate\nLSTM-based EEG classification to real-time wearable devices.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 17:48:55 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Nazari", "Najmeh", ""], ["Mirsalari", "Seyed Ahmad", ""], ["Sinaei", "Sima", ""], ["Salehi", "Mostafa E.", ""], ["Daneshtalab", "Masoud", ""]]}, {"id": "2004.11228", "submitter": "Hojjat Navidan", "authors": "Parisa Fard Moshiri, Hojjat Navidan, Reza Shahbazian, Seyed Ali\n  Ghorashi, David Windridge", "title": "Using GAN to Enhance the Accuracy of Indoor Human Activity Recognition", "comments": "5 pages, 3 figures, Proceedings of IKT2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indoor human activity recognition (HAR) explores the correlation between\nhuman body movements and the reflected WiFi signals to classify different\nactivities. By analyzing WiFi signal patterns, especially the dynamics of\nchannel state information (CSI), different activities can be distinguished.\nGathering CSI data is expensive both from the timing and equipment perspective.\nIn this paper, we use synthetic data to reduce the need for real measured CSI.\nWe present a semi-supervised learning method for CSI-based activity recognition\nsystems in which long short-term memory (LSTM) is employed to learn features\nand recognize seven different actions. We apply principal component analysis\n(PCA) on CSI amplitude data, while short-time Fourier transform (STFT) extracts\nthe features in the frequency domain. At first, we train the LSTM network with\nentirely raw CSI data, which takes much more processing time. To this end, we\naim to generate data by using 50% of raw data in conjunction with a generative\nadversarial network (GAN). Our experimental results confirm that this model can\nincrease classification accuracy by 3.4% and reduce the Log loss by almost 16%\nin the considered scenario.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:22:05 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Moshiri", "Parisa Fard", ""], ["Navidan", "Hojjat", ""], ["Shahbazian", "Reza", ""], ["Ghorashi", "Seyed Ali", ""], ["Windridge", "David", ""]]}, {"id": "2004.11231", "submitter": "Khaoula El Mekkaoui", "authors": "Khaoula El Mekkaoui, Diego Mesquita, Paul Blomstedt, Samuel Kaski", "title": "Federated Stochastic Gradient Langevin Dynamics", "comments": "Accepted to UAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient MCMC methods, such as stochastic gradient Langevin\ndynamics (SGLD), employ fast but noisy gradient estimates to enable large-scale\nposterior sampling. Although we can easily extend SGLD to distributed settings,\nit suffers from two issues when applied to federated non-IID data. First, the\nvariance of these estimates increases significantly. Second, delaying\ncommunication causes the Markov chains to diverge from the true posterior even\nfor very simple models. To alleviate both these problems, we propose conducive\ngradients, a simple mechanism that combines local likelihood approximations to\ncorrect gradient updates. Notably, conducive gradients are easy to compute, and\nsince we only calculate the approximations once, they incur negligible\noverhead. We apply conducive gradients to distributed stochastic gradient\nLangevin dynamics (DSGLD) and call the resulting method federated stochastic\ngradient Langevin dynamics (FSGLD). We demonstrate that our approach can handle\ndelayed communication rounds, converging to the target posterior in cases where\nDSGLD fails. We also show that FSGLD outperforms DSGLD for non-IID federated\ndata with experiments on metric learning and neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:25:09 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2021 14:50:31 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 23:50:47 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mekkaoui", "Khaoula El", ""], ["Mesquita", "Diego", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "2004.11233", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda", "title": "QUANOS- Adversarial Noise Sensitivity Driven Hybrid Quantization of\n  Neural Networks", "comments": "Accepted in ACM/IEEE International Symposium on Low Power Electronics\n  and Design (ISLPED), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have been shown to be vulnerable to adversarial\nattacks, wherein, a model gets fooled by applying slight perturbations on the\ninput. With the advent of Internet-of-Things and the necessity to enable\nintelligence in embedded devices, low-power and secure hardware implementation\nof DNNs is vital. In this paper, we investigate the use of quantization to\npotentially resist adversarial attacks. Several recent studies have reported\nremarkable results in reducing the energy requirement of a DNN through\nquantization. However, no prior work has considered the relationship between\nadversarial sensitivity of a DNN and its effect on quantization. We propose\nQUANOS- a framework that performs layer-specific hybrid quantization based on\nAdversarial Noise Sensitivity (ANS). We identify a novel noise stability metric\n(ANS) for DNNs, i.e., the sensitivity of each layer's computation to\nadversarial noise. ANS allows for a principled way of determining optimal\nbit-width per layer that incurs adversarial robustness as well as\nenergy-efficiency with minimal loss in accuracy. Essentially, QUANOS assigns\nlayer significance based on its contribution to adversarial perturbation and\naccordingly scales the precision of the layers. A key advantage of QUANOS is\nthat it does not rely on a pre-trained model and can be applied in the initial\nstages of training. We evaluate the benefits of QUANOS on precision scalable\nMultiply and Accumulate (MAC) hardware architectures with data gating and\nsubword parallelism capabilities. Our experiments on CIFAR10, CIFAR100 datasets\nshow that QUANOS outperforms homogenously quantized 8-bit precision baseline in\nterms of adversarial robustness (3%-4% higher) while yielding improved\ncompression (>5x) and energy savings (>2x) at iso-accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:56:31 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 13:14:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Panda", "Priyadarshini", ""]]}, {"id": "2004.11234", "submitter": "Juan-Pablo Ortega", "authors": "Lukas Gonon, Lyudmila Grigoryeva, and Juan-Pablo Ortega", "title": "Memory and forecasting capacities of nonlinear recurrent networks", "comments": "27 pages, 1 figure. To appear in Physica D", "journal-ref": null, "doi": "10.1016/j.physd.2020.132721", "report-no": null, "categories": "math.OC cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of memory capacity, originally introduced for echo state and\nlinear networks with independent inputs, is generalized to nonlinear recurrent\nnetworks with stationary but dependent inputs. The presence of dependence in\nthe inputs makes natural the introduction of the network forecasting capacity,\nthat measures the possibility of forecasting time series values using network\nstates. Generic bounds for memory and forecasting capacities are formulated in\nterms of the number of neurons of the nonlinear recurrent network and the\nautocovariance function or the spectral density of the input. These bounds\ngeneralize well-known estimates in the literature to a dependent inputs setup.\nFinally, for the particular case of linear recurrent networks with independent\ninputs it is proved that the memory capacity is given by the rank of the\nassociated controllability matrix, a fact that has been for a long time assumed\nto be true without proof by the community.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:10:51 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 10:53:00 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Gonon", "Lukas", ""], ["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "2004.11238", "submitter": "Andreas Rene Geist", "authors": "A. Rene Geist and Sebastian Trimpe", "title": "Learning Constrained Dynamics with Gauss Principle adhering Gaussian\n  Processes", "comments": "To be published in 2nd Annual Conference on Learning for Dynamics and\n  Control (L4DC), Proceedings of Machine Learning Research 2020", "journal-ref": "Proceedings of the 2nd Conference on Learning for Dynamics and\n  Control, PMLR 120:225-234, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of the constrained dynamics of mechanical systems is often\nchallenging. Learning methods promise to ease an analytical analysis, but\nrequire considerable amounts of data for training. We propose to combine\ninsights from analytical mechanics with Gaussian process regression to improve\nthe model's data efficiency and constraint integrity. The result is a Gaussian\nprocess model that incorporates a priori constraint knowledge such that its\npredictions adhere to Gauss' principle of least constraint. In return,\npredictions of the system's acceleration naturally respect potentially\nnon-ideal (non-)holonomic equality constraints. As corollary results, our model\nenables to infer the acceleration of the unconstrained system from data of the\nconstrained system and enables knowledge transfer between differing constraint\nconfigurations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:26:51 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Geist", "A. Rene", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2004.11243", "submitter": "Monica Arul", "authors": "Monica Arul and Ahsan Kareem", "title": "Applications of shapelet transform to time series classification of\n  earthquake, wind and wave data", "comments": "24 pages, 14 figures. arXiv admin note: text overlap with\n  arXiv:1911.09086", "journal-ref": "Eng. Struct 228 (2021) 111564", "doi": "10.1016/j.engstruct.2020.111564", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous detection of desired events from large databases using time series\nclassification is becoming increasingly important in civil engineering as a\nresult of continued long-term health monitoring of a large number of\nengineering structures encompassing buildings, bridges, towers, and offshore\nplatforms. In this context, this paper proposes the application of a relatively\nnew time series representation named \"Shapelet transform\", which is based on\nlocal similarity in the shape of the time series subsequences. In consideration\nof the individual attributes distinctive to time series signals in earthquake,\nwind and ocean engineering, the application of this transform yields a new\nshape-based feature representation. Combining this shape-based representation\nwith a standard machine learning algorithm, a truly \"white-box\" machine\nlearning model is proposed with understandable features and a transparent\nalgorithm. This model automates event detection without the intervention of\ndomain practitioners, yielding a practical event detection procedure. The\nefficacy of this proposed shapelet transform-based autonomous detection\nprocedure is demonstrated by examples, to identify known and unknown earthquake\nevents from continuously recorded ground-motion measurements, to detect pulses\nin the velocity time history of ground motions to distinguish between\nnear-field and far-field ground motions, to identify thunderstorms from\ncontinuous wind speed measurements, to detect large-amplitude wind-induced\nvibrations from the bridge monitoring data, and to identify plunging breaking\nwaves that have a significant impact on offshore structures.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 10:17:24 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Arul", "Monica", ""], ["Kareem", "Ahsan", ""]]}, {"id": "2004.11245", "submitter": "Claire Voreiter", "authors": "Claire Voreiter (OBELIX), Jean-Christophe Burnel (OBELIX), Pierre\n  Lassalle (CNES), Marc Spigai (TAS), Romain Hugues (TAS), Nicolas Courty (FT\n  R&D, OBELIX)", "title": "A Cycle GAN Approach for Heterogeneous Domain Adaptation in Land Use\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of remote sensing and more specifically in Earth Observation,\nnew data are available every day, coming from different sensors. Leveraging on\nthose data in classification tasks comes at the price of intense labelling\ntasks that are not realistic in operational settings. While domain adaptation\ncould be useful to counterbalance this problem, most of the usual methods\nassume that the data to adapt are comparable (they belong to the same metric\nspace), which is not the case when multiple sensors are at stake. Heterogeneous\ndomain adaptation methods are a particular solution to this problem. We present\na novel method to deal with such cases, based on a modified cycleGAN version\nthat incorporates classification losses and a metric space alignment term. We\ndemonstrate its power on a land use classification tasks, with images from both\nGoogle Earth and Sentinel-2.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:16:18 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Voreiter", "Claire", "", "OBELIX"], ["Burnel", "Jean-Christophe", "", "OBELIX"], ["Lassalle", "Pierre", "", "CNES"], ["Spigai", "Marc", "", "TAS"], ["Hugues", "Romain", "", "TAS"], ["Courty", "Nicolas", "", "FT\n  R&D, OBELIX"]]}, {"id": "2004.11250", "submitter": "Pu Zhao", "authors": "Wei Niu, Pu Zhao, Zheng Zhan, Xue Lin, Yanzhi Wang, Bin Ren", "title": "Towards Real-Time DNN Inference on Mobile Platforms with Model Pruning\n  and Compiler Optimization", "comments": "accepted by the IJCAI-PRICAI 2020 Demonstrations Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-end mobile platforms rapidly serve as primary computing devices for a\nwide range of Deep Neural Network (DNN) applications. However, the constrained\ncomputation and storage resources on these devices still pose significant\nchallenges for real-time DNN inference executions. To address this problem, we\npropose a set of hardware-friendly structured model pruning and compiler\noptimization techniques to accelerate DNN executions on mobile devices. This\ndemo shows that these optimizations can enable real-time mobile execution of\nmultiple DNN applications, including style transfer, DNN coloring and super\nresolution.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:18:23 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Niu", "Wei", ""], ["Zhao", "Pu", ""], ["Zhan", "Zheng", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""], ["Ren", "Bin", ""]]}, {"id": "2004.11252", "submitter": "Edson Bollis Mst", "authors": "Edson Bollis, Helio Pedrini, and Sandra Avila", "title": "Weakly Supervised Learning Guided by Activation Mapping Applied to a\n  Novel Citrus Pest Benchmark", "comments": "Accepted to The 1st International Workshop on Agriculture-Vision\n  Workshop - CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pests and diseases are relevant factors for production losses in agriculture\nand, therefore, promote a huge investment in the prevention and detection of\nits causative agents. In many countries, Integrated Pest Management is the most\nwidely used process to prevent and mitigate the damages caused by pests and\ndiseases in citrus crops. However, its results are credited by humans who\nvisually inspect the orchards in order to identify the disease symptoms,\ninsects and mite pests. In this context, we design a weakly supervised learning\nprocess guided by saliency maps to automatically select regions of interest in\nthe images, significantly reducing the annotation task. In addition, we create\na large citrus pest benchmark composed of positive samples (six classes of mite\nspecies) and negative samples. Experiments conducted on two large datasets\ndemonstrate that our results are very promising for the problem of pest and\ndisease classification in the agriculture field.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 01:26:50 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Bollis", "Edson", ""], ["Pedrini", "Helio", ""], ["Avila", "Sandra", ""]]}, {"id": "2004.11262", "submitter": "Lukas Hedegaard", "authors": "Lukas Hedegaard, Omar Ali Sheikh-Omar, Alexandros Iosifidis", "title": "Supervised Domain Adaptation: A Graph Embedding Perspective and a\n  Rectified Experimental Protocol", "comments": "13 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of machine learning models tends to suffer when the\ndistributions of training and test data differ. This distribution gap can be\nalleviated with a process known as Domain Adaptation. In this paper, we show\nthat Domain Adaptation methods using pair-wise relationships between source and\ntarget domain data can be formulated as a Graph Embedding in which the domain\nlabels are incorporated into the structure of the intrinsic and penalty graphs.\nSpecifically, we analyse the loss functions of three existing state-of-the-art\nSupervised Domain Adaptation methods and demonstrate that they perform Graph\nEmbedding. Moreover, we highlight some generalisation and reproducibility\nissues related to the experimental setup commonly used to demonstrate the\nfew-shot learning capabilities of these methods. To assess and compare\nSupervised Domain Adaptation methods accurately, we propose a rectified\nevaluation protocol, and report updated benchmarks on the standard datasets\nOffice31 (Amazon, DSLR, and Webcam) and Digits (MNIST, USPS, SVHN, and\nMNIST-M).\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 15:46:20 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 09:39:35 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 13:46:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Hedegaard", "Lukas", ""], ["Sheikh-Omar", "Omar Ali", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "2004.11284", "submitter": "Kaizhi Qian", "authors": "Kaizhi Qian, Yang Zhang, Shiyu Chang, David Cox, Mark Hasegawa-Johnson", "title": "Unsupervised Speech Decomposition via Triple Information Bottleneck", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech information can be roughly decomposed into four components: language\ncontent, timbre, pitch, and rhythm. Obtaining disentangled representations of\nthese components is useful in many speech analysis and generation applications.\nRecently, state-of-the-art voice conversion systems have led to speech\nrepresentations that can disentangle speaker-dependent and independent\ninformation. However, these systems can only disentangle timbre, while\ninformation about pitch, rhythm and content is still mixed together. Further\ndisentangling the remaining speech components is an under-determined problem in\nthe absence of explicit annotations for each component, which are difficult and\nexpensive to obtain. In this paper, we propose SpeechSplit, which can blindly\ndecompose speech into its four components by introducing three carefully\ndesigned information bottlenecks. SpeechSplit is among the first algorithms\nthat can separately perform style transfer on timbre, pitch and rhythm without\ntext labels. Our code is publicly available at\nhttps://github.com/auspicious3000/SpeechSplit.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:12:42 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 14:41:36 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 16:20:02 GMT"}, {"version": "v4", "created": "Sat, 27 Jun 2020 04:21:56 GMT"}, {"version": "v5", "created": "Tue, 11 Aug 2020 16:03:04 GMT"}, {"version": "v6", "created": "Sat, 13 Mar 2021 15:31:35 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Qian", "Kaizhi", ""], ["Zhang", "Yang", ""], ["Chang", "Shiyu", ""], ["Cox", "David", ""], ["Hasegawa-Johnson", "Mark", ""]]}, {"id": "2004.11293", "submitter": "Yawen Wu", "authors": "Yawen Wu, Zhepeng Wang, Zhenge Jia, Yiyu Shi, Jingtong Hu", "title": "Intermittent Inference with Nonuniformly Compressed Multi-Exit Neural\n  Network for Energy Harvesting Powered Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to enable persistent, event-driven sensing and decision\ncapabilities for energy-harvesting (EH)-powered devices by deploying\nlightweight DNNs onto EH-powered devices. However, harvested energy is usually\nweak and unpredictable and even lightweight DNNs take multiple power cycles to\nfinish one inference. To eliminate the indefinite long wait to accumulate\nenergy for one inference and to optimize the accuracy, we developed a power\ntrace-aware and exit-guided network compression algorithm to compress and\ndeploy multi-exit neural networks to EH-powered microcontrollers (MCUs) and\nselect exits during execution according to available energy. The experimental\nresults show superior accuracy and latency compared with state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:19:22 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 17:18:03 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Wu", "Yawen", ""], ["Wang", "Zhepeng", ""], ["Jia", "Zhenge", ""], ["Shi", "Yiyu", ""], ["Hu", "Jingtong", ""]]}, {"id": "2004.11300", "submitter": "Luca Mariot", "authors": "Domagoj Jakobovic, Luca Manzoni, Luca Mariot, Stjepan Picek, Mauro\n  Castelli", "title": "CoInGP: Convolutional Inpainting with Genetic Programming", "comments": "21 pages, 8 figures, updated pre-print accepted at GECCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of Genetic Programming (GP) as a convolutional\npredictor for missing pixels in images. The training phase is performed by\nsweeping a sliding window over an image, where the pixels on the border\nrepresent the inputs of a GP tree. The output of the tree is taken as the\npredicted value for the central pixel. We consider two topologies for the\nsliding window, namely the Moore and the Von Neumann neighborhood. The best GP\ntree scoring the lowest prediction error over the training set is then used to\npredict the pixels in the test set. We experimentally assess our approach\nthrough two experiments. In the first one, we train a GP tree over a subset of\n1000 complete images from the MNIST dataset. The results show that GP can learn\nthe distribution of the pixels with respect to a simple baseline predictor,\nwith no significant differences observed between the two neighborhoods. In the\nsecond experiment, we train a GP convolutional predictor on two degraded\nimages, removing around 20% of their pixels. In this case, we observe that the\nMoore neighborhood works better, although the Von Neumann neighborhood allows\nfor a larger training set.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:31:58 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 10:23:28 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Jakobovic", "Domagoj", ""], ["Manzoni", "Luca", ""], ["Mariot", "Luca", ""], ["Picek", "Stjepan", ""], ["Castelli", "Mauro", ""]]}, {"id": "2004.11302", "submitter": "Daniel Krutz", "authors": "Jeffrey Palmerino, Qi Yu, Travis Desell and Daniel E. Krutz", "title": "Improving the Decision-Making Process of Self-Adaptive Systems by\n  Accounting for Tactic Volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When self-adaptive systems encounter changes within their surrounding\nenvironments, they enact tactics to perform necessary adaptations. For example,\na self-adaptive cloud-based system may have a tactic that initiates additional\ncomputing resources when response time thresholds are surpassed, or there may\nbe a tactic to activate a specific security measure when an intrusion is\ndetected. In real-world environments, these tactics frequently experience\ntactic volatility which is variable behavior during the execution of the\ntactic.\n  Unfortunately, current self-adaptive approaches do not account for tactic\nvolatility in their decision-making processes, and merely assume that tactics\ndo not experience volatility. This limitation creates uncertainty in the\ndecision-making process and may adversely impact the system's ability to\neffectively and efficiently adapt. Additionally, many processes do not properly\naccount for volatility that may effect the system's Service Level Agreement\n(SLA). This can limit the system's ability to act proactively, especially when\nutilizing tactics that contain latency.\n  To address the challenge of sufficiently accounting for tactic volatility, we\npropose a Tactic Volatility Aware (TVA) solution. Using Multiple Regression\nAnalysis (MRA), TVA enables self-adaptive systems to accurately estimate the\ncost and time required to execute tactics. TVA also utilizes Autoregressive\nIntegrated Moving Average (ARIMA) for time series forecasting, allowing the\nsystem to proactively maintain specifications.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 16:34:28 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Palmerino", "Jeffrey", ""], ["Yu", "Qi", ""], ["Desell", "Travis", ""], ["Krutz", "Daniel E.", ""]]}, {"id": "2004.11327", "submitter": "Ahmed Hasan Zaidi", "authors": "Ahmed Zaidi, Andrew Caines, Russell Moore, Paula Buttery and Andrew\n  Rice", "title": "Adaptive Forgetting Curves for Spaced Repetition Language Learning", "comments": "Artificial Intelligence for Education 2020 (AIED)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forgetting curve has been extensively explored by psychologists,\neducationalists and cognitive scientists alike. In the context of Intelligent\nTutoring Systems, modelling the forgetting curve for each user and knowledge\ncomponent (e.g. vocabulary word) should enable us to develop optimal revision\nstrategies that counteract memory decay and ensure long-term retention. In this\nstudy we explore a variety of forgetting curve models incorporating\npsychological and linguistic features, and we use these models to predict the\nprobability of word recall by learners of English as a second language. We\nevaluate the impact of the models and their features using data from an online\nvocabulary teaching platform and find that word complexity is a highly\ninformative feature which may be successfully learned by a neural network\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:22:38 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Zaidi", "Ahmed", ""], ["Caines", "Andrew", ""], ["Moore", "Russell", ""], ["Buttery", "Paula", ""], ["Rice", "Andrew", ""]]}, {"id": "2004.11345", "submitter": "Gregory Kahn", "authors": "Suneel Belkhale, Rachel Li, Gregory Kahn, Rowan McAllister, Roberto\n  Calandra, Sergey Levine", "title": "Model-Based Meta-Reinforcement Learning for Flight with Suspended\n  Payloads", "comments": null, "journal-ref": "IEEE Robotics and Automation Letters 2021", "doi": "10.1109/LRA.2021.3057046", "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transporting suspended payloads is challenging for autonomous aerial vehicles\nbecause the payload can cause significant and unpredictable changes to the\nrobot's dynamics. These changes can lead to suboptimal flight performance or\neven catastrophic failure. Although adaptive control and learning-based methods\ncan in principle adapt to changes in these hybrid robot-payload systems, rapid\nmid-flight adaptation to payloads that have a priori unknown physical\nproperties remains an open problem. We propose a meta-learning approach that\n\"learns how to learn\" models of altered dynamics within seconds of\npost-connection flight data. Our experiments demonstrate that our online\nadaptation approach outperforms non-adaptive methods on a series of challenging\nsuspended payload transportation tasks. Videos and other supplemental material\nare available on our website: https://sites.google.com/view/meta-rl-for-flight\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:43:56 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 06:32:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Belkhale", "Suneel", ""], ["Li", "Rachel", ""], ["Kahn", "Gregory", ""], ["McAllister", "Rowan", ""], ["Calandra", "Roberto", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.11349", "submitter": "Huy Phan", "authors": "Huy Phan, Kaare Mikkelsen, Oliver Y. Ch\\'en, Philipp Koch, Alfred\n  Mertins, Preben Kidmose, Maarten De Vos", "title": "Personalized Automatic Sleep Staging with Single-Night Data: a Pilot\n  Study with KL-Divergence Regularization", "comments": "This article has been published in Physiological Measurement", "journal-ref": null, "doi": "10.1088/1361-6579/ab921e", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain waves vary between people. An obvious way to improve automatic sleep\nstaging for longitudinal sleep monitoring is personalization of algorithms\nbased on individual characteristics extracted from the first night of data. As\na single night is a very small amount of data to train a sleep staging model,\nwe propose a Kullback-Leibler (KL) divergence regularized transfer learning\napproach to address this problem. We employ the pretrained SeqSleepNet (i.e.\nthe subject independent model) as a starting point and finetune it with the\nsingle-night personalization data to derive the personalized model. This is\ndone by adding the KL divergence between the output of the subject independent\nmodel and the output of the personalized model to the loss function during\nfinetuning. In effect, KL-divergence regularization prevents the personalized\nmodel from overfitting to the single-night data and straying too far away from\nthe subject independent model. Experimental results on the Sleep-EDF Expanded\ndatabase with 75 subjects show that sleep staging personalization with a\nsingle-night data is possible with help of the proposed KL-divergence\nregularization. On average, we achieve a personalized sleep staging accuracy of\n79.6%, a Cohen's kappa of 0.706, a macro F1-score of 73.0%, a sensitivity of\n71.8%, and a specificity of 94.2%. We find both that the approach is robust\nagainst overfitting and that it improves the accuracy by 4.5 percentage points\ncompared to non-personalization and 2.2 percentage points compared to\npersonalization without regularization.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:48:22 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 23:16:17 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Phan", "Huy", ""], ["Mikkelsen", "Kaare", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Mertins", "Alfred", ""], ["Kidmose", "Preben", ""], ["De Vos", "Maarten", ""]]}, {"id": "2004.11356", "submitter": "Michael Kapteyn", "authors": "Michael G. Kapteyn and Karen E. Willcox", "title": "From Physics-Based Models to Predictive Digital Twins via Interpretable\n  Machine Learning", "comments": "20 pages, 13 figures, submitted to AIAA Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work develops a methodology for creating a data-driven digital twin from\na library of physics-based models representing various asset states. The\ndigital twin is updated using interpretable machine learning. Specifically, we\nuse optimal trees---a recently developed scalable machine learning method---to\ntrain an interpretable data-driven classifier. Training data for the classifier\nare generated offline using simulated scenarios solved by the library of\nphysics-based models. These data can be further augmented using experimental or\nother historical data. In operation, the classifier uses observational data\nfrom the asset to infer which physics-based models in the model library are the\nbest candidates for the updated digital twin. The approach is demonstrated\nthrough the development of a structural digital twin for a 12ft wingspan\nunmanned aerial vehicle. This digital twin is built from a library of\nreduced-order models of the vehicle in a range of structural states. The\ndata-driven digital twin dynamically updates in response to structural damage\nor degradation and enables the aircraft to replan a safe mission accordingly.\nWithin this context, we study the performance of the optimal tree classifiers\nand demonstrate how their interpretability enables explainable structural\nassessments from sparse sensor measurements, and also informs optimal sensor\nplacement.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:55:04 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 00:41:35 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 21:08:37 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kapteyn", "Michael G.", ""], ["Willcox", "Karen E.", ""]]}, {"id": "2004.11362", "submitter": "Aaron Maschinot", "authors": "Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian,\n  Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan", "title": "Supervised Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning applied to self-supervised representation learning has\nseen a resurgence in recent years, leading to state of the art performance in\nthe unsupervised training of deep image models. Modern batch contrastive\napproaches subsume or significantly outperform traditional contrastive losses\nsuch as triplet, max-margin and the N-pairs loss. In this work, we extend the\nself-supervised batch contrastive approach to the fully-supervised setting,\nallowing us to effectively leverage label information. Clusters of points\nbelonging to the same class are pulled together in embedding space, while\nsimultaneously pushing apart clusters of samples from different classes. We\nanalyze two possible versions of the supervised contrastive (SupCon) loss,\nidentifying the best-performing formulation of the loss. On ResNet-200, we\nachieve top-1 accuracy of 81.4% on the ImageNet dataset, which is 0.8% above\nthe best number reported for this architecture. We show consistent\noutperformance over cross-entropy on other datasets and two ResNet variants.\nThe loss shows benefits for robustness to natural corruptions and is more\nstable to hyperparameter settings such as optimizers and data augmentations.\nOur loss function is simple to implement, and reference TensorFlow code is\nreleased at https://t.ly/supcon.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 17:58:56 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:51:35 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2020 15:16:53 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 22:25:05 GMT"}, {"version": "v5", "created": "Wed, 10 Mar 2021 19:11:45 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Khosla", "Prannay", ""], ["Teterwak", "Piotr", ""], ["Wang", "Chen", ""], ["Sarna", "Aaron", ""], ["Tian", "Yonglong", ""], ["Isola", "Phillip", ""], ["Maschinot", "Aaron", ""], ["Liu", "Ce", ""], ["Krishnan", "Dilip", ""]]}, {"id": "2004.11368", "submitter": "William Aiken", "authors": "William Aiken, Hyoungshick Kim, Simon Woo", "title": "Neural Network Laundering: Removing Black-Box Backdoor Watermarks from\n  Deep Neural Networks", "comments": "15 pages, 12 figures, 8 tables, formatted for ASIACCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating a state-of-the-art deep-learning system requires vast amounts of\ndata, expertise, and hardware, yet research into embedding copyright protection\nfor neural networks has been limited. One of the main methods for achieving\nsuch protection involves relying on the susceptibility of neural networks to\nbackdoor attacks, but the robustness of these tactics has been primarily\nevaluated against pruning, fine-tuning, and model inversion attacks. In this\nwork, we propose a neural network \"laundering\" algorithm to remove black-box\nbackdoor watermarks from neural networks even when the adversary has no prior\nknowledge of the structure of the watermark.\n  We are able to effectively remove watermarks used for recent defense or\ncopyright protection mechanisms while achieving test accuracies above 97% and\n80% for both MNIST and CIFAR-10, respectively. For all backdoor watermarking\nmethods addressed in this paper, we find that the robustness of the watermark\nis significantly weaker than the original claims. We also demonstrate the\nfeasibility of our algorithm in more complex tasks as well as in more realistic\nscenarios where the adversary is able to carry out efficient laundering attacks\nusing less than 1% of the original training set size, demonstrating that\nexisting backdoor watermarks are not sufficient to reach their claims.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:02:47 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Aiken", "William", ""], ["Kim", "Hyoungshick", ""], ["Woo", "Simon", ""]]}, {"id": "2004.11369", "submitter": "Vukosi Marivate", "authors": "Henry Wandera, Vukosi Marivate, David Sengeh", "title": "Investigating similarities and differences between South African and\n  Sierra Leonean school outcomes using Machine Learning", "comments": "In review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Available or adequate information to inform decision making for resource\nallocation in support of school improvement is a critical issue globally. In\nthis paper, we apply machine learning and education data mining techniques on\neducation big data to identify determinants of high schools' performance in two\nAfrican countries: South Africa and Sierra Leone. The research objective is to\nbuild predictors for school performance and extract the importance of different\ncommunity and school-level features. We deploy interpretable metrics from\nmachine learning approaches such as SHAP values on tree models and odds ratios\nof LR to extract interactions of factors that can support policy decision\nmaking. Determinants of performance vary in these two countries, hence\ndifferent policy implications and resource allocation recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 19:29:16 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wandera", "Henry", ""], ["Marivate", "Vukosi", ""], ["Sengeh", "David", ""]]}, {"id": "2004.11370", "submitter": "Robby Costales", "authors": "Robby Costales, Chengzhi Mao, Raphael Norwitz, Bryan Kim, Junfeng Yang", "title": "Live Trojan Attacks on Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like all software systems, the execution of deep learning models is dictated\nin part by logic represented as data in memory. For decades, attackers have\nexploited traditional software programs by manipulating this data. We propose a\nlive attack on deep learning systems that patches model parameters in memory to\nachieve predefined malicious behavior on a certain set of inputs. By minimizing\nthe size and number of these patches, the attacker can reduce the amount of\nnetwork communication and memory overwrites, with minimal risk of system\nmalfunctions or other detectable side effects. We demonstrate the feasibility\nof this attack by computing efficient patches on multiple deep learning models.\nWe show that the desired trojan behavior can be induced with a few small\npatches and with limited access to training data. We describe the details of\nhow this attack is carried out on real systems and provide sample code for\npatching TensorFlow model parameters in Windows and in Linux. Lastly, we\npresent a technique for effectively manipulating entropy on perturbed inputs to\nbypass STRIP, a state-of-the-art run-time trojan detection technique.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 22:08:29 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 21:21:46 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Costales", "Robby", ""], ["Mao", "Chengzhi", ""], ["Norwitz", "Raphael", ""], ["Kim", "Bryan", ""], ["Yang", "Junfeng", ""]]}, {"id": "2004.11372", "submitter": "Ajitesh Srivastava", "authors": "Ajitesh Srivastava, Viktor K. Prasanna", "title": "Learning to Forecast and Forecasting to Learn from the COVID-19 Pandemic", "comments": "12 pages, 8 figures. Added a figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasts of COVID-19 is central to resource management and building\nstrategies to deal with the epidemic. We propose a heterogeneous infection rate\nmodel with human mobility for epidemic modeling, a preliminary version of which\nwe have successfully used during DARPA Grand Challenge 2014. By linearizing the\nmodel and using weighted least squares, our model is able to quickly adapt to\nchanging trends and provide extremely accurate predictions of confirmed cases\nat the level of countries and states of the United States. We show that during\nthe earlier part of the epidemic, using travel data increases the predictions.\nTraining the model to forecast also enables learning characteristics of the\nepidemic. In particular, we show that changes in model parameters over time can\nhelp us quantify how well a state or a country has responded to the epidemic.\nThe variations in parameters also allow us to forecast different scenarios such\nas what would happen if we were to disregard social distancing suggestions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 07:25:46 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 04:19:01 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 19:13:08 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Srivastava", "Ajitesh", ""], ["Prasanna", "Viktor K.", ""]]}, {"id": "2004.11380", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel M. Kane, Shachar Lovett, Gaurav Mahajan", "title": "Point Location and Active Learning: Learning Halfspaces Almost Optimally", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite set $X \\subset \\mathbb{R}^d$ and a binary linear classifier\n$c: \\mathbb{R}^d \\to \\{0,1\\}$, how many queries of the form $c(x)$ are required\nto learn the label of every point in $X$? Known as \\textit{point location},\nthis problem has inspired over 35 years of research in the pursuit of an\noptimal algorithm. Building on the prior work of Kane, Lovett, and Moran (ICALP\n2018), we provide the first nearly optimal solution, a randomized linear\ndecision tree of depth $\\tilde{O}(d\\log(|X|))$, improving on the previous best\nof $\\tilde{O}(d^2\\log(|X|))$ from Ezra and Sharir (Discrete and Computational\nGeometry, 2019). As a corollary, we also provide the first nearly optimal\nalgorithm for actively learning halfspaces in the membership query model. En\nroute to these results, we prove a novel characterization of Barthe's Theorem\n(Inventiones Mathematicae, 1998) of independent interest. In particular, we\nshow that $X$ may be transformed into approximate isotropic position if and\nonly if there exists no $k$-dimensional subspace with more than a\n$k/d$-fraction of $X$, and provide a similar characterization for exact\nisotropic position.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:00:00 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "2004.11410", "submitter": "Giambattista Parascandolo", "authors": "Giambattista Parascandolo, Lars Buesing, Josh Merel, Leonard\n  Hasenclever, John Aslanides, Jessica B. Hamrick, Nicolas Heess, Alexander\n  Neitz, Theophane Weber", "title": "Divide-and-Conquer Monte Carlo Tree Search For Goal-Directed Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard planners for sequential decision making (including Monte Carlo\nplanning, tree search, dynamic programming, etc.) are constrained by an\nimplicit sequential planning assumption: The order in which a plan is\nconstructed is the same in which it is executed. We consider alternatives to\nthis assumption for the class of goal-directed Reinforcement Learning (RL)\nproblems. Instead of an environment transition model, we assume an imperfect,\ngoal-directed policy. This low-level policy can be improved by a plan,\nconsisting of an appropriate sequence of sub-goals that guide it from the start\nto the goal state. We propose a planning algorithm, Divide-and-Conquer Monte\nCarlo Tree Search (DC-MCTS), for approximating the optimal plan by means of\nproposing intermediate sub-goals which hierarchically partition the initial\ntasks into simpler ones that are then solved independently and recursively. The\nalgorithm critically makes use of a learned sub-goal proposal for finding\nappropriate partitions trees of new tasks based on prior experience. Different\nstrategies for learning sub-goal proposals give rise to different planning\nstrategies that strictly generalize sequential planning. We show that this\nalgorithmic flexibility over planning order leads to improved results in\nnavigation tasks in grid-worlds as well as in challenging continuous control\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:08:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Buesing", "Lars", ""], ["Merel", "Josh", ""], ["Hasenclever", "Leonard", ""], ["Aslanides", "John", ""], ["Hamrick", "Jessica B.", ""], ["Heess", "Nicolas", ""], ["Neitz", "Alexander", ""], ["Weber", "Theophane", ""]]}, {"id": "2004.11424", "submitter": "Kexin Huang", "authors": "Kexin Huang, Cao Xiao, Lucas Glass, Jimeng Sun", "title": "MolTrans: Molecular Interaction Transformer for Drug Target Interaction\n  Prediction", "comments": "Bioinformatics, 2020", "journal-ref": null, "doi": "10.1093/bioinformatics/btaa880", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drug target interaction (DTI) prediction is a foundational task for in silico\ndrug discovery, which is costly and time-consuming due to the need of\nexperimental search over large drug compound space. Recent years have witnessed\npromising progress for deep learning in DTI predictions. However, the following\nchallenges are still open: (1) the sole data-driven molecular representation\nlearning approaches ignore the sub-structural nature of DTI, thus produce\nresults that are less accurate and difficult to explain; (2) existing methods\nfocus on limited labeled data while ignoring the value of massive unlabelled\nmolecular data. We propose a Molecular Interaction Transformer (MolTrans) to\naddress these limitations via: (1) knowledge inspired sub-structural pattern\nmining algorithm and interaction modeling module for more accurate and\ninterpretable DTI prediction; (2) an augmented transformer encoder to better\nextract and capture the semantic relations among substructures extracted from\nmassive unlabeled biomedical data. We evaluate MolTrans on real world data and\nshow it improved DTI prediction performance compared to state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 18:56:04 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "2004.11437", "submitter": "Douglas Matos De Souza", "authors": "Douglas M. Souza, J\\^onatas Wehrmann, Duncan D. Ruiz", "title": "Efficient Neural Architecture for Text-to-Image Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-to-image synthesis is the task of generating images from text\ndescriptions. Image generation, by itself, is a challenging task. When we\ncombine image generation and text, we bring complexity to a new level: we need\nto combine data from two different modalities. Most of recent works in\ntext-to-image synthesis follow a similar approach when it comes to neural\narchitectures. Due to aforementioned difficulties, plus the inherent difficulty\nof training GANs at high resolutions, most methods have adopted a multi-stage\ntraining strategy. In this paper we shift the architectural paradigm currently\nused in text-to-image methods and show that an effective neural architecture\ncan achieve state-of-the-art performance using a single stage training with a\nsingle generator and a single discriminator. We do so by applying deep residual\nnetworks along with a novel sentence interpolation strategy that enables\nlearning a smooth conditional space. Finally, our work points a new direction\nfor text-to-image research, which has not experimented with novel neural\narchitectures recently.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:33:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Souza", "Douglas M.", ""], ["Wehrmann", "J\u00f4natas", ""], ["Ruiz", "Duncan D.", ""]]}, {"id": "2004.11440", "submitter": "Sungsoo (Ray) Hong", "authors": "Sungsoo Ray Hong, Jessica Hullman, Enrico Bertini", "title": "Human Factors in Model Interpretability: Industry Practices, Challenges,\n  and Needs", "comments": "ACM CSCW 2020", "journal-ref": null, "doi": "10.1145/3392878", "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of machine learning (ML) models in product development and\ndata-driven decision-making processes became pervasive in many domains,\npeople's focus on building a well-performing model has increasingly shifted to\nunderstanding how their model works. While scholarly interest in model\ninterpretability has grown rapidly in research communities like HCI, ML, and\nbeyond, little is known about how practitioners perceive and aim to provide\ninterpretability in the context of their existing workflows. This lack of\nunderstanding of interpretability as practiced may prevent interpretability\nresearch from addressing important needs, or lead to unrealistic solutions. To\nbridge this gap, we conducted 22 semi-structured interviews with industry\npractitioners to understand how they conceive of and design for\ninterpretability while they plan, build, and use their models. Based on a\nqualitative analysis of our results, we differentiate interpretability roles,\nprocesses, goals and strategies as they exist within organizations making heavy\nuse of ML models. The characterization of interpretability work that emerges\nfrom our analysis suggests that model interpretability frequently involves\ncooperation and mental model comparison between people in different roles,\noften aimed at building trust not only between people and models but also\nbetween people within the organization. We present implications for design that\ndiscuss gaps between the interpretability challenges that practitioners face in\ntheir practice and approaches proposed in the literature, highlighting possible\nresearch directions that can better address real-world needs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:54:39 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 12:10:43 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hong", "Sungsoo Ray", ""], ["Hullman", "Jessica", ""], ["Bertini", "Enrico", ""]]}, {"id": "2004.11449", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, R\\'emi Lebret, Didier Orel, Philippe Sordet, Karl Aberer", "title": "Upgrading the Newsroom: An Automated Image Selection System for News\n  Articles", "comments": "Accepted to ACM Transactions on Multimedia Computing Communications\n  and Applications (ACM TOMM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an automated image selection system to assist photo editors in\nselecting suitable images for news articles. The system fuses multiple textual\nsources extracted from news articles and accepts multilingual inputs. It is\nequipped with char-level word embeddings to help both modeling morphologically\nrich languages, e.g. German, and transferring knowledge across nearby\nlanguages. The text encoder adopts a hierarchical self-attention mechanism to\nattend more to both keywords within a piece of text and informative components\nof a news article. We extensively experiment with our system on a large-scale\ntext-image database containing multimodal multilingual news articles collected\nfrom Swiss local news media websites. The system is compared with multiple\nbaselines with ablation studies and is shown to beat existing text-image\nretrieval methods in a weakly-supervised learning setting. Besides, we also\noffer insights on the advantage of using multiple textual sources and\nmultilingual data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 20:29:26 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Liu", "Fangyu", ""], ["Lebret", "R\u00e9mi", ""], ["Orel", "Didier", ""], ["Sordet", "Philippe", ""], ["Aberer", "Karl", ""]]}, {"id": "2004.11456", "submitter": "Yohei Hayamizu", "authors": "Yohei Hayamizu, Saeid Amiri, Kishan Chandan, Keiki Takadama, Shiqi\n  Zhang", "title": "Guiding Robot Exploration in Reinforcement Learning via Automated\n  Planning", "comments": "Accepted in International Conference of Planning and Scheduling\n  (ICAPS-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reinforcement learning (RL) enables an agent to learn from trial-and-error\nexperiences toward achieving long-term goals; automated planning aims to\ncompute plans for accomplishing tasks using action knowledge. Despite their\nshared goal of completing complex tasks, the development of RL and automated\nplanning has been largely isolated due to their different computational\nmodalities. Focusing on improving RL agents' learning efficiency, we develop\nGuided Dyna-Q (GDQ) to enable RL agents to reason with action knowledge to\navoid exploring less-relevant states. The action knowledge is used for\ngenerating artificial experiences from an optimistic simulation. GDQ has been\nevaluated in simulation and using a mobile robot conducting navigation tasks in\na multi-room office environment. Compared with competitive baselines, GDQ\nsignificantly reduces the effort in exploration while improving the quality of\nlearned policies.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:03:30 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 14:47:46 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Hayamizu", "Yohei", ""], ["Amiri", "Saeid", ""], ["Chandan", "Kishan", ""], ["Takadama", "Keiki", ""], ["Zhang", "Shiqi", ""]]}, {"id": "2004.11460", "submitter": "Jimmy Jose", "authors": "Amruthlal M, Devika S, Ameer Suhail P A, Aravind K Menon, Vignesh\n  Krishnan, Alan Thomas, Manu Thomas, Sanjay G, Lakshmi Kanth L R, Jimmy Jose,\n  Harikrishnan S", "title": "Development of a Machine Learning Model and Mobile Application to Aid in\n  Predicting Dosage of Vitamin K Antagonists Among Indian Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients who undergo mechanical heart valve replacements or have conditions\nlike Atrial Fibrillation have to take Vitamin K Antagonists (VKA) drugs to\nprevent coagulation of blood. These drugs have narrow therapeutic range and\nneed to be very closely monitored due to life threatening side effects. The\ndosage of VKA drug is determined and revised by a physician based on\nProthrombin Time - International Normalised Ratio (PT-INR) value obtained\nthrough a blood test. Our work aimed at predicting the maintenance dosage of\nwarfarin, the present most widely recommended anticoagulant drug, using the\nde-identified medical data collected from 109 patients from Kerala. A Support\nVector Machine (SVM) Regression model was built to predict the maintenance\ndosage of warfarin, for patients who have been undergoing treatment from a\nphysician and have reached stable INR values between 2.0 and 4.0.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 05:54:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["M", "Amruthlal", ""], ["S", "Devika", ""], ["A", "Ameer Suhail P", ""], ["Menon", "Aravind K", ""], ["Krishnan", "Vignesh", ""], ["Thomas", "Alan", ""], ["Thomas", "Manu", ""], ["G", "Sanjay", ""], ["R", "Lakshmi Kanth L", ""], ["Jose", "Jimmy", ""], ["S", "Harikrishnan", ""]]}, {"id": "2004.11464", "submitter": "Jocelyn Mazarura", "authors": "Jocelyn Mazarura, Alta de Waal and Pieter de Villiers", "title": "A Gamma-Poisson Mixture Topic Model for Short Text", "comments": "26 pages, 14 Figures, to be published in Mathematical Problems in\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most topic models are constructed under the assumption that documents follow\na multinomial distribution. The Poisson distribution is an alternative\ndistribution to describe the probability of count data. For topic modelling,\nthe Poisson distribution describes the number of occurrences of a word in\ndocuments of fixed length. The Poisson distribution has been successfully\napplied in text classification, but its application to topic modelling is not\nwell documented, specifically in the context of a generative probabilistic\nmodel. Furthermore, the few Poisson topic models in literature are admixture\nmodels, making the assumption that a document is generated from a mixture of\ntopics. In this study, we focus on short text. Many studies have shown that the\nsimpler assumption of a mixture model fits short text better. With mixture\nmodels, as opposed to admixture models, the generative assumption is that a\ndocument is generated from a single topic. One topic model, which makes this\none-topic-per-document assumption, is the Dirichlet-multinomial mixture model.\nThe main contributions of this work are a new Gamma-Poisson mixture model, as\nwell as a collapsed Gibbs sampler for the model. The benefit of the collapsed\nGibbs sampler derivation is that the model is able to automatically select the\nnumber of topics contained in the corpus. The results show that the\nGamma-Poisson mixture model performs better than the Dirichlet-multinomial\nmixture model at selecting the number of topics in labelled corpora.\nFurthermore, the Gamma-Poisson mixture produces better topic coherence scores\nthan the Dirichlet-multinomial mixture model, thus making it a viable option\nfor the challenging task of topic modelling of short text.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:13:53 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mazarura", "Jocelyn", ""], ["de Waal", "Alta", ""], ["de Villiers", "Pieter", ""]]}, {"id": "2004.11468", "submitter": "Zsigmond Benk\\H{o}", "authors": "Zsigmond Benk\\H{o}, Tam\\'as B\\'abel, Zolt\\'an Somogyv\\'ari", "title": "How to find a unicorn: a novel model-free, unsupervised anomaly\n  detection method for time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of anomalous events is a challenging but critical task in many\nscientific and industrial fields, especially when the properties of anomalies\nare unknown. In this paper, we introduce a new anomaly concept called \"unicorn\"\nor unique event and present a new, model-free, unsupervised detection algorithm\nto detect unicorns. The key component of the new algorithm is the Temporal\nOutlier Factor (TOF) to measure the uniqueness of events in continuous data\nsets from dynamic systems. The concept of unique events differs significantly\nfrom traditional outliers in many aspects: while repetitive outliers are no\nlonger unique events, a unique event is not necessarily an outlier; it does not\nnecessarily fall out from the distribution of normal activity. The performance\nof our algorithm was examined in recognizing unique events on different types\nof simulated data sets with anomalies and it was compared with the Local\nOutlier Factor (LOF) and discord discovery algorithms. TOF had superior\nperformance compared to LOF and discord algorithms even in recognizing\ntraditional outliers and it also recognized unique events that those did not.\nThe benefits of the unicorn concept and the new detection method were\nillustrated by example data sets from very different scientific fields. Our\nalgorithm successfully recognized unique events in those cases where they were\nalready known such as the gravitational waves of a binary black hole merger on\nLIGO detector data and the signs of respiratory failure on ECG data series.\nFurthermore, unique events were found on the LIBOR data set of the last 30\nyears.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 21:38:38 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 14:58:17 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 09:08:02 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Benk\u0151", "Zsigmond", ""], ["B\u00e1bel", "Tam\u00e1s", ""], ["Somogyv\u00e1ri", "Zolt\u00e1n", ""]]}, {"id": "2004.11483", "submitter": "Leonardo Nascimento Ferreira", "authors": "Leonardo N. Ferreira, Didier A. Vega-Oliveros, Moshe Cotacallapa,\n  Manoel F. Cardoso, Marcos G. Quiles, Liang Zhao, Elbert E. N. Macau", "title": "Spatiotemporal data analysis with chronological networks", "comments": null, "journal-ref": "Nat Commun 11, 4036 (2020)", "doi": "10.1038/s41467-020-17634-2", "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The amount and size of spatiotemporal data sets from different domains have\nbeen rapidly increasing in the last years, which demands the development of\nrobust and fast methods to analyze and extract information from them. In this\npaper, we propose a network-based model for spatiotemporal data analysis called\nchronnet. It consists of dividing a geometrical space into grid cells\nrepresented by nodes connected chronologically. The main goal of this model is\nto represent consecutive recurrent events between cells with strong links in\nthe network. This representation permits the use of network science and\ngraphing mining tools to extract information from spatiotemporal data. The\nchronnet construction process is fast, which makes it suitable for large data\nsets. In this paper, we describe how to use our model considering artificial\nand real data. For this purpose, we propose an artificial spatiotemporal data\nset generator to show how chronnets capture not just simple statistics, but\nalso frequent patterns, spatial changes, outliers, and spatiotemporal clusters.\nAdditionally, we analyze a real-world data set composed of global fire\ndetections, in which we describe the frequency of fire events, outlier fire\ndetections, and the seasonal activity, using a single chronnet.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 22:50:43 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 12:20:45 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Ferreira", "Leonardo N.", ""], ["Vega-Oliveros", "Didier A.", ""], ["Cotacallapa", "Moshe", ""], ["Cardoso", "Manoel F.", ""], ["Quiles", "Marcos G.", ""], ["Zhao", "Liang", ""], ["Macau", "Elbert E. N.", ""]]}, {"id": "2004.11488", "submitter": "Ninghao Liu", "authors": "Ninghao Liu, Mengnan Du, Ruocheng Guo, Huan Liu, Xia Hu", "title": "Adversarial Attacks and Defenses: An Interpretation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent advances in a wide spectrum of applications, machine\nlearning models, especially deep neural networks, have been shown to be\nvulnerable to adversarial attacks. Attackers add carefully-crafted\nperturbations to input, where the perturbations are almost imperceptible to\nhumans, but can cause models to make wrong predictions. Techniques to protect\nmodels against adversarial input are called adversarial defense methods.\nAlthough many approaches have been proposed to study adversarial attacks and\ndefenses in different scenarios, an intriguing and crucial challenge remains\nthat how to really understand model vulnerability? Inspired by the saying that\n\"if you know yourself and your enemy, you need not fear the battles\", we may\ntackle the aforementioned challenge after interpreting machine learning models\nto open the black-boxes. The goal of model interpretation, or interpretable\nmachine learning, is to extract human-understandable terms for the working\nmechanism of models. Recently, some approaches start incorporating\ninterpretation into the exploration of adversarial attacks and defenses.\nMeanwhile, we also observe that many existing methods of adversarial attacks\nand defenses, although not explicitly claimed, can be understood from the\nperspective of interpretation. In this paper, we review recent work on\nadversarial attacks and defenses, particularly from the perspective of machine\nlearning interpretation. We categorize interpretation into two types,\nfeature-level interpretation and model-level interpretation. For each type of\ninterpretation, we elaborate on how it could be used for adversarial attacks\nand defenses. We then briefly illustrate additional correlations between\ninterpretation and adversaries. Finally, we discuss the challenges and future\ndirections along tackling adversary issues with interpretation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 23:19:00 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 15:43:26 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Liu", "Ninghao", ""], ["Du", "Mengnan", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""], ["Hu", "Xia", ""]]}, {"id": "2004.11494", "submitter": "Yanjun  Qi Dr.", "authors": "Arshdeep Sekhon, Beilun Wang, Zhe Wang, Yanjun Qi", "title": "Differential Network Learning Beyond Data Samples", "comments": "9 pages of main draft; 25 pages of Appendix; 5 Tables ; 14 Figures ;\n  Learning of Structure Difference between Two Graphical Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the change of statistical dependencies between random variables is\nan essential task for many real-life applications, mostly in the high\ndimensional low sample regime. In this paper, we propose a novel differential\nparameter estimator that, in comparison to current methods, simultaneously\nallows (a) the flexible integration of multiple sources of information (data\nsamples, variable groupings, extra pairwise evidence, etc.), (b) being scalable\nto a large number of variables, and (c) achieving a sharp asymptotic\nconvergence rate. Our experiments, on more than 100 simulated and two\nreal-world datasets, validate the flexibility of our approach and highlight the\nbenefits of integrating spatial and anatomic information for brain connectome\nchange discovery and epigenetic network identification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:01:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sekhon", "Arshdeep", ""], ["Wang", "Beilun", ""], ["Wang", "Zhe", ""], ["Qi", "Yanjun", ""]]}, {"id": "2004.11497", "submitter": "Thanh Vinh Vo", "authors": "Thanh Vinh Vo, Pengfei Wei, Wicher Bergsma, Tze-Yun Leong", "title": "Causal Modeling with Stochastic Confounders", "comments": "AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work extends causal inference with stochastic confounders. We propose a\nnew approach to variational estimation for causal inference based on a\nrepresenter theorem with a random input space. We estimate causal effects\ninvolving latent confounders that may be interdependent and time-varying from\nsequential, repeated measurements in an observational study. Our approach\nextends current work that assumes independent, non-temporal latent confounders,\nwith potentially biased estimators. We introduce a simple yet elegant algorithm\nwithout parametric specification on model components. Our method avoids the\nneed for expensive and careful parameterization in deploying complex models,\nsuch as deep neural networks, for causal inference in existing approaches. We\ndemonstrate the effectiveness of our approach on various benchmark temporal\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:34:44 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 00:43:40 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 11:46:47 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2021 05:53:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Vo", "Thanh Vinh", ""], ["Wei", "Pengfei", ""], ["Bergsma", "Wicher", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2004.11500", "submitter": "Jiahua Dong", "authors": "Jiahua Dong, Yang Cong, Gan Sun, Bineng Zhong, Xiaowei Xu", "title": "What Can Be Transferred: Unsupervised Domain Adaptation for Endoscopic\n  Lesions Segmentation", "comments": "This paper is accepted by IEEE Conference on Computer Vision and\n  Pattern Recognition 2020 (CVPR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation has attracted growing research attention on\nsemantic segmentation. However, 1) most existing models cannot be directly\napplied into lesions transfer of medical images, due to the diverse appearances\nof same lesion among different datasets; 2) equal attention has been paid into\nall semantic representations instead of neglecting irrelevant knowledge, which\nleads to negative transfer of untransferable knowledge. To address these\nchallenges, we develop a new unsupervised semantic transfer model including two\ncomplementary modules (i.e., T_D and T_F ) for endoscopic lesions segmentation,\nwhich can alternatively determine where and how to explore transferable\ndomain-invariant knowledge between labeled source lesions dataset (e.g.,\ngastroscope) and unlabeled target diseases dataset (e.g., enteroscopy).\nSpecifically, T_D focuses on where to translate transferable visual information\nof medical lesions via residual transferability-aware bottleneck, while\nneglecting untransferable visual characterizations. Furthermore, T_F highlights\nhow to augment transferable semantic features of various lesions and\nautomatically ignore untransferable representations, which explores\ndomain-invariant knowledge and in return improves the performance of T_D. To\nthe end, theoretical analysis and extensive experiments on medical endoscopic\ndataset and several non-medical public datasets well demonstrate the\nsuperiority of our proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:57:05 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Dong", "Jiahua", ""], ["Cong", "Yang", ""], ["Sun", "Gan", ""], ["Zhong", "Bineng", ""], ["Xu", "Xiaowei", ""]]}, {"id": "2004.11506", "submitter": "Tao Wang", "authors": "Tao Wang, Junsong Wang, Chang Xu and Chao Xue", "title": "Automatic low-bit hybrid quantization of neural networks through meta\n  learning", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model quantization is a widely used technique to compress and accelerate deep\nneural network (DNN) inference, especially when deploying to edge or IoT\ndevices with limited computation capacity and power consumption budget. The\nuniform bit width quantization across all the layers is usually sub-optimal and\nthe exploration of hybrid quantization for different layers is vital for\nefficient deep compression. In this paper, we employ the meta learning method\nto automatically realize low-bit hybrid quantization of neural networks. A\nMetaQuantNet, together with a Quantization function, are trained to generate\nthe quantized weights for the target DNN. Then, we apply a genetic algorithm to\nsearch the best hybrid quantization policy that meets compression constraints.\nWith the best searched quantization policy, we subsequently retrain or finetune\nto further improve the performance of the quantized target network. Extensive\nexperiments demonstrate the performance of searched hybrid quantization scheme\nsurpass that of uniform bitwidth counterpart. Compared to the existing\nreinforcement learning (RL) based hybrid quantization search approach that\nrelies on tedious explorations, our meta learning approach is more efficient\nand effective for any compression requirements since the MetaQuantNet only\nneeds be trained once.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:01:26 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wang", "Tao", ""], ["Wang", "Junsong", ""], ["Xu", "Chang", ""], ["Xue", "Chao", ""]]}, {"id": "2004.11511", "submitter": "Xiushan Nie", "authors": "Xingbo Liu, Xiushan Nie, Qi Dai, Yupan Huang, Yilong Yin", "title": "Reinforcing Short-Length Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the compelling efficiency in retrieval and storage,\nsimilarity-preserving hashing has been widely applied to approximate nearest\nneighbor search in large-scale image retrieval. However, existing methods have\npoor performance in retrieval using an extremely short-length hash code due to\nweak ability of classification and poor distribution of hash bit. To address\nthis issue, in this study, we propose a novel reinforcing short-length hashing\n(RSLH). In this proposed RSLH, mutual reconstruction between the hash\nrepresentation and semantic labels is performed to preserve the semantic\ninformation. Furthermore, to enhance the accuracy of hash representation, a\npairwise similarity matrix is designed to make a balance between accuracy and\ntraining expenditure on memory. In addition, a parameter boosting strategy is\nintegrated to reinforce the precision with hash bits fusion. Extensive\nexperiments on three large-scale image benchmarks demonstrate the superior\nperformance of RSLH under various short-length hashing scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:23:52 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Liu", "Xingbo", ""], ["Nie", "Xiushan", ""], ["Dai", "Qi", ""], ["Huang", "Yupan", ""], ["Yin", "Yilong", ""]]}, {"id": "2004.11514", "submitter": "Brian Hutchinson", "authors": "Loc Truong, Chace Jones, Brian Hutchinson, Andrew August, Brenda\n  Praggastis, Robert Jasper, Nicole Nichols, Aaron Tuor", "title": "Systematic Evaluation of Backdoor Data Poisoning Attacks on Image\n  Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor data poisoning attacks have recently been demonstrated in computer\nvision research as a potential safety risk for machine learning (ML) systems.\nTraditional data poisoning attacks manipulate training data to induce\nunreliability of an ML model, whereas backdoor data poisoning attacks maintain\nsystem performance unless the ML model is presented with an input containing an\nembedded \"trigger\" that provides a predetermined response advantageous to the\nadversary. Our work builds upon prior backdoor data-poisoning research for ML\nimage classifiers and systematically assesses different experimental conditions\nincluding types of trigger patterns, persistence of trigger patterns during\nretraining, poisoning strategies, architectures (ResNet-50, NasNet,\nNasNet-Mobile), datasets (Flowers, CIFAR-10), and potential defensive\nregularization techniques (Contrastive Loss, Logit Squeezing, Manifold Mixup,\nSoft-Nearest-Neighbors Loss). Experiments yield four key findings. First, the\nsuccess rate of backdoor poisoning attacks varies widely, depending on several\nfactors, including model architecture, trigger pattern and regularization\ntechnique. Second, we find that poisoned models are hard to detect through\nperformance inspection alone. Third, regularization typically reduces backdoor\nsuccess rate, although it can have no effect or even slightly increase it,\ndepending on the form of regularization. Finally, backdoors inserted through\ndata poisoning can be rendered ineffective after just a few epochs of\nadditional training on a small set of clean data without affecting the model's\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:58:22 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Truong", "Loc", ""], ["Jones", "Chace", ""], ["Hutchinson", "Brian", ""], ["August", "Andrew", ""], ["Praggastis", "Brenda", ""], ["Jasper", "Robert", ""], ["Nichols", "Nicole", ""], ["Tuor", "Aaron", ""]]}, {"id": "2004.11515", "submitter": "Konstantin Pieper", "authors": "Konstantin Pieper and Armenak Petrosyan", "title": "Nonconvex penalization for sparse neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training methods for artificial neural networks often rely on\nover-parameterization and random initialization in order to avoid spurious\nlocal minima of the loss function that fail to fit the data properly. To\nsidestep this, one can employ convex neural networks, which combine a convex\ninterpretation of the loss term, sparsity promoting penalization of the outer\nweights, and greedy neuron insertion. However, the canonical $\\ell_1$ penalty\ndoes not achieve a sufficient reduction in the number of nodes in a shallow\nnetwork in the presence of large amounts of data, as observed in practice and\nsupported by our theory. As a remedy, we propose a nonconvex penalization\nmethod for the outer weights that maintains the advantages of the convex\napproach. We investigate the analytic aspects of the method in the context of\nneural network integral representations and prove attainability of minimizers,\ntogether with a finite support property and approximation guarantees.\nAdditionally, we describe how to numerically solve the minimization problem\nwith an adaptive algorithm combining local gradient based training, and\nadaptive node insertion and extraction.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 03:03:21 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Pieper", "Konstantin", ""], ["Petrosyan", "Armenak", ""]]}, {"id": "2004.11516", "submitter": "Bozhi Wu", "authors": "Bozhi Wu, Sen Chen, Cuiyun Gao, Lingling Fan, Yang Liu, Weiping Wen,\n  Michael R. Lyu", "title": "Why an Android App is Classified as Malware? Towards Malware\n  Classification Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) based approach is considered as one of the most\npromising techniques for Android malware detection and has achieved high\naccuracy by leveraging commonly-used features. In practice, most of the ML\nclassifications only provide a binary label to mobile users and app security\nanalysts. However, stakeholders are more interested in the reason why apps are\nclassified as malicious in both academia and industry. This belongs to the\nresearch area of interpretable ML but in a specific research domain (i.e.,\nmobile malware detection). Although several interpretable ML methods have been\nexhibited to explain the final classification results in many cutting-edge\nArtificial Intelligent (AI) based research fields, till now, there is no study\ninterpreting why an app is classified as malware or unveiling the\ndomain-specific challenges.\n  In this paper, to fill this gap, we propose a novel and interpretable\nML-based approach (named XMal) to classify malware with high accuracy and\nexplain the classification result meanwhile. (1) The first classification phase\nof XMal hinges multi-layer perceptron (MLP) and attention mechanism, and also\npinpoints the key features most related to the classification result. (2) The\nsecond interpreting phase aims at automatically producing neural language\ndescriptions to interpret the core malicious behaviors within apps. We evaluate\nthe behavior description results by comparing with the existing interpretable\nML-based methods (i.e., Drebin and LIME) to demonstrate the effectiveness of\nXMal. We find that XMal is able to reveal the malicious behaviors more\naccurately. Additionally, our experiments show that XMal can also interpret the\nreason why some samples are misclassified by ML classifiers. Our study peeks\ninto the interpretable ML through the research of Android malware detection and\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 03:05:09 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 13:27:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Wu", "Bozhi", ""], ["Chen", "Sen", ""], ["Gao", "Cuiyun", ""], ["Fan", "Lingling", ""], ["Liu", "Yang", ""], ["Wen", "Weiping", ""], ["Lyu", "Michael R.", ""]]}, {"id": "2004.11530", "submitter": "Joyce Whang", "authors": "Joyce Jiyoung Whang and Inderjit S. Dhillon", "title": "Non-Exhaustive, Overlapping Co-Clustering: An Extended Analysis", "comments": null, "journal-ref": "\"Non-Exhaustive, Overlapping Co-Clustering\", Proceedings of the\n  26th ACM Conference on Information and Knowledge Management (CIKM), pages\n  2367-2370, November 2017", "doi": "10.1145/3132847.3133078", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of co-clustering is to simultaneously identify a clustering of rows\nas well as columns of a two dimensional data matrix. A number of co-clustering\ntechniques have been proposed including information-theoretic co-clustering and\nthe minimum sum-squared residue co-clustering method. However, most existing\nco-clustering algorithms are designed to find pairwise disjoint and exhaustive\nco-clusters while many real-world datasets contain not only a large overlap\nbetween co-clusters but also outliers which should not belong to any\nco-cluster. In this paper, we formulate the problem of Non-Exhaustive,\nOverlapping Co-Clustering where both of the row and column clusters are allowed\nto overlap with each other and outliers for each dimension of the data matrix\nare not assigned to any cluster. To solve this problem, we propose intuitive\nobjective functions, and develop an an efficient iterative algorithm which we\ncall the NEO-CC algorithm. We theoretically show that the NEO-CC algorithm\nmonotonically decreases the proposed objective functions. Experimental results\nshow that the NEO-CC algorithm is able to effectively capture the underlying\nco-clustering structure of real-world data, and thus outperforms\nstate-of-the-art clustering and co-clustering methods. This manuscript includes\nan extended analysis of [21].\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 04:39:14 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Whang", "Joyce Jiyoung", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "2004.11532", "submitter": "Carlos Fern\\'andez-Lor\\'ia", "authors": "Carlos Fern\\'andez-Lor\\'ia, Foster Provost, Jesse Anderton, Benjamin\n  Carterette, Praveen Chandar", "title": "A Comparison of Methods for Treatment Assignment with an Application to\n  Playlist Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a systematic comparison of methods for individual\ntreatment assignment, a general problem that arises in many applications and\nhas received significant attention from economists, computer scientists, and\nsocial scientists. We characterize the various methods proposed in the\nliterature into three general approaches: learning models to predict outcomes,\nlearning models to predict causal effects, and learning models to predict\noptimal treatment assignments. We show analytically that optimizing for outcome\nor causal effect prediction is not the same as optimizing for treatment\nassignments, and thus we should prefer learning models that optimize for\ntreatment assignments. We then compare and contrast the three approaches\nempirically in the context of choosing, for each user, the best algorithm for\nplaylist generation in order to optimize engagement. This is the first\ncomparison of the different treatment assignment approaches on a real-world\napplication at scale (based on more than half a billion individual treatment\nassignments). Our results show (i) that applying different algorithms to\ndifferent users can improve streams substantially compared to deploying the\nsame algorithm for everyone, (ii) that personalized assignments improve\nsubstantially with larger data sets, and (iii) that learning models by\noptimizing for treatment assignment can increase engagement by 28% more than\nwhen optimizing for outcome or causal effect predictions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 04:56:15 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 03:27:10 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 14:33:52 GMT"}, {"version": "v4", "created": "Fri, 23 Apr 2021 17:51:45 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Fern\u00e1ndez-Lor\u00eda", "Carlos", ""], ["Provost", "Foster", ""], ["Anderton", "Jesse", ""], ["Carterette", "Benjamin", ""], ["Chandar", "Praveen", ""]]}, {"id": "2004.11540", "submitter": "Christopher Choy", "authors": "Christopher Choy, Wei Dong, Vladlen Koltun", "title": "Deep Global Registration", "comments": "Accepted for CVPR'20 oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CG cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Deep Global Registration, a differentiable framework for pairwise\nregistration of real-world 3D scans. Deep global registration is based on three\nmodules: a 6-dimensional convolutional network for correspondence confidence\nprediction, a differentiable Weighted Procrustes algorithm for closed-form pose\nestimation, and a robust gradient-based SE(3) optimizer for pose refinement.\nExperiments demonstrate that our approach outperforms state-of-the-art methods,\nboth learning-based and classical, on real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 05:47:32 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 08:59:52 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choy", "Christopher", ""], ["Dong", "Wei", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2004.11545", "submitter": "Seyed Iman Mirzadeh", "authors": "Seyed-Iman Mirzadeh, Mehrdad Farajtabar, Hassan Ghasemzadeh", "title": "Dropout as an Implicit Gating Mechanism For Continual Learning", "comments": "CVPR 2020 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have demonstrated an outstanding ability to\nachieve complex learning tasks across various domains. However, they suffer\nfrom the \"catastrophic forgetting\" problem when they face a sequence of\nlearning tasks, where they forget the old ones as they learn new tasks. This\nproblem is also highly related to the \"stability-plasticity dilemma\". The more\nplastic the network, the easier it can learn new tasks, but the faster it also\nforgets previous ones. Conversely, a stable network cannot learn new tasks as\nfast as a very plastic network. However, it is more reliable to preserve the\nknowledge it has learned from the previous tasks. Several solutions have been\nproposed to overcome the forgetting problem by making the neural network\nparameters more stable, and some of them have mentioned the significance of\ndropout in continual learning. However, their relationship has not been\nsufficiently studied yet. In this paper, we investigate this relationship and\nshow that a stable network with dropout learns a gating mechanism such that for\ndifferent tasks, different paths of the network are active. Our experiments\nshow that the stability achieved by this implicit gating plays a very critical\nrole in leading to performance comparable to or better than other involved\ncontinual learning algorithms to overcome catastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 06:04:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mirzadeh", "Seyed-Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2004.11573", "submitter": "Xiyue Zhang", "authors": "Xiyue Zhang, Xiaofei Xie, Lei Ma, Xiaoning Du, Qiang Hu, Yang Liu,\n  Jianjun Zhao, Meng Sun", "title": "Towards Characterizing Adversarial Defects of Deep Learning Software\n  from the Lens of Uncertainty", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, deep learning (DL) has been successfully applied to\nmany industrial domain-specific tasks. However, the current state-of-the-art DL\nsoftware still suffers from quality issues, which raises great concern\nespecially in the context of safety- and security-critical scenarios.\nAdversarial examples (AEs) represent a typical and important type of defects\nneeded to be urgently addressed, on which a DL software makes incorrect\ndecisions. Such defects occur through either intentional attack or\nphysical-world noise perceived by input sensors, potentially hindering further\nindustry deployment. The intrinsic uncertainty nature of deep learning\ndecisions can be a fundamental reason for its incorrect behavior. Although some\ntesting, adversarial attack and defense techniques have been recently proposed,\nit still lacks a systematic study to uncover the relationship between AEs and\nDL uncertainty. In this paper, we conduct a large-scale study towards bridging\nthis gap. We first investigate the capability of multiple uncertainty metrics\nin differentiating benign examples (BEs) and AEs, which enables to characterize\nthe uncertainty patterns of input data. Then, we identify and categorize the\nuncertainty patterns of BEs and AEs, and find that while BEs and AEs generated\nby existing methods do follow common uncertainty patterns, some other\nuncertainty patterns are largely missed. Based on this, we propose an automated\ntesting technique to generate multiple types of uncommon AEs and BEs that are\nlargely missed by existing techniques. Our further evaluation reveals that the\nuncommon data generated by our method is hard to be defended by the existing\ndefense techniques with the average defense success rate reduced by 35\\%. Our\nresults call for attention and necessity to generate more diverse data for\nevaluating quality assurance solutions of DL software.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 07:29:47 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Zhang", "Xiyue", ""], ["Xie", "Xiaofei", ""], ["Ma", "Lei", ""], ["Du", "Xiaoning", ""], ["Hu", "Qiang", ""], ["Liu", "Yang", ""], ["Zhao", "Jianjun", ""], ["Sun", "Meng", ""]]}, {"id": "2004.11587", "submitter": "Anjin Liu", "authors": "Anjin Liu, Jie Lu, Guangquan Zhang", "title": "Concept Drift Detection via Equal Intensity k-means Space Partitioning", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, vol. Early Access, pp. 1-C14,\n  2020", "doi": "10.1109/TCYB.2020.2983962", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream poses additional challenges to statistical classification tasks\nbecause distributions of the training and target samples may differ as time\npasses. Such distribution change in streaming data is called concept drift.\nNumerous histogram-based distribution change detection methods have been\nproposed to detect drift. Most histograms are developed on grid-based or\ntree-based space partitioning algorithms which makes the space partitions\narbitrary, unexplainable, and may cause drift blind-spots. There is a need to\nimprove the drift detection accuracy for histogram-based methods with the\nunsupervised setting. To address this problem, we propose a cluster-based\nhistogram, called equal intensity k-means space partitioning (EI-kMeans). In\naddition, a heuristic method to improve the sensitivity of drift detection is\nintroduced. The fundamental idea of improving the sensitivity is to minimize\nthe risk of creating partitions in distribution offset regions. Pearson's\nchi-square test is used as the statistical hypothesis test so that the test\nstatistics remain independent of the sample distribution. The number of bins\nand their shapes, which strongly influence the ability to detect drift, are\ndetermined dynamically from the sample based on an asymptotic constraint in the\nchi-square test. Accordingly, three algorithms are developed to implement\nconcept drift detection, including a greedy centroids initialization algorithm,\na cluster amplify-shrink algorithm, and a drift detection algorithm. For drift\nadaptation, we recommend retraining the learner if a drift is detected. The\nresults of experiments on synthetic and real-world datasets demonstrate the\nadvantages of EI-kMeans and show its efficacy in detecting concept drift.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 08:00:16 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Anjin", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2004.11604", "submitter": "Giovanni Quattrone", "authors": "Giovanni Quattrone, Antonino Nocera, Licia Capra, Daniele Quercia", "title": "Social Interactions or Business Transactions? What customer reviews\n  disclose about Airbnb marketplace", "comments": "17 pages, 8 figures, Proceedings of The Web Conference 2020", "journal-ref": null, "doi": "10.1145/3366423.3380225", "report-no": null, "categories": "cs.CY cs.CL cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airbnb is one of the most successful examples of sharing economy\nmarketplaces. With rapid and global market penetration, understanding its\nattractiveness and evolving growth opportunities is key to plan business\ndecision making. There is an ongoing debate, for example, about whether Airbnb\nis a hospitality service that fosters social exchanges between hosts and\nguests, as the sharing economy manifesto originally stated, or whether it is\n(or is evolving into being) a purely business transaction platform, the way\nhotels have traditionally operated. To answer these questions, we propose a\nnovel market analysis approach that exploits customers' reviews. Key to the\napproach is a method that combines thematic analysis and machine learning to\ninductively develop a custom dictionary for guests' reviews. Based on this\ndictionary, we then use quantitative linguistic analysis on a corpus of 3.2\nmillion reviews collected in 6 different cities, and illustrate how to answer a\nvariety of market research questions, at fine levels of temporal, thematic,\nuser and spatial granularity, such as (i) how the business vs social dichotomy\nis evolving over the years, (ii) what exact words within such top-level\ncategories are evolving, (iii) whether such trends vary across different user\nsegments and (iv) in different neighbourhoods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 09:08:46 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Quattrone", "Giovanni", ""], ["Nocera", "Antonino", ""], ["Capra", "Licia", ""], ["Quercia", "Daniele", ""]]}, {"id": "2004.11627", "submitter": "Zhongzhan Huang", "authors": "Zhongzhan Huang, Wenqi Shao, Xinjiang Wang, Ping Luo", "title": "Convolution-Weight-Distribution Assumption: Rethinking the Criteria of\n  Channel Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel pruning is a popular technique for compressing convolutional neural\nnetworks (CNNs), where various pruning criteria have been proposed to remove\nthe redundant filters. From our comprehensive experiments, we found two blind\nspots in the study of pruning criteria: (1) Similarity: There are some strong\nsimilarities among several primary pruning criteria that are widely cited and\ncompared. According to these criteria, the ranks of filters'Importance Score\nare almost identical, resulting in similar pruned structures. (2)\nApplicability: The filters'Importance Score measured by some pruning criteria\nare too close to distinguish the network redundancy well. In this paper, we\nanalyze these two blind spots on different types of pruning criteria with\nlayer-wise pruning or global pruning. The analyses are based on the empirical\nexperiments and our assumption (Convolutional Weight Distribution Assumption)\nthat the well-trained convolutional filters each layer approximately follow a\nGaussian-alike distribution. This assumption has been verified through\nsystematic and extensive statistical tests.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 09:54:21 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 06:36:14 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Huang", "Zhongzhan", ""], ["Shao", "Wenqi", ""], ["Wang", "Xinjiang", ""], ["Luo", "Ping", ""]]}, {"id": "2004.11637", "submitter": "Ahmet M. Elbir", "authors": "Ahmet M. Elbir and Kumar Vijay Mishra", "title": "Sparse Array Selection Across Arbitrary Sensor Geometries with Deep\n  Transfer Learning", "comments": "Accepted paper in IEEE Transactions on Cognitive Communications and\n  Networking", "journal-ref": null, "doi": "10.1109/TCCN.2020.2999811", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse sensor array selection arises in many engineering applications, where\nit is imperative to obtain maximum spatial resolution from a limited number of\narray elements. Recent research shows that computational complexity of array\nselection is reduced by replacing the conventional optimization and greedy\nsearch methods with a deep learning network. However, in practice, sufficient\nand well-calibrated labeled training data are unavailable and, more so, for\narbitrary array configurations. To address this, we adopt a deep transfer\nlearning (TL) approach, wherein we train a deep convolutional neural network\n(CNN) with data of a source sensor array for which calibrated data are readily\navailable and reuse this pre-trained CNN for a different, data-insufficient\ntarget array geometry to perform sparse array selection. Numerical experiments\nwith uniform rectangular and circular arrays demonstrate enhanced performance\nof TL-CNN on the target model than the CNN trained with insufficient data from\nthe same model. In particular, our TL framework provides approximately 20%\nhigher sensor selection accuracy and 10% improvement in the\ndirection-of-arrival estimation error.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 10:10:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 07:40:35 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Elbir", "Ahmet M.", ""], ["Mishra", "Kumar Vijay", ""]]}, {"id": "2004.11642", "submitter": "Anindya De", "authors": "Anindya De, Elchanan Mossel and Joe Neeman", "title": "Robust testing of low-dimensional functions", "comments": "We significantly strengthen the results of the previous version. This\n  includes the first fully noise tolerant testers for linear juntas as well as\n  subclasses such as any function of constantly many halfspaces", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural problem in high-dimensional inference is to decide if a classifier\n$f:\\mathbb{R}^n \\rightarrow \\{-1,1\\}$ depends on a small number of linear\ndirections of its input data. Call a function $g: \\mathbb{R}^n \\rightarrow\n\\{-1,1\\}$, a linear $k$-junta if it is completely determined by some\n$k$-dimensional subspace of the input space. A recent work of the authors\nshowed that linear $k$-juntas are testable. Thus there exists an algorithm to\ndistinguish between: 1. $f: \\mathbb{R}^n \\rightarrow \\{-1,1\\}$ which is a\nlinear $k$-junta with surface area $s$, 2. $f$ is $\\epsilon$-far from any\nlinear $k$-junta with surface area $(1+\\epsilon)s$, where the query complexity\nof the algorithm is independent of the ambient dimension $n$.\n  Following the surge of interest in noise-tolerant property testing, in this\npaper we prove a noise-tolerant (or robust) version of this result. Namely, we\ngive an algorithm which given any $c>0$, $\\epsilon>0$, distinguishes between 1.\n$f: \\mathbb{R}^n \\rightarrow \\{-1,1\\}$ has correlation at least $c$ with some\nlinear $k$-junta with surface area $s$. 2. $f$ has correlation at most\n$c-\\epsilon$ with any linear $k$-junta with surface area at most $s$. The query\ncomplexity of our tester is $k^{\\mathsf{poly}(s/\\epsilon)}$.\n  Using our techniques, we also obtain a fully noise tolerant tester with the\nsame query complexity for any class $\\mathcal{C}$ of linear $k$-juntas with\nsurface area bounded by $s$. As a consequence, we obtain a fully noise tolerant\ntester with query complexity $k^{O(\\mathsf{poly}(\\log k/\\epsilon))}$ for the\nclass of intersection of $k$-halfspaces (for constant $k$) over the Gaussian\nspace. Our query complexity is independent of the ambient dimension $n$.\nPreviously, no non-trivial noise tolerant testers were known even for a single\nhalfspace.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 10:23:12 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 22:59:17 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["De", "Anindya", ""], ["Mossel", "Elchanan", ""], ["Neeman", "Joe", ""]]}, {"id": "2004.11648", "submitter": "Cheng-Te Li", "authors": "Yi-Ju Lu and Cheng-Te Li", "title": "GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media", "comments": "To appear in Proceedings of The 58th Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020. Code is available here\n  https://github.com/l852888/GCAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 10:42:49 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Lu", "Yi-Ju", ""], ["Li", "Cheng-Te", ""]]}, {"id": "2004.11667", "submitter": "Guillaume Matheron", "authors": "Guillaume Matheron, Nicolas Perrin, Olivier Sigaud", "title": "PBCS : Efficient Exploration and Exploitation Using a Synergy between\n  Reinforcement Learning and Motion Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration-exploitation trade-off is at the heart of reinforcement\nlearning (RL). However, most continuous control benchmarks used in recent RL\nresearch only require local exploration. This led to the development of\nalgorithms that have basic exploration capabilities, and behave poorly in\nbenchmarks that require more versatile exploration. For instance, as\ndemonstrated in our empirical study, state-of-the-art RL algorithms such as\nDDPG and TD3 are unable to steer a point mass in even small 2D mazes. In this\npaper, we propose a new algorithm called \"Plan, Backplay, Chain Skills\" (PBCS)\nthat combines motion planning and reinforcement learning to solve hard\nexploration environments. In a first phase, a motion planning algorithm is used\nto find a single good trajectory, then an RL algorithm is trained using a\ncurriculum derived from the trajectory, by combining a variant of the Backplay\nalgorithm and skill chaining. We show that this method outperforms\nstate-of-the-art RL algorithms in 2D maze environments of various sizes, and is\nable to improve on the trajectory obtained by the motion planning phase.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 11:37:09 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Matheron", "Guillaume", ""], ["Perrin", "Nicolas", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2004.11675", "submitter": "Ying Da Wang", "authors": "Ying Da Wang, Traiwit Chung, Ryan T. Armstrong, and Peyman Mostaghimi", "title": "ML-LBM: Machine Learning Aided Flow Simulation in Porous Media", "comments": "23 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation of fluid flow in porous media has many applications, from the\nmicro-scale (cell membranes, filters, rocks) to macro-scale (groundwater,\nhydrocarbon reservoirs, and geothermal) and beyond. Direct simulation of flow\nin porous media requires significant computational resources to solve within\nreasonable timeframes. An integrated method combining predictions of fluid flow\n(fast, limited accuracy) with direct flow simulation (slow, high accuracy) is\noutlined. In the tortuous flow paths of porous media, Deep Learning techniques\nbased on Convolutional Neural Networks (CNNs) are shown to give an accurate\nestimate of the steady state velocity fields (in all axes), and by extension,\nthe macro-scale permeability. This estimate can be used as-is, or as initial\nconditions in direct simulation to reach a fully accurate result in a fraction\nof the compute time. A Gated U-Net Convolutional Neural Network is trained on a\ndatasets of 2D and 3D porous media generated by correlated fields, with their\nsteady state velocity fields calculated from direct LBM simulation. Sensitivity\nanalysis indicates that network accuracy is dependent on (1) the tortuosity of\nthe domain, (2) the size of convolution filters, (3) the use of distance maps\nas input, (4) the use of mass conservation loss functions. Permeability\nestimation from these predicted fields reaches over 90\\% accuracy for 80\\% of\ncases. It is further shown that these velocity fields are error prone when used\nfor solute transport simulation. Using the predicted velocity fields as initial\nconditions is shown to accelerate direct flow simulation to physically true\nsteady state conditions an order of magnitude less compute time. Using Deep\nLearning predictions (or potentially any other approximation method) to\naccelerate flow simulation to steady state in complex pore structures shows\npromise as a technique push the boundaries fluid flow modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 01:55:59 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Da Wang", "Ying", ""], ["Chung", "Traiwit", ""], ["Armstrong", "Ryan T.", ""], ["Mostaghimi", "Peyman", ""]]}, {"id": "2004.11676", "submitter": "Narinder Punn", "authors": "Narinder Singh Punn and Sonali Agarwal", "title": "Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray\n  images using fine-tuned deep neural networks", "comments": null, "journal-ref": "Appl Intell (2020)", "doi": "10.1007/s10489-020-01900-3", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The novel coronavirus 2019 (COVID-19) is a respiratory syndrome that\nresembles pneumonia. The current diagnostic procedure of COVID-19 follows\nreverse-transcriptase polymerase chain reaction (RT-PCR) based approach which\nhowever is less sensitive to identify the virus at the initial stage. Hence, a\nmore robust and alternate diagnosis technique is desirable. Recently, with the\nrelease of publicly available datasets of corona positive patients comprising\nof computed tomography (CT) and chest X-ray (CXR) imaging; scientists,\nresearchers and healthcare experts are contributing for faster and automated\ndiagnosis of COVID-19 by identifying pulmonary infections using deep learning\napproaches to achieve better cure and treatment. These datasets have limited\nsamples concerned with the positive COVID-19 cases, which raise the challenge\nfor unbiased learning. Following from this context, this article presents the\nrandom oversampling and weighted class loss function approach for unbiased\nfine-tuned learning (transfer learning) in various state-of-the-art deep\nlearning approaches such as baseline ResNet, Inception-v3, Inception ResNet-v2,\nDenseNet169, and NASNetLarge to perform binary classification (as normal and\nCOVID-19 cases) and also multi-class classification (as COVID-19, pneumonia,\nand normal case) of posteroanterior CXR images. Accuracy, precision, recall,\nloss, and area under the curve (AUC) are utilized to evaluate the performance\nof the models. Considering the experimental results, the performance of each\nmodel is scenario dependent; however, NASNetLarge displayed better scores in\ncontrast to other architectures, which is further compared with other recently\nproposed approaches. This article also added the visual explanation to\nillustrate the basis of model classification and perception of COVID-19 in CXR\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 10:24:34 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 04:15:59 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 14:56:37 GMT"}, {"version": "v4", "created": "Thu, 18 Jun 2020 08:44:20 GMT"}, {"version": "v5", "created": "Tue, 21 Jul 2020 10:27:36 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Punn", "Narinder Singh", ""], ["Agarwal", "Sonali", ""]]}, {"id": "2004.11685", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Yann Chevaleyre, Jeremy Rapin, Cl\\'ement W. Royer,\n  Olivier Teytaud", "title": "On averaging the best samples in evolutionary computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing the right selection rate is a long standing issue in evolutionary\ncomputation. In the continuous unconstrained case, we prove mathematically that\na single parent $\\mu=1$ leads to a sub-optimal simple regret in the case of the\nsphere function. We provide a theoretically-based selection rate $\\mu/\\lambda$\nthat leads to better progress rates. With our choice of selection rate, we get\na provable regret of order $O(\\lambda^{-1})$ which has to be compared with\n$O(\\lambda^{-2/d})$ in the case where $\\mu=1$. We complete our study with\nexperiments to confirm our theoretical claims.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:25:39 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 13:22:44 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 18:32:33 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Meunier", "Laurent", ""], ["Chevaleyre", "Yann", ""], ["Rapin", "Jeremy", ""], ["Royer", "Cl\u00e9ment W.", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2004.11687", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Carola Doerr, Jeremy Rapin, Olivier Teytaud", "title": "Variance Reduction for Better Sampling in Continuous Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of experiments, random search, initialization of population-based\nmethods, or sampling inside an epoch of an evolutionary algorithm use a sample\ndrawn according to some probability distribution for approximating the location\nof an optimum. Recent papers have shown that the optimal search distribution,\nused for the sampling, might be more peaked around the center of the\ndistribution than the prior distribution modelling our uncertainty about the\nlocation of the optimum. We confirm this statement, provide explicit values for\nthis reshaping of the search distribution depending on the population size\n$\\lambda$ and the dimension $d$, and validate our results experimentally.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:25:48 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Meunier", "Laurent", ""], ["Doerr", "Carola", ""], ["Rapin", "Jeremy", ""], ["Teytaud", "Olivier", ""]]}, {"id": "2004.11690", "submitter": "Xiaying Wang", "authors": "Tibor Schneider, Xiaying Wang, Michael Hersche, Lukas Cavigelli, Luca\n  Benini", "title": "Q-EEGNet: an Energy-Efficient 8-bit Quantized Parallel EEGNet\n  Implementation for Edge Motor-Imagery Brain--Machine Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor-Imagery Brain--Machine Interfaces (MI-BMIs)promise direct and\naccessible communication between human brains and machines by analyzing brain\nactivities recorded with Electroencephalography (EEG). Latency, reliability,\nand privacy constraints make it unsuitable to offload the computation to the\ncloud. Practical use cases demand a wearable, battery-operated device with low\naverage power consumption for long-term use. Recently, sophisticated\nalgorithms, in particular deep learning models, have emerged for classifying\nEEG signals. While reaching outstanding accuracy, these models often exceed the\nlimitations of edge devices due to their memory and computational requirements.\nIn this paper, we demonstrate algorithmic and implementation optimizations for\nEEGNET, a compact Convolutional Neural Network (CNN) suitable for many BMI\nparadigms. We quantize weights and activations to 8-bit fixed-point with a\nnegligible accuracy loss of 0.4% on 4-class MI, and present an energy-efficient\nhardware-aware implementation on the Mr.Wolf parallel ultra-low power (PULP)\nSystem-on-Chip (SoC) by utilizing its custom RISC-V ISA extensions and 8-core\ncompute cluster. With our proposed optimization steps, we can obtain an overall\nspeedup of 64x and a reduction of up to 85% in memory footprint with respect to\na single-core layer-wise baseline implementation. Our implementation takes only\n5.82 ms and consumes 0.627 mJ per inference. With 21.0GMAC/s/W, it is 256x more\nenergy-efficient than an EEGNET implementation on an ARM Cortex-M7\n(0.082GMAC/s/W).\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:29:03 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 11:11:03 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Schneider", "Tibor", ""], ["Wang", "Xiaying", ""], ["Hersche", "Michael", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "2004.11691", "submitter": "Peter Wakeford", "authors": "Peter Robert Wakeford, Enrico Pellegrini, Gavin Robertson, Michael\n  Verhoek, Alan Duncan Fleming, Jano van Hemert and Ik Siong Heng", "title": "Optic disc and fovea localisation in ultra-widefield scanning laser\n  ophthalmoscope images captured in multiple modalities", "comments": "Submitted to the 23rd Conference on Medical Image Understanding and\n  Analysis (MIUA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a convolutional neural network for localising the centres of the\noptic disc (OD) and fovea in ultra-wide field of view scanning laser\nophthalmoscope (UWFoV-SLO) images of the retina. Images captured in both\nreflectance and autofluorescence (AF) modes, and central pole and eyesteered\ngazes, were used. The method achieved an OD localisation accuracy of 99.4%\nwithin one OD radius, and fovea localisation accuracy of 99.1% within one OD\nradius on a test set comprising of 1790 images. The performance of fovea\nlocalisation in AF images was comparable to the variation between human\nannotators at this task. The laterality of the image (whether the image is of\nthe left or right eye) was inferred from the OD and fovea coordinates with an\naccuracy of 99.9%\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:29:10 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Wakeford", "Peter Robert", ""], ["Pellegrini", "Enrico", ""], ["Robertson", "Gavin", ""], ["Verhoek", "Michael", ""], ["Fleming", "Alan Duncan", ""], ["van Hemert", "Jano", ""], ["Heng", "Ik Siong", ""]]}, {"id": "2004.11693", "submitter": "Arunava Chakravarty", "authors": "Arka Mitra, Arunava Chakravarty, Nirmalya Ghosh, Tandra Sarkar,\n  Ramanathan Sethuraman, Debdoot Sheet", "title": "A Systematic Search over Deep Convolutional Neural Network Architectures\n  for Screening Chest Radiographs", "comments": "accepted in EMBC 2020, 4 pages+2 page Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiographs are primarily employed for the screening of pulmonary and\ncardio-/thoracic conditions. Being undertaken at primary healthcare centers,\nthey require the presence of an on-premise reporting Radiologist, which is a\nchallenge in low and middle income countries. This has inspired the development\nof machine learning based automation of the screening process. While recent\nefforts demonstrate a performance benchmark using an ensemble of deep\nconvolutional neural networks (CNN), our systematic search over multiple\nstandard CNN architectures identified single candidate CNN models whose\nclassification performances were found to be at par with ensembles. Over 63\nexperiments spanning 400 hours, executed on a 11:3 FP32 TensorTFLOPS compute\nsystem, we found the Xception and ResNet-18 architectures to be consistent\nperformers in identifying co-existing disease conditions with an average AUC of\n0.87 across nine pathologies. We conclude on the reliability of the models by\nassessing their saliency maps generated using the randomized input sampling for\nexplanation (RISE) method and qualitatively validating them against manual\nannotations locally sourced from an experienced Radiologist. We also draw a\ncritical note on the limitations of the publicly available CheXpert dataset\nprimarily on account of disparity in class distribution in training vs. testing\nsets, and unavailability of sufficient samples for few classes, which hampers\nquantitative reporting due to sample insufficiency.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:30:40 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Mitra", "Arka", ""], ["Chakravarty", "Arunava", ""], ["Ghosh", "Nirmalya", ""], ["Sarkar", "Tandra", ""], ["Sethuraman", "Ramanathan", ""], ["Sheet", "Debdoot", ""]]}, {"id": "2004.11694", "submitter": "Navedanjum Ansari Mr", "authors": "Navedanjum Ansari, Rajesh Sharma", "title": "Identifying Semantically Duplicate Questions Using Data Science\n  Approach: A Quora Case Study", "comments": "11 pages, 8 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying semantically identical questions on, Question and Answering\nsocial media platforms like Quora is exceptionally significant to ensure that\nthe quality and the quantity of content are presented to users, based on the\nintent of the question and thus enriching overall user experience. Detecting\nduplicate questions is a challenging problem because natural language is very\nexpressive, and a unique intent can be conveyed using different words, phrases,\nand sentence structuring. Machine learning and deep learning methods are known\nto have accomplished superior results over traditional natural language\nprocessing techniques in identifying similar texts. In this paper, taking Quora\nfor our case study, we explored and applied different machine learning and deep\nlearning techniques on the task of identifying duplicate questions on Quora's\ndataset. By using feature engineering, feature importance techniques, and\nexperimenting with seven selected machine learning classifiers, we demonstrated\nthat our models outperformed previous studies on this task. Xgboost model with\ncharacter level term frequency and inverse term frequency is our best machine\nlearning model that has also outperformed a few of the Deep learning baseline\nmodels. We applied deep learning techniques to model four different deep neural\nnetworks of multiple layers consisting of Glove embeddings, Long Short Term\nMemory, Convolution, Max pooling, Dense, Batch Normalization, Activation\nfunctions, and model merge. Our deep learning models achieved better accuracy\nthan machine learning models. Three out of four proposed architectures\noutperformed the accuracy from previous machine learning and deep learning\nresearch work, two out of four models outperformed accuracy from previous deep\nlearning study on Quora's question pair dataset, and our best model achieved\naccuracy of 85.82% which is close to Quora state of the art accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 19:39:58 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ansari", "Navedanjum", ""], ["Sharma", "Rajesh", ""]]}, {"id": "2004.11697", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab and Jaydip Sen", "title": "A Time Series Analysis-Based Stock Price Prediction Using Machine\n  Learning and Deep Learning Models", "comments": "This is the preprint of our paper accepted for publication in the\n  Inderscience Journal International Journal of Business Forecasting and\n  Marketing Intelligence. The paper consists of 53 pages, 26 Tables, and 46\n  Figures", "journal-ref": "International Journal of Business Forecasting and Marketing\n  Intelligence (IJBFMI), Vol 6, No 4, pp. 272 - 335, 2020. Inderscience\n  Publishers", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future movement of stock prices has always been a challenging\ntask for the researchers. While the advocates of the efficient market\nhypothesis (EMH) believe that it is impossible to design any predictive\nframework that can accurately predict the movement of stock prices, there are\nseminal work in the literature that have clearly demonstrated that the\nseemingly random movement patterns in the time series of a stock price can be\npredicted with a high level of accuracy. Design of such predictive models\nrequires choice of appropriate variables, right transformation methods of the\nvariables, and tuning of the parameters of the models. In this work, we present\na very robust and accurate framework of stock price prediction that consists of\nan agglomeration of statistical, machine learning and deep learning models. We\nuse the daily stock price data, collected at five minutes interval of time, of\na very well known company that is listed in the National Stock Exchange (NSE)\nof India. The granular data is aggregated into three slots in a day, and the\naggregated data is used for building and training the forecasting models. We\ncontend that the agglomerative approach of model building that uses a\ncombination of statistical, machine learning, and deep learning approaches, can\nvery effectively learn from the volatile and random movement patterns in a\nstock price data. We build eight classification and eight regression models\nbased on statistical and machine learning approaches. In addition to these\nmodels, a deep learning regression model using a long-and-short-term memory\n(LSTM) network is also built. Extensive results have been presented on the\nperformance of these models, and the results are critically analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:41:22 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:46:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}, {"id": "2004.11706", "submitter": "Sanjay Kumar Sonbhadra Mr.", "authors": "Sanjay Kumar Sonbhadra, Sonali Agarwal and P. Nagabhushan", "title": "Target specific mining of COVID-19 scholarly articles using one-class\n  approach", "comments": null, "journal-ref": "Chaos, Solitons and Fractals, 2020", "doi": "10.1016/j.chaos.2020.110155", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, several research articles have been published in the field\nof corona-virus caused diseases like severe acute respiratory syndrome (SARS),\nmiddle east respiratory syndrome (MERS) and COVID-19. In the presence of\nnumerous research articles, extracting best-suited articles is time-consuming\nand manually impractical. The objective of this paper is to extract the\nactivity and trends of corona-virus related research articles using machine\nlearning approaches. The COVID-19 open research dataset (CORD-19) is used for\nexperiments, whereas several target-tasks along with explanations are defined\nfor classification, based on domain knowledge. Clustering techniques are used\nto create the different clusters of available articles, and later the task\nassignment is performed using parallel one-class support vector machines\n(OCSVMs). Experiments with original and reduced features validate the\nperformance of the approach. It is evident that the k-means clustering\nalgorithm, followed by parallel OCSVMs, outperforms other methods for both\noriginal and reduced feature space.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:39:54 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:31:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Sonbhadra", "Sanjay Kumar", ""], ["Agarwal", "Sonali", ""], ["Nagabhushan", "P.", ""]]}, {"id": "2004.11709", "submitter": "Nicola Bastianello", "authors": "Nicola Bastianello, Andrea Simonetto, Ruggero Carli", "title": "Primal and Dual Prediction-Correction Methods for Time-Varying Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework for time-varying convex optimization based on\nthe prediction-correction paradigm, both in the primal and dual spaces. In this\nframework, a continuously varying optimization problem is sampled at fixed\nintervals, and each problem is approximately solved with a primal or dual\ncorrection step. The solution method is warm-started with the output of a\nprediction step, which solves an approximation of a future problem using past\ninformation. Prediction approaches are studied and compared under different\nsets of assumptions. Examples of algorithms covered by this framework are\ntime-varying versions of the gradient method, splitting methods, and the\ncelebrated alternating direction method of multipliers (ADMM).\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:48:13 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 15:11:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bastianello", "Nicola", ""], ["Simonetto", "Andrea", ""], ["Carli", "Ruggero", ""]]}, {"id": "2004.11714", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Anton Bakhtin, Myle Ott, Arthur Szlam, Marc'Aurelio\n  Ranzato", "title": "Residual Energy-Based Models for Text Generation", "comments": "published at ICLR 2020. arXiv admin note: substantial text overlap\n  with arXiv:2004.10188", "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is ubiquitous in many NLP tasks, from summarization, to\ndialogue and machine translation. The dominant parametric approach is based on\nlocally normalized models which predict one word at a time. While these work\nremarkably well, they are plagued by exposure bias due to the greedy nature of\nthe generation process. In this work, we investigate un-normalized energy-based\nmodels (EBMs) which operate not at the token but at the sequence level. In\norder to make training tractable, we first work in the residual of a pretrained\nlocally normalized language model and second we train using noise contrastive\nestimation. Furthermore, since the EBM works at the sequence level, we can\nleverage pretrained bi-directional contextual representations, such as BERT and\nRoBERTa. Our experiments on two large language modeling datasets show that\nresidual EBMs yield lower perplexity compared to locally normalized baselines.\nMoreover, generation via importance sampling is very efficient and of higher\nquality than the baseline models according to human evaluation.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 23:19:55 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Deng", "Yuntian", ""], ["Bakhtin", "Anton", ""], ["Ott", "Myle", ""], ["Szlam", "Arthur", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "2004.11721", "submitter": "Arunava Chakravarty", "authors": "Arunava Chakravarty, Tandra Sarkar, Nirmalya Ghosh, Ramanathan\n  Sethuraman, Debdoot Sheet", "title": "Learning Decision Ensemble using a Graph Neural Network for Comorbidity\n  Aware Chest Radiograph Screening", "comments": "accepted in EMBC 2020, 4pg+2pg Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiographs are primarily employed for the screening of cardio,\nthoracic and pulmonary conditions. Machine learning based automated solutions\nare being developed to reduce the burden of routine screening on Radiologists,\nallowing them to focus on critical cases. While recent efforts demonstrate the\nuse of ensemble of deep convolutional neural networks(CNN), they do not take\ndisease comorbidity into consideration, thus lowering their screening\nperformance. To address this issue, we propose a Graph Neural Network (GNN)\nbased solution to obtain ensemble predictions which models the dependencies\nbetween different diseases. A comprehensive evaluation of the proposed method\ndemonstrated its potential by improving the performance over standard\nensembling technique across a wide range of ensemble constructions. The best\nperformance was achieved using the GNN ensemble of DenseNet121 with an average\nAUC of 0.821 across thirteen disease comorbidities.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:57:50 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Chakravarty", "Arunava", ""], ["Sarkar", "Tandra", ""], ["Ghosh", "Nirmalya", ""], ["Sethuraman", "Ramanathan", ""], ["Sheet", "Debdoot", ""]]}, {"id": "2004.11722", "submitter": "Houssam Zenati", "authors": "Houssam Zenati, Alberto Bietti, Matthieu Martin, Eustache Diemert,\n  Julien Mairal", "title": "Counterfactual Learning of Continuous Stochastic Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual reasoning from logged data has become increasingly important\nfor many applications such as web advertising or healthcare. In this paper, we\naddress the problem of counterfactual risk minimization (CRM) for learning a\nstochastic policy with continuous actions. First, we introduce a new modelling\nstrategy based on a joint kernel embedding of contexts and actions, which\novercomes the shortcomings of previous discretization strategies. Second, we\nempirically show that the optimization perspective of CRM is more important\nthan previously thought, and we demonstrate the benefits of proximal point\nalgorithms and differentiable estimators. Finally, we propose an evaluation\nprotocol for offline policies in real-world logged systems, which is\nchallenging since policies cannot be replayed on test data, and we release a\nnew large-scale dataset along with multiple synthetic, yet realistic,\nevaluation setups.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 07:42:30 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 18:40:02 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 15:07:52 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Zenati", "Houssam", ""], ["Bietti", "Alberto", ""], ["Martin", "Matthieu", ""], ["Diemert", "Eustache", ""], ["Mairal", "Julien", ""]]}, {"id": "2004.11734", "submitter": "Jules Depersin", "authors": "Jules Depersin", "title": "Robust subgaussian estimation with VC-dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Median-of-means (MOM) based procedures provide non-asymptotic and strong\ndeviation bounds even when data are heavy-tailed and/or corrupted. This work\nproposes a new general way to bound the excess risk for MOM estimators. The\ncore technique is the use of VC-dimension (instead of Rademacher complexity) to\nmeasure the statistical complexity. In particular, this allows to give the\nfirst robust estimators for sparse estimation which achieves the so-called\nsubgaussian rate only assuming a finite second moment for the uncorrupted data.\nBy comparison, previous works using Rademacher complexities required a number\nof finite moments that grows logarithmically with the dimension. With this\ntechnique, we derive new robust sugaussian bounds for mean estimation in any\nnorm. We also derive a new robust estimator for covariance estimation that is\nthe first to achieve subgaussian bounds without $L_4-L_2$ norm equivalence.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 13:21:09 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 08:59:18 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 16:16:13 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Depersin", "Jules", ""]]}, {"id": "2004.11766", "submitter": "Cemil Dibek", "authors": "Matthew Andrews, Cemil Dibek, Karina Palyutina", "title": "Evolution of Q Values for Deep Q Learning in Stable Baselines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the evolution of the Q values for the implementation of Deep Q\nLearning (DQL) in the Stable Baselines library. Stable Baselines incorporates\nthe latest Reinforcement Learning techniques and achieves superhuman\nperformance in many game environments. However, for some simple non-game\nenvironments, the DQL in Stable Baselines can struggle to find the correct\nactions. In this paper we aim to understand the types of environment where this\nsuboptimal behavior can happen, and also investigate the corresponding\nevolution of the Q values for individual states.\n  We compare a smart TrafficLight environment (where performance is poor) with\nthe AI Gym FrozenLake environment (where performance is perfect). We observe\nthat DQL struggles with TrafficLight because actions are reversible and hence\nthe Q values in a given state are closer than in FrozenLake. We then\ninvestigate the evolution of the Q values using a recent decomposition\ntechnique of Achiam et al.. We observe that for TrafficLight, the function\napproximation error and the complex relationships between the states lead to a\nsituation where some Q values meander far from optimal.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:13:46 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Andrews", "Matthew", ""], ["Dibek", "Cemil", ""], ["Palyutina", "Karina", ""]]}, {"id": "2004.11778", "submitter": "Serkan Kiranyaz", "authors": "Serkan Kiranyaz, Junaid Malik, Habib Ben Abdallah, Turker Ince,\n  Alexandros Iosifidis and Moncef Gabbouj", "title": "Self-Organized Operational Neural Networks with Generative Neurons", "comments": "14 pages, 14 figures, journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operational Neural Networks (ONNs) have recently been proposed to address the\nwell-known limitations and drawbacks of conventional Convolutional Neural\nNetworks (CNNs) such as network homogeneity with the sole linear neuron model.\nONNs are heterogenous networks with a generalized neuron model that can\nencapsulate any set of non-linear operators to boost diversity and to learn\nhighly complex and multi-modal functions or spaces with minimal network\ncomplexity and training data. However, Greedy Iterative Search (GIS) method,\nwhich is the search method used to find optimal operators in ONNs takes many\ntraining sessions to find a single operator set per layer. This is not only\ncomputationally demanding, but the network heterogeneity is also limited since\nthe same set of operators will then be used for all neurons in each layer.\nMoreover, the performance of ONNs directly depends on the operator set library\nused, which introduces a certain risk of performance degradation especially\nwhen the optimal operator set required for a particular task is missing from\nthe library. In order to address these issues and achieve an ultimate\nheterogeneity level to boost the network diversity along with computational\nefficiency, in this study we propose Self-organized ONNs (Self-ONNs) with\ngenerative neurons that have the ability to adapt (optimize) the nodal operator\nof each connection during the training process. Therefore, Self-ONNs can have\nan utmost heterogeneity level required by the learning problem at hand.\nMoreover, this ability voids the need of having a fixed operator set library\nand the prior operator search within the library in order to find the best\npossible set of operators. We further formulate the training method to\nback-propagate the error through the operational layers of Self-ONNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:37:56 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Kiranyaz", "Serkan", ""], ["Malik", "Junaid", ""], ["Abdallah", "Habib Ben", ""], ["Ince", "Turker", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2004.11783", "submitter": "Barry De Bruin", "authors": "Barry de Bruin, Zoran Zivkovic, Henk Corporaal", "title": "Quantization of Deep Neural Networks for Accumulator-constrained\n  Processors", "comments": "20 pages, 13 figures", "journal-ref": "Microprocessors and Microsystems Volume 72, February 2020, 102872", "doi": "10.1016/j.micpro.2019.102872", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an Artificial Neural Network (ANN) quantization methodology for\nplatforms without wide accumulation registers. This enables fixed-point model\ndeployment on embedded compute platforms that are not specifically designed for\nlarge kernel computations (i.e. accumulator-constrained processors). We\nformulate the quantization problem as a function of accumulator size, and aim\nto maximize the model accuracy by maximizing bit width of input data and\nweights. To reduce the number of configurations to consider, only solutions\nthat fully utilize the available accumulator bits are being tested. We\ndemonstrate that 16-bit accumulators are able to obtain a classification\naccuracy within 1\\% of the floating-point baselines on the CIFAR-10 and\nILSVRC2012 image classification benchmarks. Additionally, a near-optimal\n$2\\times$ speedup is obtained on an ARM processor, by exploiting 16-bit\naccumulators for image classification on the All-CNN-C and AlexNet networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:47:14 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["de Bruin", "Barry", ""], ["Zivkovic", "Zoran", ""], ["Corporaal", "Henk", ""]]}, {"id": "2004.11791", "submitter": "Christopher Briggs", "authors": "Christopher Briggs, Zhong Fan, Peter Andras", "title": "Federated learning with hierarchical clustering of local updates to\n  improve training on non-IID data", "comments": "Accepted to 2020 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a well established method for performing machine\nlearning tasks over massively distributed data. However in settings where data\nis distributed in a non-iid (not independent and identically distributed)\nfashion -- as is typical in real world situations -- the joint model produced\nby FL suffers in terms of test set accuracy and/or communication costs compared\nto training on iid data. We show that learning a single joint model is often\nnot optimal in the presence of certain types of non-iid data. In this work we\npresent a modification to FL by introducing a hierarchical clustering step\n(FL+HC) to separate clusters of clients by the similarity of their local\nupdates to the global joint model. Once separated, the clusters are trained\nindependently and in parallel on specialised models. We present a robust\nempirical analysis of the hyperparameters for FL+HC for several iid and non-iid\nsettings. We show how FL+HC allows model training to converge in fewer\ncommunication rounds (significantly so under some non-iid settings) compared to\nFL without clustering. Additionally, FL+HC allows for a greater percentage of\nclients to reach a target accuracy compared to standard FL. Finally we make\nsuggestions for good default hyperparameters to promote superior performing\nspecialised models without modifying the the underlying federated learning\ncommunication protocol.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:16:01 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:28:10 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Briggs", "Christopher", ""], ["Fan", "Zhong", ""], ["Andras", "Peter", ""]]}, {"id": "2004.11794", "submitter": "Christopher Briggs", "authors": "Christopher Briggs, Zhong Fan, Peter Andras", "title": "A Review of Privacy-preserving Federated Learning for the\n  Internet-of-Things", "comments": "Abstract accepted for publication in a book titled: \"Federated\n  Learning Systems: Towards Next Generation AI\" in Springer's Series on\n  Studides in Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet-of-Things (IoT) generates vast quantities of data, much of it\nattributable to individuals' activity and behaviour. Gathering personal data\nand performing machine learning tasks on this data in a central location\npresents a significant privacy risk to individuals as well as challenges with\ncommunicating this data to the cloud. However, analytics based on machine\nlearning and in particular deep learning benefit greatly from large amounts of\ndata to develop high-performance predictive models. This work reviews federated\nlearning as an approach for performing machine learning on distributed data\nwith the goal of protecting the privacy of user-generated data as well as\nreducing communication costs associated with data transfer. We survey a wide\nvariety of papers covering communication-efficiency, client heterogeneity and\nprivacy preserving methods that are crucial for federated learning in the\ncontext of the IoT. Throughout this review, we identify the strengths and\nweaknesses of different methods applied to federated learning and finally, we\noutline future directions for privacy preserving federated learning research,\nparticularly focusing on IoT applications.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:27:23 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 14:08:19 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Briggs", "Christopher", ""], ["Fan", "Zhong", ""], ["Andras", "Peter", ""]]}, {"id": "2004.11803", "submitter": "Larissa Triess", "authors": "Larissa T. Triess, David Peter, Christoph B. Rist, J. Marius Z\\\"ollner", "title": "Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental\n  Study", "comments": "Accepted at IEEE Intelligent Vehicles Symposium (IV) 2020. The code\n  can be found here: http://ltriess.github.io/scan-semseg", "journal-ref": null, "doi": "10.1109/IV47402.2020.9304631", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicles need to have a semantic understanding of the\nthree-dimensional world around them in order to reason about their environment.\nState of the art methods use deep neural networks to predict semantic classes\nfor each point in a LiDAR scan. A powerful and efficient way to process LiDAR\nmeasurements is to use two-dimensional, image-like projections. In this work,\nwe perform a comprehensive experimental study of image-based semantic\nsegmentation architectures for LiDAR point clouds. We demonstrate various\ntechniques to boost the performance and to improve runtime as well as memory\nconstraints.\n  First, we examine the effect of network size and suggest that much faster\ninference times can be achieved at a very low cost to accuracy. Next, we\nintroduce an improved point cloud projection technique that does not suffer\nfrom systematic occlusions. We use a cyclic padding mechanism that provides\ncontext at the horizontal field-of-view boundaries. In a third part, we perform\nexperiments with a soft Dice loss function that directly optimizes for the\nintersection-over-union metric. Finally, we propose a new kind of convolution\nlayer with a reduced amount of weight-sharing along one of the two spatial\ndimensions, addressing the large difference in appearance along the vertical\naxis of a LiDAR scan. We propose a final set of the above methods with which\nthe model achieves an increase of 3.2% in mIoU segmentation performance over\nthe baseline while requiring only 42% of the original inference time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:08:12 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 07:12:46 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Triess", "Larissa T.", ""], ["Peter", "David", ""], ["Rist", "Christoph B.", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "2004.11804", "submitter": "Jana Obernosterer", "authors": "Nika Dogonadze, Jana Obernosterer, Ji Hou", "title": "Deep Face Forgery Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid progress in deep learning is continuously making it easier and cheaper\nto generate video forgeries. Hence, it becomes very important to have a\nreliable way of detecting these forgeries. This paper describes such an\napproach for various tampering scenarios. The problem is modelled as a\nper-frame binary classification task. We propose to use transfer learning from\nface recognition task to improve tampering detection on many different facial\nmanipulation scenarios. Furthermore, in low resolution settings, where single\nframe detection performs poorly, we try to make use of neighboring frames for\nmiddle frame classification. We evaluate both approaches on the public\nFaceForensics benchmark, achieving state of the art accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 11:13:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Dogonadze", "Nika", ""], ["Obernosterer", "Jana", ""], ["Hou", "Ji", ""]]}, {"id": "2004.11812", "submitter": "Pascal Klink", "authors": "Pascal Klink, Carlo D'Eramo, Jan Peters, Joni Pajarinen", "title": "Self-Paced Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum reinforcement learning (CRL) improves the learning speed and\nstability of an agent by exposing it to a tailored series of tasks throughout\nlearning. Despite empirical successes, an open question in CRL is how to\nautomatically generate a curriculum for a given reinforcement learning (RL)\nagent, avoiding manual design. In this paper, we propose an answer by\ninterpreting the curriculum generation as an inference problem, where\ndistributions over tasks are progressively learned to approach the target task.\nThis approach leads to an automatic curriculum generation, whose pace is\ncontrolled by the agent, with solid theoretical motivation and easily\nintegrated with deep RL algorithms. In the conducted experiments, the curricula\ngenerated with the proposed algorithm significantly improve learning\nperformance across several environments and deep RL algorithms, matching or\noutperforming state-of-the-art existing CRL algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:48:07 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 11:51:39 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 13:41:19 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 19:51:56 GMT"}, {"version": "v5", "created": "Fri, 23 Oct 2020 09:42:00 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Klink", "Pascal", ""], ["D'Eramo", "Carlo", ""], ["Peters", "Jan", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2004.11815", "submitter": "Yiye Jiang", "authors": "Yiye Jiang (1 and 2), J\\'er\\'emie Bigot (1) and Sofian Maabout (2)\n  ((1) Institut de Math\\'ematiques de Bordeaux, Universit\\'e de Bordeaux, (2)\n  Laboratoire Bordelais de Recherche en Informatique, Universit\\'e de Bordeaux)", "title": "Sensor selection on graphs via data-driven node sub-sampling in network\n  time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned by the problem of selecting an optimal sampling set\nof sensors over a network of time series for the purpose of signal recovery at\nnon-observed sensors with a minimal reconstruction error. The problem is\nmotivated by applications where time-dependent graph signals are collected over\nredundant networks. In this setting, one may wish to only use a subset of\nsensors to predict data streams over the whole collection of nodes in the\nunderlying graph. A typical application is the possibility to reduce the power\nconsumption in a network of sensors that may have limited battery supplies. We\npropose and compare various data-driven strategies to turn off a fixed number\nof sensors or equivalently to select a sampling set of nodes. We also relate\nour approach to the existing literature on sensor selection from multivariate\ndata with a (possibly) underlying graph structure. Our methodology combines\ntools from multivariate time series analysis, graph signal processing,\nstatistical learning in high-dimension and deep learning. To illustrate the\nperformances of our approach, we report numerical experiments on the analysis\nof real data from bike sharing networks in different cities.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:51:57 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Jiang", "Yiye", "", "1 and 2"], ["Bigot", "J\u00e9r\u00e9mie", ""], ["Maabout", "Sofian", ""]]}, {"id": "2004.11819", "submitter": "Junhee Kim", "authors": "Younghwan Na, Jun Hee Kim, Kyungsu Lee, Juhum Park, Jae Youn Hwang,\n  Jihwan P. Choi", "title": "Domain Adaptive Transfer Attack (DATA)-based Segmentation Networks for\n  Building Extraction from Aerial Images", "comments": "11pages, 12 figures", "journal-ref": null, "doi": "10.1109/TGRS.2020.3010055", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation models based on convolutional neural networks (CNNs)\nhave gained much attention in relation to remote sensing and have achieved\nremarkable performance for the extraction of buildings from high-resolution\naerial images. However, the issue of limited generalization for unseen images\nremains. When there is a domain gap between the training and test datasets,\nCNN-based segmentation models trained by a training dataset fail to segment\nbuildings for the test dataset. In this paper, we propose segmentation networks\nbased on a domain adaptive transfer attack (DATA) scheme for building\nextraction from aerial images. The proposed system combines the domain transfer\nand adversarial attack concepts. Based on the DATA scheme, the distribution of\nthe input images can be shifted to that of the target images while turning\nimages into adversarial examples against a target network. Defending\nadversarial examples adapted to the target domain can overcome the performance\ndegradation due to the domain gap and increase the robustness of the\nsegmentation model. Cross-dataset experiments and the ablation study are\nconducted for the three different datasets: the Inria aerial image labeling\ndataset, the Massachusetts building dataset, and the WHU East Asia dataset.\nCompared to the performance of the segmentation network without the DATA\nscheme, the proposed method shows improvements in the overall IoU. Moreover, it\nis verified that the proposed method outperforms even when compared to feature\nadaptation (FA) and output space adaptation (OSA).\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 06:17:13 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:12:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Na", "Younghwan", ""], ["Kim", "Jun Hee", ""], ["Lee", "Kyungsu", ""], ["Park", "Juhum", ""], ["Hwang", "Jae Youn", ""], ["Choi", "Jihwan P.", ""]]}, {"id": "2004.11820", "submitter": "Xuezhe Ma", "authors": "Xuezhe Ma, Xiang Kong, Shanghang Zhang, Eduard Hovy", "title": "Decoupling Global and Local Representations via Invertible Generative\n  Flows", "comments": "Camera-ready at ICLR 2021. 23 pages (plus appendix), 16 figures, 5\n  tables. Due to arxiv size constraints, this version is using downscaled\n  images. Please download the full-resolution version from\n  https://vixra.org/abs/2004.0222", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new generative model that is capable of\nautomatically decoupling global and local representations of images in an\nentirely unsupervised setting, by embedding a generative flow in the VAE\nframework to model the decoder. Specifically, the proposed model utilizes the\nvariational auto-encoding framework to learn a (low-dimensional) vector of\nlatent variables to capture the global information of an image, which is fed as\na conditional input to a flow-based invertible decoder with architecture\nborrowed from style transfer literature. Experimental results on standard image\nbenchmarks demonstrate the effectiveness of our model in terms of density\nestimation, image generation and unsupervised representation learning.\nImportantly, this work demonstrates that with only architectural inductive\nbiases, a generative model with a likelihood-based objective is capable of\nlearning decoupled representations, requiring no explicit supervision. The code\nfor our model is available at https://github.com/XuezheMax/wolf.\n", "versions": [{"version": "v1", "created": "Sun, 12 Apr 2020 03:18:13 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 20:17:34 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Ma", "Xuezhe", ""], ["Kong", "Xiang", ""], ["Zhang", "Shanghang", ""], ["Hovy", "Eduard", ""]]}, {"id": "2004.11829", "submitter": "Ievgen Redko", "authors": "Ievgen Redko, Emilie Morvant, Amaury Habrard, Marc Sebban, Youn\\`es\n  Bennani", "title": "A survey on domain adaptation theory: learning bounds and theoretical\n  guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All famous machine learning algorithms that comprise both supervised and\nsemi-supervised learning work well only under a common assumption: the training\nand test data follow the same distribution. When the distribution changes, most\nstatistical models must be reconstructed from newly collected data, which for\nsome applications can be costly or impossible to obtain. Therefore, it has\nbecome necessary to develop approaches that reduce the need and the effort to\nobtain new labeled samples by exploiting data that are available in related\nareas, and using these further across similar fields. This has given rise to a\nnew machine learning framework known as transfer learning: a learning setting\ninspired by the capability of a human being to extrapolate knowledge across\ntasks to learn more efficiently. Despite a large amount of different transfer\nlearning scenarios, the main objective of this survey is to provide an overview\nof the state-of-the-art theoretical results in a specific, and arguably the\nmost popular, sub-field of transfer learning, called domain adaptation. In this\nsub-field, the data distribution is assumed to change across the training and\nthe test data, while the learning task remains the same. We provide a first\nup-to-date description of existing results related to domain adaptation problem\nthat cover learning bounds based on different statistical learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 16:11:03 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 13:29:02 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 12:04:58 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 11:57:24 GMT"}, {"version": "v5", "created": "Thu, 6 Aug 2020 13:34:43 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Redko", "Ievgen", ""], ["Morvant", "Emilie", ""], ["Habrard", "Amaury", ""], ["Sebban", "Marc", ""], ["Bennani", "Youn\u00e8s", ""]]}, {"id": "2004.11834", "submitter": "Grzegorz Dudek", "authors": "Pawe{\\l} Pe{\\l}ka and Grzegorz Dudek", "title": "Pattern-based Long Short-term Memory for Mid-term Electrical Load\n  Forecasting", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a Long Short-Term Memory (LSTM) network for forecasting a\nmonthly electricity demand time series with a one-year horizon. The novelty of\nthis work is the use of pattern representation of the seasonal time series as\nan alternative to decomposition. Pattern representation simplifies the complex\nnonlinear and nonstationary time series, filtering out the trend and equalizing\nvariance. Two types of patterns are defined: x-pattern and y-pattern. The\nformer requires additional forecasting for the coding variables. The latter\ndetermines the coding variables from the process history. A hybrid approach\nbased on x-patterns turned out to be more accurate than the standard LSTM\napproach based on a raw time series. In this combined approach an x-pattern is\nforecasted using a sequence-to-sequence LSTM network and the coding variables\nare forecasted using exponential smoothing. A simulation study performed on the\nmonthly electricity demand time series for 35 European countries confirmed the\nhigh performance of the proposed model and its competitiveness to classical\nmodels such as ARIMA and exponential smoothing as well as the MLP neural\nnetwork model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:39:32 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Pe\u0142ka", "Pawe\u0142", ""], ["Dudek", "Grzegorz", ""]]}, {"id": "2004.11836", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Convolutional Neural Network Array for Sign Language Recognition using\n  Wearable IMUs", "comments": "https://doi.org/10.1109/SPIN.2019.8711745", "journal-ref": null, "doi": "10.1109/SPIN.2019.8711745", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in gesture recognition algorithms have led to a significant\ngrowth in sign language translation. By making use of efficient intelligent\nmodels, signs can be recognized with precision. The proposed work presents a\nnovel one-dimensional Convolutional Neural Network (CNN) array architecture for\nrecognition of signs from the Indian sign language using signals recorded from\na custom designed wearable IMU device. The IMU device makes use of tri-axial\naccelerometer and gyroscope. The signals recorded using the IMU device are\nsegregated on the basis of their context, such as whether they correspond to\nsigning for a general sentence or an interrogative sentence. The array\ncomprises of two individual CNNs, one classifying the general sentences and the\nother classifying the interrogative sentence. Performances of individual CNNs\nin the array architecture are compared to that of a conventional CNN\nclassifying the unsegregated dataset. Peak classification accuracies of 94.20%\nfor general sentences and 95.00% for interrogative sentences achieved with the\nproposed CNN array in comparison to 93.50% for conventional CNN assert the\nsuitability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 23:11:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2004.11838", "submitter": "Firoj Alam", "authors": "Ferda Ofli, Firoj Alam and Muhammad Imran", "title": "Analysis of Social Media Data using Multimodal Deep Learning for\n  Disaster Response", "comments": "Accepted in ISCRAM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimedia content in social media platforms provides significant information\nduring disaster events. The types of information shared include reports of\ninjured or deceased people, infrastructure damage, and missing or found people,\namong others. Although many studies have shown the usefulness of both text and\nimage content for disaster response purposes, the research has been mostly\nfocused on analyzing only the text modality in the past. In this paper, we\npropose to use both text and image modalities of social media data to learn a\njoint representation using state-of-the-art deep learning techniques.\nSpecifically, we utilize convolutional neural networks to define a multimodal\ndeep learning architecture with a modality-agnostic shared representation.\nExtensive experiments on real-world disaster datasets show that the proposed\nmultimodal architecture yields better performance than models trained using a\nsingle modality (e.g., either text or image).\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 19:36:11 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ofli", "Ferda", ""], ["Alam", "Firoj", ""], ["Imran", "Muhammad", ""]]}, {"id": "2004.11839", "submitter": "Chang Wei Tan", "authors": "Chang Wei Tan, Mahsa Salehi, Geoffrey Mackellar", "title": "Detecting Driver's Distraction using Long-term Recurrent Convolutional\n  Network", "comments": "3 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we demonstrate a novel Brain Computer Interface (BCI) approach\nto detect driver distraction events to improve road safety. We use a commercial\nwireless headset that generates EEG signals from the brain. We collected real\nEEG signals from participants who undertook a 40-minute driving simulation and\nwere required to perform different tasks while driving. These signals are\nsegmented into short windows and labelled using a time series classification\n(TSC) model. We studied different TSC approaches and designed a Long-term\nRecurrent Convolutional Network (LCRN) model for this task. Our results showed\nthat our LRCN model performs better than the state of the art TSC models at\ndetecting driver distraction events.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 00:35:28 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Tan", "Chang Wei", ""], ["Salehi", "Mahsa", ""], ["Mackellar", "Geoffrey", ""]]}, {"id": "2004.11841", "submitter": "Felix Sattler", "authors": "Felix Sattler, Jackie Ma, Patrick Wagner, David Neumann, Markus\n  Wenzel, Ralf Sch\\\"afer, Wojciech Samek, Klaus-Robert M\\\"uller, Thomas Wiegand", "title": "Risk Estimation of SARS-CoV-2 Transmission from Bluetooth Low Energy\n  Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.PE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing approaches based on Bluetooth low energy (BLE) have\nthe potential to efficiently contain and delay outbreaks of infectious diseases\nsuch as the ongoing SARS-CoV-2 pandemic. In this work we propose a novel\nmachine learning based approach to reliably detect subjects that have spent\nenough time in close proximity to be at risk of being infected. Our study is an\nimportant proof of concept that will aid the battery of epidemiological\npolicies aiming to slow down the rapid spread of COVID-19.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:10:35 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Sattler", "Felix", ""], ["Ma", "Jackie", ""], ["Wagner", "Patrick", ""], ["Neumann", "David", ""], ["Wenzel", "Markus", ""], ["Sch\u00e4fer", "Ralf", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Wiegand", "Thomas", ""]]}, {"id": "2004.11842", "submitter": "Amir Mosavi Prof", "authors": "Yihe Liu, Aaqif Afzaal Abbasi, Atefeh Aghaei, Almas Abbasi, Amir\n  Mosavi, Shahab Shamshirband, and Mohammed A. A. Al-qaness", "title": "A Mobile Cloud-Based eHealth Scheme", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": "10.32604/cmc.2020.07708", "report-no": null, "categories": "eess.SP cs.LG cs.NI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile cloud computing is an emerging field that is gaining popularity across\nborders at a rapid pace. Similarly, the field of health informatics is also\nconsidered as an extremely important field. This work observes the\ncollaboration between these two fields to solve the traditional problem of\nextracting Electrocardiogram signals from trace reports and then performing\nanalysis. The developed system has two front ends, the first dedicated for the\nuser to perform the photographing of the trace report. Once the photographing\nis complete, mobile computing is used to extract the signal. Once the signal is\nextracted, it is uploaded into the server and further analysis is performed on\nthe signal in the cloud. Once this is done, the second interface, intended for\nthe use of the physician, can download and view the trace from the cloud. The\ndata is securely held using a password-based authentication method. The system\npresented here is one of the first attempts at delivering the total solution,\nand after further upgrades, it will be possible to deploy the system in a\ncommercial setting.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:06:54 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Liu", "Yihe", ""], ["Abbasi", "Aaqif Afzaal", ""], ["Aghaei", "Atefeh", ""], ["Abbasi", "Almas", ""], ["Mosavi", "Amir", ""], ["Shamshirband", "Shahab", ""], ["Al-qaness", "Mohammed A. A.", ""]]}, {"id": "2004.11848", "submitter": "Chao Zhou", "authors": "Xinting Yang, Song Zhang, Jintao Liu, Qinfeng Gao, Shuanglin Dong,\n  Chao Zhou", "title": "Deep learning for smart fish farming: applications, opportunities and\n  challenges", "comments": "43 pages, 7 figures", "journal-ref": "Reviews in aquaculture,2020", "doi": "10.1111/raq.12464", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid emergence of deep learning (DL) technology, it has been\nsuccessfully used in various fields including aquaculture. This change can\ncreate new opportunities and a series of challenges for information and data\nprocessing in smart fish farming. This paper focuses on the applications of DL\nin aquaculture, including live fish identification, species classification,\nbehavioral analysis, feeding decision-making, size or biomass estimation, water\nquality prediction. In addition, the technical details of DL methods applied to\nsmart fish farming are also analyzed, including data, algorithms, computing\npower, and performance. The results of this review show that the most\nsignificant contribution of DL is the ability to automatically extract\nfeatures. However, challenges still exist; DL is still in an era of weak\nartificial intelligence. A large number of labeled data are needed for\ntraining, which has become a bottleneck restricting further DL applications in\naquaculture. Nevertheless, DL still offers breakthroughs in the handling of\ncomplex data in aquaculture. In brief, our purpose is to provide researchers\nand practitioners with a better understanding of the current state of the art\nof DL in aquaculture, which can provide strong support for the implementation\nof smart fish farming.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:07:27 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 11:11:22 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Yang", "Xinting", ""], ["Zhang", "Song", ""], ["Liu", "Jintao", ""], ["Gao", "Qinfeng", ""], ["Dong", "Shuanglin", ""], ["Zhou", "Chao", ""]]}, {"id": "2004.11890", "submitter": "Thibaut Vidal", "authors": "Daniel Gribel, Thibaut Vidal, Michel Gendreau", "title": "Assortative-Constrained Stochastic Block Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic block models (SBMs) are often used to find assortative community\nstructures in networks, such that the probability of connections within\ncommunities is higher than in between communities. However, classic SBMs are\nnot limited to assortative structures. In this study, we discuss the\nimplications of this model-inherent indifference towards assortativity or\ndisassortativity, and show that this characteristic can lead to undesirable\noutcomes for networks which are presupposedy assortative but which contain a\nreduced amount of information. To circumvent this issue, we introduce a\nconstrained SBM that imposes strong assortativity constraints, along with\nefficient algorithmic approaches to solve it. These constraints significantly\nboost community recovery capabilities in regimes that are close to the\ninformation-theoretic threshold. They also permit to identify\nstructurally-different communities in networks representing cerebral-cortex\nactivity regions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 19:52:59 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Gribel", "Daniel", ""], ["Vidal", "Thibaut", ""], ["Gendreau", "Michel", ""]]}, {"id": "2004.11898", "submitter": "Nathaniel Bastian PhD", "authors": "Elie Alhajjar and Paul Maxwell and Nathaniel D. Bastian", "title": "Adversarial Machine Learning in Network Intrusion Detection Systems", "comments": "25 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are inputs to a machine learning system intentionally\ncrafted by an attacker to fool the model into producing an incorrect output.\nThese examples have achieved a great deal of success in several domains such as\nimage recognition, speech recognition and spam detection. In this paper, we\nstudy the nature of the adversarial problem in Network Intrusion Detection\nSystems (NIDS). We focus on the attack perspective, which includes techniques\nto generate adversarial examples capable of evading a variety of machine\nlearning models. More specifically, we explore the use of evolutionary\ncomputation (particle swarm optimization and genetic algorithm) and deep\nlearning (generative adversarial networks) as tools for adversarial example\ngeneration. To assess the performance of these algorithms in evading a NIDS, we\napply them to two publicly available data sets, namely the NSL-KDD and\nUNSW-NB15, and we contrast them to a baseline perturbation method: Monte Carlo\nsimulation. The results show that our adversarial example generation techniques\ncause high misclassification rates in eleven different machine learning models,\nalong with a voting classifier. Our work highlights the vulnerability of\nmachine learning based NIDS in the face of adversarial perturbation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 19:47:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Alhajjar", "Elie", ""], ["Maxwell", "Paul", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2004.11909", "submitter": "Diego Alberto Mercado-Ravell Dr.", "authors": "Marichelo Garcia-Venegas, Diego A. Mercado-Ravell and Carlos A.\n  Carballo-Monsivais", "title": "On the safety of vulnerable road users by cyclist orientation detection\n  using Deep Learning", "comments": "\"This paper is a preprint of a paper submitted to IET Intelligent\n  Transport Systems. If accepted, the copy of record will be available at the\n  IET Digital Library\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, orientation detection using Deep Learning is acknowledged for a\nparticularly vulnerable class of road users,the cyclists. Knowing the cyclists'\norientation is of great relevance since it provides a good notion about their\nfuture trajectory, which is crucial to avoid accidents in the context of\nintelligent transportation systems. Using Transfer Learning with pre-trained\nmodels and TensorFlow, we present a performance comparison between the main\nalgorithms reported in the literature for object detection,such as SSD, Faster\nR-CNN and R-FCN along with MobilenetV2, InceptionV2, ResNet50, ResNet101\nfeature extractors. Moreover, we propose multi-class detection with eight\ndifferent classes according to orientations. To do so, we introduce a new\ndataset called \"Detect-Bike\", containing 20,229 cyclist instances over 11,103\nimages, which has been labeled based on cyclist's orientation. Then, the same\nDeep Learning methods used for detection are trained to determine the target's\nheading. Our experimental results and vast evaluation showed satisfactory\nperformance of all of the studied methods for the cyclists and their\norientation detection, especially using Faster R-CNN with ResNet50 proved to be\nprecise but significantly slower. Meanwhile, SSD using InceptionV2 provided\ngood trade-off between precision and execution time, and is to be preferred for\nreal-time embedded applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:10:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Garcia-Venegas", "Marichelo", ""], ["Mercado-Ravell", "Diego A.", ""], ["Carballo-Monsivais", "Carlos A.", ""]]}, {"id": "2004.11910", "submitter": "Gang Liu", "authors": "Gang Liu and Jing Wang", "title": "A Relation Spectrum Inheriting Taylor Series: Muscle Synergy and\n  Coupling for Hand", "comments": "Dendrite Net and Relation spectrum unify online performance and\n  offline results", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two famous function decomposition methods in math: Taylor Series\nand Fourier Series. Fourier series developed into Fourier spectrum, which was\napplied to signal decomposition\\analysis. However, because the Taylor series\nwhose function without a definite functional expression cannot be solved,\nTaylor Series has rarely been used in engineering. Here, we developed Taylor\nseries by our Dendrite Net, constructed a relation spectrum, and applied it to\nmodel or system decomposition\\analysis. Specific engineering: the knowledge of\nthe intuitive link between muscle activity and the finger movement is vital for\nthe design of commercial prosthetic hands that do not need user pre-training.\nHowever, this link has yet to be understood due to the complexity of human\nhand. In this study, the relation spectrum was applied to analyze the\nmuscle-finger system. One single muscle actuates multiple fingers, or multiple\nmuscles actuate one single finger simultaneously. Thus, the research was in\nmuscle synergy and muscle coupling for hand. This paper has two main\ncontributions. (1) The findings of hand contribute to designing prosthetic\nhands. (2) The relation spectrum makes the online model human-readable, which\nunifies online performance and offline results. Code (novel tool for most\nfields) is available at https://github.com/liugang1234567/Gang-neuron.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:26:11 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 09:42:09 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 21:37:35 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Liu", "Gang", ""], ["Wang", "Jing", ""]]}, {"id": "2004.11929", "submitter": "Nathan Musoke", "authors": "Grigor Aslanyan, Richard Easther, Nathan Musoke, Layne C. Price", "title": "Robust posterior inference when statistically emulating forward\n  simulations", "comments": "code available from https://doi.org/10.5281/zenodo.3764460 or\n  https://github.com/auckland-cosmo/LearnAsYouGoEmulator", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific analyses often rely on slow, but accurate forward models for\nobservable data conditioned on known model parameters. While various emulation\nschemes exist to approximate these slow calculations, these approaches are only\nsafe if the approximations are well understood and controlled. This workshop\nsubmission reviews and updates a previously published method, which has been\nused in cosmological simulations, to (1) train an emulator while simultaneously\nestimating posterior probabilities with MCMC and (2) explicitly propagate the\nemulation error into errors on the posterior probabilities for model\nparameters. We demonstrate how these techniques can be applied to quickly\nestimate posterior distributions for parameters of the $\\Lambda$CDM cosmology\nmodel, while also gauging the robustness of the emulator approximation.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:15:59 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Aslanyan", "Grigor", ""], ["Easther", "Richard", ""], ["Musoke", "Nathan", ""], ["Price", "Layne C.", ""]]}, {"id": "2004.11934", "submitter": "Ruohong Zhang", "authors": "Ruohong Zhang, Yu Hao, Donghan Yu, Wei-Cheng Chang, Guokun Lai, Yiming\n  Yang", "title": "Correlation-aware Unsupervised Change-point Detection via Graph Neural\n  Networks", "comments": "Accepted for publication in the International Conference on Neural\n  Information Processing (ICONIP) 2020 Original paper is 12 pages, additional\n  appendix is available on arxiv", "journal-ref": "ICONIP 2020: Neural Information Processing", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Change-point detection (CPD) aims to detect abrupt changes over time series\ndata. Intuitively, effective CPD over multivariate time series should require\nexplicit modeling of the dependencies across input variables. However, existing\nCPD methods either ignore the dependency structures entirely or rely on the\n(unrealistic) assumption that the correlation structures are static over time.\nIn this paper, we propose a Correlation-aware Dynamics Model for CPD, which\nexplicitly models the correlation structure and dynamics of variables by\nincorporating graph neural networks into an encoder-decoder framework.\nExtensive experiments on synthetic and real-world datasets demonstrate the\nadvantageous performance of the proposed model on CPD tasks over strong\nbaselines, as well as its ability to classify the change-points as correlation\nchanges or independent changes. Keywords: Multivariate Time Series,\nChange-point Detection, Graph Neural Networks\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:28:57 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2020 05:07:46 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zhang", "Ruohong", ""], ["Hao", "Yu", ""], ["Yu", "Donghan", ""], ["Chang", "Wei-Cheng", ""], ["Lai", "Guokun", ""], ["Yang", "Yiming", ""]]}, {"id": "2004.11935", "submitter": "Anirudh Goyal", "authors": "Anirudh Goyal, Yoshua Bengio, Matthew Botvinick, Sergey Levine", "title": "The Variational Bandwidth Bottleneck: Stochastic Evaluation on an\n  Information Budget", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, it is desirable to extract only the relevant\ninformation from complex input data, which involves making a decision about\nwhich input features are relevant. The information bottleneck method formalizes\nthis as an information-theoretic optimization problem by maintaining an optimal\ntradeoff between compression (throwing away irrelevant input information), and\npredicting the target. In many problem settings, including the reinforcement\nlearning problems we consider in this work, we might prefer to compress only\npart of the input. This is typically the case when we have a standard\nconditioning input, such as a state observation, and a \"privileged\" input,\nwhich might correspond to the goal of a task, the output of a costly planning\nalgorithm, or communication with another agent. In such cases, we might prefer\nto compress the privileged input, either to achieve better generalization\n(e.g., with respect to goals) or to minimize access to costly information\n(e.g., in the case of communication). Practical implementations of the\ninformation bottleneck based on variational inference require access to the\nprivileged input in order to compute the bottleneck variable, so although they\nperform compression, this compression operation itself needs unrestricted,\nlossless access. In this work, we propose the variational bandwidth bottleneck,\nwhich decides for each example on the estimated value of the privileged\ninformation before seeing it, i.e., only based on the standard input, and then\naccordingly chooses stochastically, whether to access the privileged input or\nnot. We formulate a tractable approximation to this framework and demonstrate\nin a series of reinforcement learning experiments that it can improve\ngeneralization and reduce access to computationally costly information.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:29:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Botvinick", "Matthew", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.11938", "submitter": "Rico Jonschkowski", "authors": "Michael Zhu, Kevin Murphy, Rico Jonschkowski", "title": "Towards Differentiable Resampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resampling is a key component of sample-based recursive state estimation in\nparticle filters. Recent work explores differentiable particle filters for\nend-to-end learning. However, resampling remains a challenge in these works, as\nit is inherently non-differentiable. We address this challenge by replacing\ntraditional resampling with a learned neural network resampler. We present a\nnovel network architecture, the particle transformer, and train it for particle\nresampling using a likelihood-based loss function over sets of particles.\nIncorporated into a differentiable particle filter, our model can be end-to-end\noptimized jointly with the other particle filter components via gradient\ndescent. Our results show that our learned resampler outperforms traditional\nresampling techniques on synthetic data and in a simulated robot localization\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 18:37:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhu", "Michael", ""], ["Murphy", "Kevin", ""], ["Jonschkowski", "Rico", ""]]}, {"id": "2004.11946", "submitter": "Fei Sun", "authors": "Fei Sun, Minghai Qin, Tianyun Zhang, Liu Liu, Yen-Kuang Chen, Yuan Xie", "title": "Computation on Sparse Neural Networks: an Inspiration for Future\n  Hardware", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network models are widely used in solving many challenging problems,\nsuch as computer vision, personalized recommendation, and natural language\nprocessing. Those models are very computationally intensive and reach the\nhardware limit of the existing server and IoT devices. Thus, finding better\nmodel architectures with much less amount of computation while maximally\npreserving the accuracy is a popular research topic. Among various mechanisms\nthat aim to reduce the computation complexity, identifying the zero values in\nthe model weights and in the activations to avoid computing them is a promising\ndirection.\n  In this paper, we summarize the current status of the research on the\ncomputation of sparse neural networks, from the perspective of the sparse\nalgorithms, the software frameworks, and the hardware accelerations. We observe\nthat the search for the sparse structure can be a general methodology for\nhigh-quality model explorations, in addition to a strategy for high-efficiency\nmodel execution. We discuss the model accuracy influenced by the number of\nweight parameters and the structure of the model. The corresponding models are\ncalled to be located in the weight dominated and structure dominated regions,\nrespectively. We show that for practically complicated problems, it is more\nbeneficial to search large and sparse models in the weight dominated region. In\norder to achieve the goal, new approaches are required to search for proper\nsparse structures, and new sparse training hardware needs to be developed to\nfacilitate fast iterations of sparse models.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:13:50 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sun", "Fei", ""], ["Qin", "Minghai", ""], ["Zhang", "Tianyun", ""], ["Liu", "Liu", ""], ["Chen", "Yen-Kuang", ""], ["Xie", "Yuan", ""]]}, {"id": "2004.11947", "submitter": "Jiri Kubalik", "authors": "J. Kubal\\'ik, E. Derner, R. Babu\\v{s}ka", "title": "Symbolic Regression Driven by Training Data and Prior Knowledge", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3377930.3390152", "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In symbolic regression, the search for analytic models is typically driven\npurely by the prediction error observed on the training data samples. However,\nwhen the data samples do not sufficiently cover the input space, the prediction\nerror does not provide sufficient guidance toward desired models. Standard\nsymbolic regression techniques then yield models that are partially incorrect,\nfor instance, in terms of their steady-state characteristics or local behavior.\nIf these properties were considered already during the search process, more\naccurate and relevant models could be produced. We propose a multi-objective\nsymbolic regression approach that is driven by both the training data and the\nprior knowledge of the properties the desired model should manifest. The\nproperties given in the form of formal constraints are internally represented\nby a set of discrete data samples on which candidate models are exactly\nchecked. The proposed approach was experimentally evaluated on three test\nproblems with results clearly demonstrating its capability to evolve realistic\nmodels that fit the training data well while complying with the prior knowledge\nof the desired model characteristics at the same time. It outperforms standard\nsymbolic regression by several orders of magnitude in terms of the mean squared\ndeviation from a reference model.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:15:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kubal\u00edk", "J.", ""], ["Derner", "E.", ""], ["Babu\u0161ka", "R.", ""]]}, {"id": "2004.11958", "submitter": "Awais Khan", "authors": "Ranjita Thapa (1), Noah Snavely (2), Serge Belongie (2), Awais Khan\n  (1) ((1) Plant Pathology and Plant-Microbe Biology Section, Cornell\n  University, Geneva, NY, (2) Cornell Tech)", "title": "The Plant Pathology 2020 challenge dataset to classify foliar disease of\n  apples", "comments": "11 pages, 5 figures, Kaggle competition website:\n  https://www.kaggle.com/c/plant-pathology-2020-fgvc7, CVPR fine-grained visual\n  categorization website: https://sites.google.com/view/fgvc7/competitions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apple orchards in the U.S. are under constant threat from a large number of\npathogens and insects. Appropriate and timely deployment of disease management\ndepends on early disease detection. Incorrect and delayed diagnosis can result\nin either excessive or inadequate use of chemicals, with increased production\ncosts, environmental, and health impacts. We have manually captured 3,651\nhigh-quality, real-life symptom images of multiple apple foliar diseases, with\nvariable illumination, angles, surfaces, and noise. A subset, expert-annotated\nto create a pilot dataset for apple scab, cedar apple rust, and healthy leaves,\nwas made available to the Kaggle community for 'Plant Pathology Challenge';\npart of the Fine-Grained Visual Categorization (FGVC) workshop at CVPR 2020\n(Computer Vision and Pattern Recognition). We also trained an off-the-shelf\nconvolutional neural network (CNN) on this data for disease classification and\nachieved 97% accuracy on a held-out test set. This dataset will contribute\ntowards development and deployment of machine learning-based automated plant\ndisease classification algorithms to ultimately realize fast and accurate\ndisease detection. We will continue to add images to the pilot dataset for a\nlarger, more comprehensive expert-annotated dataset for future Kaggle\ncompetitions and to explore more advanced methods for disease classification\nand quantification.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:36:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Thapa", "Ranjita", ""], ["Snavely", "Noah", ""], ["Belongie", "Serge", ""], ["Khan", "Awais", ""]]}, {"id": "2004.11963", "submitter": "Shatian Wang", "authors": "Shatian Wang, Shuoguang Yang, Zhen Xu, Van-Anh Truong", "title": "Online Learning with Cumulative Oversampling: Application to Budgeted\n  Influence Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cumulative oversampling (CO) method for online learning. Our key\nidea is to sample parameter estimations from the updated belief space once in\neach round (similar to Thompson Sampling), and utilize the cumulative samples\nup to the current round to construct optimistic parameter estimations that\nasymptotically concentrate around the true parameters as tighter upper\nconfidence bounds compared to the ones constructed with standard UCB methods.\nWe apply CO to a novel budgeted variant of the Influence Maximization (IM)\nsemi-bandits with linear generalization of edge weights, whose offline problem\nis NP-hard. Combining CO with the oracle we design for the offline problem, our\nonline learning algorithm simultaneously tackles budget allocation, parameter\nlearning, and reward maximization. We show that for IM semi-bandits, our\nCO-based algorithm achieves a scaled regret comparable to that of the UCB-based\nalgorithms in theory, and performs on par with Thompson Sampling in numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:46:41 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 04:11:57 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 01:51:09 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Wang", "Shatian", ""], ["Yang", "Shuoguang", ""], ["Xu", "Zhen", ""], ["Truong", "Van-Anh", ""]]}, {"id": "2004.11966", "submitter": "Nima Tajbakhsh", "authors": "Gaurav Fotedar, Nima Tajbakhsh, Shilpa Ananth, and Xiaowei Ding", "title": "Extreme Consistency: Overcoming Annotation Scarcity and Domain Shifts", "comments": "submitted for peer-review on March 17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning has proved effective for medical image analysis. However,\nit can utilize only the small labeled portion of data; it fails to leverage the\nlarge amounts of unlabeled data that is often available in medical image\ndatasets. Supervised models are further handicapped by domain shifts, when the\nlabeled dataset, despite being large enough, fails to cover different protocols\nor ethnicities. In this paper, we introduce \\emph{extreme consistency}, which\novercomes the above limitations, by maximally leveraging unlabeled data from\nthe same or a different domain in a teacher-student semi-supervised paradigm.\nExtreme consistency is the process of sending an extreme transformation of a\ngiven image to the student network and then constraining its prediction to be\nconsistent with the teacher network's prediction for the untransformed image.\nThe extreme nature of our consistency loss distinguishes our method from\nrelated works that yield suboptimal performance by exercising only mild\nprediction consistency. Our method is 1) auto-didactic, as it requires no extra\nexpert annotations; 2) versatile, as it handles both domain shift and limited\nannotation problems; 3) generic, as it is readily applicable to classification,\nsegmentation, and detection tasks; and 4) simple to implement, as it requires\nno adversarial training. We evaluate our method for the tasks of lesion and\nretinal vessel segmentation in skin and fundus images. Our experiments\ndemonstrate a significant performance gain over both modern supervised networks\nand recent semi-supervised models. This performance is attributed to the strong\nregularization enforced by extreme consistency, which enables the student\nnetwork to learn how to handle extreme variants of both labeled and unlabeled\nimages. This enhances the network's ability to tackle the inevitable same- and\ncross-domain data variability during inference.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:32:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Fotedar", "Gaurav", ""], ["Tajbakhsh", "Nima", ""], ["Ananth", "Shilpa", ""], ["Ding", "Xiaowei", ""]]}, {"id": "2004.11967", "submitter": "Antreas Antoniou Mr", "authors": "Antreas Antoniou, Massimiliano Patacchiola, Mateusz Ochal and Amos\n  Storkey", "title": "Defining Benchmarks for Continual Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both few-shot and continual learning have seen substantial progress in the\nlast years due to the introduction of proper benchmarks. That being said, the\nfield has still to frame a suite of benchmarks for the highly desirable setting\nof continual few-shot learning, where the learner is presented a number of\nfew-shot tasks, one after the other, and then asked to perform well on a\nvalidation set stemming from all previously seen tasks. Continual few-shot\nlearning has a small computational footprint and is thus an excellent setting\nfor efficient investigation and experimentation. In this paper we first define\na theoretical framework for continual few-shot learning, taking into account\nrecent literature, then we propose a range of flexible benchmarks that unify\nthe evaluation criteria and allows exploring the problem from multiple\nperspectives. As part of the benchmark, we introduce a compact variant of\nImageNet, called SlimageNet64, which retains all original 1000 classes but only\ncontains 200 instances of each one (a total of 200K data-points) downscaled to\n64 x 64 pixels. We provide baselines for the proposed benchmarks using a number\nof popular few-shot learning algorithms, as a result, exposing previously\nunknown strengths and weaknesses of those algorithms in continual and\ndata-limited settings.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 16:41:01 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Antoniou", "Antreas", ""], ["Patacchiola", "Massimiliano", ""], ["Ochal", "Mateusz", ""], ["Storkey", "Amos", ""]]}, {"id": "2004.11978", "submitter": "Andrea Bellotti", "authors": "Andrea Bellotti, Sergey Antopolskiy, Anna Marchenkova, Alessia\n  Colucciello, Pietro Avanzini, Giovanni Vecchiato, Jonas Ambeck-Madsen, Luca\n  Ascari", "title": "Brain-based control of car infotainment", "comments": null, "journal-ref": null, "doi": "10.1109/SMC.2019.8914448", "report-no": null, "categories": "cs.HC cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the possibility to run advanced AI on embedded systems allows\nnatural interaction between humans and machines, especially in the automotive\nfield. We present a custom portable EEG-based Brain-Computer Interface (BCI)\nthat exploits Event-Related Potentials (ERPs) induced with an oddball\nexperimental paradigm to control the infotainment menu of a car. A preliminary\nevaluation of the system was performed on 10 participants in a standard\nlaboratory setting and while driving on a closed private track. The task\nconsisted of repeated presentations of 6 different menu icons in oddball\nfashion. Subject-specific models were trained with different machine learning\napproaches on cerebral data from either only laboratory or driving experiments\n(in-lab and in-car models) or a combination of the two (hybrid model) to\nclassify EEG responses to target and non-target stimuli. All models were tested\non the subjects' last in-car sessions that were not used for the training.\nAnalysis of ERPs amplitude showed statistically significant (p < 0.05)\ndifferences between the EEG responses associated with target and non-target\nicons, both in the laboratory and while driving. Classification Accuracy (CA)\nwas above chance level for all subjects in all training configurations, with a\ndeep CNN trained on the hybrid set achieving the highest scores (mean CA = 53\n$\\pm$ 12 %, with 16 % chance level for the 6-class discrimination). The ranking\nof the features importance provided by a classical BCI approach suggests an\nERP-based discrimination between target and non-target responses. No\nstatistical differences were observed between the CAs for the in-lab and in-car\ntraining sets, nor between the EEG responses in these conditions, indicating\nthat the data collected in the standard laboratory setting could be readily\nused for a real driving application without a noticeable decrease in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:32:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bellotti", "Andrea", ""], ["Antopolskiy", "Sergey", ""], ["Marchenkova", "Anna", ""], ["Colucciello", "Alessia", ""], ["Avanzini", "Pietro", ""], ["Vecchiato", "Giovanni", ""], ["Ambeck-Madsen", "Jonas", ""], ["Ascari", "Luca", ""]]}, {"id": "2004.11985", "submitter": "Nina Varney", "authors": "Nina Varney, Vijayan K. Asari and Quinn Graehling", "title": "DALES: A Large-scale Aerial LiDAR Data Set for Semantic Segmentation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Dayton Annotated LiDAR Earth Scan (DALES) data set, a new\nlarge-scale aerial LiDAR data set with over a half-billion hand-labeled points\nspanning 10 square kilometers of area and eight object categories. Large\nannotated point cloud data sets have become the standard for evaluating deep\nlearning methods. However, most of the existing data sets focus on data\ncollected from a mobile or terrestrial scanner with few focusing on aerial\ndata. Point cloud data collected from an Aerial Laser Scanner (ALS) presents a\nnew set of challenges and applications in areas such as 3D urban modeling and\nlarge-scale surveillance. DALES is the most extensive publicly available ALS\ndata set with over 400 times the number of points and six times the resolution\nof other currently available annotated aerial point cloud data sets. This data\nset gives a critical number of expert verified hand-labeled points for the\nevaluation of new 3D deep learning algorithms, helping to expand the focus of\ncurrent algorithms to aerial data. We describe the nature of our data,\nannotation workflow, and provide a benchmark of current state-of-the-art\nalgorithm performance on the DALES data set.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 20:05:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Varney", "Nina", ""], ["Asari", "Vijayan K.", ""], ["Graehling", "Quinn", ""]]}, {"id": "2004.11986", "submitter": "Minghao Ye", "authors": "Junjie Zhang, Minghao Ye, Zehua Guo, Chen-Yu Yen, H. Jonathan Chao", "title": "CFR-RL: Traffic Engineering with Reinforcement Learning in SDN", "comments": "This article has been accepted for inclusion in a future issue of\n  IEEE Journal on Selected Areas in Communications Special Issue on Advances in\n  Artificial Intelligence and Machine Learning for Networking", "journal-ref": null, "doi": "10.1109/JSAC.2020.3000371", "report-no": null, "categories": "cs.NI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Traffic Engineering (TE) solutions can achieve the optimal or\nnear-optimal performance by rerouting as many flows as possible. However, they\ndo not usually consider the negative impact, such as packet out of order, when\nfrequently rerouting flows in the network. To mitigate the impact of network\ndisturbance, one promising TE solution is forwarding the majority of traffic\nflows using Equal-Cost Multi-Path (ECMP) and selectively rerouting a few\ncritical flows using Software-Defined Networking (SDN) to balance link\nutilization of the network. However, critical flow rerouting is not trivial\nbecause the solution space for critical flow selection is enormous. Moreover,\nit is impossible to design a heuristic algorithm for this problem based on\nfixed and simple rules, since rule-based heuristics are unable to adapt to the\nchanges of the traffic matrix and network dynamics. In this paper, we propose\nCFR-RL (Critical Flow Rerouting-Reinforcement Learning), a Reinforcement\nLearning-based scheme that learns a policy to select critical flows for each\ngiven traffic matrix automatically. CFR-RL then reroutes these selected\ncritical flows to balance link utilization of the network by formulating and\nsolving a simple Linear Programming (LP) problem. Extensive evaluations show\nthat CFR-RL achieves near-optimal performance by rerouting only 10%-21.3% of\ntotal traffic.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:46:54 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhang", "Junjie", ""], ["Ye", "Minghao", ""], ["Guo", "Zehua", ""], ["Yen", "Chen-Yu", ""], ["Chao", "H. Jonathan", ""]]}, {"id": "2004.11992", "submitter": "Bram Wallace", "authors": "Bram Wallace, Bharath Hariharan", "title": "Extending and Analyzing Self-Supervised Learning Across Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-supervised representation learning has achieved impressive results in\nrecent years, with experiments primarily coming on ImageNet or other similarly\nlarge internet imagery datasets. There has been little to no work with these\nmethods on other smaller domains, such as satellite, textural, or biological\nimagery. We experiment with several popular methods on an unprecedented variety\nof domains. We discover, among other findings, that Rotation is by far the most\nsemantically meaningful task, with much of the performance of Jigsaw and\nInstance Discrimination being attributable to the nature of their induced\ndistribution rather than semantic understanding. Additionally, there are\nseveral areas, such as fine-grain classification, where all tasks underperform.\nWe quantitatively and qualitatively diagnose the reasons for these failures and\nsuccesses via novel experiments studying pretext generalization, random\nlabelings, and implicit dimensionality. Code and models are available at\nhttps://github.com/BramSW/Extending_SSRL_Across_Domains/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:18:02 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 16:13:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wallace", "Bram", ""], ["Hariharan", "Bharath", ""]]}, {"id": "2004.11994", "submitter": "Tanwi Mallick", "authors": "Tanwi Mallick and Patha Pratim Das and Arun Kumar Majumdar", "title": "Bharatanatyam Dance Transcription using Multimedia Ontology and Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indian Classical Dance is an over 5000 years' old multi-modal language for\nexpressing emotions. Preservation of dance through multimedia technology is a\nchallenging task. In this paper, we develop a system to generate a parseable\nrepresentation of a dance performance. The system will help to preserve\nintangible heritage, annotate performances for better tutoring, and synthesize\ndance performances. We first attempt to capture the concepts of the basic steps\nof an Indian Classical Dance form, named Bharatanatyam Adavus, in an\nontological model. Next, we build an event-based low-level model that relates\nthe ontology of Adavus to the ontology of multi-modal data streams (RGB-D of\nKinect in this case) for a computationally realizable framework. Finally, the\nontology is used for transcription into Labanotation. We also present a\ntranscription tool for encoding the performances of Bharatanatyam Adavus to\nLabanotation and test it on our recorded data set. Our primary aim is to\ndocument the complex movements of dance in terms of Labanotation using the\nontology.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:22:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mallick", "Tanwi", ""], ["Das", "Patha Pratim", ""], ["Majumdar", "Arun Kumar", ""]]}, {"id": "2004.11995", "submitter": "Oliver Scheel", "authors": "Oliver Scheel, Loren Schwarz, Nassir Navab, Federico Tombari", "title": "Explicit Domain Adaptation with Loosely Coupled Samples", "comments": "Submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning is an important field of machine learning in general, and\nparticularly in the context of fully autonomous driving, which needs to be\nsolved simultaneously for many different domains, such as changing weather\nconditions and country-specific driving behaviors. Traditional transfer\nlearning methods often focus on image data and are black-box models. In this\nwork we propose a transfer learning framework, core of which is learning an\nexplicit mapping between domains. Due to its interpretability, this is\nbeneficial for safety-critical applications, like autonomous driving. We show\nits general applicability by considering image classification problems and then\nmove on to time-series data, particularly predicting lane changes. In our\nevaluation we adapt a pre-trained model to a dataset exhibiting different\ndriving and sensory characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:23:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Scheel", "Oliver", ""], ["Schwarz", "Loren", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "2004.12000", "submitter": "Egor Burkov", "authors": "Egor Burkov, Igor Pasechnik, Artur Grigorev, Victor Lempitsky", "title": "Neural Head Reenactment with Latent Pose Descriptors", "comments": null, "journal-ref": "2020 IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR). pp. 13783-13792", "doi": "10.1109/CVPR42600.2020.01380", "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural head reenactment system, which is driven by a latent pose\nrepresentation and is capable of predicting the foreground segmentation\nalongside the RGB image. The latent pose representation is learned as a part of\nthe entire reenactment system, and the learning process is based solely on\nimage reconstruction losses. We show that despite its simplicity, with a large\nand diverse enough training dataset, such learning successfully decomposes pose\nfrom identity. The resulting system can then reproduce mimics of the driving\nperson and, furthermore, can perform cross-person reenactment. Additionally, we\nshow that the learned descriptors are useful for other pose-related tasks, such\nas keypoint prediction and pose-based retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 21:37:52 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 13:37:15 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Burkov", "Egor", ""], ["Pasechnik", "Igor", ""], ["Grigorev", "Artur", ""], ["Lempitsky", "Victor", ""]]}, {"id": "2004.12019", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Philip M. Long", "title": "Finite-sample Analysis of Interpolating Linear Classifiers in the\n  Overparameterized Regime", "comments": "Corrected typographical errors from the previous version of this\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds on the population risk of the maximum margin algorithm for\ntwo-class linear classification. For linearly separable training data, the\nmaximum margin algorithm has been shown in previous work to be equivalent to a\nlimit of training with logistic loss using gradient descent, as the training\nerror is driven to zero. We analyze this algorithm applied to random data\nincluding misclassification noise. Our assumptions on the clean data include\nthe case in which the class-conditional distributions are standard normal\ndistributions. The misclassification noise may be chosen by an adversary,\nsubject to a limit on the fraction of corrupted labels. Our bounds show that,\nwith sufficient over-parameterization, the maximum margin algorithm trained on\nnoisy data can achieve nearly optimal population risk.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:06:18 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 05:46:13 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 21:45:53 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 18:03:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Long", "Philip M.", ""]]}, {"id": "2004.12028", "submitter": "Jixiong Wang", "authors": "Jixiong Wang, Ashish Patel, James M.S. Wason, Paul J. Newcombe", "title": "Two-Stage Penalized Regression Screening to Detect Biomarker-Treatment\n  Interactions in Randomized Clinical Trials", "comments": "Accepted version, to be published in Biometrics", "journal-ref": null, "doi": "10.1111/biom.13424", "report-no": null, "categories": "stat.ME cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional biomarkers such as genomics are increasingly being measured\nin randomized clinical trials. Consequently, there is a growing interest in\ndeveloping methods that improve the power to detect biomarker-treatment\ninteractions. We adapt recently proposed two-stage interaction detecting\nprocedures in the setting of randomized clinical trials. We also propose a new\nstage 1 multivariate screening strategy using ridge regression to account for\ncorrelations among biomarkers. For this multivariate screening, we prove the\nasymptotic between-stage independence, required for family-wise error rate\ncontrol, under biomarker-treatment independence. Simulation results show that\nin various scenarios, the ridge regression screening procedure can provide\nsubstantially greater power than the traditional one-biomarker-at-a-time\nscreening procedure in highly correlated data. We also exemplify our approach\nin two real clinical trial data applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:50:09 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 19:48:30 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Wang", "Jixiong", ""], ["Patel", "Ashish", ""], ["Wason", "James M. S.", ""], ["Newcombe", "Paul J.", ""]]}, {"id": "2004.12031", "submitter": "Zakaria Aldeneh", "authors": "Zakaria Aldeneh, Anushree Prasanna Kumar, Barry-John Theobald, Erik\n  Marchi, Sachin Kajarekar, Devang Naik, Ahmed Hussen Abdelaziz", "title": "On the Role of Visual Cues in Audiovisual Speech Enhancement", "comments": "ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an introspection of an audiovisual speech enhancement model. In\nparticular, we focus on interpreting how a neural audiovisual speech\nenhancement model uses visual cues to improve the quality of the target speech\nsignal. We show that visual cues provide not only high-level information about\nspeech activity, i.e., speech/silence, but also fine-grained visual information\nabout the place of articulation. One byproduct of this finding is that the\nlearned visual embeddings can be used as features for other visual speech\napplications. We demonstrate the effectiveness of the learned visual embeddings\nfor classifying visemes (the visual analogy to phonemes). Our results provide\ninsight into important aspects of audiovisual speech enhancement and\ndemonstrate how such models can be used for self-supervision tasks for visual\nspeech applications.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 01:00:03 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:27:47 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 17:11:24 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 15:56:42 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Aldeneh", "Zakaria", ""], ["Kumar", "Anushree Prasanna", ""], ["Theobald", "Barry-John", ""], ["Marchi", "Erik", ""], ["Kajarekar", "Sachin", ""], ["Naik", "Devang", ""], ["Abdelaziz", "Ahmed Hussen", ""]]}, {"id": "2004.12032", "submitter": "Sang Hun Lee", "authors": "Sangrok Lee, Eunsoo Park, Hongsuk Yi, Sang Hun Lee", "title": "StRDAN: Synthetic-to-Real Domain Adaptation Network for Vehicle\n  Re-Identification", "comments": "7 pages, 2 figures, CVPR Workshop Paper (Revised)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vehicle re-identification aims to obtain the same vehicles from vehicle\nimages. This is challenging but essential for analyzing and predicting traffic\nflow in the city. Although deep learning methods have achieved enormous\nprogress for this task, their large data requirement is a critical shortcoming.\nTherefore, we propose a synthetic-to-real domain adaptation network (StRDAN)\nframework, which can be trained with inexpensive large-scale synthetic and real\ndata to improve performance. The StRDAN training method combines domain\nadaptation and semi-supervised learning methods and their associated losses.\nStRDAN offers significant improvement over the baseline model, which can only\nbe trained using real data, for VeRi and CityFlow-ReID datasets, achieving 3.1%\nand 12.9% improved mean average precision, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 01:00:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 07:44:10 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Lee", "Sangrok", ""], ["Park", "Eunsoo", ""], ["Yi", "Hongsuk", ""], ["Lee", "Sang Hun", ""]]}, {"id": "2004.12041", "submitter": "Gina Adam", "authors": "Siyuan Huang, Brian D. Hoskins, Matthew W. Daniels, Mark D. Stiles,\n  Gina C. Adam", "title": "Memory-efficient training with streaming dimensionality reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The movement of large quantities of data during the training of a Deep Neural\nNetwork presents immense challenges for machine learning workloads. To minimize\nthis overhead, especially on the movement and calculation of gradient\ninformation, we introduce streaming batch principal component analysis as an\nupdate algorithm. Streaming batch principal component analysis uses stochastic\npower iterations to generate a stochastic k-rank approximation of the network\ngradient. We demonstrate that the low rank updates produced by streaming batch\nprincipal component analysis can effectively train convolutional neural\nnetworks on a variety of common datasets, with performance comparable to\nstandard mini batch gradient descent. These results can lead to both\nimprovements in the design of application specific integrated circuits for deep\nlearning and in the speed of synchronization of machine learning models trained\nwith data parallelism.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 02:13:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Huang", "Siyuan", ""], ["Hoskins", "Brian D.", ""], ["Daniels", "Matthew W.", ""], ["Stiles", "Mark D.", ""], ["Adam", "Gina C.", ""]]}, {"id": "2004.12058", "submitter": "Mohamed Abdelpakey", "authors": "Mohamed H. Abdelpakey, Mohamed S. Shehata", "title": "NullSpaceNet: Nullspace Convoluional Neural Network with Differentiable\n  Loss Function", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose NullSpaceNet, a novel network that maps from the pixel level input\nto a joint-nullspace (as opposed to the traditional feature space), where the\nnewly learned joint-nullspace features have clearer interpretation and are more\nseparable. NullSpaceNet ensures that all inputs from the same class are\ncollapsed into one point in this new joint-nullspace, and the different classes\nare collapsed into different points with high separation margins. Moreover, a\nnovel differentiable loss function is proposed that has a closed-form solution\nwith no free-parameters. NullSpaceNet exhibits superior performance when tested\nagainst VGG16 with fully-connected layer over 4 different datasets, with\naccuracy gain of up to 4.55%, a reduction in learnable parameters from 135M to\n19M, and reduction in inference time of 99% in favor of NullSpaceNet. This\nmeans that NullSpaceNet needs less than 1% of the time it takes a traditional\nCNN to classify a batch of images with better accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 04:58:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Abdelpakey", "Mohamed H.", ""], ["Shehata", "Mohamed S.", ""]]}, {"id": "2004.12059", "submitter": "Di Zhuang", "authors": "Di Zhuang, Nam Nguyen, Keyu Chen, J. Morris Chang", "title": "SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare\n  System", "comments": "17 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the advancement of deep learning (DL), the Internet of Things and cloud\ncomputing techniques for biomedical and healthcare problems, mobile healthcare\nsystems have received unprecedented attention. Since DL techniques usually\nrequire enormous amount of computation, most of them cannot be directly\ndeployed on the resource-constrained mobile and IoT devices. Hence, most of the\nmobile healthcare systems leverage the cloud computing infrastructure, where\nthe data collected by the mobile and IoT devices would be transmitted to the\ncloud computing platforms for analysis. However, in the contested environments,\nrelying on the cloud might not be practical at all times. For instance, the\nsatellite communication might be denied or disrupted. We propose SAIA, a Split\nArtificial Intelligence Architecture for mobile healthcare systems. Unlike\ntraditional approaches for artificial intelligence (AI) which solely exploits\nthe computational power of the cloud server, SAIA could not only relies on the\ncloud computing infrastructure while the wireless communication is available,\nbut also utilizes the lightweight AI solutions that work locally on the client\nside, hence, it can work even when the communication is impeded. In SAIA, we\npropose a meta-information based decision unit, that could tune whether a\nsample captured by the client should be operated by the embedded AI (i.e.,\nkeeping on the client) or the networked AI (i.e., sending to the server), under\ndifferent conditions. In our experimental evaluation, extensive experiments\nhave been conducted on two popular healthcare datasets. Our results show that\nSAIA consistently outperforms its baselines in terms of both effectiveness and\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 05:06:51 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 05:00:59 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhuang", "Di", ""], ["Nguyen", "Nam", ""], ["Chen", "Keyu", ""], ["Chang", "J. Morris", ""]]}, {"id": "2004.12064", "submitter": "Di Zhuang", "authors": "Di Zhuang, Keyu Chen, J. Morris Chang", "title": "CS-AF: A Cost-sensitive Multi-classifier Active Fusion Framework for\n  Skin Lesion Classification", "comments": "16 pages, 8 figures, 2 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have achieved the state-of-the-art\nperformance in skin lesion analysis. Compared with single CNN classifier,\ncombining the results of multiple classifiers via fusion approaches shows to be\nmore effective and robust. Since the skin lesion datasets are usually limited\nand statistically biased, while designing an effective fusion approach, it is\nimportant to consider not only the performance of each classifier on the\ntraining/validation dataset, but also the relative discriminative power (e.g.,\nconfidence) of each classifier regarding an individual sample in the testing\nphase, which calls for an active fusion approach. Furthermore, in skin lesion\nanalysis, the data of certain classes (e.g., the benign lesions) is usually\nabundant making them an over-represented majority, while the data of some other\nclasses (e.g., the cancerous lesions) is deficient, making them an\nunderrepresented minority. It is more crucial to precisely identify the samples\nfrom an underrepresented (i.e., in terms of the amount of data) but more\nimportant minority class (e.g., certain cancerous lesion). In other words,\nmisclassifying a more severe lesion to a benign or less severe lesion should\nhave relative more cost (e.g., money, time and even lives). To address such\nchallenges, we present CS-AF, a cost-sensitive multi-classifier active fusion\nframework for skin lesion classification. In the experimental evaluation, we\nprepared 96 base classifiers (of 12 CNN architectures) on the ISIC research\ndatasets. Our experimental results show that our framework consistently\noutperforms the static fusion competitors.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 05:48:14 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 04:37:03 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Zhuang", "Di", ""], ["Chen", "Keyu", ""], ["Chang", "J. Morris", ""]]}, {"id": "2004.12069", "submitter": "Shilin Zhu", "authors": "Shilin Zhu, Zexiang Xu, Henrik Wann Jensen, Hao Su, Ravi Ramamoorthi", "title": "Deep Photon Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning-based denoising approaches have led to dramatic\nimprovements in low sample-count Monte Carlo rendering. These approaches are\naimed at path tracing, which is not ideal for simulating challenging light\ntransport effects like caustics, where photon mapping is the method of choice.\nHowever, photon mapping requires very large numbers of traced photons to\nachieve high-quality reconstructions. In this paper, we develop the first deep\nlearning-based method for particle-based rendering, and specifically focus on\nphoton density estimation, the core of all particle-based methods. We train a\nnovel deep neural network to predict a kernel function to aggregate photon\ncontributions at shading points. Our network encodes individual photons into\nper-photon features, aggregates them in the neighborhood of a shading point to\nconstruct a photon local context vector, and infers a kernel function from the\nper-photon and photon local context features. This network is easy to\nincorporate in many previous photon mapping methods (by simply swapping the\nkernel density estimator) and can produce high-quality reconstructions of\ncomplex global illumination effects like caustics with an order of magnitude\nfewer photons compared to previous photon mapping methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 06:59:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhu", "Shilin", ""], ["Xu", "Zexiang", ""], ["Jensen", "Henrik Wann", ""], ["Su", "Hao", ""], ["Ramamoorthi", "Ravi", ""]]}, {"id": "2004.12070", "submitter": "Zhou Yu", "authors": "Zhou Yu, Yuhao Cui, Jun Yu, Meng Wang, Dacheng Tao, Qi Tian", "title": "Deep Multimodal Neural Architecture Search", "comments": "Accept to ACM MM2020, code available at\n  https://github.com/MILVLG/mmnas/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing effective neural networks is fundamentally important in deep\nmultimodal learning. Most existing works focus on a single task and design\nneural architectures manually, which are highly task-specific and hard to\ngeneralize to different tasks. In this paper, we devise a generalized deep\nmultimodal neural architecture search (MMnas) framework for various multimodal\nlearning tasks. Given multimodal input, we first define a set of primitive\noperations, and then construct a deep encoder-decoder based unified backbone,\nwhere each encoder or decoder block corresponds to an operation searched from a\npredefined operation pool. On top of the unified backbone, we attach\ntask-specific heads to tackle different multimodal learning tasks. By using a\ngradient-based NAS algorithm, the optimal architectures for different tasks are\nlearned efficiently. Extensive ablation studies, comprehensive analysis, and\ncomparative experimental results show that the obtained MMnasNet significantly\noutperforms existing state-of-the-art approaches across three multimodal\nlearning tasks (over five datasets), including visual question answering,\nimage-text matching, and visual grounding.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 07:00:32 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 03:28:08 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yu", "Zhou", ""], ["Cui", "Yuhao", ""], ["Yu", "Jun", ""], ["Wang", "Meng", ""], ["Tao", "Dacheng", ""], ["Tian", "Qi", ""]]}, {"id": "2004.12071", "submitter": "Zhong Meng", "authors": "Zhong Meng, M Umair Bin Altaf, Biing-Hwang (Fred) Juang", "title": "Active Voice Authentication", "comments": "39 pages, 4 figures", "journal-ref": "Digital Signal Processing, Volume 101, June 2020, 102672, ISSN\n  1051-2004", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active authentication refers to a new mode of identity verification in which\nbiometric indicators are continuously tested to provide real-time or near\nreal-time monitoring of an authorized access to a service or use of a device.\nThis is in contrast to the conventional authentication systems where a single\ntest in form of a verification token such as a password is performed. In active\nvoice authentication (AVA), voice is the biometric modality. This paper\ndescribes an ensemble of techniques that make reliable speaker verification\npossible using unconventionally short voice test signals. These techniques\ninclude model adaptation and minimum verification error (MVE) training that are\ntailored for the extremely short training and testing requirements. A database\nof 25 speakers is recorded for developing this system. In our off-line\nevaluation on this dataset, the system achieves an average windowed-based equal\nerror rates of 3-4% depending on the model configuration, which is remarkable\nconsidering that only 1 second of voice data is used to make every single\nauthentication decision. On the NIST SRE 2001 Dataset, the system provides a\n3.88% absolute gain over i-vector when the duration of test segment is 1\nsecond. A real-time demonstration system has been implemented on Microsoft\nSurface Pro.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 07:08:41 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Meng", "Zhong", "", "Fred"], ["Altaf", "M Umair Bin", "", "Fred"], ["Biing-Hwang", "", "", "Fred"], ["Juang", "", ""]]}, {"id": "2004.12073", "submitter": "Sho Takase", "authors": "Sho Takase and Sosuke Kobayashi", "title": "All Word Embeddings from One Embedding", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural network-based models for natural language processing (NLP), the\nlargest part of the parameters often consists of word embeddings. Conventional\nmodels prepare a large embedding matrix whose size depends on the vocabulary\nsize. Therefore, storing these models in memory and disk storage is costly. In\nthis study, to reduce the total number of parameters, the embeddings for all\nwords are represented by transforming a shared embedding. The proposed method,\nALONE (all word embeddings from one), constructs the embedding of a word by\nmodifying the shared embedding with a filter vector, which is word-specific but\nnon-trainable. Then, we input the constructed embedding into a feed-forward\nneural network to increase its expressiveness. Naively, the filter vectors\noccupy the same memory size as the conventional embedding matrix, which depends\non the vocabulary size. To solve this issue, we also introduce a\nmemory-efficient filter construction approach. We indicate our ALONE can be\nused as word representation sufficiently through an experiment on the\nreconstruction of pre-trained word embeddings. In addition, we also conduct\nexperiments on NLP application tasks: machine translation and summarization. We\ncombined ALONE with the current state-of-the-art encoder-decoder model, the\nTransformer, and achieved comparable scores on WMT 2014 English-to-German\ntranslation and DUC 2004 very short summarization with less parameters.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 07:38:08 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 03:36:32 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 03:12:12 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Takase", "Sho", ""], ["Kobayashi", "Sosuke", ""]]}, {"id": "2004.12076", "submitter": "Lucas Lamata", "authors": "Lucas Lamata", "title": "Quantum machine learning and quantum biomimetics: A perspective", "comments": "Invited Perspective article for Machine Learning: Science and\n  Technology, 17 pages, 6 figures, 110 references", "journal-ref": "Mach. Learn.: Sci. Technol. 1, 033002 (2020)", "doi": "10.1088/2632-2153/ab9803", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum machine learning has emerged as an exciting and promising paradigm\ninside quantum technologies. It may permit, on the one hand, to carry out more\nefficient machine learning calculations by means of quantum devices, while, on\nthe other hand, to employ machine learning techniques to better control quantum\nsystems. Inside quantum machine learning, quantum reinforcement learning aims\nat developing \"intelligent\" quantum agents that may interact with the outer\nworld and adapt to it, with the strategy of achieving some final goal. Another\nparadigm inside quantum machine learning is that of quantum autoencoders, which\nmay allow one for employing fewer resources in a quantum device via a training\nprocess. Moreover, the field of quantum biomimetics aims at establishing\nanalogies between biological and quantum systems, to look for previously\ninadvertent connections that may enable useful applications. Two recent\nexamples are the concepts of quantum artificial life, as well as of quantum\nmemristors. In this Perspective, we give an overview of these topics,\ndescribing the related research carried out by the scientific community.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 07:45:20 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 07:00:32 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Lamata", "Lucas", ""]]}, {"id": "2004.12084", "submitter": "Jannis Born", "authors": "Jannis Born, Gabriel Br\\\"andle, Manuel Cossio, Marion Disdier, Julie\n  Goulet, J\\'er\\'emie Roulin, Nina Wiedemann", "title": "POCOVID-Net: Automatic Detection of COVID-19 From a New Lung Ultrasound\n  Imaging Dataset (POCUS)", "comments": "7 pages, 4 figures", "journal-ref": "ISMB TransMed COSI 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid development of COVID-19 into a global pandemic, there is an\never more urgent need for cheap, fast and reliable tools that can assist\nphysicians in diagnosing COVID-19. Medical imaging such as CT can take a key\nrole in complementing conventional diagnostic tools from molecular biology,\nand, using deep learning techniques, several automatic systems were\ndemonstrated promising performances using CT or X-ray data. Here, we advocate a\nmore prominent role of point-of-care ultrasound imaging to guide COVID-19\ndetection. Ultrasound is non-invasive and ubiquitous in medical facilities\naround the globe. Our contribution is threefold. First, we gather a lung\nultrasound (POCUS) dataset consisting of 1103 images (654 COVID-19, 277\nbacterial pneumonia and 172 healthy controls), sampled from 64 videos. This\ndataset was assembled from various online sources, processed specifically for\ndeep learning models and is intended to serve as a starting point for an\nopen-access initiative. Second, we train a deep convolutional neural network\n(POCOVID-Net) on this 3-class dataset and achieve an accuracy of 89% and, by a\nmajority vote, a video accuracy of 92% . For detecting COVID-19 in particular,\nthe model performs with a sensitivity of 0.96, a specificity of 0.79 and\nF1-score of 0.92 in a 5-fold cross validation. Third, we provide an open-access\nweb service (POCOVIDScreen) that is available at: https://pocovidscreen.org.\nThe website deploys the predictive model, allowing to perform predictions on\nultrasound lung images. In addition, it grants medical staff the option to\n(bulk) upload their own screenings in order to contribute to the growing public\ndatabase of pathological lung ultrasound images.\n  Dataset and code are available from:\nhttps://github.com/jannisborn/covid19_pocus_ultrasound.\n  NOTE: This preprint is superseded by our paper in Applied Sciences:\nhttps://doi.org/10.3390/app11020672\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:41:24 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 08:20:23 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 11:30:39 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2021 13:37:44 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Born", "Jannis", ""], ["Br\u00e4ndle", "Gabriel", ""], ["Cossio", "Manuel", ""], ["Disdier", "Marion", ""], ["Goulet", "Julie", ""], ["Roulin", "J\u00e9r\u00e9mie", ""], ["Wiedemann", "Nina", ""]]}, {"id": "2004.12088", "submitter": "Chandra Thapa", "authors": "Chandra Thapa, M.A.P. Chamikara, Seyit Camtepe", "title": "SplitFed: When Federated Learning Meets Split Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) and split learning (SL) are two recent distributed\nmachine learning (ML) approaches that have gained attention due to their\ninherent privacy-preserving capabilities. Both approaches follow a\nmodel-to-data scenario, in that an ML model is sent to clients for network\ntraining and testing. However, FL and SL show contrasting strengths and\nweaknesses. For example, while FL performs faster than SL due to its parallel\nclient-side model generation strategy, SL provides better privacy than FL due\nto the ML model architecture split between clients and the server. In contrast\nto FL, SL enables ML training with clients having low computing resources as\nthe client trains only the first few layers of the split ML network model. In\nthis paper, we present a novel approach, named splitfed (SFL), that amalgamates\nthe two approaches eliminating their inherent drawbacks. SFL splits the network\narchitecture between the clients and server as in SL to provide a higher level\nof privacy than FL. Moreover, it offers better efficiency than SL by\nincorporating the parallel ML model update paradigm of FL. Our empirical\nresults, on uniformly distributed horizontally partitioned HAM10000 and MNIST\ndatasets with multiple clients, show that SFL provides similar communication\nefficiency and test accuracy as SL, while significantly decreasing - by four to\nsix times - its computation time per global epoch than in SL for both datasets.\nFurthermore, as in SL, its communication efficiency over FL improves with the\nnumber of clients. To further enhance privacy, we integrate a differentially\nprivate local model training mechanism to SFL and test its performance on\nAlexNet with the MNIST dataset under various privacy levels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:52:50 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 04:52:29 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Thapa", "Chandra", ""], ["Chamikara", "M. A. P.", ""], ["Camtepe", "Seyit", ""]]}, {"id": "2004.12092", "submitter": "Kasun Bandara", "authors": "Kasun Bandara, Christoph Bergmeir, Sam Campbell, Deborah Scott, Dan\n  Lubman", "title": "Towards Accurate Predictions and Causal 'What-if' Analyses for Planning\n  and Policy-making: A Case Study in Emergency Medical Services Demand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency Medical Services (EMS) demand load has become a considerable burden\nfor many government authorities, and EMS demand is often an early indicator for\nstress in communities, a warning sign of emerging problems. In this paper, we\nintroduce Deep Planning and Policy Making Net (DeepPPMNet), a Long Short-Term\nMemory network based, global forecasting and inference framework to forecast\nthe EMS demand, analyse causal relationships, and perform `what-if' analyses\nfor policy-making across multiple local government areas. Unless traditional\nunivariate forecasting techniques, the proposed method follows the global\nforecasting methodology, where a model is trained across all the available EMS\ndemand time series to exploit the potential cross-series information available.\nDeepPPMNet also uses seasonal decomposition techniques, incorporated in two\ndifferent training paradigms into the framework, to suit various\ncharacteristics of the EMS related time series data. We then explore causal\nrelationships using the notion of Granger Causality, where the global\nforecasting framework enables us to perform `what-if' analyses that could be\nused for the national policy-making process. We empirically evaluate our\nmethod, using a set of EMS datasets related to alcohol, drug use and self-harm\nin Australia. The proposed framework is able to outperform many\nstate-of-the-art techniques and achieve competitive results in terms of\nforecasting accuracy. We finally illustrate its use for policy-making in an\nexample regarding alcohol outlet licenses.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 09:03:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bandara", "Kasun", ""], ["Bergmeir", "Christoph", ""], ["Campbell", "Sam", ""], ["Scott", "Deborah", ""], ["Lubman", "Dan", ""]]}, {"id": "2004.12094", "submitter": "Tong Li", "authors": "Mingyang Zhang, Tong Li, Yue Yu, Yong Li, Pan Hui, Yu Zheng", "title": "Urban Anomaly Analytics: Description, Detection, and Prediction", "comments": "Accepted by IEEE Transactions on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban anomalies may result in loss of life or property if not handled\nproperly. Automatically alerting anomalies in their early stage or even\npredicting anomalies before happening are of great value for populations.\nRecently, data-driven urban anomaly analysis frameworks have been forming,\nwhich utilize urban big data and machine learning algorithms to detect and\npredict urban anomalies automatically. In this survey, we make a comprehensive\nreview of the state-of-the-art research on urban anomaly analytics. We first\ngive an overview of four main types of urban anomalies, traffic anomaly,\nunexpected crowds, environment anomaly, and individual anomaly. Next, we\nsummarize various types of urban datasets obtained from diverse devices, i.e.,\ntrajectory, trip records, CDRs, urban sensors, event records, environment data,\nsocial media and surveillance cameras. Subsequently, a comprehensive survey of\nissues on detecting and predicting techniques for urban anomalies is presented.\nFinally, research challenges and open problems as discussed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 09:23:41 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Mingyang", ""], ["Li", "Tong", ""], ["Yu", "Yue", ""], ["Li", "Yong", ""], ["Hui", "Pan", ""], ["Zheng", "Yu", ""]]}, {"id": "2004.12117", "submitter": "Reza Refaei", "authors": "Reza Refaei Afshar and Yingqian Zhang and Murat Firat and Uzay Kaymak", "title": "A State Aggregation Approach for Solving Knapsack Problem with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Deep Reinforcement Learning (DRL) approach for solving\nknapsack problem. The proposed method consists of a state aggregation step\nbased on tabular reinforcement learning to extract features and construct\nstates. The state aggregation policy is applied to each problem instance of the\nknapsack problem, which is used with Advantage Actor Critic (A2C) algorithm to\ntrain a policy through which the items are sequentially selected at each time\nstep. The method is a constructive solution approach and the process of\nselecting items is repeated until the final solution is obtained. The\nexperiments show that our approach provides close to optimal solutions for all\ntested instances, outperforms the greedy algorithm, and is able to handle\nlarger instances and more flexible than an existing DRL approach. In addition,\nthe results demonstrate that the proposed model with the state aggregation\nstrategy not only gives better solutions but also learns in less timesteps,\nthan the one without state aggregation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 11:52:24 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Afshar", "Reza Refaei", ""], ["Zhang", "Yingqian", ""], ["Firat", "Murat", ""], ["Kaymak", "Uzay", ""]]}, {"id": "2004.12130", "submitter": "Philip Nadler", "authors": "Philip Nadler, Shuo Wang, Rossella Arcucci, Xian Yang, Yike Guo", "title": "An Epidemiological Modelling Approach for Covid19 via Data Assimilation", "comments": "Initial conference version accepted at International Conference of\n  Machine Learning(ICML) workshop. Extended journal version was published in\n  the European Journal of Epidemiology\n  (https://doi.org/10.1007/s10654-020-00676-7). Please cite as accordingly", "journal-ref": null, "doi": "10.1007/s10654-020-00676-7", "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global pandemic of the 2019-nCov requires the evaluation of policy\ninterventions to mitigate future social and economic costs of quarantine\nmeasures worldwide. We propose an epidemiological model for forecasting and\npolicy evaluation which incorporates new data in real-time through variational\ndata assimilation. We analyze and discuss infection rates in China, the US and\nItaly. In particular, we develop a custom compartmental SIR model fit to\nvariables related to the epidemic in Chinese cities, named SITR model. We\ncompare and discuss model results which conducts updates as new observations\nbecome available. A hybrid data assimilation approach is applied to make\nresults robust to initial conditions. We use the model to do inference on\ninfection numbers as well as parameters such as the disease transmissibility\nrate or the rate of recovery. The parameterisation of the model is parsimonious\nand extendable, allowing for the incorporation of additional data and\nparameters of interest. This allows for scalability and the extension of the\nmodel to other locations or the adaption of novel data sources.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:46:36 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 16:11:32 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 12:48:52 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Nadler", "Philip", ""], ["Wang", "Shuo", ""], ["Arcucci", "Rossella", ""], ["Yang", "Xian", ""], ["Guo", "Yike", ""]]}, {"id": "2004.12131", "submitter": "Philipp Petersen", "authors": "Moritz Geist, Philipp Petersen, Mones Raslan, Reinhold Schneider,\n  Gitta Kutyniok", "title": "Numerical Solution of the Parametric Diffusion Equation by Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a comprehensive numerical study of the effect of\napproximation-theoretical results for neural networks on practical learning\nproblems in the context of numerical analysis. As the underlying model, we\nstudy the machine-learning-based solution of parametric partial differential\nequations. Here, approximation theory predicts that the performance of the\nmodel should depend only very mildly on the dimension of the parameter space\nand is determined by the intrinsic dimension of the solution manifold of the\nparametric partial differential equation. We use various methods to establish\ncomparability between test-cases by minimizing the effect of the choice of\ntest-cases on the optimization and sampling aspects of the learning problem. We\nfind strong support for the hypothesis that approximation-theoretical effects\nheavily influence the practical behavior of learning problems in numerical\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:48:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Geist", "Moritz", ""], ["Petersen", "Philipp", ""], ["Raslan", "Mones", ""], ["Schneider", "Reinhold", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "2004.12157", "submitter": "Roger Guimera", "authors": "Roger Guimera and Ignasi Reichardt and Antoni Aguilar-Mogas and\n  Francesco A Massucci and Manuel Miranda and Jordi Pallares and Marta\n  Sales-Pardo", "title": "A Bayesian machine scientist to aid in the solution of challenging\n  scientific problems", "comments": null, "journal-ref": "Sci. Adv. 6 (5) , eaav6971 (2020)", "doi": "10.1126/sciadv.aav6971", "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Closed-form, interpretable mathematical models have been instrumental for\nadvancing our understanding of the world; with the data revolution, we may now\nbe in a position to uncover new such models for many systems from physics to\nthe social sciences. However, to deal with increasing amounts of data, we need\n\"machine scientists\" that are able to extract these models automatically from\ndata. Here, we introduce a Bayesian machine scientist, which establishes the\nplausibility of models using explicit approximations to the exact marginal\nposterior over models and establishes its prior expectations about models by\nlearning from a large empirical corpus of mathematical expressions. It explores\nthe space of models using Markov chain Monte Carlo. We show that this approach\nuncovers accurate models for synthetic and real data and provides out-of-sample\npredictions that are more accurate than those of existing approaches and of\nother nonparametric methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:42:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Guimera", "Roger", ""], ["Reichardt", "Ignasi", ""], ["Aguilar-Mogas", "Antoni", ""], ["Massucci", "Francesco A", ""], ["Miranda", "Manuel", ""], ["Pallares", "Jordi", ""], ["Sales-Pardo", "Marta", ""]]}, {"id": "2004.12164", "submitter": "Xiao Guo", "authors": "Xiao Guo, Yixuan Qiu, Hai Zhang, Xiangyu Chang", "title": "Randomized spectral co-clustering for large-scale directed networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed networks are generally used to represent asymmetric relationships\namong units. Co-clustering aims to cluster the senders and receivers of\ndirected networks simultaneously. In particular, the well-known spectral\nclustering algorithm could be modified as the spectral co-clustering to\nco-cluster directed networks. However, large-scale networks pose computational\nchallenge to it. In this paper, we leverage randomized sketching techniques to\naccelerate the spectral co-clustering algorithms in order to co-cluster\nlarge-scale directed networks more efficiently. Specifically, we derive two\nseries of randomized spectral co-clustering algorithms, one is\nrandom-projection-based and the other is random-sampling-based. Theoretically,\nwe analyze the resulting algorithms under two generative models\\textendash the\n\\emph{stochastic co-block model} and the \\emph{degree corrected stochastic\nco-block model}. The approximation error rates and misclustering error rates of\nproposed two randomized spectral co-clustering algorithms are established,\nwhich indicate better bounds than the state-of-the-art results of co-clustering\nliterature. Numerically, we conduct simulations to support our theoretical\nresults and test the efficiency of the algorithms on real networks with up to\ntens of millions of nodes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 15:00:55 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:09:54 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Guo", "Xiao", ""], ["Qiu", "Yixuan", ""], ["Zhang", "Hai", ""], ["Chang", "Xiangyu", ""]]}, {"id": "2004.12169", "submitter": "Sheena Panthaplackel", "authors": "Sheena Panthaplackel, Pengyu Nie, Milos Gligoric, Junyi Jessy Li,\n  Raymond J. Mooney", "title": "Learning to Update Natural Language Comments Based on Code Changes", "comments": "Accepted in Association for Computational Linguistics (ACL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the novel task of automatically updating an existing natural\nlanguage comment based on changes in the body of code it accompanies. We\npropose an approach that learns to correlate changes across two distinct\nlanguage representations, to generate a sequence of edits that are applied to\nthe existing comment to reflect the source code modifications. We train and\nevaluate our model using a dataset that we collected from commit histories of\nopen-source software projects, with each example consisting of a concurrent\nupdate to a method and its corresponding comment. We compare our approach\nagainst multiple baselines using both automatic metrics and human evaluation.\nResults reflect the challenge of this task and that our model outperforms\nbaselines with respect to making edits.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 15:37:46 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 02:53:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Panthaplackel", "Sheena", ""], ["Nie", "Pengyu", ""], ["Gligoric", "Milos", ""], ["Li", "Junyi Jessy", ""], ["Mooney", "Raymond J.", ""]]}, {"id": "2004.12186", "submitter": "Daniel Groos", "authors": "Daniel Groos, Heri Ramampiaro, Espen A. F. Ihlen", "title": "EfficientPose: Scalable single-person pose estimation", "comments": "Published in Applied Intelligence Journal (APIN)", "journal-ref": "Applied Intelligence 51 (2021) 2518-2533", "doi": "10.1007/s10489-020-01918-7", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-person human pose estimation facilitates markerless movement analysis\nin sports, as well as in clinical applications. Still, state-of-the-art models\nfor human pose estimation generally do not meet the requirements of real-life\napplications. The proliferation of deep learning techniques has resulted in the\ndevelopment of many advanced approaches. However, with the progresses in the\nfield, more complex and inefficient models have also been introduced, which\nhave caused tremendous increases in computational demands. To cope with these\ncomplexity and inefficiency challenges, we propose a novel convolutional neural\nnetwork architecture, called EfficientPose, which exploits recently proposed\nEfficientNets in order to deliver efficient and scalable single-person pose\nestimation. EfficientPose is a family of models harnessing an effective\nmulti-scale feature extractor and computationally efficient detection blocks\nusing mobile inverted bottleneck convolutions, while at the same time ensuring\nthat the precision of the pose configurations is still improved. Due to its low\ncomplexity and efficiency, EfficientPose enables real-world applications on\nedge devices by limiting the memory footprint and computational cost. The\nresults from our experiments, using the challenging MPII single-person\nbenchmark, show that the proposed EfficientPose models substantially outperform\nthe widely-used OpenPose model both in terms of accuracy and computational\nefficiency. In particular, our top-performing model achieves state-of-the-art\naccuracy on single-person MPII, with low-complexity ConvNets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 16:50:46 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 09:27:44 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Groos", "Daniel", ""], ["Ramampiaro", "Heri", ""], ["Ihlen", "Espen A. F.", ""]]}, {"id": "2004.12199", "submitter": "Alexander Jung", "authors": "Alexander Jung and Yasmin SarcheshmehPour", "title": "Local Graph Clustering with Network Lasso", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3045832", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical and computational properties of a network Lasso\nmethod for local graph clustering. The clusters delivered by nLasso can be\ncharacterized elegantly via network flows between cluster boundary and seed\nnodes. While spectral clustering methods are guided by a minimization of the\ngraph Laplacian quadratic form, nLasso minimizes the total variation of cluster\nindicator signals. As demonstrated theoretically and numerically, nLasso\nmethods can handle very sparse clusters (chain-like) which are difficult for\nspectral clustering. We also verify that a primal-dual method for nonsmooth\noptimization allows to approximate nLasso solutions with optimal worst-case\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:52:05 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:45:53 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 14:13:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Jung", "Alexander", ""], ["SarcheshmehPour", "Yasmin", ""]]}, {"id": "2004.12204", "submitter": "Eduardo Nigri", "authors": "Eduardo Nigri, Nivio Ziviani, Fabio Cappabianco, Augusto Antunes,\n  Adriano Veloso", "title": "Explainable Deep CNNs for MRI-Based Diagnosis of Alzheimer's Disease", "comments": "Accepted for the IEEE International Joint Conference on Neural\n  Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNNs) are becoming prominent models for\nsemi-automated diagnosis of Alzheimer's Disease (AD) using brain Magnetic\nResonance Imaging (MRI). Although being highly accurate, deep CNN models lack\ntransparency and interpretability, precluding adequate clinical reasoning and\nnot complying with most current regulatory demands. One popular choice for\nexplaining deep image models is occluding regions of the image to isolate their\ninfluence on the prediction. However, existing methods for occluding patches of\nbrain scans generate images outside the distribution to which the model was\ntrained for, thus leading to unreliable explanations. In this paper, we propose\nan alternative explanation method that is specifically designed for the brain\nscan task. Our method, which we refer to as Swap Test, produces heatmaps that\ndepict the areas of the brain that are most indicative of AD, providing\ninterpretability for the model's decisions in a format understandable to\nclinicians. Experimental results using an axiomatic evaluation show that the\nproposed method is more suitable for explaining the diagnosis of AD using MRI\nwhile the opposite trend was observed when using a typical occlusion test.\nTherefore, we believe our method may address the inherent black-box nature of\ndeep neural networks that are capable of diagnosing AD.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:14:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Nigri", "Eduardo", ""], ["Ziviani", "Nivio", ""], ["Cappabianco", "Fabio", ""], ["Antunes", "Augusto", ""], ["Veloso", "Adriano", ""]]}, {"id": "2004.12209", "submitter": "Yingyi Ma", "authors": "Yingyi Ma, Vignesh Ganapathiraman, Yaoliang Yu, Xinhua Zhang", "title": "Convex Representation Learning for Generalized Invariance in\n  Semi-Inner-Product Space", "comments": "to appear in ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invariance (defined in a general sense) has been one of the most effective\npriors for representation learning. Direct factorization of parametric models\nis feasible only for a small range of invariances, while regularization\napproaches, despite improved generality, lead to nonconvex optimization. In\nthis work, we develop a convex representation learning algorithm for a variety\nof generalized invariances that can be modeled as semi-norms. Novel Euclidean\nembeddings are introduced for kernel representers in a semi-inner-product\nspace, and approximation bounds are established. This allows invariant\nrepresentations to be learned efficiently and effectively as confirmed in our\nexperiments, along with accurate predictions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 18:54:37 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 23:37:53 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 17:06:53 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Ma", "Yingyi", ""], ["Ganapathiraman", "Vignesh", ""], ["Yu", "Yaoliang", ""], ["Zhang", "Xinhua", ""]]}, {"id": "2004.12211", "submitter": "Kamran Javid Mr", "authors": "Kamran Javid, Will Handley, Mike Hobson, Anthony Lasenby", "title": "Compromise-free Bayesian neural networks", "comments": "https://github.com/PolyChord/PolyChordLite;\n  https://github.com/SuperKam91/bnn", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a thorough analysis of the relationship between the out-of-sample\nperformance and the Bayesian evidence (marginal likelihood) of Bayesian neural\nnetworks (BNNs), as well as looking at the performance of ensembles of BNNs,\nboth using the Boston housing dataset. Using the state-of-the-art in nested\nsampling, we numerically sample the full (non-Gaussian and multimodal) network\nposterior and obtain numerical estimates of the Bayesian evidence, considering\nnetwork models with up to 156 trainable parameters. The networks have between\nzero and four hidden layers, either $\\tanh$ or $ReLU$ activation functions, and\nwith and without hierarchical priors. The ensembles of BNNs are obtained by\ndetermining the posterior distribution over networks, from the posterior\nsamples of individual BNNs re-weighted by the associated Bayesian evidence\nvalues. There is good correlation between out-of-sample performance and\nevidence, as well as a remarkable symmetry between the evidence versus model\nsize and out-of-sample performance versus model size planes. Networks with\n$ReLU$ activation functions have consistently higher evidences than those with\n$\\tanh$ functions, and this is reflected in their out-of-sample performance.\nEnsembling over architectures acts to further improve performance relative to\nthe individual BNNs.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:12:56 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:23:29 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 12:03:28 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Javid", "Kamran", ""], ["Handley", "Will", ""], ["Hobson", "Mike", ""], ["Lasenby", "Anthony", ""]]}, {"id": "2004.12212", "submitter": "Lior Sidi", "authors": "Lior Sidi and Hadar Klein", "title": "Neural Network-Based Collaborative Filtering for Question Sequencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  E-Learning systems (ELS) and Intelligent Tutoring Systems (ITS) play a\nsignificant part in today's education programs. Sequencing questions is the art\nof generating a personalized quiz for a target learner. A personalized test\nwill enrich the learner's experience and will contribute to a more effective\nand efficient learning process. In this paper, we used the Neural Collaborative\nFiltering (NCF) model to generate question sequencing and compare it to a\npair-wise memory-based question sequencing algorithm - EduRank. The NCF model\nshowed significantly better ranking results than the EduRank model with an\nAverage precision correlation score of 0.85 compared to 0.8.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:15:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sidi", "Lior", ""], ["Klein", "Hadar", ""]]}, {"id": "2004.12214", "submitter": "Ozan Sener", "authors": "Ozan Sener, Vladlen Koltun", "title": "Learning to Guide Random Search", "comments": "Published at ICLR 2020, Code is available at:\n  https://github.com/intel-isl/LMRS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in derivative-free optimization of high-dimensional\nfunctions. The sample complexity of existing methods is high and depends on\nproblem dimensionality, unlike the dimensionality-independent rates of\nfirst-order methods. The recent success of deep learning suggests that many\ndatasets lie on low-dimensional manifolds that can be represented by deep\nnonlinear models. We therefore consider derivative-free optimization of a\nhigh-dimensional function that lies on a latent low-dimensional manifold. We\ndevelop an online learning approach that learns this manifold while performing\nthe optimization. In other words, we jointly learn the manifold and optimize\nthe function. Our analysis suggests that the presented method significantly\nreduces sample complexity. We empirically evaluate the method on continuous\noptimization benchmarks and high-dimensional continuous control problems. Our\nmethod achieves significantly lower sample complexity than Augmented Random\nSearch, Bayesian optimization, covariance matrix adaptation (CMA-ES), and other\nderivative-free optimization algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 19:21:14 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sener", "Ozan", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2004.12227", "submitter": "Yuanhao Xiong", "authors": "Yuanhao Xiong and Cho-Jui Hsieh", "title": "Improved Adversarial Training via Learned Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attack has recently become a tremendous threat to deep learning\nmodels. To improve the robustness of machine learning models, adversarial\ntraining, formulated as a minimax optimization problem, has been recognized as\none of the most effective defense mechanisms. However, the non-convex and\nnon-concave property poses a great challenge to the minimax training. In this\npaper, we empirically demonstrate that the commonly used PGD attack may not be\noptimal for inner maximization, and improved inner optimizer can lead to a more\nrobust model. Then we leverage a learning-to-learn (L2L) framework to train an\noptimizer with recurrent neural networks, providing update directions and steps\nadaptively for the inner problem. By co-training optimizer's parameters and\nmodel's weights, the proposed framework consistently improves the model\nrobustness over PGD-based adversarial training and TRADES.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 20:15:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xiong", "Yuanhao", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "2004.12231", "submitter": "Huayu Li", "authors": "Huayu Li, Xiwen Chen, Haiyu Wu, Zaoyi Chi, Christopher Mann, and\n  Abolfazl Razi", "title": "Deep DIH : Statistically Inferred Reconstruction of Digital In-Line\n  Holography by Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital in-line holography is commonly used to reconstruct 3D images from 2D\nholograms for microscopic objects. One of the technical challenges that arise\nin the signal processing stage is removing the twin image that is caused by the\nphase-conjugate wavefront from the recorded holograms. Twin image removal is\ntypically formulated as a non-linear inverse problem due to the irreversible\nscattering process when generating the hologram. Recently, end-to-end deep\nlearning-based methods have been utilized to reconstruct the object wavefront\n(as a surrogate for the 3D structure of the object) directly from a single-shot\nin-line digital hologram. However, massive data pairs are required to train\ndeep learning models for acceptable reconstruction precision. In contrast to\ntypical image processing problems, well-curated datasets for in-line digital\nholography does not exist. Also, the trained model highly influenced by the\nmorphological properties of the object and hence can vary for different\napplications. Therefore, data collection can be prohibitively cumbersome in\npractice as a major hindrance to using deep learning for digital holography. In\nthis paper, we proposed a novel implementation of autoencoder-based deep\nlearning architecture for single-shot hologram reconstruction solely based on\nthe current sample without the need for massive datasets to train the model.\nThe simulations results demonstrate the superior performance of the proposed\nmethod compared to the state of the art single-shot compressive digital in-line\nhologram reconstruction method.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 20:39:25 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 22:08:02 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Li", "Huayu", ""], ["Chen", "Xiwen", ""], ["Wu", "Haiyu", ""], ["Chi", "Zaoyi", ""], ["Mann", "Christopher", ""], ["Razi", "Abolfazl", ""]]}, {"id": "2004.12239", "submitter": "Jiaao Chen", "authors": "Jiaao Chen, Zichao Yang, Diyi Yang", "title": "MixText: Linguistically-Informed Interpolation of Hidden Space for\n  Semi-Supervised Text Classification", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents MixText, a semi-supervised learning method for text\nclassification, which uses our newly designed data augmentation method called\nTMix. TMix creates a large amount of augmented training samples by\ninterpolating text in hidden space. Moreover, we leverage recent advances in\ndata augmentation to guess low-entropy labels for unlabeled data, hence making\nthem as easy to use as labeled data.By mixing labeled, unlabeled and augmented\ndata, MixText significantly outperformed current pre-trained and fined-tuned\nmodels and other state-of-the-art semi-supervised learning methods on several\ntext classification benchmarks. The improvement is especially prominent when\nsupervision is extremely limited. We have publicly released our code at\nhttps://github.com/GT-SALT/MixText.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 21:37:36 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Jiaao", ""], ["Yang", "Zichao", ""], ["Yang", "Diyi", ""]]}, {"id": "2004.12247", "submitter": "Arda Akdemir", "authors": "Arda Akdemir and Tetsuo Shibuya and Tunga G\\\"ung\\\"or", "title": "Hierarchical Multi Task Learning with Subword Contextual Embeddings for\n  Languages with Rich Morphology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological information is important for many sequence labeling tasks in\nNatural Language Processing (NLP). Yet, existing approaches rely heavily on\nmanual annotations or external software to capture this information. In this\nstudy, we propose using subword contextual embeddings to capture the\nmorphological information for languages with rich morphology. In addition, we\nincorporate these embeddings in a hierarchical multi-task setting which is not\nemployed before, to the best of our knowledge. Evaluated on Dependency Parsing\n(DEP) and Named Entity Recognition (NER) tasks, which are shown to benefit\ngreatly from morphological information, our final model outperforms previous\nstate-of-the-art models on both tasks for the Turkish language. Besides, we\nshow a net improvement of 18.86% and 4.61% F-1 over the previously proposed\nmulti-task learner in the same setting for the DEP and the NER tasks,\nrespectively. Empirical results for five different MTL settings show that\nincorporating subword contextual embeddings brings significant improvements for\nboth tasks. In addition, we observed that multi-task learning consistently\nimproves the performance of the DEP component.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 22:55:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Akdemir", "Arda", ""], ["Shibuya", "Tetsuo", ""], ["G\u00fcng\u00f6r", "Tunga", ""]]}, {"id": "2004.12254", "submitter": "Fatemehsadat Mireshghallah", "authors": "Fatemehsadat Mireshghallah, Mohammadkazem Taram, Praneeth Vepakomma,\n  Abhishek Singh, Ramesh Raskar, Hadi Esmaeilzadeh", "title": "Privacy in Deep Learning: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing advances of deep learning in many areas including vision,\nrecommendation systems, natural language processing, etc., have led to the\nadoption of Deep Neural Networks (DNNs) in production systems. The availability\nof large datasets and high computational power are the main contributors to\nthese advances. The datasets are usually crowdsourced and may contain sensitive\ninformation. This poses serious privacy concerns as this data can be misused or\nleaked through various vulnerabilities. Even if the cloud provider and the\ncommunication link is trusted, there are still threats of inference attacks\nwhere an attacker could speculate properties of the data used for training, or\nfind the underlying model architecture and parameters. In this survey, we\nreview the privacy concerns brought by deep learning, and the mitigating\ntechniques introduced to tackle these issues. We also show that there is a gap\nin the literature regarding test-time inference privacy, and propose possible\nfuture research directions.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 23:47:25 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 17:13:21 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 22:19:53 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 20:54:34 GMT"}, {"version": "v5", "created": "Sat, 7 Nov 2020 01:52:13 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Mireshghallah", "Fatemehsadat", ""], ["Taram", "Mohammadkazem", ""], ["Vepakomma", "Praneeth", ""], ["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "2004.12261", "submitter": "Yi Xie", "authors": "Yi Xie, Zhuohang Li, Cong Shi, Jian Liu, Yingying Chen, Bo Yuan", "title": "Enabling Fast and Universal Audio Adversarial Attack Using Generative\n  Model", "comments": "Publish on AAAI21", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the vulnerability of DNN-based audio systems to adversarial attacks\nhas obtained the increasing attention. However, the existing audio adversarial\nattacks allow the adversary to possess the entire user's audio input as well as\ngranting sufficient time budget to generate the adversarial perturbations.\nThese idealized assumptions, however, makes the existing audio adversarial\nattacks mostly impossible to be launched in a timely fashion in practice (e.g.,\nplaying unnoticeable adversarial perturbations along with user's streaming\ninput). To overcome these limitations, in this paper we propose fast audio\nadversarial perturbation generator (FAPG), which uses generative model to\ngenerate adversarial perturbations for the audio input in a single forward\npass, thereby drastically improving the perturbation generation speed. Built on\nthe top of FAPG, we further propose universal audio adversarial perturbation\ngenerator (UAPG), a scheme crafting universal adversarial perturbation that can\nbe imposed on arbitrary benign audio input to cause misclassification.\nExtensive experiments show that our proposed FAPG can achieve up to 167X\nspeedup over the state-of-the-art audio adversarial attack methods. Also our\nproposed UAPG can generate universal adversarial perturbation that achieves\nmuch better attack performance than the state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 00:51:54 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 17:59:13 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Xie", "Yi", ""], ["Li", "Zhuohang", ""], ["Shi", "Cong", ""], ["Liu", "Jian", ""], ["Chen", "Yingying", ""], ["Yuan", "Bo", ""]]}, {"id": "2004.12276", "submitter": "Menglin Jia", "authors": "Menglin Jia, Mengyun Shi, Mikhail Sirotenko, Yin Cui, Claire Cardie,\n  Bharath Hariharan, Hartwig Adam, Serge Belongie", "title": "Fashionpedia: Ontology, Segmentation, and an Attribute Localization\n  Dataset", "comments": "eccv2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the task of instance segmentation with attribute\nlocalization, which unifies instance segmentation (detect and segment each\nobject instance) and fine-grained visual attribute categorization (recognize\none or multiple attributes). The proposed task requires both localizing an\nobject and describing its properties. To illustrate the various aspects of this\ntask, we focus on the domain of fashion and introduce Fashionpedia as a step\ntoward mapping out the visual aspects of the fashion world. Fashionpedia\nconsists of two parts: (1) an ontology built by fashion experts containing 27\nmain apparel categories, 19 apparel parts, 294 fine-grained attributes and\ntheir relationships; (2) a dataset with everyday and celebrity event fashion\nimages annotated with segmentation masks and their associated per-mask\nfine-grained attributes, built upon the Fashionpedia ontology. In order to\nsolve this challenging task, we propose a novel Attribute-Mask RCNN model to\njointly perform instance segmentation and localized attribute recognition, and\nprovide a novel evaluation metric for the task. We also demonstrate instance\nsegmentation models pre-trained on Fashionpedia achieve better transfer\nlearning performance on other fashion datasets than ImageNet pre-training.\nFashionpedia is available at: https://fashionpedia.github.io/home/index.html.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 02:38:26 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 21:02:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Jia", "Menglin", ""], ["Shi", "Mengyun", ""], ["Sirotenko", "Mikhail", ""], ["Cui", "Yin", ""], ["Cardie", "Claire", ""], ["Hariharan", "Bharath", ""], ["Adam", "Hartwig", ""], ["Belongie", "Serge", ""]]}, {"id": "2004.12277", "submitter": "Sheng Shi", "authors": "Sheng Shi, Yangzhou Du and Wei Fan", "title": "An Extension of LIME with Improvement of Interpretability and Fidelity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning makes significant achievements in Artificial Intelligence\n(AI), the lack of transparency has limited its broad application in various\nvertical domains. Explainability is not only a gateway between AI and real\nworld, but also a powerful feature to detect flaw of the models and bias of the\ndata. Local Interpretable Model-agnostic Explanation (LIME) is a\nwidely-accepted technique that explains the prediction of any classifier\nfaithfully by learning an interpretable model locally around the predicted\ninstance. As an extension of LIME, this paper proposes an high-interpretability\nand high-fidelity local explanation method, known as Local Explanation using\nfeature Dependency Sampling and Nonlinear Approximation (LEDSNA). Given an\ninstance being explained, LEDSNA enhances interpretability by feature sampling\nwith intrinsic dependency. Besides, LEDSNA improves the local explanation\nfidelity by approximating nonlinear boundary of local decision. We evaluate our\nmethod with classification tasks in both image domain and text domain.\nExperiments show that LEDSNA's explanation of the back-box model achieves much\nbetter performance than original LIME in terms of interpretability and\nfidelity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 02:54:27 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shi", "Sheng", ""], ["Du", "Yangzhou", ""], ["Fan", "Wei", ""]]}, {"id": "2004.12289", "submitter": "Dara Bahri", "authors": "Dara Bahri, Heinrich Jiang, Maya Gupta", "title": "Deep k-NN for Noisy Labels", "comments": "Full paper (including supplemental) can be found at\n  https://github.com/dbahri/deepknn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern machine learning models are often trained on examples with noisy\nlabels that hurt performance and are hard to identify. In this paper, we\nprovide an empirical study showing that a simple $k$-nearest neighbor-based\nfiltering approach on the logit layer of a preliminary model can remove\nmislabeled training data and produce more accurate models than many recently\nproposed methods. We also provide new statistical guarantees into its efficacy.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 05:15:36 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bahri", "Dara", ""], ["Jiang", "Heinrich", ""], ["Gupta", "Maya", ""]]}, {"id": "2004.12299", "submitter": "Su Zhu", "authors": "Su Zhu, Ruisheng Cao, and Kai Yu", "title": "Dual Learning for Semi-Supervised Natural Language Understanding", "comments": "12 pages, 4 figures; Accepted for IEEE/ACM Transactions on Audio\n  Speech and Language Processing", "journal-ref": null, "doi": "10.1109/TASLP.2020.3001684", "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) converts sentences into structured\nsemantic forms. The paucity of annotated training samples is still a\nfundamental challenge of NLU. To solve this data sparsity problem, previous\nwork based on semi-supervised learning mainly focuses on exploiting unlabeled\nsentences. In this work, we introduce a dual task of NLU, semantic-to-sentence\ngeneration (SSG), and propose a new framework for semi-supervised NLU with the\ncorresponding dual model. The framework is composed of dual pseudo-labeling and\ndual learning method, which enables an NLU model to make full use of data\n(labeled and unlabeled) through a closed-loop of the primal and dual tasks. By\nincorporating the dual task, the framework can exploit pure semantic forms as\nwell as unlabeled sentences, and further improve the NLU and SSG models\niteratively in the closed-loop. The proposed approaches are evaluated on two\npublic datasets (ATIS and SNIPS). Experiments in the semi-supervised setting\nshow that our methods can outperform various baselines significantly, and\nextensive ablation studies are conducted to verify the effectiveness of our\nframework. Finally, our method can also achieve the state-of-the-art\nperformance on the two datasets in the supervised setting. Our code is\navailable at \\url{https://github.com/rhythmcao/slu-dual-learning.git}.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 07:17:48 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 02:41:55 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 08:00:58 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 09:53:54 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Zhu", "Su", ""], ["Cao", "Ruisheng", ""], ["Yu", "Kai", ""]]}, {"id": "2004.12302", "submitter": "Canwen Xu", "authors": "Canwen Xu and Jiaxin Pei and Hongtao Wu and Yiyu Liu and Chenliang Li", "title": "MATINF: A Jointly Labeled Large-Scale Dataset for Classification,\n  Question Answering and Summarization", "comments": "Accepted as a long paper at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, large-scale datasets have vastly facilitated the development in\nnearly all domains of Natural Language Processing. However, there is currently\nno cross-task dataset in NLP, which hinders the development of multi-task\nlearning. We propose MATINF, the first jointly labeled large-scale dataset for\nclassification, question answering and summarization. MATINF contains 1.07\nmillion question-answer pairs with human-labeled categories and user-generated\nquestion descriptions. Based on such rich information, MATINF is applicable for\nthree major NLP tasks, including classification, question answering, and\nsummarization. We benchmark existing methods and a novel multi-task baseline\nover MATINF to inspire further research. Our comprehensive comparison and\nexperiments over MATINF and other datasets demonstrate the merits held by\nMATINF.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 07:43:15 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:11:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Xu", "Canwen", ""], ["Pei", "Jiaxin", ""], ["Wu", "Hongtao", ""], ["Liu", "Yiyu", ""], ["Li", "Chenliang", ""]]}, {"id": "2004.12307", "submitter": "Arindam Pal", "authors": "Paheli Bhattacharya, Kripabandhu Ghosh, Arindam Pal, Saptarshi Ghosh", "title": "Methods for Computing Legal Document Similarity: A Comparative Study", "comments": "This paper was published at the LDA 2019 workshop in the JURIX 2019\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing similarity between two legal documents is an important and\nchallenging task in the domain of Legal Information Retrieval. Finding similar\nlegal documents has many applications in downstream tasks, including prior-case\nretrieval, recommendation of legal articles, and so on. Prior works have\nproposed two broad ways of measuring similarity between legal documents -\nanalyzing the precedent citation network, and measuring similarity based on\ntextual content similarity measures. But there has not been a comprehensive\ncomparison of these existing methods on a common platform. In this paper, we\nperform the first systematic analysis of the existing methods. In addition, we\nexplore two promising new similarity computation methods - one text-based and\nthe other based on network embeddings, which have not been considered till now.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:26:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bhattacharya", "Paheli", ""], ["Ghosh", "Kripabandhu", ""], ["Pal", "Arindam", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2004.12311", "submitter": "Hao Cheng", "authors": "Hao Cheng, Fanxu Meng, Ke Li, Yuting Gao, Guangming Lu, Xing Sun,\n  Rongrong Ji", "title": "Filter Grafting for Deep Neural Networks: Reason, Method, and\n  Cultivation", "comments": "arXiv admin note: substantial text overlap with arXiv:2001.05868", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter is the key component in modern convolutional neural networks (CNNs).\nHowever, since CNNs are usually over-parameterized, a pre-trained network\nalways contain some invalid (unimportant) filters. These filters have\nrelatively small $l_{1}$ norm and contribute little to the output\n(\\textbf{Reason}). While filter pruning removes these invalid filters for\nefficiency consideration, we tend to reactivate them to improve the\nrepresentation capability of CNNs. In this paper, we introduce filter grafting\n(\\textbf{Method}) to achieve this goal. The activation is processed by grafting\nexternal information (weights) into invalid filters. To better perform the\ngrafting, we develop a novel criterion to measure the information of filters\nand an adaptive weighting strategy to balance the grafted information among\nnetworks. After the grafting operation, the network has fewer invalid filters\ncompared with its initial state, enpowering the model with more representation\ncapacity. Meanwhile, since grafting is operated reciprocally on all networks\ninvolved, we find that grafting may lose the information of valid filters when\nimproving invalid filters. To gain a universal improvement on both valid and\ninvalid filters, we compensate grafting with distillation\n(\\textbf{Cultivation}) to overcome the drawback of grafting . Extensive\nexperiments are performed on the classification and recognition tasks to show\nthe superiority of our method. Code is available at\n\\textcolor{black}{\\emph{https://github.com/fxmeng/filter-grafting}}.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:36:26 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 03:51:47 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Cheng", "Hao", ""], ["Meng", "Fanxu", ""], ["Li", "Ke", ""], ["Gao", "Yuting", ""], ["Lu", "Guangming", ""], ["Sun", "Xing", ""], ["Ji", "Rongrong", ""]]}, {"id": "2004.12314", "submitter": "Zhaohan Xiong", "authors": "Zhaohan Xiong, Qing Xia, Zhiqiang Hu, Ning Huang, Cheng Bian, Yefeng\n  Zheng, Sulaiman Vesal, Nishant Ravikumar, Andreas Maier, Xin Yang, Pheng-Ann\n  Heng, Dong Ni, Caizi Li, Qianqian Tong, Weixin Si, Elodie Puybareau, Younes\n  Khoudli, Thierry Geraud, Chen Chen, Wenjia Bai, Daniel Rueckert, Lingchao Xu,\n  Xiahai Zhuang, Xinzhe Luo, Shuman Jia, Maxime Sermesant, Yashu Liu, Kuanquan\n  Wang, Davide Borra, Alessandro Masci, Cristiana Corsi, Coen de Vente, Mitko\n  Veta, Rashed Karim, Chandrakanth Jayachandran Preetha, Sandy Engelhardt,\n  Menyun Qiao, Yuanyuan Wang, Qian Tao, Marta Nunez-Garcia, Oscar Camara,\n  Nicolo Savioli, Pablo Lamata, Jichao Zhao", "title": "A Global Benchmark of Algorithms for Segmenting Late Gadolinium-Enhanced\n  Cardiac Magnetic Resonance Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Segmentation of cardiac images, particularly late gadolinium-enhanced\nmagnetic resonance imaging (LGE-MRI) widely used for visualizing diseased\ncardiac structures, is a crucial first step for clinical diagnosis and\ntreatment. However, direct segmentation of LGE-MRIs is challenging due to its\nattenuated contrast. Since most clinical studies have relied on manual and\nlabor-intensive approaches, automatic methods are of high interest,\nparticularly optimized machine learning approaches. To address this, we\norganized the \"2018 Left Atrium Segmentation Challenge\" using 154 3D LGE-MRIs,\ncurrently the world's largest cardiac LGE-MRI dataset, and associated labels of\nthe left atrium segmented by three medical experts, ultimately attracting the\nparticipation of 27 international teams. In this paper, extensive analysis of\nthe submitted algorithms using technical and biological metrics was performed\nby undergoing subgroup analysis and conducting hyper-parameter analysis,\noffering an overall picture of the major design choices of convolutional neural\nnetworks (CNNs) and practical considerations for achieving state-of-the-art\nleft atrium segmentation. Results show the top method achieved a dice score of\n93.2% and a mean surface to a surface distance of 0.7 mm, significantly\noutperforming prior state-of-the-art. Particularly, our analysis demonstrated\nthat double, sequentially used CNNs, in which a first CNN is used for automatic\nregion-of-interest localization and a subsequent CNN is used for refined\nregional segmentation, achieved far superior results than traditional methods\nand pipelines containing single CNNs. This large-scale benchmarking study makes\na significant step towards much-improved segmentation methods for cardiac\nLGE-MRIs, and will serve as an important benchmark for evaluating and comparing\nthe future works in the field.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:49:17 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 09:54:48 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 14:05:14 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Xiong", "Zhaohan", ""], ["Xia", "Qing", ""], ["Hu", "Zhiqiang", ""], ["Huang", "Ning", ""], ["Bian", "Cheng", ""], ["Zheng", "Yefeng", ""], ["Vesal", "Sulaiman", ""], ["Ravikumar", "Nishant", ""], ["Maier", "Andreas", ""], ["Yang", "Xin", ""], ["Heng", "Pheng-Ann", ""], ["Ni", "Dong", ""], ["Li", "Caizi", ""], ["Tong", "Qianqian", ""], ["Si", "Weixin", ""], ["Puybareau", "Elodie", ""], ["Khoudli", "Younes", ""], ["Geraud", "Thierry", ""], ["Chen", "Chen", ""], ["Bai", "Wenjia", ""], ["Rueckert", "Daniel", ""], ["Xu", "Lingchao", ""], ["Zhuang", "Xiahai", ""], ["Luo", "Xinzhe", ""], ["Jia", "Shuman", ""], ["Sermesant", "Maxime", ""], ["Liu", "Yashu", ""], ["Wang", "Kuanquan", ""], ["Borra", "Davide", ""], ["Masci", "Alessandro", ""], ["Corsi", "Cristiana", ""], ["de Vente", "Coen", ""], ["Veta", "Mitko", ""], ["Karim", "Rashed", ""], ["Preetha", "Chandrakanth Jayachandran", ""], ["Engelhardt", "Sandy", ""], ["Qiao", "Menyun", ""], ["Wang", "Yuanyuan", ""], ["Tao", "Qian", ""], ["Nunez-Garcia", "Marta", ""], ["Camara", "Oscar", ""], ["Savioli", "Nicolo", ""], ["Lamata", "Pablo", ""], ["Zhao", "Jichao", ""]]}, {"id": "2004.12321", "submitter": "Ce Ju", "authors": "Ce Ju, Dashan Gao, Ravikiran Mane, Ben Tan, Yang Liu and Cuntai Guan", "title": "Federated Transfer Learning for EEG Signal Classification", "comments": "6 pages, 2 figures, Accepted for IEEE Engineering in Medicine and\n  Biology Society (EMBC) 2020 GitHub:\n  https://github.com/DashanGao/Federated-Transfer-Leraning-for-EEG", "journal-ref": "2020 42nd Annual International Conference of the IEEE Engineering\n  in Medicine & Biology Society (EMBC), Montreal, QC, Canada, 2020, pp.\n  3040-3045", "doi": "10.1109/EMBC44109.2020.9175344", "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning (DL) methods in the Brain-Computer Interfaces\n(BCI) field for classification of electroencephalographic (EEG) recordings has\nbeen restricted by the lack of large datasets. Privacy concerns associated with\nEEG signals limit the possibility of constructing a large EEG-BCI dataset by\nthe conglomeration of multiple small ones for jointly training machine learning\nmodels. Hence, in this paper, we propose a novel privacy-preserving DL\narchitecture named federated transfer learning (FTL) for EEG classification\nthat is based on the federated learning framework. Working with the\nsingle-trial covariance matrix, the proposed architecture extracts common\ndiscriminative information from multi-subject EEG data with the help of domain\nadaptation techniques. We evaluate the performance of the proposed architecture\non the PhysioNet dataset for 2-class motor imagery classification. While\navoiding the actual data sharing, our FTL approach achieves 2% higher\nclassification accuracy in a subject-adaptive analysis. Also, in the absence of\nmulti-subject data, our architecture provides 6% better accuracy compared to\nother state-of-the-art DL architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 09:03:19 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 11:31:57 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 10:05:00 GMT"}, {"version": "v4", "created": "Tue, 15 Dec 2020 04:27:13 GMT"}, {"version": "v5", "created": "Mon, 25 Jan 2021 17:01:40 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Ju", "Ce", ""], ["Gao", "Dashan", ""], ["Mane", "Ravikiran", ""], ["Tan", "Ben", ""], ["Liu", "Yang", ""], ["Guan", "Cuntai", ""]]}, {"id": "2004.12331", "submitter": "Rui Wang", "authors": "Rui Wang, Xuemeng Hu, Deyu Zhou, Yulan He, Yuxuan Xiong, Chenchen Ye,\n  Haiyang Xu", "title": "Neural Topic Modeling with Bidirectional Adversarial Training", "comments": "To appear at ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a surge of interests of using neural topic models\nfor automatic topic extraction from text, since they avoid the complicated\nmathematical derivations for model inference as in traditional topic models\nsuch as Latent Dirichlet Allocation (LDA). However, these models either\ntypically assume improper prior (e.g. Gaussian or Logistic Normal) over latent\ntopic space or could not infer topic distribution for a given document. To\naddress these limitations, we propose a neural topic modeling approach, called\nBidirectional Adversarial Topic (BAT) model, which represents the first attempt\nof applying bidirectional adversarial training for neural topic modeling. The\nproposed BAT builds a two-way projection between the document-topic\ndistribution and the document-word distribution. It uses a generator to capture\nthe semantic patterns from texts and an encoder for topic inference.\nFurthermore, to incorporate word relatedness information, the Bidirectional\nAdversarial Topic model with Gaussian (Gaussian-BAT) is extended from BAT. To\nverify the effectiveness of BAT and Gaussian-BAT, three benchmark corpora are\nused in our experiments. The experimental results show that BAT and\nGaussian-BAT obtain more coherent topics, outperforming several competitive\nbaselines. Moreover, when performing text clustering based on the extracted\ntopics, our models outperform all the baselines, with more significant\nimprovements achieved by Gaussian-BAT where an increase of near 6\\% is observed\nin accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 09:41:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Rui", ""], ["Hu", "Xuemeng", ""], ["Zhou", "Deyu", ""], ["He", "Yulan", ""], ["Xiong", "Yuxuan", ""], ["Ye", "Chenchen", ""], ["Xu", "Haiyang", ""]]}, {"id": "2004.12332", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh", "title": "Is Your Classifier Actually Biased? Measuring Fairness under Uncertainty\n  with Bernstein Bounds", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most NLP datasets are not annotated with protected attributes such as gender,\nmaking it difficult to measure classification bias using standard measures of\nfairness (e.g., equal opportunity). However, manually annotating a large\ndataset with a protected attribute is slow and expensive. Instead of annotating\nall the examples, can we annotate a subset of them and use that sample to\nestimate the bias? While it is possible to do so, the smaller this annotated\nsample is, the less certain we are that the estimate is close to the true bias.\nIn this work, we propose using Bernstein bounds to represent this uncertainty\nabout the bias estimate as a confidence interval. We provide empirical evidence\nthat a 95% confidence interval derived this way consistently bounds the true\nbias. In quantifying this uncertainty, our method, which we call\nBernstein-bounded unfairness, helps prevent classifiers from being deemed\nbiased or unbiased when there is insufficient evidence to make either claim.\nOur findings suggest that the datasets currently used to measure specific\nbiases are too small to conclusively identify bias except in the most egregious\ncases. For example, consider a co-reference resolution system that is 5% more\naccurate on gender-stereotypical sentences -- to claim it is biased with 95%\nconfidence, we need a bias-specific dataset that is 3.8 times larger than\nWinoBias, the largest available.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 09:45:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Ethayarajh", "Kawin", ""]]}, {"id": "2004.12344", "submitter": "Prabhu Pradhan", "authors": "Ruchit Rawal, Prabhu Pradhan", "title": "Climate Adaptation: Reliably Predicting from Imbalanced Satellite Data", "comments": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\n  Workshops: Agriculture-Vision 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The utility of aerial imagery (Satellite, Drones) has become an invaluable\ninformation source for cross-disciplinary applications, especially for crisis\nmanagement. Most of the mapping and tracking efforts are manual which is\nresource-intensive and often lead to delivery delays. Deep Learning methods\nhave boosted the capacity of relief efforts via recognition, detection, and are\nnow being used for non-trivial applications. However the data commonly\navailable is highly imbalanced (similar to other real-life applications) which\nseverely hampers the neural network's capabilities, this reduces robustness and\ntrust. We give an overview on different kinds of techniques being used for\nhandling such extreme settings and present solutions aimed at maximizing\nperformance on minority classes using a diverse set of methods (ranging from\narchitectural tuning to augmentation) which as a combination generalizes for\nall minority classes. We hope to amplify cross-disciplinary efforts by\nenhancing model reliability.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 10:41:08 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Rawal", "Ruchit", ""], ["Pradhan", "Prabhu", ""]]}, {"id": "2004.12361", "submitter": "Yaniv Benny", "authors": "Yaniv Benny, Tomer Galanti, Sagie Benaim, Lior Wolf", "title": "Evaluation Metrics for Conditional Image Generation", "comments": "To be published in \"INTERNATIONAL JOURNAL OF COMPUTER VISION\"", "journal-ref": null, "doi": "10.1007/s11263-020-01424-w", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new metrics for evaluating generative models in the\nclass-conditional image generation setting. These metrics are obtained by\ngeneralizing the two most popular unconditional metrics: the Inception Score\n(IS) and the Fre'chet Inception Distance (FID). A theoretical analysis shows\nthe motivation behind each proposed metric and links the novel metrics to their\nunconditional counterparts. The link takes the form of a product in the case of\nIS or an upper bound in the FID case. We provide an extensive empirical\nevaluation, comparing the metrics to their unconditional variants and to other\nmetrics, and utilize them to analyze existing generative models, thus providing\nadditional insights about their performance, from unlearned classes to mode\ncollapse.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 12:15:16 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 12:36:48 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Benny", "Yaniv", ""], ["Galanti", "Tomer", ""], ["Benaim", "Sagie", ""], ["Wolf", "Lior", ""]]}, {"id": "2004.12362", "submitter": "Xiaojun Quan", "authors": "Kai Wang and Weizhou Shen and Yunyi Yang and Xiaojun Quan and Rui Wang", "title": "Relational Graph Attention Network for Aspect-based Sentiment Analysis", "comments": "To appear at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aspect-based sentiment analysis aims to determine the sentiment polarity\ntowards a specific aspect in online reviews. Most recent efforts adopt\nattention-based neural network models to implicitly connect aspects with\nopinion words. However, due to the complexity of language and the existence of\nmultiple aspects in a single sentence, these models often confuse the\nconnections. In this paper, we address this problem by means of effective\nencoding of syntax information. Firstly, we define a unified aspect-oriented\ndependency tree structure rooted at a target aspect by reshaping and pruning an\nordinary dependency parse tree. Then, we propose a relational graph attention\nnetwork (R-GAT) to encode the new tree structure for sentiment prediction.\nExtensive experiments are conducted on the SemEval 2014 and Twitter datasets,\nand the experimental results confirm that the connections between aspects and\nopinion words can be better established with our approach, and the performance\nof the graph attention network (GAT) is significantly improved as a\nconsequence.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 12:21:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Kai", ""], ["Shen", "Weizhou", ""], ["Yang", "Yunyi", ""], ["Quan", "Xiaojun", ""], ["Wang", "Rui", ""]]}, {"id": "2004.12373", "submitter": "Sameera Horawalavithana", "authors": "Sameera Horawalavithana, John Skvoretz, Adriana Iamnitchi", "title": "Cascade-LSTM: Predicting Information Cascades using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the flow of information in dynamic social environments is relevant\nto many areas of the contemporary society, from disseminating health care\nmessages to meme tracking. While predicting the growth of information cascades\nhas been successfully addressed in diverse social platforms, predicting the\ntemporal and topological structure of information cascades has seen limited\nexploration. However, accurately predicting how many users will transmit the\nmessage of a particular user and at what time is paramount for designing\npractical intervention techniques.\n  This paper leverages Long-Short Term Memory (LSTM) neural network techniques\nto predict two spatio-temporal properties of information cascades, namely the\nsize and speed of individual-level information transmissions. We combine these\nprediction algorithms with probabilistic generation of cascade trees into a\ngenerative test model that is able to accurately generate cascade trees in two\ndifferent platforms, Reddit and Github. Our approach leads to a classification\naccuracy of over 73% for information transmitters and 83% for early\ntransmitters in a variety of social platforms.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 13:17:24 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Horawalavithana", "Sameera", ""], ["Skvoretz", "John", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "2004.12385", "submitter": "Qiuling Xu", "authors": "Qiuling Xu, Guanhong Tao, Siyuan Cheng, Xiangyu Zhang", "title": "Towards Feature Space Adversarial Attack", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new adversarial attack to Deep Neural Networks for image\nclassification. Different from most existing attacks that directly perturb\ninput pixels, our attack focuses on perturbing abstract features, more\nspecifically, features that denote styles, including interpretable styles such\nas vivid colors and sharp outlines, and uninterpretable ones. It induces model\nmisclassfication by injecting imperceptible style changes through an\noptimization procedure. We show that our attack can generate adversarial\nsamples that are more natural-looking than the state-of-the-art unbounded\nattacks. The experiment also supports that existing pixel-space adversarial\nattack detection and defense techniques can hardly ensure robustness in the\nstyle related feature space.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 13:56:31 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 03:47:44 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Xu", "Qiuling", ""], ["Tao", "Guanhong", ""], ["Cheng", "Siyuan", ""], ["Zhang", "Xiangyu", ""]]}, {"id": "2004.12388", "submitter": "Po-Ming Law", "authors": "Po-Ming Law, Sana Malik, Fan Du, Moumita Sinha", "title": "The Impact of Presentation Style on Human-In-The-Loop Detection of\n  Algorithmic Bias", "comments": "Published at Graphics Interface 2020 (GI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While decision makers have begun to employ machine learning, machine learning\nmodels may make predictions that bias against certain demographic groups.\nSemi-automated bias detection tools often present reports of\nautomatically-detected biases using a recommendation list or visual cues.\nHowever, there is a lack of guidance concerning which presentation style to use\nin what scenarios. We conducted a small lab study with 16 participants to\ninvestigate how presentation style might affect user behaviors in reviewing\nbias reports. Participants used both a prototype with a recommendation list and\na prototype with visual cues for bias detection. We found that participants\noften wanted to investigate the performance measures that were not\nautomatically detected as biases. Yet, when using the prototype with a\nrecommendation list, they tended to give less consideration to such measures.\nGrounded in the findings, we propose information load and comprehensiveness as\ntwo axes for characterizing bias detection tasks and illustrate how the two\naxes could be adopted to reason about when to use a recommendation list or\nvisual cues.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:05:23 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 14:33:08 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 22:30:29 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Law", "Po-Ming", ""], ["Malik", "Sana", ""], ["Du", "Fan", ""], ["Sinha", "Moumita", ""]]}, {"id": "2004.12389", "submitter": "Keyu Yang", "authors": "Keyu Yang, Yunjun Gao, Lei Liang, Song Bian, Lu Chen, Baihua Zheng", "title": "CrowdTSC: Crowd-based Neural Networks for Text Sentiment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment classification is a fundamental task in content analysis. Although\ndeep learning has demonstrated promising performance in text classification\ncompared with shallow models, it is still not able to train a satisfying\nclassifier for text sentiment. Human beings are more sophisticated than machine\nlearning models in terms of understanding and capturing the emotional\npolarities of texts. In this paper, we leverage the power of human intelligence\ninto text sentiment classification. We propose Crowd-based neural networks for\nText Sentiment Classification (CrowdTSC for short). We design and post the\nquestions on a crowdsourcing platform to collect the keywords in texts.\nSampling and clustering are utilized to reduce the cost of crowdsourcing. Also,\nwe present an attention-based neural network and a hybrid neural network, which\nincorporate the collected keywords as human being's guidance into deep neural\nnetworks. Extensive experiments on public datasets confirm that CrowdTSC\noutperforms state-of-the-art models, justifying the effectiveness of\ncrowd-based keyword guidance.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:08:15 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yang", "Keyu", ""], ["Gao", "Yunjun", ""], ["Liang", "Lei", ""], ["Bian", "Song", ""], ["Chen", "Lu", ""], ["Zheng", "Baihua", ""]]}, {"id": "2004.12399", "submitter": "Jerry Zikun Chen", "authors": "Jerry Zikun Chen", "title": "Reinforcement Learning Generalization with Surprise Minimization", "comments": "Inductive biases, invariances and generalization in RL Workshop, ICML\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization remains a challenging problem for deep reinforcement learning\nalgorithms, which are often trained and tested on the same set of deterministic\ngame environments. When test environments are unseen and perturbed but the\nnature of the task remains the same, generalization gaps can arise. In this\nwork, we propose and evaluate a surprise minimizing agent on a generalization\nbenchmark to show an additional reward learned from a simple density model can\nshow robustness in procedurally generated game environments that provide\nconstant source of entropy and stochasticity.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:50:59 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 23:25:49 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Chen", "Jerry Zikun", ""]]}, {"id": "2004.12416", "submitter": "Ferdi Kara", "authors": "Ahmet Emir, Ferdi Kara, Hakan Kaya", "title": "Pilot Interval Reduction by Deep Learning Based Detectors in Uplink NOMA", "comments": "in Turkish language. accepted for IEEE SIU 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-Orthogonal Multiple Access (NOMA) has higher spectral efficiency than\northogonal multiple access (OMA) techniques. In uplink communication systems\nthat the channel is not known at the receiver, pilot signals sent from each\nuser in different time intervals have reduced the spectral efficiency of NOMA.\nIn this study, in the uplink communication system, DL-deep learning based\ndetectors which are known to respond to the pilot signals sent from the users\nat the base station have been researched. It is aimed to maintain the spectral\nefficiency of NOMA by sending a single pilot from users, thus reducing the time\ninterval in the DL detectors.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 15:22:44 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Emir", "Ahmet", ""], ["Kara", "Ferdi", ""], ["Kaya", "Hakan", ""]]}, {"id": "2004.12427", "submitter": "Qian Wang", "authors": "Qian Wang, Toby P. Breckon", "title": "Cross-Domain Structure Preserving Projection for Heterogeneous Domain\n  Adaptation", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous Domain Adaptation (HDA) addresses the transfer learning\nproblems where data from the source and target domains are of different\nmodalities (e.g., texts and images) or feature dimensions (e.g., features\nextracted with different methods). It is useful for multi-modal data analysis.\nTraditional domain adaptation algorithms assume that the representations of\nsource and target samples reside in the same feature space, hence are likely to\nfail in solving the heterogeneous domain adaptation problem. Contemporary\nstate-of-the-art HDA approaches are usually composed of complex optimization\nobjectives for favourable performance and are therefore computationally\nexpensive and less generalizable. To address these issues, we propose a novel\nCross-Domain Structure Preserving Projection (CDSPP) algorithm for HDA. As an\nextension of the classic LPP to heterogeneous domains, CDSPP aims to learn\ndomain-specific projections to map sample features from source and target\ndomains into a common subspace such that the class consistency is preserved and\ndata distributions are sufficiently aligned. CDSPP is simple and has\ndeterministic solutions by solving a generalized eigenvalue problem. It is\nnaturally suitable for supervised HDA but has also been extended for\nsemi-supervised HDA where the unlabeled target domain samples are available.\nExtensive experiments have been conducted on commonly used benchmark datasets\n(i.e. Office-Caltech, Multilingual Reuters Collection, NUS-WIDE-ImageNet) for\nHDA as well as the Office-Home dataset firstly introduced for HDA by ourselves\ndue to its significantly larger number of classes than the existing ones (65 vs\n10, 6 and 8). The experimental results of both supervised and semi-supervised\nHDA demonstrate the superior performance of our proposed method against\ncontemporary state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 16:22:28 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 20:59:08 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Wang", "Qian", ""], ["Breckon", "Toby P.", ""]]}, {"id": "2004.12430", "submitter": "Manolis Tsakiris", "authors": "Manolis C. Tsakiris", "title": "Low-rank matrix completion theory via Plucker coordinates", "comments": "12 pages, major revision in terms of presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the popularity of low-rank matrix completion, the majority of its\ntheory has been developed under the assumption of random observation patterns,\nwhereas very little is known about the practically relevant case of non-random\npatterns. Specifically, a fundamental yet largely open question is to describe\npatterns that allow for unique or finitely many completions. This paper\nprovides two such families of patterns for any rank. A key to achieving this is\na novel formulation of low-rank matrix completion in terms of Plucker\ncoordinates, the latter a traditional tool in computer vision. This connection\nis of potential significance to a wide family of matrix and subspace learning\nproblems with incomplete data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 16:38:58 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 09:25:06 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 16:10:17 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 13:50:56 GMT"}, {"version": "v5", "created": "Wed, 26 May 2021 14:07:39 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Tsakiris", "Manolis C.", ""]]}, {"id": "2004.12443", "submitter": "Xingjian Li", "authors": "Xingjian Li, Haoyi Xiong, Haozhe An, Dejing Dou, Chengzhong Xu", "title": "COLAM: Co-Learning of Deep Neural Networks and Soft Labels via\n  Alternating Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Softening labels of training datasets with respect to data representations\nhas been frequently used to improve the training of deep neural networks\n(DNNs). While such a practice has been studied as a way to leverage privileged\ninformation about the distribution of the data, a well-trained learner with\nsoft classification outputs should be first obtained as a prior to generate\nsuch privileged information. To solve such chicken-egg problem, we propose\nCOLAM framework that Co-Learns DNNs and soft labels through Alternating\nMinimization of two objectives - (a) the training loss subject to soft labels\nand (b) the objective to learn improved soft labels - in one end-to-end\ntraining procedure. We performed extensive experiments to compare our proposed\nmethod with a series of baselines. The experiment results show that COLAM\nachieves improved performance on many tasks with better testing classification\naccuracy. We also provide both qualitative and quantitative analyses that\nexplain why COLAM works well.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 17:50:20 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Xingjian", ""], ["Xiong", "Haoyi", ""], ["An", "Haozhe", ""], ["Dou", "Dejing", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2004.12478", "submitter": "J. Edward Hu", "authors": "J. Edward Hu, Adith Swaminathan, Hadi Salman, Greg Yang", "title": "Improved Image Wasserstein Attacks and Defenses", "comments": "Best paper award at ICLR Trustworthy ML Workshop 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness against image perturbations bounded by a $\\ell_p$ ball have been\nwell-studied in recent literature. Perturbations in the real-world, however,\nrarely exhibit the pixel independence that $\\ell_p$ threat models assume. A\nrecently proposed Wasserstein distance-bounded threat model is a promising\nalternative that limits the perturbation to pixel mass movements. We point out\nand rectify flaws in previous definition of the Wasserstein threat model and\nexplore stronger attacks and defenses under our better-defined framework.\nLastly, we discuss the inability of current Wasserstein-robust models in\ndefending against perturbations seen in the real world. Our code and trained\nmodels are available at https://github.com/edwardjhu/improved_wasserstein .\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 20:50:33 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hu", "J. Edward", ""], ["Swaminathan", "Adith", ""], ["Salman", "Hadi", ""], ["Yang", "Greg", ""]]}, {"id": "2004.12485", "submitter": "Vijaya Sai Krishna Gottipati", "authors": "Sai Krishna Gottipati, Boris Sattarov, Sufeng Niu, Yashaswi Pathak,\n  Haoran Wei, Shengchao Liu, Karam M. J. Thomas, Simon Blackburn, Connor W.\n  Coley, Jian Tang, Sarath Chandar, Yoshua Bengio", "title": "Learning To Navigate The Synthetically Accessible Chemical Space Using\n  Reinforcement Learning", "comments": "added the statistics of top-100 compounds used logP metric with\n  scaled components added values of the initial reactants to the box plots some\n  values in tables are recalculated due to the inconsistent environments on\n  different machines. corresponding benchmarks were rerun with the requirements\n  on github. no significant changes in the results. corrected figures in the\n  Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, there has been significant progress in the field of\nmachine learning for de novo drug design, particularly in deep generative\nmodels. However, current generative approaches exhibit a significant challenge\nas they do not ensure that the proposed molecular structures can be feasibly\nsynthesized nor do they provide the synthesis routes of the proposed small\nmolecules, thereby seriously limiting their practical applicability. In this\nwork, we propose a novel forward synthesis framework powered by reinforcement\nlearning (RL) for de novo drug design, Policy Gradient for Forward Synthesis\n(PGFS), that addresses this challenge by embedding the concept of synthetic\naccessibility directly into the de novo drug design system. In this setup, the\nagent learns to navigate through the immense synthetically accessible chemical\nspace by subjecting commercially available small molecule building blocks to\nvalid chemical reactions at every time step of the iterative virtual multi-step\nsynthesis process. The proposed environment for drug discovery provides a\nhighly challenging test-bed for RL algorithms owing to the large state space\nand high-dimensional continuous action space with hierarchical actions. PGFS\nachieves state-of-the-art performance in generating structures with high QED\nand penalized clogP. Moreover, we validate PGFS in an in-silico\nproof-of-concept associated with three HIV targets. Finally, we describe how\nthe end-to-end training conceptualized in this study represents an important\nparadigm in radically expanding the synthesizable chemical space and automating\nthe drug discovery process.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:40:03 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 03:28:15 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Gottipati", "Sai Krishna", ""], ["Sattarov", "Boris", ""], ["Niu", "Sufeng", ""], ["Pathak", "Yashaswi", ""], ["Wei", "Haoran", ""], ["Liu", "Shengchao", ""], ["Thomas", "Karam M. J.", ""], ["Blackburn", "Simon", ""], ["Coley", "Connor W.", ""], ["Tang", "Jian", ""], ["Chandar", "Sarath", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2004.12488", "submitter": "Daniel Bakkelund", "authors": "Daniel Bakkelund", "title": "Order preserving hierarchical agglomerative clustering", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for hierarchical clustering of directed acyclic graphs\nand other strictly partially ordered data that preserves the data structure. In\nparticular, if we have $a<b$ in the original data and denote their respective\nclusters by $[a]$ and $[b]$, we get $[a]<[b]$ in the produced clustering. The\nclustering uses standard linkage functions, such as single- and complete\nlinkage, and is a generalisation of hierarchical clustering of non-ordered\nsets. To achieve this, we define the output from running hierarchical\nclustering algorithms on strictly ordered data to be partial dendrograms;\nsub-trees of classical dendrograms with several connected components. We then\nconstruct an embedding of partial dendrograms over a set into the family of\nultrametrics over the same set. An optimal hierarchical clustering is now\ndefined as follows: Given a collection of partial dendrograms, the optimal\nclustering is the partial dendrogram corresponding to the ultrametric closest\nto the original dissimilarity measure, measured in the $p$-norm. Thus, the\nmethod is a combination of classical hierarchical clustering and ultrametric\nfitting.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 21:58:53 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 14:23:04 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Bakkelund", "Daniel", ""]]}, {"id": "2004.12492", "submitter": "Benjamin Tan", "authors": "Kang Liu, Benjamin Tan, Gaurav Rajavendra Reddy, Siddharth Garg,\n  Yiorgos Makris, Ramesh Karri", "title": "Bias Busters: Robustifying DL-based Lithographic Hotspot Detectors\n  Against Backdooring Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) offers potential improvements throughout the CAD\ntool-flow, one promising application being lithographic hotspot detection.\nHowever, DL techniques have been shown to be especially vulnerable to inference\nand training time adversarial attacks. Recent work has demonstrated that a\nsmall fraction of malicious physical designers can stealthily \"backdoor\" a\nDL-based hotspot detector during its training phase such that it accurately\nclassifies regular layout clips but predicts hotspots containing a specially\ncrafted trigger shape as non-hotspots. We propose a novel training data\naugmentation strategy as a powerful defense against such backdooring attacks.\nThe defense works by eliminating the intentional biases introduced in the\ntraining data but does not require knowledge of which training samples are\npoisoned or the nature of the backdoor trigger. Our results show that the\ndefense can drastically reduce the attack success rate from 84% to ~0%.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 22:30:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Kang", ""], ["Tan", "Benjamin", ""], ["Reddy", "Gaurav Rajavendra", ""], ["Garg", "Siddharth", ""], ["Makris", "Yiorgos", ""], ["Karri", "Ramesh", ""]]}, {"id": "2004.12496", "submitter": "Amit Levi", "authors": "Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten", "title": "Learning and Testing Junta Distributions with Subcube Conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problems of learning and testing junta distributions on\n$\\{-1,1\\}^n$ with respect to the uniform distribution, where a distribution $p$\nis a $k$-junta if its probability mass function $p(x)$ depends on a subset of\nat most $k$ variables. The main contribution is an algorithm for finding\nrelevant coordinates in a $k$-junta distribution with subcube conditioning\n[BC18, CCKLW20]. We give two applications:\n  1. An algorithm for learning $k$-junta distributions with\n$\\tilde{O}(k/\\epsilon^2) \\log n + O(2^k/\\epsilon^2)$ subcube conditioning\nqueries, and\n  2. An algorithm for testing $k$-junta distributions with $\\tilde{O}((k +\n\\sqrt{n})/\\epsilon^2)$ subcube conditioning queries.\n  All our algorithms are optimal up to poly-logarithmic factors.\n  Our results show that subcube conditioning, as a natural model for accessing\nhigh-dimensional distributions, enables significant savings in learning and\ntesting junta distributions compared to the standard sampling model. This\naddresses an open question posed by Aliakbarpour, Blais, and Rubinfeld [ABR17].\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 22:52:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chen", "Xi", ""], ["Jayaram", "Rajesh", ""], ["Levi", "Amit", ""], ["Waingarten", "Erik", ""]]}, {"id": "2004.12500", "submitter": "Chandra Mouli Madhav Kotteti", "authors": "Chandra Mouli Madhav Kotteti, Xishuang Dong, Lijun Qian", "title": "Ensemble Deep Learning on Time-Series Representation of Tweets for Rumor\n  Detection in Social Media", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is a popular platform for timely information sharing. One of the\nimportant challenges for social media platforms like Twitter is whether to\ntrust news shared on them when there is no systematic news verification\nprocess. On the other hand, timely detection of rumors is a non-trivial task,\ngiven the fast-paced social media environment. In this work, we proposed an\nensemble model, which performs majority-voting on a collection of predictions\nby deep neural networks using time-series vector representation of Twitter data\nfor timely detection of rumors. By combining the proposed data pre-processing\nmethod with the ensemble model, better performance of rumor detection has been\ndemonstrated in the experiments using PHEME dataset. Experimental results show\nthat the classification performance has been improved by 7.9% in terms of micro\nF1 score compared to the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 23:13:31 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kotteti", "Chandra Mouli Madhav", ""], ["Dong", "Xishuang", ""], ["Qian", "Lijun", ""]]}, {"id": "2004.12508", "submitter": "Marco Cuturi", "authors": "Marco Cuturi, Olivier Teboul, Quentin Berthet, Arnaud Doucet,\n  Jean-Philippe Vert", "title": "Noisy Adaptive Group Testing using Bayesian Sequential Experimental\n  Design", "comments": "Latest version, with updated experiments, new conclusions on LBP vs\n  SMC decoding and new approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the infection prevalence of a disease is low, Dorfman showed 80 years\nago that testing groups of people can prove more efficient than testing people\nindividually. Our goal in this paper is to propose new group testing algorithms\nthat can operate in a noisy setting (tests can be mistaken) to decide\nadaptively (looking at past results) which groups to test next, with the goal\nto converge to a good detection, as quickly, and with as few tests as possible.\nWe cast this problem as a Bayesian sequential experimental design problem.\nUsing the posterior distribution of infection status vectors for $n$ patients,\ngiven observed tests carried out so far, we seek to form groups that have a\nmaximal utility. We consider utilities such as mutual information, but also\nquantities that have a more direct relevance to testing, such as the AUC of the\nROC curve of the test. Practically, the posterior distributions on $\\{0,1\\}^n$\nare approximated by sequential Monte Carlo (SMC) samplers and the utility\nmaximized by a greedy optimizer. Our procedures show in simulations significant\nimprovements over both adaptive and non-adaptive baselines, and are far more\nefficient than individual tests when disease prevalence is low. Additionally,\nwe show empirically that loopy belief propagation (LBP), widely regarded as the\nSoTA decoder to decide whether an individual is infected or not given previous\ntests, can be unreliable and exhibit oscillatory behavior. Our SMC decoder is\nmore reliable, and can improve the performance of other group testing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 23:41:33 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 22:49:38 GMT"}, {"version": "v3", "created": "Sun, 3 May 2020 21:10:58 GMT"}, {"version": "v4", "created": "Fri, 15 May 2020 17:55:11 GMT"}, {"version": "v5", "created": "Fri, 12 Jun 2020 15:10:39 GMT"}, {"version": "v6", "created": "Wed, 22 Jul 2020 08:19:33 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Cuturi", "Marco", ""], ["Teboul", "Olivier", ""], ["Berthet", "Quentin", ""], ["Doucet", "Arnaud", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2004.12519", "submitter": "Nathan Inkawhich", "authors": "Nathan Inkawhich, Kevin J Liang, Lawrence Carin and Yiran Chen", "title": "Transferable Perturbations of Deep Feature Distributions", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all current adversarial attacks of CNN classifiers rely on information\nderived from the output layer of the network. This work presents a new\nadversarial attack based on the modeling and exploitation of class-wise and\nlayer-wise deep feature distributions. We achieve state-of-the-art targeted\nblackbox transfer-based attack results for undefended ImageNet models. Further,\nwe place a priority on explainability and interpretability of the attacking\nprocess. Our methodology affords an analysis of how adversarial attacks change\nthe intermediate feature distributions of CNNs, as well as a measure of\nlayer-wise and class-wise feature distributional separability/entanglement. We\nalso conceptualize a transition from task/data-specific to model-specific\nfeatures within a CNN architecture that directly impacts the transferability of\nadversarial examples.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:32:25 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Inkawhich", "Nathan", ""], ["Liang", "Kevin J", ""], ["Carin", "Lawrence", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.12524", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Parisa Rashidi", "title": "Sequential Interpretability: Methods, Applications, and Future Direction\n  for Understanding Deep Learning Models in the Context of Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning continues to revolutionize an ever-growing number of critical\napplication areas including healthcare, transportation, finance, and basic\nsciences. Despite their increased predictive power, model transparency and\nhuman explainability remain a significant challenge due to the \"black box\"\nnature of modern deep learning models. In many cases the desired balance\nbetween interpretability and performance is predominately task specific.\nHuman-centric domains such as healthcare necessitate a renewed focus on\nunderstanding how and why these frameworks are arriving at critical and\npotentially life-or-death decisions. Given the quantity of research and\nempirical successes of deep learning for computer vision, most of the existing\ninterpretability research has focused on image processing techniques.\nComparatively, less attention has been paid to interpreting deep learning\nframeworks using sequential data. Given recent deep learning advancements in\nhighly sequential domains such as natural language processing and physiological\nsignal processing, the need for deep sequential explanations is at an all-time\nhigh. In this paper, we review current techniques for interpreting deep\nlearning techniques involving sequential data, identify similarities to\nnon-sequential methods, and discuss current limitations and future avenues of\nsequential interpretability research.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 00:58:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shickel", "Benjamin", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.12527", "submitter": "Jerry Zikun Chen", "authors": "Jerrod Parker and Jerry Zikun Chen", "title": "Neural Machine Translation with Monte-Carlo Tree Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent algorithms in machine translation have included a value network to\nassist the policy network when deciding which word to output at each step of\nthe translation. The addition of a value network helps the algorithm perform\nbetter on evaluation metrics like the BLEU score. After training the policy and\nvalue networks in a supervised setting, the policy and value networks can be\njointly improved through common actor-critic methods. The main idea of our\nproject is to instead leverage Monte-Carlo Tree Search (MCTS) to search for\ngood output words with guidance from a combined policy and value network\narchitecture in a similar fashion as AlphaZero. This network serves both as a\nlocal and a global look-ahead reference that uses the result of the search to\nimprove itself. Experiments using the IWLST14 German to English translation\ndataset show that our method outperforms the actor-critic methods used in\nrecent machine translation papers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:03:26 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Parker", "Jerrod", ""], ["Chen", "Jerry Zikun", ""]]}, {"id": "2004.12529", "submitter": "Zhongyi Han", "authors": "Zhongyi Han, Xian-Jin Gui, Chaoran Cui, Yilong Yin", "title": "Towards Accurate and Robust Domain Adaptation under Noisy Environments", "comments": "To appear in Proceedings of IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In non-stationary environments, learning machines usually confront the domain\nadaptation scenario where the data distribution does change over time. Previous\ndomain adaptation works have achieved great success in theory and practice.\nHowever, they always lose robustness in noisy environments where the labels and\nfeatures of examples from the source domain become corrupted. In this paper, we\nreport our attempt towards achieving accurate noise-robust domain adaptation.\nWe first give a theoretical analysis that reveals how harmful noises influence\nunsupervised domain adaptation. To eliminate the effect of label noise, we\npropose an offline curriculum learning for minimizing a newly-defined empirical\nsource risk. To reduce the impact of feature noise, we propose a proxy\ndistribution based margin discrepancy. We seamlessly transform our methods into\nan adversarial network that performs efficient joint optimization for them,\nsuccessfully mitigating the negative influence from both data corruption and\ndistribution shift. A series of empirical studies show that our algorithm\nremarkably outperforms state of the art, over 10% accuracy improvements in some\ndomain adaptation tasks under noisy environments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:07:19 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 01:18:01 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Han", "Zhongyi", ""], ["Gui", "Xian-Jin", ""], ["Cui", "Chaoran", ""], ["Yin", "Yilong", ""]]}, {"id": "2004.12531", "submitter": "Kazuya Nishimura", "authors": "Kazuya Nishimura, Ryoma Bise", "title": "Spatial-Temporal Mitosis Detection in Phase-Contrast Microscopy via\n  Likelihood Map Estimation by 3DCNN", "comments": "5 pages, 6 figures, Accepted in EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated mitotic detection in time-lapse phasecontrast microscopy provides\nus much information for cell behavior analysis, and thus several mitosis\ndetection methods have been proposed. However, these methods still have two\nproblems; 1) they cannot detect multiple mitosis events when there are closely\nplaced. 2) they do not consider the annotation gaps, which may occur since the\nappearances of mitosis cells are very similar before and after the annotated\nframe. In this paper, we propose a novel mitosis detection method that can\ndetect multiple mitosis events in a candidate sequence and mitigate the human\nannotation gap via estimating a spatiotemporal likelihood map by 3DCNN. In this\ntraining, the loss gradually decreases with the gap size between ground truth\nand estimation. This mitigates the annotation gaps. Our method outperformed the\ncompared methods in terms of F1- score using a challenging dataset that\ncontains the data under four different conditions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:12:48 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 13:59:38 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Nishimura", "Kazuya", ""], ["Bise", "Ryoma", ""]]}, {"id": "2004.12537", "submitter": "Jun Ma", "authors": "Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen,\n  Qiongjie Zhu, Guoqiang Dong, Jian He, Zhiqiang He, Yuntao Zhu, Ziwei Nie,\n  Xiaoping Yang", "title": "Towards Data-Efficient Learning: A Benchmark for COVID-19 CT Lung and\n  Infection Segmentation", "comments": "accepted for publication in Medical Physics", "journal-ref": null, "doi": "10.1002/mp.14676", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Purpose: Accurate segmentation of lung and infection in COVID-19 CT scans\nplays an important role in the quantitative management of patients. Most of the\nexisting studies are based on large and private annotated datasets that are\nimpractical to obtain from a single institution, especially when radiologists\nare busy fighting the coronavirus disease. Furthermore, it is hard to compare\ncurrent COVID-19 CT segmentation methods as they are developed on different\ndatasets, trained in different settings, and evaluated with different metrics.\nMethods: To promote the development of data-efficient deep learning methods, in\nthis paper, we built three benchmarks for lung and infection segmentation based\non 70 annotated COVID-19 cases, which contain current active research areas,\ne.g., few-shot learning, domain generalization, and knowledge transfer. For a\nfair comparison among different segmentation methods, we also provide standard\ntraining, validation and testing splits, evaluation metrics and, the\ncorresponding code. Results: Based on the state-of-the-art network, we provide\nmore than 40 pre-trained baseline models, which not only serve as\nout-of-the-box segmentation tools but also save computational time for\nresearchers who are interested in COVID-19 lung and infection segmentation. We\nachieve average Dice Similarity Coefficient (DSC) scores of 97.3\\%, 97.7\\%, and\n67.3\\% and average Normalized Surface Dice (NSD) scores of 90.6\\%, 91.4\\%, and\n70.0\\% for left lung, right lung, and infection, respectively. Conclusions: To\nthe best of our knowledge, this work presents the first data-efficient learning\nbenchmark for medical image segmentation and the largest number of pre-trained\nmodels up to now. All these resources are publicly available, and our work lays\nthe foundation for promoting the development of deep learning methods for\nefficient COVID-19 CT segmentation with limited data.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:31:48 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 11:21:07 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Ma", "Jun", ""], ["Wang", "Yixin", ""], ["An", "Xingle", ""], ["Ge", "Cheng", ""], ["Yu", "Ziqi", ""], ["Chen", "Jianan", ""], ["Zhu", "Qiongjie", ""], ["Dong", "Guoqiang", ""], ["He", "Jian", ""], ["He", "Zhiqiang", ""], ["Zhu", "Yuntao", ""], ["Nie", "Ziwei", ""], ["Yang", "Xiaoping", ""]]}, {"id": "2004.12538", "submitter": "Sohee Cho", "authors": "Sohee Cho, Ginkyeng Lee, Wonjoon Chang and Jaesik Choi", "title": "Interpretation of Deep Temporal Representations by Selective\n  Visualization of Internally Activated Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks demonstrate competitive performances in\nclassification and regression tasks for many temporal or sequential data.\nHowever, it is still hard to understand the classification mechanisms of\ntemporal deep neural networks. In this paper, we propose two new frameworks to\nvisualize temporal representations learned from deep neural networks. Given\ninput data and output, our algorithm interprets the decision of temporal neural\nnetwork by extracting highly activated periods and visualizes a sub-sequence of\ninput data which contributes to activate the units. Furthermore, we\ncharacterize such sub-sequences with clustering and calculate the uncertainty\nof the suggested type and actual data. We also suggest Layer-wise Relevance\nfrom the output of a unit, not from the final output, with backward Monte-Carlo\ndropout to show the relevance scores of each input point to activate units with\nproviding a visual representation of the uncertainty about this impact.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:45:55 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 05:08:29 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Cho", "Sohee", ""], ["Lee", "Ginkyeng", ""], ["Chang", "Wonjoon", ""], ["Choi", "Jaesik", ""]]}, {"id": "2004.12540", "submitter": "Hao Zhang", "authors": "Hao Zhang, Zhan Li, Zhixing Ren", "title": "Data-Driven Construction of Data Center Graph of Things for Anomaly\n  Detection", "comments": "17 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data center (DC) contains both IT devices and facility equipment, and the\noperation of a DC requires a high-quality monitoring (anomaly detection)\nsystem. There are lots of sensors in computer rooms for the DC monitoring\nsystem, and they are inherently related. This work proposes a data-driven\npipeline (ts2graph) to build a DC graph of things (sensor graph) from the time\nseries measurements of sensors. The sensor graph is an undirected weighted\nproperty graph, where sensors are the nodes, sensor features are the node\nproperties, and sensor connections are the edges. The sensor node property is\ndefined by features that characterize the sensor events (behaviors), instead of\nthe original time series. The sensor connection (edge weight) is defined by the\nprobability of concurrent events between two sensors. A graph of things\nprototype is constructed from the sensor time series of a real data center, and\nit successfully reveals meaningful relationships between the sensors. To\ndemonstrate the use of the DC sensor graph for anomaly detection, we compare\nthe performance of graph neural network (GNN) and existing standard methods on\nsynthetic anomaly data. GNN outperforms existing algorithms by a factor of 2 to\n3 (in terms of precision and F1 score), because it takes into account the\ntopology relationship between DC sensors. We expect that the DC sensor graph\ncan serve as the infrastructure for the DC monitoring system since it\nrepresents the sensor relationships.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:54:43 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Hao", ""], ["Li", "Zhan", ""], ["Ren", "Zhixing", ""]]}, {"id": "2004.12551", "submitter": "Benjamin Shickel", "authors": "Benjamin Shickel, Tyler J. Loftus, Shounak Datta, Tezcan\n  Ozrazgat-Baslanti, Azra Bihorac, Parisa Rashidi", "title": "Interpretable Multi-Task Deep Neural Networks for Dynamic Predictions of\n  Postoperative Complications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of postoperative complications can inform shared\ndecisions between patients and surgeons regarding the appropriateness of\nsurgery, preoperative risk-reduction strategies, and postoperative resource\nuse. Traditional predictive analytic tools are hindered by suboptimal\nperformance and usability. We hypothesized that novel deep learning techniques\nwould outperform logistic regression models in predicting postoperative\ncomplications. In a single-center longitudinal cohort of 43,943 adult patients\nundergoing 52,529 major inpatient surgeries, deep learning yielded greater\ndiscrimination than logistic regression for all nine complications. Predictive\nperformance was strongest when leveraging the full spectrum of preoperative and\nintraoperative physiologic time-series electronic health record data. A single\nmulti-task deep learning model yielded greater performance than separate models\ntrained on individual complications. Integrated gradients interpretability\nmechanisms demonstrated the substantial importance of missing data.\nInterpretable, multi-task deep neural networks made accurate, patient-level\npredictions that harbor the potential to augment surgical decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:32:32 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Shickel", "Benjamin", ""], ["Loftus", "Tyler J.", ""], ["Datta", "Shounak", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""], ["Rashidi", "Parisa", ""]]}, {"id": "2004.12554", "submitter": "Frederico Gadelha Guimaraes", "authors": "Petr\\^onio C\\^andido de Lima e Silva, Carlos Alberto Severiano Junior,\n  Marcos Antonio Alves, Rodrigo Silva, Miri Weiss Cohen, Frederico Gadelha\n  Guimar\\~aes", "title": "Forecasting in Non-stationary Environments with Fuzzy Time Series", "comments": "21 pages, 7 figures, submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a Non-Stationary Fuzzy Time Series (NSFTS) method\nwith time varying parameters adapted from the distribution of the data. In this\napproach, we employ Non-Stationary Fuzzy Sets, in which perturbation functions\nare used to adapt the membership function parameters in the knowledge base in\nresponse to statistical changes in the time series. The proposed method is\ncapable of dynamically adapting its fuzzy sets to reflect the changes in the\nstochastic process based on the residual errors, without the need to retraining\nthe model. This method can handle non-stationary and heteroskedastic data as\nwell as scenarios with concept-drift. The proposed approach allows the model to\nbe trained only once and remain useful long after while keeping reasonable\naccuracy. The flexibility of the method by means of computational experiments\nwas tested with eight synthetic non-stationary time series data with several\nkinds of concept drifts, four real market indices (Dow Jones, NASDAQ, SP500 and\nTAIEX), three real FOREX pairs (EUR-USD, EUR-GBP, GBP-USD), and two real\ncryptocoins exchange rates (Bitcoin-USD and Ethereum-USD). As competitor models\nthe Time Variant fuzzy time series and the Incremental Ensemble were used,\nthese are two of the major approaches for handling non-stationary data sets.\nNon-parametric tests are employed to check the significance of the results. The\nproposed method shows resilience to concept drift, by adapting parameters of\nthe model, while preserving the symbolic structure of the knowledge base.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 02:35:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Silva", "Petr\u00f4nio C\u00e2ndido de Lima e", ""], ["Junior", "Carlos Alberto Severiano", ""], ["Alves", "Marcos Antonio", ""], ["Silva", "Rodrigo", ""], ["Cohen", "Miri Weiss", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2004.12570", "submitter": "Abhishek Gupta", "authors": "Henry Zhu, Justin Yu, Abhishek Gupta, Dhruv Shah, Kristian\n  Hartikainen, Avi Singh, Vikash Kumar, Sergey Levine", "title": "The Ingredients of Real-World Robotic Reinforcement Learning", "comments": "First three authors contributed equally. Accepted as a spotlight\n  presentation at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of reinforcement learning for real world robotics has been, in\nmany cases limited to instrumented laboratory scenarios, often requiring\narduous human effort and oversight to enable continuous learning. In this work,\nwe discuss the elements that are needed for a robotic learning system that can\ncontinually and autonomously improve with data collected in the real world. We\npropose a particular instantiation of such a system, using dexterous\nmanipulation as our case study. Subsequently, we investigate a number of\nchallenges that come up when learning without instrumentation. In such\nsettings, learning must be feasible without manually designed resets, using\nonly on-board perception, and without hand-engineered reward functions. We\npropose simple and scalable solutions to these challenges, and then demonstrate\nthe efficacy of our proposed system on a set of dexterous robotic manipulation\ntasks, providing an in-depth analysis of the challenges associated with this\nlearning paradigm. We demonstrate that our complete system can learn without\nany human intervention, acquiring a variety of vision-based skills with a\nreal-world three-fingered hand. Results and videos can be found at\nhttps://sites.google.com/view/realworld-rl/\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 03:36:10 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhu", "Henry", ""], ["Yu", "Justin", ""], ["Gupta", "Abhishek", ""], ["Shah", "Dhruv", ""], ["Hartikainen", "Kristian", ""], ["Singh", "Avi", ""], ["Kumar", "Vikash", ""], ["Levine", "Sergey", ""]]}, {"id": "2004.12571", "submitter": "Xinjian Luo", "authors": "Xinjian Luo and Xiangqi Zhu", "title": "Exploiting Defenses against GAN-Based Feature Inference Attacks in\n  Federated Learning", "comments": "8 pages, 13 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid increasing of computing power and dataset volume, machine\nlearning algorithms have been widely adopted in classification and regression\ntasks. Though demonstrating superior performance than traditional algorithms,\nmachine learning algorithms are vulnerable to adversarial attacks, such as\nmodel inversion and membership inference. To protect user privacy, federated\nlearning is proposed for decentralized model training. Recent studies, however,\nshow that Generative Adversarial Network (GAN) based attacks could be applied\nin federated learning to effectively reconstruct user-level privacy data. In\nthis paper, we exploit defenses against GAN-based attacks in federated\nlearning. Given that GAN could effectively learn the distribution of training\ndata, GAN-based attacks aim to reconstruct human-distinguishable images from\nvictim's personal dataset. To defense such attacks, we propose a framework,\nAnti-GAN, to prevent attackers from learning the real distribution of victim's\ndata. More specifically, victims first project personal training data onto a\nGAN's generator, then feed the generated fake images into the global shared\nmodel for federated learning. In addition, we design a new loss function to\nencourage victim's GAN to generate images which not only have similar\nclassification features with original training data, but also have\nindistinguishable visual features to prevent inference attack.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 03:45:48 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Luo", "Xinjian", ""], ["Zhu", "Xiangqi", ""]]}, {"id": "2004.12575", "submitter": "Kazutaka Kanno", "authors": "Kazutaka Kanno, Makoto Naruse and Atsushi Uchida", "title": "Adaptive model selection in photonic reservoir computing by\n  reinforcement learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photonic reservoir computing is an emergent technology toward beyond-Neumann\ncomputing. Although photonic reservoir computing provides superior performance\nin environments whose characteristics are coincident with the training datasets\nfor the reservoir, the performance is significantly degraded if these\ncharacteristics deviate from the original knowledge used in the training phase.\nHere, we propose a scheme of adaptive model selection in photonic reservoir\ncomputing using reinforcement learning. In this scheme, a temporal waveform is\ngenerated by different dynamic source models that change over time. The system\nautonomously identifies the best source model for the task of time series\nprediction using photonic reservoir computing and reinforcement learning. We\nprepare two types of output weights for the source models, and the system\nadaptively selected the correct model using reinforcement learning, where the\nprediction errors are associated with rewards. We succeed in adaptive model\nselection when the source signal is temporally mixed, having originally been\ngenerated by two different dynamic system models, as well as when the signal is\na mixture from the same model but with different parameter values. This study\npaves the way for autonomous behavior in photonic artificial intelligence and\ncould lead to new applications in load forecasting and multi-objective control,\nwhere frequent environment changes are expected.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 03:54:48 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Kanno", "Kazutaka", ""], ["Naruse", "Makoto", ""], ["Uchida", "Atsushi", ""]]}, {"id": "2004.12585", "submitter": "Qile Zhu", "authors": "Qile Zhu, Jianlin Su, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and\n  Dapeng Wu", "title": "A Batch Normalized Inference Network Keeps the KL Vanishing Away", "comments": "An extension for the original ACL 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Autoencoder (VAE) is widely used as a generative model to\napproximate a model's posterior on latent variables by combining the amortized\nvariational inference and deep neural networks. However, when paired with\nstrong autoregressive decoders, VAE often converges to a degenerated local\noptimum known as \"posterior collapse\". Previous approaches consider the\nKullback Leibler divergence (KL) individual for each datapoint. We propose to\nlet the KL follow a distribution across the whole dataset, and analyze that it\nis sufficient to prevent posterior collapse by keeping the expectation of the\nKL's distribution positive. Then we propose Batch Normalized-VAE (BN-VAE), a\nsimple but effective approach to set a lower bound of the expectation by\nregularizing the distribution of the approximate posterior's parameters.\nWithout introducing any new model component or modifying the objective, our\napproach can avoid the posterior collapse effectively and efficiently. We\nfurther show that the proposed BN-VAE can be extended to conditional VAE\n(CVAE). Empirically, our approach surpasses strong autoregressive baselines on\nlanguage modeling, text classification and dialogue generation, and rivals more\ncomplex approaches while keeping almost the same training time as VAE.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 05:20:01 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 01:17:18 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zhu", "Qile", ""], ["Su", "Jianlin", ""], ["Bi", "Wei", ""], ["Liu", "Xiaojiang", ""], ["Ma", "Xiyao", ""], ["Li", "Xiaolin", ""], ["Wu", "Dapeng", ""]]}, {"id": "2004.12591", "submitter": "Peide Cai", "authors": "Peide Cai, Yuxiang Sun, Hengli Wang, Ming Liu", "title": "VTGNet: A Vision-based Trajectory Generation Network for Autonomous\n  Vehicles in Urban Environments", "comments": "11 pages, 14 figures, and 4 tables. The paper is accepted by IEEE\n  Transactions on Intelligent Vehicles (T-IV), 2020", "journal-ref": null, "doi": "10.1109/TIV.2020.3033878", "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for autonomous driving are implemented with many building\nblocks from perception, planning and control, making them difficult to\ngeneralize to varied scenarios due to complex assumptions and\ninterdependencies. Recently, the end-to-end driving method has emerged, which\nperforms well and generalizes to new environments by directly learning from\nexport-provided data. However, many existing methods on this topic neglect to\ncheck the confidence of the driving actions and the ability to recover from\ndriving mistakes. In this paper, we develop an uncertainty-aware end-to-end\ntrajectory generation method based on imitation learning. It can extract\nspatiotemporal features from the front-view camera images for scene\nunderstanding, and then generate collision-free trajectories several seconds\ninto the future. The experimental results suggest that under various weather\nand lighting conditions, our network can reliably generate trajectories in\ndifferent urban environments, such as turning at intersections and slowing down\nfor collision avoidance. Furthermore, closed-loop driving tests suggest that\nthe proposed method achieves better cross-scene/platform driving results than\nthe state-of-the-art (SOTA) end-to-end control method, where our model can\nrecover from off-center and off-orientation errors and capture 80% of dangerous\ncases with high uncertainty estimations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:17:55 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 08:57:14 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 08:46:58 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Cai", "Peide", ""], ["Sun", "Yuxiang", ""], ["Wang", "Hengli", ""], ["Liu", "Ming", ""]]}, {"id": "2004.12592", "submitter": "Zhongyi Han", "authors": "Tianyang Li, Zhongyi Han, Benzheng Wei, Yuanjie Zheng, Yanfei Hong,\n  Jinyu Cong", "title": "Robust Screening of COVID-19 from Chest X-ray via Discriminative\n  Cost-Sensitive Learning", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the new problem of automated screening of coronavirus\ndisease 2019 (COVID-19) based on chest X-rays, which is urgently demanded\ntoward fast stopping the pandemic. However, robust and accurate screening of\nCOVID-19 from chest X-rays is still a globally recognized challenge because of\ntwo bottlenecks: 1) imaging features of COVID-19 share some similarities with\nother pneumonia on chest X-rays, and 2) the misdiagnosis rate of COVID-19 is\nvery high, and the misdiagnosis cost is expensive. While a few pioneering works\nhave made much progress, they underestimate both crucial bottlenecks. In this\npaper, we report our solution, discriminative cost-sensitive learning (DCSL),\nwhich should be the choice if the clinical needs the assisted screening of\nCOVID-19 from chest X-rays. DCSL combines both advantages from fine-grained\nclassification and cost-sensitive learning. Firstly, DCSL develops a\nconditional center loss that learns deep discriminative representation.\nSecondly, DCSL establishes score-level cost-sensitive learning that can\nadaptively enlarge the cost of misclassifying COVID-19 examples into other\nclasses. DCSL is so flexible that it can apply in any deep neural network. We\ncollected a large-scale multi-class dataset comprised of 2,239 chest X-ray\nexamples: 239 examples from confirmed COVID-19 cases, 1,000 examples with\nconfirmed bacterial or viral pneumonia cases, and 1,000 examples of healthy\npeople. Extensive experiments on the three-class classification show that our\nalgorithm remarkably outperforms state-of-the-art algorithms. It achieves an\naccuracy of 97.01%, a precision of 97%, a sensitivity of 97.09%, and an\nF1-score of 96.98%. These results endow our algorithm as an efficient tool for\nthe fast large-scale screening of COVID-19.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:17:56 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 14:37:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Li", "Tianyang", ""], ["Han", "Zhongyi", ""], ["Wei", "Benzheng", ""], ["Zheng", "Yuanjie", ""], ["Hong", "Yanfei", ""], ["Cong", "Jinyu", ""]]}, {"id": "2004.12601", "submitter": "Zhesheng Zheng", "authors": "Jiaming Mao and Zhesheng Zheng", "title": "Structural Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for modeling data by using structural models based\non economic theory as regularizers for statistical models. We show that even if\na structural model is misspecified, as long as it is informative about the\ndata-generating mechanism, our method can outperform both the (misspecified)\nstructural model and un-structural-regularized statistical models. Our method\npermits a Bayesian interpretation of theory as prior knowledge and can be used\nboth for statistical prediction and causal inference. It contributes to\ntransfer learning by showing how incorporating theory into statistical modeling\ncan significantly improve out-of-domain predictions and offers a way to\nsynthesize reduced-form and structural approaches for causal effect estimation.\nSimulation experiments demonstrate the potential of our method in various\nsettings, including first-price auctions, dynamic models of entry and exit, and\ndemand estimation with instrumental variables. Our method has potential\napplications not only in economics, but in other scientific disciplines whose\ntheoretical models offer important insight but are subject to significant\nmisspecification concerns.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:47:07 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 01:13:46 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 14:12:13 GMT"}, {"version": "v4", "created": "Fri, 12 Jun 2020 11:59:17 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Mao", "Jiaming", ""], ["Zheng", "Zhesheng", ""]]}, {"id": "2004.12602", "submitter": "Qiang Liu", "authors": "Qiang Liu and Zhaocheng Liu and Haoli Zhang", "title": "An Empirical Study on Feature Discretization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with continuous numeric features, we usually adopt feature\ndiscretization. In this work, to find the best way to conduct feature\ndiscretization, we present some theoretical analysis, in which we focus on\nanalyzing correctness and robustness of feature discretization. Then, we\npropose a novel discretization method called Local Linear Encoding (LLE).\nExperiments on two numeric datasets show that, LLE can outperform conventional\ndiscretization method with much fewer model parameters.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:50:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Liu", "Qiang", ""], ["Liu", "Zhaocheng", ""], ["Zhang", "Haoli", ""]]}, {"id": "2004.12604", "submitter": "Michael Gadermayr", "authors": "Georg Wimmer, Michael Gadermayr, Andreas V\\'ecsei, Andreas Uhl", "title": "Improving Endoscopic Decision Support Systems by Translating Between\n  Imaging Modalities", "comments": "Submitted to MICCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel imaging technologies raise many questions concerning the adaptation of\ncomputer-aided decision support systems. Classification models either need to\nbe adapted or even newly trained from scratch to exploit the full potential of\nenhanced techniques. Both options typically require the acquisition of new\nlabeled training data. In this work we investigate the applicability of\nimage-to-image translation to endoscopic images showing different imaging\nmodalities, namely conventional white-light and narrow-band imaging. In a study\non computer-aided celiac disease diagnosis, we explore whether image-to-image\ntranslation is capable of effectively performing the translation between the\ndomains. We investigate if models can be trained on virtual (or a mixture of\nvirtual and real) samples to improve overall accuracy in a setting with limited\nlabeled training data. Finally, we also ask whether a translation of testing\nimages to another domain is capable of improving accuracy by exploiting the\nenhanced imaging characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 06:55:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wimmer", "Georg", ""], ["Gadermayr", "Michael", ""], ["V\u00e9csei", "Andreas", ""], ["Uhl", "Andreas", ""]]}, {"id": "2004.12615", "submitter": "Jingjing Li", "authors": "Li Jingjing, Chen Erpeng, Ding Zhengming, Zhu Lei, Lu Ke, Shen Heng\n  Tao", "title": "Maximum Density Divergence for Domain Adaptation", "comments": "Published on IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI)", "journal-ref": null, "doi": "10.1109/TPAMI.2020.2991050", "report-no": null, "categories": "cs.CV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation addresses the problem of transferring\nknowledge from a well-labeled source domain to an unlabeled target domain where\nthe two domains have distinctive data distributions. Thus, the essence of\ndomain adaptation is to mitigate the distribution divergence between the two\ndomains. The state-of-the-art methods practice this very idea by either\nconducting adversarial training or minimizing a metric which defines the\ndistribution gaps. In this paper, we propose a new domain adaptation method\nnamed Adversarial Tight Match (ATM) which enjoys the benefits of both\nadversarial training and metric learning. Specifically, at first, we propose a\nnovel distance loss, named Maximum Density Divergence (MDD), to quantify the\ndistribution divergence. MDD minimizes the inter-domain divergence (\"match\" in\nATM) and maximizes the intra-class density (\"tight\" in ATM). Then, to address\nthe equilibrium challenge issue in adversarial domain adaptation, we consider\nleveraging the proposed MDD into adversarial domain adaptation framework. At\nlast, we tailor the proposed MDD as a practical learning loss and report our\nATM. Both empirical evaluation and theoretical analysis are reported to verify\nthe effectiveness of the proposed method. The experimental results on four\nbenchmarks, both classical and large-scale, show that our method is able to\nachieve new state-of-the-art performance on most evaluations. Codes and\ndatasets used in this paper are available at {\\it github.com/lijin118/ATM}.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 07:35:06 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Jingjing", "Li", ""], ["Erpeng", "Chen", ""], ["Zhengming", "Ding", ""], ["Lei", "Zhu", ""], ["Ke", "Lu", ""], ["Tao", "Shen Heng", ""]]}, {"id": "2004.12636", "submitter": "Jin Hyeok Yoo", "authors": "Jin Hyeok Yoo and Yecheol Kim and Jisong Kim and Jun Won Choi", "title": "3D-CVF: Generating Joint Camera and LiDAR Features Using Cross-View\n  Spatial Feature Fusion for 3D Object Detection", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58583-9_43", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new deep architecture for fusing camera and LiDAR\nsensors for 3D object detection. Because the camera and LiDAR sensor signals\nhave different characteristics and distributions, fusing these two modalities\nis expected to improve both the accuracy and robustness of 3D object detection.\nOne of the challenges presented by the fusion of cameras and LiDAR is that the\nspatial feature maps obtained from each modality are represented by\nsignificantly different views in the camera and world coordinates; hence, it is\nnot an easy task to combine two heterogeneous feature maps without loss of\ninformation. To address this problem, we propose a method called 3D-CVF that\ncombines the camera and LiDAR features using the cross-view spatial feature\nfusion strategy. First, the method employs auto-calibrated projection, to\ntransform the 2D camera features to a smooth spatial feature map with the\nhighest correspondence to the LiDAR features in the bird's eye view (BEV)\ndomain. Then, a gated feature fusion network is applied to use the spatial\nattention maps to mix the camera and LiDAR features appropriately according to\nthe region. Next, camera-LiDAR feature fusion is also achieved in the\nsubsequent proposal refinement stage. The camera feature is used from the 2D\ncamera-view domain via 3D RoI grid pooling and fused with the BEV feature for\nproposal refinement. Our evaluations, conducted on the KITTI and nuScenes 3D\nobject detection datasets demonstrate that the camera-LiDAR fusion offers\nsignificant performance gain over single modality and that the proposed 3D-CVF\nachieves state-of-the-art performance in the KITTI benchmark.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 08:34:46 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 03:00:03 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Yoo", "Jin Hyeok", ""], ["Kim", "Yecheol", ""], ["Kim", "Jisong", ""], ["Choi", "Jun Won", ""]]}, {"id": "2004.12644", "submitter": "Valerio Bonometti", "authors": "Valerio Bonometti, Charles Ringer, Mathieu Ruiz, Alex Wade, Anders\n  Drachen", "title": "From Theory to Behaviour: Towards a General Model of Engagement", "comments": "In review for being included in the proceedings of \"Conference on\n  Games\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engagement is a fuzzy concept. In the present work we operationalize\nengagement mechanistically by linking it directly to human behaviour and show\nthat the construct of engagement can be used for shaping and interpreting\ndata-driven methods. First we outline a formal framework for engagement\nmodelling. Second we expanded on our previous work on theory-inspired\ndata-driven approaches to better model the engagement process by proposing a\nnew modelling technique, the Melchoir Model. Third, we illustrate how, through\nmodel comparison and inspection, we can link machine-learned models and\nunderlying theoretical frameworks. Finally we discuss our results in light of a\ntheory-driven hypothesis and highlight potential application of our work in\nindustry.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 08:44:30 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bonometti", "Valerio", ""], ["Ringer", "Charles", ""], ["Ruiz", "Mathieu", ""], ["Wade", "Alex", ""], ["Drachen", "Anders", ""]]}, {"id": "2004.12670", "submitter": "Gabriele Santin", "authors": "Bernard Haasdonk and Tizian Wenzel and Gabriele Santin and Syn Schmitt", "title": "Biomechanical surrogate modelling using stabilized vectorial greedy\n  kernel methods", "comments": null, "journal-ref": "Numerical Mathematics and Advanced Applications ENUMATH 2019", "doi": "10.1007/978-3-030-55874-1_49", "report-no": null, "categories": "math.NA cs.LG cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Greedy kernel approximation algorithms are successful techniques for sparse\nand accurate data-based modelling and function approximation. Based on a recent\nidea of stabilization of such algorithms in the scalar output case, we here\nconsider the vectorial extension built on VKOGA. We introduce the so called\n$\\gamma$-restricted VKOGA, comment on analytical properties and present\nnumerical evaluation on data from a clinically relevant application, the\nmodelling of the human spine. The experiments show that the new stabilized\nalgorithms result in improved accuracy and stability over the non-stabilized\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:38:12 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 07:25:55 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Haasdonk", "Bernard", ""], ["Wenzel", "Tizian", ""], ["Santin", "Gabriele", ""], ["Schmitt", "Syn", ""]]}, {"id": "2004.12678", "submitter": "Christian Muench", "authors": "Christian Muench, Frans A. Oliehoek, Dariu M. Gavrila", "title": "Diversity in Action: General-Sum Multi-Agent Continuous Inverse Optimal\n  Control", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic scenarios are inherently interactive. Multiple decision-makers\npredict the actions of others and choose strategies that maximize their\nrewards. We view these interactions from the perspective of game theory which\nintroduces various challenges. Humans are not entirely rational, their rewards\nneed to be inferred from real-world data, and any prediction algorithm needs to\nbe real-time capable so that we can use it in an autonomous vehicle (AV). In\nthis work, we present a game-theoretic method that addresses all of the points\nabove. Compared to many existing methods used for AVs, our approach does 1) not\nrequire perfect communication, and 2) allows for individual rewards per agent.\nOur experiments demonstrate that these more realistic assumptions lead to\nqualitatively and quantitatively different reward inference and prediction of\nfuture actions that match better with expected real-world behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:53:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Muench", "Christian", ""], ["Oliehoek", "Frans A.", ""], ["Gavrila", "Dariu M.", ""]]}, {"id": "2004.12684", "submitter": "Mohammad Hatami", "authors": "Mohammad Hatami, Mojtaba Jahandideh, Markus Leinonen and Marian\n  Codreanu", "title": "Age-Aware Status Update Control for Energy Harvesting IoT Sensors via\n  Reinforcement Learning", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an IoT sensing network with multiple users, multiple energy\nharvesting sensors, and a wireless edge node acting as a gateway between the\nusers and sensors. The users request for updates about the value of physical\nprocesses, each of which is measured by one sensor. The edge node has a cache\nstorage that stores the most recently received measurements from each sensor.\nUpon receiving a request, the edge node can either command the corresponding\nsensor to send a status update, or use the data in the cache. We aim to find\nthe best action of the edge node to minimize the average long-term cost which\ntrade-offs between the age of information and energy consumption. We propose a\npractical reinforcement learning approach that finds an optimal policy without\nknowing the exact battery levels of the sensors.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:01:28 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hatami", "Mohammad", ""], ["Jahandideh", "Mojtaba", ""], ["Leinonen", "Markus", ""], ["Codreanu", "Marian", ""]]}, {"id": "2004.12696", "submitter": "Shell Hu", "authors": "Shell Xu Hu, Pablo G. Moreno, Yang Xiao, Xi Shen, Guillaume Obozinski,\n  Neil D. Lawrence, Andreas Damianou", "title": "Empirical Bayes Transductive Meta-Learning with Synthetic Gradients", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a meta-learning approach that learns from multiple tasks in a\ntransductive setting, by leveraging the unlabeled query set in addition to the\nsupport set to generate a more powerful model for each task. To develop our\nframework, we revisit the empirical Bayes formulation for multi-task learning.\nThe evidence lower bound of the marginal log-likelihood of empirical Bayes\ndecomposes as a sum of local KL divergences between the variational posterior\nand the true posterior on the query set of each task. We derive a novel\namortized variational inference that couples all the variational posteriors via\na meta-model, which consists of a synthetic gradient network and an\ninitialization network. Each variational posterior is derived from synthetic\ngradient descent to approximate the true posterior on the query set, although\nwhere we do not have access to the true gradient. Our results on the\nMini-ImageNet and CIFAR-FS benchmarks for episodic few-shot classification\noutperform previous state-of-the-art methods. Besides, we conduct two zero-shot\nlearning experiments to further explore the potential of the synthetic\ngradient.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:39:33 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Hu", "Shell Xu", ""], ["Moreno", "Pablo G.", ""], ["Xiao", "Yang", ""], ["Shen", "Xi", ""], ["Obozinski", "Guillaume", ""], ["Lawrence", "Neil D.", ""], ["Damianou", "Andreas", ""]]}, {"id": "2004.12700", "submitter": "Richard Jiang", "authors": "Ranjith Dinakaran, Li Zhang and Richard Jiang", "title": "In-Vehicle Object Detection in the Wild for Driverless Vehicles", "comments": "the 14th International FLINS Conference on Robotics and Artificial\n  Intelligence", "journal-ref": "FLINS 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-vehicle human object identification plays an important role in\nvision-based automated vehicle driving systems while objects such as\npedestrians and vehicles on roads or streets are the primary targets to protect\nfrom driverless vehicles. A challenge is the difficulty to detect objects in\nmoving under the wild conditions, while illumination and image quality could\ndrastically vary. In this work, to address this challenge, we exploit Deep\nConvolutional Generative Adversarial Networks (DCGANs) with Single Shot\nDetector (SSD) to handle with the wild conditions. In our work, a GAN was\ntrained with low-quality images to handle with the challenges arising from the\nwild conditions in smart cities, while a cascaded SSD is employed as the object\ndetector to perform with the GAN. We used tested our approach under wild\nconditions using taxi driver videos on London street in both daylight and night\ntimes, and the tests from in-vehicle videos demonstrate that this strategy can\ndrastically achieve a better detection rate under the wild conditions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 10:43:00 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dinakaran", "Ranjith", ""], ["Zhang", "Li", ""], ["Jiang", "Richard", ""]]}, {"id": "2004.12724", "submitter": "Marco Toldo", "authors": "Teo Spadotto, Marco Toldo, Umberto Michieli and Pietro Zanuttigh", "title": "Unsupervised Domain Adaptation with Multiple Domain Discriminators and\n  Adaptive Self-Training", "comments": "8 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation (UDA) aims at improving the generalization\ncapability of a model trained on a source domain to perform well on a target\ndomain for which no labeled data is available. In this paper, we consider the\nsemantic segmentation of urban scenes and we propose an approach to adapt a\ndeep neural network trained on synthetic data to real scenes addressing the\ndomain shift between the two different data distributions. We introduce a novel\nUDA framework where a standard supervised loss on labeled synthetic data is\nsupported by an adversarial module and a self-training strategy aiming at\naligning the two domain distributions. The adversarial module is driven by a\ncouple of fully convolutional discriminators dealing with different domains:\nthe first discriminates between ground truth and generated maps, while the\nsecond between segmentation maps coming from synthetic or real world data. The\nself-training module exploits the confidence estimated by the discriminators on\nunlabeled data to select the regions used to reinforce the learning process.\nFurthermore, the confidence is thresholded with an adaptive mechanism based on\nthe per-class overall confidence. Experimental results prove the effectiveness\nof the proposed strategy in adapting a segmentation network trained on\nsynthetic datasets like GTA5 and SYNTHIA, to real world datasets like\nCityscapes and Mapillary.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:48:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Spadotto", "Teo", ""], ["Toldo", "Marco", ""], ["Michieli", "Umberto", ""], ["Zanuttigh", "Pietro", ""]]}, {"id": "2004.12726", "submitter": "Kawin Ethayarajh", "authors": "Kawin Ethayarajh and Dorsa Sadigh", "title": "BLEU Neighbors: A Reference-less Approach to Automatic Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation is a bottleneck in the development of natural language generation\n(NLG) models. Automatic metrics such as BLEU rely on references, but for tasks\nsuch as open-ended generation, there are no references to draw upon. Although\nlanguage diversity can be estimated using statistical measures such as\nperplexity, measuring language quality requires human evaluation. However,\nbecause human evaluation at scale is slow and expensive, it is used sparingly;\nit cannot be used to rapidly iterate on NLG models, in the way BLEU is used for\nmachine translation. To this end, we propose BLEU Neighbors, a nearest\nneighbors model for estimating language quality by using the BLEU score as a\nkernel function. On existing datasets for chitchat dialogue and open-ended\nsentence generation, we find that -- on average -- the quality estimation from\na BLEU Neighbors model has a lower mean squared error and higher Spearman\ncorrelation with the ground truth than individual human annotators. Despite its\nsimplicity, BLEU Neighbors even outperforms state-of-the-art models on\nautomatically grading essays, including models that have access to a\ngold-standard reference essay.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:51:28 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 04:54:12 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 21:20:37 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ethayarajh", "Kawin", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2004.12731", "submitter": "YouCheng Huang", "authors": "Youcheng Huang and Tangchen Wei and Jundong Zhou and Chunxin Yang", "title": "Lifelong Learning Process: Self-Memory Supervising and Dynamically\n  Growing Networks", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From childhood to youth, human gradually come to know the world. But for\nneural networks, this growing process seems difficult. Trapped in catastrophic\nforgetting, current researchers feed data of all categories to a neural network\nwhich remains the same structure in the whole training process. We compare this\ntraining process with human learing patterns, and find two major conflicts. In\nthis paper, we study how to solve these conflicts on generative models based on\nthe conditional variational autoencoder(CVAE) model. To solve the uncontinuous\nconflict, we apply memory playback strategy to maintain the model's recognizing\nand generating ability on invisible used categories. And we extend the\ntraditional one-way CVAE to a circulatory mode to better accomplish memory\nplayback strategy. To solve the `dead' structure conflict, we rewrite the CVAE\nformula then are able to make a novel interpretation about the funtions of\ndifferent parts in CVAE models. Based on the new understanding, we find ways to\ndynamically extend the network structure when training on new categories. We\nverify the effectiveness of our methods on MNIST and Fashion MNIST and display\nsome very insteresting results.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:00:18 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Huang", "Youcheng", ""], ["Wei", "Tangchen", ""], ["Zhou", "Jundong", ""], ["Yang", "Chunxin", ""]]}, {"id": "2004.12733", "submitter": "Noemi Mauro", "authors": "Noemi Mauro, Liliana Ardissono and Federica Cena", "title": "Personalized Recommendation of PoIs to People with Autism", "comments": null, "journal-ref": "Proceedings of the 28th ACM Conference on User Modeling,\n  Adaptation and Personalization (UMAP 2020)", "doi": "10.1145/3340631.3394845", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The suggestion of Points of Interest to people with Autism Spectrum Disorder\n(ASD) challenges recommender systems research because these users' perception\nof places is influenced by idiosyncratic sensory aversions which can mine their\nexperience by causing stress and anxiety. Therefore, managing individual\npreferences is not enough to provide these people with suitable\nrecommendations. In order to address this issue, we propose a Top-N\nrecommendation model that combines the user's idiosyncratic aversions with\nher/his preferences in a personalized way to suggest the most compatible and\nlikable Points of Interest for her/him. We are interested in finding a\nuser-specific balance of compatibility and interest within a recommendation\nmodel that integrates heterogeneous evaluation criteria to appropriately take\nthese aspects into account. We tested our model on both ASD and \"neurotypical\"\npeople. The evaluation results show that, on both groups, our model outperforms\nin accuracy and ranking capability the recommender systems based on item\ncompatibility, on user preferences, or which integrate these two aspects by\nmeans of a uniform evaluation model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:04:58 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Mauro", "Noemi", ""], ["Ardissono", "Liliana", ""], ["Cena", "Federica", ""]]}, {"id": "2004.12734", "submitter": "Yusuke Kawamoto", "authors": "Yusuke Kawamoto", "title": "An Epistemic Approach to the Formal Specification of Statistical Machine\n  Learning", "comments": "Accepted in Software and Systems Modeling https://rdcu.be/b7ssR This\n  paper is the journal version of the SEFM'19 conference paper arxiv:1907.10327", "journal-ref": null, "doi": "10.1007/s10270-020-00825-2", "report-no": null, "categories": "cs.LO cs.AI cs.CR cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an epistemic approach to formalizing statistical properties of\nmachine learning. Specifically, we introduce a formal model for supervised\nlearning based on a Kripke model where each possible world corresponds to a\npossible dataset and modal operators are interpreted as transformation and\ntesting on datasets. Then we formalize various notions of the classification\nperformance, robustness, and fairness of statistical classifiers by using our\nextension of statistical epistemic logic (StatEL). In this formalization, we\nshow relationships among properties of classifiers, and relevance between\nclassification performance and robustness. As far as we know, this is the first\nwork that uses epistemic models and logical formulas to express statistical\nproperties of machine learning, and would be a starting point to develop\ntheories of formal specification of machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:16:45 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:52:54 GMT"}, {"version": "v3", "created": "Sun, 20 Sep 2020 17:51:14 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Kawamoto", "Yusuke", ""]]}, {"id": "2004.12750", "submitter": "Mohamed El Yafrani", "authors": "Mohamed El Yafrani, Marcella Scoczynski Ribeiro Martins, Inkyung Sung,\n  Markus Wagner, Carola Doerr, and Peter Nielsen", "title": "MATE: A Model-based Algorithm Tuning Engine", "comments": "16 pages. Submitted to Evo* 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a Model-based Algorithm Turning Engine, namely\nMATE, where the parameters of an algorithm are represented as expressions of\nthe features of a target optimisation problem. In contrast to most static\n(feature-independent) algorithm tuning engines such as irace and SPOT, our\napproach aims to derive the best parameter configuration of a given algorithm\nfor a specific problem, exploiting the relationships between the algorithm\nparameters and the features of the problem. We formulate the problem of finding\nthe relationships between the parameters and the problem features as a symbolic\nregression problem and we use genetic programming to extract these expressions.\nFor the evaluation, we apply our approach to configuration of the (1+1) EA and\nRLS algorithms for the OneMax, LeadingOnes, BinValue and Jump optimisation\nproblems, where the theoretically optimal algorithm parameters to the problems\nare available as functions of the features of the problems. Our study shows\nthat the found relationships typically comply with known theoretical results,\nthus demonstrating a new opportunity to consider model-based parameter tuning\nas an effective alternative to the static algorithm tuning engines.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:50:48 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:38:05 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Yafrani", "Mohamed El", ""], ["Martins", "Marcella Scoczynski Ribeiro", ""], ["Sung", "Inkyung", ""], ["Wagner", "Markus", ""], ["Doerr", "Carola", ""], ["Nielsen", "Peter", ""]]}, {"id": "2004.12756", "submitter": "Yunxia Lin", "authors": "Yunxia Lin, Songcan Chen", "title": "A Centroid Auto-Fused Hierarchical Fuzzy c-Means Clustering", "comments": "12 pages, accepted by IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like k-means and Gaussian Mixture Model (GMM), fuzzy c-means (FCM) with soft\npartition has also become a popular clustering algorithm and still is\nextensively studied. However, these algorithms and their variants still suffer\nfrom some difficulties such as determination of the optimal number of clusters\nwhich is a key factor for clustering quality. A common approach for overcoming\nthis difficulty is to use the trial-and-validation strategy, i.e., traversing\nevery integer from large number like $\\sqrt{n}$ to 2 until finding the optimal\nnumber corresponding to the peak value of some cluster validity index. But it\nis scarcely possible to naturally construct an adaptively agglomerative\nhierarchical cluster structure as using the trial-and-validation strategy. Even\npossible, existing different validity indices also lead to different number of\nclusters. To effectively mitigate the problems while motivated by convex\nclustering, in this paper we present a Centroid Auto-Fused Hierarchical Fuzzy\nc-means method (CAF-HFCM) whose optimization procedure can automatically\nagglomerate to form a cluster hierarchy, more importantly, yielding an optimal\nnumber of clusters without resorting to any validity index. Although a\nrecently-proposed robust-learning fuzzy c-means (RL-FCM) can also automatically\nobtain the best number of clusters without the help of any validity index,\nso-involved 3 hyper-parameters need to adjust expensively, conversely, our\nCAF-HFCM involves just 1 hyper-parameter which makes the corresponding\nadjustment is relatively easier and more operational. Further, as an additional\nbenefit from our optimization objective, the CAF-HFCM effectively reduces the\nsensitivity to the initialization of clustering performance. Moreover, our\nproposed CAF-HFCM method is able to be straightforwardly extended to various\nvariants of FCM.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 12:59:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Lin", "Yunxia", ""], ["Chen", "Songcan", ""]]}, {"id": "2004.12765", "submitter": "Issa Annamoradnejad", "authors": "Issa Annamoradnejad and Gohar Zoghi", "title": "ColBERT: Using BERT Sentence Embedding for Humor Detection", "comments": "6 pages, 3 tables, 1 figure; Under review with THMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic humor detection has interesting use cases in modern technologies,\nsuch as chatbots and virtual assistants. In this paper, we propose a novel\napproach for detecting humor in short texts based on the general linguistic\nstructure of humor. Our proposed method uses BERT to generate embeddings for\nsentences of a given text and uses these embeddings as inputs of parallel lines\nof hidden layers in a neural network. These lines are finally concatenated to\npredict the target value. For evaluation purposes, we created a new dataset for\nhumor detection consisting of 200k formal short texts (100k positive and 100k\nnegative). Experimental results show that our proposed method can determine\nhumor in short texts with accuracy and an F1-score of 98.2 percent. Our 8-layer\nmodel with 110M parameters outperforms the baseline models with a large margin,\nshowing the importance of utilizing linguistic structure of texts in machine\nlearning models.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 13:10:11 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 16:11:01 GMT"}, {"version": "v3", "created": "Wed, 10 Mar 2021 13:01:46 GMT"}, {"version": "v4", "created": "Tue, 23 Mar 2021 15:19:00 GMT"}, {"version": "v5", "created": "Mon, 5 Apr 2021 09:29:01 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Annamoradnejad", "Issa", ""], ["Zoghi", "Gohar", ""]]}, {"id": "2004.12770", "submitter": "Crist\\'obal Eyzaguirre", "authors": "Cristobal Eyzaguirre, Alvaro Soto", "title": "Differentiable Adaptive Computation Time for Visual Reasoning", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel attention-based algorithm for achieving adaptive\ncomputation called DACT, which, unlike existing ones, is end-to-end\ndifferentiable. Our method can be used in conjunction with many networks; in\nparticular, we study its application to the widely known MAC architecture,\nobtaining a significant reduction in the number of recurrent steps needed to\nachieve similar accuracies, therefore improving its performance to computation\nratio. Furthermore, we show that by increasing the maximum number of steps\nused, we surpass the accuracy of even our best non-adaptive MAC in the CLEVR\ndataset, demonstrating that our approach is able to control the number of steps\nwithout significant loss of performance. Additional advantages provided by our\napproach include considerably improving interpretability by discarding useless\nsteps and providing more insights into the underlying reasoning process.\nFinally, we present adaptive computation as an equivalent to an ensemble of\nmodels, similar to a mixture of expert formulation. Both the code and the\nconfiguration files for our experiments are made available to support further\nresearch in this area.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 13:20:23 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:16:57 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 16:57:14 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Eyzaguirre", "Cristobal", ""], ["Soto", "Alvaro", ""]]}, {"id": "2004.12782", "submitter": "Himanshu Tyagi", "authors": "Aditya Gopalan and Himanshu Tyagi", "title": "How Reliable are Test Numbers for Revealing the COVID-19 Ground Truth\n  and Applying Interventions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG q-bio.PE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of confirmed cases of COVID-19 is often used as a proxy for the\nactual number of ground truth COVID-19 infected cases in both public discourse\nand policy making. However, the number of confirmed cases depends on the\ntesting policy, and it is important to understand how the number of positive\ncases obtained using different testing policies reveals the unknown ground\ntruth. We develop an agent-based simulation framework in Python that can\nsimulate various testing policies as well as interventions such as lockdown\nbased on them. The interaction between the agents can take into account various\ncommunities and mobility patterns. A distinguishing feature of our framework is\nthe presence of another `flu'-like illness with symptoms similar to COVID-19,\nthat allows us to model the noise in selecting the pool of patients to be\ntested. We instantiate our model for the city of Bengaluru in India, using\ncensus data to distribute agents geographically, and traffic flow mobility data\nto model long-distance interactions and mixing. We use the simulation framework\nto compare the performance of three testing policies: Random Symptomatic\nTesting (RST), Contact Tracing (CT), and a new Location Based Testing policy\n(LBT). We observe that if a sufficient fraction of symptomatic patients come\nout for testing, then RST can capture the ground truth quite closely even with\nvery few daily tests. However, CT consistently captures more positive cases.\nInterestingly, our new LBT, which is operationally less intensive than CT,\ngives performance that is comparable with CT. In another direction, we compare\nthe efficacy of these three testing policies in enabling lockdown, and observe\nthat CT flattens the ground truth curve maximally, followed closely by LBT, and\nsignificantly better than RST.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 17:39:49 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gopalan", "Aditya", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "2004.12783", "submitter": "Sathish Kumar Chandrasekaran", "authors": "Anshul Tanwar, Krishna Sundaresan, Parmesh Ashwath, Prasanna Ganesan,\n  Sathish Kumar Chandrasekaran, Sriram Ravi", "title": "Predicting Vulnerability In Large Codebases With Deep Code\n  Representation", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, while software engineers write code for various modules, quite\noften, various types of errors - coding, logic, semantic, and others (most of\nwhich are not caught by compilation and other tools) get introduced. Some of\nthese bugs might be found in the later stage of testing, and many times it is\nreported by customers on production code. Companies have to spend many\nresources, both money and time in finding and fixing the bugs which would have\nbeen avoided if coding was done right. Also, concealed flaws in software can\nlead to security vulnerabilities that potentially allow attackers to compromise\nsystems and applications. Interestingly, same or similar issues/bugs, which\nwere fixed in the past (although in different modules), tend to get introduced\nin production code again.\n  We developed a novel AI-based system which uses the deep representation of\nAbstract Syntax Tree (AST) created from the source code and also the active\nfeedback loop to identify and alert the potential bugs that could be caused at\nthe time of development itself i.e. as the developer is writing new code (logic\nand/or function). This tool integrated with IDE as a plugin would work in the\nbackground, point out existing similar functions/code-segments and any\nassociated bugs in those functions. The tool would enable the developer to\nincorporate suggestions right at the time of development, rather than waiting\nfor UT/QA/customer to raise a defect.\n  We assessed our tool on both open-source code and also on Cisco codebase for\nC and C++ programing language. Our results confirm that deep representation of\nsource code and the active feedback loop is an assuring approach for predicting\nsecurity and other vulnerabilities present in the code.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 13:18:35 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Tanwar", "Anshul", ""], ["Sundaresan", "Krishna", ""], ["Ashwath", "Parmesh", ""], ["Ganesan", "Prasanna", ""], ["Chandrasekaran", "Sathish Kumar", ""], ["Ravi", "Sriram", ""]]}, {"id": "2004.12786", "submitter": "Tyng-Luh Liu", "authors": "Chun-Fu Yeh, Hsien-Tzu Cheng, Andy Wei, Hsin-Ming Chen, Po-Chen Kuo,\n  Keng-Chi Liu, Mong-Chi Ko, Ray-Jade Chen, Po-Chang Lee, Jen-Hsiang Chuang,\n  Chi-Mai Chen, Yi-Chang Chen, Wen-Jeng Lee, Ning Chien, Jo-Yu Chen, Yu-Sen\n  Huang, Yu-Chien Chang, Yu-Cheng Huang, Nai-Kuan Chou, Kuan-Hua Chao, Yi-Chin\n  Tu, Yeun-Chung Chang, Tyng-Luh Liu", "title": "A Cascaded Learning Strategy for Robust COVID-19 Pneumonia Chest X-Ray\n  Screening", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a comprehensive screening platform for the COVID-19 (a.k.a.,\nSARS-CoV-2) pneumonia. The proposed AI-based system works on chest x-ray (CXR)\nimages to predict whether a patient is infected with the COVID-19 disease.\nAlthough the recent international joint effort on making the availability of\nall sorts of open data, the public collection of CXR images is still relatively\nsmall for reliably training a deep neural network (DNN) to carry out COVID-19\nprediction. To better address such inefficiency, we design a cascaded learning\nstrategy to improve both the sensitivity and the specificity of the resulting\nDNN classification model. Our approach leverages a large CXR image dataset of\nnon-COVID-19 pneumonia to generalize the original well-trained classification\nmodel via a cascaded learning scheme. The resulting screening system is shown\nto achieve good classification performance on the expanded dataset, including\nthose newly added COVID-19 CXR images.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 15:44:51 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:46:13 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Yeh", "Chun-Fu", ""], ["Cheng", "Hsien-Tzu", ""], ["Wei", "Andy", ""], ["Chen", "Hsin-Ming", ""], ["Kuo", "Po-Chen", ""], ["Liu", "Keng-Chi", ""], ["Ko", "Mong-Chi", ""], ["Chen", "Ray-Jade", ""], ["Lee", "Po-Chang", ""], ["Chuang", "Jen-Hsiang", ""], ["Chen", "Chi-Mai", ""], ["Chen", "Yi-Chang", ""], ["Lee", "Wen-Jeng", ""], ["Chien", "Ning", ""], ["Chen", "Jo-Yu", ""], ["Huang", "Yu-Sen", ""], ["Chang", "Yu-Chien", ""], ["Huang", "Yu-Cheng", ""], ["Chou", "Nai-Kuan", ""], ["Chao", "Kuan-Hua", ""], ["Tu", "Yi-Chin", ""], ["Chang", "Yeun-Chung", ""], ["Liu", "Tyng-Luh", ""]]}, {"id": "2004.12794", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Meysam Majidi Nezhad, Ehsan Abbasnejad, Daniele Groppi,\n  Azim Heydari, Lina Bertling Tjernberg, Davide Astiaso Garcia, Bradley\n  Alexander and Markus Wagner", "title": "Hybrid Neuro-Evolutionary Method for Predicting Wind Turbine Power\n  Output", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable wind turbine power prediction is imperative to the planning,\nscheduling and control of wind energy farms for stable power production. In\nrecent years Machine Learning (ML) methods have been successfully applied in a\nwide range of domains, including renewable energy. However, due to the\nchallenging nature of power prediction in wind farms, current models are far\nshort of the accuracy required by industry. In this paper, we deploy a\ncomposite ML approach--namely a hybrid neuro-evolutionary algorithm--for\naccurate forecasting of the power output in wind-turbine farms. We use\nhistorical data in the supervisory control and data acquisition (SCADA) systems\nas input to estimate the power output from an onshore wind farm in Sweden. At\nthe beginning stage, the k-means clustering method and an Autoencoder are\nemployed, respectively, to detect and filter noise in the SCADA measurements.\nNext, with the prior knowledge that the underlying wind patterns are highly\nnon-linear and diverse, we combine a self-adaptive differential evolution\n(SaDE) algorithm as a hyper-parameter optimizer, and a recurrent neural network\n(RNN) called Long Short-term memory (LSTM) to model the power curve of a wind\nturbine in a farm. Two short time forecasting horizons, including ten-minutes\nahead and one-hour ahead, are considered in our experiments. We show that our\napproach outperforms its counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 04:22:22 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Neshat", "Mehdi", ""], ["Nezhad", "Meysam Majidi", ""], ["Abbasnejad", "Ehsan", ""], ["Groppi", "Daniele", ""], ["Heydari", "Azim", ""], ["Tjernberg", "Lina Bertling", ""], ["Garcia", "Davide Astiaso", ""], ["Alexander", "Bradley", ""], ["Wagner", "Markus", ""]]}, {"id": "2004.12805", "submitter": "Takato Yasuno", "authors": "Takato Yasuno, Nakajima Michihiro, and Noda Kazuhiro", "title": "Per-pixel Classification Rebar Exposures in Bridge Eye-inspection", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient inspection and accurate diagnosis are required for civil\ninfrastructures with 50 years since completion. Especially in municipalities,\nthe shortage of technical staff and budget constraints on repair expenses have\nbecome a critical problem. If we can detect damaged photos automatically\nper-pixels from the record of the inspection record in addition to the 5-step\njudgment and countermeasure classification of eye-inspection vision, then it is\npossible that countermeasure information can be provided more flexibly, whether\nwe need to repair and how large the expose of damage interest. A piece of\ndamage photo is often sparse as long as it is not zoomed around damage, exactly\nthe range where the detection target is photographed, is at most only 1%.\nGenerally speaking, rebar exposure is frequently occurred, and there are many\nopportunities to judge repair measure. In this paper, we propose three damage\ndetection methods of transfer learning which enables semantic segmentation in\nan image with low pixels using damaged photos of human eye-inspection. Also, we\ntried to create a deep convolutional network from scratch with the\npreprocessing that random crops with rotations are generated. In fact, we show\nthe results applied this method using the 208 rebar exposed images on the 106\nreal-world bridges. Finally, future tasks of damage detection modeling are\nmentioned.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 17:28:42 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Yasuno", "Takato", ""], ["Michihiro", "Nakajima", ""], ["Kazuhiro", "Noda", ""]]}, {"id": "2004.12814", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Michele Scarpiniti, Enzo Baccarelli, Aurelio Uncini", "title": "Why should we add early exits to neural networks?", "comments": "Published in Cognitive Computation", "journal-ref": "Cognitive Computation, 2020", "doi": "10.1007/s12559-020-09734-4", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are generally designed as a stack of differentiable\nlayers, in which a prediction is obtained only after running the full stack.\nRecently, some contributions have proposed techniques to endow the networks\nwith early exits, allowing to obtain predictions at intermediate points of the\nstack. These multi-output networks have a number of advantages, including: (i)\nsignificant reductions of the inference time, (ii) reduced tendency to\noverfitting and vanishing gradients, and (iii) capability of being distributed\nover multi-tier computation platforms. In addition, they connect to the wider\nthemes of biological plausibility and layered cognitive reasoning. In this\npaper, we provide a comprehensive introduction to this family of neural\nnetworks, by describing in a unified fashion the way these architectures can be\ndesigned, trained, and actually deployed in time-constrained scenarios. We also\ndescribe in-depth their application scenarios in 5G and Fog computing\nenvironments, as long as some of the open research questions connected to them.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 13:53:16 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 07:42:10 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Baccarelli", "Enzo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2004.12817", "submitter": "Kaitao Song", "authors": "Kaitao Song, Hao Sun, Xu Tan, Tao Qin, Jianfeng Lu, Hongzhi Liu and\n  Tie-Yan Liu", "title": "LightPAFF: A Two-Stage Distillation Framework for Pre-training and\n  Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While pre-training and fine-tuning, e.g., BERT~\\citep{devlin2018bert},\nGPT-2~\\citep{radford2019language}, have achieved great success in language\nunderstanding and generation tasks, the pre-trained models are usually too big\nfor online deployment in terms of both memory cost and inference speed, which\nhinders them from practical online usage. In this paper, we propose LightPAFF,\na Lightweight Pre-training And Fine-tuning Framework that leverages two-stage\nknowledge distillation to transfer knowledge from a big teacher model to a\nlightweight student model in both pre-training and fine-tuning stages. In this\nway the lightweight model can achieve similar accuracy as the big teacher\nmodel, but with much fewer parameters and thus faster online inference speed.\nLightPAFF can support different pre-training methods (such as BERT, GPT-2 and\nMASS~\\citep{song2019mass}) and be applied to many downstream tasks. Experiments\non three language understanding tasks, three language modeling tasks and three\nsequence to sequence generation tasks demonstrate that while achieving similar\naccuracy with the big BERT, GPT-2 and MASS models, LightPAFF reduces the model\nsize by nearly 5x and improves online inference speed by 5x-7x.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:00:09 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Song", "Kaitao", ""], ["Sun", "Hao", ""], ["Tan", "Xu", ""], ["Qin", "Tao", ""], ["Lu", "Jianfeng", ""], ["Liu", "Hongzhi", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2004.12819", "submitter": "Zezhou Cheng", "authors": "Zezhou Cheng, Saadia Gabriel, Pankaj Bhambhani, Daniel Sheldon,\n  Subhransu Maji, Andrew Laughlin, David Winkler", "title": "Detecting and Tracking Communal Bird Roosts in Weather Radar Data", "comments": "9 pages, 6 figures, AAAI 2020 (AI for Social Impact Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The US weather radar archive holds detailed information about biological\nphenomena in the atmosphere over the last 20 years. Communally roosting birds\ncongregate in large numbers at nighttime roosting locations, and their morning\nexodus from the roost is often visible as a distinctive pattern in radar\nimages. This paper describes a machine learning system to detect and track\nroost signatures in weather radar data. A significant challenge is that labels\nwere collected opportunistically from previous research studies and there are\nsystematic differences in labeling style. We contribute a latent variable model\nand EM algorithm to learn a detection model together with models of labeling\nstyles for individual annotators. By properly accounting for these variations\nwe learn a significantly more accurate detector. The resulting system detects\npreviously unknown roosting locations and provides comprehensive\nspatio-temporal data about roosts across the US. This data will provide\nbiologists important information about the poorly understood phenomena of\nbroad-scale habitat use and movements of communally roosting birds during the\nnon-breeding season.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:40:50 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Cheng", "Zezhou", ""], ["Gabriel", "Saadia", ""], ["Bhambhani", "Pankaj", ""], ["Sheldon", "Daniel", ""], ["Maji", "Subhransu", ""], ["Laughlin", "Andrew", ""], ["Winkler", "David", ""]]}, {"id": "2004.12823", "submitter": "Gianluca Maguolo", "authors": "Gianluca Maguolo, Loris Nanni", "title": "A Critic Evaluation of Methods for COVID-19 Automatic Detection from\n  X-Ray Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we compare and evaluate different testing protocols used for\nautomatic COVID-19 diagnosis from X-Ray images in the recent literature. We\nshow that similar results can be obtained using X-Ray images that do not\ncontain most of the lungs. We are able to remove the lungs from the images by\nturning to black the center of the X-Ray scan and training our classifiers only\non the outer part of the images. Hence, we deduce that several testing\nprotocols for the recognition are not fair and that the neural networks are\nlearning patterns in the dataset that are not correlated to the presence of\nCOVID-19. Finally, we show that creating a fair testing protocol is a\nchallenging task, and we provide a method to measure how fair a specific\ntesting protocol is. In the future research we suggest to check the fairness of\na testing protocol using our tools and we encourage researchers to look for\nbetter techniques than the ones that we propose.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:05:36 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 02:17:02 GMT"}, {"version": "v3", "created": "Tue, 19 May 2020 01:49:41 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 00:36:28 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Maguolo", "Gianluca", ""], ["Nanni", "Loris", ""]]}, {"id": "2004.12828", "submitter": "Liming Zhang", "authors": "Liming Zhang, Andreas Z\\\"ufle, Dieter Pfoser", "title": "Station-to-User Transfer Learning: Towards Explainable User Clustering\n  Through Latent Trip Signatures Using Tidal-Regularized Non-Negative Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban areas provide us with a treasure trove of available data capturing\nalmost every aspect of a population's life. This work focuses on mobility data\nand how it will help improve our understanding of urban mobility patterns.\nReadily available and sizable farecard data captures trips in a public\ntransportation network. However, such data typically lacks temporal modalities\nand as such the task of inferring trip semantic, station function, and user\nprofile is quite challenging. As existing approaches either focus on\nstation-level or user-level signals, they are prone to overfitting and generate\nless credible and insightful results. To properly learn such characteristics\nfrom trip data, we propose a Collective Learning Framework through Latent\nRepresentation, which augments user-level learning with collective patterns\nlearned from station-level signals. This framework uses a novel, so-called\nTidal-Regularized Non-negative Matrix Factorization method, which incorporates\ndomain knowledge in the form of temporal passenger flow patterns in generic\nNon-negative Matrix Factorization. To evaluate our model performance, a user\nstability test based on the classical Rand Index is introduced as a metric to\nbenchmark different unsupervised learning models. We provide a qualitative\nanalysis of the station functions and user profiles for the Washington D.C.\nmetro and show how our method supports spatiotemporal intra-city mobility\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:13:56 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Zhang", "Liming", ""], ["Z\u00fcfle", "Andreas", ""], ["Pfoser", "Dieter", ""]]}, {"id": "2004.12835", "submitter": "Ivan P Yamshchikov", "authors": "Igor Samenko, Alexey Tikhonov, Ivan P. Yamshchikov", "title": "Synonyms and Antonyms: Embedded Conflict", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since modern word embeddings are motivated by a distributional hypothesis and\nare, therefore, based on local co-occurrences of words, it is only to be\nexpected that synonyms and antonyms can have very similar embeddings. Contrary\nto this widespread assumption, this paper shows that modern embeddings contain\ninformation that distinguishes synonyms and antonyms despite small cosine\nsimilarities between corresponding vectors. This information is encoded in the\ngeometry of the embeddings and could be extracted with a manifold learning\nprocedure or {\\em contrasting map}. Such a map is trained on a small labeled\nsubset of the data and can produce new empeddings that explicitly highlight\nspecific semantic attributes of the word. The new embeddings produced by the\nmap are shown to improve the performance on downstream tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:33:37 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Samenko", "Igor", ""], ["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "2004.12837", "submitter": "Matteo Polsinelli", "authors": "Matteo Polsinelli, Luigi Cinque, Giuseppe Placidi", "title": "A Light CNN for detecting COVID-19 from CT scans of the chest", "comments": null, "journal-ref": "Pattern Recognition Letters. 140 (2020) 95-100", "doi": "10.1016/j.patrec.2020.10.001", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OVID-19 is a world-wide disease that has been declared as a pandemic by the\nWorld Health Organization. Computer Tomography (CT) imaging of the chest seems\nto be a valid diagnosis tool to detect COVID-19 promptly and to control the\nspread of the disease. Deep Learning has been extensively used in medical\nimaging and convolutional neural networks (CNNs) have been also used for\nclassification of CT images. We propose a light CNN design based on the model\nof the SqueezeNet, for the efficient discrimination of COVID-19 CT images with\nother CT images (community-acquired pneumonia and/or healthy images). On the\ntested datasets, the proposed modified SqueezeNet CNN achieved 83.00\\% of\naccuracy, 85.00\\% of sensitivity, 81.00\\% of specificity, 81.73\\% of precision\nand 0.8333 of F1Score in a very efficient way (7.81 seconds medium-end laptot\nwithout GPU acceleration). Besides performance, the average classification time\nis very competitive with respect to more complex CNN designs, thus allowing its\nusability also on medium power computers. In the next future we aim at\nimproving the performances of the method along two directions: 1) by increasing\nthe training dataset (as soon as other CT images will be available); 2) by\nintroducing an efficient pre-processing strategy.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 07:58:49 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Polsinelli", "Matteo", ""], ["Cinque", "Luigi", ""], ["Placidi", "Giuseppe", ""]]}, {"id": "2004.12846", "submitter": "Eseoghene Ben-Iwhiwhu", "authors": "Eseoghene Ben-Iwhiwhu, Pawel Ladosz, Jeffery Dick, Wen-Hua Chen,\n  Praveen Pilly, Andrea Soltoggio", "title": "Evolving Inborn Knowledge For Fast Adaptation in Dynamic POMDP Problems", "comments": "9 pages. Accepted as a full paper in the Genetic and Evolutionary\n  Computation Conference (GECCO 2020)", "journal-ref": null, "doi": "10.1145/3377930.3390214", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid online adaptation to changing tasks is an important problem in machine\nlearning and, recently, a focus of meta-reinforcement learning. However,\nreinforcement learning (RL) algorithms struggle in POMDP environments because\nthe state of the system, essential in a RL framework, is not always visible.\nAdditionally, hand-designed meta-RL architectures may not include suitable\ncomputational structures for specific learning problems. The evolution of\nonline learning mechanisms, on the contrary, has the ability to incorporate\nlearning strategies into an agent that can (i) evolve memory when required and\n(ii) optimize adaptation speed to specific online learning problems. In this\npaper, we exploit the highly adaptive nature of neuromodulated neural networks\nto evolve a controller that uses the latent space of an autoencoder in a POMDP.\nThe analysis of the evolved networks reveals the ability of the proposed\nalgorithm to acquire inborn knowledge in a variety of aspects such as the\ndetection of cues that reveal implicit rewards, and the ability to evolve\nlocation neurons that help with navigation. The integration of inborn knowledge\nand online plasticity enabled fast adaptation and better performance in\ncomparison to some non-evolutionary meta-reinforcement learning algorithms. The\nalgorithm proved also to succeed in the 3D gaming environment Malmo Minecraft.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 14:55:08 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 10:04:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ben-Iwhiwhu", "Eseoghene", ""], ["Ladosz", "Pawel", ""], ["Dick", "Jeffery", ""], ["Chen", "Wen-Hua", ""], ["Pilly", "Praveen", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "2004.12850", "submitter": "Masataro Asai", "authors": "Masataro Asai and Christian Muise", "title": "Learning Neural-Symbolic Descriptive Planning Models via Cube-Space\n  Priors: The Voyage Home (to STRIPS)", "comments": "Accepted in IJCAI 2020 main track (accept ratio 12.6%). The prequel\n  of this paper, \"The Search for STRIPS\", can be found here: arXiv:1912.05492 .\n  (update, 2020/08/11) We expanded the related work section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We achieved a new milestone in the difficult task of enabling agents to learn\nabout their environment autonomously. Our neuro-symbolic architecture is\ntrained end-to-end to produce a succinct and effective discrete state\ntransition model from images alone. Our target representation (the Planning\nDomain Definition Language) is already in a form that off-the-shelf solvers can\nconsume, and opens the door to the rich array of modern heuristic search\ncapabilities. We demonstrate how the sophisticated innate prior we place on the\nlearning process significantly reduces the complexity of the learned\nrepresentation, and reveals a connection to the graph-theoretic notion of\n\"cube-like graphs\", thus opening the door to a deeper understanding of the\nideal properties for learned symbolic representations. We show that the\npowerful domain-independent heuristics allow our system to solve visual\n15-Puzzle instances which are beyond the reach of blind search, without\nresorting to the Reinforcement Learning approach that requires a huge amount of\ntraining on the domain-dependent reward information.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:01:54 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 16:08:38 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 20:05:30 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Asai", "Masataro", ""], ["Muise", "Christian", ""]]}, {"id": "2004.12852", "submitter": "Maria Vakalopoulou", "authors": "Guillaume Chassagnon, Maria Vakalopoulou, Enzo Battistella, Stergios\n  Christodoulidis, Trieu-Nghi Hoang-Thi, Severine Dangeard, Eric Deutsch,\n  Fabrice Andre, Enora Guillo, Nara Halm, Stefany El Hajj, Florian Bompard,\n  Sophie Neveu, Chahinez Hani, Ines Saab, Alienor Campredon, Hasmik Koulakian,\n  Souhail Bennani, Gael Freche, Aurelien Lombard, Laure Fournier, Hippolyte\n  Monnier, Teodor Grand, Jules Gregory, Antoine Khalil, Elyas Mahdjoub,\n  Pierre-Yves Brillet, Stephane Tran Ba, Valerie Bousson, Marie-Pierre Revel,\n  Nikos Paragios", "title": "AI-Driven CT-based quantification, staging and short-term outcome\n  prediction of COVID-19 pneumonia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest computed tomography (CT) is widely used for the management of\nCoronavirus disease 2019 (COVID-19) pneumonia because of its availability and\nrapidity. The standard of reference for confirming COVID-19 relies on\nmicrobiological tests but these tests might not be available in an emergency\nsetting and their results are not immediately available, contrary to CT. In\naddition to its role for early diagnosis, CT has a prognostic role by allowing\nvisually evaluating the extent of COVID-19 lung abnormalities. The objective of\nthis study is to address prediction of short-term outcomes, especially need for\nmechanical ventilation. In this multi-centric study, we propose an end-to-end\nartificial intelligence solution for automatic quantification and prognosis\nassessment by combining automatic CT delineation of lung disease meeting\nperformance of experts and data-driven identification of biomarkers for its\nprognosis. AI-driven combination of variables with CT-based biomarkers offers\nperspectives for optimal patient management given the shortage of intensive\ncare beds and ventilators.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 12:24:08 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Chassagnon", "Guillaume", ""], ["Vakalopoulou", "Maria", ""], ["Battistella", "Enzo", ""], ["Christodoulidis", "Stergios", ""], ["Hoang-Thi", "Trieu-Nghi", ""], ["Dangeard", "Severine", ""], ["Deutsch", "Eric", ""], ["Andre", "Fabrice", ""], ["Guillo", "Enora", ""], ["Halm", "Nara", ""], ["Hajj", "Stefany El", ""], ["Bompard", "Florian", ""], ["Neveu", "Sophie", ""], ["Hani", "Chahinez", ""], ["Saab", "Ines", ""], ["Campredon", "Alienor", ""], ["Koulakian", "Hasmik", ""], ["Bennani", "Souhail", ""], ["Freche", "Gael", ""], ["Lombard", "Aurelien", ""], ["Fournier", "Laure", ""], ["Monnier", "Hippolyte", ""], ["Grand", "Teodor", ""], ["Gregory", "Jules", ""], ["Khalil", "Antoine", ""], ["Mahdjoub", "Elyas", ""], ["Brillet", "Pierre-Yves", ""], ["Ba", "Stephane Tran", ""], ["Bousson", "Valerie", ""], ["Revel", "Marie-Pierre", ""], ["Paragios", "Nikos", ""]]}, {"id": "2004.12867", "submitter": "David Yevick", "authors": "David Yevick, Roger Melko", "title": "The Accuracy of Restricted Boltzmann Machine Models of Ising Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.LG physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machine (RBM) provide a general framework for modeling\nphysical systems, but their behavior is dependent on hyperparameters such as\nthe learning rate, the number of hidden nodes and the form of the threshold\nfunction. This article accordingly examines in detail the influence of these\nparameters on Ising spin system calculations. A tradeoff is identified between\nthe accuracy of statistical quantities such as the specific heat and that of\nthe joint distribution of energy and magnetization. The optimal structure of\nthe RBM therefore depends intrinsically on the physical problem to which it is\napplied.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:23:42 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yevick", "David", ""], ["Melko", "Roger", ""]]}, {"id": "2004.12873", "submitter": "Saurabh Arora", "authors": "Saurabh Arora, Bikramjit Banerjee, Prashant Doshi", "title": "Maximum Entropy Multi-Task Inverse RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task IRL allows for the possibility that the expert could be switching\nbetween multiple ways of solving the same problem, or interleaving\ndemonstrations of multiple tasks. The learner aims to learn the multiple reward\nfunctions that guide these ways of solving the problem. We present a new method\nfor multi-task IRL that generalizes the well-known maximum entropy approach to\nIRL by combining it with the Dirichlet process based clustering of the observed\ninput. This yields a single nonlinear optimization problem, called MaxEnt\nMulti-task IRL, which can be solved using the Lagrangian relaxation and\ngradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on\nthe robotic task of sorting onions on a processing line where the expert\nutilizes multiple ways of detecting and removing blemished onions. The method\nis able to learn the underlying reward functions to a high level of accuracy\nand it improves on the previous approaches to multi-task IRL.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:30:58 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Arora", "Saurabh", ""], ["Banerjee", "Bikramjit", ""], ["Doshi", "Prashant", ""]]}, {"id": "2004.12880", "submitter": "Vittorio Mazzia", "authors": "Vittorio Mazzia, Aleem Khaliq, Marcello Chiaberge", "title": "Improvement in Land Cover and Crop Classification based on Temporal\n  Features Learning from Sentinel-2 Data Using Recurrent-Convolutional Neural\n  Network (R-CNN)", "comments": null, "journal-ref": "Appl. Sci. 2020, 10(1), 238", "doi": "10.3390/app10010238", "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing spatial and temporal resolution of globally available\nsatellite images, such as provided by Sentinel-2, creates new possibilities for\nresearchers to use freely available multi-spectral optical images, with\ndecametric spatial resolution and more frequent revisits for remote sensing\napplications such as land cover and crop classification (LC&CC), agricultural\nmonitoring and management, environment monitoring. Existing solutions dedicated\nto cropland mapping can be categorized based on per-pixel based and\nobject-based. However, it is still challenging when more classes of\nagricultural crops are considered at a massive scale. In this paper, a novel\nand optimal deep learning model for pixel-based LC&CC is developed and\nimplemented based on Recurrent Neural Networks (RNN) in combination with\nConvolutional Neural Networks (CNN) using multi-temporal sentinel-2 imagery of\ncentral north part of Italy, which has diverse agricultural system dominated by\neconomic crop types. The proposed methodology is capable of automated feature\nextraction by learning time correlation of multiple images, which reduces\nmanual feature engineering and modeling crop phenological stages. Fifteen\nclasses, including major agricultural crops, were considered in this study. We\nalso tested other widely used traditional machine learning algorithms for\ncomparison such as support vector machine SVM, random forest (RF), Kernal SVM,\nand gradient boosting machine, also called XGBoost. The overall accuracy\nachieved by our proposed Pixel R-CNN was 96.5%, which showed considerable\nimprovements in comparison with existing mainstream methods. This study showed\nthat Pixel R-CNN based model offers a highly accurate way to assess and employ\ntime-series data for multi-temporal classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:39:50 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 10:28:07 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Mazzia", "Vittorio", ""], ["Khaliq", "Aleem", ""], ["Chiaberge", "Marcello", ""]]}, {"id": "2004.12905", "submitter": "James Mullenbach", "authors": "James Mullenbach, Jordan Swartz, T. Greg McKelvey, Hui Dai, David\n  Sontag", "title": "Knowledge Base Completion for Constructing Problem-Oriented Medical\n  Records", "comments": "MLHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both electronic health records and personal health records are typically\norganized by data type, with medical problems, medications, procedures, and\nlaboratory results chronologically sorted in separate areas of the chart. As a\nresult, it can be difficult to find all of the relevant information for\nanswering a clinical question about a given medical problem. A promising\nalternative is to instead organize by problems, with related medications,\nprocedures, and other pertinent information all grouped together. A recent\neffort by Buchanan (2017) manually defined, through expert consensus, 11\nmedical problems and the relevant labs and medications for each. We show how to\nuse machine learning on electronic health records to instead automatically\nconstruct these problem-based groupings of relevant medications, procedures,\nand laboratory tests. We formulate the learning task as one of knowledge base\ncompletion, and annotate a dataset that expands the set of problems from 11 to\n32. We develop a model architecture that exploits both pre-trained concept\nembeddings and usage data relating the concepts contained in a longitudinal\ndataset from a large health system. We evaluate our algorithms' ability to\nsuggest relevant medications, procedures, and lab tests, and find that the\napproach provides feasible suggestions even for problems that are hidden during\ntraining. The dataset, along with code to reproduce our results, is available\nat https://github.com/asappresearch/kbc-pomr.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:05:23 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:22:31 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mullenbach", "James", ""], ["Swartz", "Jordan", ""], ["McKelvey", "T. Greg", ""], ["Dai", "Hui", ""], ["Sontag", "David", ""]]}, {"id": "2004.12906", "submitter": "Julius von K\\\"ugelgen", "authors": "Julius von K\\\"ugelgen, Ivan Ustyuzhaninov, Peter Gehler, Matthias\n  Bethge, Bernhard Sch\\\"olkopf", "title": "Towards causal generative scene models via competition of experts", "comments": "Presented at the ICLR 2020 workshop \"Causal learning for decision\n  making\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning how to model complex scenes in a modular way with recombinable\ncomponents is a pre-requisite for higher-order reasoning and acting in the\nphysical world. However, current generative models lack the ability to capture\nthe inherently compositional and layered nature of visual scenes. While recent\nwork has made progress towards unsupervised learning of object-based scene\nrepresentations, most models still maintain a global representation space\n(i.e., objects are not explicitly separated), and cannot generate scenes with\nnovel object arrangement and depth ordering. Here, we present an alternative\napproach which uses an inductive bias encouraging modularity by training an\nensemble of generative models (experts). During training, experts compete for\nexplaining parts of a scene, and thus specialise on different object classes,\nwith objects being identified as parts that re-occur across multiple scenes.\nOur model allows for controllable sampling of individual objects and\nrecombination of experts in physically plausible ways. In contrast to other\nmethods, depth layering and occlusion are handled correctly, moving this\napproach closer to a causal generative scene model. Experiments on simple toy\ndata qualitatively demonstrate the conceptual advantages of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:10:04 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["von K\u00fcgelgen", "Julius", ""], ["Ustyuzhaninov", "Ivan", ""], ["Gehler", "Peter", ""], ["Bethge", "Matthias", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2004.12908", "submitter": "Jayanta Dey", "authors": "Joshua T. Vogelstein, Jayanta Dey, Hayden S. Helm, Will LeVine, Ronak\n  D. Mehta, Ali Geisa, Gido M. van de Ven, Emily Chang, Chenyu Gao, Weiwei\n  Yang, Bryan Tower, Jonathan Larson, Christopher M. White, and Carey E. Priebe", "title": "Omnidirectional Transfer for Quasilinear Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In biological learning, data are used to improve performance not only on the\ncurrent task, but also on previously encountered and as yet unencountered\ntasks. In contrast, classical machine learning starts from a blank slate, or\ntabula rasa, using data only for the single task at hand. While typical\ntransfer learning algorithms can improve performance on future tasks, their\nperformance on prior tasks degrades upon learning new tasks (called\ncatastrophic forgetting). Many recent approaches for continual or lifelong\nlearning have attempted to maintain performance given new tasks. But striving\nto avoid forgetting sets the goal unnecessarily low: the goal of lifelong\nlearning, whether biological or artificial, should be to improve performance on\nall tasks (including past and future) with any new data. We propose\nomnidirectional transfer learning algorithms, which includes two special cases\nof interest: decision forests and deep networks. Our key insight is the\ndevelopment of the omni-voter layer, which ensembles representations learned\nindependently on all tasks to jointly decide how to proceed on any given new\ndata point, thereby improving performance on both past and future tasks. Our\nalgorithms demonstrate omnidirectional transfer in a variety of simulated and\nreal data scenarios, including tabular data, image data, spoken data, and\nadversarial tasks. Moreover, they do so with quasilinear space and time\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:16:30 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 17:42:48 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 19:10:05 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 19:22:48 GMT"}, {"version": "v5", "created": "Thu, 20 Aug 2020 14:34:24 GMT"}, {"version": "v6", "created": "Wed, 3 Mar 2021 15:46:10 GMT"}, {"version": "v7", "created": "Mon, 14 Jun 2021 15:35:21 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Vogelstein", "Joshua T.", ""], ["Dey", "Jayanta", ""], ["Helm", "Hayden S.", ""], ["LeVine", "Will", ""], ["Mehta", "Ronak D.", ""], ["Geisa", "Ali", ""], ["van de Ven", "Gido M.", ""], ["Chang", "Emily", ""], ["Gao", "Chenyu", ""], ["Yang", "Weiwei", ""], ["Tower", "Bryan", ""], ["Larson", "Jonathan", ""], ["White", "Christopher M.", ""], ["Priebe", "Carey E.", ""]]}, {"id": "2004.12909", "submitter": "Hao Sun", "authors": "Hao Sun, Xinyu Pan, Bo Dai, Dahua Lin, Bolei Zhou", "title": "Evolutionary Stochastic Policy Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving the Goal-Conditioned Reward Sparse (GCRS) task is a challenging\nreinforcement learning problem due to the sparsity of reward signals. In this\nwork, we propose a new formulation of GCRS tasks from the perspective of the\ndrifted random walk on the state space, and design a novel method called\nEvolutionary Stochastic Policy Distillation (ESPD) to solve them based on the\ninsight of reducing the First Hitting Time of the stochastic process. As a\nself-imitate approach, ESPD enables a target policy to learn from a series of\nits stochastic variants through the technique of policy distillation (PD). The\nlearning mechanism of ESPD can be considered as an Evolution Strategy (ES) that\napplies perturbations upon policy directly on the action space, with a SELECT\nfunction to check the superiority of stochastic variants and then use PD to\nupdate the policy. The experiments based on the MuJoCo robotics control suite\nshow the high learning efficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:19:25 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:00:24 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Sun", "Hao", ""], ["Pan", "Xinyu", ""], ["Dai", "Bo", ""], ["Lin", "Dahua", ""], ["Zhou", "Bolei", ""]]}, {"id": "2004.12917", "submitter": "Shaocheng Huang", "authors": "Shaocheng Huang, Yu Ye, Ming Xiao", "title": "Learning Based Hybrid Beamforming for Millimeter Wave Multi-User MIMO\n  Systems", "comments": "2 figure, one table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid beamforming (HBF) design is a crucial stage in millimeter wave\n(mmWave) multi-user multi-input multi-output (MU-MIMO) systems. However,\nconventional HBF methods are still with high complexity and strongly rely on\nthe quality of channel state information. We propose an extreme learning\nmachine (ELM) framework to jointly optimize transmitting and receiving\nbeamformers. Specifically, to provide accurate labels for training, we first\npropose an factional-programming and majorization-minimization based HBF method\n(FP-MM-HBF). Then, an ELM based HBF (ELM-HBF) framework is proposed to increase\nthe robustness of beamformers. Both FP-MM-HBF and ELM-HBF can provide higher\nsystem sum-rate compared with existing methods. Moreover, ELM-HBF cannot only\nprovide robust HBF performance, but also consume very short computation time.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:31:08 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Huang", "Shaocheng", ""], ["Ye", "Yu", ""], ["Xiao", "Ming", ""]]}, {"id": "2004.12956", "submitter": "Tengyu Xu", "authors": "Tengyu Xu, Zhe Wang, Yingbin Liang", "title": "Improving Sample Complexity Bounds for (Natural) Actor-Critic Algorithms", "comments": "Accepted by NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The actor-critic (AC) algorithm is a popular method to find an optimal policy\nin reinforcement learning. In the infinite horizon scenario, the finite-sample\nconvergence rate for the AC and natural actor-critic (NAC) algorithms has been\nestablished recently, but under independent and identically distributed\n(i.i.d.) sampling and single-sample update at each iteration. In contrast, this\npaper characterizes the convergence rate and sample complexity of AC and NAC\nunder Markovian sampling, with mini-batch data for each iteration, and with\nactor having general policy class approximation. We show that the overall\nsample complexity for a mini-batch AC to attain an $\\epsilon$-accurate\nstationary point improves the best known sample complexity of AC by an order of\n$\\mathcal{O}(\\epsilon^{-1}\\log(1/\\epsilon))$, and the overall sample complexity\nfor a mini-batch NAC to attain an $\\epsilon$-accurate globally optimal point\nimproves the existing sample complexity of NAC by an order of\n$\\mathcal{O}(\\epsilon^{-1}/\\log(1/\\epsilon))$. Moreover, the sample complexity\nof AC and NAC characterized in this work outperforms that of policy gradient\n(PG) and natural policy gradient (NPG) by a factor of\n$\\mathcal{O}((1-\\gamma)^{-3})$ and\n$\\mathcal{O}((1-\\gamma)^{-4}\\epsilon^{-1}/\\log(1/\\epsilon))$, respectively.\nThis is the first theoretical study establishing that AC and NAC attain\norderwise performance improvement over PG and NPG under infinite horizon due to\nthe incorporation of critic.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:11:06 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 15:20:38 GMT"}, {"version": "v3", "created": "Wed, 24 Jun 2020 17:23:59 GMT"}, {"version": "v4", "created": "Fri, 12 Feb 2021 01:00:43 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Xu", "Tengyu", ""], ["Wang", "Zhe", ""], ["Liang", "Yingbin", ""]]}, {"id": "2004.12974", "submitter": "Archit Sharma", "authors": "Archit Sharma, Michael Ahn, Sergey Levine, Vikash Kumar, Karol\n  Hausman, Shixiang Gu", "title": "Emergent Real-World Robotic Skills via Unsupervised Off-Policy\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning provides a general framework for learning robotic\nskills while minimizing engineering effort. However, most reinforcement\nlearning algorithms assume that a well-designed reward function is provided,\nand learn a single behavior for that single reward function. Such reward\nfunctions can be difficult to design in practice. Can we instead develop\nefficient reinforcement learning methods that acquire diverse skills without\nany reward function, and then repurpose these skills for downstream tasks? In\nthis paper, we demonstrate that a recently proposed unsupervised skill\ndiscovery algorithm can be extended into an efficient off-policy method, making\nit suitable for performing unsupervised reinforcement learning in the real\nworld. Firstly, we show that our proposed algorithm provides substantial\nimprovement in learning efficiency, making reward-free real-world training\nfeasible. Secondly, we move beyond the simulation environments and evaluate the\nalgorithm on real physical hardware. On quadrupeds, we observe that locomotion\nskills with diverse gaits and different orientations emerge without any rewards\nor demonstrations. We also demonstrate that the learned skills can be composed\nusing model predictive control for goal-oriented navigation, without any\nadditional training.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:38:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Sharma", "Archit", ""], ["Ahn", "Michael", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""], ["Hausman", "Karol", ""], ["Gu", "Shixiang", ""]]}, {"id": "2004.12983", "submitter": "Mahdi Haghifam", "authors": "Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M. Roy, Gintare\n  Karolina Dziugaite", "title": "Sharpened Generalization Bounds based on Conditional Mutual Information\n  and an Application to Noisy, Iterative Algorithms", "comments": "23 Pages, 3 Figures. To appear in, Advances in Neural Information\n  Processing Systems (34), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information-theoretic framework of Russo and J. Zou (2016) and Xu and\nRaginsky (2017) provides bounds on the generalization error of a learning\nalgorithm in terms of the mutual information between the algorithm's output and\nthe training sample. In this work, we study the proposal, by Steinke and\nZakynthinou (2020), to reason about the generalization error of a learning\nalgorithm by introducing a super sample that contains the training sample as a\nrandom subset and computing mutual information conditional on the super sample.\nWe first show that these new bounds based on the conditional mutual information\nare tighter than those based on the unconditional mutual information. We then\nintroduce yet tighter bounds, building on the \"individual sample\" idea of Bu,\nS. Zou, and Veeravalli (2019) and the \"data dependent\" ideas of Negrea et al.\n(2019), using disintegrated mutual information. Finally, we apply these bounds\nto the study of Langevin dynamics algorithm, showing that conditioning on the\nsuper sample allows us to exploit information in the optimization trajectory to\nobtain tighter bounds based on hypothesis tests.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:51:09 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 14:10:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Haghifam", "Mahdi", ""], ["Negrea", "Jeffrey", ""], ["Khisti", "Ashish", ""], ["Roy", "Daniel M.", ""], ["Dziugaite", "Gintare Karolina", ""]]}, {"id": "2004.12993", "submitter": "Ji Xin", "authors": "Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, Jimmy Lin", "title": "DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained language models such as BERT have brought significant\nimprovements to NLP applications. However, they are also notorious for being\nslow in inference, which makes them difficult to deploy in real-time\napplications. We propose a simple but effective method, DeeBERT, to accelerate\nBERT inference. Our approach allows samples to exit earlier without passing\nthrough the entire model. Experiments show that DeeBERT is able to save up to\n~40% inference time with minimal degradation in model quality. Further analyses\nshow different behaviors in the BERT transformer layers and also reveal their\nredundancy. Our work provides new ideas to efficiently apply deep\ntransformer-based models to downstream tasks. Code is available at\nhttps://github.com/castorini/DeeBERT.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 17:58:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Xin", "Ji", ""], ["Tang", "Raphael", ""], ["Lee", "Jaejun", ""], ["Yu", "Yaoliang", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.13002", "submitter": "Swagatam Das", "authors": "Arka Ghosh, Sankha Subhra Mullick, Shounak Datta, Swagatam Das,\n  Rammohan Mallipeddi, Asit Kr. Das", "title": "One Sparse Perturbation to Fool them All, almost Always!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing adversarial perturbations for deep neural networks is an\nimportant direction of research. Crafting image-dependent adversarial\nperturbations using white-box feedback has hitherto been the norm for such\nadversarial attacks. However, black-box attacks are much more practical for\nreal-world applications. Universal perturbations applicable across multiple\nimages are gaining popularity due to their innate generalizability. There have\nalso been efforts to restrict the perturbations to a few pixels in the image.\nThis helps to retain visual similarity with the original images making such\nattacks hard to detect. This paper marks an important step which combines all\nthese directions of research. We propose the DEceit algorithm for constructing\neffective universal pixel-restricted perturbations using only black-box\nfeedback from the target network. We conduct empirical investigations using the\nImageNet validation set on the state-of-the-art deep neural classifiers by\nvarying the number of pixels to be perturbed from a meagre 10 pixels to as high\nas all pixels in the image. We find that perturbing only about 10% of the\npixels in an image using DEceit achieves a commendable and highly transferable\nFooling Rate while retaining the visual quality. We further demonstrate that\nDEceit can be successfully applied to image dependent attacks as well. In both\nsets of experiments, we outperformed several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:42:00 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:02:32 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Ghosh", "Arka", ""], ["Mullick", "Sankha Subhra", ""], ["Datta", "Shounak", ""], ["Das", "Swagatam", ""], ["Mallipeddi", "Rammohan", ""], ["Das", "Asit Kr.", ""]]}, {"id": "2004.13003", "submitter": "Tian Shi", "authors": "Tian Shi, Xuchao Zhang, Ping Wang, Chandan K. Reddy", "title": "Corpus-level and Concept-based Explanations for Interpretable Document\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using attention weights to identify information that is important for models'\ndecision-making is a popular approach to interpret attention-based neural\nnetworks. This is commonly realized in practice through the generation of a\nheat-map for every single document based on attention weights. However, this\ninterpretation method is fragile, and easy to find contradictory examples. In\nthis paper, we propose a corpus-level explanation approach, which aims to\ncapture causal relationships between keywords and model predictions via\nlearning the importance of keywords for predicted labels across a training\ncorpus based on attention weights. Based on this idea, we further propose a\nconcept-based explanation method that can automatically learn higher-level\nconcepts and their importance to model prediction tasks. Our concept-based\nexplanation method is built upon a novel Abstraction-Aggregation Network, which\ncan automatically cluster important keywords during an end-to-end training\nprocess. We apply these methods to the document classification task and show\nthat they are powerful in extracting semantically meaningful keywords and\nconcepts. Our consistency analysis results based on an attention-based Na\\\"ive\nBayes classifier also demonstrate these keywords and concepts are important for\nmodel predictions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:54:17 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 21:48:26 GMT"}, {"version": "v3", "created": "Fri, 1 Jan 2021 04:50:32 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 03:22:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shi", "Tian", ""], ["Zhang", "Xuchao", ""], ["Wang", "Ping", ""], ["Reddy", "Chandan K.", ""]]}, {"id": "2004.13004", "submitter": "Saurabh Jha", "authors": "Saurabh Jha, Shengkun Cui, Subho S. Banerjee, Timothy Tsai, Zbigniew\n  Kalbarczyk, Ravi Iyer", "title": "ML-driven Malware that Targets AV Safety", "comments": "Accepted for DSN 2020", "journal-ref": "2020 50th Annual IEEE/IFIP International Conference on Dependable\n  Systems and Networks", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring the safety of autonomous vehicles (AVs) is critical for their mass\ndeployment and public adoption. However, security attacks that violate safety\nconstraints and cause accidents are a significant deterrent to achieving public\ntrust in AVs, and that hinders a vendor's ability to deploy AVs. Creating a\nsecurity hazard that results in a severe safety compromise (for example, an\naccident) is compelling from an attacker's perspective. In this paper, we\nintroduce an attack model, a method to deploy the attack in the form of smart\nmalware, and an experimental evaluation of its impact on production-grade\nautonomous driving software. We find that determining the time interval during\nwhich to launch the attack is{ critically} important for causing safety hazards\n(such as collisions) with a high degree of success. For example, the smart\nmalware caused 33X more forced emergency braking than random attacks did, and\naccidents in 52.6% of the driving simulations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 22:29:59 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 01:42:56 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Jha", "Saurabh", ""], ["Cui", "Shengkun", ""], ["Banerjee", "Subho S.", ""], ["Tsai", "Timothy", ""], ["Kalbarczyk", "Zbigniew", ""], ["Iyer", "Ravi", ""]]}, {"id": "2004.13005", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Amro El-Jaroudi, William Hartmann, Damianos Karakos,\n  Lingjun Zhao", "title": "Cross-lingual Information Retrieval with BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple neural language models have been developed recently, e.g., BERT and\nXLNet, and achieved impressive results in various NLP tasks including sentence\nclassification, question answering and document ranking. In this paper, we\nexplore the use of the popular bidirectional language model, BERT, to model and\nlearn the relevance between English queries and foreign-language documents in\nthe task of cross-lingual information retrieval. A deep relevance matching\nmodel based on BERT is introduced and trained by finetuning a pretrained\nmultilingual BERT model with weak supervision, using home-made CLIR training\ndata derived from parallel corpora. Experimental results of the retrieval of\nLithuanian documents against short English queries show that our model is\neffective and outperforms the competitive baseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:32:13 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jiang", "Zhuolin", ""], ["El-Jaroudi", "Amro", ""], ["Hartmann", "William", ""], ["Karakos", "Damianos", ""], ["Zhao", "Lingjun", ""]]}, {"id": "2004.13006", "submitter": "Onur Barut", "authors": "Onur Barut, Yan Luo, Tong Zhang, Weigang Li, Peilong Li", "title": "NetML: A Challenge for Network Traffic Analytics", "comments": "27 pages, 39 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classifying network traffic is the basis for important network applications.\nPrior research in this area has faced challenges on the availability of\nrepresentative datasets, and many of the results cannot be readily reproduced.\nSuch a problem is exacerbated by emerging data-driven machine learning based\napproaches. To address this issue, we provide three open datasets containing\nalmost 1.3M labeled flows in total, with flow features and anonymized raw\npackets, for the research community. We focus on broad aspects in network\ntraffic analysis, including both malware detection and application\nclassification. We release the datasets in the form of an open challenge called\nNetML and implement several machine learning methods including random-forest,\nSVM and MLP. As we continue to grow NetML, we expect the datasets to serve as a\ncommon platform for AI driven, reproducible research on network flow analytics.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 01:12:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Barut", "Onur", ""], ["Luo", "Yan", ""], ["Zhang", "Tong", ""], ["Li", "Weigang", ""], ["Li", "Peilong", ""]]}, {"id": "2004.13007", "submitter": "Mar\\'ia N. Moreno Garc\\'ia", "authors": "Diego S\\'anchez-Moreno, Vivian F. L\\'opez Batista, M. Dolores Mu\\~noz\n  Vicente, Ana B. Gil Gonz\\'alez and Mar\\'ia N. Moreno-Garc\\'ia", "title": "A session-based song recommendation approach involving user\n  characterization along the play power-law distribution", "comments": "Accepted in Complexity (ISSN: 1099-0526)", "journal-ref": null, "doi": "10.1155/2020/7309453", "report-no": null, "categories": "cs.IR cs.HC cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, streaming music platforms have become very popular mainly\ndue to the huge number of songs these systems make available to users. This\nenormous availability means that recommendation mechanisms that help users to\nselect the music they like need to be incorporated. However, developing\nreliable recommender systems in the music field involves dealing with many\nproblems, some of which are generic and widely studied in the literature, while\nothers are specific to this application domain and are therefore less\nwell-known. This work is focused on two important issues that have not received\nmuch attention: managing gray-sheep users and obtaining implicit ratings. The\nfirst one is usually addressed by resorting to content information that is\noften difficult to obtain. The other drawback is related to the sparsity\nproblem that arises when there are obstacles to gather explicit ratings. In\nthis work, the referred shortcomings are addressed by means of a recommendation\napproach based on the users' streaming sessions. The method is aimed at\nmanaging the well-known power-law probability distribution representing the\nlistening behavior of users. This proposal improves the recommendation\nreliability of collaborative filtering methods while reducing the complexity of\nthe procedures used so far to deal with the gray-sheep problem.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 07:17:03 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["S\u00e1nchez-Moreno", "Diego", ""], ["Batista", "Vivian F. L\u00f3pez", ""], ["Vicente", "M. Dolores Mu\u00f1oz", ""], ["Gonz\u00e1lez", "Ana B. Gil", ""], ["Moreno-Garc\u00eda", "Mar\u00eda N.", ""]]}, {"id": "2004.13011", "submitter": "Jun Zhang", "authors": "Jun Zhang, Yao-Kun Lei, Zhen Zhang, Junhan Chang, Maodong Li, Xu Han,\n  Lijiang Yang, Yi Isaac Yang and Yi Qin Gao", "title": "A Perspective on Deep Learning for Molecular Modeling and Simulations", "comments": null, "journal-ref": "J.Phys.Chem.A,2020,124,34,6745-6763", "doi": "10.1021/acs.jpca.0c04473", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is transforming many areas in science, and it has great\npotential in modeling molecular systems. However, unlike the mature deployment\nof deep learning in computer vision and natural language processing, its\ndevelopment in molecular modeling and simulations is still at an early stage,\nlargely because the inductive biases of molecules are completely different from\nthose of images or texts. Footed on these differences, we first reviewed the\nlimitations of traditional deep learning models from the perspective of\nmolecular physics, and wrapped up some relevant technical advancement at the\ninterface between molecular modeling and deep learning. We do not focus merely\non the ever more complex neural network models, instead, we emphasize the\ntheories and ideas behind modern deep learning. We hope that transacting these\nideas into molecular modeling will create new opportunities. For this purpose,\nwe summarized several representative applications, ranging from supervised to\nunsupervised and reinforcement learning, and discussed their connections with\nthe emerging trends in deep learning. Finally, we outlook promising directions\nwhich may help address the existing issues in the current framework of deep\nmolecular modeling.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 22:58:25 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Zhang", "Jun", ""], ["Lei", "Yao-Kun", ""], ["Zhang", "Zhen", ""], ["Chang", "Junhan", ""], ["Li", "Maodong", ""], ["Han", "Xu", ""], ["Yang", "Lijiang", ""], ["Yang", "Yi Isaac", ""], ["Gao", "Yi Qin", ""]]}, {"id": "2004.13012", "submitter": "Dara Bahri", "authors": "Dara Bahri, Yi Tay, Che Zheng, Donald Metzler, Andrew Tomkins", "title": "Choppy: Cut Transformer For Ranked List Truncation", "comments": "SIGIR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work in information retrieval has traditionally focused on ranking and\nrelevance: given a query, return some number of results ordered by relevance to\nthe user. However, the problem of determining how many results to return, i.e.\nhow to optimally truncate the ranked result list, has received less attention\ndespite being of critical importance in a range of applications. Such\ntruncation is a balancing act between the overall relevance, or usefulness of\nthe results, with the user cost of processing more results. In this work, we\npropose Choppy, an assumption-free model based on the widely successful\nTransformer architecture, to the ranked list truncation problem. Needing\nnothing more than the relevance scores of the results, the model uses a\npowerful multi-head attention mechanism to directly optimize any user-defined\nIR metric. We show Choppy improves upon recent state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 00:52:49 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bahri", "Dara", ""], ["Tay", "Yi", ""], ["Zheng", "Che", ""], ["Metzler", "Donald", ""], ["Tomkins", "Andrew", ""]]}, {"id": "2004.13013", "submitter": "Ali Borji", "authors": "Ali Borji", "title": "Harnessing adversarial examples with a surprisingly simple defense", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce a very simple method to defend against adversarial examples. The\nbasic idea is to raise the slope of the ReLU function at the test time.\nExperiments over MNIST and CIFAR-10 datasets demonstrate the effectiveness of\nthe proposed defense against a number of strong attacks in both untargeted and\ntargeted settings. While perhaps not as effective as the state of the art\nadversarial defenses, this approach can provide insights to understand and\nmitigate adversarial attacks. It can also be used in conjunction with other\ndefenses.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 03:09:42 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 22:49:12 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 02:52:54 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Borji", "Ali", ""]]}, {"id": "2004.13021", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Frank Schulz, Lefteris Angelis, David Pahor, Ivona\n  Brandic, David Atlan, Rosemary Tate", "title": "Towards an Integrated Platform for Big Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data in the world is expanding rapidly. Every day, huge amounts\nof data are created by scientific experiments, companies, and end users'\nactivities. These large data sets have been labeled as \"Big Data\", and their\nstorage, processing and analysis presents a plethora of new challenges to\ncomputer science researchers and IT professionals. In addition to efficient\ndata management, additional complexity arises from dealing with semi-structured\nor unstructured data, and from time critical processing requirements. In order\nto understand these massive amounts of data, advanced visualization and data\nexploration techniques are required. Innovative approaches to these challenges\nhave been developed during recent years, and continue to be a hot topic for\nre-search and industry in the future. An investigation of current approaches\nreveals that usually only one or two aspects are ad-dressed, either in the data\nmanagement, processing, analysis or visualization. This paper presents the\nvision of an integrated plat-form for big data analysis that combines all these\naspects. Main benefits of this approach are an enhanced scalability of the\nwhole platform, a better parameterization of algorithms, a more efficient usage\nof system resources, and an improved usability during the end-to-end data\nanalysis process.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 03:15:23 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Schulz", "Frank", ""], ["Angelis", "Lefteris", ""], ["Pahor", "David", ""], ["Brandic", "Ivona", ""], ["Atlan", "David", ""], ["Tate", "Rosemary", ""]]}, {"id": "2004.13023", "submitter": "Hufei Zhu", "authors": "Hufei Zhu", "title": "Efficient Inverse-Free Incremental and Decremental Algorithms for\n  Multiple Hidden Nodes in Extreme Learning Machine", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.04856", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse-free extreme learning machine (ELM) algorithm proposed in [4] was\nbased on an inverse-free algorithm to compute the regularized pseudo-inverse,\nwhich was deduced from an inverse-free recursive algorithm to update the\ninverse of a Hermitian matrix. Before that recursive algorithm was applied in\n[4], its improved version had been utilized in previous literatures [9], [10].\nAccordingly from the improved recursive algorithm [9], [10], several efficient\ninverse-free algorithms for ELM were proposed in [13] to reduce the\ncomputational complexity. In this paper, we propose two inverse-free algorithms\nfor ELM with Tikhonov regularization, which can increase multiple hidden nodes\nin an iteration. On the other hand, we also propose two efficient decremental\nlearning algorithms for ELM with Tikhonov regularization, which can remove\nmultiple redundant nodes in an iteration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 07:04:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhu", "Hufei", ""]]}, {"id": "2004.13027", "submitter": "Sangkug Lym", "authors": "Sangkug Lym, Mattan Erez", "title": "FlexSA: Flexible Systolic Array Architecture for Efficient Pruned DNN\n  Model Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Modern deep learning models have high memory and computation cost. To make\nthem fast and memory-cost efficient, structured model pruning is commonly used.\nWe find that pruning a model using a common training accelerator with large\nsystolic arrays is extremely performance-inefficient. To make a systolic array\nefficient for pruning and training, we propose FlexSA, a flexible systolic\narray architecture. FlexSA dynamically reconfigures the systolic array\nstructure and offers multiple sub-systolic operating modes, which are designed\nfor energy- and memory bandwidth-efficient processing of tensors with different\nsizes and shapes. We also present a compilation heuristic for tiling\nmatrix-multiplication-and-accumulation operations in a training workload to\nbest utilize the resources of FlexSA. Based on our evaluation, FlexSA with the\nproposed compilation heuristic improves compute resource utilization of pruning\nand training modern CNN models by 37% compared to a conventional training\naccelerator with a large systolic array. FlexSA also improves on-chip data\nreuse by 1.7X saving 28% energy compared to naive systolic array splitting.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 15:51:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lym", "Sangkug", ""], ["Erez", "Mattan", ""]]}, {"id": "2004.13066", "submitter": "Azra Bihorac", "authors": "Yanjun Li (4)(5), Yuanfang Ren (1)(5), Tyler J. Loftus (2,5), Shounak\n  Datta (1) (5), M. Ruppert (1)(5), Ziyuan Guan (1)(5), Dapeng Wu (4), Parisa\n  Rashidi (3)(5), Tezcan Ozrazgat-Baslanti (1)(5)(6), and Azra Bihorac\n  (3)(5)(6) ((1) Department of Medicine, Division of Nephrology, Hypertension,\n  and Renal Transplantation, University of Florida, Gainesville, FL. (2)\n  Department of Surgery, University of Florida, Gainesville, FL. (3) J. Crayton\n  Pruitt Family Department of Biomedical Engineering, University of Florida,\n  Gainesville, FL. (4) NSF Center for Big Learning, University of Florida,\n  Gainesville, FL. (5) Precision and Intelligent Systems in Medicine (PrismaP),\n  University of Florida, Gainesville, FL (6) Sepsis and Critical Illness\n  Research Center, University of Florida, Gainesville, FL. )", "title": "Application of Deep Interpolation Network for Clustering of Physiologic\n  Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: During the early stages of hospital admission, clinicians must\nuse limited information to make diagnostic and treatment decisions as patient\nacuity evolves. However, it is common that the time series vital sign\ninformation from patients to be both sparse and irregularly collected, which\nposes a significant challenge for machine / deep learning techniques to analyze\nand facilitate the clinicians to improve the human health outcome. To deal with\nthis problem, We propose a novel deep interpolation network to extract latent\nrepresentations from sparse and irregularly sampled time-series vital signs\nmeasured within six hours of hospital admission. Methods: We created a\nsingle-center longitudinal dataset of electronic health record data for all\n(n=75,762) adult patient admissions to a tertiary care center lasting six hours\nor longer, using 55% of the dataset for training, 23% for validation, and 22%\nfor testing. All raw time series within six hours of hospital admission were\nextracted for six vital signs (systolic blood pressure, diastolic blood\npressure, heart rate, temperature, blood oxygen saturation, and respiratory\nrate). A deep interpolation network is proposed to learn from such irregular\nand sparse multivariate time series data to extract the fixed low-dimensional\nlatent patterns. We use k-means clustering algorithm to clusters the patient\nadmissions resulting into 7 clusters. Findings: Training, validation, and\ntesting cohorts had similar age (55-57 years), sex (55% female), and admission\nvital signs. Seven distinct clusters were identified. M Interpretation: In a\nheterogeneous cohort of hospitalized patients, a deep interpolation network\nextracted representations from vital sign data measured within six hours of\nhospital admission. This approach may have important implications for clinical\ndecision-support under time constraints and uncertainty.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:03:24 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Li", "Yanjun", ""], ["Ren", "Yuanfang", ""], ["Loftus", "Tyler J.", ""], ["Datta", "Shounak", ""], ["Ruppert", "M.", ""], ["Guan", "Ziyuan", ""], ["Wu", "Dapeng", ""], ["Rashidi", "Parisa", ""], ["Ozrazgat-Baslanti", "Tezcan", ""], ["Bihorac", "Azra", ""]]}, {"id": "2004.13073", "submitter": "Matteo Stefanini", "authors": "Matteo Stefanini, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara", "title": "A Novel Attention-based Aggregation Function to Combine Vision and\n  Language", "comments": "ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The joint understanding of vision and language has been recently gaining a\nlot of attention in both the Computer Vision and Natural Language Processing\ncommunities, with the emergence of tasks such as image captioning, image-text\nmatching, and visual question answering. As both images and text can be encoded\nas sets or sequences of elements -- like regions and words -- proper reduction\nfunctions are needed to transform a set of encoded elements into a single\nresponse, like a classification or similarity score. In this paper, we propose\na novel fully-attentive reduction method for vision and language. Specifically,\nour approach computes a set of scores for each element of each modality\nemploying a novel variant of cross-attention, and performs a learnable and\ncross-modal reduction, which can be used for both classification and ranking.\nWe test our approach on image-text matching and visual question answering,\nbuilding fair comparisons with other reduction choices, on both COCO and VQA\n2.0 datasets. Experimentally, we demonstrate that our approach leads to a\nperformance increase on both tasks. Further, we conduct ablation studies to\nvalidate the role of each component of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:09:46 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 12:22:38 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Stefanini", "Matteo", ""], ["Cornia", "Marcella", ""], ["Baraldi", "Lorenzo", ""], ["Cucchiara", "Rita", ""]]}, {"id": "2004.13074", "submitter": "Phat Nguyen", "authors": "Kevin Weston, Vahid Jafanza, Arnav Kansal, Abhishek Taur, Mohamed\n  Zahran, Abdullah Muzahid", "title": "The Case for Learning Application Behavior to Improve Hardware Energy\n  Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer applications are continuously evolving. However, significant\nknowledge can be harvested from a set of applications and applied in the\ncontext of unknown applications. In this paper, we propose to use the harvested\nknowledge to tune hardware configurations. The goal of such tuning is to\nmaximize hardware efficiency (i.e., maximize an applications performance while\nminimizing the energy consumption). Our proposed approach, called FORECASTER,\nuses a deep learning model to learn what configuration of hardware resources\nprovides the optimal energy efficiency for a certain behavior of an\napplication. During the execution of an unseen application, the model uses the\nlearned knowledge to reconfigure hardware resources in order to maximize energy\nefficiency. We have provided a detailed design and implementation of FORECASTER\nand compared its performance against a prior state-of-the-art hardware\nreconfiguration approach. Our results show that FORECASTER can save as much as\n18.4% system power over the baseline set up with all resources. On average,\nFORECASTER saves 16% system power over the baseline setup while sacrificing\nless than 0.01% of overall performance. Compared to the prior scheme,\nFORECASTER increases power savings by 7%.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:11:12 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 20:12:39 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Weston", "Kevin", ""], ["Jafanza", "Vahid", ""], ["Kansal", "Arnav", ""], ["Taur", "Abhishek", ""], ["Zahran", "Mohamed", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "2004.13081", "submitter": "Matthew Leon", "authors": "Matthew Leon", "title": "The Dark Side of Unikernels for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the shortcomings of unikernels as a method of deployment\nfor machine learning inferencing applications as well as provides insights and\nanalysis on future work in this space. The findings of this paper advocate for\na tool to enable management of dependent libraries in a unikernel to enable a\nmore ergonomic build process as well as take advantage of the inherent security\nand performance benefits of unikernels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 18:33:46 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Leon", "Matthew", ""]]}, {"id": "2004.13102", "submitter": "Gagan Bansal", "authors": "Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, Daniel S. Weld", "title": "Is the Most Accurate AI the Best Teammate? Optimizing AI for Teamwork", "comments": "v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI practitioners typically strive to develop the most accurate systems,\nmaking an implicit assumption that the AI system will function autonomously.\nHowever, in practice, AI systems often are used to provide advice to people in\ndomains ranging from criminal justice and finance to healthcare. In such\nAI-advised decision making, humans and machines form a team, where the human is\nresponsible for making final decisions. But is the most accurate AI the best\nteammate? We argue \"No\" -- predictable performance may be worth a slight\nsacrifice in AI accuracy. Instead, we argue that AI systems should be trained\nin a human-centered manner, directly optimized for team performance. We study\nthis proposal for a specific type of human-AI teaming, where the human overseer\nchooses to either accept the AI recommendation or solve the task themselves. To\noptimize the team performance for this setting we maximize the team's expected\nutility, expressed in terms of the quality of the final decision, cost of\nverifying, and individual accuracies of people and machines. Our experiments\nwith linear and non-linear models on real-world, high-stakes datasets show that\nthe most accuracy AI may not lead to highest team performance and show the\nbenefit of modeling teamwork during training through improvements in expected\nteam utility across datasets, considering parameters such as human skill and\nthe cost of mistakes. We discuss the shortcoming of current optimization\napproaches beyond well-studied loss functions such as log-loss, and encourage\nfuture work on AI optimization problems motivated by human-AI collaboration.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:06:28 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 02:07:57 GMT"}, {"version": "v3", "created": "Fri, 19 Feb 2021 20:22:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Bansal", "Gagan", ""], ["Nushi", "Besmira", ""], ["Kamar", "Ece", ""], ["Horvitz", "Eric", ""], ["Weld", "Daniel S.", ""]]}, {"id": "2004.13106", "submitter": "Beyza Ermis Ms", "authors": "Beyza Ermis, Patrick Ernst, Yannik Stein, Giovanni Zappella", "title": "Learning to Rank in the Position Based Model with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is a crucial aspect of many online experiences. In\nparticular, content ranking is often a key component in delivering\nsophisticated personalization results. Commonly, supervised learning-to-rank\nmethods are applied, which suffer from bias introduced during data collection\nby production systems in charge of producing the ranking. To compensate for\nthis problem, we leverage contextual multi-armed bandits. We propose novel\nextensions of two well-known algorithms viz. LinUCB and Linear Thompson\nSampling to the ranking use-case. To account for the biases in a production\nenvironment, we employ the position-based click model. Finally, we show the\nvalidity of the proposed algorithms by conducting extensive offline experiments\non synthetic datasets as well as customer facing online A/B experiments.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:12:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ermis", "Beyza", ""], ["Ernst", "Patrick", ""], ["Stein", "Yannik", ""], ["Zappella", "Giovanni", ""]]}, {"id": "2004.13122", "submitter": "Seifedine Kadry", "authors": "Seifedine Kadry, Venkatesan Rajinikanth, Seungmin Rho, Nadaradjane Sri\n  Madhava Raja, Vaddi Seshagiri Rao, Krishnan Palani Thanaraj", "title": "Development of a Machine-Learning System to Classify Lung CT Scan Images\n  into Normal/COVID-19 Class", "comments": "16 PAGES", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the lung infection due to Coronavirus Disease (COVID-19) affected a\nlarge human group worldwide and the assessment of the infection rate in the\nlung is essential for treatment planning. This research aims to propose a\nMachine-Learning-System (MLS) to detect the COVID-19 infection using the CT\nscan Slices (CTS). This MLS implements a sequence of methods, such as\nmulti-thresholding, image separation using threshold filter,\nfeature-extraction, feature-selection, feature-fusion and classification. The\ninitial part implements the Chaotic-Bat-Algorithm and Kapur's Entropy (CBA+KE)\nthresholding to enhance the CTS. The threshold filter separates the image into\ntwo segments based on a chosen threshold 'Th'. The texture features of these\nimages are extracted, refined and selected using the chosen procedures.\nFinally, a two-class classifier system is implemented to categorize the chosen\nCTS (n=500 with a pixel dimension of 512x512x1) into normal/COVID-19 group. In\nthis work, the classifiers, such as Naive Bayes (NB), k-Nearest Neighbors\n(KNN), Decision Tree (DT), Random Forest (RF) and Support Vector Machine with\nlinear kernel (SVM) are implemented and the classification task is performed\nusing various feature vectors. The experimental outcome of the SVM with\nFused-Feature-Vector (FFV) helped to attain a detection accuracy of 89.80%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:52:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kadry", "Seifedine", ""], ["Rajinikanth", "Venkatesan", ""], ["Rho", "Seungmin", ""], ["Raja", "Nadaradjane Sri Madhava", ""], ["Rao", "Vaddi Seshagiri", ""], ["Thanaraj", "Krishnan Palani", ""]]}, {"id": "2004.13135", "submitter": "Florian Krach", "authors": "Calypso Herrera, Florian Krach, Josef Teichmann", "title": "Estimating Full Lipschitz Constants of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the Lipschitz constants of the gradient of a deep neural network\nand the network itself with respect to the full set of parameters. We first\ndevelop estimates for a deep feed-forward densely connected network and then,\nin a more general framework, for all neural networks that can be represented as\nsolutions of controlled ordinary differential equations, where time appears as\ncontinuous depth. These estimates can be used to set the step size of\nstochastic gradient descent methods, which is illustrated for one example\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:02:04 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:29:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Herrera", "Calypso", ""], ["Krach", "Florian", ""], ["Teichmann", "Josef", ""]]}, {"id": "2004.13138", "submitter": "Jinghui Lu", "authors": "Jinghui Lu and Brian MacNamee", "title": "Investigating the Effectiveness of Representations Based on Pretrained\n  Transformer-based Language Models in Active Learning for Labelling Text\n  Datasets", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.03505", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning has been shown to be an effective way to alleviate some of\nthe effort required in utilising large collections of unlabelled data for\nmachine learning tasks without needing to fully label them. The representation\nmechanism used to represent text documents when performing active learning,\nhowever, has a significant influence on how effective the process will be.\nWhile simple vector representations such as bag-of-words and embedding-based\nrepresentations based on techniques such as word2vec have been shown to be an\neffective way to represent documents during active learning, the emergence of\nrepresentation mechanisms based on the pre-trained transformer-based neural\nnetwork models popular in natural language processing research (e.g. BERT)\noffer a promising, and as yet not fully explored, alternative. This paper\ndescribes a comprehensive evaluation of the effectiveness of representations\nbased on pre-trained transformer-based language models for active learning.\nThis evaluation shows that transformer-based models, especially BERT-like\nmodels, that have not yet been widely used in active learning, achieve a\nsignificant improvement over more commonly used vector representations like\nbag-of-words or other classical word embeddings like word2vec. This paper also\ninvestigates the effectiveness of representations based on variants of BERT\nsuch as Roberta, Albert as well as comparing the effectiveness of the [CLS]\ntoken representation and the aggregated representation that can be generated\nusing BERT-like models. Finally, we propose an approach Adaptive Tuning Active\nLearning. Our experiments show that the limited label information acquired in\nactive learning can not only be used for training a classifier but can also\nadaptively improve the embeddings generated by the BERT-like language models as\nwell.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 02:37:44 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lu", "Jinghui", ""], ["MacNamee", "Brian", ""]]}, {"id": "2004.13139", "submitter": "Yang Sun", "authors": "Yang Sun, Fajie Yuan, Min Yang, Guoao Wei, Zhou Zhao, and Duo Liu", "title": "A Generic Network Compression Framework for Sequential Recommender\n  Systems", "comments": "Accepted by SIGIR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential recommender systems (SRS) have become the key technology in\ncapturing user's dynamic interests and generating high-quality recommendations.\nCurrent state-of-the-art sequential recommender models are typically based on a\nsandwich-structured deep neural network, where one or more middle (hidden)\nlayers are placed between the input embedding layer and output softmax layer.\nIn general, these models require a large number of parameters (such as using a\nlarge embedding dimension or a deep network architecture) to obtain their\noptimal performance. Despite the effectiveness, at some point, further\nincreasing model size may be harder for model deployment in resource-constraint\ndevices, resulting in longer responding time and larger memory footprint. To\nresolve the issues, we propose a compressed sequential recommendation\nframework, termed as CpRec, where two generic model shrinking techniques are\nemployed. Specifically, we first propose a block-wise adaptive decomposition to\napproximate the input and softmax matrices by exploiting the fact that items in\nSRS obey a long-tailed distribution. To reduce the parameters of the middle\nlayers, we introduce three layer-wise parameter sharing schemes. We instantiate\nCpRec using deep convolutional neural network with dilated kernels given\nconsideration to both recommendation accuracy and efficiency. By the extensive\nablation studies, we demonstrate that the proposed CpRec can achieve up to\n4$\\sim$8 times compression rates in real-world SRS datasets. Meanwhile, CpRec\nis faster during training\\inference, and in most cases outperforms its\nuncompressed counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 08:40:55 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 08:10:16 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 03:16:13 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 14:49:16 GMT"}, {"version": "v5", "created": "Tue, 26 May 2020 06:25:41 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Sun", "Yang", ""], ["Yuan", "Fajie", ""], ["Yang", "Min", ""], ["Wei", "Guoao", ""], ["Zhao", "Zhou", ""], ["Liu", "Duo", ""]]}, {"id": "2004.13146", "submitter": "Xin Qian", "authors": "Xin Qian, Diego Klabjan", "title": "The Impact of the Mini-batch Size on the Variance of Gradients in\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mini-batch stochastic gradient descent (SGD) algorithm is widely used in\ntraining machine learning models, in particular deep learning models. We study\nSGD dynamics under linear regression and two-layer linear networks, with an\neasy extension to deeper linear networks, by focusing on the variance of the\ngradients, which is the first study of this nature. In the linear regression\ncase, we show that in each iteration the norm of the gradient is a decreasing\nfunction of the mini-batch size $b$ and thus the variance of the stochastic\ngradient estimator is a decreasing function of $b$. For deep neural networks\nwith $L_2$ loss we show that the variance of the gradient is a polynomial in\n$1/b$. The results back the important intuition that smaller batch sizes yield\nlower loss function values which is a common believe among the researchers. The\nproof techniques exhibit a relationship between stochastic gradient estimators\nand initial weights, which is useful for further research on the dynamics of\nSGD. We empirically provide further insights to our results on various datasets\nand commonly used deep network structures.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:06:11 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Qian", "Xin", ""], ["Klabjan", "Diego", ""]]}, {"id": "2004.13148", "submitter": "Lauri Alho", "authors": "Lauri Alho, Adrian Burian, Janne Helenius, Joni Pajarinen", "title": "Machine Learning Based Mobile Network Throughput Classification", "comments": "Submitted to IEEE International Symposium on Personal, Indoor and\n  Mobile Radio Communications 2020 (IEEE PIMRC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying mobile network problems in 4G cells is more challenging when the\ncomplexity of the network increases, and privacy concerns limit the information\ncontent of the data. This paper proposes a data driven model for identifying 4G\ncells that have fundamental network throughput problems. The proposed model\ntakes advantage of clustering and Deep Neural Networks (DNNs). Model parameters\nare learnt using a small number of expert-labeled data. To achieve case\nspecific classification, we propose a model that contains a multiple clustering\nmodels block, for capturing features common for problematic cells. The captured\nfeatures of this block are then used as an input to a DNN. Experiments show\nthat the proposed model outperforms a simple classifier in identifying cells\nwith network throughput problems. To the best of the authors' knowledge, there\nis no related research where network throughput classification is performed on\nthe cell level with information gathered only from the service provider's side.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:08:06 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Alho", "Lauri", ""], ["Burian", "Adrian", ""], ["Helenius", "Janne", ""], ["Pajarinen", "Joni", ""]]}, {"id": "2004.13152", "submitter": "Joshua Lockhart", "authors": "Joshua Lockhart, Samuel Assefa, Tucker Balch, Manuela Veloso", "title": "Some people aren't worth listening to: periodically retraining\n  classifiers with feedback from a team of end users", "comments": "Presented at the 2019 ICML Workshop on AI in Finance: Applications\n  and Infrastructure for Multi-Agent Learning. Long Beach, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document classification is ubiquitous in a business setting, but often the\nend users of a classifier are engaged in an ongoing feedback-retrain loop with\nthe team that maintain it. We consider this feedback-retrain loop from a\nmulti-agent point of view, considering the end users as autonomous agents that\nprovide feedback on the labelled data provided by the classifier. This allows\nus to examine the effect on the classifier's performance of unreliable end\nusers who provide incorrect feedback. We demonstrate a classifier that can\nlearn which users tend to be unreliable, filtering their feedback out of the\nloop, thus improving performance in subsequent iterations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:18:29 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lockhart", "Joshua", ""], ["Assefa", "Samuel", ""], ["Balch", "Tucker", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.13160", "submitter": "Jie Yang", "authors": "Jie Yang and Chin-Teng Lin", "title": "Clustering via torque balance with mass and distance", "comments": "28 pages, 12 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grouping similar objects is a fundamental tool of scientific analysis,\nubiquitous in disciplines from biology and chemistry to astronomy and pattern\nrecognition. Inspired by the torque balance that exists in gravitational\ninteractions when galaxies merge, we propose a novel clustering method based on\ntwo natural properties of the universe: mass and distance. The concept of\ntorque describing the interactions of mass and distance forms the basis of the\nproposed parameter-free clustering algorithm, which harnesses torque balance to\nrecognize any cluster, regardless of shape, size, or density. The gravitational\ninteractions govern the merger process, while the concept of torque balance\nreveals partitions that do not conform to the natural order for removal.\nExperiments on benchmark data sets show the enormous versatility of the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:34:06 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yang", "Jie", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "2004.13167", "submitter": "Joshua Meier", "authors": "Yilun Du, Joshua Meier, Jerry Ma, Rob Fergus, Alexander Rives", "title": "Energy-based models for atomic-resolution protein conformations", "comments": "Accepted to ICLR 2020", "journal-ref": "International Conference on Learning Representations (ICLR), 2020", "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an energy-based model (EBM) of protein conformations that operates\nat atomic scale. The model is trained solely on crystallized protein data. By\ncontrast, existing approaches for scoring conformations use energy functions\nthat incorporate knowledge of physical principles and features that are the\ncomplex product of several decades of research and tuning. To evaluate the\nmodel, we benchmark on the rotamer recovery task, the problem of predicting the\nconformation of a side chain from its context within a protein structure, which\nhas been used to evaluate energy functions for protein design. The model\nachieves performance close to that of the Rosetta energy function, a\nstate-of-the-art method widely used in protein structure prediction and design.\nAn investigation of the model's outputs and hidden representations finds that\nit captures physicochemical properties relevant to protein energy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:45:12 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Du", "Yilun", ""], ["Meier", "Joshua", ""], ["Ma", "Jerry", ""], ["Fergus", "Rob", ""], ["Rives", "Alexander", ""]]}, {"id": "2004.13172", "submitter": "Joseph Colonel", "authors": "Joseph Colonel and Christopher Curro and Sam Keene", "title": "Autoencoding Neural Networks as Musical Audio Synthesizers", "comments": null, "journal-ref": "Proceedings of the 21st International Conference on Digital Audio\n  Effects (DAFx-18), 2018, pp40-44", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for musical audio synthesis using autoencoding neural networks is\nproposed. The autoencoder is trained to compress and reconstruct magnitude\nshort-time Fourier transform frames. The autoencoder produces a spectrogram by\nactivating its smallest hidden layer, and a phase response is calculated using\nreal-time phase gradient heap integration. Taking an inverse short-time Fourier\ntransform produces the audio signal. Our algorithm is light-weight when\ncompared to current state-of-the-art audio-producing machine learning\nalgorithms. We outline our design process, produce metrics, and detail an\nopen-source Python implementation of our model.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:58:03 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Colonel", "Joseph", ""], ["Curro", "Christopher", ""], ["Keene", "Sam", ""]]}, {"id": "2004.13173", "submitter": "Fangliang Bai", "authors": "Fangliang Bai, Jinchao Liu, Xiaojuan Liu, Margarita Osadchy, Chao\n  Wang, Stuart J. Gibson", "title": "LSHR-Net: a hardware-friendly solution for high-resolution computational\n  imaging using a mixed-weights neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work showed neural-network-based approaches to reconstructing images\nfrom compressively sensed measurements offer significant improvements in\naccuracy and signal compression. Such methods can dramatically boost the\ncapability of computational imaging hardware. However, to date, there have been\ntwo major drawbacks: (1) the high-precision real-valued sensing patterns\nproposed in the majority of existing works can prove problematic when used with\ncomputational imaging hardware such as a digital micromirror sampling device\nand (2) the network structures for image reconstruction involve intensive\ncomputation, which is also not suitable for hardware deployment. To address\nthese problems, we propose a novel hardware-friendly solution based on\nmixed-weights neural networks for computational imaging. In particular, learned\nbinary-weight sensing patterns are tailored to the sampling device. Moreover,\nwe proposed a recursive network structure for low-resolution image sampling and\nhigh-resolution reconstruction scheme. It reduces both the required number of\nmeasurements and reconstruction computation by operating convolution on small\nintermediate feature maps. The recursive structure further reduced the model\nsize, making the network more computationally efficient when deployed with the\nhardware. Our method has been validated on benchmark datasets and achieved the\nstate of the art reconstruction accuracy. We tested our proposed network in\nconjunction with a proof-of-concept hardware setup.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:59:51 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bai", "Fangliang", ""], ["Liu", "Jinchao", ""], ["Liu", "Xiaojuan", ""], ["Osadchy", "Margarita", ""], ["Wang", "Chao", ""], ["Gibson", "Stuart J.", ""]]}, {"id": "2004.13175", "submitter": "Mohammad Morid", "authors": "Mohammad Amin Morid, Alireza Borjali, Guilherme Del Fiol", "title": "A scoping review of transfer learning research on medical image analysis\n  using ImageNet", "comments": null, "journal-ref": "Computers in Biology and Medicine, 128 (2021)", "doi": "10.1016/j.compbiomed.2020.104115", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Employing transfer learning (TL) with convolutional neural\nnetworks (CNNs), well-trained on non-medical ImageNet dataset, has shown\npromising results for medical image analysis in recent years. We aimed to\nconduct a scoping review to identify these studies and summarize their\ncharacteristics in terms of the problem description, input, methodology, and\noutcome. Materials and Methods: To identify relevant studies, MEDLINE, IEEE,\nand ACM digital library were searched. Two investigators independently reviewed\narticles to determine eligibility and to extract data according to a study\nprotocol defined a priori. Results: After screening of 8,421 articles, 102 met\nthe inclusion criteria. Of 22 anatomical areas, eye (18%), breast (14%), and\nbrain (12%) were the most commonly studied. Data augmentation was performed in\n72% of fine-tuning TL studies versus 15% of the feature-extracting TL studies.\nInception models were the most commonly used in breast related studies (50%),\nwhile VGGNet was the common in eye (44%), skin (50%) and tooth (57%) studies.\nAlexNet for brain (42%) and DenseNet for lung studies (38%) were the most\nfrequently used models. Inception models were the most frequently used for\nstudies that analyzed ultrasound (55%), endoscopy (57%), and skeletal system\nX-rays (57%). VGGNet was the most common for fundus (42%) and optical coherence\ntomography images (50%). AlexNet was the most frequent model for brain MRIs\n(36%) and breast X-Rays (50%). 35% of the studies compared their model with\nother well-trained CNN models and 33% of them provided visualization for\ninterpretation. Discussion: This study identified the most prevalent tracks of\nimplementation in the literature for data preparation, methodology selection\nand output evaluation for medical image analysis. Also, we identified several\ncritical research gaps existing in the TL studies on medical image analysis.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 21:01:45 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 23:22:20 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 22:25:16 GMT"}, {"version": "v4", "created": "Thu, 12 Nov 2020 18:21:39 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 18:25:06 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Morid", "Mohammad Amin", ""], ["Borjali", "Alireza", ""], ["Del Fiol", "Guilherme", ""]]}, {"id": "2004.13181", "submitter": "Sheldon Tan", "authors": "Wentian Jin, Sheriff Sadiqbatcha, Jinwei Zhang, Sheldon X.-D. Tan", "title": "EM-GAN: Fast Stress Analysis for Multi-Segment Interconnect Using\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a fast transient hydrostatic stress analysis for\nelectromigration (EM) failure assessment for multi-segment interconnects using\ngenerative adversarial networks (GANs). Our work leverages the image synthesis\nfeature of GAN-based generative deep neural networks. The stress evaluation of\nmulti-segment interconnects, modeled by partial differential equations, can be\nviewed as time-varying 2D-images-to-image problem where the input is the\nmulti-segment interconnects topology with current densities and the output is\nthe EM stress distribution in those wire segments at the given aging time.\nBased on this observation, we train conditional GAN model using the images of\nmany self-generated multi-segment wires and wire current densities and aging\ntime (as conditions) against the COMSOL simulation results. Different\nhyperparameters of GAN were studied and compared. The proposed algorithm,\ncalled {\\it EM-GAN}, can quickly give accurate stress distribution of a general\nmulti-segment wire tree for a given aging time, which is important for\nfull-chip fast EM failure assessment. Our experimental results show that the\nEM-GAN shows 6.6\\% averaged error compared to COMSOL simulation results with\norders of magnitude speedup. It also delivers 8.3X speedup over\nstate-of-the-art analytic based EM analysis solver.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 21:18:11 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Jin", "Wentian", ""], ["Sadiqbatcha", "Sheriff", ""], ["Zhang", "Jinwei", ""], ["Tan", "Sheldon X. -D.", ""]]}, {"id": "2004.13195", "submitter": "Naomi Saphra", "authors": "Naomi Saphra and Adam Lopez", "title": "Word Interdependence Exposes How LSTMs Compose Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in NLP shows that LSTM language models capture compositional\nstructure in language data. For a closer look at how these representations are\ncomposed hierarchically, we present a novel measure of interdependence between\nword meanings in an LSTM, based on their interactions at the internal gates. To\nexplore how compositional representations arise over training, we conduct\nsimple experiments on synthetic data, which illustrate our measure by showing\nhow high interdependence can hurt generalization. These synthetic experiments\nalso illustrate a specific hypothesis about how hierarchical structures are\ndiscovered over the course of training: that parent constituents rely on\neffective representations of their children, rather than on learning long-range\nrelations independently. We further support this measure with experiments on\nEnglish language data, where interdependence is higher for more closely\nsyntactically linked word pairs.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 21:48:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "2004.13202", "submitter": "Bohan Fan", "authors": "Bohan Fan, Diego Ihara Centurion, Neshat Mohammadi, Francesco Sgherzi,\n  Anastasios Sidiropoulos, Mina Valizadeh", "title": "Learning Lines with Ordinal Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding a mapping $f$ from a set of points into the\nreal line, under ordinal triple constraints. An ordinal constraint for a triple\nof points $(u,v,w)$ asserts that $|f(u)-f(v)|<|f(u)-f(w)|$. We present an\napproximation algorithm for the dense case of this problem. Given an instance\nthat admits a solution that satisfies $(1-\\varepsilon)$-fraction of all\nconstraints, our algorithm computes a solution that satisfies\n$(1-O(\\varepsilon^{1/8}))$-fraction of all constraints, in time $O(n^7) +\n(1/\\varepsilon)^{O(1/\\varepsilon^{1/8})} n$.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 22:45:04 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 20:18:26 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Fan", "Bohan", ""], ["Centurion", "Diego Ihara", ""], ["Mohammadi", "Neshat", ""], ["Sgherzi", "Francesco", ""], ["Sidiropoulos", "Anastasios", ""], ["Valizadeh", "Mina", ""]]}, {"id": "2004.13214", "submitter": "Rafael-Michael Karampatsis", "authors": "Rafael - Michael Karampatsis and Charles Sutton", "title": "SCELMo: Source Code Embeddings from Language Models", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous embeddings of tokens in computer programs have been used to\nsupport a variety of software development tools, including readability, code\nsearch, and program repair. Contextual embeddings are common in natural\nlanguage processing but have not been previously applied in software\nengineering. We introduce a new set of deep contextualized word representations\nfor computer programs based on language models. We train a set of embeddings\nusing the ELMo (embeddings from language models) framework of Peters et al\n(2018). We investigate whether these embeddings are effective when fine-tuned\nfor the downstream task of bug detection. We show that even a low-dimensional\nembedding trained on a relatively small corpus of programs can improve a\nstate-of-the-art machine learning system for bug detection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 00:06:25 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Karampatsis", "Rafael - Michael", ""], ["Sutton", "Charles", ""]]}, {"id": "2004.13230", "submitter": "Marjan Albooyeh", "authors": "Marjan Albooyeh, Rishab Goel, Seyed Mehran Kazemi", "title": "Out-of-Sample Representation Learning for Multi-Relational Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important problems can be formulated as reasoning in knowledge graphs.\nRepresentation learning has proved extremely effective for transductive\nreasoning, in which one needs to make new predictions for already observed\nentities. This is true for both attributed graphs(where each entity has an\ninitial feature vector) and non-attributed graphs (where the only initial\ninformation derives from known relations with other entities). For\nout-of-sample reasoning, where one needs to make predictions for entities that\nwere unseen at training time, much prior work considers attributed graph.\nHowever, this problem is surprisingly under-explored for non-attributed graphs.\nIn this paper, we study the out-of-sample representation learning problem for\nnon-attributed knowledge graphs, create benchmark datasets for this task,\ndevelop several models and baselines, and provide empirical analyses and\ncomparisons of the proposed models and baselines.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 00:53:01 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 16:22:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Albooyeh", "Marjan", ""], ["Goel", "Rishab", ""], ["Kazemi", "Seyed Mehran", ""]]}, {"id": "2004.13233", "submitter": "Shixiang Chen", "authors": "Shixiang Chen, Alfredo Garcia and Shahin Shahrampour", "title": "On Distributed Non-convex Optimization: Projected Subgradient Method For\n  Weakly Convex Problems in Networks", "comments": null, "journal-ref": null, "doi": "10.1109/TAC.2021.3056535", "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic subgradient method is a widely-used algorithm for solving\nlarge-scale optimization problems arising in machine learning. Often these\nproblems are neither smooth nor convex. Recently, Davis et al. [1-2]\ncharacterized the convergence of the stochastic subgradient method for the\nweakly convex case, which encompasses many important applications (e.g., robust\nphase retrieval, blind deconvolution, biconvex compressive sensing, and\ndictionary learning). In practice, distributed implementations of the projected\nstochastic subgradient method (stoDPSM) are used to speed-up risk minimization.\nIn this paper, we propose a distributed implementation of the stochastic\nsubgradient method with a theoretical guarantee. Specifically, we show the\nglobal convergence of stoDPSM using the Moreau envelope stationarity measure.\nFurthermore, under a so-called sharpness condition, we show that deterministic\nDPSM (with a proper initialization) converges linearly to the sharp minima,\nusing geometrically diminishing step-size. We provide numerical experiments to\nsupport our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:01:49 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 20:32:36 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Chen", "Shixiang", ""], ["Garcia", "Alfredo", ""], ["Shahrampour", "Shahin", ""]]}, {"id": "2004.13237", "submitter": "Leopoldo Bertossi", "authors": "Leopoldo Bertossi", "title": "An ASP-Based Approach to Counterfactual Explanations for Classification", "comments": "Revised and extended version. To appear in Proc. RuleML+RR, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose answer-set programs that specify and compute counterfactual\ninterventions as a basis for causality-based explanations to decisions produced\nby classification models. They can be applied with black-box models and models\nthat can be specified as logic programs, such as rule-based classifiers. The\nmain focus in on the specification and computation of maximum responsibility\ncausal explanations. The use of additional semantic knowledge is investigated.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:36:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 03:56:13 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Bertossi", "Leopoldo", ""]]}, {"id": "2004.13240", "submitter": "M Saiful Bari", "authors": "M Saiful Bari, Tasnim Mohiuddin, Shafiq Joty", "title": "UXLA: A Robust Unsupervised Data Augmentation Framework for\n  Zero-Resource Cross-Lingual NLP", "comments": "ACL-2021 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has yielded state-of-the-art (SoTA) results in many\nsupervised NLP tasks. However, annotated data for every target task in every\ntarget language is rare, especially for low-resource languages. We propose\nUXLA, a novel unsupervised data augmentation framework for zero-resource\ntransfer learning scenarios. In particular, UXLA aims to solve cross-lingual\nadaptation problems from a source language task distribution to an unknown\ntarget language task distribution, assuming no training label in the target\nlanguage. At its core, UXLA performs simultaneous self-training with data\naugmentation and unsupervised sample selection. To show its effectiveness, we\nconduct extensive experiments on three diverse zero-resource cross-lingual\ntransfer tasks. UXLA achieves SoTA results in all the tasks, outperforming the\nbaselines by a good margin. With an in-depth framework dissection, we\ndemonstrate the cumulative contributions of different components to its\nsuccess.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 01:47:37 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 19:40:50 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 05:38:12 GMT"}, {"version": "v4", "created": "Sat, 26 Jun 2021 04:16:43 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bari", "M Saiful", ""], ["Mohiuddin", "Tasnim", ""], ["Joty", "Shafiq", ""]]}, {"id": "2004.13242", "submitter": "Cameron Allen", "authors": "Cameron Allen, Michael Katz, Tim Klinger, George Konidaris, Matthew\n  Riemer, Gerald Tesauro", "title": "Efficient Black-Box Planning Using Macro-Actions with Focused Effects", "comments": "To appear at IJCAI 2021; code available at\n  https://github.com/camall3n/focused-macros", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of deterministic planning increases exponentially with\nsearch-tree depth. Black-box planning presents an even greater challenge, since\nplanners must operate without an explicit model of the domain. Heuristics can\nmake search more efficient, but goal-aware heuristics for black-box planning\nusually rely on goal counting, which is often quite uninformative. In this\nwork, we show how to overcome this limitation by discovering macro-actions that\nmake the goal-count heuristic more accurate. Our approach searches for\nmacro-actions with focused effects (i.e. macros that modify only a small number\nof state variables), which align well with the assumptions made by the\ngoal-count heuristic. Focused macros dramatically improve black-box planning\nefficiency across a wide range of planning domains, sometimes beating even\nstate-of-the-art planners with access to a full domain model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:13:12 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 13:17:18 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 19:38:24 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Allen", "Cameron", ""], ["Katz", "Michael", ""], ["Klinger", "Tim", ""], ["Konidaris", "George", ""], ["Riemer", "Matthew", ""], ["Tesauro", "Gerald", ""]]}, {"id": "2004.13245", "submitter": "Dai Tran", "authors": "Dai Hoang Tran, Quan Z. Sheng, Wei Emma Zhang, Salma Abdalla Hamad,\n  Munazza Zaib, Nguyen H. Tran, Lina Yao, Nguyen Lu Dang Khoa", "title": "Deep Conversational Recommender Systems: A New Frontier for\n  Goal-Oriented Dialogue Systems", "comments": "7 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the emerging topics of recommender systems that take\nadvantage of natural language processing techniques have attracted much\nattention, and one of their applications is the Conversational Recommender\nSystem (CRS). Unlike traditional recommender systems with content-based and\ncollaborative filtering approaches, CRS learns and models user's preferences\nthrough interactive dialogue conversations. In this work, we provide a\nsummarization of the recent evolution of CRS, where deep learning approaches\nare applied to CRS and have produced fruitful results. We first analyze the\nresearch problems and present key challenges in the development of Deep\nConversational Recommender Systems (DCRS), then present the current state of\nthe field taken from the most recent researches, including the most common deep\nlearning models that benefit DCRS. Finally, we discuss future directions for\nthis vibrant area.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:20:42 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Tran", "Dai Hoang", ""], ["Sheng", "Quan Z.", ""], ["Zhang", "Wei Emma", ""], ["Hamad", "Salma Abdalla", ""], ["Zaib", "Munazza", ""], ["Tran", "Nguyen H.", ""], ["Yao", "Lina", ""], ["Khoa", "Nguyen Lu Dang", ""]]}, {"id": "2004.13248", "submitter": "Tuhin Chakrabarty Mr", "authors": "Tuhin Chakrabarty, and Debanjan Ghosh, and Smaranda Muresan, and\n  Nanyun Peng", "title": "$R^3$: Reverse, Retrieve, and Rank for Sarcasm Generation with\n  Commonsense Knowledge", "comments": "Accepted at the 2020 Annual Conference of the Association for\n  Computational Linguistics (ACL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an unsupervised approach for sarcasm generation based on a\nnon-sarcastic input sentence. Our method employs a retrieve-and-edit framework\nto instantiate two major characteristics of sarcasm: reversal of valence and\nsemantic incongruity with the context which could include shared commonsense or\nworld knowledge between the speaker and the listener. While prior works on\nsarcasm generation predominantly focus on context incongruity, we show that\ncombining valence reversal and semantic incongruity based on the commonsense\nknowledge generates sarcasm of higher quality. Human evaluation shows that our\nsystem generates sarcasm better than human annotators 34% of the time, and\nbetter than a reinforced hybrid baseline 90% of the time.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:30:09 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 20:34:04 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 11:14:11 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 06:42:06 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Chakrabarty", "Tuhin", ""], ["Ghosh", "Debanjan", ""], ["Muresan", "Smaranda", ""], ["Peng", "Nanyun", ""]]}, {"id": "2004.13251", "submitter": "Aymen Hamrouni", "authors": "Aymen Hamrouni, Hakim Ghazzai, Mounir Frikha, and Yehia Massoud", "title": "A Photo-Based Mobile Crowdsourcing Framework for Event Reporting", "comments": "Published in 2019 IEEE 62nd International Midwest Symposium on\n  Circuits and Systems (MWSCAS)", "journal-ref": "2019 IEEE 62nd International Midwest Symposium on Circuits and\n  Systems (MWSCAS), Dallas, TX, USA, 2019, pp. 198-202", "doi": "10.1109/MWSCAS.2019.8884949", "report-no": null, "categories": "cs.CY cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Crowdsourcing (MCS) photo-based is an arising field of interest and a\ntrending topic in the domain of ubiquitous computing. It has recently drawn\nsubstantial attention of the smart cities and urban computing communities. In\nfact, the built-in cameras of mobile devices are becoming the most common way\nfor visual logging techniques in our daily lives. MCS photo-based frameworks\ncollect photos in a distributed way in which a large number of contributors\nupload photos whenever and wherever it is suitable. This inevitably leads to\nevolving picture streams which possibly contain misleading and redundant\ninformation that affects the task result. In order to overcome these issues, we\ndevelop, in this paper, a solution for selecting highly relevant data from an\nevolving picture stream and ensuring correct submission. The proposed\nphoto-based MCS framework for event reporting incorporates (i) a deep learning\nmodel to eliminate false submissions and ensure photos credibility and (ii) an\nA-Tree shape data structure model for clustering streaming pictures to reduce\ninformation redundancy and provide maximum event coverage. Simulation results\nindicate that the implemented framework can effectively reduce false\nsubmissions and select a subset with high utility coverage with low redundancy\nratio from the streaming data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:44:19 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 23:36:15 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hamrouni", "Aymen", ""], ["Ghazzai", "Hakim", ""], ["Frikha", "Mounir", ""], ["Massoud", "Yehia", ""]]}, {"id": "2004.13255", "submitter": "Yaushian Wang", "authors": "Yau-Shian Wang and Hung-Yi Lee and Yun-Nung Chen", "title": "Learning Interpretable and Discrete Representations with Adversarial\n  Training for Unsupervised Text Classification", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning continuous representations from unlabeled textual data has been\nincreasingly studied for benefiting semi-supervised learning. Although it is\nrelatively easier to interpret discrete representations, due to the difficulty\nof training, learning discrete representations for unlabeled textual data has\nnot been widely explored. This work proposes TIGAN that learns to encode texts\ninto two disentangled representations, including a discrete code and a\ncontinuous noise, where the discrete code represents interpretable topics, and\nthe noise controls the variance within the topics. The discrete code learned by\nTIGAN can be used for unsupervised text classification. Compared to other\nunsupervised baselines, the proposed TIGAN achieves superior performance on six\ndifferent corpora. Also, the performance is on par with a recently proposed\nweakly-supervised text classification method. The extracted topical words for\nrepresenting latent topics show that TIGAN learns coherent and highly\ninterpretable topics.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:53:59 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Wang", "Yau-Shian", ""], ["Lee", "Hung-Yi", ""], ["Chen", "Yun-Nung", ""]]}, {"id": "2004.13263", "submitter": "Alex Chang", "authors": "Alex Habeen Chang, Benjamin M. Case", "title": "Attacks on Image Encryption Schemes for Privacy-Preserving Deep Neural\n  Networks", "comments": "For associated code, see\n  https://github.com/ahchang98/image-encryption-scheme-attacks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving machine learning is an active area of research usually\nrelying on techniques such as homomorphic encryption or secure multiparty\ncomputation. Recent novel encryption techniques for performing machine learning\nusing deep neural nets on images have recently been proposed by Tanaka and\nSirichotedumrong, Kinoshita, and Kiya. We present new chosen-plaintext and\nciphertext-only attacks against both of these proposed image encryption schemes\nand demonstrate the attacks' effectiveness on several examples.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 03:34:01 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 06:22:13 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Chang", "Alex Habeen", ""], ["Case", "Benjamin M.", ""]]}, {"id": "2004.13270", "submitter": "Shilin He", "authors": "Shilin He, Xing Wang, Shuming Shi, Michael R. Lyu, Zhaopeng Tu", "title": "Assessing the Bilingual Knowledge Learned by Neural Machine Translation\n  Models", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine translation (MT) systems translate text between different languages\nby automatically learning in-depth knowledge of bilingual lexicons, grammar and\nsemantics from the training examples. Although neural machine translation (NMT)\nhas led the field of MT, we have a poor understanding on how and why it works.\nIn this paper, we bridge the gap by assessing the bilingual knowledge learned\nby NMT models with phrase table -- an interpretable table of bilingual\nlexicons. We extract the phrase table from the training examples that an NMT\nmodel correctly predicts. Extensive experiments on widely-used datasets show\nthat the phrase table is reasonable and consistent against language pairs and\nrandom seeds. Equipped with the interpretable phrase table, we find that NMT\nmodels learn patterns from simple to complex and distill essential bilingual\nknowledge from the training examples. We also revisit some advances that\npotentially affect the learning of bilingual knowledge (e.g.,\nback-translation), and report some interesting findings. We believe this work\nopens a new angle to interpret NMT with statistic models, and provides\nempirical supports for recent advances in improving NMT models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 03:44:34 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["He", "Shilin", ""], ["Wang", "Xing", ""], ["Shi", "Shuming", ""], ["Lyu", "Michael R.", ""], ["Tu", "Zhaopeng", ""]]}, {"id": "2004.13271", "submitter": "Zhaohe Liao", "authors": "Zhaohe Liao", "title": "Trainable Activation Function in Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current research of neural networks, the activation function is\nmanually specified by human and not able to change themselves during training.\nThis paper focus on how to make the activation function trainable for deep\nneural networks. We use series and linear combination of different activation\nfunctions make activation functions continuously variable. Also, we test the\nperformance of CNNs with Fourier series simulated activation(Fourier-CNN) and\nCNNs with linear combined activation function (LC-CNN) on Cifar-10 dataset. The\nresult shows our trainable activation function reveals better performance than\nthe most used ReLU activation function. Finally, we improves the performance of\nFourier-CNN with Autoencoder, and test the performance of PSO algorithm in\noptimizing the parameters of networks\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 03:50:53 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 09:05:35 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Liao", "Zhaohe", ""]]}, {"id": "2004.13277", "submitter": "Akira Matsui", "authors": "Akira Matsui, Teruyoshi Kobayashi, Daisuke Moriwaki, Emilio Ferrara", "title": "Detecting multi-timescale consumption patterns from receipt data: A\n  non-negative tensor factorization approach", "comments": "16 pages, 10 figures", "journal-ref": "Journal of Computational Social Science (2020)", "doi": "10.1007/s42001-020-00078-5", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding consumer behavior is an important task, not only for developing\nmarketing strategies but also for the management of economic policies.\nDetecting consumption patterns, however, is a high-dimensional problem in which\nvarious factors that would affect consumers' behavior need to be considered,\nsuch as consumers' demographics, circadian rhythm, seasonal cycles, etc. Here,\nwe develop a method to extract multi-timescale expenditure patterns of\nconsumers from a large dataset of scanned receipts. We use a non-negative\ntensor factorization (NTF) to detect intra- and inter-week consumption patterns\nat one time. The proposed method allows us to characterize consumers based on\ntheir consumption patterns that are correlated over different timescales.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:07:03 GMT"}, {"version": "v2", "created": "Sun, 2 Aug 2020 04:03:23 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Matsui", "Akira", ""], ["Kobayashi", "Teruyoshi", ""], ["Moriwaki", "Daisuke", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2004.13282", "submitter": "William La Cava", "authors": "William La Cava and Jason H. Moore", "title": "Genetic programming approaches to learning fair classifiers", "comments": "9 pages, 7 figures. GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3390157", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Society has come to rely on algorithms like classifiers for important\ndecision making, giving rise to the need for ethical guarantees such as\nfairness. Fairness is typically defined by asking that some statistic of a\nclassifier be approximately equal over protected groups within a population. In\nthis paper, current approaches to fairness are discussed and used to motivate\nalgorithmic proposals that incorporate fairness into genetic programming for\nclassification. We propose two ideas. The first is to incorporate a fairness\nobjective into multi-objective optimization. The second is to adapt lexicase\nselection to define cases dynamically over intersections of protected groups.\nWe describe why lexicase selection is well suited to pressure models to perform\nwell across the potentially infinitely many subgroups over which fairness is\ndesired. We use a recent genetic programming approach to construct models on\nfour datasets for which fairness constraints are necessary, and empirically\ncompare performance to prior methods utilizing game-theoretic solutions.\nMethods are assessed based on their ability to generate trade-offs of subgroup\nfairness and accuracy that are Pareto optimal. The result show that genetic\nprogramming methods in general, and random search in particular, are well\nsuited to this task.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:20:25 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "2004.13291", "submitter": "Rodrigo Canaan", "authors": "Rodrigo Canaan, Xianbo Gao, Youjin Chung, Julian Togelius, Andy Nealen\n  and Stefan Menzel", "title": "Evaluating the Rainbow DQN Agent in Hanabi with Unseen Partners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hanabi is a cooperative game that challenges exist-ing AI techniques due to\nits focus on modeling the mental states ofother players to interpret and\npredict their behavior. While thereare agents that can achieve near-perfect\nscores in the game byagreeing on some shared strategy, comparatively little\nprogresshas been made in ad-hoc cooperation settings, where partnersand\nstrategies are not known in advance. In this paper, we showthat agents trained\nthrough self-play using the popular RainbowDQN architecture fail to cooperate\nwell with simple rule-basedagents that were not seen during training and,\nconversely, whenthese agents are trained to play with any individual\nrule-basedagent, or even a mix of these agents, they fail to achieve\ngoodself-play scores.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:24:44 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Canaan", "Rodrigo", ""], ["Gao", "Xianbo", ""], ["Chung", "Youjin", ""], ["Togelius", "Julian", ""], ["Nealen", "Andy", ""], ["Menzel", "Stefan", ""]]}, {"id": "2004.13294", "submitter": "Anjali Balagopal", "authors": "Anjali Balagopal, Dan Nguyen, Howard Morgan, Yaochung Weng, Michael\n  Dohopolski, Mu-Han Lin, Azar Sadeghnejad Barkousaraie, Yesenia Gonzalez,\n  Aurelie Garant, Neil Desai, Raquibul Hannan, Steve Jiang", "title": "A deep learning-based framework for segmenting invisible clinical target\n  volumes with estimated uncertainties for post-operative prostate cancer\n  radiotherapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In post-operative radiotherapy for prostate cancer, the cancerous prostate\ngland has been surgically removed, so the clinical target volume (CTV) to be\nirradiated encompasses the microscopic spread of tumor cells, which cannot be\nvisualized in typical clinical images such as computed tomography or magnetic\nresonance imaging. In current clinical practice, physicians segment CTVs\nmanually based on their relationship with nearby organs and other clinical\ninformation, per clinical guidelines. Automating post-operative prostate CTV\nsegmentation with traditional image segmentation methods has been a major\nchallenge. Here, we propose a deep learning model to overcome this problem by\nsegmenting nearby organs first, then using their relationship with the CTV to\nassist CTV segmentation. The model proposed is trained using labels clinically\napproved and used for patient treatment, which are subject to relatively large\ninter-physician variations due to the absence of a visual ground truth. The\nmodel achieves an average Dice similarity coefficient (DSC) of 0.87 on a\nholdout dataset of 50 patients, much better than established methods, such as\natlas-based methods (DSC<0.7). The uncertainties associated with automatically\nsegmented CTV contours are also estimated to help physicians inspect and revise\nthe contours, especially in areas with large inter-physician variations. We\nalso use a 4-point grading system to show that the clinical quality of the\nautomatically segmented CTV contours is equal to that of approved clinical\ncontours manually drawn by physicians.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:29:46 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Balagopal", "Anjali", ""], ["Nguyen", "Dan", ""], ["Morgan", "Howard", ""], ["Weng", "Yaochung", ""], ["Dohopolski", "Michael", ""], ["Lin", "Mu-Han", ""], ["Barkousaraie", "Azar Sadeghnejad", ""], ["Gonzalez", "Yesenia", ""], ["Garant", "Aurelie", ""], ["Desai", "Neil", ""], ["Hannan", "Raquibul", ""], ["Jiang", "Steve", ""]]}, {"id": "2004.13303", "submitter": "Joey Tianyi Zhou Dr", "authors": "Joey Tianyi Zhou, Xi Peng and Yew-Soon Ong", "title": "Heterogeneous Representation Learning: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real-world data usually exhibits heterogeneous properties such as\nmodalities, views, or resources, which brings some unique challenges wherein\nthe key is Heterogeneous Representation Learning (HRL) termed in this paper.\nThis brief survey covers the topic of HRL, centered around several major\nlearning settings and real-world applications. First of all, from the\nmathematical perspective, we present a unified learning framework which is able\nto model most existing learning settings with the heterogeneous inputs. After\nthat, we conduct a comprehensive discussion on the HRL framework by reviewing\nsome selected learning problems along with the mathematics perspectives,\nincluding multi-view learning, heterogeneous transfer learning, Learning using\nprivileged information and heterogeneous multi-task learning. For each learning\ntask, we also discuss some applications under these learning problems and\ninstantiates the terms in the mathematical framework. Finally, we highlight the\nchallenges that are less-touched in HRL and present future research directions.\nTo the best of our knowledge, there is no such framework to unify these\nheterogeneous problems, and this survey would benefit the community.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 05:12:31 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:46:43 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhou", "Joey Tianyi", ""], ["Peng", "Xi", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2004.13314", "submitter": "Hamed Majidifard", "authors": "Hamed Majidifard, Yaw Adu-Gyamfi, William G. Buttlar", "title": "Deep Machine Learning Approach to Develop a New Asphalt Pavement\n  Condition Index", "comments": null, "journal-ref": null, "doi": "10.1016/j.conbuildmat.2020.118513", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated pavement distress detection via road images is still a challenging\nissue among pavement researchers and computer-vision community. In recent\nyears, advancement in deep learning has enabled researchers to develop robust\ntools for analyzing pavement images at unprecedented accuracies. Nevertheless,\ndeep learning models necessitate a big ground truth dataset, which is often not\nreadily accessible for pavement field. In this study, we reviewed our previous\nstudy, which a labeled pavement dataset was presented as the first step towards\na more robust, easy-to-deploy pavement condition assessment system. In total,\n7237 google street-view images were extracted, manually annotated for\nclassification (nine categories of distress classes). Afterward, YOLO (you look\nonly once) deep learning framework was implemented to train the model using the\nlabeled dataset. In the current study, a U-net based model is developed to\nquantify the severity of the distresses, and finally, a hybrid model is\ndeveloped by integrating the YOLO and U-net model to classify the distresses\nand quantify their severity simultaneously. Various pavement condition indices\nare developed by implementing various machine learning algorithms using the\nYOLO deep learning framework for distress classification and U-net for\nsegmentation and distress densification. The output of the distress\nclassification and segmentation models are used to develop a comprehensive\npavement condition tool which rates each pavement image according to the type\nand severity of distress extracted.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 05:57:43 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Majidifard", "Hamed", ""], ["Adu-Gyamfi", "Yaw", ""], ["Buttlar", "William G.", ""]]}, {"id": "2004.13316", "submitter": "Xue Yang", "authors": "Xue Yang, Junchi Yan, Xiaokang Yang, Jin Tang, Wenlong Liao, Tao He", "title": "SCRDet++: Detecting Small, Cluttered and Rotated Objects via\n  Instance-Level Feature Denoising and Rotation Loss Smoothing", "comments": "15 pages, 12 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small and cluttered objects are common in real-world which are challenging\nfor detection. The difficulty is further pronounced when the objects are\nrotated, as traditional detectors often routinely locate the objects in\nhorizontal bounding box such that the region of interest is contaminated with\nbackground or nearby interleaved objects. In this paper, we first innovatively\nintroduce the idea of denoising to object detection. Instance-level denoising\non the feature map is performed to enhance the detection to small and cluttered\nobjects. To handle the rotation variation, we also add a novel IoU constant\nfactor to the smooth L1 loss to address the long standing boundary problem,\nwhich to our analysis, is mainly caused by the periodicity of angular (PoA) and\nexchangeability of edges (EoE). By combing these two features, our proposed\ndetector is termed as SCRDet++. Extensive experiments are performed on large\naerial images public datasets DOTA, DIOR, UCAS-AOD as well as natural image\ndataset COCO, scene text dataset ICDAR2015, small traffic light dataset BSTLD\nand our newly released S$^2$TLD by this paper. The results show the\neffectiveness of our approach. Project page at\nhttps://yangxue0827.github.io/SCRDet++.html.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:03:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yang", "Xue", ""], ["Yan", "Junchi", ""], ["Yang", "Xiaokang", ""], ["Tang", "Jin", ""], ["Liao", "Wenlong", ""], ["He", "Tao", ""]]}, {"id": "2004.13321", "submitter": "Islem Rekik", "authors": "Ismail Bilgen and Goktug Guvercin and Islem Rekik", "title": "Machine Learning Methods for Brain Network Classification: Application\n  to Autism Diagnosis using Cortical Morphological Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) affects the brain connectivity at different\nlevels. Nonetheless, non-invasively distinguishing such effects using magnetic\nresonance imaging (MRI) remains very challenging to machine learning diagnostic\nframeworks due to ASD heterogeneity. So far, existing network neuroscience\nworks mainly focused on functional (derived from functional MRI) and structural\n(derived from diffusion MRI) brain connectivity, which might not capture\nrelational morphological changes between brain regions. Indeed, machine\nlearning (ML) studies for ASD diagnosis using morphological brain networks\nderived from conventional T1-weighted MRI are very scarce. To fill this gap, we\nleverage crowdsourcing by organizing a Kaggle competition to build a pool of\nmachine learning pipelines for neurological disorder diagnosis with application\nto ASD diagnosis using cortical morphological networks derived from T1-weighted\nMRI. During the competition, participants were provided with a training dataset\nand only allowed to check their performance on a public test data. The final\nevaluation was performed on both public and hidden test datasets based on\naccuracy, sensitivity, and specificity metrics. Teams were ranked using each\nperformance metric separately and the final ranking was determined based on the\nmean of all rankings. The first-ranked team achieved 70% accuracy, 72.5%\nsensitivity, and 67.5% specificity, while the second-ranked team achieved\n63.8%, 62.5%, 65% respectively. Leveraging participants to design ML diagnostic\nmethods within a competitive machine learning setting has allowed the\nexploration and benchmarking of wide spectrum of ML methods for ASD diagnosis\nusing cortical morphological networks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:23:29 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bilgen", "Ismail", ""], ["Guvercin", "Goktug", ""], ["Rekik", "Islem", ""]]}, {"id": "2004.13328", "submitter": "Manish Shukla", "authors": "Manish Shukla, Rajan M A, Sachin Lodha, Gautam Shroff, Ramesh Raskar", "title": "Privacy Guidelines for Contact Tracing Applications", "comments": "10 pages, 0 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is a very powerful method to implement and enforce social\ndistancing to avoid spreading of infectious diseases. The traditional approach\nof contact tracing is time consuming, manpower intensive, dangerous and prone\nto error due to fatigue or lack of skill. Due to this there is an emergence of\nmobile based applications for contact tracing. These applications primarily\nutilize a combination of GPS based absolute location and Bluetooth based\nrelative location remitted from user's smartphone to infer various insights.\nThese applications have eased the task of contact tracing; however, they also\nhave severe implication on user's privacy, for example, mass surveillance,\npersonal information leakage and additionally revealing the behavioral patterns\nof the user. This impact on user's privacy leads to trust deficit in these\napplications, and hence defeats their purpose.\n  In this work we discuss the various scenarios which a contact tracing\napplication should be able to handle. We highlight the privacy handling of some\nof the prominent contact tracing applications. Additionally, we describe the\nvarious threat actors who can disrupt its working, or misuse end user's data,\nor hamper its mass adoption. Finally, we present privacy guidelines for contact\ntracing applications from different stakeholder's perspective. To best of our\nknowledge, this is the first generic work which provides privacy guidelines for\ncontact tracing applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:44:14 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Shukla", "Manish", ""], ["A", "Rajan M", ""], ["Lodha", "Sachin", ""], ["Shroff", "Gautam", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2004.13332", "submitter": "Stephan Zheng", "authors": "Stephan Zheng, Alexander Trott, Sunil Srinivasa, Nikhil Naik, Melvin\n  Gruesbeck, David C. Parkes, Richard Socher", "title": "The AI Economist: Improving Equality and Productivity with AI-Driven Tax\n  Policies", "comments": "46 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.LG q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tackling real-world socio-economic challenges requires designing and testing\neconomic policies. However, this is hard in practice, due to a lack of\nappropriate (micro-level) economic data and limited opportunity to experiment.\nIn this work, we train social planners that discover tax policies in dynamic\neconomies that can effectively trade-off economic equality and productivity. We\npropose a two-level deep reinforcement learning approach to learn dynamic tax\npolicies, based on economic simulations in which both agents and a government\nlearn and adapt. Our data-driven approach does not make use of economic\nmodeling assumptions, and learns from observational data alone. We make four\nmain contributions. First, we present an economic simulation environment that\nfeatures competitive pressures and market dynamics. We validate the simulation\nby showing that baseline tax systems perform in a way that is consistent with\neconomic theory, including in regard to learned agent behaviors and\nspecializations. Second, we show that AI-driven tax policies improve the\ntrade-off between equality and productivity by 16% over baseline policies,\nincluding the prominent Saez tax framework. Third, we showcase several emergent\nfeatures: AI-driven tax policies are qualitatively different from baselines,\nsetting a higher top tax rate and higher net subsidies for low incomes.\nMoreover, AI-driven tax policies perform strongly in the face of emergent\ntax-gaming strategies learned by AI agents. Lastly, AI-driven tax policies are\nalso effective when used in experiments with human participants. In experiments\nconducted on MTurk, an AI tax policy provides an equality-productivity\ntrade-off that is similar to that provided by the Saez framework along with\nhigher inverse-income weighted social welfare.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 06:57:18 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zheng", "Stephan", ""], ["Trott", "Alexander", ""], ["Srinivasa", "Sunil", ""], ["Naik", "Nikhil", ""], ["Gruesbeck", "Melvin", ""], ["Parkes", "David C.", ""], ["Socher", "Richard", ""]]}, {"id": "2004.13335", "submitter": "Alam Zaib", "authors": "Alam Zaib, Tarig Ballal, Shahid Khattak and Tareq Y. Al-Naffouri", "title": "A Doubly Regularized Linear Discriminant Analysis Classifier with\n  Automatic Parameter Selection", "comments": "11 pages, 40 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear discriminant analysis (LDA) based classifiers tend to falter in many\npractical settings where the training data size is smaller than, or comparable\nto, the number of features. As a remedy, different regularized LDA (RLDA)\nmethods have been proposed. These methods may still perform poorly depending on\nthe size and quality of the available training data. In particular, the test\ndata deviation from the training data model, for example, due to noise\ncontamination, can cause severe performance degradation. Moreover, these\nmethods commit further to the Gaussian assumption (upon which LDA is\nestablished) to tune their regularization parameters, which may compromise\naccuracy when dealing with real data. To address these issues, we propose a\ndoubly regularized LDA classifier that we denote as R2LDA. In the proposed\nR2LDA approach, the RLDA score function is converted into an inner product of\ntwo vectors. By substituting the expressions of the regularized estimators of\nthese vectors, we obtain the R2LDA score function that involves two\nregularization parameters. To set the values of these parameters, we adopt\nthree existing regularization techniques; the constrained perturbation\nregularization approach (COPRA), the bounded perturbation regularization (BPR)\nalgorithm, and the generalized cross-validation (GCV) method. These methods are\nused to tune the regularization parameters based on linear estimation models,\nwith the sample covariance matrix's square root being the linear operator.\nResults obtained from both synthetic and real data demonstrate the consistency\nand effectiveness of the proposed R2LDA approach, especially in scenarios\ninvolving test data contaminated with noise that is not observed during the\ntraining phase.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:09:22 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 17:44:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zaib", "Alam", ""], ["Ballal", "Tarig", ""], ["Khattak", "Shahid", ""], ["Al-Naffouri", "Tareq Y.", ""]]}, {"id": "2004.13336", "submitter": "Yuanzhong Xu", "authors": "Yuanzhong Xu, HyoukJoong Lee, Dehao Chen, Hongjun Choi, Blake\n  Hechtman, Shibo Wang", "title": "Automatic Cross-Replica Sharding of Weight Update in Data-Parallel\n  Training", "comments": "12 pages, 23 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data-parallel synchronous training of deep neural networks, different\ndevices (replicas) run the same program with different partitions of the\ntraining batch, but weight update computation is repeated on all replicas,\nbecause the weights do not have a batch dimension to partition. This can be a\nbottleneck for performance and scalability in typical language models with\nlarge weights, and models with small per-replica batch size which is typical in\nlarge-scale training. This paper presents an approach to automatically shard\nthe weight update computation across replicas with efficient communication\nprimitives and data formatting, using static analysis and transformations on\nthe training computation graph. We show this technique achieves substantial\nspeedups on typical image and language models on Cloud TPUs, requiring no\nchange to model code. This technique helps close the gap between traditionally\nexpensive (ADAM) and cheap (SGD) optimizers, as they will only take a small\npart of training step time and have similar peak memory usage. It helped us to\nachieve state-of-the-art training performance in Google's MLPerf 0.6\nsubmission.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:13:50 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Xu", "Yuanzhong", ""], ["Lee", "HyoukJoong", ""], ["Chen", "Dehao", ""], ["Choi", "Hongjun", ""], ["Hechtman", "Blake", ""], ["Wang", "Shibo", ""]]}, {"id": "2004.13342", "submitter": "Wangchunshu Zhou", "authors": "Wangchunshu Zhou, Tao Ge, Ke Xu, Furu Wei, Ming Zhou", "title": "Scheduled DropHead: A Regularization Method for Transformer Models", "comments": "EMNLP 2020 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce DropHead, a structured dropout method\nspecifically designed for regularizing the multi-head attention mechanism,\nwhich is a key component of transformer, a state-of-the-art model for various\nNLP tasks. In contrast to the conventional dropout mechanisms which randomly\ndrop units or connections, the proposed DropHead is a structured dropout\nmethod. It drops entire attention-heads during training and It prevents the\nmulti-head attention model from being dominated by a small portion of attention\nheads while also reduces the risk of overfitting the training data, thus making\nuse of the multi-head attention mechanism more efficiently. Motivated by recent\nstudies about the learning dynamic of the multi-head attention mechanism, we\npropose a specific dropout rate schedule to adaptively adjust the dropout rate\nof DropHead and achieve better regularization effect. Experimental results on\nboth machine translation and text classification benchmark datasets demonstrate\nthe effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:33:14 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 15:57:37 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Zhou", "Wangchunshu", ""], ["Ge", "Tao", ""], ["Xu", "Ke", ""], ["Wei", "Furu", ""], ["Zhou", "Ming", ""]]}, {"id": "2004.13344", "submitter": "Shufei Zhang Mr", "authors": "Shufei Zhang, Zhuang Qian, Kaizhu Huang, Jimin Xiao, Yuan He", "title": "Robust Generative Adversarial Network", "comments": "This paper has been submitted to ICLR in Sep 25. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are powerful generative models, but\nusually suffer from instability and generalization problem which may lead to\npoor generations. Most existing works focus on stabilizing the training of the\ndiscriminator while ignoring the generalization properties. In this work, we\naim to improve the generalization capability of GANs by promoting the local\nrobustness within the small neighborhood of the training samples. We also prove\nthat the robustness in small neighborhood of training sets can lead to better\ngeneralization. Particularly, we design a robust optimization framework where\nthe generator and discriminator compete with each other in a\n\\textit{worst-case} setting within a small Wasserstein ball. The generator\ntries to map \\textit{the worst input distribution} (rather than a Gaussian\ndistribution used in most GANs) to the real data distribution, while the\ndiscriminator attempts to distinguish the real and fake distribution\n\\textit{with the worst perturbation}. We have proved that our robust method can\nobtain a tighter generalization upper bound than traditional GANs under mild\nassumptions, ensuring a theoretical superiority of RGAN over GANs. A series of\nexperiments on CIFAR-10, STL-10 and CelebA datasets indicate that our proposed\nrobust framework can improve on five baseline GAN models substantially and\nconsistently.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 07:37:01 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Zhang", "Shufei", ""], ["Qian", "Zhuang", ""], ["Huang", "Kaizhu", ""], ["Xiao", "Jimin", ""], ["He", "Yuan", ""]]}, {"id": "2004.13351", "submitter": "Zhanpeng Yang", "authors": "Kai Yang, Yong Zhou, Zhanpeng Yang, Yuanming Shi", "title": "Communication-Efficient Edge AI Inference Over Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the fast growth of intelligent devices, it is expected that a large\nnumber of high-stake artificial intelligence (AI) applications, e.g., drones,\nautonomous cars, tactile robots, will be deployed at the edge of wireless\nnetworks in the near future. As such, the intelligent communication networks\nwill be designed to leverage advanced wireless techniques and edge computing\ntechnologies to support AI-enabled applications at various end devices with\nlimited communication, computation, hardware and energy resources. In this\narticle, we shall present the principles of efficient deployment of model\ninference at network edge to provide low-latency and energy-efficient AI\nservices. This includes the wireless distributed computing framework for\nlow-latency device distributed model inference as well as the wireless\ncooperative transmission strategy for energy-efficient edge cooperative model\ninference. The communication efficiency of edge inference systems is further\nimproved by building up a smart radio propagation environment via intelligent\nreflecting surface.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 08:04:06 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yang", "Kai", ""], ["Zhou", "Yong", ""], ["Yang", "Zhanpeng", ""], ["Shi", "Yuanming", ""]]}, {"id": "2004.13361", "submitter": "Manuel Morante", "authors": "Manuel Morante", "title": "A lite parametric model for the Hemodynamic Response Function", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with task-related fMRI data, one of the most crucial parts of\nthe data analysis consists of determining a proper estimate of the BOLD\nresponse. The following document presents a lite model for the Hemodynamic\nResponse Function HRF. Between other advances, the proposed model present less\nnumber of parameters compared to other similar HRF alternative, which reduces\nits optimization complexity and facilitates its potential applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 08:29:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Morante", "Manuel", ""]]}, {"id": "2004.13384", "submitter": "Bogdan Boc\\c{s}e", "authors": "Bogdan Bocse and Ioan Radu Jinga", "title": "The Immersion of Directed Multi-graphs in Embedding Fields.\n  Generalisations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The purpose of this paper is to outline a generalised model for representing\nhybrids of relational-categorical, symbolic, perceptual-sensory and\nperceptual-latent data, so as to embody, in the same architectural data layer,\nrepresentations for the input, output and latent tensors. This variety of\nrepresentation is currently used by various machine-learning models in computer\nvision, NLP/NLU, reinforcement learning which allows for direct application of\ncross-domain queries and functions. This is achieved by endowing a directed\nTensor-Typed Multi-Graph with at least some edge attributes which represent the\nembeddings from various latent spaces, so as to define, construct and compute\nnew similarity and distance relationships between and across tensorial forms,\nincluding visual, linguistic, auditory latent representations, thus stitching\nthe logical-categorical view of the observed universe to the\nBayesian/statistical view.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:28:08 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bocse", "Bogdan", ""], ["Jinga", "Ioan Radu", ""]]}, {"id": "2004.13390", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Sherrie Wang, Marco K\\\"orner, David Lobell", "title": "Meta-Learning for Few-Shot Land Cover Classification", "comments": "accepted to the CVPR 2020 EarthVision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The representations of the Earth's surface vary from one geographic region to\nanother. For instance, the appearance of urban areas differs between\ncontinents, and seasonality influences the appearance of vegetation. To capture\nthe diversity within a single category, like as urban or vegetation, requires a\nlarge model capacity and, consequently, large datasets. In this work, we\npropose a different perspective and view this diversity as an inductive\ntransfer learning problem where few data samples from one region allow a model\nto adapt to an unseen region. We evaluate the model-agnostic meta-learning\n(MAML) algorithm on classification and segmentation tasks using globally and\nregionally distributed datasets. We find that few-shot model adaptation\noutperforms pre-training with regular gradient descent and fine-tuning on (1)\nthe Sen12MS dataset and (2) DeepGlobe data when the source domain and target\ndomain differ. This indicates that model optimization with meta-learning may\nbenefit tasks in the Earth sciences whose data show a high degree of diversity\nfrom region to region, while traditional gradient-based supervised learning\nremains suitable in the absence of a feature or label shift.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:42:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Wang", "Sherrie", ""], ["K\u00f6rner", "Marco", ""], ["Lobell", "David", ""]]}, {"id": "2004.13406", "submitter": "Abhilash Nandy", "authors": "Abhilash Nandy, Rachana Sathish, Debdoot Sheet", "title": "Identification of Cervical Pathology using Adversarial Neural Networks", "comments": "9 pages, 10 images, 5th MedImage Workshop of 11th Indian Conference\n  on Computer Vision, Graphics and Image Processing, Hyderabad, India, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various screening and diagnostic methods have led to a large reduction of\ncervical cancer death rates in developed countries. However, cervical cancer is\nthe leading cause of cancer related deaths in women in India and other low and\nmiddle income countries (LMICs) especially among the urban poor and slum\ndwellers. Several sophisticated techniques such as cytology tests, HPV tests\netc. have been widely used for screening of cervical cancer. These tests are\ninherently time consuming. In this paper, we propose a convolutional\nautoencoder based framework, having an architecture similar to SegNet which is\ntrained in an adversarial fashion for classifying images of the cervix acquired\nusing a colposcope. We validate performance on the Intel-Mobile ODT cervical\nimage classification dataset. The proposed method outperforms the standard\ntechnique of fine-tuning convolutional neural networks pre-trained on ImageNet\ndatabase with an average accuracy of 73.75%.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:22:16 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Nandy", "Abhilash", ""], ["Sathish", "Rachana", ""], ["Sheet", "Debdoot", ""]]}, {"id": "2004.13408", "submitter": "Bryan Lim", "authors": "Bryan Lim and Stefan Zohren", "title": "Time Series Forecasting With Deep Learning: A Survey", "comments": null, "journal-ref": "Philosophical Transactions of the Royal Society A 2020", "doi": "10.1098/rsta.2020.0209", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous deep learning architectures have been developed to accommodate the\ndiversity of time series datasets across different domains. In this article, we\nsurvey common encoder and decoder designs used in both one-step-ahead and\nmulti-horizon time series forecasting -- describing how temporal information is\nincorporated into predictions by each model. Next, we highlight recent\ndevelopments in hybrid deep learning models, which combine well-studied\nstatistical models with neural network components to improve pure methods in\neither category. Lastly, we outline some ways in which deep learning can also\nfacilitate decision support with time series data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:32:26 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:10:48 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Lim", "Bryan", ""], ["Zohren", "Stefan", ""]]}, {"id": "2004.13414", "submitter": "Bhasker Sri Harsha Suri", "authors": "Bhasker Sri Harsha Suri, Kalidas Yeturu", "title": "Pseudo Rehearsal using non photo-realistic images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural networks forget previously learnt tasks when they are faced with\nlearning new tasks. This is called catastrophic forgetting. Rehearsing the\nneural network with the training data of the previous task can protect the\nnetwork from catastrophic forgetting. Since rehearsing requires the storage of\nentire previous data, Pseudo rehearsal was proposed, where samples belonging to\nthe previous data are generated synthetically for rehearsal. In an image\nclassification setting, while current techniques try to generate synthetic data\nthat is photo-realistic, we demonstrated that Neural networks can be rehearsed\non data that is not photo-realistic and still achieve good retention of the\nprevious task. We also demonstrated that forgoing the constraint of having\nphoto realism in the generated data can result in a significant reduction in\nthe consumption of computational and memory resources for pseudo rehearsal.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 10:44:57 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Suri", "Bhasker Sri Harsha", ""], ["Yeturu", "Kalidas", ""]]}, {"id": "2004.13431", "submitter": "Yiming Hu", "authors": "Yiming Hu, Yuding Liang, Zichao Guo, Ruosi Wan, Xiangyu Zhang, Yichen\n  Wei, Qingyi Gu, Jian Sun", "title": "Angle-based Search Space Shrinking for Neural Architecture Search", "comments": "Accepted in ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a simple and general search space shrinking method,\ncalled Angle-Based search space Shrinking (ABS), for Neural Architecture Search\n(NAS). Our approach progressively simplifies the original search space by\ndropping unpromising candidates, thus can reduce difficulties for existing NAS\nmethods to find superior architectures. In particular, we propose an\nangle-based metric to guide the shrinking process. We provide comprehensive\nevidences showing that, in weight-sharing supernet, the proposed metric is more\nstable and accurate than accuracy-based and magnitude-based metrics to predict\nthe capability of child models. We also show that the angle-based metric can\nconverge fast while training supernet, enabling us to get promising shrunk\nsearch spaces efficiently. ABS can easily apply to most of NAS approaches (e.g.\nSPOS, FairNAS, ProxylessNAS, DARTS and PDARTS). Comprehensive experiments show\nthat ABS can dramatically enhance existing NAS approaches by providing a\npromising shrunk search space.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:26:46 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 13:04:04 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 14:45:22 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hu", "Yiming", ""], ["Liang", "Yuding", ""], ["Guo", "Zichao", ""], ["Wan", "Ruosi", ""], ["Zhang", "Xiangyu", ""], ["Wei", "Yichen", ""], ["Gu", "Qingyi", ""], ["Sun", "Jian", ""]]}, {"id": "2004.13432", "submitter": "Wenliang Dai", "authors": "Wenliang Dai, Tiezheng Yu, Zihan Liu, Pascale Fung", "title": "Kungfupanda at SemEval-2020 Task 12: BERT-Based Multi-Task Learning for\n  Offensive Language Detection", "comments": "Submitted to SemEval-2020 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, offensive content in social media has become a serious problem, and\nautomatically detecting offensive language is an essential task. In this paper,\nwe build an offensive language detection system, which combines multi-task\nlearning with BERT-based models. Using a pre-trained language model such as\nBERT, we can effectively learn the representations for noisy text in social\nmedia. Besides, to boost the performance of offensive language detection, we\nleverage the supervision signals from other related tasks. In the\nOffensEval-2020 competition, our model achieves 91.51% F1 score in English\nSub-task A, which is comparable to the first place (92.23%F1). An empirical\nanalysis is provided to explain the effectiveness of our approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:27:24 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 06:51:59 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dai", "Wenliang", ""], ["Yu", "Tiezheng", ""], ["Liu", "Zihan", ""], ["Fung", "Pascale", ""]]}, {"id": "2004.13439", "submitter": "Thilo Stadelmann", "authors": "Dano Roost, Ralph Meier, Stephan Huschauer, Erik Nygren, Adrian Egli,\n  Andreas Weiler, Thilo Stadelmann", "title": "Improving Sample Efficiency and Multi-Agent Communication in RL-based\n  Train Rescheduling", "comments": "Accepted for publication at the 7th Swiss Conference on Data Science\n  (SDS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present preliminary results from our sixth placed entry to the Flatland\ninternational competition for train rescheduling, including two improvements\nfor optimized reinforcement learning (RL) training efficiency, and two\nhypotheses with respect to the prospect of deep RL for complex real-world\ncontrol tasks: first, that current state of the art policy gradient methods\nseem inappropriate in the domain of high-consequence environments; second, that\nlearning explicit communication actions (an emerging machine-to-machine\nlanguage, so to speak) might offer a remedy. These hypotheses need to be\nconfirmed by future work. If confirmed, they hold promises with respect to\noptimizing highly efficient logistics ecosystems like the Swiss Federal\nRailways railway network.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:46:58 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Roost", "Dano", ""], ["Meier", "Ralph", ""], ["Huschauer", "Stephan", ""], ["Nygren", "Erik", ""], ["Egli", "Adrian", ""], ["Weiler", "Andreas", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "2004.13446", "submitter": "Ankit Sharma", "authors": "Ankit Sharma, Garima Gupta, Ranjitha Prasad, Arnab Chatterjee,\n  Lovekesh Vig, Gautam Shroff", "title": "MultiMBNN: Matched and Balanced Causal Inference with Neural Networks", "comments": "7 pages, 3 figures, Accepted in ESANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference (CI) in observational studies has received a lot of\nattention in healthcare, education, ad attribution, policy evaluation, etc.\nConfounding is a typical hazard, where the context affects both, the treatment\nassignment and response. In a multiple treatment scenario, we propose the\nneural network based MultiMBNN, where we overcome confounding by employing\ngeneralized propensity score based matching, and learning balanced\nrepresentations. We benchmark the performance on synthetic and real-world\ndatasets using PEHE, and mean absolute percentage error over ATE as metrics.\nMultiMBNN outperforms the state-of-the-art algorithms for CI such as TARNet and\nPerfect Match (PM).\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 11:58:38 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:34:17 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 10:58:56 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Sharma", "Ankit", ""], ["Gupta", "Garima", ""], ["Prasad", "Ranjitha", ""], ["Chatterjee", "Arnab", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "2004.13465", "submitter": "Bo Xue", "authors": "Bo Xue, Guanghui Wang, Yimu Wang and Lijun Zhang", "title": "Nearly Optimal Regret for Stochastic Linear Bandits with Heavy-Tailed\n  Payoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of stochastic linear bandits with finite\naction sets. Most of existing work assume the payoffs are bounded or\nsub-Gaussian, which may be violated in some scenarios such as financial\nmarkets. To settle this issue, we analyze the linear bandits with heavy-tailed\npayoffs, where the payoffs admit finite $1+\\epsilon$ moments for some\n$\\epsilon\\in(0,1]$. Through median of means and dynamic truncation, we propose\ntwo novel algorithms which enjoy a sublinear regret bound of\n$\\widetilde{O}(d^{\\frac{1}{2}}T^{\\frac{1}{1+\\epsilon}})$, where $d$ is the\ndimension of contextual information and $T$ is the time horizon. Meanwhile, we\nprovide an $\\Omega(d^{\\frac{\\epsilon}{1+\\epsilon}}T^{\\frac{1}{1+\\epsilon}})$\nlower bound, which implies our upper bound matches the lower bound up to\npolylogarithmic factors in the order of $d$ and $T$ when $\\epsilon=1$. Finally,\nwe conduct numerical experiments to demonstrate the effectiveness of our\nalgorithms and the empirical results strongly support our theoretical\nguarantees.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:01:38 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Xue", "Bo", ""], ["Wang", "Guanghui", ""], ["Wang", "Yimu", ""], ["Zhang", "Lijun", ""]]}, {"id": "2004.13480", "submitter": "Zhong Meng", "authors": "Zhong Meng, Hu Hu, Jinyu Li, Changliang Liu, Yan Huang, Yifan Gong,\n  Chin-Hui Lee", "title": "L-Vector: Neural Label Embedding for Domain Adaptation", "comments": "5 pages, 2 figure, ICASSP 2020", "journal-ref": "2019 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP), Barcelona, Spain", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural label embedding (NLE) scheme for the domain\nadaptation of a deep neural network (DNN) acoustic model with unpaired data\nsamples from source and target domains. With NLE method, we distill the\nknowledge from a powerful source-domain DNN into a dictionary of label\nembeddings, or l-vectors, one for each senone class. Each l-vector is a\nrepresentation of the senone-specific output distributions of the source-domain\nDNN and is learned to minimize the average L2, Kullback-Leibler (KL) or\nsymmetric KL distance to the output vectors with the same label through simple\naveraging or standard back-propagation. During adaptation, the l-vectors serve\nas the soft targets to train the target-domain model with cross-entropy loss.\nWithout parallel data constraint as in the teacher-student learning, NLE is\nspecially suited for the situation where the paired target-domain data cannot\nbe simulated from the source-domain data. We adapt a 6400 hours\nmulti-conditional US English acoustic model to each of the 9 accented English\n(80 to 830 hours) and kids' speech (80 hours). NLE achieves up to 14.1%\nrelative word error rate reduction over direct re-training with one-hot labels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 06:40:31 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Meng", "Zhong", ""], ["Hu", "Hu", ""], ["Li", "Jinyu", ""], ["Liu", "Changliang", ""], ["Huang", "Yan", ""], ["Gong", "Yifan", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2004.13486", "submitter": "Bhaskar Mitra", "authors": "Emine Yilmaz, Nick Craswell, Bhaskar Mitra and Daniel Campos", "title": "On the Reliability of Test Collections for Evaluating Systems of\n  Different Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning based models are increasingly being used for information\nretrieval (IR), a major challenge is to ensure the availability of test\ncollections for measuring their quality. Test collections are generated based\non pooling results of various retrieval systems, but until recently this did\nnot include deep learning systems. This raises a major challenge for reusable\nevaluation: Since deep learning based models use external resources (e.g. word\nembeddings) and advanced representations as opposed to traditional methods that\nare mainly based on lexical similarity, they may return different types of\nrelevant document that were not identified in the original pooling. If so, test\ncollections constructed using traditional methods are likely to lead to biased\nand unfair evaluation results for deep learning (neural) systems. This paper\nuses simulated pooling to test the fairness and reusability of test\ncollections, showing that pooling based on traditional systems only can lead to\nbiased evaluation of deep learning systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:22:26 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Yilmaz", "Emine", ""], ["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Campos", "Daniel", ""]]}, {"id": "2004.13521", "submitter": "Sourav Sen", "authors": "Sourav Sen", "title": "Detect Language of Transliterated Texts", "comments": "10 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informal transliteration from other languages to English is prevalent in\nsocial media threads, instant messaging, and discussion forums. Without\nidentifying the language of such transliterated text, users who do not speak\nthat language cannot understand its content using translation tools. We propose\na Language Identification (LID) system, with an approach for feature\nextraction, which can detect the language of transliterated texts reasonably\nwell even with limited training data and computational resources. We tokenize\nthe words into phonetic syllables and use a simple Long Short-term Memory\n(LSTM) network architecture to detect the language of transliterated texts.\nWith intensive experiments, we show that the tokenization of transliterated\nwords as phonetic syllables effectively represents their causal sound patterns.\nPhonetic syllable tokenization, therefore, makes it easier for even simpler\nmodel architectures to learn the characteristic patterns to identify any\nlanguage.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 10:28:02 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Sen", "Sourav", ""]]}, {"id": "2004.13522", "submitter": "Li Fu", "authors": "Li Fu, Xiaoxiao Li, Libo Zi", "title": "Research on Modeling Units of Transformer Transducer for Mandarin Speech\n  Recognition", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling unit and model architecture are two key factors of Recurrent Neural\nNetwork Transducer (RNN-T) in end-to-end speech recognition. To improve the\nperformance of RNN-T for Mandarin speech recognition task, a novel transformer\ntransducer with the combination architecture of self-attention transformer and\nRNN is proposed. And then the choice of different modeling units for\ntransformer transducer is explored. In addition, we present a new mix-bandwidth\ntraining method to obtain a general model that is able to accurately recognize\nMandarin speech with different sampling rates simultaneously. All of our\nexperiments are conducted on about 12,000 hours of Mandarin speech with\nsampling rate in 8kHz and 16kHz. Experimental results show that Mandarin\ntransformer transducer using syllable with tone achieves the best performance.\nIt yields an average of 14.4% and 44.1% relative Word Error Rate (WER)\nreduction when compared with the models using syllable initial/final with tone\nand Chinese character, respectively. Also, it outperforms the model based on\nsyllable initial/final with tone with an average of 13.5% relative Character\nError Rate (CER) reduction.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 05:12:52 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Fu", "Li", ""], ["Li", "Xiaoxiao", ""], ["Zi", "Libo", ""]]}, {"id": "2004.13524", "submitter": "Saeed Anwar", "authors": "Saeed Anwar, Nick Barnes, and Lars Petersson", "title": "Attention Based Real Image Restoration", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.07396", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep convolutional neural networks perform better on images containing\nspatially invariant degradations, also known as synthetic degradations;\nhowever, their performance is limited on real-degraded photographs and requires\nmultiple-stage network modeling. To advance the practicability of restoration\nalgorithms, this paper proposes a novel single-stage blind real image\nrestoration network (R$^2$Net) by employing a modular architecture. We use a\nresidual on the residual structure to ease the flow of low-frequency\ninformation and apply feature attention to exploit the channel dependencies.\nFurthermore, the evaluation in terms of quantitative metrics and visual quality\nfor four restoration tasks i.e. Denoising, Super-resolution, Raindrop Removal,\nand JPEG Compression on 11 real degraded datasets against more than 30\nstate-of-the-art algorithms demonstrate the superiority of our R$^2$Net. We\nalso present the comparison on three synthetically generated degraded datasets\nfor denoising to showcase the capability of our method on synthetics denoising.\nThe codes, trained models, and results are available on\nhttps://github.com/saeed-anwar/R2Net.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 04:21:49 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2020 06:52:45 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Anwar", "Saeed", ""], ["Barnes", "Nick", ""], ["Petersson", "Lars", ""]]}, {"id": "2004.13527", "submitter": "Daniel Leite", "authors": "Leticia Decker, Daniel Leite, Luca Giommi, Daniele Bonacorsi", "title": "Real-Time Anomaly Detection in Data Centers for Log-based Predictive\n  Maintenance using an Evolving Fuzzy-Rule-Based Approach", "comments": "9 pages, 6 figures, 1 table, IEEE World Congress on Computational\n  Intelligence (WCCI 2020). arXiv admin note: substantial text overlap with\n  arXiv:2004.09986", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of anomalous behaviors in data centers is crucial to predictive\nmaintenance and data safety. With data centers, we mean any computer network\nthat allows users to transmit and exchange data and information. In particular,\nwe focus on the Tier-1 data center of the Italian Institute for Nuclear Physics\n(INFN), which supports the high-energy physics experiments at the Large Hadron\nCollider (LHC) in Geneva. The center provides resources and services needed for\ndata processing, storage, analysis, and distribution. Log records in the data\ncenter is a stochastic and non-stationary phenomenon in nature. We propose a\nreal-time approach to monitor and classify log records based on sliding time\nwindows, and a time-varying evolving fuzzy-rule-based classification model. The\nmost frequent log pattern according to a control chart is taken as the normal\nsystem status. We extract attributes from time windows to gradually develop and\nupdate an evolving Gaussian Fuzzy Classifier (eGFC) on the fly. The real-time\nanomaly monitoring system has to provide encouraging results in terms of\naccuracy, compactness, and real-time operation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 21:19:44 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Decker", "Leticia", ""], ["Leite", "Daniel", ""], ["Giommi", "Luca", ""], ["Bonacorsi", "Daniele", ""]]}, {"id": "2004.13530", "submitter": "Luca Benedetto", "authors": "Luca Benedetto, Andrea Cappelli, Roberto Turrin, Paolo Cremonesi", "title": "Introducing a framework to assess newly created questions with Natural\n  Language Processing", "comments": "Accepted at the International Conference of Artificial Intelligence\n  in Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical models such as those derived from Item Response Theory (IRT)\nenable the assessment of students on a specific subject, which can be useful\nfor several purposes (e.g., learning path customization, drop-out prediction).\nHowever, the questions have to be assessed as well and, although it is possible\nto estimate with IRT the characteristics of questions that have already been\nanswered by several students, this technique cannot be used on newly generated\nquestions. In this paper, we propose a framework to train and evaluate models\nfor estimating the difficulty and discrimination of newly created Multiple\nChoice Questions by extracting meaningful features from the text of the\nquestion and of the possible choices. We implement one model using this\nframework and test it on a real-world dataset provided by CloudAcademy, showing\nthat it outperforms previously proposed models, reducing by 6.7% the RMSE for\ndifficulty estimation and by 10.8% the RMSE for discrimination estimation. We\nalso present the results of an ablation study performed to support our features\nchoice and to show the effects of different characteristics of the questions'\ntext on difficulty and discrimination.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:57:21 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 09:06:57 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Benedetto", "Luca", ""], ["Cappelli", "Andrea", ""], ["Turrin", "Roberto", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2004.13532", "submitter": "Richard Gerum", "authors": "Richard C. Gerum, Achim Schilling", "title": "Integration of Leaky-Integrate-and-Fire-Neurons in Deep Learning\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up to now, modern Machine Learning is mainly based on fitting high\ndimensional functions to enormous data sets, taking advantage of huge hardware\nresources. We show that biologically inspired neuron models such as the\nLeaky-Integrate-and-Fire (LIF) neurons provide novel and efficient ways of\ninformation encoding. They can be integrated in Machine Learning models, and\nare a potential target to improve Machine Learning performance.\n  Thus, we derived simple update-rules for the LIF units from the differential\nequations, which are easy to numerically integrate. We apply a novel approach\nto train the LIF units supervisedly via backpropagation, by assigning a\nconstant value to the derivative of the neuron activation function exclusively\nfor the backpropagation step. This simple mathematical trick helps to\ndistribute the error between the neurons of the pre-connected layer. We apply\nour method to the IRIS blossoms image data set and show that the training\ntechnique can be used to train LIF neurons on image classification tasks.\nFurthermore, we show how to integrate our method in the KERAS (tensorflow)\nframework and efficiently run it on GPUs. To generate a deeper understanding of\nthe mechanisms during training we developed interactive illustrations, which we\nprovide online.\n  With this study we want to contribute to the current efforts to enhance\nMachine Intelligence by integrating principles from biology.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:57:42 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:27:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gerum", "Richard C.", ""], ["Schilling", "Achim", ""]]}, {"id": "2004.13546", "submitter": "Fabian K\\\"uppers", "authors": "Fabian K\\\"uppers, Jan Kronenberger, Amirhossein Shantia, Anselm\n  Haselhoff", "title": "Multivariate Confidence Calibration for Object Detection", "comments": "Accepted on CVPR 2020 Workshop: \"2nd Workshop on Safe Artificial\n  Intelligence for Automated Driving (SAIAD)\"", "journal-ref": null, "doi": "10.1109/CVPRW50498.2020.00171", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unbiased confidence estimates of neural networks are crucial especially for\nsafety-critical applications. Many methods have been developed to calibrate\nbiased confidence estimates. Though there is a variety of methods for\nclassification, the field of object detection has not been addressed yet.\nTherefore, we present a novel framework to measure and calibrate biased (or\nmiscalibrated) confidence estimates of object detection methods. The main\ndifference to related work in the field of classifier calibration is that we\nalso use additional information of the regression output of an object detector\nfor calibration. Our approach allows, for the first time, to obtain calibrated\nconfidence estimates with respect to image location and box scale. In addition,\nwe propose a new measure to evaluate miscalibration of object detectors.\nFinally, we show that our developed methods outperform state-of-the-art\ncalibration models for the task of object detection and provides reliable\nconfidence estimates across different locations and scales.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 14:17:41 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["K\u00fcppers", "Fabian", ""], ["Kronenberger", "Jan", ""], ["Shantia", "Amirhossein", ""], ["Haselhoff", "Anselm", ""]]}, {"id": "2004.13550", "submitter": "Durgesh Samariya", "authors": "Durgesh Samariya, Sunil Aryal, Kai Ming Ting", "title": "A new effective and efficient measure for outlying aspect mining", "comments": "Co-authors are not agree with submission of paper on arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlying Aspect Mining (OAM) aims to find the subspaces (a.k.a. aspects) in\nwhich a given query is an outlier with respect to a given dataset. Existing OAM\nalgorithms use traditional distance/density-based outlier scores to rank\nsubspaces. Because these distance/density-based scores depend on the\ndimensionality of subspaces, they cannot be compared directly between subspaces\nof different dimensionality. $Z$-score normalisation has been used to make them\ncomparable. It requires to compute outlier scores of all instances in each\nsubspace. This adds significant computational overhead on top of already\nexpensive density estimation---making OAM algorithms infeasible to run in large\nand/or high-dimensional datasets. We also discover that $Z$-score normalisation\nis inappropriate for OAM in some cases. In this paper, we introduce a new score\ncalled SiNNE, which is independent of the dimensionality of subspaces. This\nenables the scores in subspaces with different dimensionalities to be compared\ndirectly without any additional normalisation. Our experimental results\nrevealed that SiNNE produces better or at least the same results as existing\nscores; and it significantly improves the runtime of an existing OAM algorithm\nbased on beam search.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 14:20:51 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 06:03:29 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 03:58:30 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Samariya", "Durgesh", ""], ["Aryal", "Sunil", ""], ["Ting", "Kai Ming", ""]]}, {"id": "2004.13557", "submitter": "Shunbo Lei", "authors": "Shunbo Lei, David Hong, Johanna L. Mathieu, Ian A. Hiskens", "title": "Baseline Estimation of Commercial Building HVAC Fan Power Using Tensor\n  Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commercial building heating, ventilation, and air conditioning (HVAC) systems\nhave been studied for providing ancillary services to power grids via demand\nresponse (DR). One critical issue is to estimate the counterfactual baseline\npower consumption that would have prevailed without DR. Baseline methods have\nbeen developed based on whole building electric load profiles. New methods are\nnecessary to estimate the baseline power consumption of HVAC sub-components\n(e.g., supply and return fans), which have different characteristics compared\nto that of the whole building. Tensor completion can estimate the unobserved\nentries of multi-dimensional tensors describing complex data sets. It exploits\nhigh-dimensional data to capture granular insights into the problem. This paper\nproposes to use it for baselining HVAC fan power, by utilizing its capability\nof capturing dominant fan power patterns. The tensor completion method is\nevaluated using HVAC fan power data from several buildings at the University of\nMichigan, and compared with several existing methods. The tensor completion\nmethod generally outperforms the benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:03:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lei", "Shunbo", ""], ["Hong", "David", ""], ["Mathieu", "Johanna L.", ""], ["Hiskens", "Ian A.", ""]]}, {"id": "2004.13558", "submitter": "Atiyeh Fotoohinasab", "authors": "Atiyeh Fotoohinasab, Toby Hocking, and Fatemeh Afghah", "title": "A Graph-constrained Changepoint Detection Approach for ECG Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiogram (ECG) signal is the most commonly used non-invasive tool in\nthe assessment of cardiovascular diseases. Segmentation of the ECG signal to\nlocate its constitutive waves, in particular the R-peaks, is a key step in ECG\nprocessing and analysis. Over the years, several segmentation and QRS complex\ndetection algorithms have been proposed with different features; however, their\nperformance highly depends on applying preprocessing steps which makes them\nunreliable in real-time data analysis of ambulatory care settings and remote\nmonitoring systems, where the collected data is highly noisy. Moreover, some\nissues still remain with the current algorithms in regard to the diverse\nmorphological categories for the ECG signal and their high computation cost. In\nthis paper, we introduce a novel graph-based optimal changepoint detection\n(GCCD) method for reliable detection of R-peak positions without employing any\npreprocessing step. The proposed model guarantees to compute the globally\noptimal changepoint detection solution. It is also generic in nature and can be\napplied to other time-series biomedical signals. Based on the MIT-BIH\narrhythmia (MIT-BIH-AR) database, the proposed method achieves overall\nsensitivity Sen = 99.76, positive predictivity PPR = 99.68, and detection error\nrate DER = 0.55 which are comparable to other state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 23:41:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Fotoohinasab", "Atiyeh", ""], ["Hocking", "Toby", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2004.13560", "submitter": "Haibin Chang", "authors": "Nanzhe Wang, Haibin Chang, Dongxiao Zhang", "title": "Efficient Uncertainty Quantification for Dynamic Subsurface Flow with\n  Surrogate by Theory-guided Neural Network", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113492", "report-no": null, "categories": "eess.SP cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subsurface flow problems usually involve some degree of uncertainty.\nConsequently, uncertainty quantification is commonly necessary for subsurface\nflow prediction. In this work, we propose a methodology for efficient\nuncertainty quantification for dynamic subsurface flow with a surrogate\nconstructed by the Theory-guided Neural Network (TgNN). The TgNN here is\nspecially designed for problems with stochastic parameters. In the TgNN,\nstochastic parameters, time and location comprise the input of the neural\nnetwork, while the quantity of interest is the output. The neural network is\ntrained with available simulation data, while being simultaneously guided by\ntheory (e.g., the governing equation, boundary conditions, initial conditions,\netc.) of the underlying problem. The trained neural network can predict\nsolutions of subsurface flow problems with new stochastic parameters. With the\nTgNN surrogate, the Monte Carlo (MC) method can be efficiently implemented for\nuncertainty quantification. The proposed methodology is evaluated with\ntwo-dimensional dynamic saturated flow problems in porous medium. Numerical\nresults show that the TgNN based surrogate can significantly improve the\nefficiency of uncertainty quantification tasks compared with simulation based\nimplementation. Further investigations regarding stochastic fields with smaller\ncorrelation length, larger variance, changing boundary values and\nout-of-distribution variances are performed, and satisfactory results are\nobtained.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 12:41:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wang", "Nanzhe", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2004.13562", "submitter": "Yuntian Chen", "authors": "Yuntian Chen and Dongxiao Zhang", "title": "Ensemble long short-term memory (EnLSTM) network", "comments": "18 pages, 3 figures, including Supporting Information", "journal-ref": "Geophysical Research Letters, 2020", "doi": "10.1029/2020GL087685", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose an ensemble long short-term memory (EnLSTM)\nnetwork, which can be trained on a small dataset and process sequential data.\nThe EnLSTM is built by combining the ensemble neural network (ENN) and the\ncascaded long short-term memory (C-LSTM) network to leverage their\ncomplementary strengths. In order to resolve the issues of over-convergence and\ndisturbance compensation associated with training failure owing to the nature\nof small-data problems, model parameter perturbation and high-fidelity\nobservation perturbation methods are introduced. The EnLSTM is compared with\ncommonly-used models on a published dataset, and proven to be the\nstate-of-the-art model in generating well logs with a mean-square-error (MSE)\nreduction of 34%. In the case study, 12 well logs that cannot be measured while\ndrilling are generated based on logging-while-drilling (LWD) data. The EnLSTM\nis capable to reduce cost and save time in practice.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 05:42:18 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 02:17:49 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chen", "Yuntian", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2004.13563", "submitter": "Yong Xiao", "authors": "Yong Xiao and Guangming Shi and Marwan Krunz", "title": "Towards Ubiquitous AI in 6G with Federated Learning", "comments": "Submitted to IEEE Communication Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With 5G cellular systems being actively deployed worldwide, the research\ncommunity has started to explore novel technological advances for the\nsubsequent generation, i.e., 6G. It is commonly believed that 6G will be built\non a new vision of ubiquitous AI, an hyper-flexible architecture that brings\nhuman-like intelligence into every aspect of networking systems. Despite its\ngreat promise, there are several novel challenges expected to arise in\nubiquitous AI-based 6G. Although numerous attempts have been made to apply AI\nto wireless networks, these attempts have not yet seen any large-scale\nimplementation in practical systems. One of the key challenges is the\ndifficulty to implement distributed AI across a massive number of heterogeneous\ndevices. Federated learning (FL) is an emerging distributed AI solution that\nenables data-driven AI solutions in heterogeneous and potentially massive-scale\nnetworks. Although it still in an early stage of development, FL-inspired\narchitecture has been recognized as one of the most promising solutions to\nfulfill ubiquitous AI in 6G. In this article, we identify the requirements that\nwill drive convergence between 6G and AI. We propose an FL-based network\narchitecture and discuss its potential for addressing some of the novel\nchallenges expected in 6G. Future trends and key research problems for\nFL-enabled 6G are also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 13:05:29 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Xiao", "Yong", ""], ["Shi", "Guangming", ""], ["Krunz", "Marwan", ""]]}, {"id": "2004.13574", "submitter": "Qingyao Ai", "authors": "Qingyao Ai, Tao Yang, Huazheng Wang, Jiaxin Mao", "title": "Unbiased Learning to Rank: Online or Offline?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to obtain an unbiased ranking model by learning to rank with biased user\nfeedback is an important research question for IR. Existing work on unbiased\nlearning to rank (ULTR) can be broadly categorized into two groups -- the\nstudies on unbiased learning algorithms with logged data, namely the\n\\textit{offline} unbiased learning, and the studies on unbiased parameters\nestimation with real-time user interactions, namely the \\textit{online}\nlearning to rank. While their definitions of \\textit{unbiasness} are different,\nthese two types of ULTR algorithms share the same goal -- to find the best\nmodels that rank documents based on their intrinsic relevance or utility.\nHowever, most studies on offline and online unbiased learning to rank are\ncarried in parallel without detailed comparisons on their background theories\nand empirical performance. In this paper, we formalize the task of unbiased\nlearning to rank and show that existing algorithms for offline unbiased\nlearning and online learning to rank are just the two sides of the same coin.\nWe evaluate six state-of-the-art ULTR algorithms and find that most of them can\nbe used in both offline settings and online environments with or without minor\nmodifications. Further, we analyze how different offline and online learning\nparadigms would affect the theoretical foundation and empirical effectiveness\nof each algorithm on both synthetic and real search data. Our findings could\nprovide important insights and guideline for choosing and deploying ULTR\nalgorithms in practice.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:01:33 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 21:26:49 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 16:55:23 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ai", "Qingyao", ""], ["Yang", "Tao", ""], ["Wang", "Huazheng", ""], ["Mao", "Jiaxin", ""]]}, {"id": "2004.13576", "submitter": "Giuseppe Di Benedetto", "authors": "Giuseppe Di Benedetto, Vito Bellini, Giovanni Zappella", "title": "A Linear Bandit for Seasonal Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual bandit algorithms are extremely popular and widely used in\nrecommendation systems to provide online personalised recommendations. A\nrecurrent assumption is the stationarity of the reward function, which is\nrather unrealistic in most of the real-world applications. In the music\nrecommendation scenario for instance, people's music taste can abruptly change\nduring certain events, such as Halloween or Christmas, and revert to the\nprevious music taste soon after.\n  We would therefore need an algorithm which can promptly react to these\nchanges. Moreover, we would like to leverage already observed rewards collected\nduring different stationary periods which can potentially reoccur, without the\nneed of restarting the learning process from scratch. A growing literature has\naddressed the problem of reward's non-stationarity, providing algorithms that\ncould quickly adapt to the changing environment. However, up to our knowledge,\nthere is no algorithm which deals with seasonal changes of the reward function.\nHere we present a contextual bandit algorithm which detects and adapts to\nabrupt changes of the reward function and leverages previous estimations\nwhenever the environment falls back to a previously observed state. We show\nthat the proposed method can outperform state-of-the-art algorithms for\nnon-stationary environments. We ran our experiment on both synthetic and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:03:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Di Benedetto", "Giuseppe", ""], ["Bellini", "Vito", ""], ["Zappella", "Giovanni", ""]]}, {"id": "2004.13577", "submitter": "Zhongyi Han", "authors": "Zhongyi Han, Benzheng Wei, Yilong Yin, Shuo Li", "title": "Unifying Neural Learning and Symbolic Reasoning for Spinal Medical\n  Report Generation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated medical report generation in spine radiology, i.e., given spinal\nmedical images and directly create radiologist-level diagnosis reports to\nsupport clinical decision making, is a novel yet fundamental study in the\ndomain of artificial intelligence in healthcare. However, it is incredibly\nchallenging because it is an extremely complicated task that involves visual\nperception and high-level reasoning processes. In this paper, we propose the\nneural-symbolic learning (NSL) framework that performs human-like learning by\nunifying deep neural learning and symbolic logical reasoning for the spinal\nmedical report generation. Generally speaking, the NSL framework firstly\nemploys deep neural learning to imitate human visual perception for detecting\nabnormalities of target spinal structures. Concretely, we design an adversarial\ngraph network that interpolates a symbolic graph reasoning module into a\ngenerative adversarial network through embedding prior domain knowledge,\nachieving semantic segmentation of spinal structures with high complexity and\nvariability. NSL secondly conducts human-like symbolic logical reasoning that\nrealizes unsupervised causal effect analysis of detected entities of\nabnormalities through meta-interpretive learning. NSL finally fills these\ndiscoveries of target diseases into a unified template, successfully achieving\na comprehensive medical report generation. When it employed in a real-world\nclinical dataset, a series of empirical studies demonstrate its capacity on\nspinal medical report generation as well as show that our algorithm remarkably\nexceeds existing methods in the detection of spinal structures. These indicate\nits potential as a clinical tool that contributes to computer-aided diagnosis.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:06:24 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Han", "Zhongyi", ""], ["Wei", "Benzheng", ""], ["Yin", "Yilong", ""], ["Li", "Shuo", ""]]}, {"id": "2004.13579", "submitter": "Zequn Sun", "authors": "Zequn Sun, Jiacheng Huang, Wei Hu, Muchao Chen, Lingbing Guo, Yuzhong\n  Qu", "title": "TransEdge: Translating Relation-contextualized Embeddings for Knowledge\n  Graphs", "comments": "Published in proceedings of the 18th International Semantic Web\n  Conference (ISWC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph (KG) embeddings has received increasing attention in\nrecent years. Most embedding models in literature interpret relations as linear\nor bilinear mapping functions to operate on entity embeddings. However, we find\nthat such relation-level modeling cannot capture the diverse relational\nstructures of KGs well. In this paper, we propose a novel edge-centric\nembedding model TransEdge, which contextualizes relation representations in\nterms of specific head-tail entity pairs. We refer to such contextualized\nrepresentations of a relation as edge embeddings and interpret them as\ntranslations between entity embeddings. TransEdge achieves promising\nperformance on different prediction tasks. Our experiments on benchmark\ndatasets indicate that it obtains the state-of-the-art results on\nembedding-based entity alignment. We also show that TransEdge is complementary\nwith conventional entity alignment methods. Moreover, it shows very competitive\nperformance on link prediction.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 03:00:45 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Sun", "Zequn", ""], ["Huang", "Jiacheng", ""], ["Hu", "Wei", ""], ["Chen", "Muchao", ""], ["Guo", "Lingbing", ""], ["Qu", "Yuzhong", ""]]}, {"id": "2004.13587", "submitter": "Zhongchao Qian", "authors": "Zhongchao Qian, Tyler L. Hayes, Kushal Kafle, Christopher Kanan", "title": "Do We Need Fully Connected Output Layers in Convolutional Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, deep convolutional neural networks consist of a series of\nconvolutional and pooling layers followed by one or more fully connected (FC)\nlayers to perform the final classification. While this design has been\nsuccessful, for datasets with a large number of categories, the fully connected\nlayers often account for a large percentage of the network's parameters. For\napplications with memory constraints, such as mobile devices and embedded\nplatforms, this is not ideal. Recently, a family of architectures that involve\nreplacing the learned fully connected output layer with a fixed layer has been\nproposed as a way to achieve better efficiency. In this paper we examine this\nidea further and demonstrate that fixed classifiers offer no additional benefit\ncompared to simply removing the output layer along with its parameters. We\nfurther demonstrate that the typical approach of having a fully connected final\noutput layer is inefficient in terms of parameter count. We are able to achieve\ncomparable performance to a traditionally learned fully connected\nclassification output layer on the ImageNet-1K, CIFAR-100, Stanford Cars-196,\nand Oxford Flowers-102 datasets, while not having a fully connected output\nlayer at all.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:21:44 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 03:20:47 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Qian", "Zhongchao", ""], ["Hayes", "Tyler L.", ""], ["Kafle", "Kushal", ""], ["Kanan", "Christopher", ""]]}, {"id": "2004.13595", "submitter": "Lei Xie", "authors": "Shan Yang, Yuxuan Wang, Lei Xie", "title": "Adversarial Feature Learning and Unsupervised Clustering based Speech\n  Synthesis for Found Data with Acoustic and Textual Noise", "comments": "submitted to IEEE SPL", "journal-ref": null, "doi": "10.1109/LSP.2020.3025410", "report-no": null, "categories": "cs.SD cs.LG eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based sequence-to-sequence (seq2seq) speech synthesis has achieved\nextraordinary performance. But a studio-quality corpus with manual\ntranscription is necessary to train such seq2seq systems. In this paper, we\npropose an approach to build high-quality and stable seq2seq based speech\nsynthesis system using challenging found data, where training speech contains\nnoisy interferences (acoustic noise) and texts are imperfect speech recognition\ntranscripts (textual noise). To deal with text-side noise, we propose a VQVAE\nbased heuristic method to compensate erroneous linguistic feature with phonetic\ninformation learned directly from speech. As for the speech-side noise, we\npropose to learn a noise-independent feature in the auto-regressive decoder\nthrough adversarial training and data augmentation, which does not need an\nextra speech enhancement model. Experiments show the effectiveness of the\nproposed approach in dealing with text-side and speech-side noise. Surpassing\nthe denoising approach based on a state-of-the-art speech enhancement model,\nour system built on noisy found data can synthesize clean and high-quality\nspeech with MOS close to the system built on the clean counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:32:45 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Yang", "Shan", ""], ["Wang", "Yuxuan", ""], ["Xie", "Lei", ""]]}, {"id": "2004.13598", "submitter": "Amit Chaulwar", "authors": "Amit Chaulwar", "title": "Private Dataset Generation Using Privacy Preserving Collaborative\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With increasing usage of deep learning algorithms in many application, new\nresearch questions related to privacy and adversarial attacks are emerging.\nHowever, the deep learning algorithm improvement needs more and more data to be\nshared within research community. Methodologies like federated learning,\ndifferential privacy, additive secret sharing provides a way to train machine\nlearning models on edge without moving the data from the edge. However, it is\nvery computationally intensive and prone to adversarial attacks. Therefore,\nthis work introduces a privacy preserving FedCollabNN framework for training\nmachine learning models at edge, which is computationally efficient and robust\nagainst adversarial attacks. The simulation results using MNIST dataset\nindicates the effectiveness of the framework.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:35:20 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Chaulwar", "Amit", ""]]}, {"id": "2004.13606", "submitter": "Xiang Zhou", "authors": "Xiang Zhou, Yixin Nie, Hao Tan, Mohit Bansal", "title": "The Curse of Performance Instability in Analysis Datasets: Consequences,\n  Source, and Suggestions", "comments": "EMNLP 2020 (14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that the performance of state-of-the-art models on Natural Language\nInference (NLI) and Reading Comprehension (RC) analysis/stress sets can be\nhighly unstable. This raises three questions: (1) How will the instability\naffect the reliability of the conclusions drawn based on these analysis sets?\n(2) Where does this instability come from? (3) How should we handle this\ninstability and what are some potential solutions? For the first question, we\nconduct a thorough empirical study over analysis sets and find that in addition\nto the unstable final performance, the instability exists all along the\ntraining curve. We also observe lower-than-expected correlations between the\nanalysis validation set and standard validation set, questioning the\neffectiveness of the current model-selection routine. Next, to answer the\nsecond question, we give both theoretical explanations and empirical evidence\nregarding the source of the instability, demonstrating that the instability\nmainly comes from high inter-example correlations within analysis sets.\nFinally, for the third question, we discuss an initial attempt to mitigate the\ninstability and suggest guidelines for future work such as reporting the\ndecomposed variance for more interpretable results and fair comparison across\nmodels. Our code is publicly available at:\nhttps://github.com/owenzx/InstabilityAnalysis\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:41:12 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 02:22:35 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Zhou", "Xiang", ""], ["Nie", "Yixin", ""], ["Tan", "Hao", ""], ["Bansal", "Mohit", ""]]}, {"id": "2004.13608", "submitter": "Namkyoung Lee", "authors": "Namkyoung Lee, Michael H. Azarian and Michael G. Pecht", "title": "An Explainable Deep Learning-based Prognostic Model for Rotating\n  Machinery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper develops an explainable deep learning model that estimates the\nremaining useful lives of rotating machinery. The model extracts high-level\nfeatures from Fourier transform using an autoencoder. The features are used as\ninput to a feedforward neural network to estimate the remaining useful lives.\nThe paper explains the model's behavior by analyzing the composition of the\nfeatures and the relationships between the features and the estimation results.\nIn order to make the model explainable, the paper introduces octave-band\nfiltering. The filtering reduces the input size of the autoencoder and\nsimplifies the model. A case study demonstrates the methods to explain the\nmodel. The study also shows that the octave band-filtering in the model\nimitates the functionality of low-level convolutional layers. This result\nsupports the validity of using the filtering to reduce the depth of the model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:41:43 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Lee", "Namkyoung", ""], ["Azarian", "Michael H.", ""], ["Pecht", "Michael G.", ""]]}, {"id": "2004.13612", "submitter": "Calypso Herrera", "authors": "Calypso Herrera, Florian Krach, Anastasis Kratsios, Pierre Ruyssen,\n  Josef Teichmann", "title": "Denise: Deep Robust Principal Component Analysis for Positive\n  Semidefinite Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust PCA of covariance matrices plays an essential role when isolating\nkey explanatory features. The currently available methods for performing such a\nlow-rank plus sparse decomposition are matrix specific, meaning, those\nalgorithms must re-run for every new matrix. Since these algorithms are\ncomputationally expensive, it is preferable to learn and store a function that\ninstantaneously performs this decomposition when evaluated. Therefore, we\nintroduce Denise, a deep learning-based algorithm for robust PCA of covariance\nmatrices, or more generally of symmetric positive semidefinite matrices, which\nlearns precisely such a function. Theoretical guarantees for Denise are\nprovided. These include a novel universal approximation theorem adapted to our\ngeometric deep learning problem, convergence to an optimal solution of the\nlearning problem and convergence of the training scheme. Our experiments show\nthat Denise matches state-of-the-art performance in terms of decomposition\nquality, while being approximately 2000x faster than the state-of-the-art, PCP,\nand 200x faster than the current speed optimized method, fast PCP.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:45:21 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 18:26:24 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 13:35:22 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Herrera", "Calypso", ""], ["Krach", "Florian", ""], ["Kratsios", "Anastasis", ""], ["Ruyssen", "Pierre", ""], ["Teichmann", "Josef", ""]]}, {"id": "2004.13617", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi, Natalie Frank, Mehryar Mohri", "title": "Adversarial Learning Guarantees for Linear Hypotheses and Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial or test time robustness measures the susceptibility of a\nclassifier to perturbations to the test input. While there has been a flurry of\nrecent work on designing defenses against such perturbations, the theory of\nadversarial robustness is not well understood. In order to make progress on\nthis, we focus on the problem of understanding generalization in adversarial\nsettings, via the lens of Rademacher complexity. We give upper and lower bounds\nfor the adversarial empirical Rademacher complexity of linear hypotheses with\nadversarial perturbations measured in $l_r$-norm for an arbitrary $r \\geq 1$.\nThis generalizes the recent result of [Yin et al.'19] that studies the case of\n$r = \\infty$, and provides a finer analysis of the dependence on the input\ndimensionality as compared to the recent work of [Khim and Loh'19] on linear\nhypothesis classes.\n  We then extend our analysis to provide Rademacher complexity lower and upper\nbounds for a single ReLU unit. Finally, we give adversarial Rademacher\ncomplexity bounds for feed-forward neural networks with one hidden layer.\nUnlike previous works we directly provide bounds on the adversarial Rademacher\ncomplexity of the given network, as opposed to a bound on a surrogate. A\nby-product of our analysis also leads to tighter bounds for the Rademacher\ncomplexity of linear hypotheses, for which we give a detailed analysis and\npresent a comparison with existing bounds.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 15:55:16 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Frank", "Natalie", ""], ["Mohri", "Mehryar", ""]]}, {"id": "2004.13631", "submitter": "Jie Zhou", "authors": "Jie Zhou, Shengding Hu, Xin Lv, Cheng Yang, Zhiyuan Liu, Wei Xu, Jie\n  Jiang, Juanzi Li, Maosong Sun", "title": "KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization\n  and Completion", "comments": "Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive knowledge graph (KG) contains an instance-level entity graph\nand an ontology-level concept graph. The two-view KG provides a testbed for\nmodels to \"simulate\" human's abilities on knowledge abstraction,\nconcretization, and completion (KACC), which are crucial for human to recognize\nthe world and manage learned knowledge. Existing studies mainly focus on\npartial aspects of KACC. In order to promote thorough analyses for KACC\nabilities of models, we propose a unified KG benchmark by improving existing\nbenchmarks in terms of dataset scale, task coverage, and difficulty.\nSpecifically, we collect new datasets that contain larger concept graphs,\nabundant cross-view links as well as dense entity graphs. Based on the\ndatasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),\nmulti-hop knowledge concretization (MKC) and then design a comprehensive\nbenchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical\ntriples as harder samples. The experimental results of existing methods\ndemonstrate the challenges of our benchmark. The resource is available at\nhttps://github.com/thunlp/KACC.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:21:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 03:23:10 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zhou", "Jie", ""], ["Hu", "Shengding", ""], ["Lv", "Xin", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Xu", "Wei", ""], ["Jiang", "Jie", ""], ["Li", "Juanzi", ""], ["Sun", "Maosong", ""]]}, {"id": "2004.13649", "submitter": "Rob Fergus", "authors": "Ilya Kostrikov, Denis Yarats, Rob Fergus", "title": "Image Augmentation Is All You Need: Regularizing Deep Reinforcement\n  Learning from Pixels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple data augmentation technique that can be applied to\nstandard model-free reinforcement learning algorithms, enabling robust learning\ndirectly from pixels without the need for auxiliary losses or pre-training. The\napproach leverages input perturbations commonly used in computer vision tasks\nto regularize the value function. Existing model-free approaches, such as Soft\nActor-Critic (SAC), are not able to train deep networks effectively from image\npixels. However, the addition of our augmentation method dramatically improves\nSAC's performance, enabling it to reach state-of-the-art performance on the\nDeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC)\nmethods and recently proposed contrastive learning (CURL). Our approach can be\ncombined with any model-free reinforcement learning algorithm, requiring only\nminor modifications. An implementation can be found at\nhttps://sites.google.com/view/data-regularized-q.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:48:16 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 14:51:10 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 13:47:47 GMT"}, {"version": "v4", "created": "Sun, 7 Mar 2021 16:37:37 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kostrikov", "Ilya", ""], ["Yarats", "Denis", ""], ["Fergus", "Rob", ""]]}, {"id": "2004.13651", "submitter": "Miltiadis Allamanis", "authors": "Alexey Svyatkovskiy, Sebastian Lee, Anna Hadjitofi, Maik Riechert,\n  Juliana Franco, Miltiadis Allamanis", "title": "Fast and Memory-Efficient Neural Code Completion", "comments": null, "journal-ref": "Published at Mining Software Repositories 2021", "doi": null, "report-no": null, "categories": "cs.SE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code completion is one of the most widely used features of modern integrated\ndevelopment environments (IDEs). While deep learning has made significant\nprogress in the statistical prediction of source code, state-of-the-art neural\nnetwork models consume hundreds of megabytes of memory, bloating the\ndevelopment environment. We address this in two steps: first we present a\nmodular neural framework for code completion. This allows us to explore the\ndesign space and evaluate different techniques. Second, within this framework\nwe design a novel reranking neural completion model that combines static\nanalysis with granular token encodings. The best neural reranking model\nconsumes just 6 MB of RAM, - 19x less than previous models - computes a single\ncompletion in 8 ms, and achieves 90% accuracy in its top five suggestions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 16:51:59 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 07:27:03 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 20:13:36 GMT"}, {"version": "v4", "created": "Tue, 16 Mar 2021 07:48:36 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Svyatkovskiy", "Alexey", ""], ["Lee", "Sebastian", ""], ["Hadjitofi", "Anna", ""], ["Riechert", "Maik", ""], ["Franco", "Juliana", ""], ["Allamanis", "Miltiadis", ""]]}, {"id": "2004.13657", "submitter": "Katya Kudashkina", "authors": "Katya Kudashkina, Valliappa Chockalingam, Graham W. Taylor, Michael\n  Bowling", "title": "Sample-Efficient Model-based Actor-Critic for an Interactive Dialogue\n  Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-computer interactive systems that rely on machine learning are becoming\nparamount to the lives of millions of people who use digital assistants on a\ndaily basis. Yet, further advances are limited by the availability of data and\nthe cost of acquiring new samples. One way to address this problem is by\nimproving the sample efficiency of current approaches. As a solution path, we\npresent a model-based reinforcement learning algorithm for an interactive\ndialogue task. We build on commonly used actor-critic methods, adding an\nenvironment model and planner that augments a learning agent to learn the model\nof the environment dynamics. Our results show that, on a simulation that mimics\nthe interactive task, our algorithm requires 70 times fewer samples, compared\nto the baseline of commonly used model-free algorithm, and demonstrates 2~times\nbetter performance asymptotically. Moreover, we introduce a novel contribution\nof computing a soft planner policy and further updating a model-free policy\nyielding a less computationally expensive model-free agent as good as the\nmodel-based one. This model-based architecture serves as a foundation that can\nbe extended to other human-computer interactive tasks allowing further advances\nin this direction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:00:59 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Kudashkina", "Katya", ""], ["Chockalingam", "Valliappa", ""], ["Taylor", "Graham W.", ""], ["Bowling", "Michael", ""]]}, {"id": "2004.13664", "submitter": "Yunzhu Li", "authors": "Yunzhu Li, Toru Lin, Kexin Yi, Daniel M. Bear, Daniel L. K. Yamins,\n  Jiajun Wu, Joshua B. Tenenbaum, Antonio Torralba", "title": "Visual Grounding of Learned Physical Models", "comments": "The second and the third authors contributed equally to this paper,\n  and are listed in alphabetical order. Project Page:\n  http://visual-physics-grounding.csail.mit.edu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans intuitively recognize objects' physical properties and predict their\nmotion, even when the objects are engaged in complicated interactions. The\nabilities to perform physical reasoning and to adapt to new environments, while\nintrinsic to humans, remain challenging to state-of-the-art computational\nmodels. In this work, we present a neural model that simultaneously reasons\nabout physics and makes future predictions based on visual and dynamics priors.\nThe visual prior predicts a particle-based representation of the system from\nvisual observations. An inference module operates on those particles,\npredicting and refining estimates of particle locations, object states, and\nphysical parameters, subject to the constraints imposed by the dynamics prior,\nwhich we refer to as visual grounding. We demonstrate the effectiveness of our\nmethod in environments involving rigid objects, deformable materials, and\nfluids. Experiments show that our model can infer the physical properties\nwithin a few observations, which allows the model to quickly adapt to unseen\nscenarios and make accurate predictions into the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:06:38 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:13:21 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Li", "Yunzhu", ""], ["Lin", "Toru", ""], ["Yi", "Kexin", ""], ["Bear", "Daniel M.", ""], ["Yamins", "Daniel L. K.", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""], ["Torralba", "Antonio", ""]]}, {"id": "2004.13667", "submitter": "Ayaka Sakata", "authors": "Ayaka Sakata", "title": "Bayesian inference of infected patients in group testing with prevalence\n  estimation", "comments": null, "journal-ref": null, "doi": "10.7566/JPSJ.89.084001", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group testing is a method of identifying infected patients by performing\ntests on a pool of specimens collected from patients. For the case in which the\ntest returns a false result with finite probability, we propose Bayesian\ninference and a corresponding belief propagation (BP) algorithm to identify the\ninfected patients from the results of tests performed on the pool. We show that\nthe true-positive rate is improved by taking into account the credible interval\nof a point estimate of each patient. Further, the prevalence and the error\nprobability in the test are estimated by combining an expectation-maximization\nmethod with the BP algorithm. As another approach, we introduce a hierarchical\nBayes model to identify the infected patients and estimate the prevalence. By\ncomparing these methods, we formulate a guide for practical usage.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:11:43 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 02:28:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sakata", "Ayaka", ""]]}, {"id": "2004.13688", "submitter": "Shaan Desai", "authors": "Shaan Desai, Marios Mattheakis and Stephen Roberts", "title": "Variational Integrator Graph Networks for Learning Energy Conserving\n  Dynamical Systems", "comments": "updated version that includes an extensive ablation across\n  graph,non-graph methods as well as different integrators [under review]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances show that neural networks embedded with physics-informed\npriors significantly outperform vanilla neural networks in learning and\npredicting the long term dynamics of complex physical systems from noisy data.\nDespite this success, there has only been a limited study on how to optimally\ncombine physics priors to improve predictive performance. To tackle this\nproblem we unpack and generalize recent innovations into individual inductive\nbias segments. As such, we are able to systematically investigate all possible\ncombinations of inductive biases of which existing methods are a natural\nsubset. Using this framework we introduce Variational Integrator Graph Networks\n- a novel method that unifies the strengths of existing approaches by combining\nan energy constraint, high-order symplectic variational integrators, and graph\nneural networks. We demonstrate, across an extensive ablation, that the\nproposed unifying framework outperforms existing methods, for data-efficient\nlearning and in predictive accuracy, across both single and many-body problems\nstudied in recent literature. We empirically show that the improvements arise\nbecause high order variational integrators combined with a potential energy\nconstraint induce coupled learning of generalized position and momentum updates\nwhich can be formalized via the Partitioned Runge-Kutta method.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:42:47 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 16:06:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Desai", "Shaan", ""], ["Mattheakis", "Marios", ""], ["Roberts", "Stephen", ""]]}, {"id": "2004.13701", "submitter": "Nils Strodthoff", "authors": "Nils Strodthoff, Patrick Wagner, Tobias Schaeffter, Wojciech Samek", "title": "Deep Learning for ECG Analysis: Benchmarks and Insights from PTB-XL", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocardiography is a very common, non-invasive diagnostic procedure and\nits interpretation is increasingly supported by automatic interpretation\nalgorithms. The progress in the field of automatic ECG interpretation has up to\nnow been hampered by a lack of appropriate datasets for training as well as a\nlack of well-defined evaluation procedures to ensure comparability of different\nalgorithms. To alleviate these issues, we put forward first benchmarking\nresults for the recently published, freely accessible PTB-XL dataset, covering\na variety of tasks from different ECG statement prediction tasks over age and\ngender prediction to signal quality assessment. We find that convolutional\nneural networks, in particular resnet- and inception-based architectures, show\nthe strongest performance across all tasks outperforming feature-based\nalgorithms by a large margin. These results are complemented by deeper insights\ninto the classification algorithm in terms of hidden stratification, model\nuncertainty and an exploratory interpretability analysis. We also put forward\nbenchmarking results for the ICBEB2018 challenge ECG dataset and discuss\nprospects of transfer learning using classifiers pretrained on PTB-XL. With\nthis resource, we aim to establish the PTB-XL dataset as a resource for\nstructured benchmarking of ECG analysis algorithms and encourage other\nresearchers in the field to join these efforts.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:55:17 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Strodthoff", "Nils", ""], ["Wagner", "Patrick", ""], ["Schaeffter", "Tobias", ""], ["Samek", "Wojciech", ""]]}, {"id": "2004.13705", "submitter": "Raphael Tang", "authors": "Raphael Tang, Jaejun Lee, Ji Xin, Xinyu Liu, Yaoliang Yu, Jimmy Lin", "title": "Showing Your Work Doesn't Always Work", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing, a recently popular line of work explores how\nto best report the experimental results of neural networks. One exemplar\npublication, titled \"Show Your Work: Improved Reporting of Experimental\nResults,\" advocates for reporting the expected validation effectiveness of the\nbest-tuned model, with respect to the computational budget. In the present\nwork, we critically examine this paper. As far as statistical generalizability\nis concerned, we find unspoken pitfalls and caveats with this approach. We\nanalytically show that their estimator is biased and uses error-prone\nassumptions. We find that the estimator favors negative errors and yields poor\nbootstrapped confidence intervals. We derive an unbiased alternative and\nbolster our claims with empirical evidence from statistical simulation. Our\ncodebase is at http://github.com/castorini/meanmax.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:59:01 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Tang", "Raphael", ""], ["Lee", "Jaejun", ""], ["Xin", "Ji", ""], ["Liu", "Xinyu", ""], ["Yu", "Yaoliang", ""], ["Lin", "Jimmy", ""]]}, {"id": "2004.13714", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Yash Kumar Singh, Dhish Kumar Saxena", "title": "On Learning Combinatorial Patterns to Assist Large-Scale Airline Crew\n  Pairing Optimization", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Airline Crew Pairing Optimization (CPO) aims at generating a set of legal\nflight sequences (crew pairings), to cover an airline's flight schedule, at\nminimum cost. It is usually performed using Column Generation (CG), a\nmathematical programming technique for guided search-space exploration. CG\nexploits the interdependencies between the current and the preceding\nCG-iteration for generating new variables (pairings) during the\noptimization-search. However, with the unprecedented scale and complexity of\nthe emergent flight networks, it has become imperative to learn higher-order\ninterdependencies among the flight-connection graphs, and utilize those to\nenhance the efficacy of the CPO. In first of its kind and what marks a\nsignificant departure from the state-of-the-art, this paper proposes a novel\nadaptation of the Variational Graph Auto-Encoder for learning plausible\ncombinatorial patterns among the flight-connection data obtained through the\nsearch-space exploration by an Airline Crew Pairing Optimizer, AirCROP\n(developed by the authors and validated by the research consortium's industrial\nsponsor, GE Aviation). The resulting flight-connection predictions are combined\non-the-fly using a novel heuristic to generate new pairings for the optimizer.\nThe utility of the proposed approach is demonstrated on large-scale (over 4200\nflights), real-world, complex flight-networks of US-based airlines,\ncharacterized by multiple hub-and-spoke subnetworks and several crew bases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:16:22 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 07:57:27 GMT"}, {"version": "v3", "created": "Sat, 2 May 2020 11:46:35 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Singh", "Yash Kumar", ""], ["Saxena", "Dhish Kumar", ""]]}, {"id": "2004.13715", "submitter": "Luca Belli", "authors": "Luca Belli, Sofia Ira Ktena, Alykhan Tejani, Alexandre Lung-Yut-Fon,\n  Frank Portman, Xiao Zhu, Yuanpu Xie, Akshay Gupta, Michael Bronstein, Amra\n  Deli\\'c, Gabriele Sottocornola, Walter Anelli, Nazareno Andrade, Jessie\n  Smith, Wenzhe Shi", "title": "Privacy-Aware Recommender Systems Challenge on Twitter's Home Timeline", "comments": "16 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems constitute the core engine of most social network\nplatforms nowadays, aiming to maximize user satisfaction along with other key\nbusiness objectives. Twitter is no exception. Despite the fact that Twitter\ndata has been extensively used to understand socioeconomic and political\nphenomena and user behaviour, the implicit feedback provided by users on Tweets\nthrough their engagements on the Home Timeline has only been explored to a\nlimited extent. At the same time, there is a lack of large-scale public social\nnetwork datasets that would enable the scientific community to both benchmark\nand build more powerful and comprehensive models that tailor content to user\ninterests. By releasing an original dataset of 160 million Tweets along with\nengagement information, Twitter aims to address exactly that. During this\nrelease, special attention is drawn on maintaining compliance with existing\nprivacy laws. Apart from user privacy, this paper touches on the key challenges\nfaced by researchers and professionals striving to predict user engagements. It\nfurther describes the key aspects of the RecSys 2020 Challenge that was\norganized by ACM RecSys in partnership with Twitter using this dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 23:54:33 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 13:26:49 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 13:25:23 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Belli", "Luca", ""], ["Ktena", "Sofia Ira", ""], ["Tejani", "Alykhan", ""], ["Lung-Yut-Fon", "Alexandre", ""], ["Portman", "Frank", ""], ["Zhu", "Xiao", ""], ["Xie", "Yuanpu", ""], ["Gupta", "Akshay", ""], ["Bronstein", "Michael", ""], ["Deli\u0107", "Amra", ""], ["Sottocornola", "Gabriele", ""], ["Anelli", "Walter", ""], ["Andrade", "Nazareno", ""], ["Smith", "Jessie", ""], ["Shi", "Wenzhe", ""]]}, {"id": "2004.13747", "submitter": "Timo Felser", "authors": "Timo Felser, Marco Trenti, Lorenzo Sestini, Alessio Gianelle, Davide\n  Zuliani, Donatella Lucchesi and Simone Montangero", "title": "Quantum-inspired Machine Learning on high-energy physics data", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG hep-ex physics.data-an quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor Networks, a numerical tool originally designed for simulating quantum\nmany-body systems, have recently been applied to solve Machine Learning\nproblems. Exploiting a tree tensor network, we apply a quantum-inspired machine\nlearning technique to a very important and challenging big data problem in high\nenergy physics: the analysis and classification of data produced by the Large\nHadron Collider at CERN. In particular, we present how to effectively classify\nso-called b-jets, jets originating from b-quarks from proton-proton collisions\nin the LHCb experiment, and how to interpret the classification results. We\nexploit the Tensor Network approach to select important features and adapt the\nnetwork geometry based on information acquired in the learning process.\nFinally, we show how to adapt the tree tensor network to achieve optimal\nprecision or fast response in time without the need of repeating the learning\nprocess. These results pave the way to the implementation of high-frequency\nreal-time applications, a key ingredient needed among others for current and\nfuture LHCb event classification able to trigger events at the tens of MHz\nscale.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:00:12 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 08:36:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Felser", "Timo", ""], ["Trenti", "Marco", ""], ["Sestini", "Lorenzo", ""], ["Gianelle", "Alessio", ""], ["Zuliani", "Davide", ""], ["Lucchesi", "Donatella", ""], ["Montangero", "Simone", ""]]}, {"id": "2004.13748", "submitter": "Sitan Chen", "authors": "Sitan Chen, Raghu Meka", "title": "Learning Polynomials of Few Relevant Dimensions", "comments": "64 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polynomial regression is a basic primitive in learning and statistics. In its\nmost basic form the goal is to fit a degree $d$ polynomial to a response\nvariable $y$ in terms of an $n$-dimensional input vector $x$. This is extremely\nwell-studied with many applications and has sample and runtime complexity\n$\\Theta(n^d)$. Can one achieve better runtime if the intrinsic dimension of the\ndata is much smaller than the ambient dimension $n$? Concretely, we are given\nsamples $(x,y)$ where $y$ is a degree at most $d$ polynomial in an unknown\n$r$-dimensional projection (the relevant dimensions) of $x$. This can be seen\nboth as a generalization of phase retrieval and as a special case of learning\nmulti-index models where the link function is an unknown low-degree polynomial.\nNote that without distributional assumptions, this is at least as hard as junta\nlearning.\n  In this work we consider the important case where the covariates are\nGaussian. We give an algorithm that learns the polynomial within accuracy\n$\\epsilon$ with sample complexity that is roughly $N = O_{r,d}(n\n\\log^2(1/\\epsilon) (\\log n)^d)$ and runtime $O_{r,d}(N n^2)$. Prior to our\nwork, no such results were known even for the case of $r=1$. We introduce a new\nfiltered PCA approach to get a warm start for the true subspace and use\ngeodesic SGD to boost to arbitrary accuracy; our techniques may be of\nindependent interest, especially for problems dealing with subspace recovery or\nanalyzing SGD on manifolds.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:00:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Chen", "Sitan", ""], ["Meka", "Raghu", ""]]}, {"id": "2004.13770", "submitter": "Michela Paganini", "authors": "Michela Paganini and Jessica Forde", "title": "Streamlining Tensor and Network Pruning in PyTorch", "comments": "5 pages, 1 figure, 5 code listings. Published as a workshop paper at\n  ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to contrast the explosion in size of state-of-the-art machine\nlearning models that can be attributed to the empirical advantages of\nover-parametrization, and due to the necessity of deploying fast, sustainable,\nand private on-device models on resource-constrained devices, the community has\nfocused on techniques such as pruning, quantization, and distillation as\ncentral strategies for model compression. Towards the goal of facilitating the\nadoption of a common interface for neural network pruning in PyTorch, this\ncontribution describes the recent addition of the PyTorch torch.nn.utils.prune\nmodule, which provides shared, open source pruning functionalities to lower the\ntechnical implementation barrier to reducing model size and capacity before,\nduring, and/or after training. We present the module's user interface,\nelucidate implementation details, illustrate example usage, and suggest ways to\nextend the contributed functionalities to new pruning methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 18:39:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Paganini", "Michela", ""], ["Forde", "Jessica", ""]]}, {"id": "2004.13781", "submitter": "Shu Cheng Li", "authors": "Shucheng Li, Lingfei Wu, Shiwei Feng, Fangli Xu, Fengyuan Xu and Sheng\n  Zhong", "title": "Graph-to-Tree Neural Networks for Learning Structured Input-Output\n  Translation with Applications to Semantic Parsing and Math Word Problem", "comments": "Long Paper in EMNLP 2020. 12 pages including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Seq2Seq technique and its numerous variants achieve excellent\nperformance on many tasks such as neural machine translation, semantic parsing,\nand math word problem solving. However, these models either only consider input\nobjects as sequences while ignoring the important structural information for\nencoding, or they simply treat output objects as sequence outputs instead of\nstructural objects for decoding. In this paper, we present a novel\nGraph-to-Tree Neural Networks, namely Graph2Tree consisting of a graph encoder\nand a hierarchical tree decoder, that encodes an augmented graph-structured\ninput and decodes a tree-structured output. In particular, we investigated our\nmodel for solving two problems, neural semantic parsing and math word problem.\nOur extensive experiments demonstrate that our Graph2Tree model outperforms or\nmatches the performance of other state-of-the-art models on these tasks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:36:38 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:07:57 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Li", "Shucheng", ""], ["Wu", "Lingfei", ""], ["Feng", "Shiwei", ""], ["Xu", "Fangli", ""], ["Xu", "Fengyuan", ""], ["Zhong", "Sheng", ""]]}, {"id": "2004.13786", "submitter": "Shanchan Wu", "authors": "Shanchan Wu and Kai Fan", "title": "A Practical Framework for Relation Extraction with Noisy Labels Based on\n  Doubly Transitional Loss", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Either human annotation or rule based automatic labeling is an effective\nmethod to augment data for relation extraction. However, the inevitable wrong\nlabeling problem for example by distant supervision may deteriorate the\nperformance of many existing methods. To address this issue, we introduce a\npractical end-to-end deep learning framework, including a standard feature\nextractor and a novel noisy classifier with our proposed doubly transitional\nmechanism. One transition is basically parameterized by a non-linear\ntransformation between hidden layers that implicitly represents the conversion\nbetween the true and noisy labels, and it can be readily optimized together\nwith other model parameters. Another is an explicit probability transition\nmatrix that captures the direct conversion between labels but needs to be\nderived from an EM algorithm. We conduct experiments on the NYT dataset and\nSemEval 2018 Task 7. The empirical results show comparable or better\nperformance over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 19:38:20 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wu", "Shanchan", ""], ["Fan", "Kai", ""]]}, {"id": "2004.13795", "submitter": "Daniele Cattaneo", "authors": "Daniele Cattaneo, Domenico Giorgio Sorrenti, Abhinav Valada", "title": "CMRNet++: Map and Camera Agnostic Monocular Visual Localization in LiDAR\n  Maps", "comments": "Spotlight talk at IEEE ICRA 2020 Workshop on Emerging Learning and\n  Algorithmic Methods for Data Association in Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization is a critically essential and crucial enabler of autonomous\nrobots. While deep learning has made significant strides in many computer\nvision tasks, it is still yet to make a sizeable impact on improving\ncapabilities of metric visual localization. One of the major hindrances has\nbeen the inability of existing Convolutional Neural Network (CNN)-based pose\nregression methods to generalize to previously unseen places. Our recently\nintroduced CMRNet effectively addresses this limitation by enabling map\nindependent monocular localization in LiDAR-maps. In this paper, we now take it\na step further by introducing CMRNet++, which is a significantly more robust\nmodel that not only generalizes to new places effectively, but is also\nindependent of the camera parameters. We enable this capability by combining\ndeep learning with geometric techniques, and by moving the metric reasoning\noutside the learning process. In this way, the weights of the network are not\ntied to a specific camera. Extensive evaluations of CMRNet++ on three\nchallenging autonomous driving datasets, i.e., KITTI, Argoverse, and Lyft5,\nshow that CMRNet++ outperforms CMRNet as well as other baselines by a large\nmargin. More importantly, for the first-time, we demonstrate the ability of a\ndeep learning approach to accurately localize without any retraining or\nfine-tuning in a completely new environment and independent of the camera\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 10:10:14 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 09:00:25 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Cattaneo", "Daniele", ""], ["Sorrenti", "Domenico Giorgio", ""], ["Valada", "Abhinav", ""]]}, {"id": "2004.13796", "submitter": "Qingyang Wu", "authors": "Qingyang Wu, Lei Li, Zhou Yu", "title": "TextGAIL: Generative Adversarial Imitation Learning for Text Generation", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) for text generation have recently\nreceived many criticisms, as they perform worse than their MLE counterparts. We\nsuspect previous text GANs' inferior performance is due to the lack of a\nreliable guiding signal in their discriminators. To address this problem, we\npropose a generative adversarial imitation learning framework for text\ngeneration that uses large pre-trained language models to provide more reliable\nreward guidance. Our approach uses contrastive discriminator, and proximal\npolicy optimization (PPO) to stabilize and improve text generation performance.\nFor evaluation, we conduct experiments on a diverse set of unconditional and\nconditional text generation tasks. Experimental results show that TextGAIL\nachieves better performance in terms of both quality and diversity than the MLE\nbaseline. We also validate our intuition that TextGAIL's discriminator\ndemonstrates the capability of providing reasonable rewards with an additional\ntask.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:24:35 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 23:22:07 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 02:40:09 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 19:32:42 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Wu", "Qingyang", ""], ["Li", "Lei", ""], ["Yu", "Zhou", ""]]}, {"id": "2004.13799", "submitter": "Michael McCoyd", "authors": "Michael McCoyd, Won Park, Steven Chen, Neil Shah, Ryan Roggenkemper,\n  Minjune Hwang, Jason Xinyu Liu and David Wagner", "title": "Minority Reports Defense: Defending Against Adversarial Patches", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning image classification is vulnerable to adversarial attack, even\nif the attacker changes just a small patch of the image. We propose a defense\nagainst patch attacks based on partially occluding the image around each\ncandidate patch location, so that a few occlusions each completely hide the\npatch. We demonstrate on CIFAR-10, Fashion MNIST, and MNIST that our defense\nprovides certified security against patch attacks of a certain size.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:11:18 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["McCoyd", "Michael", ""], ["Park", "Won", ""], ["Chen", "Steven", ""], ["Shah", "Neil", ""], ["Roggenkemper", "Ryan", ""], ["Hwang", "Minjune", ""], ["Liu", "Jason Xinyu", ""], ["Wagner", "David", ""]]}, {"id": "2004.13805", "submitter": "Taeuk Kim", "authors": "Taeuk Kim, Bowen Li, Sang-goo Lee", "title": "Multilingual Chart-based Constituency Parse Extraction from Pre-trained\n  Language Models", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As it has been unveiled that pre-trained language models (PLMs) are to some\nextent capable of recognizing syntactic concepts in natural language, much\neffort has been made to develop a method for extracting complete (binary)\nparses from PLMs without training separate parsers. We improve upon this\nparadigm by proposing a novel chart-based method and an effective top-K\nensemble technique. Moreover, we demonstrate that we can broaden the scope of\napplication of the approach into multilingual settings. Specifically, we show\nthat by applying our method on multilingual PLMs, it becomes possible to induce\nnon-trivial parses for sentences from nine languages in an integrated and\nlanguage-agnostic manner, attaining performance superior or comparable to that\nof unsupervised PCFGs. We also verify that our approach is robust to\ncross-lingual transfer. Finally, we provide analyses on the inner workings of\nour method. For instance, we discover universal attention heads which are\nconsistently sensitive to syntactic information irrespective of the input\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 05:42:26 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 05:40:25 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 03:52:38 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kim", "Taeuk", ""], ["Li", "Bowen", ""], ["Lee", "Sang-goo", ""]]}, {"id": "2004.13809", "submitter": "Aneta Polewko-Klim", "authors": "Aneta Polewko-Klim, Witold R. Rudnicki", "title": "Analysis of ensemble feature selection for correlated high-dimensional\n  RNA-Seq cancer data", "comments": "14 pages, 1 table, 29 figure, submitted to International Conference\n  on Computational Science, Amsterdam 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovery of diagnostic and prognostic molecular markers is important and\nactively pursued the research field in cancer research. For complex diseases,\nthis process is often performed using Machine Learning. The current study\ncompares two approaches for the discovery of relevant variables: by application\nof a single feature selection algorithm, versus by an ensemble of diverse\nalgorithms. These approaches are used to identify variables that are relevant\ndiscerning of four cancer types using RNA-seq profiles from the Cancer Genome\nAtlas. The comparison is carried out in two directions: evaluating the\npredictive performance of models and monitoring the stability of selected\nvariables. The most informative features are identified using a four feature\nselection algorithms, namely U-test, ReliefF, and two variants of the MDFS\nalgorithm. Discerning normal and tumor tissues is performed using the Random\nForest algorithm. The highest stability of the feature set was obtained when\nU-test was used. Unfortunately, models built on feature sets obtained from the\nensemble of feature selection algorithms were no better than for models\ndeveloped on feature sets obtained from individual algorithms. On the other\nhand, the feature selectors leading to the best classification results varied\nbetween data sets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 20:38:53 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Polewko-Klim", "Aneta", ""], ["Rudnicki", "Witold R.", ""]]}, {"id": "2004.13818", "submitter": "Long Xuan Ma", "authors": "Longxuan Ma and Wei-Nan Zhang and Mingda Li and Ting Liu", "title": "A Survey of Document Grounded Dialogue Systems (DGDS)", "comments": "30 pages, 4 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue system (DS) attracts great attention from industry and academia\nbecause of its wide application prospects. Researchers usually divide the DS\naccording to the function. However, many conversations require the DS to switch\nbetween different functions. For example, movie discussion can change from\nchit-chat to QA, the conversational recommendation can transform from chit-chat\nto recommendation, etc. Therefore, classification according to functions may\nnot be enough to help us appreciate the current development trend. We classify\nthe DS based on background knowledge. Specifically, study the latest DS based\non the unstructured document(s). We define Document Grounded Dialogue System\n(DGDS) as the DS that the dialogues are centering on the given document(s). The\nDGDS can be used in scenarios such as talking over merchandise against product\nManual, commenting on news reports, etc. We believe that extracting\nunstructured document(s) information is the future trend of the DS because a\ngreat amount of human knowledge lies in these document(s). The research of the\nDGDS not only possesses a broad application prospect but also facilitates AI to\nbetter understand human knowledge and natural language. We analyze the\nclassification, architecture, datasets, models, and future development trends\nof the DGDS, hoping to help researchers in this field.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 03:22:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ma", "Longxuan", ""], ["Zhang", "Wei-Nan", ""], ["Li", "Mingda", ""], ["Liu", "Ting", ""]]}, {"id": "2004.13821", "submitter": "GuanMing Xiong", "authors": "Guanming Xiong", "title": "Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network", "comments": "the experience result is not as good as I except", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a two stage model for multi-hop question answering.\nThe first stage is a hierarchical graph network, which is used to reason over\nmulti-hop question and is capable to capture different levels of granularity\nusing the nature structure(i.e., paragraphs, questions, sentences and entities)\nof documents. The reasoning process is convert to node classify task(i.e.,\nparagraph nodes and sentences nodes). The second stage is a language model\nfine-tuning task. In a word, stage one use graph neural network to select and\nconcatenate support sentences as one paragraph, and stage two find the answer\nspan in language model fine-tuning paradigm.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 09:34:16 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 03:33:21 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xiong", "Guanming", ""]]}, {"id": "2004.13822", "submitter": "Simon Vandenhende", "authors": "Simon Vandenhende, Thierry Deruyttere and Dusan Grujicic", "title": "A Baseline for the Commands For Autonomous Vehicles Challenge", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Commands For Autonomous Vehicles (C4AV) challenge requires participants\nto solve an object referral task in a real-world setting. More specifically, we\nconsider a scenario where a passenger can pass free-form natural language\ncommands to a self-driving car. This problem is particularly challenging, as\nthe language is much less constrained compared to existing benchmarks, and\nobject references are often implicit. The challenge is based on the recent\n\\texttt{Talk2Car} dataset. This document provides a technical overview of a\nmodel that we released to help participants get started in the competition. The\ncode can be found at https://github.com/talk2car/Talk2Car.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 13:35:47 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Vandenhende", "Simon", ""], ["Deruyttere", "Thierry", ""], ["Grujicic", "Dusan", ""]]}, {"id": "2004.13824", "submitter": "Yiqun Mei", "authors": "Yiqun Mei, Yuchen Fan, Yulun Zhang, Jiahui Yu, Yuqian Zhou, Ding Liu,\n  Yun Fu, Thomas S. Huang and Humphrey Shi", "title": "Pyramid Attention Networks for Image Restoration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-similarity refers to the image prior widely used in image restoration\nalgorithms that small but similar patterns tend to occur at different locations\nand scales. However, recent advanced deep convolutional neural network based\nmethods for image restoration do not take full advantage of self-similarities\nby relying on self-attention neural modules that only process information at\nthe same scale. To solve this problem, we present a novel Pyramid Attention\nmodule for image restoration, which captures long-range feature correspondences\nfrom a multi-scale feature pyramid. Inspired by the fact that corruptions, such\nas noise or compression artifacts, drop drastically at coarser image scales,\nour attention module is designed to be able to borrow clean signals from their\n\"clean\" correspondences at the coarser levels. The proposed pyramid attention\nmodule is a generic building block that can be flexibly integrated into various\nneural architectures. Its effectiveness is validated through extensive\nexperiments on multiple image restoration tasks: image denoising, demosaicing,\ncompression artifact reduction, and super resolution. Without any bells and\nwhistles, our PANet (pyramid attention module with simple network backbones)\ncan produce state-of-the-art results with superior accuracy and visual quality.\nOur code will be available at\nhttps://github.com/SHI-Labs/Pyramid-Attention-Networks\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:12:36 GMT"}, {"version": "v2", "created": "Sun, 31 May 2020 00:58:54 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 14:11:21 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2020 18:47:11 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Mei", "Yiqun", ""], ["Fan", "Yuchen", ""], ["Zhang", "Yulun", ""], ["Yu", "Jiahui", ""], ["Zhou", "Yuqian", ""], ["Liu", "Ding", ""], ["Fu", "Yun", ""], ["Huang", "Thomas S.", ""], ["Shi", "Humphrey", ""]]}, {"id": "2004.13825", "submitter": "Jihong Wang", "authors": "Jihong Wang, Minnan Luo, Fnu Suya, Jundong Li, Zijiang Yang, Qinghua\n  Zheng", "title": "Scalable Attack on Graph Data by Injecting Vicious Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that graph convolution networks (GCNs) are\nvulnerable to carefully designed attacks, which aim to cause misclassification\nof a specific node on the graph with unnoticeable perturbations. However, a\nvast majority of existing works cannot handle large-scale graphs because of\ntheir high time complexity. Additionally, existing works mainly focus on\nmanipulating existing nodes on the graph, while in practice, attackers usually\ndo not have the privilege to modify information of existing nodes. In this\npaper, we develop a more scalable framework named Approximate Fast Gradient\nSign Method (AFGSM) which considers a more practical attack scenario where\nadversaries can only inject new vicious nodes to the graph while having no\ncontrol over the original graph. Methodologically, we provide an approximation\nstrategy to linearize the model we attack and then derive an approximate\nclosed-from solution with a lower time cost. To have a fair comparison with\nexisting attack methods that manipulate the original graph, we adapt them to\nthe new attack scenario by injecting vicious nodes. Empirical experimental\nresults show that our proposed attack method can significantly reduce the\nclassification accuracy of GCNs and is much faster than existing methods\nwithout jeopardizing the attack performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 02:11:13 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wang", "Jihong", ""], ["Luo", "Minnan", ""], ["Suya", "Fnu", ""], ["Li", "Jundong", ""], ["Yang", "Zijiang", ""], ["Zheng", "Qinghua", ""]]}, {"id": "2004.13828", "submitter": "Prabhakar Gupta", "authors": "Prabhakar Gupta and Anil Nelakanti", "title": "DeepSubQE: Quality estimation for subtitle translations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Quality estimation (QE) for tasks involving language data is hard owing to\nnumerous aspects of natural language like variations in paraphrasing, style,\ngrammar, etc. There can be multiple answers with varying levels of\nacceptability depending on the application at hand. In this work, we look at\nestimating quality of translations for video subtitles. We show how existing QE\nmethods are inadequate and propose our method DeepSubQE as a system to estimate\nquality of translation given subtitles data for a pair of languages. We rely on\nvarious data augmentation strategies for automated labelling and synthesis for\ntraining. We create a hybrid network which learns semantic and syntactic\nfeatures of bilingual data and compare it with only-LSTM and only-CNN networks.\nOur proposed network outperforms them by significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:41:15 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gupta", "Prabhakar", ""], ["Nelakanti", "Anil", ""]]}, {"id": "2004.13829", "submitter": "Makoto Nakatsuji Ph. D.", "authors": "Makoto Nakatsuji, Sohei Okui", "title": "Answer Generation through Unified Memories over Multiple Passages", "comments": "IJCAI-2020 (Accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine reading comprehension methods that generate answers by referring to\nmultiple passages for a question have gained much attention in AI and NLP\ncommunities. The current methods, however, do not investigate the relationships\namong multiple passages in the answer generation process, even though topics\ncorrelated among the passages may be answer candidates. Our method, called\nneural answer Generation through Unified Memories over Multiple Passages\n(GUM-MP), solves this problem as follows. First, it determines which tokens in\nthe passages are matched to the question. In particular, it investigates\nmatches between tokens in positive passages, which are assigned to the\nquestion, and those in negative passages, which are not related to the\nquestion. Next, it determines which tokens in the passage are matched to other\npassages assigned to the same question and at the same time it investigates the\ntopics in which they are matched. Finally, it encodes the token sequences with\nthe above two matching results into unified memories in the passage encoders\nand learns the answer sequence by using an encoder-decoder with a\nmultiple-pointer-generator mechanism. As a result, GUM-MP can generate answers\nby pointing to important tokens present across passages. Evaluations indicate\nthat GUM-MP generates much more accurate results than the current models do.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 11:46:40 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Nakatsuji", "Makoto", ""], ["Okui", "Sohei", ""]]}, {"id": "2004.13839", "submitter": "Louis Falissard", "authors": "Louis Falissard, Claire Morgand, Sylvie Roussel, Claire Imbaud, Walid\n  Ghosn, Karim Bounebache, Gr\\'egoire Rey", "title": "Neural translation and automated recognition of ICD10 medical entities\n  from natural language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of medical entities from natural language is an ubiquitous\nproblem in the medical field, with applications ranging from medical act coding\nto the analysis of electronic health data for public health. It is however a\ncomplex task usually requiring human expert intervention, thus making it\nexpansive and time consuming. The recent advances in artificial intelligence,\nspecifically the raise of deep learning methods, has enabled computers to make\nefficient decisions on a number of complex problems, with the notable example\nof neural sequence models and their powerful applications in natural language\nprocessing. They however require a considerable amount of data to learn from,\nwhich is typically their main limiting factor. However, the C\\'epiDc stores an\nexhaustive database of death certificates at the French national scale,\namounting to several millions of natural language examples provided with their\nassociated human coded medical entities available to the machine learning\npractitioner. This article investigates the applications of deep neural\nsequence models to the medical entity recognition from natural language\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 18:17:53 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 10:30:24 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Falissard", "Louis", ""], ["Morgand", "Claire", ""], ["Roussel", "Sylvie", ""], ["Imbaud", "Claire", ""], ["Ghosn", "Walid", ""], ["Bounebache", "Karim", ""], ["Rey", "Gr\u00e9goire", ""]]}, {"id": "2004.13840", "submitter": "Sileye Ba", "authors": "Lo Alla and Dione Cheikh Bamba and Nguer Elhadji Mamadou and Ba Sileye\n  O. Ba and Lo Moussa", "title": "Using LSTM to Translate French to Senegalese Local Languages: Wolof as a\n  Case Study", "comments": "4 pages, 2 tables, ICLR AfricaNLP2020 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a neural machine translation system for Wolof, a\nlow-resource Niger-Congo language. First we gathered a parallel corpus of 70000\naligned French-Wolof sentences. Then we developped a baseline LSTM based\nencoder-decoder architecture which was further extended to bidirectional LSTMs\nwith attention mechanisms. Our models are trained on a limited amount of\nparallel French-Wolof data of approximately 35000 parallel sentences.\nExperimental results on French-Wolof translation tasks show that our approach\nproduces promising translations in extremely low-resource conditions. The best\nmodel was able to achieve a good performance of 47% BLEU score.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 17:09:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Alla", "Lo", ""], ["Bamba", "Dione Cheikh", ""], ["Mamadou", "Nguer Elhadji", ""], ["Ba", "Ba Sileye O.", ""], ["Moussa", "Lo", ""]]}, {"id": "2004.13841", "submitter": "Michael Franklin Mbouopda", "authors": "Michael Franklin Mbouopda, Paulin Melatagia Yonta and Guy Stephane B.\n  Fedim Lombo", "title": "Neurals Networks for Projecting Named Entities from English to Ewondo", "comments": null, "journal-ref": null, "doi": null, "report-no": "2004.13841", "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity recognition is an important task in natural language processing.\nIt is very well studied for rich language, but still under explored for\nlow-resource languages. The main reason is that the existing techniques\nrequired a lot of annotated data to reach good performance. Recently, a new\ndistributional representation of words has been proposed to project named\nentities from a rich language to a low-resource one. This representation has\nbeen coupled to a neural network in order to project named entities from\nEnglish to Ewondo, a Bantu language spoken in Cameroon. Although the proposed\nmethod reached appreciable results, the size of the used neural network was too\nlarge compared to the size of the dataset. Furthermore the impact of the model\nparameters has not been studied. In this paper, we show experimentally that the\nsame results can be obtained using a smaller neural network. We also emphasize\nthe parameters that are highly correlated to the network performance. This work\nis a step forward to build a reliable and robust network architecture for named\nentity projection in low resource languages.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 22:05:30 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Mbouopda", "Michael Franklin", ""], ["Yonta", "Paulin Melatagia", ""], ["Lombo", "Guy Stephane B. Fedim", ""]]}, {"id": "2004.13843", "submitter": "Ram G Athreya", "authors": "Ram G Athreya, Srividya Bansal, Axel-Cyrille Ngonga Ngomo, Ricardo\n  Usbeck", "title": "Template-based Question Answering using Recursive Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network-based approach to automatically learn and\nclassify natural language questions into its corresponding template using\nrecursive neural networks. An obvious advantage of using neural networks is the\nelimination of the need for laborious feature engineering that can be\ncumbersome and error-prone. The input question is encoded into a vector\nrepresentation. The model is trained and evaluated on the LC-QuAD dataset\n(Large-scale Complex Question Answering Dataset). The LC-QuAD queries are\nannotated based on 38 unique templates that the model attempts to classify. The\nresulting model is evaluated against both the LC-QuAD dataset and the 7th\nQuestion Answering Over Linked Data (QALD-7) dataset. The recursive neural\nnetwork achieves template classification accuracy of 0.828 on the LC-QuAD\ndataset and an accuracy of 0.618 on the QALD-7 dataset. When the top-2 most\nlikely templates were considered the model achieves an accuracy of 0.945 on the\nLC-QuAD dataset and 0.786 on the QALD-7 dataset. After slot filling, the\noverall system achieves a macro F-score 0.419 on the LC-QuAD dataset and a\nmacro F-score of 0.417 on the QALD-7 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 18:14:39 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:26:26 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 01:41:26 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Athreya", "Ram G", ""], ["Bansal", "Srividya", ""], ["Ngomo", "Axel-Cyrille Ngonga", ""], ["Usbeck", "Ricardo", ""]]}, {"id": "2004.13845", "submitter": "Yannis Papanikolaou", "authors": "Yannis Papanikolaou and Andrea Pierleoni", "title": "DARE: Data Augmented Relation Extraction with GPT-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world Relation Extraction (RE) tasks are challenging to deal with,\neither due to limited training data or class imbalance issues. In this work, we\npresent Data Augmented Relation Extraction(DARE), a simple method to augment\ntraining data by properly fine-tuning GPT-2 to generate examples for specific\nrelation types. The generated training data is then used in combination with\nthe gold dataset to train a BERT-based RE classifier. In a series of\nexperiments we show the advantages of our method, which leads in improvements\nof up to 11 F1 score points against a strong base-line. Also, DARE achieves new\nstate of the art in three widely used biomedical RE datasets surpassing the\nprevious best results by 4.7 F1 points on average.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:38:36 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Papanikolaou", "Yannis", ""], ["Pierleoni", "Andrea", ""]]}, {"id": "2004.13846", "submitter": "Kenya Sakka", "authors": "Kenya Sakka, Kotaro Nakayama, Nisei Kimura, Taiki Inoue, Yusuke\n  Iwasawa, Ryohei Yamaguchi, Yosimasa Kawazoe, Kazuhiko Ohe, Yutaka Matsuo", "title": "Character-level Japanese Text Generation with Attention Mechanism for\n  Chest Radiography Diagnosis", "comments": "8 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chest radiography is a general method for diagnosing a patient's condition\nand identifying important information; therefore, radiography is used\nextensively in routine medical practice in various situations, such as\nemergency medical care and medical checkup. However, a high level of expertise\nis required to interpret chest radiographs. Thus, medical specialists spend\nconsiderable time in diagnosing such huge numbers of radiographs. In order to\nsolve these problems, methods for generating findings have been proposed.\nHowever, the study of generating chest radiograph findings has primarily\nfocused on the English language, and to the best of our knowledge, no studies\nhave studied Japanese data on this subject. There are two challenges involved\nin generating findings in the Japanese language. The first challenge is that\nword splitting is difficult because the boundaries of Japanese word are not\nclear. The second challenge is that there are numerous orthographic variants.\nFor deal with these two challenges, we proposed an end-to-end model that\ngenerates Japanese findings at the character-level from chest radiographs. In\naddition, we introduced the attention mechanism to improve not only the\naccuracy, but also the interpretation ability of the results. We evaluated the\nproposed method using a public dataset with Japanese findings. The\neffectiveness of the proposed method was confirmed using the Bilingual\nEvaluation Understudy score. And, we were confirmed from the generated findings\nthat the proposed method was able to consider the orthographic variants.\nFurthermore, we confirmed via visual inspection that the attention mechanism\ncaptures the features and positional information of radiographs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 18:19:27 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 05:37:51 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Sakka", "Kenya", ""], ["Nakayama", "Kotaro", ""], ["Kimura", "Nisei", ""], ["Inoue", "Taiki", ""], ["Iwasawa", "Yusuke", ""], ["Yamaguchi", "Ryohei", ""], ["Kawazoe", "Yosimasa", ""], ["Ohe", "Kazuhiko", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "2004.13847", "submitter": "Adly Templeton", "authors": "Adly Templeton", "title": "Inherently Interpretable Sparse Word Embeddings through Sparse Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a powerful natural language processing technique, but\nthey are extremely difficult to interpret. In order to create more\ninterpretable word embeddings, we transform pretrained dense word embeddings\ninto sparse embeddings. These new embeddings are inherently interpretable: each\nof their dimensions are created from and represent a natural language word or\nspecific syntactic concept. We construct these embeddings through sparse\ncoding, where each vector in the basis set is itself a word embedding. We show\nthat models trained using these sparse embeddings can achieve good performance\nand are extremely interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 19:49:49 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Templeton", "Adly", ""]]}, {"id": "2004.13850", "submitter": "Lukas Stappen", "authors": "Lukas Stappen, Fabian Brunn, Bj\\\"orn Schuller", "title": "Cross-lingual Zero- and Few-shot Hate Speech Detection Utilising Frozen\n  Transformer Language Models and AXEL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting hate speech, especially in low-resource languages, is a non-trivial\nchallenge. To tackle this, we developed a tailored architecture based on\nfrozen, pre-trained Transformers to examine cross-lingual zero-shot and\nfew-shot learning, in addition to uni-lingual learning, on the HatEval\nchallenge data set. With our novel attention-based classification block AXEL,\nwe demonstrate highly competitive results on the English and Spanish subsets.\nWe also re-sample the English subset, enabling additional, meaningful\ncomparisons in the future.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 09:58:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Stappen", "Lukas", ""], ["Brunn", "Fabian", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "2004.13851", "submitter": "Siqi Liu", "authors": "Siqi Liu", "title": "Sentiment Analysis of Yelp Reviews: A Comparison of Techniques and\n  Models", "comments": "7 pages, 12 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use over 350,000 Yelp reviews on 5,000 restaurants to perform an ablation\nstudy on text preprocessing techniques. We also compare the effectiveness of\nseveral machine learning and deep learning models on predicting user sentiment\n(negative, neutral, or positive). For machine learning models, we find that\nusing binary bag-of-word representation, adding bi-grams, imposing minimum\nfrequency constraints and normalizing texts have positive effects on model\nperformance. For deep learning models, we find that using pre-trained word\nembeddings and capping maximum length often boost model performance. Finally,\nusing macro F1 score as our comparison metric, we find simpler models such as\nLogistic Regression and Support Vector Machine to be more effective at\npredicting sentiments than more complex models such as Gradient Boosting, LSTM\nand BERT.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:50:49 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Liu", "Siqi", ""]]}, {"id": "2004.13852", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Jun Ma, Xin Luna Dong", "title": "TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product\n  Categories", "comments": "Accepted to ACL 2020 (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting structured knowledge from product profiles is crucial for various\napplications in e-Commerce. State-of-the-art approaches for knowledge\nextraction were each designed for a single category of product, and thus do not\napply to real-life e-Commerce scenarios, which often contain thousands of\ndiverse categories. This paper proposes TXtract, a taxonomy-aware knowledge\nextraction model that applies to thousands of product categories organized in a\nhierarchical taxonomy. Through category conditional self-attention and\nmulti-task learning, our approach is both scalable, as it trains a single model\nfor thousands of categories, and effective, as it extracts category-specific\nattribute values. Experiments on products from a taxonomy with 4,000 categories\nshow that TXtract outperforms state-of-the-art approaches by up to 10% in F1\nand 15% in coverage across all categories.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 03:02:09 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 14:54:13 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Ma", "Jun", ""], ["Dong", "Xin Luna", ""]]}, {"id": "2004.13859", "submitter": "Kun Wang", "authors": "Kun Wang, Mridul Aanjaneya, Kostas Bekris", "title": "A First Principles Approach for Data-Efficient System Identification of\n  Spring-Rod Systems via Differentiable Physics Engines", "comments": "accepted at 2020 Learning for Dynamics and Control (L4DC2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel differentiable physics engine for system identification of\ncomplex spring-rod assemblies. Unlike black-box data-driven methods for\nlearning the evolution of a dynamical system and its parameters, we modularize\nthe design of our engine using a discrete form of the governing equations of\nmotion, similar to a traditional physics engine. We further reduce the\ndimension from 3D to 1D for each module, which allows efficient learning of\nsystem parameters using linear regression. As a side benefit, the regression\nparameters correspond to physical quantities, such as spring stiffness or the\nmass of the rod, making the pipeline explainable. The approach significantly\nreduces the amount of training data required, and also avoids iterative\nidentification of data sampling and model training. We compare the performance\nof the proposed engine with previous solutions, and demonstrate its efficacy on\ntensegrity systems, such as NASA's icosahedron.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:37:55 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wang", "Kun", ""], ["Aanjaneya", "Mridul", ""], ["Bekris", "Kostas", ""]]}, {"id": "2004.13861", "submitter": "Thomas Lachmann", "authors": "Pierre Gillibert, Thomas Lachmann, Clemens M\\\"ullner", "title": "The VC-Dimension of Axis-Parallel Boxes on the Torus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show in this paper that the VC-dimension of the family of $d$-dimensional\naxis-parallel boxes and cubes on the $d$-dimensional torus are both\nasymptotically $d \\log_2(d)$. This is especially surprising as the VC-dimension\nusually grows linearly with $d$ in similar settings.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:41:05 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gillibert", "Pierre", ""], ["Lachmann", "Thomas", ""], ["M\u00fcllner", "Clemens", ""]]}, {"id": "2004.13866", "submitter": "Nikita Jaipuria", "authors": "Nikita Jaipuria, Xianling Zhang, Rohan Bhasin, Mayar Arafa, Punarjay\n  Chakravarty, Shubham Shrivastava, Sagar Manglani, Vidya N. Murali", "title": "Deflating Dataset Bias Using Synthetic Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has seen an unprecedented increase in vision applications since\nthe publication of large-scale object recognition datasets and introduction of\nscalable compute hardware. State-of-the-art methods for most vision tasks for\nAutonomous Vehicles (AVs) rely on supervised learning and often fail to\ngeneralize to domain shifts and/or outliers. Dataset diversity is thus key to\nsuccessful real-world deployment. No matter how big the size of the dataset,\ncapturing long tails of the distribution pertaining to task-specific\nenvironmental factors is impractical. The goal of this paper is to investigate\nthe use of targeted synthetic data augmentation - combining the benefits of\ngaming engine simulations and sim2real style transfer techniques - for filling\ngaps in real datasets for vision tasks. Empirical studies on three different\ncomputer vision tasks of practical use to AVs - parking slot detection, lane\ndetection and monocular depth estimation - consistently show that having\nsynthetic data in the training mix provides a significant boost in\ncross-dataset generalization performance as compared to training on real data\nonly, for the same size of the training set.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 21:56:10 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Jaipuria", "Nikita", ""], ["Zhang", "Xianling", ""], ["Bhasin", "Rohan", ""], ["Arafa", "Mayar", ""], ["Chakravarty", "Punarjay", ""], ["Shrivastava", "Shubham", ""], ["Manglani", "Sagar", ""], ["Murali", "Vidya N.", ""]]}, {"id": "2004.13883", "submitter": "Moulay Akhloufi", "authors": "Moulay A. Akhloufi, Nicolas A. Castro, Andy Couturier", "title": "Unmanned Aerial Systems for Wildland and Forest Fires", "comments": "A recent published version of this paper is available at:\n  https://doi.org/10.3390/drones5010015", "journal-ref": "Drones. 2021; 5(1):15; pp 1-25", "doi": "10.3390/drones5010015", "report-no": null, "categories": "cs.RO cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wildfires represent an important natural risk causing economic losses, human\ndeath and important environmental damage. In recent years, we witness an\nincrease in fire intensity and frequency. Research has been conducted towards\nthe development of dedicated solutions for wildland and forest fire assistance\nand fighting. Systems were proposed for the remote detection and tracking of\nfires. These systems have shown improvements in the area of efficient data\ncollection and fire characterization within small scale environments. However,\nwildfires cover large areas making some of the proposed ground-based systems\nunsuitable for optimal coverage. To tackle this limitation, Unmanned Aerial\nSystems (UAS) were proposed. UAS have proven to be useful due to their\nmaneuverability, allowing for the implementation of remote sensing, allocation\nstrategies and task planning. They can provide a low-cost alternative for the\nprevention, detection and real-time support of firefighting. In this paper we\nreview previous work related to the use of UAS in wildfires. Onboard sensor\ninstruments, fire perception algorithms and coordination strategies are\nconsidered. In addition, we present some of the recent frameworks proposing the\nuse of both aerial vehicles and Unmanned Ground Vehicles (UV) for a more\nefficient wildland firefighting strategy at a larger scale.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 23:01:12 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 16:33:41 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Akhloufi", "Moulay A.", ""], ["Castro", "Nicolas A.", ""], ["Couturier", "Andy", ""]]}, {"id": "2004.13889", "submitter": "Tasnim Mohiuddin", "authors": "Tasnim Mohiuddin, M Saiful Bari, and Shafiq Joty", "title": "LNMap: Departures from Isomorphic Assumption in Bilingual Lexicon\n  Induction Through Non-Linear Mapping in Latent Space", "comments": "EMNLP 2020 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Most of the successful and predominant methods for bilingual lexicon\ninduction (BLI) are mapping-based, where a linear mapping function is learned\nwith the assumption that the word embedding spaces of different languages\nexhibit similar geometric structures (i.e., approximately isomorphic). However,\nseveral recent studies have criticized this simplified assumption showing that\nit does not hold in general even for closely related languages. In this work,\nwe propose a novel semi-supervised method to learn cross-lingual word\nembeddings for BLI. Our model is independent of the isomorphic assumption and\nuses nonlinear mapping in the latent space of two independently trained\nauto-encoders. Through extensive experiments on fifteen (15) different language\npairs (in both directions) comprising resource-rich and low-resource languages\nfrom two different datasets, we demonstrate that our method outperforms\nexisting models by a good margin. Ablation studies show the importance of\ndifferent model components and the necessity of non-linear mapping.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 23:28:26 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 00:42:16 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Mohiuddin", "Tasnim", ""], ["Bari", "M Saiful", ""], ["Joty", "Shafiq", ""]]}, {"id": "2004.13909", "submitter": "Xin-Long Luo", "authors": "Yiyan Yao and Xin-long Luo", "title": "Improving Vertical Positioning Accuracy with the Weighted Multinomial\n  Logistic Regression Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, a method of improving vertical positioning accuracy with the\nGlobal Positioning System (GPS) information and barometric pressure values is\nproposed. Firstly, we clear null values for the raw data collected in various\nenvironments, and use the 3$\\sigma$-rule to identify outliers. Secondly, the\nWeighted Multinomial Logistic Regression (WMLR) classifier is trained to obtain\nthe predicted altitude of outliers. Finally, in order to verify its effect, we\ncompare the MLR method, the WMLR method, and the Support Vector Machine (SVM)\nmethod for the cleaned dataset which is regarded as the test baseline. The\nnumerical results show that the vertical positioning accuracy is improved from\n5.9 meters (the MLR method), 5.4 meters (the SVM method) to 5 meters (the WMLR\nmethod) for 67% test points.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:13:51 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 11:18:27 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Yao", "Yiyan", ""], ["Luo", "Xin-long", ""]]}, {"id": "2004.13912", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Nicholas Frosst, Xuezhou Zhang, Rich Caruana and\n  Geoffrey E. Hinton", "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful black-box predictors that have\nachieved impressive performance on a wide variety of tasks. However, their\naccuracy comes at the cost of intelligibility: it is usually unclear how they\nmake their decisions. This hinders their applicability to high stakes\ndecision-making domains such as healthcare. We propose Neural Additive Models\n(NAMs) which combine some of the expressivity of DNNs with the inherent\nintelligibility of generalized additive models. NAMs learn a linear combination\nof neural networks that each attend to a single input feature. These networks\nare trained jointly and can learn arbitrarily complex relationships between\ntheir input feature and the output. Our experiments on regression and\nclassification datasets show that NAMs are more accurate than widely used\nintelligible models such as logistic regression and shallow decision trees.\nThey perform similarly to existing state-of-the-art generalized additive models\nin accuracy, but can be more easily applied to real-world problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:28:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Frosst", "Nicholas", ""], ["Zhang", "Xuezhou", ""], ["Caruana", "Rich", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "2004.13918", "submitter": "Jun-Ho Choi", "authors": "Jun-Ho Choi, Jong-Seok Lee", "title": "EmbraceNet for Activity: A Deep Multimodal Fusion Architecture for\n  Activity Recognition", "comments": "Accepted in HASCA at ACM UbiComp/ISWC 2019, won the 2nd place in the\n  SHL Recognition Challenge 2019", "journal-ref": null, "doi": "10.1145/3341162.3344871", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition using multiple sensors is a challenging but\npromising task in recent decades. In this paper, we propose a deep multimodal\nfusion model for activity recognition based on the recently proposed feature\nfusion architecture named EmbraceNet. Our model processes each sensor data\nindependently, combines the features with the EmbraceNet architecture, and\npost-processes the fused feature to predict the activity. In addition, we\npropose additional processes to boost the performance of our model. We submit\nthe results obtained from our proposed model to the SHL recognition challenge\nwith the team name \"Yonsei-MCML.\"\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:54:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Choi", "Jun-Ho", ""], ["Lee", "Jong-Seok", ""]]}, {"id": "2004.13930", "submitter": "Zhiyong Yang", "authors": "Zhiyong Yang, Qianqian Xu, Xiaochun Cao, Qingming Huang", "title": "Task-Feature Collaborative Learning with Application to Personalized\n  Attribute Prediction", "comments": "To appear in T-PAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an effective learning paradigm against insufficient training samples,\nMulti-Task Learning (MTL) encourages knowledge sharing across multiple related\ntasks so as to improve the overall performance. In MTL, a major challenge\nsprings from the phenomenon that sharing the knowledge with dissimilar and hard\ntasks, known as negative transfer, often results in a worsened performance.\nThough a substantial amount of studies have been carried out against the\nnegative transfer, most of the existing methods only model the transfer\nrelationship as task correlations, with the transfer across features and tasks\nleft unconsidered. Different from the existing methods, our goal is to\nalleviate negative transfer collaboratively across features and tasks. To this\nend, we propose a novel multi-task learning method called Task-Feature\nCollaborative Learning (TFCL). Specifically, we first propose a base model with\na heterogeneous block-diagonal structure regularizer to leverage the\ncollaborative grouping of features and tasks and suppressing inter-group\nknowledge sharing. We then propose an optimization method for the model.\nExtensive theoretical analysis shows that our proposed method has the following\nbenefits: (a) it enjoys the global convergence property and (b) it provides a\nblock-diagonal structure recovery guarantee. As a practical extension, we\nextend the base model by allowing overlapping features and differentiating the\nhard tasks. We further apply it to the personalized attribute prediction\nproblem with fine-grained modeling of user behaviors. Finally, experimental\nresults on both simulated dataset and real-world datasets demonstrate the\neffectiveness of our proposed method\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 02:32:04 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Yang", "Zhiyong", ""], ["Xu", "Qianqian", ""], ["Cao", "Xiaochun", ""], ["Huang", "Qingming", ""]]}, {"id": "2004.13937", "submitter": "Jihyung Moon", "authors": "Jihyung Moon, Hyunchang Cho, Eunjeong L. Park", "title": "Revisiting Round-Trip Translation for Quality Estimation", "comments": "To be published in EAMT 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Quality estimation (QE) is the task of automatically evaluating the quality\nof translations without human-translated references. Calculating BLEU between\nthe input sentence and round-trip translation (RTT) was once considered as a\nmetric for QE, however, it was found to be a poor predictor of translation\nquality. Recently, various pre-trained language models have made breakthroughs\nin NLP tasks by providing semantically meaningful word and sentence embeddings.\nIn this paper, we employ semantic embeddings to RTT-based QE. Our method\nachieves the highest correlations with human judgments, compared to previous\nWMT 2019 quality estimation metric task submissions. While backward translation\nmodels can be a drawback when using RTT, we observe that with semantic-level\nmetrics, RTT-based QE is robust to the choice of the backward translation\nsystem. Additionally, the proposed method shows consistent performance for both\nSMT and NMT forward translation systems, implying the method does not penalize\na certain type of model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 03:20:22 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Moon", "Jihyung", ""], ["Cho", "Hyunchang", ""], ["Park", "Eunjeong L.", ""]]}, {"id": "2004.13940", "submitter": "Parameswaran Raman", "authors": "Parameswaran Raman, S.V.N. Vishwanathan", "title": "DS-FACTO: Doubly Separable Factorization Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorization Machines (FM) are powerful class of models that incorporate\nhigher-order interaction among features to add more expressive power to linear\nmodels. They have been used successfully in several real-world tasks such as\nclick-prediction, ranking and recommender systems. Despite using a low-rank\nrepresentation for the pairwise features, the memory overheads of using\nfactorization machines on large-scale real-world datasets can be prohibitively\nhigh. For instance on the criteo tera dataset, assuming a modest $128$\ndimensional latent representation and $10^{9}$ features, the memory requirement\nfor the model is in the order of $1$ TB. In addition, the data itself occupies\n$2.1$ TB. Traditional algorithms for FM which work on a single-machine are not\nequipped to handle this scale and therefore, using a distributed algorithm to\nparallelize the computation across a cluster is inevitable. In this work, we\npropose a hybrid-parallel stochastic optimization algorithm DS-FACTO, which\npartitions both the data as well as parameters of the factorization machine\nsimultaneously. Our solution is fully de-centralized and does not require the\nuse of any parameter servers. We present empirical results to analyze the\nconvergence behavior, predictive power and scalability of DS-FACTO.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 03:36:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Raman", "Parameswaran", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "2004.13954", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Haoyi Xiong, Dongrui Wu", "title": "Rethink the Connections among Generalization, Memorization and the\n  Spectral Bias of DNNs", "comments": "IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks (DNNs) with sufficient capacity to\nmemorize random noise can achieve excellent generalization performance,\nchallenging the bias-variance trade-off in classical learning theory. Recent\nstudies claimed that DNNs first learn simple patterns and then memorize noise;\nsome other works showed a phenomenon that DNNs have a spectral bias to learn\ntarget functions from low to high frequencies during training. However, we show\nthat the monotonicity of the learning bias does not always hold: under the\nexperimental setup of deep double descent, the high-frequency components of\nDNNs diminish in the late stage of training, leading to the second descent of\nthe test error. Besides, we find that the spectrum of DNNs can be applied to\nindicating the second descent of the test error, even though it is calculated\nfrom the training set only.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 04:24:25 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 11:18:34 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Zhang", "Xiao", ""], ["Xiong", "Haoyi", ""], ["Wu", "Dongrui", ""]]}, {"id": "2004.13965", "submitter": "Megha Khosla", "authors": "Vikram Waradpande, Daniel Kudenko, Megha Khosla", "title": "Graph-based State Representation for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep RL approaches build much of their success on the ability of the deep\nneural network to generate useful internal representations. Nevertheless, they\nsuffer from a high sample-complexity and starting with a good input\nrepresentation can have a significant impact on the performance. In this paper,\nwe exploit the fact that the underlying Markov decision process (MDP)\nrepresents a graph, which enables us to incorporate the topological information\nfor effective state representation learning.\n  Motivated by the recent success of node representations for several graph\nanalytical tasks we specifically investigate the capability of node\nrepresentation learning methods to effectively encode the topology of the\nunderlying MDP in Deep RL. To this end we perform a comparative analysis of\nseveral models chosen from 4 different classes of representation learning\nalgorithms for policy learning in grid-world navigation tasks, which are\nrepresentative of a large class of RL problems. We find that all embedding\nmethods outperform the commonly used matrix representation of grid-world\nenvironments in all of the studied cases. Moreoever, graph convolution based\nmethods are outperformed by simpler random walk based methods and graph linear\nautoencoders.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 05:43:15 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 15:31:22 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:49:34 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Waradpande", "Vikram", ""], ["Kudenko", "Daniel", ""], ["Khosla", "Megha", ""]]}, {"id": "2004.13970", "submitter": "Zekun Tong", "authors": "Zekun Tong, Yuxuan Liang, Changsheng Sun, David S. Rosenblum and\n  Andrew Lim", "title": "Directed Graph Convolutional Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have been widely used due to their\noutstanding performance in processing graph-structured data. However, the\nundirected graphs limit their application scope. In this paper, we extend\nspectral-based graph convolution to directed graphs by using first- and\nsecond-order proximity, which can not only retain the connection properties of\nthe directed graph, but also expand the receptive field of the convolution\noperation. A new GCN model, called DGCN, is then designed to learn\nrepresentations on the directed graph, leveraging both the first- and\nsecond-order proximity information. We empirically show the fact that GCNs\nworking only with DGCNs can encode more useful information from graph and help\nachieve better performance when generalized to other models. Moreover,\nextensive experiments on citation networks and co-purchase datasets demonstrate\nthe superiority of our model against the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:19:10 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Tong", "Zekun", ""], ["Liang", "Yuxuan", ""], ["Sun", "Changsheng", ""], ["Rosenblum", "David S.", ""], ["Lim", "Andrew", ""]]}, {"id": "2004.13971", "submitter": "Youssef Hammadi", "authors": "Youssef Hammadi (MAT), David Ryckelynck (LMSP), Amin El-Bakkali", "title": "Reduced Bond Graph via machine learning for nonlinear multiphysics\n  dynamic systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA cs.NE math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a machine learning approach aiming at reducing Bond Graphs. The\noutput of the machine learning is a hybrid modeling that contains a reduced\nBond Graph coupled to a simple artificial neural network. The proposed coupling\nenables knowledge continuity in machine learning. In this paper, a neural\nnetwork is obtained by a linear calibration procedure. We propose a method that\ncontains two training steps. First, the method selects the components of the\noriginal Bond Graph that are kept in the Reduced Bond Graph. Secondly, the\nmethod builds an artificial neural network that supplements the reduced Bond\nGraph. Because the output of the machine learning is a hybrid model, not solely\ndata, it becomes difficult to use a usual Backpropagation Through Time to\ncalibrate the weights of the neural network. So, in a first attempt, a very\nsimple neural network is proposed by following a model reduction approach. We\nconsider the modeling of the automotive cabins thermal behavior. The data used\nfor the training step are obtained via solutions of differential algebraic\nequations by using a design of experiment. Simple cooling simulations are run\nduring the training step. We show a simulation speed-up when the reduced bond\ngraph is used to simulate the driving cycle of the WLTP vehicles homologation\nprocedure, while preserving accuracy on output variables. The variables of the\noriginal Bond Graph are split into a set of primary variables, a set of\nsecondary variables and a set of tertiary variables. The reduced bond graph\ncontains all the primary variables, but none of the tertiary variables.\nSecondary variables are coupled to primary ones via an artificial neural\nnetwork. We discuss the extension of this coupling approach to more complex\nartificial neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:19:14 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Hammadi", "Youssef", "", "MAT"], ["Ryckelynck", "David", "", "LMSP"], ["El-Bakkali", "Amin", ""]]}, {"id": "2004.13972", "submitter": "Avishek Anand", "authors": "Jaspreet Singh, Zhenye Wang, Megha Khosla, and Avishek Anand", "title": "Valid Explanations for Learning to Rank Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-rank (LTR) is a class of supervised learning techniques that\napply to ranking problems dealing with a large number of features.\n  The popularity and widespread application of LTR models in prioritizing\ninformation in a variety of domains makes their scrutability vital in today's\nlandscape of fair and transparent learning systems. However, limited work\nexists that deals with interpreting the decisions of learning systems that\noutput rankings. In this paper we propose a model agnostic local explanation\nmethod that seeks to identify a small subset of input features as explanation\nto a ranking decision. We introduce new notions of validity and completeness of\nexplanations specifically for rankings, based on the presence or absence of\nselected features, as a way of measuring goodness. We devise a novel\noptimization problem to maximize validity directly and propose greedy\nalgorithms as solutions. In extensive quantitative experiments we show that our\napproach outperforms other model agnostic explanation approaches across\npointwise, pairwise and listwise LTR models in validity while not compromising\non completeness.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:21:56 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 13:31:40 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 15:46:57 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Singh", "Jaspreet", ""], ["Wang", "Zhenye", ""], ["Khosla", "Megha", ""], ["Anand", "Avishek", ""]]}, {"id": "2004.13977", "submitter": "Xinbo Yu", "authors": "Bruce X. B. Yu, Yan Liu, Keith C. C. Chan", "title": "Effective Human Activity Recognition Based on Small Datasets", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent work on vision-based human activity recognition (HAR) focuses on\ndesigning complex deep learning models for the task. In so doing, there is a\nrequirement for large datasets to be collected. As acquiring and processing\nlarge training datasets are usually very expensive, the problem of how dataset\nsize can be reduced without affecting recognition accuracy has to be tackled.\nTo do so, we propose a HAR method that consists of three steps: (i) data\ntransformation involving the generation of new features based on transforming\nof raw data, (ii) feature extraction involving the learning of a classifier\nbased on the AdaBoost algorithm and the use of training data consisting of the\ntransformed features, and (iii) parameter determination and pattern recognition\ninvolving the determination of parameters based on the features generated in\n(ii) and the use of the parameters as training data for deep learning\nalgorithms to be used to recognize human activities. Compared to existing\napproaches, this proposed approach has the advantageous characteristics that it\nis simple and robust. The proposed approach has been tested with a number of\nexperiments performed on a relatively small real dataset. The experimental\nresults indicate that using the proposed method, human activities can be more\naccurately recognized even with smaller training data size.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:38:23 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Yu", "Bruce X. B.", ""], ["Liu", "Yan", ""], ["Chan", "Keith C. C.", ""]]}, {"id": "2004.13979", "submitter": "Xinbo Yu", "authors": "Bruce X. B. Yu, Yan Liu, Keith C. C. Chan", "title": "Skeleton Focused Human Activity Recognition in RGB Video", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven approach that learns an optimal representation of vision\nfeatures like skeleton frames or RGB videos is currently a dominant paradigm\nfor activity recognition. While great improvements have been achieved from\nexisting single modal approaches with increasingly larger datasets, the fusion\nof various data modalities at the feature level has seldom been attempted. In\nthis paper, we propose a multimodal feature fusion model that utilizes both\nskeleton and RGB modalities to infer human activity. The objective is to\nimprove the activity recognition accuracy by effectively utilizing the mutual\ncomplemental information among different data modalities. For the skeleton\nmodality, we propose to use a graph convolutional subnetwork to learn the\nskeleton representation. Whereas for the RGB modality, we will use the\nspatial-temporal region of interest from RGB videos and take the attention\nfeatures from the skeleton modality to guide the learning process. The model\ncould be either individually or uniformly trained by the back-propagation\nalgorithm in an end-to-end manner. The experimental results for the NTU-RGB+D\nand Northwestern-UCLA Multiview datasets achieved state-of-the-art performance,\nwhich indicates that the proposed skeleton-driven attention mechanism for the\nRGB modality increases the mutual communication between different data\nmodalities and brings more discriminative features for inferring human\nactivities.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 06:40:42 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Yu", "Bruce X. B.", ""], ["Liu", "Yan", ""], ["Chan", "Keith C. C.", ""]]}, {"id": "2004.14016", "submitter": "Daisuke Kaji", "authors": "Daisuke Kaji, Kazuho Watanabe, Masahiro Kobayashi", "title": "Multi-Decoder RNN Autoencoder Based on Variational Bayes Method", "comments": "8 pages, 11 figures, accepted for publication in IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms have wide applications and play an important role in\ndata analysis fields including time series data analysis. However, in time\nseries analysis, most of the algorithms used signal shape features or the\ninitial value of hidden variable of a neural network. Little has been discussed\non the methods based on the generative model of the time series. In this paper,\nwe propose a new clustering algorithm focusing on the generative process of the\nsignal with a recurrent neural network and the variational Bayes method. Our\nexperiments show that the proposed algorithm not only has a robustness against\nfor phase shift, amplitude and signal length variations but also provide a\nflexible clustering based on the property of the variational Bayes method.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:25:07 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kaji", "Daisuke", ""], ["Watanabe", "Kazuho", ""], ["Kobayashi", "Masahiro", ""]]}, {"id": "2004.14020", "submitter": "Sangeetha Abdu Jyothi", "authors": "Sayed Hadi Hashemi, Sangeetha Abdu Jyothi, Brighten Godfrey, Roy\n  Campbell", "title": "Caramel: Accelerating Decentralized Distributed Deep Learning with\n  Computation Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of choice for parameter aggregation in Deep Neural Network (DNN)\ntraining, a network-intensive task, is shifting from the Parameter Server model\nto decentralized aggregation schemes (AllReduce) inspired by theoretical\nguarantees of better performance. However, current implementations of AllReduce\noverlook the interdependence of communication and computation, resulting in\nsignificant performance degradation. In this paper, we develop Caramel, a\nsystem that accelerates decentralized distributed deep learning through\nmodel-aware computation scheduling and communication optimizations for\nAllReduce. Caramel achieves this goal through (a) computation DAG scheduling\nthat expands the feasible window of transfer for each parameter (transfer\nboundaries), and (b) network optimizations for smoothening of the load\nincluding adaptive batching and pipelining of parameter transfers. Caramel\nmaintains the correctness of the dataflow model, is hardware-independent, and\ndoes not require any user-level or framework-level changes. We implement\nCaramel over TensorFlow and show that the iteration time of DNN training can be\nimproved by up to 3.62x in a cloud environment.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:32:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Hashemi", "Sayed Hadi", ""], ["Jyothi", "Sangeetha Abdu", ""], ["Godfrey", "Brighten", ""], ["Campbell", "Roy", ""]]}, {"id": "2004.14026", "submitter": "Jens Schreiber", "authors": "Stephan Deist, Jens Schreiber, Maarten Bieshaar and Bernhard Sick", "title": "Extended Coopetitive Soft Gating Ensemble", "comments": "14 pages; 15 figures; 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is about an extension of a recent ensemble method called\nCoopetitive Soft Gating Ensemble (CSGE) and its application on power\nforecasting as well as motion primitive forecasting of cyclists. The CSGE has\nbeen used successfully in the field of wind power forecasting, outperforming\ncommon algorithms in this domain. The principal idea of the CSGE is to weight\nthe models regarding their observed performance during training on different\naspects. Several extensions are proposed to the original CSGE within this\narticle, making the ensemble even more flexible and powerful. The extended CSGE\n(XCSGE as we term it), is used to predict the power generation on both wind-\nand solar farms. Moreover, the XCSGE is applied to forecast the movement state\nof cyclists in the context of driver assistance systems. Both domains have\ndifferent requirements, are non-trivial problems, and are used to evaluate\nvarious facets of the novel XCSGE. The two problems differ fundamentally in the\nsize of the data sets and the number of features. Power forecasting is based on\nweather forecasts that are subject to fluctuations in their features. In the\nmovement primitive forecasting of cyclists, time delays contribute to the\ndifficulty of the prediction. The XCSGE reaches an improvement of the\nprediction performance of up to 11% for wind power forecasting and 30% for\nsolar power forecasting compared to the worst performing model. For the\nclassification of movement primitives of cyclists, the XCSGE reaches an\nimprovement of up to 28%. The evaluation includes a comparison with other\nstate-of-the-art ensemble methods. We can verify that the XCSGE results are\nsignificantly better using the Nemenyi post-hoc test.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:48:37 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Deist", "Stephan", ""], ["Schreiber", "Jens", ""], ["Bieshaar", "Maarten", ""], ["Sick", "Bernhard", ""]]}, {"id": "2004.14031", "submitter": "Md Ashad Alam PhD", "authors": "Md Ashad Alam, Chuan Qiu, Hui Shen, Yu-Ping Wang, and Hong-Wen Deng", "title": "A generalized kernel machine approach to identify higher-order composite\n  effects in multi-view datasets", "comments": "19 pages, 9 figures, and Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a comprehensive study of multi-view datasets (e.g.,\nmulti-omics and imaging scans) has been a focus and forefront in biomedical\nresearch. State-of-the-art biomedical technologies are enabling us to collect\nmulti-view biomedical datasets for the study of complex diseases. While all the\nviews of data tend to explore complementary information of a disease,\nmulti-view data analysis with complex interactions is challenging for a deeper\nand holistic understanding of biological systems. In this paper, we propose a\nnovel generalized kernel machine approach to identify higher-order composite\neffects in multi-view biomedical datasets. This generalized semi-parametric (a\nmixed-effect linear model) approach includes the marginal and joint Hadamard\nproduct of features from different views of data. The proposed kernel machine\napproach considers multi-view data as predictor variables to allow more\nthorough and comprehensive modeling of a complex trait. The proposed method can\nbe applied to the study of any disease model, where multi-view datasets are\navailable. We applied our approach to both synthesized datasets and real\nmulti-view datasets from adolescence brain development and osteoporosis study,\nincluding an imaging scan dataset and five omics datasets. Our experiments\ndemonstrate that the proposed method can effectively identify higher-order\ncomposite effects and suggest that corresponding features (genes, region of\ninterests, and chemical taxonomies) function in a concerted effort. We show\nthat the proposed method is more generalizable than existing ones.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:56:02 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Alam", "Md Ashad", ""], ["Qiu", "Chuan", ""], ["Shen", "Hui", ""], ["Wang", "Yu-Ping", ""], ["Deng", "Hong-Wen", ""]]}, {"id": "2004.14034", "submitter": "Jens Schreiber", "authors": "Jens Schreiber, Bernhard Sick", "title": "Emerging Relation Network and Task Embedding for Multi-Task Regression\n  Problems", "comments": "8 pages;2 tables;5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning (mtl) provides state-of-the-art results in many\napplications of computer vision and natural language processing. In contrast to\nsingle-task learning (stl), mtl allows for leveraging knowledge between related\ntasks improving prediction results on the main task (in contrast to an\nauxiliary task) or all tasks. However, there is a limited number of comparative\nstudies on applying mtl architectures for regression and time series problems\ntaking recent advances of mtl into account. An interesting, non-linear problem\nis the forecast of the expected power generation for renewable power plants.\nTherefore, this article provides a comparative study of the following recent\nand important mtl architectures: Hard parameter sharing, cross-stitch network,\nsluice network (sn). They are compared to a multi-layer perceptron model of\nsimilar size in an stl setting. Additionally, we provide a simple, yet\neffective approach to model task specific information through an embedding\nlayer in an multi-layer perceptron, referred to as task embedding. Further, we\nintroduce a new mtl architecture named emerging relation network (ern), which\ncan be considered as an extension of the sluice network. For a solar power\ndataset, the task embedding achieves the best mean improvement with 14.9%. The\nmean improvement of the ern and the sn on the solar dataset is of similar\nmagnitude with 14.7% and 14.8%. On a wind power dataset, only the ern achieves\na significant improvement of up to 7.7%. Results suggest that the ern is\nbeneficial when tasks are only loosely related and the prediction problem is\nmore non-linear. Contrary, the proposed task embedding is advantageous when\ntasks are strongly correlated. Further, the task embedding provides an\neffective approach with reduced computational effort compared to other mtl\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:02:24 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Schreiber", "Jens", ""], ["Sick", "Bernhard", ""]]}, {"id": "2004.14036", "submitter": "Sebastian Feld", "authors": "Thomas Gabor, Sebastian Feld, Hila Safi, Thomy Phan, Claudia\n  Linnhoff-Popien (LMU Munich)", "title": "Insights on Training Neural Networks for QUBO Tasks", "comments": "6 pages, 5 figures, accepted at the 1st International Workshop on\n  Quantum Software Engineering (Q-SE 2020) at ICSE 2020 and to be published in\n  the corresponding proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current hardware limitations restrict the potential when solving quadratic\nunconstrained binary optimization (QUBO) problems via the quantum approximate\noptimization algorithm (QAOA) or quantum annealing (QA). Thus, we consider\ntraining neural networks in this context. We first discuss QUBO problems that\noriginate from translated instances of the traveling salesman problem (TSP):\nAnalyzing this representation via autoencoders shows that there is way more\ninformation included than necessary to solve the original TSP. Then we show\nthat neural networks can be used to solve TSP instances from both QUBO input\nand autoencoders' hiddenstate representation. We finally generalize the\napproach and successfully train neural networks to solve arbitrary QUBO\nproblems, sketching means to use neuromorphic hardware as a simulator or an\nadditional co-processor for quantum computing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:09:17 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Gabor", "Thomas", "", "LMU Munich"], ["Feld", "Sebastian", "", "LMU Munich"], ["Safi", "Hila", "", "LMU Munich"], ["Phan", "Thomy", "", "LMU Munich"], ["Linnhoff-Popien", "Claudia", "", "LMU Munich"]]}, {"id": "2004.14046", "submitter": "Wojciech Masarczyk", "authors": "Wojciech Masarczyk and Ivona Tautkute", "title": "Reducing catastrophic forgetting with learning on synthetic data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a problem caused by neural networks' inability to\nlearn data in sequence. After learning two tasks in sequence, performance on\nthe first one drops significantly. This is a serious disadvantage that prevents\nmany deep learning applications to real-life problems where not all object\nclasses are known beforehand; or change in data requires adjustments to the\nmodel. To reduce this problem we investigate the use of synthetic data, namely\nwe answer a question: Is it possible to generate such data synthetically which\nlearned in sequence does not result in catastrophic forgetting? We propose a\nmethod to generate such data in two-step optimisation process via\nmeta-gradients. Our experimental results on Split-MNIST dataset show that\ntraining a model on such synthetic data in sequence does not result in\ncatastrophic forgetting. We also show that our method of generating data is\nrobust to different learning scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:45:06 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Masarczyk", "Wojciech", ""], ["Tautkute", "Ivona", ""]]}, {"id": "2004.14070", "submitter": "Siddharth Swaroop", "authors": "Pingbo Pan, Siddharth Swaroop, Alexander Immer, Runa Eschenhagen,\n  Richard E. Turner, Mohammad Emtiyaz Khan", "title": "Continual Deep Learning by Functional Regularisation of Memorable Past", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continually learning new skills is important for intelligent systems, yet\nstandard deep learning methods suffer from catastrophic forgetting of the past.\nRecent works address this with weight regularisation. Functional\nregularisation, although computationally expensive, is expected to perform\nbetter, but rarely does so in practice. In this paper, we fix this issue by\nusing a new functional-regularisation approach that utilises a few memorable\npast examples crucial to avoid forgetting. By using a Gaussian Process\nformulation of deep networks, our approach enables training in weight-space\nwhile identifying both the memorable past and a functional prior. Our method\nachieves state-of-the-art performance on standard benchmarks and opens a new\ndirection for life-long learning where regularisation and memory-based methods\nare naturally combined.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:47:54 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 15:30:05 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 16:47:20 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 09:48:17 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Pan", "Pingbo", ""], ["Swaroop", "Siddharth", ""], ["Immer", "Alexander", ""], ["Eschenhagen", "Runa", ""], ["Turner", "Richard E.", ""], ["Khan", "Mohammad Emtiyaz", ""]]}, {"id": "2004.14071", "submitter": "Noa Fish", "authors": "Noa Fish, Richard Zhang, Lilach Perry, Daniel Cohen-Or, Eli Shechtman,\n  Connelly Barnes", "title": "Image Morphing with Perceptual Constraints and STN Alignment", "comments": null, "journal-ref": null, "doi": "10.1111/cgf.14027", "report-no": null, "categories": "cs.GR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In image morphing, a sequence of plausible frames are synthesized and\ncomposited together to form a smooth transformation between given instances.\nIntermediates must remain faithful to the input, stand on their own as members\nof the set, and maintain a well-paced visual transition from one to the next.\nIn this paper, we propose a conditional GAN morphing framework operating on a\npair of input images. The network is trained to synthesize frames corresponding\nto temporal samples along the transformation, and learns a proper shape prior\nthat enhances the plausibility of intermediate frames. While individual frame\nplausibility is boosted by the adversarial setup, a special training protocol\nproducing sequences of frames, combined with a perceptual similarity loss,\npromote smooth transformation over time. Explicit stating of correspondences is\nreplaced with a grid-based freeform deformation spatial transformer that\npredicts the geometric warp between the inputs, instituting the smooth\ngeometric effect by bringing the shapes into an initial alignment. We provide\ncomparisons to classic as well as latent space morphing techniques, and\ndemonstrate that, given a set of images for self-supervision, our network\nlearns to generate visually pleasing morphing effects featuring believable\nin-betweens, with robustness to changes in shape and texture, requiring no\ncorrespondence annotation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:49:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Fish", "Noa", ""], ["Zhang", "Richard", ""], ["Perry", "Lilach", ""], ["Cohen-Or", "Daniel", ""], ["Shechtman", "Eli", ""], ["Barnes", "Connelly", ""]]}, {"id": "2004.14074", "submitter": "Nicola Pellicano", "authors": "Alexandre Tamborrino, Nicola Pellicano, Baptiste Pannier, Pascal\n  Voitot and Louise Naudin", "title": "Pre-training Is (Almost) All You Need: An Application to Commonsense\n  Reasoning", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning of pre-trained transformer models has become the standard\napproach for solving common NLP tasks. Most of the existing approaches rely on\na randomly initialized classifier on top of such networks. We argue that this\nfine-tuning procedure is sub-optimal as the pre-trained model has no prior on\nthe specific classifier labels, while it might have already learned an\nintrinsic textual representation of the task. In this paper, we introduce a new\nscoring method that casts a plausibility ranking task in a full-text format and\nleverages the masked language modeling head tuned during the pre-training\nphase. We study commonsense reasoning tasks where the model must rank a set of\nhypotheses given a premise, focusing on the COPA, Swag, HellaSwag and\nCommonsenseQA datasets. By exploiting our scoring method without fine-tuning,\nwe are able to produce strong baselines (e.g. 80% test accuracy on COPA) that\nare comparable to supervised approaches. Moreover, when fine-tuning directly on\nthe proposed scoring function, we show that our method provides a much more\nstable training phase across random restarts (e.g $\\times 10$ standard\ndeviation reduction on COPA test accuracy) and requires less annotated data\nthan the standard classifier approach to reach equivalent performances.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 10:54:40 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Tamborrino", "Alexandre", ""], ["Pellicano", "Nicola", ""], ["Pannier", "Baptiste", ""], ["Voitot", "Pascal", ""], ["Naudin", "Louise", ""]]}, {"id": "2004.14088", "submitter": "Guanhua Zhang", "authors": "Guanhua Zhang, Bing Bai, Junqi Zhang, Kun Bai, Conghui Zhu and Tiejun\n  Zhao", "title": "Demographics Should Not Be the Reason of Toxicity: Mitigating\n  Discrimination in Text Classifications with Instance Weighting", "comments": "Accepted by ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent proliferation of the use of text classifications, researchers\nhave found that there are certain unintended biases in text classification\ndatasets. For example, texts containing some demographic identity-terms (e.g.,\n\"gay\", \"black\") are more likely to be abusive in existing abusive language\ndetection datasets. As a result, models trained with these datasets may\nconsider sentences like \"She makes me happy to be gay\" as abusive simply\nbecause of the word \"gay.\" In this paper, we formalize the unintended biases in\ntext classification datasets as a kind of selection bias from the\nnon-discrimination distribution to the discrimination distribution. Based on\nthis formalization, we further propose a model-agnostic debiasing training\nframework by recovering the non-discrimination distribution using instance\nweighting, which does not require any extra resources or annotations apart from\na pre-defined set of demographic identity-terms. Experiments demonstrate that\nour method can effectively alleviate the impacts of the unintended biases\nwithout significantly hurting models' generalization ability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:22:19 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 07:44:34 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 14:22:11 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Zhang", "Guanhua", ""], ["Bai", "Bing", ""], ["Zhang", "Junqi", ""], ["Bai", "Kun", ""], ["Zhu", "Conghui", ""], ["Zhao", "Tiejun", ""]]}, {"id": "2004.14096", "submitter": "Artur Kulmizev", "authors": "Artur Kulmizev, Vinit Ravishankar, Mostafa Abdou, Joakim Nivre", "title": "Do Neural Language Models Show Preferences for Syntactic Formalisms?", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on the interpretability of deep neural language models has\nconcluded that many properties of natural language syntax are encoded in their\nrepresentational spaces. However, such studies often suffer from limited scope\nby focusing on a single language and a single linguistic formalism. In this\nstudy, we aim to investigate the extent to which the semblance of syntactic\nstructure captured by language models adheres to a surface-syntactic or deep\nsyntactic style of analysis, and whether the patterns are consistent across\ndifferent languages. We apply a probe for extracting directed dependency trees\nto BERT and ELMo models trained on 13 different languages, probing for two\ndifferent syntactic annotation styles: Universal Dependencies (UD),\nprioritizing deep syntactic relations, and Surface-Syntactic Universal\nDependencies (SUD), focusing on surface structure. We find that both models\nexhibit a preference for UD over SUD - with interesting variations across\nlanguages and layers - and that the strength of this preference is correlated\nwith differences in tree shape.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:37:53 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Kulmizev", "Artur", ""], ["Ravishankar", "Vinit", ""], ["Abdou", "Mostafa", ""], ["Nivre", "Joakim", ""]]}, {"id": "2004.14107", "submitter": "He Wang", "authors": "Feixiang He, Yuanhang Xiang, Xi Zhao, He Wang", "title": "Informative Scene Decomposition for Crowd Analysis, Comparison and\n  Simulation Guidance", "comments": "accepted in SIGGRAPH 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd simulation is a central topic in several fields including graphics. To\nachieve high-fidelity simulations, data has been increasingly relied upon for\nanalysis and simulation guidance. However, the information in real-world data\nis often noisy, mixed and unstructured, making it difficult for effective\nanalysis, therefore has not been fully utilized. With the fast-growing volume\nof crowd data, such a bottleneck needs to be addressed. In this paper, we\npropose a new framework which comprehensively tackles this problem. It centers\nat an unsupervised method for analysis. The method takes as input raw and noisy\ndata with highly mixed multi-dimensional (space, time and dynamics)\ninformation, and automatically structure it by learning the correlations among\nthese dimensions. The dimensions together with their correlations fully\ndescribe the scene semantics which consists of recurring activity patterns in a\nscene, manifested as space flows with temporal and dynamics profiles. The\neffectiveness and robustness of the analysis have been tested on datasets with\ngreat variations in volume, duration, environment and crowd dynamics. Based on\nthe analysis, new methods for data visualization, simulation evaluation and\nsimulation guidance are also proposed. Together, our framework establishes a\nhighly automated pipeline from raw data to crowd analysis, comparison and\nsimulation guidance. Extensive experiments and evaluations have been conducted\nto show the flexibility, versatility and intuitiveness of our framework.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:03:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["He", "Feixiang", ""], ["Xiang", "Yuanhang", ""], ["Zhao", "Xi", ""], ["Wang", "He", ""]]}, {"id": "2004.14119", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Manaj Srivastava, Sanjay Krishna, David Akodes, Richard\n  Schwartz", "title": "Combining Word Embeddings and N-grams for Unsupervised Document\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based extractive document summarization relies on the quality of the\nsentence similarity graph. Bag-of-words or tf-idf based sentence similarity\nuses exact word matching, but fails to measure the semantic similarity between\nindividual words or to consider the semantic structure of sentences. In order\nto improve the similarity measure between sentences, we employ off-the-shelf\ndeep embedding features and tf-idf features, and introduce a new text\nsimilarity metric. An improved sentence similarity graph is built and used in a\nsubmodular objective function for extractive summarization, which consists of a\nweighted coverage term and a diversity term. A Transformer based compression\nmodel is developed for sentence compression to aid in document summarization.\nOur summarization approach is extractive and unsupervised. Experiments\ndemonstrate that our approach can outperform the tf-idf based approach and\nachieve state-of-the-art performance on the DUC04 dataset, and comparable\nperformance to the fully supervised learning methods on the CNN/DM and NYT\ndatasets.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 00:22:46 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Jiang", "Zhuolin", ""], ["Srivastava", "Manaj", ""], ["Krishna", "Sanjay", ""], ["Akodes", "David", ""], ["Schwartz", "Richard", ""]]}, {"id": "2004.14120", "submitter": "Ant\\'onio G\\'ois", "authors": "Ant\\'onio G\\'ois, Kyunghyun Cho, Andr\\'e Martins", "title": "Learning Non-Monotonic Automatic Post-Editing of Translations from Human\n  Orderings", "comments": "Accepted at EAMT 2020; dataset available here:\n  https://github.com/antoniogois/keystrokes_ape", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in neural machine translation has explored flexible\ngeneration orders, as an alternative to left-to-right generation. However,\ntraining non-monotonic models brings a new complication: how to search for a\ngood ordering when there is a combinatorial explosion of orderings arriving at\nthe same final result? Also, how do these automatic orderings compare with the\nactual behaviour of human translators? Current models rely on manually built\nbiases or are left to explore all possibilities on their own. In this paper, we\nanalyze the orderings produced by human post-editors and use them to train an\nautomatic post-editing system. We compare the resulting system with those\ntrained with left-to-right and random post-editing orderings. We observe that\nhumans tend to follow a nearly left-to-right order, but with interesting\ndeviations, such as preferring to start by correcting punctuation or verbs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:19:50 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["G\u00f3is", "Ant\u00f3nio", ""], ["Cho", "Kyunghyun", ""], ["Martins", "Andr\u00e9", ""]]}, {"id": "2004.14129", "submitter": "Xin Wang", "authors": "Evani Radiya-Dixit and Xin Wang", "title": "How fine can fine-tuning be? Learning efficient language models", "comments": "11 pages, 11 figures and 6 tables; accepted to the 23rd International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art performance on language understanding tasks is now achieved\nwith increasingly large networks; the current record holder has billions of\nparameters. Given a language model pre-trained on massive unlabeled text\ncorpora, only very light supervised fine-tuning is needed to learn a task: the\nnumber of fine-tuning steps is typically five orders of magnitude lower than\nthe total parameter count. Does this mean that fine-tuning only introduces\nsmall differences from the pre-trained model in the parameter space? If so, can\none avoid storing and computing an entire model for each task? In this work, we\naddress these questions by using Bidirectional Encoder Representations from\nTransformers (BERT) as an example. As expected, we find that the fine-tuned\nmodels are close in parameter space to the pre-trained one, with the closeness\nvarying from layer to layer. We show that it suffices to fine-tune only the\nmost critical layers. Further, we find that there are surprisingly many good\nsolutions in the set of sparsified versions of the pre-trained model. As a\nresult, fine-tuning of huge language models can be achieved by simply setting a\ncertain number of entries in certain layers of the pre-trained parameters to\nzero, saving both task-specific parameter storage and computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:31:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Radiya-Dixit", "Evani", ""], ["Wang", "Xin", ""]]}, {"id": "2004.14133", "submitter": "Huazhu Fu", "authors": "Deng-Ping Fan, Tao Zhou, Ge-Peng Ji, Yi Zhou, Geng Chen, Huazhu Fu,\n  Jianbing Shen, Ling Shao", "title": "Inf-Net: Automatic COVID-19 Lung Infection Segmentation from CT Images", "comments": "To appear in IEEE TMI. The code is released in:\n  https://github.com/DengPingFan/Inf-Net", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus Disease 2019 (COVID-19) spread globally in early 2020, causing\nthe world to face an existential health crisis. Automated detection of lung\ninfections from computed tomography (CT) images offers a great potential to\naugment the traditional healthcare strategy for tackling COVID-19. However,\nsegmenting infected regions from CT slices faces several challenges, including\nhigh variation in infection characteristics, and low intensity contrast between\ninfections and normal tissues. Further, collecting a large amount of data is\nimpractical within a short time period, inhibiting the training of a deep\nmodel. To address these challenges, a novel COVID-19 Lung Infection\nSegmentation Deep Network (Inf-Net) is proposed to automatically identify\ninfected regions from chest CT slices. In our Inf-Net, a parallel partial\ndecoder is used to aggregate the high-level features and generate a global map.\nThen, the implicit reverse attention and explicit edge-attention are utilized\nto model the boundaries and enhance the representations. Moreover, to alleviate\nthe shortage of labeled data, we present a semi-supervised segmentation\nframework based on a randomly selected propagation strategy, which only\nrequires a few labeled images and leverages primarily unlabeled data. Our\nsemi-supervised framework can improve the learning ability and achieve a higher\nperformance. Extensive experiments on our COVID-SemiSeg and real CT volumes\ndemonstrate that the proposed Inf-Net outperforms most cutting-edge\nsegmentation models and advances the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 07:30:56 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 13:01:30 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 19:40:13 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 18:23:37 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Fan", "Deng-Ping", ""], ["Zhou", "Tao", ""], ["Ji", "Ge-Peng", ""], ["Zhou", "Yi", ""], ["Chen", "Geng", ""], ["Fu", "Huazhu", ""], ["Shen", "Jianbing", ""], ["Shao", "Ling", ""]]}, {"id": "2004.14135", "submitter": "Khalid Elmadani", "authors": "Khalid N. Elmadani, Mukhtar Elgezouli, Anas Showk", "title": "BERT Fine-tuning For Arabic Text Summarization", "comments": "4 pages, 2 tables, Published as a conference paper at AfricaNLP\n  workshop at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fine-tuning a pretrained BERT model is the state of the art method for\nextractive/abstractive text summarization, in this paper we showcase how this\nfine-tuning method can be applied to the Arabic language to both construct the\nfirst documented model for abstractive Arabic text summarization and show its\nperformance in Arabic extractive summarization. Our model works with\nmultilingual BERT (as Arabic language does not have a pretrained BERT of its\nown). We show its performance in English corpus first before applying it to\nArabic corpora in both extractive and abstractive tasks.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:23:14 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Elmadani", "Khalid N.", ""], ["Elgezouli", "Mukhtar", ""], ["Showk", "Anas", ""]]}, {"id": "2004.14143", "submitter": "Mahdi Rezaei", "authors": "Mahdi Rezaei and Mahsa Shahidi", "title": "Zero-Shot Learning and its Applications from Autonomous Vehicles to\n  COVID-19 Diagnosis: A Review", "comments": "Accepted in Journal of Intelligence-Based Medicine (Elsevier)", "journal-ref": "Journal of Intelligence-Based Medicine, Volumes 4, 2020", "doi": "10.1016/j.ibmed.2020.100005", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The challenge of learning a new concept, object, or a new medical disease\nrecognition without receiving any examples beforehand is called Zero-Shot\nLearning (ZSL). One of the major issues in deep learning based methodologies\nsuch as in Medical Imaging and other real-world applications is the requirement\nof large annotated datasets prepared by clinicians or experts to train the\nmodel. ZSL is known for having minimal human intervention by relying only on\npreviously known or trained concepts plus currently existing auxiliary\ninformation. This makes the ZSL applicable in many real-world scenarios, from\nunknown object detection in autonomous vehicles to medical imaging and\nunforeseen diseases such as COVID-19 Chest X-Ray (CXR) based diagnosis. We\nintroduce a novel and broaden solution called Few/one-shot learning, and\npresent the definition of the ZSL problem as an extreme case of the few-shot\nlearning. We review over fundamentals and the challenging steps of Zero-Shot\nLearning, including state-of-the-art categories of solutions, as well as our\nrecommended solution, motivations behind each approach, their advantages over\neach category to guide both clinicians and AI researchers to proceed with the\nbest techniques and practices based on their applications. We then review\nthrough different datasets inducing medical and non-medical images, the variety\nof splits, and the evaluation protocols proposed so far. Finally, we discuss\nthe recent applications and future directions of ZSL. We aim to convey a useful\nintuition through this paper towards the goal of handling complex learning\ntasks more similar to the way humans learn. We mainly focus on two applications\nin the current modern yet challenging era: coping with an early and fast\ndiagnosis of COVID-19 cases, and also encouraging the readers to develop other\nsimilar AI-based automated detection/recognition systems using ZSL.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:45:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 12:04:17 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 03:27:44 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Rezaei", "Mahdi", ""], ["Shahidi", "Mahsa", ""]]}, {"id": "2004.14164", "submitter": "Xiaoqing Geng", "authors": "Xiaoqing Geng, Xiwen Chen, Kenny Q. Zhu, Libin Shen, Yinggong Zhao", "title": "MICK: A Meta-Learning Framework for Few-shot Relation Classification\n  with Small Training Data", "comments": null, "journal-ref": "CIKM 2020: The 29th ACM International Conference on Information\n  and Knowledge Management", "doi": "10.1145/3340531.3411858", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot relation classification seeks to classify incoming query instances\nafter meeting only few support instances. This ability is gained by training\nwith large amount of in-domain annotated data. In this paper, we tackle an even\nharder problem by further limiting the amount of data available at training\ntime. We propose a few-shot learning framework for relation classification,\nwhich is particularly powerful when the training data is very small. In this\nframework, models not only strive to classify query instances, but also seek\nunderlying knowledge about the support instances to obtain better instance\nrepresentations. The framework also includes a method for aggregating\ncross-domain knowledge into models by open-source task enrichment.\nAdditionally, we construct a brand new dataset: the TinyRel-CM dataset, a\nfew-shot relation classification dataset in health domain with purposely small\ntraining data and challenging relation classes. Experimental results\ndemonstrate that our framework brings performance gains for most underlying\nclassification models, outperforms the state-of-the-art results given small\ntraining data, and achieves competitive results with sufficiently large\ntraining data.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 06:23:38 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 15:54:51 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Geng", "Xiaoqing", ""], ["Chen", "Xiwen", ""], ["Zhu", "Kenny Q.", ""], ["Shen", "Libin", ""], ["Zhao", "Yinggong", ""]]}, {"id": "2004.14171", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Ling Cai, Rui Zhu, Blake Regalia, Bo\n  Yan, Meilin Shi, Ni Lao", "title": "SE-KGE: A Location-Aware Knowledge Graph Embedding Model for Geographic\n  Question Answering and Spatial Semantic Lifting", "comments": "Accepted to Transactions in GIS", "journal-ref": "Transactions in GIS, 2020", "doi": "10.1111/TGIS.12629", "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning knowledge graph (KG) embeddings is an emerging technique for a\nvariety of downstream tasks such as summarization, link prediction, information\nretrieval, and question answering. However, most existing KG embedding models\nneglect space and, therefore, do not perform well when applied to (geo)spatial\ndata and tasks. For those models that consider space, most of them primarily\nrely on some notions of distance. These models suffer from higher computational\ncomplexity during training while still losing information beyond the relative\ndistance between entities. In this work, we propose a location-aware KG\nembedding model called SE-KGE. It directly encodes spatial information such as\npoint coordinates or bounding boxes of geographic entities into the KG\nembedding space. The resulting model is capable of handling different types of\nspatial reasoning. We also construct a geographic knowledge graph as well as a\nset of geographic query-answer pairs called DBGeo to evaluate the performance\nof SE-KGE in comparison to multiple baselines. Evaluation results show that\nSE-KGE outperforms these baselines on the DBGeo dataset for geographic logic\nquery answering task. This demonstrates the effectiveness of our\nspatially-explicit model and the importance of considering the scale of\ndifferent geographic entities. Finally, we introduce a novel downstream task\ncalled spatial semantic lifting which links an arbitrary location in the study\narea to entities in the KG via some relations. Evaluation on DBGeo shows that\nour model outperforms the baseline by a substantial margin.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 17:46:31 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Cai", "Ling", ""], ["Zhu", "Rui", ""], ["Regalia", "Blake", ""], ["Yan", "Bo", ""], ["Shi", "Meilin", ""], ["Lao", "Ni", ""]]}, {"id": "2004.14174", "submitter": "John Morris", "authors": "John X. Morris, Eli Lifland, Jack Lanchantin, Yangfeng Ji, Yanjun Qi", "title": "Reevaluating Adversarial Examples in Natural Language", "comments": "15 pages; 9 Tables; 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art attacks on NLP models lack a shared definition of a what\nconstitutes a successful attack. We distill ideas from past work into a unified\nframework: a successful natural language adversarial example is a perturbation\nthat fools the model and follows some linguistic constraints. We then analyze\nthe outputs of two state-of-the-art synonym substitution attacks. We find that\ntheir perturbations often do not preserve semantics, and 38% introduce\ngrammatical errors. Human surveys reveal that to successfully preserve\nsemantics, we need to significantly increase the minimum cosine similarities\nbetween the embeddings of swapped words and between the sentence encodings of\noriginal and perturbed sentences.With constraints adjusted to better preserve\nsemantics and grammaticality, the attack success rate drops by over 70\npercentage points.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 03:09:48 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 04:16:23 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Morris", "John X.", ""], ["Lifland", "Eli", ""], ["Lanchantin", "Jack", ""], ["Ji", "Yangfeng", ""], ["Qi", "Yanjun", ""]]}, {"id": "2004.14176", "submitter": "Emeka Ogbuju Mr", "authors": "Emeka Ogbuju and Moses Onyesolu", "title": "Development of a General Purpose Sentiment Lexicon for Igbo Language", "comments": "Accepted and presented at the Widening Natural Language Processing\n  (WiNLP) workshop, co-located with the Association for Computational\n  Linguistics (ACL) conference 2019 in Florence, Italy. See\n  https://www.winlp.org/wp-content/uploads/2019/final_papers/103_Paper.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are publicly available general purpose sentiment lexicons in some high\nresource languages but very few exist in the low resource languages. This makes\nit difficult to directly perform sentiment analysis tasks in such languages.\nThe objective of this work is to create a general purpose sentiment lexicon for\nthe Igbo language that can determine the sentiment of documents written in the\nIgbo language without having to translate it to the English language. The\nmaterial used was an automatically translated lexicon by Liu and the manual\naddition of Igbo native words. The result of this work is a general purpose\nlexicon called IgboSentilex. The performance was tested on the BBC Igbo news\nchannel. It returned an average polarity agreement of 95.75 percent with other\ngeneral purpose sentiment lexicons.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 22:10:34 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Ogbuju", "Emeka", ""], ["Onyesolu", "Moses", ""]]}, {"id": "2004.14180", "submitter": "Li Shen", "authors": "Congliang Chen, Li Shen, Haozhi Huang, and Wei Liu", "title": "Quantized Adam with Error Feedback", "comments": "Accepted to ACM Transactions on Intelligent Systems and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a distributed variant of adaptive stochastic\ngradient method for training deep neural networks in the parameter-server\nmodel. To reduce the communication cost among the workers and server, we\nincorporate two types of quantization schemes, i.e., gradient quantization and\nweight quantization, into the proposed distributed Adam. Besides, to reduce the\nbias introduced by quantization operations, we propose an error-feedback\ntechnique to compensate for the quantized gradient. Theoretically, in the\nstochastic nonconvex setting, we show that the distributed adaptive gradient\nmethod with gradient quantization and error-feedback converges to the\nfirst-order stationary point, and that the distributed adaptive gradient method\nwith weight quantization and error-feedback converges to the point related to\nthe quantized level under both the single-worker and multi-worker modes. At\nlast, we apply the proposed distributed adaptive gradient methods to train deep\nneural networks. Experimental results demonstrate the efficacy of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:21:54 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 04:41:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Chen", "Congliang", ""], ["Shen", "Li", ""], ["Huang", "Haozhi", ""], ["Liu", "Wei", ""]]}, {"id": "2004.14185", "submitter": "Simon Van Eyndhoven", "authors": "Simon Van Eyndhoven, Patrick Dupont, Simon Tousseyn, Nico Vervliet,\n  Wim Van Paesschen, Sabine Van Huffel, Borb\\'ala Hunyadi", "title": "Augmenting interictal mapping with neurovascular coupling biomarkers by\n  structured factorization of epileptic EEG and fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": "20-59", "categories": "eess.SP cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG-correlated fMRI analysis is widely used to detect regional blood oxygen\nlevel dependent fluctuations that are significantly synchronized to interictal\nepileptic discharges, which can provide evidence for localizing the ictal onset\nzone. However, such an asymmetrical, mass-univariate approach cannot capture\nthe inherent, higher order structure in the EEG data, nor multivariate\nrelations in the fMRI data, and it is nontrivial to accurately handle varying\nneurovascular coupling over patients and brain regions. We aim to overcome\nthese drawbacks in a data-driven manner by means of a novel structured\nmatrix-tensor factorization: the single-subject EEG data (represented as a\nthird-order spectrogram tensor) and fMRI data (represented as a spatiotemporal\nBOLD signal matrix) are jointly decomposed into a superposition of several\nsources, characterized by space-time-frequency profiles. In the shared temporal\nmode, Toeplitz-structured factors account for a spatially specific,\nneurovascular `bridge' between the EEG and fMRI temporal fluctuations,\ncapturing the hemodynamic response's variability over brain regions. We show\nthat the extracted source signatures provide a sensitive localization of the\nictal onset zone, and, moreover, that complementary localizing information can\nbe derived from the spatial variation of the hemodynamic response. Hence, this\nmultivariate, multimodal factorization provides two useful sets of EEG-fMRI\nbiomarkers, which can inform the presurgical evaluation of epilepsy. We make\nall code required to perform the computations available.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:27:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Van Eyndhoven", "Simon", ""], ["Dupont", "Patrick", ""], ["Tousseyn", "Simon", ""], ["Vervliet", "Nico", ""], ["Van Paesschen", "Wim", ""], ["Van Huffel", "Sabine", ""], ["Hunyadi", "Borb\u00e1la", ""]]}, {"id": "2004.14203", "submitter": "Diego Klabjan", "authors": "Diego Klabjan, Xiaofeng Zhu", "title": "Neural Network Retraining for Model Serving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose incremental (re)training of a neural network model to cope with a\ncontinuous flow of new data in inference during model serving. As such, this is\na life-long learning process. We address two challenges of life-long\nretraining: catastrophic forgetting and efficient retraining. If we combine all\npast and new data it can easily become intractable to retrain the neural\nnetwork model. On the other hand, if the model is retrained using only new\ndata, it can easily suffer catastrophic forgetting and thus it is paramount to\nstrike the right balance. Moreover, if we retrain all weights of the model\nevery time new data is collected, retraining tends to require too many\ncomputing resources. To solve these two issues, we propose a novel retraining\nmodel that can select important samples and important weights utilizing\nmulti-armed bandits. To further address forgetting, we propose a new\nregularization term focusing on synapse and neuron importance. We analyze\nmultiple datasets to document the outcome of the proposed retraining methods.\nVarious experiments demonstrate that our retraining methodologies mitigate the\ncatastrophic forgetting problem while boosting model performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:52:28 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Klabjan", "Diego", ""], ["Zhu", "Xiaofeng", ""]]}, {"id": "2004.14214", "submitter": "Eyy\\\"ub Sari", "authors": "Eyy\\\"ub Sari, Vahid Partovi Nia", "title": "Batch Normalization in Quantized Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementation of quantized neural networks on computing hardware leads to\nconsiderable speed up and memory saving. However, quantized deep networks are\ndifficult to train and batch~normalization (BatchNorm) layer plays an important\nrole in training full-precision and quantized networks. Most studies on\nBatchNorm are focused on full-precision networks, and there is little research\nin understanding BatchNorm affect in quantized training which we address here.\nWe show BatchNorm avoids gradient explosion which is counter-intuitive and\nrecently observed in numerical experiments by other researchers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:03:02 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Sari", "Eyy\u00fcb", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "2004.14218", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Andrea Madotto, Pascale Fung", "title": "Exploring Fine-tuning Techniques for Pre-trained Cross-lingual Models\n  via Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, fine-tuning pre-trained language models (e.g., multilingual BERT)\nto downstream cross-lingual tasks has shown promising results. However, the\nfine-tuning process inevitably changes the parameters of the pre-trained model\nand weakens its cross-lingual ability, which leads to sub-optimal performance.\nTo alleviate this problem, we leverage continual learning to preserve the\noriginal cross-lingual ability of the pre-trained model when we fine-tune it to\ndownstream tasks. The experimental result shows that our fine-tuning methods\ncan better preserve the cross-lingual ability of the pre-trained model in a\nsentence retrieval task. Our methods also achieve better performance than other\nfine-tuning baselines on the zero-shot cross-lingual part-of-speech tagging and\nnamed entity recognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:07:18 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2020 08:43:24 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2004.14224", "submitter": "Tao Shen", "authors": "Tao Shen, Yi Mao, Pengcheng He, Guodong Long, Adam Trischler, Weizhu\n  Chen", "title": "Exploiting Structured Knowledge in Text via Graph-Guided Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim at equipping pre-trained language models with structured\nknowledge. We present two self-supervised tasks learning over raw text with the\nguidance from knowledge graphs. Building upon entity-level masked language\nmodels, our first contribution is an entity masking scheme that exploits\nrelational knowledge underlying the text. This is fulfilled by using a linked\nknowledge graph to select informative entities and then masking their mentions.\nIn addition we use knowledge graphs to obtain distractors for the masked\nentities, and propose a novel distractor-suppressed ranking objective which is\noptimized jointly with masked language model. In contrast to existing\nparadigms, our approach uses knowledge graphs implicitly, only during\npre-training, to inject language models with structured knowledge via learning\nfrom raw text. It is more efficient than retrieval-based methods that perform\nentity linking and integration during finetuning and inference, and generalizes\nmore effectively than the methods that directly learn from concatenated graph\ntriples. Experiments show that our proposed model achieves improved performance\non five benchmark datasets, including question answering and knowledge base\ncompletion tasks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:22:42 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Shen", "Tao", ""], ["Mao", "Yi", ""], ["He", "Pengcheng", ""], ["Long", "Guodong", ""], ["Trischler", "Adam", ""], ["Chen", "Weizhu", ""]]}, {"id": "2004.14227", "submitter": "Sanyou Wu", "authors": "Sanyou Wu, Xingdong Feng, Fan Zhou", "title": "Metric learning by Similarity Network for Deep Semi-Supervised Learning", "comments": "Published as a conference paper at FLINS/ISKE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep semi-supervised learning has been widely implemented in the real-world\ndue to the rapid development of deep learning. Recently, attention has shifted\nto the approaches such as Mean-Teacher to penalize the inconsistency between\ntwo perturbed input sets. Although these methods may achieve positive results,\nthey ignore the relationship information between data instances. To solve this\nproblem, we propose a novel method named Metric Learning by Similarity Network\n(MLSN), which aims to learn a distance metric adaptively on different domains.\nBy co-training with the classification network, similarity network can learn\nmore information about pairwise relationships and performs better on some\nempirical tasks than state-of-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:25:13 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Wu", "Sanyou", ""], ["Feng", "Xingdong", ""], ["Zhou", "Fan", ""]]}, {"id": "2004.14230", "submitter": "Evgeny Mirkes", "authors": "Evgeny M. Mirkes, Jeza Allohibi, and Alexander N. Gorban", "title": "Fractional norms and quasinorms do not help to overcome the curse of\n  dimensionality", "comments": null, "journal-ref": "Entropy. 2020; 22(10):1105", "doi": "10.3390/e22101105", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality causes the well-known and widely discussed\nproblems for machine learning methods. There is a hypothesis that using of the\nManhattan distance and even fractional quasinorms lp (for p less than 1) can\nhelp to overcome the curse of dimensionality in classification problems. In\nthis study, we systematically test this hypothesis. We confirm that fractional\nquasinorms have a greater relative contrast or coefficient of variation than\nthe Euclidean norm l2, but we also demonstrate that the distance concentration\nshows qualitatively the same behaviour for all tested norms and quasinorms and\nthe difference between them decays as dimension tends to infinity. Estimation\nof classification quality for kNN based on different norms and quasinorms shows\nthat a greater relative contrast does not mean better classifier performance\nand the worst performance for different databases was shown by different norms\n(quasinorms). A systematic comparison shows that the difference of the\nperformance of kNN based on lp for p=2, 1, and 0.5 is statistically\ninsignificant.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:30:12 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Mirkes", "Evgeny M.", ""], ["Allohibi", "Jeza", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2004.14281", "submitter": "Titas De", "authors": "Nick Haber, Catalin Voss, Jena Daniels, Peter Washington, Azar Fazel,\n  Aaron Kline, Titas De, Terry Winograd, Carl Feinstein, Dennis P. Wall", "title": "A Wearable Social Interaction Aid for Children with Autism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With most recent estimates giving an incidence rate of 1 in 68 children in\nthe United States, the autism spectrum disorder (ASD) is a growing public\nhealth crisis. Many of these children struggle to make eye contact, recognize\nfacial expressions, and engage in social interactions. Today the standard for\ntreatment of the core autism-related deficits focuses on a form of behavior\ntraining known as Applied Behavioral Analysis. To address perceived deficits in\nexpression recognition, ABA approaches routinely involve the use of prompts\nsuch as flash cards for repetitive emotion recognition training via\nmemorization. These techniques must be administered by trained practitioners\nand often at clinical centers that are far outnumbered by and out of reach from\nthe many children and families in need of attention. Waitlists for access are\nup to 18 months long, and this wait may lead to children regressing down a path\nof isolation that worsens their long-term prognosis. There is an urgent need to\ninnovate new methods of care delivery that can appropriately empower caregivers\nof children at risk or with a diagnosis of autism, and that capitalize on\nmobile tools and wearable devices for use outside of clinical settings.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 13:14:32 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Haber", "Nick", ""], ["Voss", "Catalin", ""], ["Daniels", "Jena", ""], ["Washington", "Peter", ""], ["Fazel", "Azar", ""], ["Kline", "Aaron", ""], ["De", "Titas", ""], ["Winograd", "Terry", ""], ["Feinstein", "Carl", ""], ["Wall", "Dennis P.", ""]]}, {"id": "2004.14288", "submitter": "Wei Pan", "authors": "Minghao Han, Lixian Zhang, Jun Wang, Wei Pan", "title": "Actor-Critic Reinforcement Learning for Control with Stability Guarantee", "comments": "IEEE RA-L + IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement Learning (RL) and its integration with deep learning have\nachieved impressive performance in various robotic control tasks, ranging from\nmotion planning and navigation to end-to-end visual manipulation. However,\nstability is not guaranteed in model-free RL by solely using data. From a\ncontrol-theoretic perspective, stability is the most important property for any\ncontrol system, since it is closely related to safety, robustness, and\nreliability of robotic systems. In this paper, we propose an actor-critic RL\nframework for control which can guarantee closed-loop stability by employing\nthe classic Lyapunov's method in control theory. First of all, a data-based\nstability theorem is proposed for stochastic nonlinear systems modeled by\nMarkov decision process. Then we show that the stability condition could be\nexploited as the critic in the actor-critic RL to learn a controller/policy. At\nlast, the effectiveness of our approach is evaluated on several well-known\n3-dimensional robot control tasks and a synthetic biology gene network tracking\ntask in three different popular physics simulation platforms. As an empirical\nevaluation on the advantage of stability, we show that the learned policies can\nenable the systems to recover to the equilibrium or way-points when interfered\nby uncertainties such as system parametric variations and external disturbances\nto a certain extent.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:14:30 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 07:27:41 GMT"}, {"version": "v3", "created": "Wed, 15 Jul 2020 15:25:55 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Han", "Minghao", ""], ["Zhang", "Lixian", ""], ["Wang", "Jun", ""], ["Pan", "Wei", ""]]}, {"id": "2004.14289", "submitter": "Shailesh Arya", "authors": "Shailesh Arya, Hrithik Mesariya, Vishal Parekh", "title": "Smart Attendance System Usign CNN", "comments": "4 Pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on the attendance system has been going for a very long time,\nnumerous arrangements have been proposed in the last decade to make this system\nefficient and less time consuming, but all those systems have several flaws. In\nthis paper, we are introducing a smart and efficient system for attendance\nusing face detection and face recognition. This system can be used to take\nattendance in colleges or offices using real-time face recognition with the\nhelp of the Convolution Neural Network(CNN). The conventional methods like\nEigenfaces and Fisher faces are sensitive to lighting, noise, posture,\nobstruction, illumination etc. Hence, we have used CNN to recognize the face\nand overcome such difficulties. The attendance records will be updated\nautomatically and stored in an excel sheet as well as in a database. We have\nused MongoDB as a backend database for attendance records.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 09:04:33 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Arya", "Shailesh", ""], ["Mesariya", "Hrithik", ""], ["Parekh", "Vishal", ""]]}, {"id": "2004.14293", "submitter": "Yuntian Chen", "authors": "Yuntian Chen and Dongxiao Zhang", "title": "Physics-constrained indirect supervised learning", "comments": "5 pages and 5 figures", "journal-ref": null, "doi": "10.1016/j.taml.2020.01.019", "report-no": null, "categories": "eess.SP cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a supervised learning method that does not rely on\nlabels. We use variables associated with the label as indirect labels, and\nconstruct an indirect physics-constrained loss based on the physical mechanism\nto train the model. In the training process, the model prediction is mapped to\nthe space of value that conforms to the physical mechanism through the\nprojection matrix, and then the model is trained based on the indirect labels.\nThe final prediction result of the model conforms to the physical mechanism\nbetween indirect label and label, and also meets the constraints of the\nindirect label. The present study also develops projection matrix normalization\nand prediction covariance analysis to ensure that the model can be fully\ntrained. Finally, the effect of the physics-constrained indirect supervised\nlearning is verified based on a well log generation problem.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 10:50:48 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Chen", "Yuntian", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2004.14294", "submitter": "Jurek Leonhardt", "authors": "Jurek Leonhardt, Avishek Anand, Megha Khosla", "title": "Boilerplate Removal using a Neural Sequence Labeling Model", "comments": "WWW20 Demo paper", "journal-ref": null, "doi": "10.1145/3366424.3383547", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of main content from web pages is an important task for\nnumerous applications, ranging from usability aspects, like reader views for\nnews articles in web browsers, to information retrieval or natural language\nprocessing. Existing approaches are lacking as they rely on large amounts of\nhand-crafted features for classification. This results in models that are\ntailored to a specific distribution of web pages, e.g. from a certain time\nframe, but lack in generalization power. We propose a neural sequence labeling\nmodel that does not rely on any hand-crafted features but takes only the HTML\ntags and words that appear in a web page as input. This allows us to present a\nbrowser extension which highlights the content of arbitrary web pages directly\nwithin the browser using our model. In addition, we create a new, more current\ndataset to show that our model is able to adapt to changes in the structure of\nweb pages and outperform the state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 08:06:59 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Leonhardt", "Jurek", ""], ["Anand", "Avishek", ""], ["Khosla", "Megha", ""]]}, {"id": "2004.14307", "submitter": "Hung Le", "authors": "Hung Le, Doyen Sahoo, Chenghao Liu, Nancy F. Chen, Steven C.H. Hoi", "title": "UniConv: A Unified Conversational Neural Architecture for Multi-domain\n  Task-oriented Dialogues", "comments": "Accepted The 2020 Conference on Empirical Methods in Natural Language\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building an end-to-end conversational agent for multi-domain task-oriented\ndialogues has been an open challenge for two main reasons. First, tracking\ndialogue states of multiple domains is non-trivial as the dialogue agent must\nobtain complete states from all relevant domains, some of which might have\nshared slots among domains as well as unique slots specifically for one domain\nonly. Second, the dialogue agent must also process various types of information\nacross domains, including dialogue context, dialogue states, and database, to\ngenerate natural responses to users. Unlike the existing approaches that are\noften designed to train each module separately, we propose \"UniConv\" -- a novel\nunified neural architecture for end-to-end conversational systems in\nmulti-domain task-oriented dialogues, which is designed to jointly train (i) a\nBi-level State Tracker which tracks dialogue states by learning signals at both\nslot and domain level independently, and (ii) a Joint Dialogue Act and Response\nGenerator which incorporates information from various input components and\nmodels dialogue acts and target responses simultaneously. We conduct\ncomprehensive experiments in dialogue state tracking, context-to-text, and\nend-to-end settings on the MultiWOZ2.1 benchmark, achieving superior\nperformance over competitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:28:22 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 03:52:34 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Le", "Hung", ""], ["Sahoo", "Doyen", ""], ["Liu", "Chenghao", ""], ["Chen", "Nancy F.", ""], ["Hoi", "Steven C. H.", ""]]}, {"id": "2004.14308", "submitter": "Julien Horwood", "authors": "Julien Horwood and Emmanuel Noutahi", "title": "Molecular Design in Synthetically Accessible Chemical Space via Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1021/acsomega.0c04153", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental goal of generative drug design is to propose optimized\nmolecules that meet predefined activity, selectivity, and pharmacokinetic\ncriteria. Despite recent progress, we argue that existing generative methods\nare limited in their ability to favourably shift the distributions of molecular\nproperties during optimization. We instead propose a novel Reinforcement\nLearning framework for molecular design in which an agent learns to directly\noptimize through a space of synthetically-accessible drug-like molecules. This\nbecomes possible by defining transitions in our Markov Decision Process as\nchemical reactions, and allows us to leverage synthetic routes as an inductive\nbias. We validate our method by demonstrating that it outperforms existing\nstate-of the art approaches in the optimization of pharmacologically-relevant\nobjectives, while results on multi-objective optimization tasks suggest\nincreased scalability to realistic pharmaceutical design problems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:29:28 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 19:44:35 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Horwood", "Julien", ""], ["Noutahi", "Emmanuel", ""]]}, {"id": "2004.14309", "submitter": "Pierluca D'Oro", "authors": "Pierluca D'Oro, Wojciech Ja\\'skowski", "title": "How to Learn a Useful Critic? Model-based Action-Gradient-Estimator\n  Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic-policy actor-critic algorithms for continuous control improve\nthe actor by plugging its actions into the critic and ascending the\naction-value gradient, which is obtained by chaining the actor's Jacobian\nmatrix with the gradient of the critic with respect to input actions. However,\ninstead of gradients, the critic is, typically, only trained to accurately\npredict expected returns, which, on their own, are useless for policy\noptimization. In this paper, we propose MAGE, a model-based actor-critic\nalgorithm, grounded in the theory of policy gradients, which explicitly learns\nthe action-value gradient. MAGE backpropagates through the learned dynamics to\ncompute gradient targets in temporal difference learning, leading to a critic\ntailored for policy improvement. On a set of MuJoCo continuous-control tasks,\nwe demonstrate the efficiency of the algorithm in comparison to model-free and\nmodel-based state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:30:53 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 14:24:34 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["D'Oro", "Pierluca", ""], ["Ja\u015bkowski", "Wojciech", ""]]}, {"id": "2004.14322", "submitter": "Andreas Peter", "authors": "Valentine Legoy, Marco Caselli, Christin Seifert, and Andreas Peter", "title": "Automated Retrieval of ATT&CK Tactics and Techniques for Cyber Threat\n  Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, threat intelligence sharing has steadily grown, leading\ncybersecurity professionals to access increasingly larger amounts of\nheterogeneous data. Among those, cyber attacks' Tactics, Techniques and\nProcedures (TTPs) have proven to be particularly valuable to characterize\nthreat actors' behaviors and, thus, improve defensive countermeasures.\nUnfortunately, this information is often hidden within human-readable textual\nreports and must be extracted manually. In this paper, we evaluate several\nclassification approaches to automatically retrieve TTPs from unstructured\ntext. To implement these approaches, we take advantage of the MITRE ATT&CK\nframework, an open knowledge base of adversarial tactics and techniques, to\ntrain classifiers and label results. Finally, we present rcATT, a tool built on\ntop of our findings and freely distributed to the security community to support\ncyber threat report automated analysis.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:45:14 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Legoy", "Valentine", ""], ["Caselli", "Marco", ""], ["Seifert", "Christin", ""], ["Peter", "Andreas", ""]]}, {"id": "2004.14340", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh, Dan Alistarh", "title": "WoodFisher: Efficient Second-Order Approximation for Neural Network\n  Compression", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Second-order information, in the form of Hessian- or Inverse-Hessian-vector\nproducts, is a fundamental tool for solving optimization problems. Recently,\nthere has been significant interest in utilizing this information in the\ncontext of deep neural networks; however, relatively little is known about the\nquality of existing approximations in this context. Our work examines this\nquestion, identifies issues with existing approaches, and proposes a method\ncalled WoodFisher to compute a faithful and efficient estimate of the inverse\nHessian.\n  Our main application is to neural network compression, where we build on the\nclassic Optimal Brain Damage/Surgeon framework. We demonstrate that WoodFisher\nsignificantly outperforms popular state-of-the-art methods for one-shot\npruning. Further, even when iterative, gradual pruning is considered, our\nmethod results in a gain in test accuracy over the state-of-the-art approaches,\nfor pruning popular neural networks (like ResNet-50, MobileNetV1) trained on\nstandard image classification datasets such as ImageNet ILSVRC. We examine how\nour method can be extended to take into account first-order information, as\nwell as illustrate its ability to automatically set layer-wise pruning\nthresholds and perform compression in the limited-data regime. The code is\navailable at the following link, https://github.com/IST-DASLab/WoodFisher.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:14:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 17:13:28 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 10:40:36 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2020 17:34:49 GMT"}, {"version": "v5", "created": "Wed, 25 Nov 2020 17:31:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Alistarh", "Dan", ""]]}, {"id": "2004.14341", "submitter": "Dimitrios Bachtis", "authors": "Dimitrios Bachtis, Gert Aarts, Biagio Lucini", "title": "Extending machine learning classification capabilities with histogram\n  reweighting", "comments": null, "journal-ref": "Phys. Rev. E 102, 033303 (2020)", "doi": "10.1103/PhysRevE.102.033303", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG hep-lat physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of Monte Carlo histogram reweighting to extrapolate\npredictions of machine learning methods. In our approach, we treat the output\nfrom a convolutional neural network as an observable in a statistical system,\nenabling its extrapolation over continuous ranges in parameter space. We\ndemonstrate our proposal using the phase transition in the two-dimensional\nIsing model. By interpreting the output of the neural network as an order\nparameter, we explore connections with known observables in the system and\ninvestigate its scaling behaviour. A finite size scaling analysis is conducted\nbased on quantities derived from the neural network that yields accurate\nestimates for the critical exponents and the critical temperature. The method\nimproves the prospects of acquiring precision measurements from machine\nlearning in physical systems without an order parameter and those where direct\nsampling in regions of parameter space might not be possible.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:20:16 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 15:54:54 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 08:47:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Bachtis", "Dimitrios", ""], ["Aarts", "Gert", ""], ["Lucini", "Biagio", ""]]}, {"id": "2004.14353", "submitter": "Weijia Xu", "authors": "Weijia Xu, Batool Haider, Saab Mansour", "title": "End-to-End Slot Alignment and Recognition for Cross-Lingual NLU", "comments": "Accepted at EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural language understanding (NLU) in the context of goal-oriented dialog\nsystems typically includes intent classification and slot labeling tasks.\nExisting methods to expand an NLU system to new languages use machine\ntranslation with slot label projection from source to the translated\nutterances, and thus are sensitive to projection errors. In this work, we\npropose a novel end-to-end model that learns to align and predict target slot\nlabels jointly for cross-lingual transfer. We introduce MultiATIS++, a new\nmultilingual NLU corpus that extends the Multilingual ATIS corpus to nine\nlanguages across four language families, and evaluate our method using the\ncorpus. Results show that our method outperforms a simple label projection\nmethod using fast-align on most languages, and achieves competitive performance\nto the more complex, state-of-the-art projection method with only half of the\ntraining time. We release our MultiATIS++ corpus to the community to continue\nfuture research on cross-lingual NLU.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:31:11 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 04:36:04 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Xu", "Weijia", ""], ["Haider", "Batool", ""], ["Mansour", "Saab", ""]]}, {"id": "2004.14355", "submitter": "Nithin Holla", "authors": "Nithin Holla, Pushkar Mishra, Helen Yannakoudakis, Ekaterina Shutova", "title": "Learning to Learn to Disambiguate: Meta-Learning for Few-Shot Word Sense\n  Disambiguation", "comments": "Camera-ready: Findings of EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning methods hinges on the availability of large\ntraining datasets annotated for the task of interest. In contrast to human\nintelligence, these methods lack versatility and struggle to learn and adapt\nquickly to new tasks, where labeled data is scarce. Meta-learning aims to solve\nthis problem by training a model on a large number of few-shot tasks, with an\nobjective to learn new tasks quickly from a small number of examples. In this\npaper, we propose a meta-learning framework for few-shot word sense\ndisambiguation (WSD), where the goal is to learn to disambiguate unseen words\nfrom only a few labeled instances. Meta-learning approaches have so far been\ntypically tested in an $N$-way, $K$-shot classification setting where each task\nhas $N$ classes with $K$ examples per class. Owing to its nature, WSD deviates\nfrom this controlled setup and requires the models to handle a large number of\nhighly unbalanced classes. We extend several popular meta-learning approaches\nto this scenario, and analyze their strengths and weaknesses in this new\nchallenging setting.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:33:31 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 14:40:51 GMT"}, {"version": "v3", "created": "Mon, 12 Oct 2020 10:09:05 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Holla", "Nithin", ""], ["Mishra", "Pushkar", ""], ["Yannakoudakis", "Helen", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "2004.14364", "submitter": "Gerasimos Lampouras", "authors": "Giulio Zhou and Gerasimos Lampouras", "title": "Generating Safe Diversity in NLG via Imitation Learning", "comments": "10 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning models for language generation tasks tend to produce repetitive\noutput. Various methods have been proposed to encourage lexical diversity\nduring decoding, but this often comes at a cost to the perceived fluency and\nadequacy of the output. In this work, we propose to ameliorate this cost by\nusing an Imitation Learning approach to explore the level of diversity that a\nlanguage generation model can safely produce. Specifically, we augment the\ndecoding process with a meta-classifier trained to distinguish which words at\nany given timestep will lead to high-quality output. We focus our experiments\non concept-to-text generation where models are sensitive to the inclusion of\nirrelevant words due to the strict relation between input and output. Our\nanalysis shows that previous methods for diversity underperform in this\nsetting, while human evaluation suggests that our proposed method achieves a\nhigh level of diversity with minimal effect to the output's fluency and\nadequacy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:43:24 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Zhou", "Giulio", ""], ["Lampouras", "Gerasimos", ""]]}, {"id": "2004.14366", "submitter": "James Thorne", "authors": "James Thorne, Andreas Vlachos", "title": "Elastic weight consolidation for better bias inoculation", "comments": "Accepted at EACL 2021. Was previously submitted to arxiv with the\n  title \"Avoiding catastrophic forgetting in mitigating model biases in\n  sentence-pair classification with elastic weight consolidation\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biases present in training datasets have been shown to affect models for\nsentence pair classification tasks such as natural language inference (NLI) and\nfact verification. While fine-tuning models on additional data has been used to\nmitigate them, a common issue is that of catastrophic forgetting of the\noriginal training dataset. In this paper, we show that elastic weight\nconsolidation (EWC) allows fine-tuning of models to mitigate biases while being\nless susceptible to catastrophic forgetting. In our evaluation on fact\nverification and NLI stress tests, we show that fine-tuning with EWC dominates\nstandard fine-tuning, yielding models with lower levels of forgetting on the\noriginal (biased) dataset for equivalent gains in accuracy on the fine-tuning\n(unbiased) dataset.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:45:12 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 10:57:26 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Thorne", "James", ""], ["Vlachos", "Andreas", ""]]}, {"id": "2004.14367", "submitter": "Edo Collins", "authors": "Edo Collins, Raja Bala, Bob Price, Sabine S\\\"usstrunk", "title": "Editing in Style: Uncovering the Local Semantics of GANs", "comments": "IEEE Conference on Computer Vision and Patten Recognition (CVPR),\n  2020. Code: https://github.com/IVRL/GANLocalEditing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the quality of GAN image synthesis has improved tremendously in recent\nyears, our ability to control and condition the output is still limited.\nFocusing on StyleGAN, we introduce a simple and effective method for making\nlocal, semantically-aware edits to a target output image. This is accomplished\nby borrowing elements from a source image, also a GAN output, via a novel\nmanipulation of style vectors. Our method requires neither supervision from an\nexternal model, nor involves complex spatial morphing operations. Instead, it\nrelies on the emergent disentanglement of semantic objects that is learned by\nStyleGAN during its training. Semantic editing is demonstrated on GANs\nproducing human faces, indoor scenes, cats, and cars. We measure the locality\nand photorealism of the edits produced by our method, and find that it\naccomplishes both.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:45:56 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 13:01:07 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Collins", "Edo", ""], ["Bala", "Raja", ""], ["Price", "Bob", ""], ["S\u00fcsstrunk", "Sabine", ""]]}, {"id": "2004.14373", "submitter": "Ankur Parikh", "authors": "Ankur P. Parikh, Xuezhi Wang, Sebastian Gehrmann, Manaal Faruqui,\n  Bhuwan Dhingra, Diyi Yang, Dipanjan Das", "title": "ToTTo: A Controlled Table-To-Text Generation Dataset", "comments": "Accepted to EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ToTTo, an open-domain English table-to-text dataset with over\n120,000 training examples that proposes a controlled generation task: given a\nWikipedia table and a set of highlighted table cells, produce a one-sentence\ndescription. To obtain generated targets that are natural but also faithful to\nthe source table, we introduce a dataset construction process where annotators\ndirectly revise existing candidate sentences from Wikipedia. We present\nsystematic analyses of our dataset and annotation process as well as results\nachieved by several state-of-the-art baselines. While usually fluent, existing\nmethods often hallucinate phrases that are not supported by the table,\nsuggesting that this dataset can serve as a useful research benchmark for\nhigh-precision conditional text generation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 17:53:45 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 05:18:35 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 06:07:06 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Parikh", "Ankur P.", ""], ["Wang", "Xuezhi", ""], ["Gehrmann", "Sebastian", ""], ["Faruqui", "Manaal", ""], ["Dhingra", "Bhuwan", ""], ["Yang", "Diyi", ""], ["Das", "Dipanjan", ""]]}, {"id": "2004.14382", "submitter": "Nan Gao", "authors": "Nan Gao, Wei Shao, Mohammad Saiedur Rahaman, Jun Zhai, Klaus David,\n  Flora D. Salim", "title": "Transfer Learning for Thermal Comfort Prediction in Multiple Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HVAC (Heating, Ventilation and Air Conditioning) system is an important part\nof a building, which constitutes up to 40% of building energy usage. The main\npurpose of HVAC, maintaining appropriate thermal comfort, is crucial for the\nbest utilisation of energy usage. Besides, thermal comfort is also crucial for\nwell-being, health, and work productivity. Recently, data-driven thermal\ncomfort models have got better performance than traditional knowledge-based\nmethods (e.g. Predicted Mean Vote Model). An accurate thermal comfort model\nrequires a large amount of self-reported thermal comfort data from indoor\noccupants which undoubtedly remains a challenge for researchers. In this\nresearch, we aim to tackle this data-shortage problem and boost the performance\nof thermal comfort prediction. We utilise sensor data from multiple cities in\nthe same climate zone to learn thermal comfort patterns. We present a transfer\nlearning based multilayer perceptron model from the same climate zone\n(TL-MLP-C*) for accurate thermal comfort prediction. Extensive experimental\nresults on ASHRAE RP-884, the Scales Project and Medium US Office datasets show\nthat the performance of the proposed TL-MLP-C* exceeds the state-of-the-art\nmethods in accuracy, precision and F1-score.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:42:02 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 04:28:39 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 00:14:52 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Gao", "Nan", ""], ["Shao", "Wei", ""], ["Rahaman", "Mohammad Saiedur", ""], ["Zhai", "Jun", ""], ["David", "Klaus", ""], ["Salim", "Flora D.", ""]]}, {"id": "2004.14404", "submitter": "Ashvin Nair", "authors": "Gerrit Schoettler, Ashvin Nair, Juan Aparicio Ojea, Sergey Levine,\n  Eugen Solowjow", "title": "Meta-Reinforcement Learning for Robotic Industrial Insertion Tasks", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic insertion tasks are characterized by contact and friction mechanics,\nmaking them challenging for conventional feedback control methods due to\nunmodeled physical effects. Reinforcement learning (RL) is a promising approach\nfor learning control policies in such settings. However, RL can be unsafe\nduring exploration and might require a large amount of real-world training\ndata, which is expensive to collect. In this paper, we study how to use\nmeta-reinforcement learning to solve the bulk of the problem in simulation by\nsolving a family of simulated industrial insertion tasks and then adapt\npolicies quickly in the real world. We demonstrate our approach by training an\nagent to successfully perform challenging real-world insertion tasks using less\nthan 20 trials of real-world experience. Videos and other material are\navailable at https://pearl-insertion.github.io/\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:00:22 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 01:42:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Schoettler", "Gerrit", ""], ["Nair", "Ashvin", ""], ["Ojea", "Juan Aparicio", ""], ["Levine", "Sergey", ""], ["Solowjow", "Eugen", ""]]}, {"id": "2004.14407", "submitter": "Mathieu Bauchy", "authors": "Boya Ouyang, Yuhai Li, Yu Song, Feishu Wu, Huizi Yu, Yongzhe Wang,\n  Mathieu Bauchy, and Gaurav Sant", "title": "Learning from Sparse Datasets: Predicting Concrete's Strength by Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite enormous efforts over the last decades to establish the relationship\nbetween concrete proportioning and strength, a robust knowledge-based model for\naccurate concrete strength predictions is still lacking. As an alternative to\nphysical or chemical-based models, data-driven machine learning (ML) methods\noffer a new solution to this problem. Although this approach is promising for\nhandling the complex, non-linear, non-additive relationship between concrete\nmixture proportions and strength, a major limitation of ML lies in the fact\nthat large datasets are needed for model training. This is a concern as\nreliable, consistent strength data is rather limited, especially for realistic\nindustrial concretes. Here, based on the analysis of a large dataset (>10,000\nobservations) of measured compressive strengths from industrially-produced\nconcretes, we compare the ability of select ML algorithms to \"learn\" how to\nreliably predict concrete strength as a function of the size of the dataset.\nBased on these results, we discuss the competition between how accurate a given\nmodel can eventually be (when trained on a large dataset) and how much data is\nactually required to train this model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:06:07 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Ouyang", "Boya", ""], ["Li", "Yuhai", ""], ["Song", "Yu", ""], ["Wu", "Feishu", ""], ["Yu", "Huizi", ""], ["Wang", "Yongzhe", ""], ["Bauchy", "Mathieu", ""], ["Sant", "Gaurav", ""]]}, {"id": "2004.14409", "submitter": "Eugene Zabrodin", "authors": "Yu. Kvasiuk, E. Zabrodin, L. Bravina, I. Didur, M. Frolov", "title": "Classification of Equation of State in Relativistic Heavy-Ion Collisions\n  Using Deep Learning", "comments": "matches published version", "journal-ref": "J. High Energ. Phys. 07 (2020) 133", "doi": "10.1007/JHEP07(2020)133", "report-no": null, "categories": "nucl-th cs.LG hep-ph nucl-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Nets, which is a powerful method of Deep Learning, is\napplied to classify equation of state of heavy-ion collision event generated\nwithin the UrQMD model. Event-by-event transverse momentum and azimuthal angle\ndistributions of protons are used to train a classifier. An overall accuracy of\nclassification of 98\\% is reached for Au+Au events at $\\sqrt{s_{NN}} = 11$ GeV.\nPerformance of classifiers, trained on events at different colliding energies,\nis investigated. Obtained results indicate extensive possibilities of\napplication of Deep Learning methods to other problems in physics of heavy-ion\ncollisions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:08:36 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 09:57:17 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kvasiuk", "Yu.", ""], ["Zabrodin", "E.", ""], ["Bravina", "L.", ""], ["Didur", "I.", ""], ["Frolov", "M.", ""]]}, {"id": "2004.14415", "submitter": "Ke Liu", "authors": "Ke Liu, Nicolas Sadoune, Nihal Rao, Jonas Greitemann, and Lode Pollet", "title": "Revealing the Phase Diagram of Kitaev Materials by Machine Learning:\n  Cooperation and Competition between Spin Liquids", "comments": "17 pages, 12 figures, 2 tables; Editors' Suggestion", "journal-ref": "Phys. Rev. Research 3, 023016 (2021)", "doi": "10.1103/PhysRevResearch.3.023016", "report-no": null, "categories": "cond-mat.str-el cond-mat.mtrl-sci cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kitaev materials are promising materials for hosting quantum spin liquids and\ninvestigating the interplay of topological and symmetry-breaking phases. We use\nan unsupervised and interpretable machine-learning method, the tensorial-kernel\nsupport vector machine, to study the honeycomb Kitaev-$\\Gamma$ model in a\nmagnetic field. Our machine learns the global classical phase diagram and the\nassociated analytical order parameters, including several distinct spin\nliquids, two exotic $S_3$ magnets, and two modulated $S_3 \\times Z_3$ magnets.\nWe find that the extension of Kitaev spin liquids and a field-induced\nsuppression of magnetic order already occur in the large-$S$ limit, implying\nthat critical parts of the physics of Kitaev materials can be understood at the\nclassical level. Moreover, the two $S_3 \\times Z_3$ orders are induced by\ncompetition between Kitaev and $\\Gamma$ spin liquids and feature a different\ntype of spin-lattice entangled modulation, which requires a matrix description\ninstead of scalar phase factors. Our work provides a direct instance of a\nmachine detecting new phases and paves the way towards the development of\nautomated tools to explore unsolved problems in many-body physics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:18:34 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 12:45:50 GMT"}, {"version": "v3", "created": "Sun, 1 Nov 2020 15:57:24 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 15:34:00 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Liu", "Ke", ""], ["Sadoune", "Nicolas", ""], ["Rao", "Nihal", ""], ["Greitemann", "Jonas", ""], ["Pollet", "Lode", ""]]}, {"id": "2004.14418", "submitter": "Ambarish Moharil", "authors": "Ambarish Moharil, Nikhil Sonavane, Chirag Kedia, Mansimran Singh Anand", "title": "To Reduce Gross NPA and Classify Defaulters Using Shannon Entropy", "comments": "11 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non Performing Asset(NPA) has been in a serious attention by banks over the\npast few years. NPA cause a huge loss to the banks hence it becomes an\nextremely critical step in deciding which loans have the capabilities to become\nan NPA and thereby deciding which loans to grant and which ones to reject. In\nthis paper which focuses on the exact crux of the matter we have proposed an\nalgorithm which is designed to handle the financial data very meticulously to\npredict with a very high accuracy whether a particular loan would be classified\nas a NPA in future or not. Instead of the conventional less accurate\nclassifiers used to decide which loans can turn to be NPA we build our own\nclassifier model using Entropy as the base. We have created an entropy based\nclassifier using Shannon Entropy. The classifier model categorizes our data\npoints in two categories accepted or rejected. We make use of local entropy and\nglobal entropy to help us determine the output. The entropy classifier model is\nthen compared with existing classifiers used to predict NPAs thereby giving us\nan idea about the performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:29:34 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Moharil", "Ambarish", ""], ["Sonavane", "Nikhil", ""], ["Kedia", "Chirag", ""], ["Anand", "Mansimran Singh", ""]]}, {"id": "2004.14421", "submitter": "Vittorio Mazzia", "authors": "Vittorio Mazzia, Lorenzo Comba, Aleem Khaliq, Marcello Chiaberge,\n  Paolo Gay", "title": "UAV and Machine Learning Based Refinement of a Satellite-Driven\n  Vegetation Index for Precision Agriculture", "comments": null, "journal-ref": "Sensors 2020, 20(9), 2530", "doi": "10.3390/s20092530", "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Precision agriculture is considered to be a fundamental approach in pursuing\na low-input, high-efficiency, and sustainable kind of agriculture when\nperforming site-specific management practices. To achieve this objective, a\nreliable and updated description of the local status of crops is required.\nRemote sensing, and in particular satellite-based imagery, proved to be a\nvaluable tool in crop mapping, monitoring, and diseases assessment. However,\nfreely available satellite imagery with low or moderate resolutions showed some\nlimits in specific agricultural applications, e.g., where crops are grown by\nrows. Indeed, in this framework, the satellite's output could be biased by\nintra-row covering, giving inaccurate information about crop status. This paper\npresents a novel satellite imagery refinement framework, based on a deep\nlearning technique which exploits information properly derived from high\nresolution images acquired by unmanned aerial vehicle (UAV) airborne\nmultispectral sensors. To train the convolutional neural network, only a single\nUAV-driven dataset is required, making the proposed approach simple and\ncost-effective. A vineyard in Serralunga d'Alba (Northern Italy) was chosen as\na case study for validation purposes. Refined satellite-driven normalized\ndifference vegetation index (NDVI) maps, acquired in four different periods\nduring the vine growing season, were shown to better describe crop status with\nrespect to raw datasets by correlation analysis and ANOVA. In addition, using a\nK-means based classifier, 3-class vineyard vigor maps were profitably derived\nfrom the NDVI maps, which are a valuable tool for growers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:34:48 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mazzia", "Vittorio", ""], ["Comba", "Lorenzo", ""], ["Khaliq", "Aleem", ""], ["Chiaberge", "Marcello", ""], ["Gay", "Paolo", ""]]}, {"id": "2004.14427", "submitter": "Konstantin Avrachenkov", "authors": "Konstantin Avrachenkov and Vivek S. Borkar", "title": "Whittle index based Q-learning for restless bandits with average reward", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel reinforcement learning algorithm is introduced for multiarmed\nrestless bandits with average reward, using the paradigms of Q-learning and\nWhittle index. Specifically, we leverage the structure of the Whittle index\npolicy to reduce the search space of Q-learning, resulting in major\ncomputational gains. Rigorous convergence analysis is provided, supported by\nnumerical experiments. The numerical experiments show excellent empirical\nperformance of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 18:43:36 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 16:05:12 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Avrachenkov", "Konstantin", ""], ["Borkar", "Vivek S.", ""]]}, {"id": "2004.14443", "submitter": "Johny Moreira", "authors": "Johny Moreira, Chaina Oliveira, David Mac\\^edo, Cleber Zanchettin,\n  Luciano Barbosa", "title": "Distantly-Supervised Neural Relation Extraction with Side Information\n  using BERT", "comments": "2020 International Joint Conference on Neural Networks (IJCNN)", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9206648", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) consists in categorizing the relationship between\nentities in a sentence. A recent paradigm to develop relation extractors is\nDistant Supervision (DS), which allows the automatic creation of new datasets\nby taking an alignment between a text corpus and a Knowledge Base (KB). KBs can\nsometimes also provide additional information to the RE task. One of the\nmethods that adopt this strategy is the RESIDE model, which proposes a\ndistantly-supervised neural relation extraction using side information from\nKBs. Considering that this method outperformed state-of-the-art baselines, in\nthis paper, we propose a related approach to RESIDE also using additional side\ninformation, but simplifying the sentence encoding with BERT embeddings.\nThrough experiments, we show the effectiveness of the proposed method in Google\nDistant Supervision and Riedel datasets concerning the BGWA and RESIDE baseline\nmethods. Although Area Under the Curve is decreased because of unbalanced\ndatasets, P@N results have shown that the use of BERT as sentence encoding\nallows superior performance to baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 19:29:10 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 21:45:15 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 20:30:34 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Moreira", "Johny", ""], ["Oliveira", "Chaina", ""], ["Mac\u00eado", "David", ""], ["Zanchettin", "Cleber", ""], ["Barbosa", "Luciano", ""]]}, {"id": "2004.14444", "submitter": "John Miller", "authors": "John Miller, Karl Krauth, Benjamin Recht, Ludwig Schmidt", "title": "The Effect of Natural Distribution Shift on Question Answering Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build four new test sets for the Stanford Question Answering Dataset\n(SQuAD) and evaluate the ability of question-answering systems to generalize to\nnew data. Our first test set is from the original Wikipedia domain and measures\nthe extent to which existing systems overfit the original test set. Despite\nseveral years of heavy test set re-use, we find no evidence of adaptive\noverfitting. The remaining three test sets are constructed from New York Times\narticles, Reddit posts, and Amazon product reviews and measure robustness to\nnatural distribution shifts. Across a broad range of models, we observe average\nperformance drops of 3.8, 14.0, and 17.4 F1 points, respectively. In contrast,\na strong human baseline matches or exceeds the performance of SQuAD models on\nthe original domain and exhibits little to no drop in new domains. Taken\ntogether, our results confirm the surprising resilience of the holdout method\nand emphasize the need to move towards evaluation metrics that incorporate\nrobustness to natural distribution shifts.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 19:34:19 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Miller", "John", ""], ["Krauth", "Karl", ""], ["Recht", "Benjamin", ""], ["Schmidt", "Ludwig", ""]]}, {"id": "2004.14475", "submitter": "Burkhard Hoppenstedt", "authors": "Burkhard Hoppenstedt, Manfred Reichert, Ghada El-Khawaga, Klaus\n  Kammerer, Karl-Michael Winter, R\\\"udiger Pryss", "title": "Detecting Production Phases Based on Sensor Values using 1D-CNNs", "comments": "2 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Industry 4.0, the knowledge extraction from sensor\ninformation plays an important role. Often, information gathered from sensor\nvalues reveals meaningful insights for production levels, such as anomalies or\nmachine states. In our use case, we identify production phases through the\ninspection of sensor values with the help of convolutional neural networks. The\ndata set stems from a tempering furnace used for metal heat treating. Our\nsupervised learning approach unveils a promising accuracy for the chosen neural\nnetwork that was used for the detection of production phases. We consider\nsolutions like shown in this work as salient pillars in the field of predictive\nmaintenance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 00:45:48 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Hoppenstedt", "Burkhard", ""], ["Reichert", "Manfred", ""], ["El-Khawaga", "Ghada", ""], ["Kammerer", "Klaus", ""], ["Winter", "Karl-Michael", ""], ["Pryss", "R\u00fcdiger", ""]]}, {"id": "2004.14476", "submitter": "Jaehoon Oh", "authors": "Gihun Lee, Sangmin Bae, Jaehoon Oh, Se-Young Yun", "title": "SIPA: A Simple Framework for Efficient Networks", "comments": "14 pages, 9 figures", "journal-ref": "20th International Conference on Data Mining Workshops, 2020,\n  729-736", "doi": "10.1109/ICDMW51313.2020.00105", "report-no": null, "categories": "cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep learning in various fields and the advent of\nnumerous Internet of Things (IoT) devices, it is essential to lighten models\nsuitable for low-power devices. In keeping with this trend, MicroNet Challenge,\nwhich is the challenge to build efficient models from the view of both storage\nand computation, was hosted at NeurIPS 2019. To develop efficient models\nthrough this challenge, we propose a framework, coined as SIPA, consisting of\nfour stages: Searching, Improving, Pruning, and Accelerating. With the proposed\nframework, our team, OSI AI, compressed 334x the parameter storage and 357x the\nmath operation compared to WideResNet-28-10 and took 4th place in the CIFAR-100\ntrack at MicroNet Challenge 2019 with the top 10% highly efficient computation.\nOur source code is available from https://github.com/Lee-Gihun/MicroNet_OSI-AI.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 06:39:15 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Lee", "Gihun", ""], ["Bae", "Sangmin", ""], ["Oh", "Jaehoon", ""], ["Yun", "Se-Young", ""]]}, {"id": "2004.14477", "submitter": "Eric Goodman", "authors": "Eric L. Goodman, Chase Zimmerman, Corey Hudson", "title": "Packet2Vec: Utilizing Word2Vec for Feature Extraction in Packet Data", "comments": "MLDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of deep learning's attractive benefits is the ability to automatically\nextract relevant features for a target problem from largely raw data, instead\nof utilizing human engineered and error prone handcrafted features. While deep\nlearning has shown success in fields such as image classification and natural\nlanguage processing, its application for feature extraction on raw network\npacket data for intrusion detection is largely unexplored. In this paper we\nmodify a Word2Vec approach, used for text processing, and apply it to packet\ndata for automatic feature extraction. We call this approach Packet2Vec. For\nthe classification task of benign versus malicious traffic on a 2009 DARPA\nnetwork data set, we obtain an area under the curve (AUC) of the receiver\noperating characteristic (ROC) between 0.988-0.996 and an AUC of the\nPrecision/Recall curve between 0.604-0.667.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 21:03:48 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Goodman", "Eric L.", ""], ["Zimmerman", "Chase", ""], ["Hudson", "Corey", ""]]}, {"id": "2004.14479", "submitter": "Marco Henrique de Almeida In\\'acio", "authors": "Marco H A In\\'acio", "title": "Monte Carlo simulation studies on Python using the sstudy package with\n  SQL databases as storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Performance assessment is a key issue in the process of proposing new machine\nlearning/statistical estimators. A possible method to complete such task is by\nusing simulation studies, which can be defined as the procedure of estimating\nand comparing properties (such as predictive power) of estimators (and other\nstatistics) by averaging over many replications given a true distribution;\ni.e.: generating a dataset, fitting the estimator, calculating and storing the\npredictive power, and then repeating the procedure many times and finally\naveraging over the stored predictive powers. Given that, in this paper, we\npresent sstudy: a Python package designed to simplify the preparation of\nsimulation studies using SQL database engines as the storage system; more\nspecifically, we present its basic features, usage examples and references to\nthe its documentation. We also present a short statistical description of the\nsimulation study procedure with a simplified explanation of what is being\nestimated by it, as well as some examples of applications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 20:49:43 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:23:15 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 12:49:31 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["In\u00e1cio", "Marco H A", ""]]}, {"id": "2004.14480", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Prasanna Sattigeri, Deepta Rajan and Bindya\n  Venkatesh", "title": "Calibrating Healthcare AI: Towards Reliable and Interpretable Deep\n  Predictive Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide-spread adoption of representation learning technologies in clinical\ndecision making strongly emphasizes the need for characterizing model\nreliability and enabling rigorous introspection of model behavior. While the\nformer need is often addressed by incorporating uncertainty quantification\nstrategies, the latter challenge is addressed using a broad class of\ninterpretability techniques. In this paper, we argue that these two objectives\nare not necessarily disparate and propose to utilize prediction calibration to\nmeet both objectives. More specifically, our approach is comprised of a\ncalibration-driven learning method, which is also used to design an\ninterpretability technique based on counterfactual reasoning. Furthermore, we\nintroduce \\textit{reliability plots}, a holistic evaluation mechanism for model\nreliability. Using a lesion classification problem with dermoscopy images, we\ndemonstrate the effectiveness of our approach and infer interesting insights\nabout the model behavior.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 22:15:17 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Sattigeri", "Prasanna", ""], ["Rajan", "Deepta", ""], ["Venkatesh", "Bindya", ""]]}, {"id": "2004.14487", "submitter": "Matthew Purri", "authors": "Matthew Purri and Kristin Dana", "title": "Teaching Cameras to Feel: Estimating Tactile Physical Properties of\n  Surfaces From Images", "comments": "19 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection between visual input and tactile sensing is critical for\nobject manipulation tasks such as grasping and pushing. In this work, we\nintroduce the challenging task of estimating a set of tactile physical\nproperties from visual information. We aim to build a model that learns the\ncomplex mapping between visual information and tactile physical properties. We\nconstruct a first of its kind image-tactile dataset with over 400 multiview\nimage sequences and the corresponding tactile properties. A total of fifteen\ntactile physical properties across categories including friction, compliance,\nadhesion, texture, and thermal conductance are measured and then estimated by\nour models. We develop a cross-modal framework comprised of an adversarial\nobjective and a novel visuo-tactile joint classification loss. Additionally, we\ndevelop a neural architecture search framework capable of selecting optimal\ncombinations of viewing angles for estimating a given physical property.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 21:27:26 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 16:43:34 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Purri", "Matthew", ""], ["Dana", "Kristin", ""]]}, {"id": "2004.14491", "submitter": "Shruti Agarwal", "authors": "Shruti Agarwal (1), Tarek El-Gaaly (2), Hany Farid (1), Ser-Nam Lim\n  (2) ((1) Univeristy of California, Berkeley, Berkeley, CA, USA, (2) Facebook\n  Research, New York, NY, USA)", "title": "Detecting Deep-Fake Videos from Appearance and Behavior", "comments": null, "journal-ref": "IEEE Workshop on Image Forensics and Security, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetically-generated audios and videos -- so-called deep fakes -- continue\nto capture the imagination of the computer-graphics and computer-vision\ncommunities. At the same time, the democratization of access to technology that\ncan create sophisticated manipulated video of anybody saying anything continues\nto be of concern because of its power to disrupt democratic elections, commit\nsmall to large-scale fraud, fuel dis-information campaigns, and create\nnon-consensual pornography. We describe a biometric-based forensic technique\nfor detecting face-swap deep fakes. This technique combines a static biometric\nbased on facial recognition with a temporal, behavioral biometric based on\nfacial expressions and head movements, where the behavioral embedding is\nlearned using a CNN with a metric-learning objective function. We show the\nefficacy of this approach across several large-scale video datasets, as well as\nin-the-wild deep fakes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 21:38:22 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Agarwal", "Shruti", ""], ["El-Gaaly", "Tarek", ""], ["Farid", "Hany", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "2004.14500", "submitter": "Jung Taehee", "authors": "Taehee Jung, Dongyeop Kang, Hua Cheng, Lucas Mentch, Thomas Schaaf", "title": "Posterior Calibrated Training on Sentence Classification Tasks", "comments": "Accepted at ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most classification models work by first predicting a posterior probability\ndistribution over all classes and then selecting that class with the largest\nestimated probability. In many settings however, the quality of posterior\nprobability itself (e.g., 65% chance having diabetes), gives more reliable\ninformation than the final predicted class alone. When these methods are shown\nto be poorly calibrated, most fixes to date have relied on posterior\ncalibration, which rescales the predicted probabilities but often has little\nimpact on final classifications. Here we propose an end-to-end training\nprocedure called posterior calibrated (PosCal) training that directly optimizes\nthe objective while minimizing the difference between the predicted and\nempirical posterior probabilities.We show that PosCal not only helps reduce the\ncalibration error but also improve task performance by penalizing drops in\nperformance of both objectives. Our PosCal achieves about 2.5% of task\nperformance gain and 16.1% of calibration error reduction on GLUE (Wang et al.,\n2018) compared to the baseline. We achieved the comparable task performance\nwith 13.2% calibration error reduction on xSLUE (Kang and Hovy, 2019), but not\noutperforming the two-stage calibration baseline. PosCal training can be easily\nextendable to any types of classification tasks as a form of regularization\nterm. Also, PosCal has the advantage that it incrementally tracks needed\nstatistics for the calibration objective during the training process, making\nefficient use of large training sets.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 22:13:15 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:26:16 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Jung", "Taehee", ""], ["Kang", "Dongyeop", ""], ["Cheng", "Hua", ""], ["Mentch", "Lucas", ""], ["Schaaf", "Thomas", ""]]}, {"id": "2004.14501", "submitter": "Sayak Mukherjee", "authors": "Sayak Mukherjee, He Bai, Aranya Chakrabortty", "title": "Reduced-Dimensional Reinforcement Learning Control using Singular\n  Perturbation Approximations", "comments": null, "journal-ref": "Automatica 2021 (full version with proofs)", "doi": "10.1016/j.automatica.2020.109451", "report-no": null, "categories": "eess.SY cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of model-free, reduced-dimensional reinforcement learning\n(RL) based optimal control designs for linear time-invariant singularly\nperturbed (SP) systems. We first present a state-feedback and output-feedback\nbased RL control design for a generic SP system with unknown state and input\nmatrices. We take advantage of the underlying time-scale separation property of\nthe plant to learn a linear quadratic regulator (LQR) for only its slow\ndynamics, thereby saving a significant amount of learning time compared to the\nconventional full-dimensional RL controller. We analyze the sub-optimality of\nthe design using SP approximation theorems and provide sufficient conditions\nfor closed-loop stability. Thereafter, we extend both designs to clustered\nmulti-agent consensus networks, where the SP property reflects through\nclustering. We develop both centralized and cluster-wise block-decentralized RL\ncontrollers for such networks, in reduced dimensions. We demonstrate the\ndetails of the implementation of these controllers using simulations of\nrelevant numerical examples and compare them with conventional RL designs to\nshow the computational benefits of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 22:15:54 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Mukherjee", "Sayak", ""], ["Bai", "He", ""], ["Chakrabortty", "Aranya", ""]]}, {"id": "2004.14507", "submitter": "Qingfu Zhu", "authors": "Qingfu Zhu, Weinan Zhang, Ting Liu, William Yang Wang", "title": "Counterfactual Off-Policy Training for Neural Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-domain dialogue generation suffers from the data insufficiency problem\ndue to the vast size of potential responses. In this paper, we propose to\nexplore potential responses by counterfactual reasoning. Given an observed\nresponse, the counterfactual reasoning model automatically infers the outcome\nof an alternative policy that could have been taken. The resulting\ncounterfactual response synthesized in hindsight is of higher quality than the\nresponse synthesized from scratch. Training on the counterfactual responses\nunder the adversarial learning framework helps to explore the high-reward area\nof the potential response space. An empirical study on the DailyDialog dataset\nshows that our approach significantly outperforms the HRED model as well as the\nconventional adversarial learning approaches.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 22:46:28 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 07:47:45 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Zhu", "Qingfu", ""], ["Zhang", "Weinan", ""], ["Liu", "Ting", ""], ["Wang", "William Yang", ""]]}, {"id": "2004.14514", "submitter": "Hiroki Ouchi", "authors": "Hiroki Ouchi, Jun Suzuki, Sosuke Kobayashi, Sho Yokoi, Tatsuki\n  Kuribayashi, Ryuto Konno, Kentaro Inui", "title": "Instance-Based Learning of Span Representations: A Case Study through\n  Named Entity Recognition", "comments": "Accepted by ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable rationales for model predictions play a critical role in\npractical applications. In this study, we develop models possessing\ninterpretable inference process for structured prediction. Specifically, we\npresent a method of instance-based learning that learns similarities between\nspans. At inference time, each span is assigned a class label based on its\nsimilar spans in the training set, where it is easy to understand how much each\ntraining instance contributes to the predictions. Through empirical analysis on\nnamed entity recognition, we demonstrate that our method enables to build\nmodels that have high interpretability without sacrificing performance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 23:32:42 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Ouchi", "Hiroki", ""], ["Suzuki", "Jun", ""], ["Kobayashi", "Sosuke", ""], ["Yokoi", "Sho", ""], ["Kuribayashi", "Tatsuki", ""], ["Konno", "Ryuto", ""], ["Inui", "Kentaro", ""]]}, {"id": "2004.14528", "submitter": "Jugurta Montalv\\~ao", "authors": "Jugurta Montalv\\~ao, J\\^anio Canuto, Luiz Miranda", "title": "Bias-corrected estimator for intrinsic dimension and differential\n  entropy--a visual multiscale approach", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.IT cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsic dimension and differential entropy estimators are studied in this\npaper, including their systematic bias. A pragmatic approach for joint\nestimation and bias correction of these two fundamental measures is proposed.\nShared steps on both estimators are highlighted, along with their useful\nconsequences to data analysis. It is shown that both estimators can be\ncomplementary parts of a single approach, and that the simultaneous estimation\nof differential entropy and intrinsic dimension give meaning to each other,\nwhere estimates at different observation scales convey different perspectives\nof underlying manifolds. Experiments with synthetic and real datasets are\npresented to illustrate how to extract meaning from visual inspections, and how\nto compensate for biases.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 00:29:28 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Montalv\u00e3o", "Jugurta", ""], ["Canuto", "J\u00e2nio", ""], ["Miranda", "Luiz", ""]]}, {"id": "2004.14539", "submitter": "Zihang Meng", "authors": "Zihang Meng, Sathya N. Ravi, Vikas Singh", "title": "Physarum Powered Differentiable Linear Programming Layers and\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a learning algorithm, which involves an internal call to an\noptimization routine such as a generalized eigenvalue problem, a cone\nprogramming problem or even sorting. Integrating such a method as a layer(s)\nwithin a trainable deep neural network (DNN) in an efficient and numerically\nstable way is not straightforward -- for instance, only recently, strategies\nhave emerged for eigendecomposition and differentiable sorting. We propose an\nefficient and differentiable solver for general linear programming problems\nwhich can be used in a plug and play manner within DNNs as a layer. Our\ndevelopment is inspired by a fascinating but not widely used link between\ndynamics of slime mold (physarum) and optimization schemes such as steepest\ndescent. We describe our development and show the use of our solver in a video\nsegmentation task and meta-learning for few-shot learning. We review the\nexisting results and provide a technical analysis describing its applicability\nfor our use cases. Our solver performs comparably with a customized projected\ngradient descent method on the first task and outperforms the differentiable\nCVXPY-SCS solver on the second task. Experiments show that our solver converges\nquickly without the need for a feasible initial point. Our proposal is easy to\nimplement and can easily serve as layers whenever a learning procedure needs a\nfast approximate solution to a LP, within a larger network.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 01:50:37 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 17:21:06 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Meng", "Zihang", ""], ["Ravi", "Sathya N.", ""], ["Singh", "Vikas", ""]]}, {"id": "2004.14541", "submitter": "Andreas Kipf", "authors": "Andreas Kipf, Ryan Marcus, Alexander van Renen, Mihail Stoian, Alfons\n  Kemper, Tim Kraska, Thomas Neumann", "title": "RadixSpline: A Single-Pass Learned Index", "comments": "Third International Workshop on Exploiting Artificial Intelligence\n  Techniques for Data Management (aiDM 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that learned models can outperform state-of-the-art\nindex structures in size and lookup performance. While this is a very promising\nresult, existing learned structures are often cumbersome to implement and are\nslow to build. In fact, most approaches that we are aware of require multiple\ntraining passes over the data.\n  We introduce RadixSpline (RS), a learned index that can be built in a single\npass over the data and is competitive with state-of-the-art learned index\nmodels, like RMI, in size and lookup performance. We evaluate RS using the SOSD\nbenchmark and show that it achieves competitive results on all datasets,\ndespite the fact that it only has two parameters.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 01:56:54 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 21:01:04 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Kipf", "Andreas", ""], ["Marcus", "Ryan", ""], ["van Renen", "Alexander", ""], ["Stoian", "Mihail", ""], ["Kemper", "Alfons", ""], ["Kraska", "Tim", ""], ["Neumann", "Thomas", ""]]}, {"id": "2004.14545", "submitter": "Ning Xie", "authors": "Ning Xie, Gabrielle Ras, Marcel van Gerven, Derek Doran", "title": "Explainable Deep Learning: A Field Guide for the Uninitiated", "comments": "Survey paper on Explainable Deep Learning, 54 pages including\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) is an indispensable machine learning tool for\nachieving human-level performance on many learning tasks. Yet, due to its\nblack-box nature, it is inherently difficult to understand which aspects of the\ninput data drive the decisions of the network. There are various real-world\nscenarios in which humans need to make actionable decisions based on the output\nDNNs. Such decision support systems can be found in critical domains, such as\nlegislation, law enforcement, etc. It is important that the humans making\nhigh-level decisions can be sure that the DNN decisions are driven by\ncombinations of data features that are appropriate in the context of the\ndeployment of the decision support system and that the decisions made are\nlegally or ethically defensible. Due to the incredible pace at which DNN\ntechnology is being developed, the development of new methods and studies on\nexplaining the decision-making process of DNNs has blossomed into an active\nresearch field. A practitioner beginning to study explainable deep learning may\nbe intimidated by the plethora of orthogonal directions the field is taking.\nThis complexity is further exacerbated by the general confusion that exists in\ndefining what it means to be able to explain the actions of a deep learning\nsystem and to evaluate a system's \"ability to explain\". To alleviate this\nproblem, this article offers a \"field guide\" to deep learning explainability\nfor those uninitiated in the field. The field guide: i) Discusses the traits of\na deep learning system that researchers enhance in explainability research, ii)\nplaces explainability in the context of other related deep learning research\nareas, and iii) introduces three simple dimensions defining the space of\nfoundational methods that contribute to explainable deep learning. The guide is\ndesigned as an easy-to-digest starting point for those just embarking in the\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:09:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Xie", "Ning", ""], ["Ras", "Gabrielle", ""], ["van Gerven", "Marcel", ""], ["Doran", "Derek", ""]]}, {"id": "2004.14546", "submitter": "Sharan Narang", "authors": "Sharan Narang, Colin Raffel, Katherine Lee, Adam Roberts, Noah Fiedel,\n  Karishma Malkan", "title": "WT5?! Training Text-to-Text Models to Explain their Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have recently achieved human-level performance on various\nchallenging natural language processing (NLP) tasks, but it is notoriously\ndifficult to understand why a neural network produced a particular prediction.\nIn this paper, we leverage the text-to-text framework proposed by Raffel et\nal.(2019) to train language models to output a natural text explanation\nalongside their prediction. Crucially, this requires no modifications to the\nloss function or training and decoding procedures -- we simply train the model\nto output the explanation after generating the (natural text) prediction. We\nshow that this approach not only obtains state-of-the-art results on\nexplainability benchmarks, but also permits learning from a limited set of\nlabeled explanations and transferring rationalization abilities across\ndatasets. To facilitate reproducibility and future work, we release our code\nuse to train the models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:20:14 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Narang", "Sharan", ""], ["Raffel", "Colin", ""], ["Lee", "Katherine", ""], ["Roberts", "Adam", ""], ["Fiedel", "Noah", ""], ["Malkan", "Karishma", ""]]}, {"id": "2004.14547", "submitter": "Xiaoteng Ma", "authors": "Xiaoteng Ma, Li Xia, Zhengyuan Zhou, Jun Yang, Qianchuan Zhao", "title": "DSAC: Distributional Soft Actor Critic for Risk-Sensitive Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new reinforcement learning (RL) algorithm called\nDistributional Soft Actor Critic (DSAC), which exploits the distributional\ninformation of accumulated rewards to achieve better performance. Seamlessly\nintegrating SAC (which uses entropy to encourage exploration) with a principled\ndistributional view of the underlying objective, DSAC takes into consideration\nthe randomness in both action and rewards, and beats the state-of-the-art\nbaselines in several continuous control benchmarks. Moreover, with the\ndistributional information of rewards, we propose a unified framework for\nrisk-sensitive learning, one that goes beyond maximizing only expected\naccumulated rewards. Under this framework we discuss three specific\nrisk-related metrics: percentile, mean-variance and distorted expectation. Our\nextensive experiments demonstrate that with distribution modeling in RL, the\nagent performs better for both risk-averse and risk-seeking control tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 02:23:15 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 02:08:35 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ma", "Xiaoteng", ""], ["Xia", "Li", ""], ["Zhou", "Zhengyuan", ""], ["Yang", "Jun", ""], ["Zhao", "Qianchuan", ""]]}, {"id": "2004.14566", "submitter": "Yuhui Xu", "authors": "Yuhui Xu, Yuxi Li, Shuai Zhang, Wei Wen, Botao Wang, Yingyong Qi,\n  Yiran Chen, Weiyao Lin, Hongkai Xiong", "title": "TRP: Trained Rank Pruning for Efficient Deep Neural Networks", "comments": "Accepted by IJCAI2020, An extension version of arXiv:1812.02402", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable DNNs on edge devices like mobile phones, low-rank approximation has\nbeen widely adopted because of its solid theoretical rationale and efficient\nimplementations. Several previous works attempted to directly approximate a\npretrained model by low-rank decomposition; however, small approximation errors\nin parameters can ripple over a large prediction loss. As a result, performance\nusually drops significantly and a sophisticated effort on fine-tuning is\nrequired to recover accuracy. Apparently, it is not optimal to separate\nlow-rank approximation from training. Unlike previous works, this paper\nintegrates low rank approximation and regularization into the training process.\nWe propose Trained Rank Pruning (TRP), which alternates between low rank\napproximation and training. TRP maintains the capacity of the original network\nwhile imposing low-rank constraints during training. A nuclear regularization\noptimized by stochastic sub-gradient descent is utilized to further promote low\nrank in TRP. The TRP trained network inherently has a low-rank structure, and\nis approximated with negligible performance loss, thus eliminating the\nfine-tuning process after low rank decomposition. The proposed method is\ncomprehensively evaluated on CIFAR-10 and ImageNet, outperforming previous\ncompression methods using low rank approximation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:37:36 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Xu", "Yuhui", ""], ["Li", "Yuxi", ""], ["Zhang", "Shuai", ""], ["Wen", "Wei", ""], ["Wang", "Botao", ""], ["Qi", "Yingyong", ""], ["Chen", "Yiran", ""], ["Lin", "Weiyao", ""], ["Xiong", "Hongkai", ""]]}, {"id": "2004.14567", "submitter": "Max Pflueger", "authors": "Max Pflueger and Gaurav S. Sukhatme", "title": "Plan-Space State Embeddings for Improved Reinforcement Learning", "comments": "Submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot control problems are often structured with a policy function that maps\nstate values into control values, but in many dynamic problems the observed\nstate can have a difficult to characterize relationship with useful policy\nactions. In this paper we present a new method for learning state embeddings\nfrom plans or other forms of demonstrations such that the embedding space has a\nspecified geometric relationship with the demonstrations. We present a novel\nvariational framework for learning these embeddings that attempts to optimize\ntrajectory linearity in the learned embedding space. We show how these\nembedding spaces can then be used as an augmentation to the robot state in\nreinforcement learning problems. We use kinodynamic planning to generate\ntraining trajectories for some example environments, and then train embedding\nspaces for these environments. We show empirically that observing a system in\nthe learned embedding space improves the performance of policy gradient\nreinforcement learning algorithms, particularly by reducing the variance\nbetween training runs. Our technique is limited to environments where\ndemonstration data is available, but places no limits on how that data is\ncollected. Our embedding technique provides a way to transfer domain knowledge\nfrom existing technologies such as planning and control algorithms, into more\nflexible policy learning algorithms, by creating an abstract representation of\nthe robot state with meaningful geometry.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:38:14 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Pflueger", "Max", ""], ["Sukhatme", "Gaurav S.", ""]]}, {"id": "2004.14569", "submitter": "Jiangning Zhang", "authors": "Jiangning Zhang, Liang Liu, Zhucun Xue, Yong Liu", "title": "APB2Face: Audio-guided face reenactment with auxiliary pose and blink\n  signals", "comments": "ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio-guided face reenactment aims at generating photorealistic faces using\naudio information while maintaining the same facial movement as when speaking\nto a real person. However, existing methods can not generate vivid face images\nor only reenact low-resolution faces, which limits the application value. To\nsolve those problems, we propose a novel deep neural network named APB2Face,\nwhich consists of GeometryPredictor and FaceReenactor modules.\nGeometryPredictor uses extra head pose and blink state signals as well as audio\nto predict the latent landmark geometry information, while FaceReenactor inputs\nthe face landmark image to reenact the photorealistic face. A new dataset AnnVI\ncollected from YouTube is presented to support the approach, and experimental\nresults indicate the superiority of our method than state-of-the-arts, whether\nin authenticity or controllability.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 03:44:35 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Zhang", "Jiangning", ""], ["Liu", "Liang", ""], ["Xue", "Zhucun", ""], ["Liu", "Yong", ""]]}, {"id": "2004.14580", "submitter": "Md Navid Akbar", "authors": "Md Navid Akbar, Marianna La Rocca, Rachael Garner, Dominique Duncan,\n  Deniz Erdo\\u{g}mu\\c{s}", "title": "Prediction of Epilepsy Development in Traumatic Brain Injury Patients\n  from Diffusion Weighted MRI", "comments": "2 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-traumatic epilepsy (PTE) is a life-long complication of traumatic brain\ninjury (TBI) and is a major public health problem that has an estimated\nincidence that ranges from 2%-50%, depending on the severity of the TBI.\nCurrently, the pathomechanism that in-duces epileptogenesis in TBI patients is\nunclear, and one of the most challenging goals in the epilepsy community is to\npredict which TBI patients will develop epilepsy. In this work, we used\ndiffusion-weighted imaging (DWI) of 14 TBI patients recruited in the Epilepsy\nBioinformatics Study for Antiepileptogenic Therapy (EpiBioS4Rx)to measure and\nanalyze fractional anisotropy (FA), obtained from tract-based spatial statistic\n(TBSS) analysis. Then we used these measurements to train two support vector\nmachine (SVM) models to predict which TBI patients have developed epilepsy. Our\napproach, tested on these 14 patients with a leave-two-out cross-validation,\nallowed us to obtain an accuracy of 0.857 $\\pm$ 0.18 (with a 95% level of\nconfidence), demonstrating it to be potentially promising for the early\ncharacterization of PTE.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 04:06:24 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 22:22:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Akbar", "Md Navid", ""], ["La Rocca", "Marianna", ""], ["Garner", "Rachael", ""], ["Duncan", "Dominique", ""], ["Erdo\u011fmu\u015f", "Deniz", ""]]}, {"id": "2004.14584", "submitter": "Ragav Venkatesan", "authors": "Ragav Venkatesan, Gurumurthy Swaminathan, Xiong Zhou, Anna Luo", "title": "Out-of-the-box channel pruned networks", "comments": "Under review at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade convolutional neural networks have become gargantuan.\nPre-trained models, when used as initializers are able to fine-tune ever larger\nnetworks on small datasets. Consequently, not all the convolutional features\nthat these fine-tuned models detect are requisite for the end-task. Several\nworks of channel pruning have been proposed to prune away compute and memory\nfrom models that were trained already. Typically, these involve policies that\ndecide which and how many channels to remove from each layer leading to\nchannel-wise and/or layer-wise pruning profiles, respectively. In this paper,\nwe conduct several baseline experiments and establish that profiles from random\nchannel-wise pruning policies are as good as metric-based ones. We also\nestablish that there may exist profiles from some layer-wise pruning policies\nthat are measurably better than common baselines. We then demonstrate that the\ntop layer-wise pruning profiles found using an exhaustive random search from\none datatset are also among the top profiles for other datasets. This implies\nthat we could identify out-of-the-box layer-wise pruning profiles using\nbenchmark datasets and use these directly for new datasets. Furthermore, we\ndevelop a Reinforcement Learning (RL) policy-based search algorithm with a\ndirect objective of finding transferable layer-wise pruning profiles using many\nmodels for the same architecture. We use a novel reward formulation that drives\nthis RL search towards an expected compression while maximizing accuracy. Our\nresults show that our transferred RL-based profiles are as good or better than\nbest profiles found on the original dataset via exhaustive search. We then\ndemonstrate that if we found the profiles using a mid-sized dataset such as\nCifar10/100, we are able to transfer them to even a large dataset such as\nImagenet.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 04:40:47 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Venkatesan", "Ragav", ""], ["Swaminathan", "Gurumurthy", ""], ["Zhou", "Xiong", ""], ["Luo", "Anna", ""]]}, {"id": "2004.14589", "submitter": "Daniel Kang", "authors": "Daniel Kang and Tatsunori Hashimoto", "title": "Improved Natural Language Generation via Loss Truncation", "comments": "ACL 2020 Camera Ready Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural language models are usually trained to match the distributional\nproperties of a large-scale corpus by minimizing the log loss. While\nstraightforward to optimize, this approach forces the model to reproduce all\nvariations in the dataset, including noisy and invalid references (e.g.,\nmisannotation and hallucinated facts). Worse, the commonly used log loss is\noverly sensitive to such phenomena and even a small fraction of noisy data can\ndegrade performance. In this work, we show that the distinguishability of the\nmodels and reference serves as a principled and robust alternative for handling\ninvalid references. To optimize distinguishability, we propose loss truncation,\nwhich adaptively removes high loss examples during training. We show this is as\neasy to optimize as log loss and tightly bounds distinguishability under noise.\nEmpirically, we demonstrate that loss truncation outperforms existing baselines\non distinguishability on a summarization task, and show that samples generated\nby the loss truncation model have factual accuracy ratings that exceed those of\nbaselines and match human references.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 05:31:31 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 02:22:04 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Kang", "Daniel", ""], ["Hashimoto", "Tatsunori", ""]]}, {"id": "2004.14593", "submitter": "Xi-Lin Li", "authors": "Xi-Lin Li", "title": "A Triangular Network For Density Estimation", "comments": "Supplements like code at https://github.com/lixilinx/TriNet4PdfEst", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a triangular neural network implementation of neural autoregressive\nflow (NAF). Unlike many universal autoregressive density models, our design is\nhighly modular, parameter economy, computationally efficient, and applicable to\ndensity estimation of data with high dimensions. It achieves state-of-the-art\nbits-per-dimension indices on MNIST and CIFAR-10 (about 1.1 and 3.7,\nrespectively) in the category of general-purpose density estimators.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 06:01:40 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 05:12:09 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Li", "Xi-Lin", ""]]}, {"id": "2004.14603", "submitter": "Thao Minh Le", "authors": "Thao Minh Le, Vuong Le, Svetha Venkatesh, Truyen Tran", "title": "Dynamic Language Binding in Relational Visual Reasoning", "comments": "Early version accepted by IJCAI20, Code available at\n  https://github.com/thaolmk54/LOGNet-VQA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Language-binding Object Graph Network, the first neural reasoning\nmethod with dynamic relational structures across both visual and textual\ndomains with applications in visual question answering. Relaxing the common\nassumption made by current models that the object predicates pre-exist and stay\nstatic, passive to the reasoning process, we propose that these dynamic\npredicates expand across the domain borders to include pair-wise\nvisual-linguistic object binding. In our method, these contextualized object\nlinks are actively found within each recurrent reasoning step without relying\non external predicative priors. These dynamic structures reflect the\nconditional dual-domain object dependency given the evolving context of the\nreasoning through co-attention. Such discovered dynamic graphs facilitate\nmulti-step knowledge combination and refinements that iteratively deduce the\ncompact representation of the final answer. The effectiveness of this model is\ndemonstrated on image question answering demonstrating favorable performance on\nmajor VQA datasets. Our method outperforms other methods in sophisticated\nquestion-answering tasks wherein multiple object relations are involved. The\ngraph structure effectively assists the progress of training, and therefore the\nnetwork learns efficiently compared to other reasoning models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 06:26:20 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 01:24:55 GMT"}, {"version": "v3", "created": "Thu, 18 Feb 2021 03:35:24 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Le", "Thao Minh", ""], ["Le", "Vuong", ""], ["Venkatesh", "Svetha", ""], ["Tran", "Truyen", ""]]}, {"id": "2004.14619", "submitter": "Zheng Tang", "authors": "Milind Naphade, Shuo Wang, David Anastasiu, Zheng Tang, Ming-Ching\n  Chang, Xiaodong Yang, Liang Zheng, Anuj Sharma, Rama Chellappa, Pranamesh\n  Chakraborty", "title": "The 4th AI City Challenge", "comments": "Organization summary of the 4th AI City Challenge Workshop @ CVPR\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI City Challenge was created to accelerate intelligent video analysis\nthat helps make cities smarter and safer. Transportation is one of the largest\nsegments that can benefit from actionable insights derived from data captured\nby sensors, where computer vision and deep learning have shown promise in\nachieving large-scale practical deployment. The 4th annual edition of the AI\nCity Challenge has attracted 315 participating teams across 37 countries, who\nleveraged city-scale real traffic data and high-quality synthetic data to\ncompete in four challenge tracks. Track 1 addressed video-based automatic\nvehicle counting, where the evaluation is conducted on both algorithmic\neffectiveness and computational efficiency. Track 2 addressed city-scale\nvehicle re-identification with augmented synthetic data to substantially\nincrease the training set for the task. Track 3 addressed city-scale\nmulti-target multi-camera vehicle tracking. Track 4 addressed traffic anomaly\ndetection. The evaluation system shows two leader boards, in which a general\nleader board shows all submitted results, and a public leader board shows\nresults limited to our contest participation rules, that teams are not allowed\nto use external data in their work. The public leader board shows results more\nclose to real-world situations where annotated data are limited. Our results\nshow promise that AI technology can enable smarter and safer transportation\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 07:47:14 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Naphade", "Milind", ""], ["Wang", "Shuo", ""], ["Anastasiu", "David", ""], ["Tang", "Zheng", ""], ["Chang", "Ming-Ching", ""], ["Yang", "Xiaodong", ""], ["Zheng", "Liang", ""], ["Sharma", "Anuj", ""], ["Chellappa", "Rama", ""], ["Chakraborty", "Pranamesh", ""]]}, {"id": "2004.14637", "submitter": "Martin Hellkvist", "authors": "Martin Hellkvist and Ay\\c{c}a \\\"Oz\\c{c}elikkale and Anders Ahl\\'en", "title": "Generalization Error for Linear Regression under Distributed Learning", "comments": "Comments: updated typo in author list", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning facilitates the scaling-up of data processing by\ndistributing the computational burden over several nodes. Despite the vast\ninterest in distributed learning, generalization performance of such approaches\nis not well understood. We address this gap by focusing on a linear regression\nsetting. We consider the setting where the unknowns are distributed over a\nnetwork of nodes. We present an analytical characterization of the dependence\nof the generalization error on the partitioning of the unknowns over nodes. In\nparticular, for the overparameterized case, our results show that while the\nerror on training data remains in the same range as that of the centralized\nsolution, the generalization error of the distributed solution increases\ndramatically compared to that of the centralized solution when the number of\nunknowns estimated at any node is close to the number of observations. We\nfurther provide numerical examples to verify our analytical expressions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 08:49:46 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 05:23:13 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Hellkvist", "Martin", ""], ["\u00d6z\u00e7elikkale", "Ay\u00e7a", ""], ["Ahl\u00e9n", "Anders", ""]]}, {"id": "2004.14641", "submitter": "Raffaele Perego", "authors": "Claudio Lucchese, Franco Maria Nardini, Salvatore Orlando, Raffaele\n  Perego, Salvatore Trani", "title": "Query-level Early Exit for Additive Learning-to-Rank Ensembles", "comments": "Accepted at SIGIR 2020 (short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engine ranking pipelines are commonly based on large ensembles of\nmachine-learned decision trees. The tight constraints on query response time\nrecently motivated researchers to investigate algorithms to make faster the\ntraversal of the additive ensemble or to early terminate the evaluation of\ndocuments that are unlikely to be ranked among the top-k. In this paper, we\ninvestigate the novel problem of \\textit{query-level early exiting}, aimed at\ndeciding the profitability of early stopping the traversal of the ranking\nensemble for all the candidate documents to be scored for a query, by simply\nreturning a ranking based on the additive scores computed by a limited portion\nof the ensemble. Besides the obvious advantage on query latency and throughput,\nwe address the possible positive impact of query-level early exiting on ranking\neffectiveness. To this end, we study the actual contribution of incremental\nportions of the tree ensemble to the ranking of the top-k documents scored for\na given query. Our main finding is that queries exhibit different behaviors as\nscores are accumulated during the traversal of the ensemble and that\nquery-level early stopping can remarkably improve ranking quality. We present a\nreproducible and comprehensive experimental evaluation, conducted on two public\ndatasets, showing that query-level early exiting achieves an overall gain of up\nto 7.5% in terms of NDCG@10 with a speedup of the scoring process of up to\n2.2x.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 08:59:45 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lucchese", "Claudio", ""], ["Nardini", "Franco Maria", ""], ["Orlando", "Salvatore", ""], ["Perego", "Raffaele", ""], ["Trani", "Salvatore", ""]]}, {"id": "2004.14646", "submitter": "Mohammad Gheshlaghi Azar", "authors": "Daniel Guo, Bernardo Avila Pires, Bilal Piot, Jean-bastien Grill,\n  Florent Altch\\'e, R\\'emi Munos, Mohammad Gheshlaghi Azar", "title": "Bootstrap Latent-Predictive Representations for Multitask Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good representation is an essential component for deep\nreinforcement learning (RL). Representation learning is especially important in\nmultitask and partially observable settings where building a representation of\nthe unknown environment is crucial to solve the tasks. Here we introduce\nPrediction of Bootstrap Latents (PBL), a simple and flexible self-supervised\nrepresentation learning algorithm for multitask deep RL. PBL builds on\nmultistep predictive representations of future observations, and focuses on\ncapturing structured information about environment dynamics. Specifically, PBL\ntrains its representation by predicting latent embeddings of future\nobservations. These latent embeddings are themselves trained to be predictive\nof the aforementioned representations. These predictions form a bootstrapping\neffect, allowing the agent to learn more about the key aspects of the\nenvironment dynamics. In addition, by defining prediction tasks completely in\nlatent space, PBL provides the flexibility of using multimodal observations\ninvolving pixel images, language instructions, rewards and more. We show in our\nexperiments that PBL delivers across-the-board improved performance over state\nof the art deep RL agents in the DMLab-30 and Atari-57 multitask setting.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:09:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Guo", "Daniel", ""], ["Pires", "Bernardo Avila", ""], ["Piot", "Bilal", ""], ["Grill", "Jean-bastien", ""], ["Altch\u00e9", "Florent", ""], ["Munos", "R\u00e9mi", ""], ["Azar", "Mohammad Gheshlaghi", ""]]}, {"id": "2004.14652", "submitter": "Svitlana Vakulenko", "authors": "Svitlana Vakulenko, Shayne Longpre, Zhucheng Tu, Raviteja Anantha", "title": "Question Rewriting for Conversational Question Answering", "comments": "Version accepted to WSDM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational question answering (QA) requires the ability to correctly\ninterpret a question in the context of previous conversation turns. We address\nthe conversational QA task by decomposing it into question rewriting and\nquestion answering subtasks. The question rewriting (QR) subtask is\nspecifically designed to reformulate ambiguous questions, which depend on the\nconversational context, into unambiguous questions that can be correctly\ninterpreted outside of the conversational context. We introduce a\nconversational QA architecture that sets the new state of the art on the TREC\nCAsT 2019 passage retrieval dataset. Moreover, we show that the same QR model\nimproves QA performance on the QuAC dataset with respect to answer span\nextraction, which is the next step in QA after passage retrieval. Our\nevaluation results indicate that the QR model we proposed achieves near\nhuman-level performance on both datasets and the gap in performance on the\nend-to-end conversational QA task is attributed mostly to the errors in QA.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:27:43 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 11:25:55 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 09:22:49 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Vakulenko", "Svitlana", ""], ["Longpre", "Shayne", ""], ["Tu", "Zhucheng", ""], ["Anantha", "Raviteja", ""]]}, {"id": "2004.14667", "submitter": "Hassan Kane", "authors": "Hassan Kane, Muhammed Yusuf Kocyigit, Ali Abdalla, Pelkins Ajanoh,\n  Mohamed Coulibali", "title": "NUBIA: NeUral Based Interchangeability Assessor for Text Generation", "comments": "8 pages, 5 tables, and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NUBIA, a methodology to build automatic evaluation metrics for\ntext generation using only machine learning models as core components. A\ntypical NUBIA model is composed of three modules: a neural feature extractor,\nan aggregator and a calibrator. We demonstrate an implementation of NUBIA which\noutperforms metrics currently used to evaluate machine translation, summaries\nand slightly exceeds/matches state of the art metrics on correlation with human\njudgement on the WMT segment-level Direct Assessment task, sentence-level\nranking and image captioning evaluation. The model implemented is modular,\nexplainable and set to continuously improve over time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:11:33 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 09:58:56 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Kane", "Hassan", ""], ["Kocyigit", "Muhammed Yusuf", ""], ["Abdalla", "Ali", ""], ["Ajanoh", "Pelkins", ""], ["Coulibali", "Mohamed", ""]]}, {"id": "2004.14674", "submitter": "Manu Mathew", "authors": "Aniket Limaye, Manu Mathew, Soyeb Nagori, Pramod Kumar Swami,\n  Debapriya Maji, Kumar Desappan", "title": "SS3D: Single Shot 3D Object Detector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single stage deep learning algorithm for 2D object detection was made popular\nby Single Shot MultiBox Detector (SSD) and it was heavily adopted in several\nembedded applications. PointPillars is a state of the art 3D object detection\nalgorithm that uses a Single Shot Detector adapted for 3D object detection. The\nmain downside of PointPillars is that it has a two stage approach with learned\ninput representation based on fully connected layers followed by the Single\nShot Detector for 3D detection. In this paper we present Single Shot 3D Object\nDetection (SS3D) - a single stage 3D object detection algorithm which combines\nstraight forward, statistically computed input representation and a Single Shot\nDetector (based on PointPillars). Computing the input representation is\nstraight forward, does not involve learning and does not have much\ncomputational cost. We also extend our method to stereo input and show that,\naided by additional semantic segmentation input; our method produces similar\naccuracy as state of the art stereo based detectors. Achieving the accuracy of\ntwo stage detectors using a single stage approach is important as single stage\napproaches are simpler to implement in embedded, real-time applications. With\nLiDAR as well as stereo input, our method outperforms PointPillars. When using\nLiDAR input, our input representation is able to improve the AP3D of Cars\nobjects in the moderate category from 74.99 to 76.84. When using stereo input,\nour input representation is able to improve the AP3D of Cars objects in the\nmoderate category from 38.13 to 45.13. Our results are also better than other\npopular 3D object detectors such as AVOD and F-PointNet.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:28:08 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 12:33:08 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Limaye", "Aniket", ""], ["Mathew", "Manu", ""], ["Nagori", "Soyeb", ""], ["Swami", "Pramod Kumar", ""], ["Maji", "Debapriya", ""], ["Desappan", "Kumar", ""]]}, {"id": "2004.14681", "submitter": "Dylan Foster", "authors": "Dylan J. Foster, Alexander Rakhlin, Tuhin Sarkar", "title": "Learning nonlinear dynamical systems from a single trajectory", "comments": "To appear at L4DC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce algorithms for learning nonlinear dynamical systems of the form\n$x_{t+1}=\\sigma(\\Theta^{\\star}x_t)+\\varepsilon_t$, where $\\Theta^{\\star}$ is a\nweight matrix, $\\sigma$ is a nonlinear link function, and $\\varepsilon_t$ is a\nmean-zero noise process. We give an algorithm that recovers the weight matrix\n$\\Theta^{\\star}$ from a single trajectory with optimal sample complexity and\nlinear running time. The algorithm succeeds under weaker statistical\nassumptions than in previous work, and in particular i) does not require a\nbound on the spectral norm of the weight matrix $\\Theta^{\\star}$ (rather, it\ndepends on a generalization of the spectral radius) and ii) enjoys guarantees\nfor non-strictly-increasing link functions such as the ReLU. Our analysis has\ntwo key components: i) we give a general recipe whereby global stability for\nnonlinear dynamical systems can be used to certify that the state-vector\ncovariance is well-conditioned, and ii) using these tools, we extend well-known\nalgorithms for efficiently learning generalized linear models to the dependent\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 10:42:48 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Foster", "Dylan J.", ""], ["Rakhlin", "Alexander", ""], ["Sarkar", "Tuhin", ""]]}, {"id": "2004.14690", "submitter": "Fei Tang", "authors": "Fei Tang, Wanling Gao, Jianfeng Zhan, Chuanxin Lan, Xu Wen, Lei Wang,\n  Chunjie Luo, Jiahui Dai, Zheng Cao, Xingwang Xiong, Zihan Jiang, Tianshu Hao,\n  Fanda Fan, Fan Zhang, Yunyou Huang, Jianan Chen, Mengjia Du, Rui Ren, Chen\n  Zheng, Daoyi Zheng, Haoning Tang, Kunlin Zhan, Biao Wang, Defei Kong, Minghe\n  Yu, Chongkang Tan, Huan Li, Xinhui Tian, Yatao Li, Junchao Shao, Zhenyu Wang,\n  Xiaoyu Wang, and Hainan Ye", "title": "AIBench Training: Balanced Industry-Standard AI Training Benchmarking", "comments": "ISPASS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earlier-stage evaluations of a new AI architecture/system need affordable\nbenchmarks. Only using a few AI component benchmarks like MLPerfalone in the\nother stages may lead to misleading conclusions. Moreover, the learning\ndynamics are not well understood, and the benchmarks' shelf-life is short. This\npaper proposes a balanced benchmarking methodology. We use real-world\nbenchmarks to cover the factors space that impacts the learning dynamics to the\nmost considerable extent. After performing an exhaustive survey on Internet\nservice AI domains, we identify and implement nineteen representative AI tasks\nwith state-of-the-art models. For repeatable performance ranking (RPR subset)\nand workload characterization (WC subset), we keep two subsets to a minimum for\naffordability. We contribute by far the most comprehensive AI training\nbenchmark suite. The evaluations show: (1) AIBench Training (v1.1) outperforms\nMLPerfTraining (v0.7) in terms of diversity and representativeness of model\ncomplexity, computational cost, convergent rate, computation, and memory access\npatterns, and hotspot functions; (2) Against the AIBench full benchmarks, its\nRPR subset shortens the benchmarking cost by 64%, while maintaining the primary\nworkload characteristics; (3) The performance ranking shows the single-purpose\nAI accelerator like TPU with the optimized TensorFlowframework performs better\nthan that of GPUs while losing the latter's general support for various AI\nmodels. The specification, source code, and performance numbers are available\nfrom the AIBench homepage\nhttps://www.benchcouncil.org/aibench-training/index.html.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:08:49 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 01:44:14 GMT"}, {"version": "v3", "created": "Mon, 8 Mar 2021 16:41:13 GMT"}, {"version": "v4", "created": "Wed, 10 Mar 2021 06:24:57 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Tang", "Fei", ""], ["Gao", "Wanling", ""], ["Zhan", "Jianfeng", ""], ["Lan", "Chuanxin", ""], ["Wen", "Xu", ""], ["Wang", "Lei", ""], ["Luo", "Chunjie", ""], ["Dai", "Jiahui", ""], ["Cao", "Zheng", ""], ["Xiong", "Xingwang", ""], ["Jiang", "Zihan", ""], ["Hao", "Tianshu", ""], ["Fan", "Fanda", ""], ["Zhang", "Fan", ""], ["Huang", "Yunyou", ""], ["Chen", "Jianan", ""], ["Du", "Mengjia", ""], ["Ren", "Rui", ""], ["Zheng", "Chen", ""], ["Zheng", "Daoyi", ""], ["Tang", "Haoning", ""], ["Zhan", "Kunlin", ""], ["Wang", "Biao", ""], ["Kong", "Defei", ""], ["Yu", "Minghe", ""], ["Tan", "Chongkang", ""], ["Li", "Huan", ""], ["Tian", "Xinhui", ""], ["Li", "Yatao", ""], ["Shao", "Junchao", ""], ["Wang", "Zhenyu", ""], ["Wang", "Xiaoyu", ""], ["Ye", "Hainan", ""]]}, {"id": "2004.14692", "submitter": "S. Akshay", "authors": "Kuldeep S. Meel and S. Akshay", "title": "Sparse Hashing for Scalable Approximate Model Counting: Theory and\n  Practice", "comments": "Full version of paper accepted in LICS2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a CNF formula F on n variables, the problem of model counting or #SAT\nis to compute the number of satisfying assignments of F . Model counting is a\nfundamental but hard problem in computer science with varied applications.\nRecent years have witnessed a surge of effort towards developing efficient\nalgorithmic techniques that combine the classical 2-universal hashing with the\nremarkable progress in SAT solving over the past decade. These techniques\naugment the CNF formula F with random XOR constraints and invoke an NP oracle\nrepeatedly on the resultant CNF-XOR formulas. In practice, calls to the NP\noracle calls are replaced a SAT solver whose runtime performance is adversely\naffected by size of XOR constraints. The standard construction of 2-universal\nhash functions chooses every variable with probability p = 1/2 leading to XOR\nconstraints of size n/2 in expectation. Consequently, the challenge is to\ndesign sparse hash functions where variables can be chosen with smaller\nprobability and lead to smaller sized XOR constraints.\n  In this paper, we address this challenge from theoretical and practical\nperspectives. First, we formalize a relaxation of universal hashing, called\nconcentrated hashing and establish a novel and beautiful connection between\nconcentration measures of these hash functions and isoperimetric inequalities\non boolean hypercubes. This allows us to obtain (log m) tight bounds on\nvariance and dispersion index and show that p = O( log(m)/m ) suffices for\ndesign of sparse hash functions from {0, 1}^n to {0, 1}^m. We then use sparse\nhash functions belonging to this concentrated hash family to develop new\napproximate counting algorithms. A comprehensive experimental evaluation of our\nalgorithm on 1893 benchmarks demonstrates that usage of sparse hash functions\ncan lead to significant speedups.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:17:26 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Meel", "Kuldeep S.", ""], ["Akshay", "S.", ""]]}, {"id": "2004.14696", "submitter": "Chuan Xu", "authors": "Chuan Xu, Giovanni Neglia, Nicola Sebastianelli", "title": "Dynamic backup workers for parallel machine learning", "comments": "Journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular framework for distributed training of machine learning\nmodels is the (synchronous) parameter server (PS). This paradigm consists of\n$n$ workers, which iteratively compute updates of the model parameters, and a\nstateful PS, which waits and aggregates all updates to generate a new estimate\nof model parameters and sends it back to the workers for a new iteration.\nTransient computation slowdowns or transmission delays can intolerably lengthen\nthe time of each iteration. An efficient way to mitigate this problem is to let\nthe PS wait only for the fastest $n-b$ updates, before generating the new\nparameters. The slowest $b$ workers are called backup workers. The optimal\nnumber $b$ of backup workers depends on the cluster configuration and workload,\nbut also (as we show in this paper) on the hyper-parameters of the learning\nalgorithm and the current stage of the training. We propose DBW, an algorithm\nthat dynamically decides the number of backup workers during the training\nprocess to maximize the convergence speed at each iteration. Our experiments\nshow that DBW 1) removes the necessity to tune $b$ by preliminary\ntime-consuming experiments, and 2) makes the training up to a factor $3$ faster\nthan the optimal static configuration.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:25:00 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 01:35:38 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Xu", "Chuan", ""], ["Neglia", "Giovanni", ""], ["Sebastianelli", "Nicola", ""]]}, {"id": "2004.14698", "submitter": "Erwan Renaudo", "authors": "R\\'emi Dromnelle, Erwan Renaudo, Guillaume Pourcel, Raja Chatila,\n  Beno\\^it Girard, and Mehdi Khamassi", "title": "How to reduce computation time while sparing performance during robot\n  navigation? A neuro-inspired architecture for autonomous shifting between\n  model-based and model-free learning", "comments": "12 pages, 4 figures ; Living Machines 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking inspiration from how the brain coordinates multiple learning systems\nis an appealing strategy to endow robots with more flexibility. One of the\nexpected advantages would be for robots to autonomously switch to the least\ncostly system when its performance is satisfying. However, to our knowledge no\nstudy on a real robot has yet shown that the measured computational cost is\nreduced while performance is maintained with such brain-inspired algorithms. We\npresent navigation experiments involving paths of different lengths to the\ngoal, dead-end, and non-stationarity (i.e., change in goal location and\napparition of obstacles). We present a novel arbitration mechanism between\nlearning systems that explicitly measures performance and cost. We find that\nthe robot can adapt to environment changes by switching between learning\nsystems so as to maintain a high performance. Moreover, when the task is\nstable, the robot also autonomously shifts to the least costly system, which\nleads to a drastic reduction in computation cost while keeping a high\nperformance. Overall, these results illustrates the interest of using multiple\nlearning systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:29:16 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:48:56 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Dromnelle", "R\u00e9mi", ""], ["Renaudo", "Erwan", ""], ["Pourcel", "Guillaume", ""], ["Chatila", "Raja", ""], ["Girard", "Beno\u00eet", ""], ["Khamassi", "Mehdi", ""]]}, {"id": "2004.14704", "submitter": "Yang Wei", "authors": "Yang Wei, Yuanbin Wu, and Man Lan", "title": "A Span-based Linearization for Constituent Trees", "comments": "Accepted to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel linearization of a constituent tree, together with a new\nlocally normalized model. For each split point in a sentence, our model\ncomputes the normalizer on all spans ending with that split point, and then\npredicts a tree span from them. Compared with global models, our model is fast\nand parallelizable. Different from previous local models, our linearization\nmethod is tied on the spans directly and considers more local features when\nperforming span prediction, which is more interpretable and effective.\nExperiments on PTB (95.8 F1) and CTB (92.4 F1) show that our model\nsignificantly outperforms existing local models and efficiently achieves\ncompetitive results with global models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:36:33 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 11:42:39 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Wei", "Yang", ""], ["Wu", "Yuanbin", ""], ["Lan", "Man", ""]]}, {"id": "2004.14705", "submitter": "Yuheng Jia", "authors": "Yuheng Jia, Hui Liu, Junhui Hou, Sam Kwong, Qingfu Zhang", "title": "Multi-View Spectral Clustering Tailored Tensor Low-Rank Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of multi-view spectral clustering (MVSC)\nbased on tensor low-rank modeling. Unlike the existing methods that all adopt\nan off-the-shelf tensor low-rank norm without considering the special\ncharacteristics of the tensor in MVSC, we design a novel structured tensor\nlow-rank norm tailored to MVSC. Specifically, we explicitly impose a symmetric\nlow-rank constraint and a structured sparse low-rank constraint on the frontal\nand horizontal slices of the tensor to characterize the intra-view and\ninter-view relationships, respectively. Moreover, the two constraints could be\njointly optimized to achieve mutual refinement. On the basis of the novel\ntensor low-rank norm, we formulate MVSC as a convex low-rank tensor recovery\nproblem, which is then efficiently solved with an augmented Lagrange multiplier\nbased method iteratively. Extensive experimental results on five benchmark\ndatasets show that the proposed method outperforms state-of-the-art methods to\na significant extent. Impressively, our method is able to produce perfect\nclustering. In addition, the parameters of our method can be easily tuned, and\nthe proposed model is robust to different datasets, demonstrating its potential\nin practice.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 11:52:12 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:35:01 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Jia", "Yuheng", ""], ["Liu", "Hui", ""], ["Hou", "Junhui", ""], ["Kwong", "Sam", ""], ["Zhang", "Qingfu", ""]]}, {"id": "2004.14717", "submitter": "Viacheslav Osaulenko", "authors": "Viacheslav Osaulenko", "title": "Binary autoencoder with random binary weights", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here is presented an analysis of an autoencoder with binary activations $\\{0,\n1\\}$ and binary $\\{0, 1\\}$ random weights. Such set up puts this model at the\nintersection of different fields: neuroscience, information theory, sparse\ncoding, and machine learning. It is shown that the sparse activation of the\nhidden layer arises naturally in order to preserve information between layers.\nFurthermore, with a large enough hidden layer, it is possible to get zero\nreconstruction error for any input just by varying the thresholds of neurons.\nThe model preserves the similarity of inputs at the hidden layer that is\nmaximal for the dense hidden layer activation. By analyzing the mutual\ninformation between layers it is shown that the difference between sparse and\ndense representations is related to a memory-computation trade-off. The model\nis similar to an olfactory perception system of a fruit fly, and the presented\ntheoretical results give useful insights toward understanding more complex\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:13:19 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Osaulenko", "Viacheslav", ""]]}, {"id": "2004.14723", "submitter": "Pierre Lison", "authors": "Pierre Lison, Aliaksandr Hubin, Jeremy Barnes, and Samia Touileb", "title": "Named Entity Recognition without Labelled Data: A Weak Supervision\n  Approach", "comments": "Accepted to ACL 2020 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Named Entity Recognition (NER) performance often degrades rapidly when\napplied to target domains that differ from the texts observed during training.\nWhen in-domain labelled data is available, transfer learning techniques can be\nused to adapt existing NER models to the target domain. But what should one do\nwhen there is no hand-labelled data for the target domain? This paper presents\na simple but powerful approach to learn NER models in the absence of labelled\ndata through weak supervision. The approach relies on a broad spectrum of\nlabelling functions to automatically annotate texts from the target domain.\nThese annotations are then merged together using a hidden Markov model which\ncaptures the varying accuracies and confusions of the labelling functions. A\nsequence labelling model can finally be trained on the basis of this unified\nannotation. We evaluate the approach on two English datasets (CoNLL 2003 and\nnews articles from Reuters and Bloomberg) and demonstrate an improvement of\nabout 7 percentage points in entity-level $F_1$ scores compared to an\nout-of-domain neural NER model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:29:55 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Lison", "Pierre", ""], ["Hubin", "Aliaksandr", ""], ["Barnes", "Jeremy", ""], ["Touileb", "Samia", ""]]}, {"id": "2004.14724", "submitter": "Niels Gr\\\"uttemeier", "authors": "Niels Gr\\\"uttemeier and Christian Komusiewicz", "title": "Learning Bayesian Networks Under Sparsity Constraints: A Parameterized\n  Complexity Analysis", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning the structure of an optimal Bayesian network\n$D$ when additional constraints are posed on the DAG $D$ or on its moralized\ngraph. More precisely, we consider the constraint that the moralized graph can\nbe transformed to a graph from a sparse graph class $\\Pi$ by at most $k$ vertex\ndeletions. We show that for $\\Pi$ being the graphs with maximum degree $1$, an\noptimal network can be computed in polynomial time when $k$ is constant,\nextending previous work that gave an algorithm with such a running time for\n$\\Pi$ being the class of edgeless graphs [Korhonen & Parviainen, NIPS 2015]. We\nthen show that further extensions or improvements are presumably impossible.\nFor example, we show that when $\\Pi$ is the set of graphs with maximum degree\n$2$ or when $\\Pi$ is the set of graphs in which each component has size at most\nthree, then learning an optimal network is NP-hard even if $k=0$. Finally, we\nshow that learning an optimal network with at most $k$ edges in the moralized\ngraph presumably has no $f(k)\\cdot |I|^{\\mathcal{O}(1)}$-time algorithm and\nthat, in contrast, an optimal network with at most $k$ arcs in the DAG $D$ can\nbe computed in $2^{\\mathcal{O}(k)}\\cdot\n  |I|^{\\mathcal{O}(1)}$ time where $|I|$ is the total input size.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:31:13 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 08:41:55 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Gr\u00fcttemeier", "Niels", ""], ["Komusiewicz", "Christian", ""]]}, {"id": "2004.14733", "submitter": "Erik Scharw\\\"achter", "authors": "Erik Scharw\\\"achter and Emmanuel M\\\"uller", "title": "Does Terrorism Trigger Online Hate Speech? On the Association of Events\n  and Time Series", "comments": "19 pages, 8 figures, to appear in the Annals of Applied Statistics,\n  source code available at https://github.com/diozaka/pECA", "journal-ref": "Annals of Applied Statistics 14 (3) 2020, pp. 1285-1303", "doi": "10.1214/20-AOAS1338", "report-no": null, "categories": "stat.AP cs.CY cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hate speech is ubiquitous on the Web. Recently, the offline causes that\ncontribute to online hate speech have received increasing attention. A\nrecurring question is whether the occurrence of extreme events offline\nsystematically triggers bursts of hate speech online, indicated by peaks in the\nvolume of hateful social media posts. Formally, this question translates into\nmeasuring the association between a sparse event series and a time series. We\npropose a novel statistical methodology to measure, test and visualize the\nsystematic association between rare events and peaks in a time series. In\ncontrast to previous methods for causal inference or independence tests on time\nseries, our approach focuses only on the timing of events and peaks, and no\nother distributional characteristics. We follow the framework of event\ncoincidence analysis (ECA) that was originally developed to correlate point\nprocesses. We formulate a discrete-time variant of ECA and derive all required\ndistributions to enable analyses of peaks in time series, with a special focus\non serial dependencies and peaks over multiple thresholds. The analysis gives\nrise to a novel visualization of the association via quantile-trigger rate\nplots. We demonstrate the utility of our approach by analyzing whether Islamist\nterrorist attacks in Western Europe and North America systematically trigger\nbursts of hate speech and counter-hate speech on Twitter.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:47:22 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 10:15:18 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Scharw\u00e4chter", "Erik", ""], ["M\u00fcller", "Emmanuel", ""]]}, {"id": "2004.14734", "submitter": "Shaowen Peng", "authors": "Shaowen Peng, Tsunenori Mine", "title": "A Robust Hierarchical Graph Convolutional Network Model for\n  Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) has achieved great success and has been\napplied in various fields including recommender systems. However, GCN still\nsuffers from many issues such as training difficulties, over-smoothing,\nvulnerable to adversarial attacks, etc. Distinct from current GCN-based methods\nwhich simply employ GCN for recommendation, in this paper we are committed to\nbuild a robust GCN model for collaborative filtering. Firstly, we argue that\nrecursively incorporating messages from different order neighborhood mixes\ndistinct node messages indistinguishably, which increases the training\ndifficulty; instead we choose to separately aggregate different order neighbor\nmessages with a simple GCN model which has been shown effective; then we\naccumulate them together in a hierarchical way without introducing additional\nmodel parameters. Secondly, we propose a solution to alleviate over-smoothing\nby randomly dropping out neighbor messages at each layer, which also well\nprevents over-fitting and enhances the robustness. Extensive experiments on\nthree real-world datasets demonstrate the effectiveness and robustness of our\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:50:39 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Peng", "Shaowen", ""], ["Mine", "Tsunenori", ""]]}, {"id": "2004.14745", "submitter": "Ralf Raumanns", "authors": "Ralf Raumanns, Elif K Contar, Gerard Schouten, Veronika Cheplygina", "title": "Multi-task Ensembles with Crowdsourced Features Improve Skin Lesion\n  Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has a recognised need for large amounts of annotated data.\nDue to the high cost of expert annotations, crowdsourcing, where non-experts\nare asked to label or outline images, has been proposed as an alternative.\nAlthough many promising results are reported, the quality of diagnostic\ncrowdsourced labels is still unclear. We propose to address this by instead\nasking the crowd about visual features of the images, which can be provided\nmore intuitively, and by using these features in a multi-task learning\nframework through ensemble strategies. We compare our proposed approach to a\nbaseline model with a set of 2000 skin lesions from the ISIC 2017 challenge\ndataset. The baseline model only predicts a binary label from the skin lesion\nimage, while our multi-task model also predicts one of the following features:\nasymmetry of the lesion, border irregularity and color. We show that multi-task\nmodels with individual crowdsourced features have limited effect on the model,\nbut when combined in an ensembles, leads to improved generalisation. The area\nunder the receiver operating characteristic curve is 0.794 for the baseline\nmodel and 0.811 and 0.808 for multi-task ensembles respectively. Finally, we\ndiscuss the findings, identify some limitations and recommend directions for\nfurther research. The code of the models is available at\nhttps://github.com/raumannsr/hints_crowd.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:48:40 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 18:12:41 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Raumanns", "Ralf", ""], ["Contar", "Elif K", ""], ["Schouten", "Gerard", ""], ["Cheplygina", "Veronika", ""]]}, {"id": "2004.14754", "submitter": "Hady Elsahar Dr", "authors": "Hady Elsahar, Maximin Coavoux, Matthias Gall\\'e, Jos Rozen", "title": "Self-Supervised and Controlled Multi-Document Opinion Summarization", "comments": "18 pages including 5 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We address the problem of unsupervised abstractive summarization of\ncollections of user generated reviews with self-supervision and control. We\npropose a self-supervised setup that considers an individual document as a\ntarget summary for a set of similar documents. This setting makes training\nsimpler than previous approaches by relying only on standard log-likelihood\nloss. We address the problem of hallucinations through the use of control\ncodes, to steer the generation towards more coherent and relevant\nsummaries.Finally, we extend the Transformer architecture to allow for multiple\nreviews as input. Our benchmarks on two datasets against graph-based and recent\nneural abstractive unsupervised models show that our proposed method generates\nsummaries with a superior quality and relevance.This is confirmed in our human\nevaluation which focuses explicitly on the faithfulness of generated summaries\nWe also provide an ablation study, which shows the importance of the control\nsetup in controlling hallucinations and achieve high sentiment and topic\nalignment of the summaries with the input reviews.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:20:18 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 00:26:52 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Elsahar", "Hady", ""], ["Coavoux", "Maximin", ""], ["Gall\u00e9", "Matthias", ""], ["Rozen", "Jos", ""]]}, {"id": "2004.14756", "submitter": "Matthew Mirman", "authors": "Matthew Mirman, Timon Gehr, Martin Vechev", "title": "Robustness Certification of Generative Models", "comments": "Prior version submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative neural networks can be used to specify continuous transformations\nbetween images via latent-space interpolation. However, certifying that all\nimages captured by the resulting path in the image manifold satisfy a given\nproperty can be very challenging. This is because this set is highly\nnon-convex, thwarting existing scalable robustness analysis methods, which are\noften based on convex relaxations. We present ApproxLine, a scalable\ncertification method that successfully verifies non-trivial specifications\ninvolving generative models and classifiers. ApproxLine can provide both sound\ndeterministic and probabilistic guarantees, by capturing either infinite\nnon-convex sets of neural network activation vectors or distributions over such\nsets. We show that ApproxLine is practically useful and can verify interesting\ninterpolations in the networks latent space.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:23:02 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Mirman", "Matthew", ""], ["Gehr", "Timon", ""], ["Vechev", "Martin", ""]]}, {"id": "2004.14758", "submitter": "Serhii Havrylov", "authors": "Serhii Havrylov, Ivan Titov", "title": "Preventing Posterior Collapse with Levenshtein Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAEs) are a standard framework for inducing latent\nvariable models that have been shown effective in learning text representations\nas well as in text generation. The key challenge with using VAEs is the {\\it\nposterior collapse} problem: learning tends to converge to trivial solutions\nwhere the generators ignore latent variables. In our Levenstein VAE, we propose\nto replace the evidence lower bound (ELBO) with a new objective which is simple\nto optimize and prevents posterior collapse. Intuitively, it corresponds to\ngenerating a sequence from the autoencoder and encouraging the model to predict\nan optimal continuation according to the Levenshtein distance (LD) with the\nreference sentence at each time step in the generated sequence. We motivate the\nmethod from the probabilistic perspective by showing that it is closely related\nto optimizing a bound on the intractable Kullback-Leibler divergence of an\nLD-based kernel density estimator from the model distribution. With this\nobjective, any generator disregarding latent variables will incur large\npenalties and hence posterior collapse does not happen. We relate our approach\nto policy distillation \\cite{RossGB11} and dynamic oracles \\cite{GoldbergN12}.\nBy considering Yelp and SNLI benchmarks, we show that Levenstein VAE produces\nmore informative latent representations than alternative approaches to\npreventing posterior collapse.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:27:26 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Havrylov", "Serhii", ""], ["Titov", "Ivan", ""]]}, {"id": "2004.14764", "submitter": "Jos\\'e A. Cuesta", "authors": "Ignacio Tamarit, Mar\\'ia Pereda, and Jos\\'e A. Cuesta", "title": "Hierarchical clustering of bipartite data sets based on the statistical\n  significance of coincidences", "comments": "8 figures, includes a pdf file with Supplementary figures", "journal-ref": "Phys. Rev. E 102, 042304 (2020)", "doi": "10.1103/PhysRevE.102.042304", "report-no": null, "categories": "cs.SI cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When some 'entities' are related by the 'features' they share they are\namenable to a bipartite network representation. Plant-pollinator ecological\ncommunities, co-authorship of scientific papers, customers and purchases, or\nanswers in a poll, are but a few examples. Analyzing clustering of such\nentities in the network is a useful tool with applications in many fields, like\ninternet technology, recommender systems, or detection of diseases. The\nalgorithms most widely applied to find clusters in bipartite networks are\nvariants of modularity optimization. Here we provide an hierarchical clustering\nalgorithm based on a dissimilarity between entities that quantifies the\nprobability that the features shared by two entities is due to mere chance. The\nalgorithm performance is $O(n^2)$ when applied to a set of n entities, and its\noutcome is a dendrogram exhibiting the connections of those entities. Through\nthe introduction of a 'susceptibility' measure we can provide an 'optimal'\nchoice for the clustering as well as quantify its quality. The dendrogram\nreveals further useful structural information though -- like the existence of\nsub-clusters within clusters or of nodes that do not fit in any cluster. We\nillustrate the algorithm by applying it first to a set of synthetic networks,\nand then to a selection of examples. We also illustrate how to transform our\nalgorithm into a valid alternative for one-mode networks as well, and show that\nit performs at least as well as the standard, modularity-based algorithms --\nwith a higher numerical performance. We provide an implementation of the\nalgorithm in Python freely accessible from GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 23:30:18 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 09:04:05 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Tamarit", "Ignacio", ""], ["Pereda", "Mar\u00eda", ""], ["Cuesta", "Jos\u00e9 A.", ""]]}, {"id": "2004.14765", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Andrea Bragagnolo and Marco Grangetto", "title": "Pruning artificial neural networks: a way to find well-generalizing,\n  high-entropy sharp minima", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a race towards the simplification of deep networks has begun,\nshowing that it is effectively possible to reduce the size of these models with\nminimal or no performance loss. However, there is a general lack in\nunderstanding why these pruning strategies are effective. In this work, we are\ngoing to compare and analyze pruned solutions with two different pruning\napproaches, one-shot and gradual, showing the higher effectiveness of the\nlatter. In particular, we find that gradual pruning allows access to narrow,\nwell-generalizing minima, which are typically ignored when using one-shot\napproaches. In this work we also propose PSP-entropy, a measure to understand\nhow a given neuron correlates to some specific learned classes. Interestingly,\nwe observe that the features extracted by iteratively-pruned models are less\ncorrelated to specific classes, potentially making these models a better fit in\ntransfer learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 13:29:37 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Bragagnolo", "Andrea", ""], ["Grangetto", "Marco", ""]]}, {"id": "2004.14774", "submitter": "Qi She", "authors": "Qi She, Fan Feng, Qi Liu, Rosa H. M. Chan, Xinyue Hao, Chuanlin Lan,\n  Qihan Yang, Vincenzo Lomonaco, German I. Parisi, Heechul Bae, Eoin Brophy,\n  Baoquan Chen, Gabriele Graffieti, Vidit Goel, Hyonyoung Han, Sathursan\n  Kanagarajah, Somesh Kumar, Siew-Kei Lam, Tin Lun Lam, Liang Ma, Davide\n  Maltoni, Lorenzo Pellegrini, Duvindu Piyasena, Shiliang Pu, Debdoot Sheet,\n  Soonyong Song, Youngsung Son, Zhengwei Wang, Tomas E. Ward, Jianwen Wu,\n  Meiqing Wu, Di Xie, Yangsheng Xu, Lin Yang, Qiaoyong Zhong, Liguang Zhou", "title": "IROS 2019 Lifelong Robotic Vision Challenge -- Lifelong Object\n  Recognition Report", "comments": "9 pages, 11 figures, 3 tables, accepted into IEEE Robotics and\n  Automation Magazine. arXiv admin note: text overlap with arXiv:1911.06487", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report summarizes IROS 2019-Lifelong Robotic Vision Competition\n(Lifelong Object Recognition Challenge) with methods and results from the top\n$8$ finalists (out of over~$150$ teams). The competition dataset (L)ifel(O)ng\n(R)obotic V(IS)ion (OpenLORIS) - Object Recognition (OpenLORIS-object) is\ndesigned for driving lifelong/continual learning research and application in\nrobotic vision domain, with everyday objects in home, office, campus, and mall\nscenarios. The dataset explicitly quantifies the variants of illumination,\nobject occlusion, object size, camera-object distance/angles, and clutter\ninformation. Rules are designed to quantify the learning capability of the\nrobotic vision system when faced with the objects appearing in the dynamic\nenvironments in the contest. Individual reports, dataset information, rules,\nand released source code can be found at the project homepage:\n\"https://lifelong-robotic-vision.github.io/competition/\".\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 08:33:55 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["She", "Qi", ""], ["Feng", "Fan", ""], ["Liu", "Qi", ""], ["Chan", "Rosa H. M.", ""], ["Hao", "Xinyue", ""], ["Lan", "Chuanlin", ""], ["Yang", "Qihan", ""], ["Lomonaco", "Vincenzo", ""], ["Parisi", "German I.", ""], ["Bae", "Heechul", ""], ["Brophy", "Eoin", ""], ["Chen", "Baoquan", ""], ["Graffieti", "Gabriele", ""], ["Goel", "Vidit", ""], ["Han", "Hyonyoung", ""], ["Kanagarajah", "Sathursan", ""], ["Kumar", "Somesh", ""], ["Lam", "Siew-Kei", ""], ["Lam", "Tin Lun", ""], ["Ma", "Liang", ""], ["Maltoni", "Davide", ""], ["Pellegrini", "Lorenzo", ""], ["Piyasena", "Duvindu", ""], ["Pu", "Shiliang", ""], ["Sheet", "Debdoot", ""], ["Song", "Soonyong", ""], ["Son", "Youngsung", ""], ["Wang", "Zhengwei", ""], ["Ward", "Tomas E.", ""], ["Wu", "Jianwen", ""], ["Wu", "Meiqing", ""], ["Xie", "Di", ""], ["Xu", "Yangsheng", ""], ["Yang", "Lin", ""], ["Zhong", "Qiaoyong", ""], ["Zhou", "Liguang", ""]]}, {"id": "2004.14777", "submitter": "Lambert Leong", "authors": "Lambert T. Leong, Sean Wiere", "title": "Digit Recognition From Wrist Movements and Security Concerns with Smart\n  Wrist Wearable IOT Devices", "comments": "7 pages, 5 figures, 10 tables, in Proc Hawaii International\n  Conference on System Science (HICSS)", "journal-ref": null, "doi": "10.24251/HICSS.2020.790", "report-no": "978-0-9981331-3-3", "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a potential security vulnerability associated\nwith wrist wearable devices. Hardware components on common wearable devices\ninclude an accelerometer and gyroscope, among other sensors. We demonstrate\nthat an accelerometer and gyroscope can pick up enough unique wrist movement\ninformation to identify digits being written by a user. With a data set of 400\nwriting samples, of either the digit zero or the digit one, we constructed a\nmachine learning model to correctly identify the digit being written based on\nthe movements of the wrist. Our model's performance on an unseen test set\nresulted in an area under the receiver operating characteristic (AUROC) curve\nof 1.00. Loading our model onto our fabricated device resulted in 100% accuracy\nwhen predicting ten writing samples in real-time. The model's ability to\ncorrectly identify all digits via wrist movement and orientation changes raises\nsecurity concerns. Our results imply that nefarious individuals may be able to\ngain sensitive digit based information such as social security, credit card,\nand medical record numbers from wrist wearable devices.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 23:37:38 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Leong", "Lambert T.", ""], ["Wiere", "Sean", ""]]}, {"id": "2004.14795", "submitter": "Jingcai Guo", "authors": "Jingcai Guo, Song Guo", "title": "A Novel Perspective to Zero-shot Learning: Towards an Alignment of\n  Manifold Structures via Semantic Feature Expansion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zero-shot learning aims at recognizing unseen classes (no training example)\nwith knowledge transferred from seen classes. This is typically achieved by\nexploiting a semantic feature space shared by both seen and unseen classes,\ni.e., attribute or word vector, as the bridge. One common practice in zero-shot\nlearning is to train a projection between the visual and semantic feature\nspaces with labeled seen classes examples. When inferring, this learned\nprojection is applied to unseen classes and recognizes the class labels by some\nmetrics. However, the visual and semantic feature spaces are mutually\nindependent and have quite different manifold structures. Under such a\nparadigm, most existing methods easily suffer from the domain shift problem and\nweaken the performance of zero-shot recognition. To address this issue, we\npropose a novel model called AMS-SFE. It considers the alignment of manifold\nstructures by semantic feature expansion. Specifically, we build upon an\nautoencoder-based model to expand the semantic features from the visual inputs.\nAdditionally, the expansion is jointly guided by an embedded manifold extracted\nfrom the visual feature space of the data. Our model is the first attempt to\nalign both feature spaces by expanding semantic features and derives two\nbenefits: first, we expand some auxiliary features that enhance the semantic\nfeature space; second and more importantly, we implicitly align the manifold\nstructures between the visual and semantic feature spaces; thus, the projection\ncan be better trained and mitigate the domain shift problem. Extensive\nexperiments show significant performance improvement, which verifies the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:08:10 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Guo", "Jingcai", ""], ["Guo", "Song", ""]]}, {"id": "2004.14798", "submitter": "Jiawei Du", "authors": "Jiawei Du, Hanshu Yan, Vincent Y. F. Tan, Joey Tianyi Zhou, Rick Siow\n  Mong Goh, Jiashi Feng", "title": "RAIN: A Simple Approach for Robust and Accurate Image Classification\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that the majority of existing adversarial defense methods\nachieve robustness at the cost of sacrificing prediction accuracy. The\nundesirable severe drop in accuracy adversely affects the reliability of\nmachine learning algorithms and prohibits their deployment in realistic\napplications. This paper aims to address this dilemma by proposing a novel\npreprocessing framework, which we term Robust and Accurate Image\nclassificatioN(RAIN), to improve the robustness of given CNN classifiers and,\nat the same time, preserve their high prediction accuracies. RAIN introduces a\nnew randomization-enhancement scheme. It applies randomization over inputs to\nbreak the ties between the model forward prediction path and the backward\ngradient path, thus improving the model robustness. However, similar to\nexisting preprocessing-based methods, the randomized process will degrade the\nprediction accuracy. To understand why this is the case, we compare the\ndifference between original and processed images, and find it is the loss of\nhigh-frequency components in the input image that leads to accuracy drop of the\nclassifier. Based on this finding, RAIN enhances the input's high-frequency\ndetails to retain the CNN's high prediction accuracy. Concretely, RAIN consists\nof two novel randomization modules: randomized small circular shift (RdmSCS)\nand randomized down-upsampling (RdmDU). The RdmDU module randomly downsamples\nthe input image, and then the RdmSCS module circularly shifts the input image\nalong a randomly chosen direction by a small but random number of pixels.\nFinally, the RdmDU module performs upsampling with a detail-enhancement model,\nsuch as deep super-resolution networks. We conduct extensive experiments on the\nSTL10 and ImageNet datasets to verify the effectiveness of RAIN against various\ntypes of adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 02:03:56 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 11:34:11 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 16:56:42 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 13:24:52 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Du", "Jiawei", ""], ["Yan", "Hanshu", ""], ["Tan", "Vincent Y. F.", ""], ["Zhou", "Joey Tianyi", ""], ["Goh", "Rick Siow Mong", ""], ["Feng", "Jiashi", ""]]}, {"id": "2004.14826", "submitter": "Amir Hossein Kargaran", "authors": "Amir Hossein Kargaran, Mohammad Sadegh Akhondzadeh, Mohammad Reza\n  Heidarpour, Mohammad Hossein Manshaei, Kave Salamatian, Masoud Nejad Sattary", "title": "Wide-AdGraph: Detecting Ad Trackers with a Wide Dependency Chain Graph", "comments": "9 pages, 7 figures, To appear in the 13th ACM Web Science Conference\n  2021 (WebSci '21), June 2021", "journal-ref": null, "doi": "10.1145/3447535.3462549", "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Websites use third-party ads and tracking services to deliver targeted ads\nand collect information about users that visit them. These services put users'\nprivacy at risk, and that is why users' demand for blocking these services is\ngrowing. Most of the blocking solutions rely on crowd-sourced filter lists\nmanually maintained by a large community of users. In this work, we seek to\nsimplify the update of these filter lists by combining different websites\nthrough a large-scale graph connecting all resource requests made over a large\nset of sites. The features of this graph are extracted and used to train a\nmachine learning algorithm with the aim of detecting ads and tracking\nresources. As our approach combines different information sources, it is more\nrobust toward evasion techniques that use obfuscation or changing the usage\npatterns. We evaluate our work over the Alexa top-10K websites and find its\naccuracy to be 96.1% biased and 90.9% unbiased with high precision and recall.\nIt can also block new ads and tracking services, which would necessitate being\nblocked by further crowd-sourced existing filter lists. Moreover, the approach\nfollowed in this paper sheds light on the ecosystem of third-party tracking and\nadvertising.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 11:28:49 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 11:43:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kargaran", "Amir Hossein", ""], ["Akhondzadeh", "Mohammad Sadegh", ""], ["Heidarpour", "Mohammad Reza", ""], ["Manshaei", "Mohammad Hossein", ""], ["Salamatian", "Kave", ""], ["Sattary", "Masoud Nejad", ""]]}, {"id": "2004.14832", "submitter": "Sarah Verhulst", "authors": "Deepak Baby, Arthur Van Den Broucke, Sarah Verhulst", "title": "A convolutional neural-network model of human cochlear mechanics and\n  filter tuning for real-time applications", "comments": null, "journal-ref": null, "doi": "10.1038/s42256-020-00286-8", "report-no": null, "categories": "eess.AS cs.CE cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auditory models are commonly used as feature extractors for automatic\nspeech-recognition systems or as front-ends for robotics, machine-hearing and\nhearing-aid applications. Although auditory models can capture the biophysical\nand nonlinear properties of human hearing in great detail, these biophysical\nmodels are computationally expensive and cannot be used in real-time\napplications. We present a hybrid approach where convolutional neural networks\nare combined with computational neuroscience to yield a real-time end-to-end\nmodel for human cochlear mechanics, including level-dependent filter tuning\n(CoNNear). The CoNNear model was trained on acoustic speech material and its\nperformance and applicability were evaluated using (unseen) sound stimuli\ncommonly employed in cochlear mechanics research. The CoNNear model accurately\nsimulates human cochlear frequency selectivity and its dependence on sound\nintensity, an essential quality for robust speech intelligibility at negative\nspeech-to-background-noise ratios. The CoNNear architecture is based on\nparallel and differentiable computations and has the power to achieve real-time\nhuman performance. These unique CoNNear features will enable the next\ngeneration of human-like machine-hearing applications.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:43:03 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:38:38 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 12:05:56 GMT"}, {"version": "v4", "created": "Fri, 4 Dec 2020 20:08:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Baby", "Deepak", ""], ["Broucke", "Arthur Van Den", ""], ["Verhulst", "Sarah", ""]]}, {"id": "2004.14837", "submitter": "Yun Chen", "authors": "Yun Chen, Yang Liu, Guanhua Chen, Xin Jiang, Qun Liu", "title": "Accurate Word Alignment Induction from Neural Machine Translation", "comments": "Accepted by EMNLP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its original goal to jointly learn to align and translate, prior\nresearches suggest that Transformer captures poor word alignments through its\nattention mechanism. In this paper, we show that attention weights DO capture\naccurate word alignments and propose two novel word alignment induction methods\nShift-Att and Shift-AET. The main idea is to induce alignments at the step when\nthe to-be-aligned target token is the decoder input rather than the decoder\noutput as in previous work. Shift-Att is an interpretation method that induces\nalignments from the attention weights of Transformer and does not require\nparameter update or architecture change. Shift-AET extracts alignments from an\nadditional alignment module which is tightly integrated into Transformer and\ntrained in isolation with supervision from symmetrized Shift-Att alignments.\nExperiments on three publicly available datasets demonstrate that both methods\nperform better than their corresponding neural baselines and Shift-AET\nsignificantly outperforms GIZA++ by 1.4-4.8 AER points.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:47:05 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 01:57:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Chen", "Yun", ""], ["Liu", "Yang", ""], ["Chen", "Guanhua", ""], ["Jiang", "Xin", ""], ["Liu", "Qun", ""]]}, {"id": "2004.14840", "submitter": "Georgios Paraskevopoulos", "authors": "Georgios Paraskevopoulos, Srinivas Parthasarathy, Aparna Khare, and\n  Shiva Sundaram", "title": "Multiresolution and Multimodal Speech Recognition with Transformers", "comments": "Accepted for ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CV cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an audio visual automatic speech recognition (AV-ASR)\nsystem using a Transformer-based architecture. We particularly focus on the\nscene context provided by the visual information, to ground the ASR. We extract\nrepresentations for audio features in the encoder layers of the transformer and\nfuse video features using an additional crossmodal multihead attention layer.\nAdditionally, we incorporate a multitask training criterion for multiresolution\nASR, where we train the model to generate both character and subword level\ntranscriptions.\n  Experimental results on the How2 dataset, indicate that multiresolution\ntraining can speed up convergence by around 50% and relatively improves word\nerror rate (WER) performance by upto 18% over subword prediction models.\nFurther, incorporating visual information improves performance with relative\ngains upto 3.76% over audio only models.\n  Our results are comparable to state-of-the-art Listen, Attend and Spell-based\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 09:32:11 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Paraskevopoulos", "Georgios", ""], ["Parthasarathy", "Srinivas", ""], ["Khare", "Aparna", ""], ["Sundaram", "Shiva", ""]]}, {"id": "2004.14841", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM (UMR\\_8001)), G\\'erard Biau (LSTA),\n  S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "Interpretable Random Forests via Rule Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SIRUS (Stable and Interpretable RUle Set) for regression, a\nstable rule learning algorithm which takes the form of a short and simple list\nof rules. State-of-the-art learning algorithms are often referred to as \"black\nboxes\" because of the high number of operations involved in their prediction\nprocess. Despite their powerful predictivity, this lack of interpretability may\nbe highly restrictive for applications with critical decisions at stake. On the\nother hand, algorithms with a simple structure-typically decision trees, rule\nalgorithms, or sparse linear models-are well known for their instability. This\nundesirable feature makes the conclusions of the data analysis unreliable and\nturns out to be a strong operational limitation. This motivates the design of\nSIRUS, which combines a simple structure with a remarkable stable behavior when\ndata is perturbed. The algorithm is based on random forests, the predictive\naccuracy of which is preserved. We demonstrate the efficiency of the method\nboth empirically (through experiments) and theoretically (with the proof of its\nasymptotic stability). Our R/C++ software implementation sirus is available\nfrom CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 08:13:35 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:56:50 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2020 07:45:02 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2021 09:09:31 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LSTA"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2004.14842", "submitter": "Dehua Chen", "authors": "Dehua Chen, Amir Jalilifard, Adriano Veloso, Nivio Ziviani", "title": "Modeling Pharmacological Effects with Multi-Relation Unsupervised Graph\n  Embedding", "comments": "Accepted at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A pharmacological effect of a drug on cells, organs and systems refers to the\nspecific biochemical interaction produced by a drug substance, which is called\nits mechanism of action. Drug repositioning (or drug repurposing) is a\nfundamental problem for the identification of new opportunities for the use of\nalready approved or failed drugs. In this paper, we present a method based on a\nmulti-relation unsupervised graph embedding model that learns latent\nrepresentations for drugs and diseases so that the distance between these\nrepresentations reveals repositioning opportunities. Once representations for\ndrugs and diseases are obtained we learn the likelihood of new links (that is,\nnew indications) between drugs and diseases. Known drug indications are used\nfor learning a model that predicts potential indications. Compared with\nexisting unsupervised graph embedding methods our method shows superior\nprediction performance in terms of area under the ROC curve, and we present\nexamples of repositioning opportunities found on recent biomedical literature\nthat were also predicted by our method.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 14:51:25 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 23:30:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Chen", "Dehua", ""], ["Jalilifard", "Amir", ""], ["Veloso", "Adriano", ""], ["Ziviani", "Nivio", ""]]}, {"id": "2004.14861", "submitter": "Nathan Inkawhich", "authors": "Nathan Inkawhich, Kevin J Liang, Binghui Wang, Matthew Inkawhich,\n  Lawrence Carin and Yiran Chen", "title": "Perturbing Across the Feature Hierarchy to Improve Standard and Strict\n  Blackbox Attack Transferability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the blackbox transfer-based targeted adversarial attack threat\nmodel in the realm of deep neural network (DNN) image classifiers. Rather than\nfocusing on crossing decision boundaries at the output layer of the source\nmodel, our method perturbs representations throughout the extracted feature\nhierarchy to resemble other classes. We design a flexible attack framework that\nallows for multi-layer perturbations and demonstrates state-of-the-art targeted\ntransfer performance between ImageNet DNNs. We also show the superiority of our\nfeature space methods under a relaxation of the common assumption that the\nsource and target models are trained on the same dataset and label space, in\nsome instances achieving a $10\\times$ increase in targeted success rate\nrelative to other blackbox transfer methods. Finally, we analyze why the\nproposed methods outperform existing attack strategies and show an extension of\nthe method in the case when limited queries to the blackbox model are allowed.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 16:00:13 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Inkawhich", "Nathan", ""], ["Liang", "Kevin J", ""], ["Wang", "Binghui", ""], ["Inkawhich", "Matthew", ""], ["Carin", "Lawrence", ""], ["Chen", "Yiran", ""]]}, {"id": "2004.14870", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Lav R. Varshney, Min-Yen Kan", "title": "Mind Your Inflections! Improving NLP for Non-Standard Englishes with\n  Base-Inflection Encoding", "comments": "Published in the Proceedings of the 2020 Conference on Empirical\n  Methods in Natural Language Processing", "journal-ref": "2020.emnlp-main.455", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inflectional variation is a common feature of World Englishes such as\nColloquial Singapore English and African American Vernacular English. Although\ncomprehension by human readers is usually unimpaired by non-standard\ninflections, current NLP systems are not yet robust. We propose Base-Inflection\nEncoding (BITE), a method to tokenize English text by reducing inflected words\nto their base forms before reinjecting the grammatical information as special\nsymbols. Fine-tuning pretrained NLP models for downstream tasks using our\nencoding defends against inflectional adversaries while maintaining performance\non clean data. Models using BITE generalize better to dialects with\nnon-standard inflections without explicit training and translation models\nconverge faster when trained with BITE. Finally, we show that our encoding\nimproves the vocabulary efficiency of popular data-driven subword tokenizers.\nSince there has been no prior work on quantitatively evaluating vocabulary\nefficiency, we propose metrics to do so.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:15:40 GMT"}, {"version": "v2", "created": "Sun, 11 Oct 2020 18:54:40 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 05:20:28 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 06:16:31 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Varshney", "Lav R.", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2004.14874", "submitter": "Ben Saunders", "authors": "Ben Saunders and Necati Cihan Camgoz and Richard Bowden", "title": "Progressive Transformers for End-to-End Sign Language Production", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of automatic Sign Language Production (SLP) is to translate spoken\nlanguage to a continuous stream of sign language video at a level comparable to\na human translator. If this was achievable, then it would revolutionise Deaf\nhearing communications. Previous work on predominantly isolated SLP has shown\nthe need for architectures that are better suited to the continuous domain of\nfull sign sequences.\n  In this paper, we propose Progressive Transformers, a novel architecture that\ncan translate from discrete spoken language sentences to continuous 3D skeleton\npose outputs representing sign language. We present two model configurations,\nan end-to-end network that produces sign direct from text and a stacked network\nthat utilises a gloss intermediary.\n  Our transformer network architecture introduces a counter that enables\ncontinuous sequence generation at training and inference. We also provide\nseveral data augmentation processes to overcome the problem of drift and\nimprove the performance of SLP models. We propose a back translation evaluation\nmechanism for SLP, presenting benchmark quantitative results on the challenging\nRWTH-PHOENIX-Weather-2014T(PHOENIX14T) dataset and setting baselines for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:20:25 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 10:20:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Saunders", "Ben", ""], ["Camgoz", "Necati Cihan", ""], ["Bowden", "Richard", ""]]}, {"id": "2004.14875", "submitter": "Nicolas Girard", "authors": "Nicolas Girard, Dmitriy Smirnov, Justin Solomon, Yuliya Tarabalka", "title": "Polygonal Building Segmentation by Frame Field Learning", "comments": "CVPR 2021 - IEEE Conference on Computer Vision and Pattern\n  Recognition, Jun 2021, Pittsburg / Virtual, United States", "journal-ref": null, "doi": null, "report-no": "hal-02548545, v2", "categories": "cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While state of the art image segmentation models typically output\nsegmentations in raster format, applications in geographic information systems\noften require vector polygons. To help bridge the gap between deep network\noutput and the format used in downstream tasks, we add a frame field output to\na deep segmentation model for extracting buildings from remote sensing images.\nWe train a deep neural network that aligns a predicted frame field to ground\ntruth contours. This additional objective improves segmentation quality by\nleveraging multi-task learning and provides structural information that later\nfacilitates polygonization; we also introduce a polygonization algorithm that\nutilizes the frame field along with the raster segmentation. Our code is\navailable at https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:21:56 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 13:30:18 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Girard", "Nicolas", ""], ["Smirnov", "Dmitriy", ""], ["Solomon", "Justin", ""], ["Tarabalka", "Yuliya", ""]]}, {"id": "2004.14878", "submitter": "Zdenek Straka", "authors": "Zdenek Straka, Tomas Svoboda, Matej Hoffmann", "title": "PreCNet: Next Frame Video Prediction Based on Predictive Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding, currently a highly influential theory in neuroscience, has\nnot been widely adopted in machine learning yet. In this work, we transform the\nseminal model of Rao and Ballard (1999) into a modern deep learning framework\nwhile remaining maximally faithful to the original schema. The resulting\nnetwork we propose (PreCNet) is tested on a widely used next frame video\nprediction benchmark, which consists of images from an urban environment\nrecorded from a car-mounted camera. On this benchmark (training: 41k images\nfrom KITTI dataset; testing: Caltech Pedestrian dataset), we achieve to our\nknowledge the best performance to date when measured with the Structural\nSimilarity Index (SSIM). Performance on all measures was further improved when\na larger training set (2M images from BDD100k), pointing to the limitations of\nthe KITTI training set. This work demonstrates that an architecture carefully\nbased in a neuroscience model, without being explicitly tailored to the task at\nhand, can exhibit unprecedented performance.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:31:24 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 13:58:55 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Straka", "Zdenek", ""], ["Svoboda", "Tomas", ""], ["Hoffmann", "Matej", ""]]}, {"id": "2004.14882", "submitter": "Simone Scardapane", "authors": "Paolo Di Lorenzo, Simone Scardapane", "title": "Distributed Stochastic Nonconvex Optimization and Learning based on\n  Successive Convex Approximation", "comments": "Proceedings of 2019 Asilomar Conference on Signals, Systems, and\n  Computers", "journal-ref": null, "doi": "10.1109/IEEECONF44664.2019.9089408", "report-no": null, "categories": "eess.SP cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed stochastic nonconvex optimization in multi-agent\nnetworks. We introduce a novel algorithmic framework for the distributed\nminimization of the sum of the expected value of a smooth (possibly nonconvex)\nfunction (the agents' sum-utility) plus a convex (possibly nonsmooth)\nregularizer. The proposed method hinges on successive convex approximation\n(SCA) techniques, leveraging dynamic consensus as a mechanism to track the\naverage gradient among the agents, and recursive averaging to recover the\nexpected gradient of the sum-utility function. Almost sure convergence to\n(stationary) solutions of the nonconvex problem is established. Finally, the\nmethod is applied to distributed stochastic training of neural networks.\nNumerical results confirm the theoretical claims, and illustrate the advantages\nof the proposed method with respect to other methods available in the\nliterature.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:36:46 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 08:08:03 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Di Lorenzo", "Paolo", ""], ["Scardapane", "Simone", ""]]}, {"id": "2004.14884", "submitter": "Arthur Bra\\v{z}inskas", "authors": "Arthur Bra\\v{z}inskas, Mirella Lapata, Ivan Titov", "title": "Few-Shot Learning for Opinion Summarization", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion summarization is the automatic creation of text reflecting subjective\ninformation expressed in multiple documents, such as user reviews of a product.\nThe task is practically important and has attracted a lot of attention.\nHowever, due to the high cost of summary production, datasets large enough for\ntraining supervised models are lacking. Instead, the task has been\ntraditionally approached with extractive methods that learn to select text\nfragments in an unsupervised or weakly-supervised way. Recently, it has been\nshown that abstractive summaries, potentially more fluent and better at\nreflecting conflicting information, can also be produced in an unsupervised\nfashion. However, these models, not being exposed to actual summaries, fail to\ncapture their essential properties. In this work, we show that even a handful\nof summaries is sufficient to bootstrap generation of the summary text with all\nexpected properties, such as writing style, informativeness, fluency, and\nsentiment preservation. We start by training a conditional Transformer language\nmodel to generate a new product review given other available reviews of the\nproduct. The model is also conditioned on review properties that are directly\nrelated to summaries; the properties are derived from reviews with no manual\neffort. In the second stage, we fine-tune a plug-in module that learns to\npredict property values on a handful of summaries. This lets us switch the\ngenerator to the summarization mode. We show on Amazon and Yelp datasets that\nour approach substantially outperforms previous extractive and abstractive\nmethods in automatic and human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 15:37:38 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 19:45:25 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 06:30:38 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Bra\u017einskas", "Arthur", ""], ["Lapata", "Mirella", ""], ["Titov", "Ivan", ""]]}, {"id": "2004.14905", "submitter": "David Wilmot", "authors": "David Wilmot and Frank Keller", "title": "Modelling Suspense in Short Stories as Uncertainty Reduction over Neural\n  Representation", "comments": "9 pages, 3 figures, accepted as long paper to ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Suspense is a crucial ingredient of narrative fiction, engaging readers and\nmaking stories compelling. While there is a vast theoretical literature on\nsuspense, it is computationally not well understood. We compare two ways for\nmodelling suspense: surprise, a backward-looking measure of how unexpected the\ncurrent state is given the story so far; and uncertainty reduction, a\nforward-looking measure of how unexpected the continuation of the story is.\nBoth can be computed either directly over story representations or over their\nprobability distributions. We propose a hierarchical language model that\nencodes stories and computes surprise and uncertainty reduction. Evaluating\nagainst short stories annotated with human suspense judgements, we find that\nuncertainty reduction over representations is the best predictor, resulting in\nnear-human accuracy. We also show that uncertainty reduction can be used to\npredict suspenseful events in movie synopses.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:03:06 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Wilmot", "David", ""], ["Keller", "Frank", ""]]}, {"id": "2004.14936", "submitter": "Michael Gadermayr", "authors": "Maximilian Ernst Tschuchnig, Gertie Janneke Oostingh, Michael\n  Gadermayr", "title": "Generative Adversarial Networks in Digital Pathology: A Survey on Trends\n  and Future Potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image analysis in the field of digital pathology has recently gained\nincreased popularity. The use of high-quality whole slide scanners enables the\nfast acquisition of large amounts of image data, showing extensive context and\nmicroscopic detail at the same time. Simultaneously, novel machine learning\nalgorithms have boosted the performance of image analysis approaches. In this\npaper, we focus on a particularly powerful class of architectures, called\nGenerative Adversarial Networks (GANs), applied to histological image data.\nBesides improving performance, GANs also enable application scenarios in this\nfield, which were previously intractable. However, GANs could exhibit a\npotential for introducing bias. Hereby, we summarize the recent\nstate-of-the-art developments in a generalizing notation, present the main\napplications of GANs and give an outlook of some chosen promising approaches\nand their possible future applications. In addition, we identify currently\nunavailable methods with potential for future applications.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:38:06 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 06:05:07 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Tschuchnig", "Maximilian Ernst", ""], ["Oostingh", "Gertie Janneke", ""], ["Gadermayr", "Michael", ""]]}, {"id": "2004.14941", "submitter": "Ziv Goldfeld", "authors": "Ziv Goldfeld and Yury Polyanskiy", "title": "The Information Bottleneck Problem and Its Applications in Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference capabilities of machine learning (ML) systems skyrocketed in recent\nyears, now playing a pivotal role in various aspect of society. The goal in\nstatistical learning is to use data to obtain simple algorithms for predicting\na random variable $Y$ from a correlated observation $X$. Since the dimension of\n$X$ is typically huge, computationally feasible solutions should summarize it\ninto a lower-dimensional feature vector $T$, from which $Y$ is predicted. The\nalgorithm will successfully make the prediction if $T$ is a good proxy of $Y$,\ndespite the said dimensionality-reduction. A myriad of ML algorithms (mostly\nemploying deep learning (DL)) for finding such representations $T$ based on\nreal-world data are now available. While these methods are often effective in\npractice, their success is hindered by the lack of a comprehensive theory to\nexplain it. The information bottleneck (IB) theory recently emerged as a bold\ninformation-theoretic paradigm for analyzing DL systems. Adopting mutual\ninformation as the figure of merit, it suggests that the best representation\n$T$ should be maximally informative about $Y$ while minimizing the mutual\ninformation with $X$. In this tutorial we survey the information-theoretic\norigins of this abstract principle, and its recent impact on DL. For the\nlatter, we cover implications of the IB problem on DL theory, as well as\npractical algorithms inspired by it. Our goal is to provide a unified and\ncohesive description. A clear view of current knowledge is particularly\nimportant for further leveraging IB and other information-theoretic ideas to\nstudy DL models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:48:51 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 16:24:03 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Goldfeld", "Ziv", ""], ["Polyanskiy", "Yury", ""]]}, {"id": "2004.14949", "submitter": "Kexin Huang", "authors": "Kexin Huang, Cao Xiao, Lucas Glass, Marinka Zitnik, Jimeng Sun", "title": "SkipGNN: Predicting Molecular Interactions with Skip-Graph Networks", "comments": "Published in Nature Scientific Reports:\n  https://www.nature.com/articles/s41598-020-77766-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Molecular interaction networks are powerful resources for the discovery. They\nare increasingly used with machine learning methods to predict biologically\nmeaningful interactions. While deep learning on graphs has dramatically\nadvanced the prediction prowess, current graph neural network (GNN) methods are\noptimized for prediction on the basis of direct similarity between interacting\nnodes. In biological networks, however, similarity between nodes that do not\ndirectly interact has proved incredibly useful in the last decade across a\nvariety of interaction networks. Here, we present SkipGNN, a graph neural\nnetwork approach for the prediction of molecular interactions. SkipGNN predicts\nmolecular interactions by not only aggregating information from direct\ninteractions but also from second-order interactions, which we call skip\nsimilarity. In contrast to existing GNNs, SkipGNN receives neural messages from\ntwo-hop neighbors as well as immediate neighbors in the interaction network and\nnon-linearly transforms the messages to obtain useful information for\nprediction. To inject skip similarity into a GNN, we construct a modified\nversion of the original network, called the skip graph. We then develop an\niterative fusion scheme that optimizes a GNN using both the skip graph and the\noriginal graph. Experiments on four interaction networks, including drug-drug,\ndrug-target, protein-protein, and gene-disease interactions, show that SkipGNN\nachieves superior and robust performance, outperforming existing methods by up\nto 28.8\\% of area under the precision recall curve (PR-AUC). Furthermore, we\nshow that unlike popular GNNs, SkipGNN learns biologically meaningful\nembeddings and performs especially well on noisy, incomplete interaction\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 16:55:58 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 18:31:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas", ""], ["Zitnik", "Marinka", ""], ["Sun", "Jimeng", ""]]}, {"id": "2004.14954", "submitter": "Guang Cheng", "authors": "Ruiqi Liu, Zuofeng Shang, Guang Cheng", "title": "On Deep Instrumental Variables Estimate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The endogeneity issue is fundamentally important as many empirical\napplications may suffer from the omission of explanatory variables, measurement\nerror, or simultaneous causality. Recently, \\cite{hllt17} propose a \"Deep\nInstrumental Variable (IV)\" framework based on deep neural networks to address\nendogeneity, demonstrating superior performances than existing approaches. The\naim of this paper is to theoretically understand the empirical success of the\nDeep IV. Specifically, we consider a two-stage estimator using deep neural\nnetworks in the linear instrumental variables model. By imposing a latent\nstructural assumption on the reduced form equation between endogenous variables\nand instrumental variables, the first-stage estimator can automatically capture\nthis latent structure and converge to the optimal instruments at the minimax\noptimal rate, which is free of the dimension of instrumental variables and thus\nmitigates the curse of dimensionality. Additionally, in comparison with\nclassical methods, due to the faster convergence rate of the first-stage\nestimator, the second-stage estimator has {a smaller (second order) estimation\nerror} and requires a weaker condition on the smoothness of the optimal\ninstruments. Given that the depth and width of the employed deep neural network\nare well chosen, we further show that the second-stage estimator achieves the\nsemiparametric efficiency bound. Simulation studies on synthetic data and\napplication to automobile market data confirm our theory.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:03:00 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Liu", "Ruiqi", ""], ["Shang", "Zuofeng", ""], ["Cheng", "Guang", ""]]}, {"id": "2004.14958", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka, Eneko\n  Agirre", "title": "A Call for More Rigor in Unsupervised Cross-lingual Learning", "comments": "ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review motivations, definition, approaches, and methodology for\nunsupervised cross-lingual learning and call for a more rigorous position in\neach of them. An existing rationale for such research is based on the lack of\nparallel data for many of the world's languages. However, we argue that a\nscenario without any parallel data and abundant monolingual data is unrealistic\nin practice. We also discuss different training signals that have been used in\nprevious work, which depart from the pure unsupervised setting. We then\ndescribe common methodological issues in tuning and evaluation of unsupervised\ncross-lingual models and present best practices. Finally, we provide a unified\noutlook for different types of research in this area (i.e., cross-lingual word\nembeddings, deep multilingual pretraining, and unsupervised machine\ntranslation) and argue for comparable evaluation of these models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:06:23 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Artetxe", "Mikel", ""], ["Ruder", "Sebastian", ""], ["Yogatama", "Dani", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "2004.14970", "submitter": "Teague Tomesh", "authors": "Teague Tomesh, Pranav Gokhale, Eric R. Anschuetz, Frederic T. Chong", "title": "Coreset Clustering on Small Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many quantum algorithms for machine learning require access to classical data\nin superposition. However, for many natural data sets and algorithms, the\noverhead required to load the data set in superposition can erase any potential\nquantum speedup over classical algorithms. Recent work by Harrow introduces a\nnew paradigm in hybrid quantum-classical computing to address this issue,\nrelying on coresets to minimize the data loading overhead of quantum\nalgorithms. We investigate using this paradigm to perform $k$-means clustering\non near-term quantum computers, by casting it as a QAOA optimization instance\nover a small coreset. We compare the performance of this approach to classical\n$k$-means clustering both numerically and experimentally on IBM Q hardware. We\nare able to find data sets where coresets work well relative to random sampling\nand where QAOA could potentially outperform standard $k$-means on a coreset.\nHowever, finding data sets where both coresets and QAOA work well--which is\nnecessary for a quantum advantage over $k$-means on the entire data\nset--appears to be challenging.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:19:19 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Tomesh", "Teague", ""], ["Gokhale", "Pranav", ""], ["Anschuetz", "Eric R.", ""], ["Chong", "Frederic T.", ""]]}, {"id": "2004.14973", "submitter": "Arjun Majumdar", "authors": "Arjun Majumdar, Ayush Shrivastava, Stefan Lee, Peter Anderson, Devi\n  Parikh, Dhruv Batra", "title": "Improving Vision-and-Language Navigation with Image-Text Pairs from the\n  Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a navigation instruction such as 'Walk down the stairs and stop at\nthe brown sofa' requires embodied AI agents to ground scene elements referenced\nvia language (e.g. 'stairs') to visual content in the environment (pixels\ncorresponding to 'stairs').\n  We ask the following question -- can we leverage abundant 'disembodied'\nweb-scraped vision-and-language corpora (e.g. Conceptual Captions) to learn\nvisual groundings (what do 'stairs' look like?) that improve performance on a\nrelatively data-starved embodied perception task (Vision-and-Language\nNavigation)? Specifically, we develop VLN-BERT, a visiolinguistic\ntransformer-based model for scoring the compatibility between an instruction\n('...stop at the brown sofa') and a sequence of panoramic RGB images captured\nby the agent. We demonstrate that pretraining VLN-BERT on image-text pairs from\nthe web before fine-tuning on embodied path-instruction data significantly\nimproves performance on VLN -- outperforming the prior state-of-the-art in the\nfully-observed setting by 4 absolute percentage points on success rate.\nAblations of our pretraining curriculum show each stage to be impactful -- with\ntheir combination resulting in further positive synergistic effects.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:22:40 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 17:16:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Majumdar", "Arjun", ""], ["Shrivastava", "Ayush", ""], ["Lee", "Stefan", ""], ["Anderson", "Peter", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""]]}, {"id": "2004.14975", "submitter": "Alex Tamkin", "authors": "Alex Tamkin, Trisha Singh, Davide Giovanardi, Noah Goodman", "title": "Investigating Transferability in Pretrained Language Models", "comments": "Findings of EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does language model pretraining help transfer learning? We consider a\nsimple ablation technique for determining the impact of each pretrained layer\non transfer task performance. This method, partial reinitialization, involves\nreplacing different layers of a pretrained model with random weights, then\nfinetuning the entire model on the transfer task and observing the change in\nperformance. This technique reveals that in BERT, layers with high probing\nperformance on downstream GLUE tasks are neither necessary nor sufficient for\nhigh accuracy on those tasks. Furthermore, the benefit of using pretrained\nparameters for a layer varies dramatically with finetuning dataset size:\nparameters that provide tremendous performance improvement when data is\nplentiful may provide negligible benefits in data-scarce settings. These\nresults reveal the complexity of the transfer learning process, highlighting\nthe limitations of methods that operate on frozen models or single data\nsamples.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:23:19 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 00:56:31 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Tamkin", "Alex", ""], ["Singh", "Trisha", ""], ["Giovanardi", "Davide", ""], ["Goodman", "Noah", ""]]}, {"id": "2004.14990", "submitter": "Kimin Lee", "authors": "Michael Laskin, Kimin Lee, Adam Stooke, Lerrel Pinto, Pieter Abbeel,\n  and Aravind Srinivas", "title": "Reinforcement Learning with Augmented Data", "comments": "NeurIPS 2020 camera-ready version. First two authors contributed\n  equally, website: https://mishalaskin.github.io/rad code:\n  https://github.com/MishaLaskin/rad and\n  https://github.com/pokaxpoka/rad_procgen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from visual observations is a fundamental yet challenging problem in\nReinforcement Learning (RL). Although algorithmic advances combined with\nconvolutional neural networks have proved to be a recipe for success, current\nmethods are still lacking on two fronts: (a) data-efficiency of learning and\n(b) generalization to new environments. To this end, we present Reinforcement\nLearning with Augmented Data (RAD), a simple plug-and-play module that can\nenhance most RL algorithms. We perform the first extensive study of general\ndata augmentations for RL on both pixel-based and state-based inputs, and\nintroduce two new data augmentations - random translate and random amplitude\nscale. We show that augmentations such as random translate, crop, color jitter,\npatch cutout, random convolutions, and amplitude scale can enable simple RL\nalgorithms to outperform complex state-of-the-art methods across common\nbenchmarks. RAD sets a new state-of-the-art in terms of data-efficiency and\nfinal performance on the DeepMind Control Suite benchmark for pixel-based\ncontrol as well as OpenAI Gym benchmark for state-based control. We further\ndemonstrate that RAD significantly improves test-time generalization over\nexisting methods on several OpenAI ProcGen benchmarks. Our RAD module and\ntraining code are available at https://www.github.com/MishaLaskin/rad.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:35:32 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 17:16:13 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 17:02:23 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 17:13:45 GMT"}, {"version": "v5", "created": "Thu, 5 Nov 2020 06:04:50 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Laskin", "Michael", ""], ["Lee", "Kimin", ""], ["Stooke", "Adam", ""], ["Pinto", "Lerrel", ""], ["Abbeel", "Pieter", ""], ["Srinivas", "Aravind", ""]]}, {"id": "2004.14996", "submitter": "He Bai", "authors": "He Bai, Peng Shi, Jimmy Lin, Yuqing Xie, Luchen Tan, Kun Xiong, Wen\n  Gao and Ming Li", "title": "Segatron: Segment-Aware Transformer for Language Modeling and\n  Understanding", "comments": "Accepted by AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are powerful for sequence modeling. Nearly all state-of-the-art\nlanguage models and pre-trained language models are based on the Transformer\narchitecture. However, it distinguishes sequential tokens only with the token\nposition index. We hypothesize that better contextual representations can be\ngenerated from the Transformer with richer positional information. To verify\nthis, we propose a segment-aware Transformer (Segatron), by replacing the\noriginal token position encoding with a combined position encoding of\nparagraph, sentence, and token. We first introduce the segment-aware mechanism\nto Transformer-XL, which is a popular Transformer-based language model with\nmemory extension and relative position encoding. We find that our method can\nfurther improve the Transformer-XL base model and large model, achieving 17.1\nperplexity on the WikiText-103 dataset. We further investigate the pre-training\nmasked language modeling task with Segatron. Experimental results show that\nBERT pre-trained with Segatron (SegaBERT) can outperform BERT with vanilla\nTransformer on various NLP tasks, and outperforms RoBERTa on zero-shot sentence\nrepresentation learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:38:27 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 22:29:36 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Bai", "He", ""], ["Shi", "Peng", ""], ["Lin", "Jimmy", ""], ["Xie", "Yuqing", ""], ["Tan", "Luchen", ""], ["Xiong", "Kun", ""], ["Gao", "Wen", ""], ["Li", "Ming", ""]]}, {"id": "2004.15001", "submitter": "Phillip Keung", "authors": "Phillip Keung, Yichao Lu, Julian Salazar, Vikas Bhardwaj", "title": "Don't Use English Dev: On the Zero-Shot Cross-Lingual Evaluation of\n  Contextual Embeddings", "comments": "To appear in EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual contextual embeddings have demonstrated state-of-the-art\nperformance in zero-shot cross-lingual transfer learning, where multilingual\nBERT is fine-tuned on one source language and evaluated on a different target\nlanguage. However, published results for mBERT zero-shot accuracy vary as much\nas 17 points on the MLDoc classification task across four papers. We show that\nthe standard practice of using English dev accuracy for model selection in the\nzero-shot setting makes it difficult to obtain reproducible results on the\nMLDoc and XNLI tasks. English dev accuracy is often uncorrelated (or even\nanti-correlated) with target language accuracy, and zero-shot performance\nvaries greatly at different points in the same fine-tuning run and between\ndifferent fine-tuning runs. These reproducibility issues are also present for\nother tasks with different pre-trained embeddings (e.g., MLQA with XLM-R). We\nrecommend providing oracle scores alongside zero-shot results: still fine-tune\nusing English data, but choose a checkpoint with the target dev set. Reporting\nthis upper bound makes results more consistent by avoiding arbitrarily bad\ncheckpoints.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:47:17 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 09:50:52 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Keung", "Phillip", ""], ["Lu", "Yichao", ""], ["Salazar", "Julian", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "2004.15004", "submitter": "Zijie Wang", "authors": "Zijie J. Wang, Robert Turko, Omar Shaikh, Haekyu Park, Nilaksh Das,\n  Fred Hohman, Minsuk Kahng, Duen Horng Chau", "title": "CNN Explainer: Learning Convolutional Neural Networks with Interactive\n  Visualization", "comments": "11 pages, 14 figures, to be presented at IEEE VIS 2020. For a demo\n  video, see https://youtu.be/HnWIHWFbuUQ . For a live demo, visit\n  https://poloclub.github.io/cnn-explainer/", "journal-ref": null, "doi": "10.1109/TVCG.2020.3030418", "report-no": null, "categories": "cs.HC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning's great success motivates many practitioners and students to\nlearn about this exciting technology. However, it is often challenging for\nbeginners to take their first step due to the complexity of understanding and\napplying deep learning. We present CNN Explainer, an interactive visualization\ntool designed for non-experts to learn and examine convolutional neural\nnetworks (CNNs), a foundational deep learning model architecture. Our tool\naddresses key challenges that novices face while learning about CNNs, which we\nidentify from interviews with instructors and a survey with past students. CNN\nExplainer tightly integrates a model overview that summarizes a CNN's\nstructure, and on-demand, dynamic visual explanation views that help users\nunderstand the underlying components of CNNs. Through smooth transitions across\nlevels of abstraction, our tool enables users to inspect the interplay between\nlow-level mathematical operations and high-level model structures. A\nqualitative user study shows that CNN Explainer helps users more easily\nunderstand the inner workings of CNNs, and is engaging and enjoyable to use. We\nalso derive design lessons from our study. Developed using modern web\ntechnologies, CNN Explainer runs locally in users' web browsers without the\nneed for installation or specialized hardware, broadening the public's\neducation access to modern deep learning techniques.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:49:44 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 01:37:29 GMT"}, {"version": "v3", "created": "Fri, 28 Aug 2020 18:42:23 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Wang", "Zijie J.", ""], ["Turko", "Robert", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Das", "Nilaksh", ""], ["Hohman", "Fred", ""], ["Kahng", "Minsuk", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2004.15015", "submitter": "Eric Wallace", "authors": "Eric Wallace, Mitchell Stern, Dawn Song", "title": "Imitation Attacks and Defenses for Black-box Machine Translation Systems", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversaries may look to steal or attack black-box NLP systems, either for\nfinancial gain or to exploit model errors. One setting of particular interest\nis machine translation (MT), where models have high commercial value and errors\ncan be costly. We investigate possible exploits of black-box MT systems and\nexplore a preliminary defense against such threats. We first show that MT\nsystems can be stolen by querying them with monolingual sentences and training\nmodels to imitate their outputs. Using simulated experiments, we demonstrate\nthat MT model stealing is possible even when imitation models have different\ninput data or architectures than their target models. Applying these ideas, we\ntrain imitation models that reach within 0.6 BLEU of three production MT\nsystems on both high-resource and low-resource language pairs. We then leverage\nthe similarity of our imitation models to transfer adversarial examples to the\nproduction systems. We use gradient-based attacks that expose inputs which lead\nto semantically-incorrect translations, dropped content, and vulgar model\noutputs. To mitigate these vulnerabilities, we propose a defense that modifies\ntranslation outputs in order to misdirect the optimization of imitation models.\nThis defense degrades the adversary's BLEU score and attack success rate at\nsome cost in the defender's BLEU and inference speed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 17:56:49 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 22:05:02 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2021 19:05:24 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Wallace", "Eric", ""], ["Stern", "Mitchell", ""], ["Song", "Dawn", ""]]}]